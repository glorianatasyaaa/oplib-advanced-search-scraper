[
    {
        "judul":[
            "Fast and Accurate Fish Classification from Underwater Video using You only Look Once"
        ],
        "penulis":"Lathifah, Hasna Maudi;Novamizanti, Ledya;Rizal, Syamsul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia is a maritime country and one of the largest archipelago countries in the world. Indonesian fisheries have many types of fish in stock, this causes difficulties in introducing fish species directly. This study designed a fish species classification system using the You Only Look Once (YOLO) architecture. YOLO is an object detection method using a convolutional network that will only be just once. Unlike the convolutional networks in general that spend thousands of networks to obtain an image with computing that is long enough. The architecture of this work using YOLO9000. The dataset consists of 6 classes, that is banded butterflyfish, blue tang surgeonfish, barred hamlet, black side hawkfish, Arabian Picasso triggerfish, dan black margate grunt. System testing produces an accuracy of 92%, IoS 0.75, and 2.223 FPS using Adam optimizer. The proposed system model has good accuracy and fast detection time.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is a maritime country and one of the largest archipelago countries in the world. Indonesian fisheries have many types of fish in stock, this causes difficulties in introducing fish species directly. This study designed a fish species classification system using the You Only Look Once (YOLO) architecture. YOLO is an object detection method using a convolutional network that will only be just once. Unlike the convolutional networks in general that spend thousands of networks to obtain an image with computing that is long enough. The architecture of this work using YOLO9000. The dataset consists of 6 classes, that is banded butterflyfish, blue tang surgeonfish, barred hamlet, black side hawkfish, Arabian Picasso triggerfish, dan black margate grunt. System testing produces an accuracy of 92%, IoS 0.75, and 2.223 FPS using Adam optimizer. The proposed system model has good accuracy and fast detection time.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Design of blockchain-based electronic health records for indonesian context: Narrative review"
        ],
        "penulis":"Sari, Puspita Kencana;Yazid, Setiadi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Healthcare providers in developing countries manage their medical data in Electronic Health Records (EHRs) system in silos with different structures and data formats that causes the problem of data sharing, interoperability, and data security. This paper aims to propose a concept of blockchain-based EHRs that is relevant to the case of developing countries, especially in Indonesia. The research method used is a narrative review of several literature related to the design of blockchain-based EHRs using Smart Contract from 2016-2020. The design proposed permissioned blockchain with several health care stakeholders as nodes in the network. Different with most previous research that using proof-based, we propose to use vote-based consensus protocol to execute transaction faster. Based on number of national health insurance policy holders, outpatient, and inpatient visits per year, the storage capacity required to keep the transaction is estimated around 2,7 TB per year with 77 transactions per seconds. This design is intended to be a contribution for EHRs platform architecture in the future.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Healthcare providers in developing countries manage their medical data in Electronic Health Records (EHRs) system in silos with different structures and data formats that causes the problem of data sharing, interoperability, and data security. This paper aims to propose a concept of blockchain-based EHRs that is relevant to the case of developing countries, especially in Indonesia. The research method used is a narrative review of several literature related to the design of blockchain-based EHRs using Smart Contract from 2016-2020. The design proposed permissioned blockchain with several health care stakeholders as nodes in the network. Different with most previous research that using proof-based, we propose to use vote-based consensus protocol to execute transaction faster. Based on number of national health insurance policy holders, outpatient, and inpatient visits per year, the storage capacity required to keep the transaction is estimated around 2,7 TB per year with 77 transactions per seconds. This design is intended to be a contribution for EHRs platform architecture in the future.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Speech Age-Gender Classification Using Long Short-Term Memory"
        ],
        "penulis":"Nitisara, Galih Rahagi;Suyanto, Suyanto;Ramadhani, Kurniawan Nur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Recognizing the age and gender of a person with certainty from a media has a significant advantage. For example, the perpetrators recorded on a CCTV camera can be easily recognized, or someone used to lie about age on social media or job application applications can be easily detected. However, detecting the exact age of a person is still a tricky thing because of the quality media and the characteristics of the person who seems deceptive. In machine learning, the neural-based methods are commonly used for classification and recognition. However, age and gender classifications stillproduce unsatisfactory results, even age and gender classifications by speech are rarely discussed.Hence, the right approach is needed to create a good age and gender classification model. One of the solutions is using Recurrent Neural Network (RNN), which is made for sequential data like speech.In this paper, a speech age-gender classification model is developed using one of the popular RNN models called Long Short-Term Memory (LSTM). The experimental results show that the proposed model is trapped on the overfitting problem so that the accuracy of the testing set is lower than the training set. Regularization can reduce the difference between the accuracies of both training and testing sets but it cannot increase them. The data augmentation is able to slightly solve the overfitting problem. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recognizing the age and gender of a person with certainty from a media has a significant advantage. For example, the perpetrators recorded on a CCTV camera can be easily recognized, or someone used to lie about age on social media or job application applications can be easily detected. However, detecting the exact age of a person is still a tricky thing because of the quality media and the characteristics of the person who seems deceptive. In machine learning, the neural-based methods are commonly used for classification and recognition. However, age and gender classifications stillproduce unsatisfactory results, even age and gender classifications by speech are rarely discussed.Hence, the right approach is needed to create a good age and gender classification model. One of the solutions is using Recurrent Neural Network (RNN), which is made for sequential data like speech.In this paper, a speech age-gender classification model is developed using one of the popular RNN models called Long Short-Term Memory (LSTM). The experimental results show that the proposed model is trapped on the overfitting problem so that the accuracy of the testing set is lower than the training set. Regularization can reduce the difference between the accuracies of both training and testing sets but it cannot increase them. The data augmentation is able to slightly solve the overfitting problem. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "How to Integrate Enterprise Asset Management System for Smart Hospital: A Case Study"
        ],
        "penulis":"Saputra, Muhardi;Hermawan, Ikhsan;Puspitasari, Warih;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "XYZ Regional Public Hospital is one of the government-owned hospitals of Indonesia, XYZ regional public hospital has numerous patient and employee, yet it has not been supported by a good information system, there is no integrated system that helps the exchange of data between each sector in the hospital. Data exchange is done conventionally by using paper as a physical document. The archives of the document would cost a lot and spent wide space that made several rooms are filled with a pile of archives due to lack of space in the hospital. ERP is a concept that integrates all business process activities of an agency or company so that the processes that occur are mutually sustainable in achieving the goals of an organization, ERP provides a solution for managing complex data and information that runs in the hospital. This research is focusing on designing an ERP system in asset management of the warehousing sector in XYZ regional public hospital using Odoo on Asset Maintenance Module with Quickstart methodology. The result of this research is the ERP system that focused on how the asset maintenance is managed in the hospital and how it will be integrated with inventory sector. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "XYZ Regional Public Hospital is one of the government-owned hospitals of Indonesia, XYZ regional public hospital has numerous patient and employee, yet it has not been supported by a good information system, there is no integrated system that helps the exchange of data between each sector in the hospital. Data exchange is done conventionally by using paper as a physical document. The archives of the document would cost a lot and spent wide space that made several rooms are filled with a pile of archives due to lack of space in the hospital. ERP is a concept that integrates all business process activities of an agency or company so that the processes that occur are mutually sustainable in achieving the goals of an organization, ERP provides a solution for managing complex data and information that runs in the hospital. This research is focusing on designing an ERP system in asset management of the warehousing sector in XYZ regional public hospital using Odoo on Asset Maintenance Module with Quickstart methodology. The result of this research is the ERP system that focused on how the asset maintenance is managed in the hospital and how it will be integrated with inventory sector. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "LORAWAN Internet of Things Network Planning for Smart Metering Services"
        ],
        "penulis":"Yusri, Alvin;Nashiruddin, Muhammad Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Optimization of energy usage is essential to minimize the waste of energy usage. Smart Metering is a solution to resolve this problem. It can measure, collect, analyze energy distribution and its consumption, and communicate with metering devices on schedule and on-demand, i.e., for electricity, water, and gas services. However, selecting the right Internet of Things (IoT) network connectivity to deploy Smart Metering services is still the main challenge, especially for the dense urban setting. LoRaWAN is one of the most popular Low Power Wide Area technologies consider as a suitable IoT network connectivity for Smart Metering because LoRaWAN has a long battery life, using unlicensed frequency and low cost of deployment. In this research, the LoRaWAN IoT network planning to deliver Smart Metering services was conducted in Jakarta City, as representative of the dense urban setting. The network planning methods are using capacity and coverage analysis as well as radio network planning simulation. It is found that to deploy Smart Metering services in the Jakarta City area, at least 23 gateways are required with Spreading Factor (SF) values of 7, Code Rate (CR) of 1\/2\/3\/4, and can serve at the level of receiver sensitivity > -129dBm. An average received signal level of -78.84 dBm with an average of throughput distribution of 21.69 kbps were obtained based on coverage prediction simulation. Meanwhile the Signal to Noise Ratio (SNR) simulation generated the highest SNR is 30 dB, and the lowest SNR is -20dB resulting in the average SNR level of the entire region is about -1.05dB.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Optimization of energy usage is essential to minimize the waste of energy usage. Smart Metering is a solution to resolve this problem. It can measure, collect, analyze energy distribution and its consumption, and communicate with metering devices on schedule and on-demand, i.e., for electricity, water, and gas services. However, selecting the right Internet of Things (IoT) network connectivity to deploy Smart Metering services is still the main challenge, especially for the dense urban setting. LoRaWAN is one of the most popular Low Power Wide Area technologies consider as a suitable IoT network connectivity for Smart Metering because LoRaWAN has a long battery life, using unlicensed frequency and low cost of deployment. In this research, the LoRaWAN IoT network planning to deliver Smart Metering services was conducted in Jakarta City, as representative of the dense urban setting. The network planning methods are using capacity and coverage analysis as well as radio network planning simulation. It is found that to deploy Smart Metering services in the Jakarta City area, at least 23 gateways are required with Spreading Factor (SF) values of 7, Code Rate (CR) of 1\/2\/3\/4, and can serve at the level of receiver sensitivity > -129dBm. An average received signal level of -78.84 dBm with an average of throughput distribution of 21.69 kbps were obtained based on coverage prediction simulation. Meanwhile the Signal to Noise Ratio (SNR) simulation generated the highest SNR is 30 dB, and the lowest SNR is -20dB resulting in the average SNR level of the entire region is about -1.05dB.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Rateless raptor codes for reliable wireless capsule endoscopy (WCE)"
        ],
        "penulis":"Sobiroh, Indriana Fitriotavia Endah;Anwar, Khoirul;Mukhtar, Husneni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Wireless Capsule Endoscopy (WCE) has established as painless endoscopic imaging of the gastrointestinal (GI) tract To improve the performance of video transfer, we propose a rateless Raptor coding scheme with low coding rate to overcome the potential interference from other signals due to the low-power transmission characteristic of the WCE communications. In addition, the proposed Raptor codes with rateless capability can protect the information from error under varying channel conditions between capsule and the receiver outside the body. The proposed Raptor codes are constructed from Low-Density Parity Check (LDPC) and Luby Transform (LT) codes suitable for short block length of WCE applications such that the rateless capability of the codes can adapt to the dynamic GI channel modeled by multipath In-Body-to-On-Body (IB-to-OB) ultra wide band (UWB) channels in the 3.4-4.8 GHz. We also evaluate the performance of the codes under the multipath channel model for WCE using Cyclic-Prefix Orthogonal Frequency Division Multiplexing (CP-OFDM) in terms of average bit error rate (BER) using a series of computer simulations. The results confirmed that the proposed rateless Raptor codes can adapt well to the dynamic changes of channel conditions and are suitable for practical reliable WCE applications. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Wireless Capsule Endoscopy (WCE) has established as painless endoscopic imaging of the gastrointestinal (GI) tract To improve the performance of video transfer, we propose a rateless Raptor coding scheme with low coding rate to overcome the potential interference from other signals due to the low-power transmission characteristic of the WCE communications. In addition, the proposed Raptor codes with rateless capability can protect the information from error under varying channel conditions between capsule and the receiver outside the body. The proposed Raptor codes are constructed from Low-Density Parity Check (LDPC) and Luby Transform (LT) codes suitable for short block length of WCE applications such that the rateless capability of the codes can adapt to the dynamic GI channel modeled by multipath In-Body-to-On-Body (IB-to-OB) ultra wide band (UWB) channels in the 3.4-4.8 GHz. We also evaluate the performance of the codes under the multipath channel model for WCE using Cyclic-Prefix Orthogonal Frequency Division Multiplexing (CP-OFDM) in terms of average bit error rate (BER) using a series of computer simulations. The results confirmed that the proposed rateless Raptor codes can adapt well to the dynamic changes of channel conditions and are suitable for practical reliable WCE applications. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis the measurement quality system of clearence tappet using measurement system analysis on motorcycle manufacturing company"
        ],
        "penulis":"Doaly, Carla Olyvia;Sriwana, Iphov K.;Salomon, Lithrone;Farrell;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A motorcycle manufacturing company on the K56S engine has a symptom that often occurs called noise tappet. The observations found that Symptom was caused by clearence or tappet gap that was not in accordance with the specified specifications. The gap measurement system uses fuller which usually relies on the experience and feeling of the operator, so it is possible to produce an unsuitable gap measurement. This research will evaluate the measurement system of clearence tappet using Measurement system analysis (MSA) which includes stability, bias, linearity, repeatability & reproducibility. Based on data processing known that the measurement system has a stable process with a linearity level of 2.6% is acceptable. The measurement system has a biased problem with an average bias value of 0.054 mm (not acceptable) and from repeatability & reproducibility with a GRR% of ANOVA method of 49.98% that exceeds the acceptance criteria. \u00a9 2020 Institute of Physics Publishing. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A motorcycle manufacturing company on the K56S engine has a symptom that often occurs called noise tappet. The observations found that Symptom was caused by clearence or tappet gap that was not in accordance with the specified specifications. The gap measurement system uses fuller which usually relies on the experience and feeling of the operator, so it is possible to produce an unsuitable gap measurement. This research will evaluate the measurement system of clearence tappet using Measurement system analysis (MSA) which includes stability, bias, linearity, repeatability & reproducibility. Based on data processing known that the measurement system has a stable process with a linearity level of 2.6% is acceptable. The measurement system has a biased problem with an average bias value of 0.054 mm (not acceptable) and from repeatability & reproducibility with a GRR% of ANOVA method of 49.98% that exceeds the acceptance criteria. \u00a9 2020 Institute of Physics Publishing. All rights reserved."
        ]
    },
    {
        "judul":[
            "City-TSP with Objective Minimizing Distance and Noise"
        ],
        "penulis":"Aurachman, Rio;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Urbanization has encouraged people to have a home in the city. The process of transportation and logistics is also forced to pass through the city area. There is a need to formulate solutions to transportation, supply chain, and logistics problems for cities. One of the commonly used transportation models is the TSP, the Traveling Salesman Problem. Through this paper, we propose a City-TSP, which is a TSP that considers objectives, parameters, and constraints in urban areas. One of the parameters considered is the noise generated from a truck trip. This paper presents the City-TSP model that simultaneously minimizes distance and noise.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Urbanization has encouraged people to have a home in the city. The process of transportation and logistics is also forced to pass through the city area. There is a need to formulate solutions to transportation, supply chain, and logistics problems for cities. One of the commonly used transportation models is the TSP, the Traveling Salesman Problem. Through this paper, we propose a City-TSP, which is a TSP that considers objectives, parameters, and constraints in urban areas. One of the parameters considered is the noise generated from a truck trip. This paper presents the City-TSP model that simultaneously minimizes distance and noise.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Personal performance measurement of project manager using project manager competency development framework (PMCDF\u00ae) (case study PT.XYZ)"
        ],
        "penulis":"Wahyuni, Sarah;Pratami, Devi;Bay, Achmad Fuad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT. XYZ is a company engaged in telecommunications construction. So far, the company has conducted performance appraisals of its employees using the rating scale method. The assessment conducted by the company is less objective because the assessment is carried out by two supervisors of the object being assessed. In addition, the results are only used for consideration of promotion. The format made by the company also has no KPI or minimum value used in assessing. Based on this, a valuation format and a more objective assessment system are needed with the aim of knowing how the personal competencies of managers. Personal competency measurements are carried out at the project manager level with an assessment format based on PMCDF\u00ae, 360 feedbacks as a scoring system, and AHP as weighting on six PMCDF\u00ae competencies. From the results of the study, the priority results obtained in the six competencies variable PMCDF\u00ae are Managing with a weight of 40%, Leading with a weight of 23%, and Communicating with a weight of 11%. The personal competency score of the project manager for each competence is in good category. \u00a9 2020 Institute of Physics Publishing. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. XYZ is a company engaged in telecommunications construction. So far, the company has conducted performance appraisals of its employees using the rating scale method. The assessment conducted by the company is less objective because the assessment is carried out by two supervisors of the object being assessed. In addition, the results are only used for consideration of promotion. The format made by the company also has no KPI or minimum value used in assessing. Based on this, a valuation format and a more objective assessment system are needed with the aim of knowing how the personal competencies of managers. Personal competency measurements are carried out at the project manager level with an assessment format based on PMCDF\u00ae, 360 feedbacks as a scoring system, and AHP as weighting on six PMCDF\u00ae competencies. From the results of the study, the priority results obtained in the six competencies variable PMCDF\u00ae are Managing with a weight of 40%, Leading with a weight of 23%, and Communicating with a weight of 11%. The personal competency score of the project manager for each competence is in good category. \u00a9 2020 Institute of Physics Publishing. All rights reserved."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Optimization of rice husk ash (Rha) as partial replacement of cementing material in structural ceramic composite concrete using response surface methodology (rsm) statistical experimental design"
        ],
        "penulis":"Fazli, Aliff Akhmal Mohd;Zakaria, Siti Koriah;Rahman, Nur Iman Najwa Abd;Salleh, Siti Zuliana;Yusoff, Abdul Hafidz;Salleh, Nurul Azita;Taib, Mustaffa Ali Azhar;Budiman, Faisal;Ali, Arlina;Teo, Pao Ter;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Rapid development in the concrete industry leads to a higher demand for cement consumption worldwide. Due to this, the production of cement has become very crucial, resulting in a high carbon footprint and pollution along the process. Therefore, the utilization of agricultural by-products as cement replacement will help to reduce pollution caused by conventional cement production and therefore reduce the unsystematic waste management. Rice husk ash contains high silica content that makes it a potential material to partially replace cement in concrete production. This is because, the reaction between rice husk ash and cement can improve the compressive strength of the concrete. With the aid of response surface methodology, the optimization of utilizing rice husk ash as a partial replacement of cement in concrete can be achieved. Therefore, concrete incorporated with rice husk ash with high and optimum compressive strength can be produced. \u00a9 2020, Hanyang University. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rapid development in the concrete industry leads to a higher demand for cement consumption worldwide. Due to this, the production of cement has become very crucial, resulting in a high carbon footprint and pollution along the process. Therefore, the utilization of agricultural by-products as cement replacement will help to reduce pollution caused by conventional cement production and therefore reduce the unsystematic waste management. Rice husk ash contains high silica content that makes it a potential material to partially replace cement in concrete production. This is because, the reaction between rice husk ash and cement can improve the compressive strength of the concrete. With the aid of response surface methodology, the optimization of utilizing rice husk ash as a partial replacement of cement in concrete can be achieved. Therefore, concrete incorporated with rice husk ash with high and optimum compressive strength can be produced. \u00a9 2020, Hanyang University. All rights reserved."
        ]
    },
    {
        "judul":[
            "Implementation Face Recognition Attendance Monitoring System for Lab Surveillance with Hash Encryption"
        ],
        "penulis":"Hamami F.;Dahlan I.A.;Prakosa S.W.;Somantri K.F.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Face recognition (FR) is becoming popular to identify people. In fact, using the FR scheme, surveillance tasks can be built by recognizing people from their faces. This paper presents the implementation of face recognition as a biometric method for smart attendance as well as we also proposed the integrated scheme from capturing data from edge devices (CCTVs), streaming data to the dedicated server, then presenting the real-time data through android mobile devices. In this scheme, we proposed to employ deep learning algorithms based on the Convolutional Neural Network (CNN). Throughthe CCTV data streaming, faces are captured and matched with the database. Therefore, it is considered as their logging attendance. Furthermore, it is marked and stored into the database. This system prototype is developed by big data technology to tackle this complexity of data. The recognized faces can be monitored in real time monitoring. Eventually, real time reports are delivered through the web and android device with API after the data transmission is secured with hash encryption. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Face recognition (FR) is becoming popular to identify people. In fact, using the FR scheme, surveillance tasks can be built by recognizing people from their faces. This paper presents the implementation of face recognition as a biometric method for smart attendance as well as we also proposed the integrated scheme from capturing data from edge devices (CCTVs), streaming data to the dedicated server, then presenting the real-time data through android mobile devices. In this scheme, we proposed to employ deep learning algorithms based on the Convolutional Neural Network (CNN). Throughthe CCTV data streaming, faces are captured and matched with the database. Therefore, it is considered as their logging attendance. Furthermore, it is marked and stored into the database. This system prototype is developed by big data technology to tackle this complexity of data. The recognized faces can be monitored in real time monitoring. Eventually, real time reports are delivered through the web and android device with API after the data transmission is secured with hash encryption. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Detection of Multi-Class Glaucoma Using Active Contour Snakes and Support Vector Machine"
        ],
        "penulis":"Zulfira, Fakhira Zahra;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "There are several ways to detect glaucoma, one of the most accurate is the presence of peripapillary atrophy (PPA). PPA is located outside the optic disc around the optic nerve head (ONH) and sometimes looks vague which can cause misclassification, so other parameters that can detect glaucoma are needed. The calculation of the optic cup to disc ratio (CDR) is mostly done for glaucoma detection so that CDR can be considered in addition to the presence of PPA to improve classification results. In this paper, a multi-class glaucoma detection is developed using an active contour snake to get the value of the optic cup and optic disc to measure CDR and a support vector machine (SVM) for classification. Glaucoma is categorized into three classes: non-glaucoma, mild-glaucoma, and severe-glaucoma. Hence, the model can detect its severity which determines further treatment. Evaluation using two datasets of 210 retinal fundus images (165 train and 45 test) informs that the model reaches high accuracies of 95%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "There are several ways to detect glaucoma, one of the most accurate is the presence of peripapillary atrophy (PPA). PPA is located outside the optic disc around the optic nerve head (ONH) and sometimes looks vague which can cause misclassification, so other parameters that can detect glaucoma are needed. The calculation of the optic cup to disc ratio (CDR) is mostly done for glaucoma detection so that CDR can be considered in addition to the presence of PPA to improve classification results. In this paper, a multi-class glaucoma detection is developed using an active contour snake to get the value of the optic cup and optic disc to measure CDR and a support vector machine (SVM) for classification. Glaucoma is categorized into three classes: non-glaucoma, mild-glaucoma, and severe-glaucoma. Hence, the model can detect its severity which determines further treatment. Evaluation using two datasets of 210 retinal fundus images (165 train and 45 test) informs that the model reaches high accuracies of 95%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Determinant factors to become a gig worker in an online course"
        ],
        "penulis":"Alif, Ifa;Sucahyo, Yudho Giri;Gandhi, Arfive;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "As the trending learning system, online course has actualized the concept of gig economy. People can participate as a gig worker using these roles: a tutor, a teacher, and a content creator in an online course while the students are clients. Some problems have occurred as a relatively new business model in Indonesia, the gig economy did not offer stable and fixed employment, and most of gig workers had no education background. This research aimed to look for determinant factors that motivate people to become gig workers in an online course. This brought Technology Acceptance Model (TAM) and Unified Theory of Acceptance and Use of Technology (UTAUT) as foundations. Relying on a quantitative approach in a questionnaire, eleven hypotheses were examined using Partial List Square-Structural Equation Modeling (PLS-SEM). 187 respondents took part to expose their perception about the candidate of determinant factors. Its result distinguished eight accepted hypotheses, while three others were rejected. This research captured the following variables as determinant factors with a positive relationship: social influence, the factors of benefit, personal interest, and economic value. In contrast, the perceived risk was a negative determinant factor. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "As the trending learning system, online course has actualized the concept of gig economy. People can participate as a gig worker using these roles: a tutor, a teacher, and a content creator in an online course while the students are clients. Some problems have occurred as a relatively new business model in Indonesia, the gig economy did not offer stable and fixed employment, and most of gig workers had no education background. This research aimed to look for determinant factors that motivate people to become gig workers in an online course. This brought Technology Acceptance Model (TAM) and Unified Theory of Acceptance and Use of Technology (UTAUT) as foundations. Relying on a quantitative approach in a questionnaire, eleven hypotheses were examined using Partial List Square-Structural Equation Modeling (PLS-SEM). 187 respondents took part to expose their perception about the candidate of determinant factors. Its result distinguished eight accepted hypotheses, while three others were rejected. This research captured the following variables as determinant factors with a positive relationship: social influence, the factors of benefit, personal interest, and economic value. In contrast, the perceived risk was a negative determinant factor. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Experimental and Simulation Approach for Water Bed Movements"
        ],
        "penulis":"Jaya, Alya Alifia Anwar;Gunawan P.H.;Aditsania, Annisa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper examines the simulation of a 1D half nonlinear shallow water model using a staggered grid scheme for comparing with experiment results. Here, the experiment of the moving bottom problem in one-directional horizontal is given. The experiment was built in a glass basin with an obstacle as the moving bottom. Indeed, the impact of moving the bottom in shallow water can generate surface waves with various elevation values. The results showed that numerical simulation using nonlinear shallow water equations is close enough with the experimental data. The comparison of water elevation from simulation results and experimental data is observed in three gauge which are shown as G 1, G 2, and G 3. Using the initial condition of water elevation 0.1 m, then the error measurement of each gauge are obtained less than 10 {-3}.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper examines the simulation of a 1D half nonlinear shallow water model using a staggered grid scheme for comparing with experiment results. Here, the experiment of the moving bottom problem in one-directional horizontal is given. The experiment was built in a glass basin with an obstacle as the moving bottom. Indeed, the impact of moving the bottom in shallow water can generate surface waves with various elevation values. The results showed that numerical simulation using nonlinear shallow water equations is close enough with the experimental data. The comparison of water elevation from simulation results and experimental data is observed in three gauge which are shown as G 1, G 2, and G 3. Using the initial condition of water elevation 0.1 m, then the error measurement of each gauge are obtained less than 10 {-3}.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Leader-follower synchronization of uncertain Euler-Lagrange dynamics with input constraints"
        ],
        "penulis":"Rosa, Muhammad Ridho;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper addresses the problem of leader-follower synchronization of uncertain Euler-Lagrange systems under input constraints. The problem is solved in a distributed model reference adaptive control framework that includes positive m-modification to address input constraints. The proposed design has the distinguishing features of updating the gains to synchronize the uncertain systems and of providing stable adaptation in the presence of input saturation. By using a matching condition assumption, a distributed inverse dynamics architecture is adopted to guarantee convergence to common dynamics. The design is studied analytically, and its performance is validated in simulation using spacecraft dynamics. \u00a9 2020 by the authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper addresses the problem of leader-follower synchronization of uncertain Euler-Lagrange systems under input constraints. The problem is solved in a distributed model reference adaptive control framework that includes positive m-modification to address input constraints. The proposed design has the distinguishing features of updating the gains to synchronize the uncertain systems and of providing stable adaptation in the presence of input saturation. By using a matching condition assumption, a distributed inverse dynamics architecture is adopted to guarantee convergence to common dynamics. The design is studied analytically, and its performance is validated in simulation using spacecraft dynamics. \u00a9 2020 by the authors."
        ]
    },
    {
        "judul":[
            "Single Speaker Recognition Using Deep Belief Network Gender Classification Voices"
        ],
        "penulis":"Prasetio, Murman Dwi;Sekizaki, Shinya;Hayashida, Tomohiro;Susanto, Agus;Nishisaki, Ichiro;Abdillah, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Recently, the algorithm of machine learning are used to able to train, enhance, characterize and anticipate the data results accurately. In a way to training, the process on the algorithm can be able to produce an appropriate model based on that data; it's like supervised and unsupervised data. In this paper, we tried to trace the gender (male and female) from acoustic data i.e., pitch, median, frequency etc. The gender that would like to implement is classified on the basis of the intensity of their utterances. To analyze the utterances, the voice intensity measuring by the hamming window to make a normalize curve to obtain the peaks of the utterances where peaks are found from each frame of speech utterance when it is divided into frames of the length of 20 milliseconds. At certain amplitude levels it can be considered to find a peak. As well as making decisions about gender use a thresholds that are adapted are adjusted. If the area of an utterance is above the threshold the gender type is a female otherwise male. After that, we handle the feature learning from the utterance into deep belief network as a machine learning tool to predict single speech by gender classification voices with optimization (taboo search) to train several neurons in the initial weight vector for the accuracy of female and male voices 75.67% and 80.83% precisely.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recently, the algorithm of machine learning are used to able to train, enhance, characterize and anticipate the data results accurately. In a way to training, the process on the algorithm can be able to produce an appropriate model based on that data; it's like supervised and unsupervised data. In this paper, we tried to trace the gender (male and female) from acoustic data i.e., pitch, median, frequency etc. The gender that would like to implement is classified on the basis of the intensity of their utterances. To analyze the utterances, the voice intensity measuring by the hamming window to make a normalize curve to obtain the peaks of the utterances where peaks are found from each frame of speech utterance when it is divided into frames of the length of 20 milliseconds. At certain amplitude levels it can be considered to find a peak. As well as making decisions about gender use a thresholds that are adapted are adjusted. If the area of an utterance is above the threshold the gender type is a female otherwise male. After that, we handle the feature learning from the utterance into deep belief network as a machine learning tool to predict single speech by gender classification voices with optimization (taboo search) to train several neurons in the initial weight vector for the accuracy of female and male voices 75.67% and 80.83% precisely.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Restaurant Recommender System Using User-Based Collaborative Filtering Approach: A Case Study at Bandung Raya Region"
        ],
        "penulis":"Fakhri, Alif Azhar;Baizal Z.K.A.;Setiawan, Erwin Budi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Culinary becomes one of the needs of today's society. The large number of restaurant choices and also lack of information about the restaurant become an obstacle to people's needs in choosing a restaurant. In this paper, we build a recommender system that can recommend the restaurant in Bandung area. However, today, users want to get a restaurant with a good reputation and fit their tastes, so that restaurant ratings from other users are required in the restaurant recommendation process. We implement a user-based collaborative filtering method for recommend a restaurant personally, based on ratings given by other users. We also implement two similarities, i.e., user rating similarity and user attribute similarity to find the proximity between users. We use Mean Absolute Error (MAE) to evaluate accuration of rating prediction. The best MAE result of each performance is 1.492 for calculation without user attributes and 2.166 for calculation with user attributes. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Culinary becomes one of the needs of today's society. The large number of restaurant choices and also lack of information about the restaurant become an obstacle to people's needs in choosing a restaurant. In this paper, we build a recommender system that can recommend the restaurant in Bandung area. However, today, users want to get a restaurant with a good reputation and fit their tastes, so that restaurant ratings from other users are required in the restaurant recommendation process. We implement a user-based collaborative filtering method for recommend a restaurant personally, based on ratings given by other users. We also implement two similarities, i.e., user rating similarity and user attribute similarity to find the proximity between users. We use Mean Absolute Error (MAE) to evaluate accuration of rating prediction. The best MAE result of each performance is 1.492 for calculation without user attributes and 2.166 for calculation with user attributes. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Accurate thermal conductivity measurement of Java and Sumatra rock samples using time varying heat flow measurement"
        ],
        "penulis":"Nurhandoko, Bagus Endar B.;Kurniadi, Rizal;Widowati, Sri;Susilowati;Martha, Rio K.;Listyobudi, Mahatman;Komara, Insan Rizal;Kusudiharjo, Danang;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Thermal conductivity is an important parameter for many applications, including having an essential role in the thermal history reconstruction of a petroleum system. This paper will present an accurate methodology of rock's thermal conductivity measurement by time-varying heat flow. The thermal conductivity measurements were done to various lithologies of rock samples from Java and Sumatra, including mud from Purwodadi Bledug Kuwu mudflow. The collected sample cover many lithologies, such as Limestone, Volcanic, Shale, Coal, and Sand.Particular measurement of time-varying heat flow has been designed and applied to various samples. The equipment consists temperature sensors, heat source, heat measurement and data recorder. The measurement results show that the thermal conductivity of shale rocks ranges from 0.414-2.749 J \/ s.m.\u00b0C, sandstone 0.931-2.748 J \/ s.m.\u00b0C, coal 0.353 J \/ s.m.\u00b0C whereas limestone carbonate is 0.92-6.86 J \/ s.m.\u00b0C. The thermal conductivity of each type of rock is unique, even for the same rock's lithology may have different values. The thermal conductivity parameter is influenced by the particle size distribution, pore parameter including pore shape or pore structure, fracture parameter of rock, and even the fluid or water content in the rock pores. \u00a9 Published under licence by IOP Publishing Ltd.",
            "OOOCaView detailsExpand Substance calcium carbonate",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Thermal conductivity is an important parameter for many applications, including having an essential role in the thermal history reconstruction of a petroleum system. This paper will present an accurate methodology of rock's thermal conductivity measurement by time-varying heat flow. The thermal conductivity measurements were done to various lithologies of rock samples from Java and Sumatra, including mud from Purwodadi Bledug Kuwu mudflow. The collected sample cover many lithologies, such as Limestone, Volcanic, Shale, Coal, and Sand.Particular measurement of time-varying heat flow has been designed and applied to various samples. The equipment consists temperature sensors, heat source, heat measurement and data recorder. The measurement results show that the thermal conductivity of shale rocks ranges from 0.414-2.749 J \/ s.m.\u00b0C, sandstone 0.931-2.748 J \/ s.m.\u00b0C, coal 0.353 J \/ s.m.\u00b0C whereas limestone carbonate is 0.92-6.86 J \/ s.m.\u00b0C. The thermal conductivity of each type of rock is unique, even for the same rock's lithology may have different values. The thermal conductivity parameter is influenced by the particle size distribution, pore parameter including pore shape or pore structure, fracture parameter of rock, and even the fluid or water content in the rock pores. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Firm Innovation Capability through Knowledge Sharing at Indonesian Small and Medium Industries: Impact of Tacit and Explicit Knowledge Perspective"
        ],
        "penulis":"Rumanti, Augustina Asih;Wiratmadja, Iwan Inrawan;Sunaryo, Indryati;Ajidarma, Praditya;Ari Samadhi T.M.A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tacit knowledge is an asset that is embedded in an individual, while explicit knowledge is a type of knowledge that can be readily documented in an organization. Both types of knowledge are crucial for knowledge sharing within any organization as both are primary factors to boost innovation capability. Knowledge sharing process requires an enabler in its process. This research studies Small and Medium Industries (SMI), where knowledge sharing between one SMI to another is necessary, which enables a group of SMIs within a certain area to grow altogether. This research aims to analyze how the innovation capability of a company is influenced by knowledge sharing with the perspective of both tacit and explicit knowledge. The result shows that each indicator in every construct has a good validity, reliability, and significance level, which evidently suggests that a company's capacity to share knowledge, both tacitly and explicitly, is indeed significant and influential towards the innovation capability of such company in this case, SMI. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tacit knowledge is an asset that is embedded in an individual, while explicit knowledge is a type of knowledge that can be readily documented in an organization. Both types of knowledge are crucial for knowledge sharing within any organization as both are primary factors to boost innovation capability. Knowledge sharing process requires an enabler in its process. This research studies Small and Medium Industries (SMI), where knowledge sharing between one SMI to another is necessary, which enables a group of SMIs within a certain area to grow altogether. This research aims to analyze how the innovation capability of a company is influenced by knowledge sharing with the perspective of both tacit and explicit knowledge. The result shows that each indicator in every construct has a good validity, reliability, and significance level, which evidently suggests that a company's capacity to share knowledge, both tacitly and explicitly, is indeed significant and influential towards the innovation capability of such company in this case, SMI. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Decision Making in Inventory Policy Determination for Each Echelon to Stabilize Capsicum Frutescens Price and Increase Farmers Share Value Using Discrete Event Simulation"
        ],
        "penulis":"Novitasari, Nia;Setyawan E.B.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Capsicum frutescens is one of the vegetable commodities that can affect the dynamics of the national economy. The dynamics of the national economy is due to significant fluctuations in chili prices in Indonesia at all times. Price fluctuations occur due to lack of information either in the form of demand information or Chilean price information about consumers received by farmers for marketing red pepper. Besides, the length of the distribution of red pepper (farmer- the middleman- wholesaler- retailer- consumer) results in significant price changes from farmers to consumers at each echelon or distribution level. Such price changes result in a decline in the farmer's share. Farmer's share has a negative relationship with marketing margins. the negative relationship is the higher the marketing margin, the lower the share received by the farmer. from the explanation, the concept shows that the victims of the length of the distribution channel are farmers and consumers. Where farmers will bear a high business risk, and consumers will get high chili prices. The research will discuss how to stabilize the price of red pepper and improve farmer's share by making the best decision using discrete simulation using Monte Carlo, so it can determine the supply policy by the distribution at each level aimed at reducing the operational cost. Besides, this can also reduce the hoarding activities undertaken by the relevant distribution. The hoarding can disrupt the stability of the existing chili price. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Capsicum frutescens is one of the vegetable commodities that can affect the dynamics of the national economy. The dynamics of the national economy is due to significant fluctuations in chili prices in Indonesia at all times. Price fluctuations occur due to lack of information either in the form of demand information or Chilean price information about consumers received by farmers for marketing red pepper. Besides, the length of the distribution of red pepper (farmer- the middleman- wholesaler- retailer- consumer) results in significant price changes from farmers to consumers at each echelon or distribution level. Such price changes result in a decline in the farmer's share. Farmer's share has a negative relationship with marketing margins. the negative relationship is the higher the marketing margin, the lower the share received by the farmer. from the explanation, the concept shows that the victims of the length of the distribution channel are farmers and consumers. Where farmers will bear a high business risk, and consumers will get high chili prices. The research will discuss how to stabilize the price of red pepper and improve farmer's share by making the best decision using discrete simulation using Monte Carlo, so it can determine the supply policy by the distribution at each level aimed at reducing the operational cost. Besides, this can also reduce the hoarding activities undertaken by the relevant distribution. The hoarding can disrupt the stability of the existing chili price. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Development of high power class-E amplifier for radio communication of tsunami early warning system"
        ],
        "penulis":"Kusmadi, Kusmadi;Syihabuddin, Budi;Aji, Galih Mustiko;Fajar Pratiwi, Artdhita;Purwiyanto, Purwiyanto;Chairunnisa, Chairunnisa;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Utilization of radio communication is one of alternative methods which can be offered to the society in responding tsunami warning. In order to have large coverage, the used radio communication requires high power output of radio frequency (RF) amplifier. This paper deals with the development of high power class-E amplifier implemented for radio communication of tsunami early warning systems (TEWS). The proposed amplifier is developed using a power laterally-diffused metal-oxide semiconductor (LDMOS) transistor of BLF188XR type from Am-pleon as the main component. The frequency range of developed amplifier is 90MHz to 110 MHz which is suited for proposed radio communication of TEWS. Some attempts to attain high power amplification are performed through a circuit EM simulator software. Based on the optimum performance, the proposed amplifier is then deployed on a printed circuit board (PCB) for experimental measurement. The result shows that the realized amplifier has the gain achievement more than 21 dB at the frequency of 100 MHz suitable for the desired application. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Utilization of radio communication is one of alternative methods which can be offered to the society in responding tsunami warning. In order to have large coverage, the used radio communication requires high power output of radio frequency (RF) amplifier. This paper deals with the development of high power class-E amplifier implemented for radio communication of tsunami early warning systems (TEWS). The proposed amplifier is developed using a power laterally-diffused metal-oxide semiconductor (LDMOS) transistor of BLF188XR type from Am-pleon as the main component. The frequency range of developed amplifier is 90MHz to 110 MHz which is suited for proposed radio communication of TEWS. Some attempts to attain high power amplification are performed through a circuit EM simulator software. Based on the optimum performance, the proposed amplifier is then deployed on a printed circuit board (PCB) for experimental measurement. The result shows that the realized amplifier has the gain achievement more than 21 dB at the frequency of 100 MHz suitable for the desired application. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Critical Failure Factors in Enterprise Resource Planning (ERP) Implementation: Case Study of PT.Toyota Astra Motor Indonesia"
        ],
        "penulis":"Prasetyo, Sardhika Janar;Lubis, Muharman;Witjaksono, R. Wahjoe;Azizah, Anik Hanifatul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In addition to the popularity of ERP usage, the failure rate of ERP implementation in the company is quite high, the results obtained indicate that the failure of ERP implementation ranges from 67% -90%, the current study mostly discusses Critical Success Factors (CSF) rather than Critical Failure Factors (CFF), there are 6% of journals that are successfully published, which contain CSF and less than 1% that discuss CFF. The inhibiting factors of ERP implementation are more often found in ERP implementation in developing countries, because ERP systems are built and designed with and for better technology in developed countries. The main objective of this research is to identify the factors that become obstacles and classify them to help industries in developing countries, especially companies that are the object of research in this case PT. Toyota Astra Motor, consultants and implementers to prevent failure in the implementation of ERP projects using CFF (Critical Failure Factors) models with 7 variables and assisted with SPSS and SmartPLS for calculation methods. Based on the results of the study using the CFF model at PT. Toyota Astra Motor is known that variables that have no significant and strong effect are Process Variables. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In addition to the popularity of ERP usage, the failure rate of ERP implementation in the company is quite high, the results obtained indicate that the failure of ERP implementation ranges from 67% -90%, the current study mostly discusses Critical Success Factors (CSF) rather than Critical Failure Factors (CFF), there are 6% of journals that are successfully published, which contain CSF and less than 1% that discuss CFF. The inhibiting factors of ERP implementation are more often found in ERP implementation in developing countries, because ERP systems are built and designed with and for better technology in developed countries. The main objective of this research is to identify the factors that become obstacles and classify them to help industries in developing countries, especially companies that are the object of research in this case PT. Toyota Astra Motor, consultants and implementers to prevent failure in the implementation of ERP projects using CFF (Critical Failure Factors) models with 7 variables and assisted with SPSS and SmartPLS for calculation methods. Based on the results of the study using the CFF model at PT. Toyota Astra Motor is known that variables that have no significant and strong effect are Process Variables. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Segment repetition based on high amplitude to enhance a speech emotion recognition"
        ],
        "penulis":"Prayitno, Bagas Adi;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Speech Emotion Recognition (SER) is a technology developed on a computer to realize a Human-Computer Interaction (HCI). It is a challenging task since the lack of data. Some data augmentation methods have been created to increase the data variation, but they do not significantly improve accuracy. Therefore, a new additional data augmentation method called Segment Repetition based on High Amplitude (SRHA) is proposed to solve this problem. This method makes some repetitions on the segments that have the highest amplitude. An experiment of 10 times data augmentation, using five standard augmentations and the additional SRHA with a Long Short-Term Memory (LSTM) as the classifier, shows that the proposed SRHA significantly increases the SER accuracy from 95.88% to 98.16%. Other experiments for 20 and 40 times data augmentations also show that the SRHA outperforms the five standard augmentations. These indicate that the SRHA is a powerful data augmentation method for SER. \u00a9 2019 The Authors. Published by Elsevier B.V.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Speech Emotion Recognition (SER) is a technology developed on a computer to realize a Human-Computer Interaction (HCI). It is a challenging task since the lack of data. Some data augmentation methods have been created to increase the data variation, but they do not significantly improve accuracy. Therefore, a new additional data augmentation method called Segment Repetition based on High Amplitude (SRHA) is proposed to solve this problem. This method makes some repetitions on the segments that have the highest amplitude. An experiment of 10 times data augmentation, using five standard augmentations and the additional SRHA with a Long Short-Term Memory (LSTM) as the classifier, shows that the proposed SRHA significantly increases the SER accuracy from 95.88% to 98.16%. Other experiments for 20 and 40 times data augmentations also show that the SRHA outperforms the five standard augmentations. These indicate that the SRHA is a powerful data augmentation method for SER. \u00a9 2019 The Authors. Published by Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Music fingerprinting based on bhattacharya distance for song and cover song recognition"
        ],
        "penulis":"Sarno, Riyanarto;Wijaya, Dedy Rahman;Mahardika, Muhammad Nezar;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "People often have trouble recognizing a song especially, if the song is sung by a not original artist which is called cover song. Hence, an identification system might be used to help recognize a song or to detect copyright violation. In this study, we try to recognize a song and a cover song by using the fingerprint of the song represented by features extracted from MPEG-7. The fingerprint of the song is represented by Audio Signature Type. Moreover, the fingerprint of the cover song is represented by Audio Spectrum Flatness and Audio Spectrum Projection. Furthermore, we propose a sliding algorithm and k-Nearest Neighbor (k-NN) with Bhattacharyya distance for song recognition and cover song recognition. The results of this experiment show that the proposed fingerprint technique has an accuracy of 100% for song recognition and an accuracy of 85.3% for cover song recognition. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "People often have trouble recognizing a song especially, if the song is sung by a not original artist which is called cover song. Hence, an identification system might be used to help recognize a song or to detect copyright violation. In this study, we try to recognize a song and a cover song by using the fingerprint of the song represented by features extracted from MPEG-7. The fingerprint of the song is represented by Audio Signature Type. Moreover, the fingerprint of the cover song is represented by Audio Spectrum Flatness and Audio Spectrum Projection. Furthermore, we propose a sliding algorithm and k-Nearest Neighbor (k-NN) with Bhattacharyya distance for song recognition and cover song recognition. The results of this experiment show that the proposed fingerprint technique has an accuracy of 100% for song recognition and an accuracy of 85.3% for cover song recognition. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Chili commodity price forecasting in bandung regency using the adaptive synthetic sampling (ADASYN) and K-Nearest neighbor (KNN) algorithms"
        ],
        "penulis":"Hasmita S.;Nhita, Fhira;Saepudin, Deni;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Red chili is an important spice in Indonesia. The Ministry of Agriculture (MoA) reported the significant contribution of red chili to the Indonesian economy both locally and internationally. Chili plants experience price inflation from year to year. This price change is influenced by several factors such as the number of requests and changes in the weather, both of which can affect production. In this study, the prediction of chili prices was carried out using the K-Nearest Neighbor (KNN) algorithm based on chili price data and weather data. The data obtained had imbalanced classes, so the Adaptive Synthetic (ADASYN) algorithm was used to overcome this issue. From the results, the classification using KNN reached the highest accuracy of 93% but with an F1-Score of 0%. In contrast, classification using KNN and ADASYN obtained 100% accuracy and an F1-Score of 100%. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Red chili is an important spice in Indonesia. The Ministry of Agriculture (MoA) reported the significant contribution of red chili to the Indonesian economy both locally and internationally. Chili plants experience price inflation from year to year. This price change is influenced by several factors such as the number of requests and changes in the weather, both of which can affect production. In this study, the prediction of chili prices was carried out using the K-Nearest Neighbor (KNN) algorithm based on chili price data and weather data. The data obtained had imbalanced classes, so the Adaptive Synthetic (ADASYN) algorithm was used to overcome this issue. From the results, the classification using KNN reached the highest accuracy of 93% but with an F1-Score of 0%. In contrast, classification using KNN and ADASYN obtained 100% accuracy and an F1-Score of 100%. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Employing Moving Average Long Short Term Memory for Predicting Rainfall"
        ],
        "penulis":"Caraka, Rezzy Eko;Chen, Rung Ching;Supatmanto, Budi Darmawan;Arnita;Tahmid, Muhammad;Toharudin, Toni;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Rainfall is significant in influencing human life. Therefore, it is necessary to predict or forecast rainfall in decision making. Forecasting rainfall can be calculated by the average rainfall of an area and by using the time-series method. Moreover, the government has a climatology station to measure rainfall at specific points or locations in various regions. In Indonesia, they are considered to have potential and represent the surrounding area. However, rainfall outside the climatology station area is not known for sure, while for specific purposes, information about rain is needed at other points. This research work focuses on the application of machine learning methods to the problem of computing prediction on time series as input variables. More specifically, we employ moving average (MA) and long short-term memory (LSTM) method to predict the rainfall in Winangun, North Sulawesi, Indonesia. LSTM is a neural network development that can be used for time-series data modelling. Based on the simulation, the combination of these methods, in-sample data reaches the R295.11%, and out-sample data reach R290.46% respectively. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rainfall is significant in influencing human life. Therefore, it is necessary to predict or forecast rainfall in decision making. Forecasting rainfall can be calculated by the average rainfall of an area and by using the time-series method. Moreover, the government has a climatology station to measure rainfall at specific points or locations in various regions. In Indonesia, they are considered to have potential and represent the surrounding area. However, rainfall outside the climatology station area is not known for sure, while for specific purposes, information about rain is needed at other points. This research work focuses on the application of machine learning methods to the problem of computing prediction on time series as input variables. More specifically, we employ moving average (MA) and long short-term memory (LSTM) method to predict the rainfall in Winangun, North Sulawesi, Indonesia. LSTM is a neural network development that can be used for time-series data modelling. Based on the simulation, the combination of these methods, in-sample data reaches the R295.11%, and out-sample data reach R290.46% respectively. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Evaluation of Listen before Talk (LBT) mechanism fairness at LTE-Licensed Assisted Access (LAA) against Wi-Fi 5 GHz"
        ],
        "penulis":"Sukma Dilaga, Dilla Fajar;Usman, Uke Kurniawan;Perdana, Doan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "LTE Release 13 allow the use of unlicensed frequency variations called Licensed Assisted Access (LAA). Combination of licensed LTE is used as primary cells to carry information and transport traffic data. Whereas the unlicensed spectrum is used as secondary cells that are proposed to increase capacity and distribute the spectrum fairly. The simulation results of scenario 1 produce a fairness index of 64 users for FTP over UDP in scenario 1 of 0.998, scenario 2 is 0.857 and scenario 3 is 0.997. Whereas for FTP over TCP in scenario 1 is 0.779, scenario 2 is 0.639 and scenario 3 is 0.74. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "LTE Release 13 allow the use of unlicensed frequency variations called Licensed Assisted Access (LAA). Combination of licensed LTE is used as primary cells to carry information and transport traffic data. Whereas the unlicensed spectrum is used as secondary cells that are proposed to increase capacity and distribute the spectrum fairly. The simulation results of scenario 1 produce a fairness index of 64 users for FTP over UDP in scenario 1 of 0.998, scenario 2 is 0.857 and scenario 3 is 0.997. Whereas for FTP over TCP in scenario 1 is 0.779, scenario 2 is 0.639 and scenario 3 is 0.74. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Uncoordinated transmissions in multi-way relaying systems"
        ],
        "penulis":"Anwar, Khoirul;Hasan, Mohammad Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper we propose an uncoordinated transmissions scheme in multi-way relaying systems and define its capacity at relatively low signal-to-noise power ratio (SNR) region. We adopt the concept of coded slotted ALOHA (CSA) to overcome the interference problem. To improve the threshold of the offered traffic, we employ iterative demapping algorithm that can decode multi-packet simultaneously. From the capacity bound of the proposed networks which is higher than CSA, we conjecture that the proposed system can achieve a reliable communication with throughput more than 1 packet\/slot. Extrinsic information transfer (EXIT) chart analysis is shown to confirm the conjecture. \u00a9 VDE VERLAG GMBH \u00b7 Berlin \u00b7 Offenbach.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper we propose an uncoordinated transmissions scheme in multi-way relaying systems and define its capacity at relatively low signal-to-noise power ratio (SNR) region. We adopt the concept of coded slotted ALOHA (CSA) to overcome the interference problem. To improve the threshold of the offered traffic, we employ iterative demapping algorithm that can decode multi-packet simultaneously. From the capacity bound of the proposed networks which is higher than CSA, we conjecture that the proposed system can achieve a reliable communication with throughput more than 1 packet\/slot. Extrinsic information transfer (EXIT) chart analysis is shown to confirm the conjecture. \u00a9 VDE VERLAG GMBH \u00b7 Berlin \u00b7 Offenbach."
        ]
    },
    {
        "judul":[
            "Water flow control system based on context aware algorithm and IoT for hydroponic"
        ],
        "penulis":"Gandhi, Otrinanda;Ramdhani, Mohamad;Murti, Muhammad Ary;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Question Classification for e-Learning Using Machine Learning Approach"
        ],
        "penulis":"Pratiwi, Oktariani Nurul;Syukriyah, Yenie;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Along with the use of e-learning, the collection of questions in the database is also increasing. The questions that have been uploaded to the e-learning system can certainly be used repeatedly. The use of repetitive questions will be easy to do with the process of reinvention if the questions have been grouped properly. Unfortunately, grouping questions based on subjects to details on grouping per topic is rarely done in e-learning. This makes the process of tracking the existing problems difficult.In addition, the state of the educational curriculum in Indonesia is often changing. Changes can be changes in whole or in part. This change can make the material content in the subject change order or be eliminated. When these changes occur, the previous problems that can still be used will be difficult to use when curriculum changes occur.Therefore, the large amount of question data and the difficulty in finding the questions again made the researcher to conduct this research. E-learning systems must have machine learning capabilities that are able to classify questions automatically based on topics to sub topics. Examined deeper, each question can have a classification in the form of subject categories, topics, sub topics to the level of difficulty of the questions. In this study, researchers focused on grouping questions based on subject categories and topics.The purpose of this study is to find the right method in building machine learning models in classifying questions according to topic categories and subtopics accurately and quickly. So, the questions in e-learning can be called back exactly as needed automatically. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Along with the use of e-learning, the collection of questions in the database is also increasing. The questions that have been uploaded to the e-learning system can certainly be used repeatedly. The use of repetitive questions will be easy to do with the process of reinvention if the questions have been grouped properly. Unfortunately, grouping questions based on subjects to details on grouping per topic is rarely done in e-learning. This makes the process of tracking the existing problems difficult.In addition, the state of the educational curriculum in Indonesia is often changing. Changes can be changes in whole or in part. This change can make the material content in the subject change order or be eliminated. When these changes occur, the previous problems that can still be used will be difficult to use when curriculum changes occur.Therefore, the large amount of question data and the difficulty in finding the questions again made the researcher to conduct this research. E-learning systems must have machine learning capabilities that are able to classify questions automatically based on topics to sub topics. Examined deeper, each question can have a classification in the form of subject categories, topics, sub topics to the level of difficulty of the questions. In this study, researchers focused on grouping questions based on subject categories and topics.The purpose of this study is to find the right method in building machine learning models in classifying questions according to topic categories and subtopics accurately and quickly. So, the questions in e-learning can be called back exactly as needed automatically. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Topologically significant directed random walk with applied walker network in cancer environment"
        ],
        "penulis":"Seah, Choon Sen;Kasim, Shahreen;Saedudin, Rd Rohmat;Md Fudzee, Mohd Farhan;Mohamad, Mohd Saberi;Hassan, Rohayanti;Ismail, Mohd Arfian;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Numerous cancer studies have combined different datasets for the prognosis of patients. This study incorporated four networks for significant directed random walk (sDRW) to predict cancerous genes and risk pathways. The study investigated the feasibility of cancer prediction via different networks. In this study, multiple micro array data were analysed and used in the experiment. Six gene expression datasets were applied in four networks to study the effectiveness of the networks in sDRW in terms of cancer prediction. The experimental results showed that one of the proposed networks is outstanding compared to other networks. The network is then proposed to be implemented in sDRW as a walker network. This study provides a foundation for further studies and research on other networks. We hope these finding will improve the prognostic methods of cancer patients.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Numerous cancer studies have combined different datasets for the prognosis of patients. This study incorporated four networks for significant directed random walk (sDRW) to predict cancerous genes and risk pathways. The study investigated the feasibility of cancer prediction via different networks. In this study, multiple micro array data were analysed and used in the experiment. Six gene expression datasets were applied in four networks to study the effectiveness of the networks in sDRW in terms of cancer prediction. The experimental results showed that one of the proposed networks is outstanding compared to other networks. The network is then proposed to be implemented in sDRW as a walker network. This study provides a foundation for further studies and research on other networks. We hope these finding will improve the prognostic methods of cancer patients."
        ]
    },
    {
        "judul":[
            "Implementing principal component analysis and multinomial logit for cancer detection based on microarray data classification"
        ],
        "penulis":"Khoirunnisa, Azka;Adiwijaya;Rohmawati, Aniq A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cancer is the second largest cause of death in the world; in 2018, a total of 9.6 million mortalities were recorder, due to cancer alone. It is important to detect this deadly disease early. In the medical field, there are many methods that can be used to detect cancer. One of these methods is microarray data technology. Microarray data reads thousands of gene expressions at the same time. However, this method has a major problem; data with high dimensions can affect classification performance and consume a lot of computational time. Therefore, this research used Principal Component Analysis as the dimensional reduction method. This method performed feature extraction based on a Principal Component (PC) obtained from the calculation of eigenvalues and eigenvectors. Moreover, the data reduction was implemented using a Multinomial Logit Classifier by modifying the parameters estimator using Maximum Likelihood Estimation. The cancer data used in this research consists of Colon Cancer, Leukemia, Lung Cancer, and Ovarian Cancer datasets. The test results for the Ovarian Cancer dataset gave an accuracy of 100% using a Proportion of Variance (PPV) of 90%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is the second largest cause of death in the world; in 2018, a total of 9.6 million mortalities were recorder, due to cancer alone. It is important to detect this deadly disease early. In the medical field, there are many methods that can be used to detect cancer. One of these methods is microarray data technology. Microarray data reads thousands of gene expressions at the same time. However, this method has a major problem; data with high dimensions can affect classification performance and consume a lot of computational time. Therefore, this research used Principal Component Analysis as the dimensional reduction method. This method performed feature extraction based on a Principal Component (PC) obtained from the calculation of eigenvalues and eigenvectors. Moreover, the data reduction was implemented using a Multinomial Logit Classifier by modifying the parameters estimator using Maximum Likelihood Estimation. The cancer data used in this research consists of Colon Cancer, Leukemia, Lung Cancer, and Ovarian Cancer datasets. The test results for the Ovarian Cancer dataset gave an accuracy of 100% using a Proportion of Variance (PPV) of 90%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Indexing name in hadith translation using hidden markov model (HMM)"
        ],
        "penulis":"Sari, Widia Permata;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hadith is one of Islamic's source beside the Qur'an which contains words and actions narrated by the Prophet SAW. There are so Prophet SAW's friends who followed his journey and had an important role in spreading Islam. There are still many people who do not know and have difficult time to finding the names of the friends who participated in the Prophet SAW's journey. Therefore, this research will make an indexing of the names that appear in the nine narrators' hadith collections. This indexing names uses Named Entity Recognition (NER) because indexing names only need entities in the form of people names. To make indexing names in hadith collections, this research will be use Hidden Markov Model (HMM) as a method. HMM is very often used in previous research and often gets quite good performance scores. Using the HMM's method and using several combinations of features, the system has a pretty good performance by counting recall, precision and F-1 for by calculating this performance. The values of performance were obtained using HMM's method are 86%. But by using cross validation based on the parameters, the performance values increase 2%, which means that the performance in this research is quite good for 38.102 data hadith. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hadith is one of Islamic's source beside the Qur'an which contains words and actions narrated by the Prophet SAW. There are so Prophet SAW's friends who followed his journey and had an important role in spreading Islam. There are still many people who do not know and have difficult time to finding the names of the friends who participated in the Prophet SAW's journey. Therefore, this research will make an indexing of the names that appear in the nine narrators' hadith collections. This indexing names uses Named Entity Recognition (NER) because indexing names only need entities in the form of people names. To make indexing names in hadith collections, this research will be use Hidden Markov Model (HMM) as a method. HMM is very often used in previous research and often gets quite good performance scores. Using the HMM's method and using several combinations of features, the system has a pretty good performance by counting recall, precision and F-1 for by calculating this performance. The values of performance were obtained using HMM's method are 86%. But by using cross validation based on the parameters, the performance values increase 2%, which means that the performance in this research is quite good for 38.102 data hadith. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Communication learning user interface model for children with autism with the goal-directed design method"
        ],
        "penulis":"Susanti, Fitrilia;Junaedi, Danang;Effendy, Veronikha;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Children with autism have communication disorder that affects the children face difficulty interacting and communicating with their environment both verbally and non-verbally. To facilitate it, learning visual communication was needed because children with autism were better at receiving information visually than orally. The application of visual communication learning for children with autism developed in digital media used the Picture Exchange Communication System (PECS) method. However, there was still a weakness in the development of digital media for example; there were no stages in the communication learning process. Therefore, this study modeled a prototype of 'Belajar Komunikasi' (BERAKSI) on a mobile application to correct deficiencies in the development of communication learning. The method used to produce an interface that fits the needs and ability of the children with autism was the Goal-Directed Design (GDD) method. To find out the level of success of usability from the prototype, then testing used by usability goals needed for children with autism, namely easy to use, learnability, feedback and good error messages, adequate help and document, appealing interface with the result of usability testing 78% in the excellent category. This category proves that autistic children are satisfied in using the BERAKSI application. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Children with autism have communication disorder that affects the children face difficulty interacting and communicating with their environment both verbally and non-verbally. To facilitate it, learning visual communication was needed because children with autism were better at receiving information visually than orally. The application of visual communication learning for children with autism developed in digital media used the Picture Exchange Communication System (PECS) method. However, there was still a weakness in the development of digital media for example; there were no stages in the communication learning process. Therefore, this study modeled a prototype of 'Belajar Komunikasi' (BERAKSI) on a mobile application to correct deficiencies in the development of communication learning. The method used to produce an interface that fits the needs and ability of the children with autism was the Goal-Directed Design (GDD) method. To find out the level of success of usability from the prototype, then testing used by usability goals needed for children with autism, namely easy to use, learnability, feedback and good error messages, adequate help and document, appealing interface with the result of usability testing 78% in the excellent category. This category proves that autistic children are satisfied in using the BERAKSI application. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Multilayer X-Band Wave Absorber with Enhanced Absorption Bandwidth"
        ],
        "penulis":"Syihabuddin, Budi;Effendi, Mohammad Ridwan;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electromagnetics (EM) wave absorber implemented with common pattern structure such as rectangular and circular patches on a single-layer of dielectric substrate has deficiency in performance. The use of passive components incorporated into the structure was sometimes employed to overcome the issue of deficiency. This paper proposes wave absorber composed of multilayer dielectric substrates to enhance the absorption characteristic focused on its bandwidth performance. The proposed multilayer wave absorber is designed to work at the X-band frequency with an FR4 epoxy dielectric substrate applied for each layer. A multi-impedance concept of each layer which depends on its patch dimension is implemented to acquire the bandwidth improvement. The characteristic of proposed wave absorber is investigated through its unit cell with the dimension of 5.80 mm \u00d7 5.80 mm. The characterization result shows that the fractional bandwidth for the unit cell using square patch could increase up to 127% and 169% for the double-layer and the triple-layers, respectively, compared to the single-layer of dielectric substrate at the X-band frequency of 9.5 GHz. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electromagnetics (EM) wave absorber implemented with common pattern structure such as rectangular and circular patches on a single-layer of dielectric substrate has deficiency in performance. The use of passive components incorporated into the structure was sometimes employed to overcome the issue of deficiency. This paper proposes wave absorber composed of multilayer dielectric substrates to enhance the absorption characteristic focused on its bandwidth performance. The proposed multilayer wave absorber is designed to work at the X-band frequency with an FR4 epoxy dielectric substrate applied for each layer. A multi-impedance concept of each layer which depends on its patch dimension is implemented to acquire the bandwidth improvement. The characteristic of proposed wave absorber is investigated through its unit cell with the dimension of 5.80 mm \u00d7 5.80 mm. The characterization result shows that the fractional bandwidth for the unit cell using square patch could increase up to 127% and 169% for the double-layer and the triple-layers, respectively, compared to the single-layer of dielectric substrate at the X-band frequency of 9.5 GHz. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Seismic data compression using auto-associative neural network and restricted Boltzmann machine"
        ],
        "penulis":"Nuha, Hilal;Mohandes, Mohamed;Liu, Bo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In a geophysical exploration survey, thousands of geophones are deployed where each geophone must transmit hundreds of recording over a narrow band channel to a fusion center. A lightweight compression technique for geophones is required to reduce the data traffic to the center. We present an efficient implementation of neural network for real-time seismic data compression for geophones. We use an auto-associative neural network architecture with a single linear hidden layer. The neural network is trained in two stages. First, we apply unsupervised learning with restricted Boltzmann machine (RBM) to obtain good initial weights. Secondly, the neural network with the initial weights is further fine-tuned in a supervised fashion with scaled conjugate gradient (SCG). Experimental results with real data have shown that the trained neural network achieves a peak signal-to-noise ratio (PSNR) of more than 30dB with a compression ratio of 10:1. The RBM is also proven to speed up the training up to nine times than that of without RBM. The proposed method is also compared with the linear predictive coding (LPC) and shows significant superiority in terms of compression error and reconstruction quality. \u00a9 2018 SEG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a geophysical exploration survey, thousands of geophones are deployed where each geophone must transmit hundreds of recording over a narrow band channel to a fusion center. A lightweight compression technique for geophones is required to reduce the data traffic to the center. We present an efficient implementation of neural network for real-time seismic data compression for geophones. We use an auto-associative neural network architecture with a single linear hidden layer. The neural network is trained in two stages. First, we apply unsupervised learning with restricted Boltzmann machine (RBM) to obtain good initial weights. Secondly, the neural network with the initial weights is further fine-tuned in a supervised fashion with scaled conjugate gradient (SCG). Experimental results with real data have shown that the trained neural network achieves a peak signal-to-noise ratio (PSNR) of more than 30dB with a compression ratio of 10:1. The RBM is also proven to speed up the training up to nine times than that of without RBM. The proposed method is also compared with the linear predictive coding (LPC) and shows significant superiority in terms of compression error and reconstruction quality. \u00a9 2018 SEG."
        ]
    },
    {
        "judul":[
            "Development and Analysis of Programmable Logic Controller Program for Defect Detection Prototype by CX Programmer"
        ],
        "penulis":"Mulyana, Tatang;Ibrahim, Rasidi;Abd Rahim, Erween;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents a development of Programmable Logic Controller program for defect detection prototype by CX programmer. The PLC is a digital system that operates digitally, using programmable memory for user-oriented internal storage, to perform special functions such as logic, sequencing, timing, and arithmetic; to be controlled through input, both analogue and digital; various machines or processes. CX Programmer is software used to create Omron PLC ladder diagrams. It system scenario is done to analyse the system that has been created to fit the scenario. It is seen from the input and output system made in the ladder diagram on CX Programmer. For scenario design can be analysed by looking at indicator light on PLC when the program is running. Based on the tested results can be concluded that the development is successfully. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents a development of Programmable Logic Controller program for defect detection prototype by CX programmer. The PLC is a digital system that operates digitally, using programmable memory for user-oriented internal storage, to perform special functions such as logic, sequencing, timing, and arithmetic; to be controlled through input, both analogue and digital; various machines or processes. CX Programmer is software used to create Omron PLC ladder diagrams. It system scenario is done to analyse the system that has been created to fit the scenario. It is seen from the input and output system made in the ladder diagram on CX Programmer. For scenario design can be analysed by looking at indicator light on PLC when the program is running. Based on the tested results can be concluded that the development is successfully. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "River water pollution pattern prediction using a simple neural network"
        ],
        "penulis":"Kennedy;Kusuma, Purba Daru;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Rivers are an important element of its environment; river water sustains and prospers living beings in its surrounding. When river water becomes polluted, though, it becomes useless or even harmful to its ecosystem. This Paper proposes an IoT (Internet of Things) based system as a solution to counteract river pollution. The system is composed of a hardware that measures pH, temperature, and turbidity of the water-then transmitting the data via LPWAN (Low Power Wide Area Network), more specifically LoRa (Long Range. Successfully transmitted data will be used to train an ANN (Artificial Neural Network) which is used to recognize and predict patterns of river water pollution. The monitoring and prediction results will be accessible via a web app. This Paper has successfully designed and built a system that implements an ANN for recognizing patterns in river conditions, to predict potential river pollution. Early detection of river pollution can serve as vital information to act in preventing or anticipating river pollution. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentClean water and sanitationGoal 6",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rivers are an important element of its environment; river water sustains and prospers living beings in its surrounding. When river water becomes polluted, though, it becomes useless or even harmful to its ecosystem. This Paper proposes an IoT (Internet of Things) based system as a solution to counteract river pollution. The system is composed of a hardware that measures pH, temperature, and turbidity of the water-then transmitting the data via LPWAN (Low Power Wide Area Network), more specifically LoRa (Long Range. Successfully transmitted data will be used to train an ANN (Artificial Neural Network) which is used to recognize and predict patterns of river water pollution. The monitoring and prediction results will be accessible via a web app. This Paper has successfully designed and built a system that implements an ANN for recognizing patterns in river conditions, to predict potential river pollution. Early detection of river pollution can serve as vital information to act in preventing or anticipating river pollution. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Early Detection of Superficial Basal-Cell Carcinoma Skin Cancer with Extraction Method ABCD Feature Based on Android"
        ],
        "penulis":"Ratnasari, Deva;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Basal Cell Carcinoma (KSB) is a deadly skin cancer that has become one of the most common diseases. This disease generally occurs in areas of the skin that are often exposed to sunlight such as the face and neck. Basal cell carcinoma usually appears after more than 40 years of age, although it can also be found in children and adolescents rarely. If not treated immediately, basal cell carcinoma will spread locally, resulting in substantial tissue damage which causes impaired function. So we need the right steps in handling itThe purpose of designing this application is to detect basal cell carcinoma skin cancer on an Android-based device. In Paper, the authors discusses ways to overcome this problem by using the ABCD Feature extraction and K-Nearest Neighbor (KNN) as a classification. This application has a user friendly application display because it was developed using a platform that can be used by all circles of science, so users do not need a qualified IT skills. The results of this study are beneficial to the community, which can be used by the community and can find out whether or not KSB is detected or not. From the results of tests that have been done, the results of feature extraction accuracy get an accuracy of 91,6%.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Basal Cell Carcinoma (KSB) is a deadly skin cancer that has become one of the most common diseases. This disease generally occurs in areas of the skin that are often exposed to sunlight such as the face and neck. Basal cell carcinoma usually appears after more than 40 years of age, although it can also be found in children and adolescents rarely. If not treated immediately, basal cell carcinoma will spread locally, resulting in substantial tissue damage which causes impaired function. So we need the right steps in handling itThe purpose of designing this application is to detect basal cell carcinoma skin cancer on an Android-based device. In Paper, the authors discusses ways to overcome this problem by using the ABCD Feature extraction and K-Nearest Neighbor (KNN) as a classification. This application has a user friendly application display because it was developed using a platform that can be used by all circles of science, so users do not need a qualified IT skills. The results of this study are beneficial to the community, which can be used by the community and can find out whether or not KSB is detected or not. From the results of tests that have been done, the results of feature extraction accuracy get an accuracy of 91,6%.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Mobile Sensor Navigation System Based on Adaptive Monte Carlo Localization"
        ],
        "penulis":"Wasisto, Isro;Istiqomah, Novera;Trisnawan, I Kadek Nuary;Jati, Agung Nugroho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Adaptive Monte Carlo Localization is a method used for mobile sensor localization in environment with representations of particle filters and Kullback-Leibler Distance (KLD) sampling to accelerate time execution of Localization. Mobile sensor has the ability to explore previously unknown environments using the mapping method. The mobile sensor must localize the pose (position and orientation) inside the operating environment before navigating. The final step is to navigate automatically to the specific point in the by using Cartesian Coordinate 2-dimensions (x,y). In this paper concerned about this AMCL algorithm in Robot Operating System (ROS), by using the different number of particle that is used for localization of the actual robot position and used it for navigating. The experiments that have been done, a map is obtained and can do the Localization process with Adaptive Monte Carlo Localization and the accuracy of the navigation process is influenced by the number of particles and the surrounding environment. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Adaptive Monte Carlo Localization is a method used for mobile sensor localization in environment with representations of particle filters and Kullback-Leibler Distance (KLD) sampling to accelerate time execution of Localization. Mobile sensor has the ability to explore previously unknown environments using the mapping method. The mobile sensor must localize the pose (position and orientation) inside the operating environment before navigating. The final step is to navigate automatically to the specific point in the by using Cartesian Coordinate 2-dimensions (x,y). In this paper concerned about this AMCL algorithm in Robot Operating System (ROS), by using the different number of particle that is used for localization of the actual robot position and used it for navigating. The experiments that have been done, a map is obtained and can do the Localization process with Adaptive Monte Carlo Localization and the accuracy of the navigation process is influenced by the number of particles and the surrounding environment. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Building Construction and Environment Control for Data Centre Based on ANSI\/TIA-942 in Networking Content Company"
        ],
        "penulis":"MaishaShahrani T.;Ramdhania, Aliyya Nur;Lubis, Muharman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The data centre room is different with other networking or IT type of room, which its space are necessarily required certain stringent requirements to achieve borderline of safety and stability in the prevention of interference or disturbance either physically or digitally. Therefore, it should also take note of the ease and access of the user to the data by considering the aspect of necessities and maintenance. Data center also transport energy upstream and greenhouse gas emissions due to processes, the resources and capital equipment used to extract and build, which should be considered carefully to avoid worst case scenario. This study explore the implementation issues in specific networking content company in Indonesia to manage building construction and environment control based on criteria derived from ANSI\/TIA-942. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentClimate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The data centre room is different with other networking or IT type of room, which its space are necessarily required certain stringent requirements to achieve borderline of safety and stability in the prevention of interference or disturbance either physically or digitally. Therefore, it should also take note of the ease and access of the user to the data by considering the aspect of necessities and maintenance. Data center also transport energy upstream and greenhouse gas emissions due to processes, the resources and capital equipment used to extract and build, which should be considered carefully to avoid worst case scenario. This study explore the implementation issues in specific networking content company in Indonesia to manage building construction and environment control based on criteria derived from ANSI\/TIA-942. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Is information privacy awareness important for Indonesian social media instagram users?"
        ],
        "penulis":"Candiwan;Savindraputra, Faiz;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the current information technology era, social media users increase every year. Recorded in 2017, among 143.26 million internet users, 87.13% or about 124.82 million used social media as part of lifestyle. There are some crimes such as robberies and murder happen caused by posting pictures or video regarding the privacy of Instagram users. In this research, there are some actions that users can do to avoid the crimes. This research aims to measure the privacy awareness of Instagram users in Indonesia by doing measurement using three dimensions of awareness such as Attitude, Knowledge, Behavior with four focus areas of privacy, namely Perceived Surveillance, Perceived Intrusion, Secondary Use of Information, Disclosing Personal Information. This research used the Analytical Hierarchy Process (AHP) method to measure the privacy awareness of Instagram users in Indonesia. Privacy awareness level in all dimensions is good. However, the attitude dimension with focus areas on perceived surveillance and perceived intrusion is still in the criterion of average awareness. It means that those focus areas potentially need treatment to improve such as being more careful while posting some content on Instagram because unauthorized people can get access more easily to the user's personal information and the users\u2019 activities. \u00a9 2019, World Academy of Research in Science and Engineering. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the current information technology era, social media users increase every year. Recorded in 2017, among 143.26 million internet users, 87.13% or about 124.82 million used social media as part of lifestyle. There are some crimes such as robberies and murder happen caused by posting pictures or video regarding the privacy of Instagram users. In this research, there are some actions that users can do to avoid the crimes. This research aims to measure the privacy awareness of Instagram users in Indonesia by doing measurement using three dimensions of awareness such as Attitude, Knowledge, Behavior with four focus areas of privacy, namely Perceived Surveillance, Perceived Intrusion, Secondary Use of Information, Disclosing Personal Information. This research used the Analytical Hierarchy Process (AHP) method to measure the privacy awareness of Instagram users in Indonesia. Privacy awareness level in all dimensions is good. However, the attitude dimension with focus areas on perceived surveillance and perceived intrusion is still in the criterion of average awareness. It means that those focus areas potentially need treatment to improve such as being more careful while posting some content on Instagram because unauthorized people can get access more easily to the user's personal information and the users\u2019 activities. \u00a9 2019, World Academy of Research in Science and Engineering. All rights reserved."
        ]
    },
    {
        "judul":[
            "'Wisdom of the Crowd' as Personalized Music Recommendation Model for Langit Musik Service"
        ],
        "penulis":"Yudiana, Wayan Agus;Ariyanti, Maya;Alamsyah, Andry;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We have been witnessing digital music industry has been grown rapidly in recent years. One Innovation which helps this industry improving its customer satisfaction, customer loyalty, and customer engagement, is personalized recommendation system. It has not only been an interesting innovation in digital music service, but also in almost all digital services. Telkomsel, the leader of the cellular industry in Indonesia, would also like to compete in providing'On Demand Music Streaming Service' by launching its own brand, Langit Musik and personalized recommendation system is supposed to be one of the improvements which can be implemented on top of it. Unfortunately, this personalized recommendation was not yet implemented. This research builds model to predict customer preferences for artists in Langit Musik service, to provide more personalized recommendations for each customer. This study applies an implicit preference from the amount of music listening for customers in period of l and3 months, from Mobile Apps and Unstructured Supplementary Service Data (USSD). The modeling uses a collaborative filtering approach with matrix factorization method and measure the model accuracy using Receiver Operating Characteristic \/ Area Under the Curve (ROC\/AUC). The AUC value indicates the prediction quality of the model above prediction from random method. In addition, it was also concluded that the matrix factorization method provides advantages in resource efficiency. The contribution of this research is to improve the customer experience, satisfaction, loyalty and engagement to Langit Musik. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We have been witnessing digital music industry has been grown rapidly in recent years. One Innovation which helps this industry improving its customer satisfaction, customer loyalty, and customer engagement, is personalized recommendation system. It has not only been an interesting innovation in digital music service, but also in almost all digital services. Telkomsel, the leader of the cellular industry in Indonesia, would also like to compete in providing'On Demand Music Streaming Service' by launching its own brand, Langit Musik and personalized recommendation system is supposed to be one of the improvements which can be implemented on top of it. Unfortunately, this personalized recommendation was not yet implemented. This research builds model to predict customer preferences for artists in Langit Musik service, to provide more personalized recommendations for each customer. This study applies an implicit preference from the amount of music listening for customers in period of l and3 months, from Mobile Apps and Unstructured Supplementary Service Data (USSD). The modeling uses a collaborative filtering approach with matrix factorization method and measure the model accuracy using Receiver Operating Characteristic \/ Area Under the Curve (ROC\/AUC). The AUC value indicates the prediction quality of the model above prediction from random method. In addition, it was also concluded that the matrix factorization method provides advantages in resource efficiency. The contribution of this research is to improve the customer experience, satisfaction, loyalty and engagement to Langit Musik. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The influences of tourism experience and destination image on the intention of local tourists to revisit to Ciletuh-Palabuhanratu Geopark"
        ],
        "penulis":"Hidayah, Riski Taufik;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "West Java Province is the province with the largest number of destinations and visit levels in Indonesia. One of the leading destinations is the Ciletuh-Palabuhanratu which is in Sukabumi Regency area. Ciletuh \u2013 Palabuhanratu Geopark received recognition from Unesco as an international standard Geopark. But it still has not been able to increase the level of visits significantly in Sukabumi district. This study aims to determine how much influence tourism experience and destination image on the intention of local tourists to revisit to Ciletuh-Palabuhanratu Geopark. The research method used in this research is descriptive and verification method, the population is local tourists who have visited a Ciletuh-Palabuhanratu Geopark tourist attraction with a total sample of 100 respondents. The data analysis method used in this study is Multiple Regression Analysis using the Statistical Package for the Social Science (SPSS) program. \u00a9 2019, Institute of Advanced Scientific Research, Inc.. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "West Java Province is the province with the largest number of destinations and visit levels in Indonesia. One of the leading destinations is the Ciletuh-Palabuhanratu which is in Sukabumi Regency area. Ciletuh \u2013 Palabuhanratu Geopark received recognition from Unesco as an international standard Geopark. But it still has not been able to increase the level of visits significantly in Sukabumi district. This study aims to determine how much influence tourism experience and destination image on the intention of local tourists to revisit to Ciletuh-Palabuhanratu Geopark. The research method used in this research is descriptive and verification method, the population is local tourists who have visited a Ciletuh-Palabuhanratu Geopark tourist attraction with a total sample of 100 respondents. The data analysis method used in this study is Multiple Regression Analysis using the Statistical Package for the Social Science (SPSS) program. \u00a9 2019, Institute of Advanced Scientific Research, Inc.. All rights reserved."
        ]
    },
    {
        "judul":[
            "Mac-Cormack\u2019s Scheme for Shock Filtering Equation in Image Enhancement"
        ],
        "penulis":"Gunawan P.H.;Gumilar, Agung F.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Mac-Cormack\u2019s scheme is elaborated to approximate the solution of shock filtering equation in image enhancement. This scheme is in second order approximation of spatial and time variables. Here, the comparison results of upwind and Mac-Cormack\u2019s scheme are given. The results show that Mac-Cormack\u2019s scheme is able to preserve the edge discontinuity. For evaluating the performance of numerical results, the discrete L2norm error for both numerical schemes is given. From several experiments, along the increasing of image sizes, the error of Mac-Cormack\u2019s scheme is observed getting smaller. For instance, using image sizes (64,64) the error is obtained 0.13762, meanwhile using (512,512) the error is observed 0.06640. \u00a9 2019, Springer Nature Switzerland AG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mac-Cormack\u2019s scheme is elaborated to approximate the solution of shock filtering equation in image enhancement. This scheme is in second order approximation of spatial and time variables. Here, the comparison results of upwind and Mac-Cormack\u2019s scheme are given. The results show that Mac-Cormack\u2019s scheme is able to preserve the edge discontinuity. For evaluating the performance of numerical results, the discrete L2norm error for both numerical schemes is given. From several experiments, along the increasing of image sizes, the error of Mac-Cormack\u2019s scheme is observed getting smaller. For instance, using image sizes (64,64) the error is obtained 0.13762, meanwhile using (512,512) the error is observed 0.06640. \u00a9 2019, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Construction of the ontology design for political parties' ideological characteristics"
        ],
        "penulis":"Hanum, Savira Latifah;Rusmawati, Yanti;Arzaki, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We construct an ontology design of political parties' ideological characteristics. The ontology is basically constructed from the concept lattice that has been built regarding the ideo-logical characteristics of the parties. Moreover, we also perform knowledge acquisition from pertinent studies concerning political parties' identities. We also conduct correctness checking for the resulting ontology to check whether it is correct in accordance with the previously built concept lattice. The analysis results show that the ontology is correct with respect to the canonical basis of implication rules resulted from the associated formal context and concept lattice. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We construct an ontology design of political parties' ideological characteristics. The ontology is basically constructed from the concept lattice that has been built regarding the ideo-logical characteristics of the parties. Moreover, we also perform knowledge acquisition from pertinent studies concerning political parties' identities. We also conduct correctness checking for the resulting ontology to check whether it is correct in accordance with the previously built concept lattice. The analysis results show that the ontology is correct with respect to the canonical basis of implication rules resulted from the associated formal context and concept lattice. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The spillover effects of University to Business Growth: Evidence from Malaysia"
        ],
        "penulis":"Muhamad, Suriyani;Kusairi, Suhal;Ab Manah, Siti Khatijah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Higher education institutions (HEI) or universities are known as knowledge and learning centres that produce skilled human capital, educate productive workers and entrepreneurs. Their functions have changed with current demands of society, making significant their role in stimulating and sustaining economic growth. However, there are few studies that investigate the effects of the establishment of universities to cater for and address local economic development. This study aims to examine the spill over effects of universities in nurturing local business activities. With regards to universities, the study explores the (i) stakeholders' spending impact; faculty, staff, student and visitors; (ii) human capital impact and; (iii) knowledge and exploration impact of business growth. Using a Structural Equation Model (SEM), the research applies multistage sampling to survey 445 university stakeholders involving alumni, community and industry from three universities; (i) University of Technology Malaysia (UTM); (ii) Universiti Utara Malaysia (UUM) and; (iii) Universiti Malaysia Terengganu (UMT). The findings show that university expenditure, human capital and knowledge exploration positively influence local business growth. This affirms a positive spill-over effects of universities to regional business growth. Hence, the findings of the research suggest that the positive roles of universities to the local economic development need to be given a priority by related stakeholders. \u00a9 2019, Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Higher education institutions (HEI) or universities are known as knowledge and learning centres that produce skilled human capital, educate productive workers and entrepreneurs. Their functions have changed with current demands of society, making significant their role in stimulating and sustaining economic growth. However, there are few studies that investigate the effects of the establishment of universities to cater for and address local economic development. This study aims to examine the spill over effects of universities in nurturing local business activities. With regards to universities, the study explores the (i) stakeholders' spending impact; faculty, staff, student and visitors; (ii) human capital impact and; (iii) knowledge and exploration impact of business growth. Using a Structural Equation Model (SEM), the research applies multistage sampling to survey 445 university stakeholders involving alumni, community and industry from three universities; (i) University of Technology Malaysia (UTM); (ii) Universiti Utara Malaysia (UUM) and; (iii) Universiti Malaysia Terengganu (UMT). The findings show that university expenditure, human capital and knowledge exploration positively influence local business growth. This affirms a positive spill-over effects of universities to regional business growth. Hence, the findings of the research suggest that the positive roles of universities to the local economic development need to be given a priority by related stakeholders. \u00a9 2019, Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Web-Based Flood Warning System Using Decision Tree Method"
        ],
        "penulis":"Solehman, Mudy;Azmi, Fairuz;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Flooding is a disaster that often occurs in Indonesia, especially in the Dayahkolout Region from the beginning until now, and causes very significant damage in life. Based on this problem, we need a system that is able to handle the problem. This system is designed using the Decision Tree C4.5 Algorithm method to predict potentially flooded areas based on parameters that will later be connected to the Internet of Things. The parameters used are water level, rainfall, and water discharge. Where each parameter will be connected to IoT and the results of the predictions will later be shown on the web application. From the results of testing that has been done, the C4.5 algorithm has the best performance on the 70%: 30% data partition which has an accuracy of 100%.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Flooding is a disaster that often occurs in Indonesia, especially in the Dayahkolout Region from the beginning until now, and causes very significant damage in life. Based on this problem, we need a system that is able to handle the problem. This system is designed using the Decision Tree C4.5 Algorithm method to predict potentially flooded areas based on parameters that will later be connected to the Internet of Things. The parameters used are water level, rainfall, and water discharge. Where each parameter will be connected to IoT and the results of the predictions will later be shown on the web application. From the results of testing that has been done, the C4.5 algorithm has the best performance on the 70%: 30% data partition which has an accuracy of 100%.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A heuristic method for location-inventory-routing problem in a three-echelon supply chain system"
        ],
        "penulis":"Saragih, Nova Indah;Bahagia, Senator Nur;Suprayogi;Syabri, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Location-inventory-routing problem belongs to the class of NP-hard problems. It needs a heuristic method to solve the problem in large scales so it can be applied in a real system case. This paper develops a heuristic method for location-inventory-routing problem in a three-echelon supply chain system where inventory decisions are made in the three involved entities. The involved entities in the system are single supplier, multi depots, and multi retailers. The demand of the retailers is probabilistic, single product, and following a normal distribution. The heuristic method consists of two stages, which are constructive stage and improvement stage. At the improvement stage, there are three phases developed to improve solution iteratively. The phases are location phase, inventory phase, and routing phase. SA (simulated annealing) is used at the improvement stage to improve the solution. The heuristic method is evaluated using instances and the solutions are compared to the MINLP (mixed integer nonlinear programming) model. Average gap between the heuristic method and the MINLP model is 0.55% in terms of total cost. The proposed heuristic is applied in a real system case which is food supply chain system of DKI Jakarta to design a new supply chain system that can increase availability. The new design can increase the availability from 76% to 95%. \u00a9 2018 Elsevier Ltd",
            "SOHOOHONOView detailsExpand Substance 3-(N-morpholinyl)-2-hydroxypropanesulfonic acid",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Location-inventory-routing problem belongs to the class of NP-hard problems. It needs a heuristic method to solve the problem in large scales so it can be applied in a real system case. This paper develops a heuristic method for location-inventory-routing problem in a three-echelon supply chain system where inventory decisions are made in the three involved entities. The involved entities in the system are single supplier, multi depots, and multi retailers. The demand of the retailers is probabilistic, single product, and following a normal distribution. The heuristic method consists of two stages, which are constructive stage and improvement stage. At the improvement stage, there are three phases developed to improve solution iteratively. The phases are location phase, inventory phase, and routing phase. SA (simulated annealing) is used at the improvement stage to improve the solution. The heuristic method is evaluated using instances and the solutions are compared to the MINLP (mixed integer nonlinear programming) model. Average gap between the heuristic method and the MINLP model is 0.55% in terms of total cost. The proposed heuristic is applied in a real system case which is food supply chain system of DKI Jakarta to design a new supply chain system that can increase availability. The new design can increase the availability from 76% to 95%. \u00a9 2018 Elsevier Ltd"
        ]
    },
    {
        "judul":[
            "Smart Lighting in Corridor Using Particle Swarm Optimization"
        ],
        "penulis":"Maharani, Trisha;Abdurohman, Maman;Putrada, Aji Gautama;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electricity usage needs are increasing every year, where some electricity usage is for lights. The use of smart lighting can be a solution in reducing the use of electricity in lamps, especially LED lights. The solution proposed in the concept of smart lighting is by adjusting the intensity of the lights produced. With the capability of dimming and detecting natural light intensity, energy efficiency can be achieved. However, the drawback is the requirement of sufficient lighting can sometimes not come to expectation. Particle Swarm Optimization (PSO) is a reinforcement learning method to obtain optimum results from contradicting and complex matters. In this research, a Smart Lighting System is proposed to optimize efficient lighting with sufficient light intensity. To achieve this goal, an Internet of Things System is created using two Sensor Nodes. The communication of the system uses MQTT. Using the PSO method, energy savings obtained is 67.3% while still keeping enough sufficient light intensity. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electricity usage needs are increasing every year, where some electricity usage is for lights. The use of smart lighting can be a solution in reducing the use of electricity in lamps, especially LED lights. The solution proposed in the concept of smart lighting is by adjusting the intensity of the lights produced. With the capability of dimming and detecting natural light intensity, energy efficiency can be achieved. However, the drawback is the requirement of sufficient lighting can sometimes not come to expectation. Particle Swarm Optimization (PSO) is a reinforcement learning method to obtain optimum results from contradicting and complex matters. In this research, a Smart Lighting System is proposed to optimize efficient lighting with sufficient light intensity. To achieve this goal, an Internet of Things System is created using two Sensor Nodes. The communication of the system uses MQTT. Using the PSO method, energy savings obtained is 67.3% while still keeping enough sufficient light intensity. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Modified-LRU algorithm for caching in named data network on mobile network"
        ],
        "penulis":"Kurniawan, Fandi Setio;Yovita, Leanna Vidya;Wibowo, Tody Ariefianto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "It is estimated that the annual internet network traffic will exceed the threshold of 3.3 zettabytes by 2021. However, internet architecture is currently inefficient to support the distribution of information-sharing content. Thus, a new internet architecture is designed, namely Named Data Network. Named Data Network (NDN) can store data that has been accessed by consumers in the content store so that when the data is requested by other consumers, it will be fast in distributing data. Nonetheless, it is not possible to store all the content in the content store. Optimization should be made, the existing optimization technique based on the replacement algorithm is Least Recent Used (LRU). However, LRU has a weakness, which only uses the latest reference time and cannot distinguish between frequent or rare objects that are being accessed. Previous research has been conducted on modified-LRU but only on fixed networks, while currently the majority of users use mobile networks, and the condition of mobile networks is very different from the condition of fixed networks. In this research, scenario 5 testing was carried out relating to packet ratio, delay, and packet drop on mobile networks. Modified-LRU show great improvement by the performance of the Hit ratio, 3.6% greater than the LRU, reducing delay by 19.67%, and packet drop by 94% better than LRU. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "It is estimated that the annual internet network traffic will exceed the threshold of 3.3 zettabytes by 2021. However, internet architecture is currently inefficient to support the distribution of information-sharing content. Thus, a new internet architecture is designed, namely Named Data Network. Named Data Network (NDN) can store data that has been accessed by consumers in the content store so that when the data is requested by other consumers, it will be fast in distributing data. Nonetheless, it is not possible to store all the content in the content store. Optimization should be made, the existing optimization technique based on the replacement algorithm is Least Recent Used (LRU). However, LRU has a weakness, which only uses the latest reference time and cannot distinguish between frequent or rare objects that are being accessed. Previous research has been conducted on modified-LRU but only on fixed networks, while currently the majority of users use mobile networks, and the condition of mobile networks is very different from the condition of fixed networks. In this research, scenario 5 testing was carried out relating to packet ratio, delay, and packet drop on mobile networks. Modified-LRU show great improvement by the performance of the Hit ratio, 3.6% greater than the LRU, reducing delay by 19.67%, and packet drop by 94% better than LRU. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Performance enhancement of complete ensemble empirical mode decomposition (CEEMD) - Independent component analysis (ICA) in ocular artifact removal"
        ],
        "penulis":"Pramudita, Brahmantya Aji;Sumanto, Budi;Setiawan, Noor Akhmad;Ardiyanto, Igi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Inaccuracies in removing Ocular Artifact (OA) in EEG signals can cause loss of information in EEG signals. Several previous methods utilize the feature of OA to detect OA and then remove all the components contaminated by OA. Those processes cause high errors in the OA removal results. A high error indicates that any information in EEG signals is lost during the OA removal process. The purpose of this research is to develop combination methods of CEEMD and ICA in order to improve performance in eliminating OA without omitting information in EEG signals. In its implementation, the combination of CEEMD and ICA are enhanced by the entropy method to find out the existence of OA, and Teager Kaiser Energy Operator (TKEO) method to measure the OA energy. Both ways can make it easier to detect and eliminate the OA by using the modified z-score method. The result of the test by using Relative Error (RE) indicates that the proposed method successfully eliminates OA with the average error of 0.4365 for Dataset A, 0.4597 for Dataset B, and 0.5337 for Dataset C. Thus, the results show the proposed method is able to remove OA without interfering information of EEG signal.  \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Inaccuracies in removing Ocular Artifact (OA) in EEG signals can cause loss of information in EEG signals. Several previous methods utilize the feature of OA to detect OA and then remove all the components contaminated by OA. Those processes cause high errors in the OA removal results. A high error indicates that any information in EEG signals is lost during the OA removal process. The purpose of this research is to develop combination methods of CEEMD and ICA in order to improve performance in eliminating OA without omitting information in EEG signals. In its implementation, the combination of CEEMD and ICA are enhanced by the entropy method to find out the existence of OA, and Teager Kaiser Energy Operator (TKEO) method to measure the OA energy. Both ways can make it easier to detect and eliminate the OA by using the modified z-score method. The result of the test by using Relative Error (RE) indicates that the proposed method successfully eliminates OA with the average error of 0.4365 for Dataset A, 0.4597 for Dataset B, and 0.5337 for Dataset C. Thus, the results show the proposed method is able to remove OA without interfering information of EEG signal.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Developing a Complete Dialogue System Using Long Short-Term Memory"
        ],
        "penulis":"Bunga, Muhammad Husain Toding;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "As technologies of natural language understanding and generation improve, the human interest towards human-computer interaction increases. The technologies can be applied for various applications of customer services. Most works related to this field are emphasizing on single sentence and speaker turn. Meanwhile, a conversation sometimes has its own context according to the previous one. Designing this kind of conversational system is challenging. Most conversational agents are built based on knowledge-based and rule based systems. This paper discusses a development of a complete dialogue system to understand the intent of a text and give response based on the dialogue state. The dialogue model is implemented using the combination of rule-based and data-driven approach by utilizing a long short-Term memory (LSTM). Some experiments show that the developed system give a high performance. A detail observation informs that some errors come from the intent classifier that fails to classify some sentences not in the corpus. This system can be improved by increasing the performance of the intent classifier and incorporating an additional named entity recognition module. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "As technologies of natural language understanding and generation improve, the human interest towards human-computer interaction increases. The technologies can be applied for various applications of customer services. Most works related to this field are emphasizing on single sentence and speaker turn. Meanwhile, a conversation sometimes has its own context according to the previous one. Designing this kind of conversational system is challenging. Most conversational agents are built based on knowledge-based and rule based systems. This paper discusses a development of a complete dialogue system to understand the intent of a text and give response based on the dialogue state. The dialogue model is implemented using the combination of rule-based and data-driven approach by utilizing a long short-Term memory (LSTM). Some experiments show that the developed system give a high performance. A detail observation informs that some errors come from the intent classifier that fails to classify some sentences not in the corpus. This system can be improved by increasing the performance of the intent classifier and incorporating an additional named entity recognition module. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Sense of presence and learning satisfaction among students of different age groups in a 3-D virtual world"
        ],
        "penulis":"Rahman, Mohd Hishamuddin Abdul;Phon, Danakorn Nincarean Eh;Utama, Nur Ichsan;Yahaya, Noraffandy;Halim, Noor Dayana Abd;Kasim, Shahreen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Virtual worlds are growing in popularity very quickly. This growing popularity of 3-dimensional (3-D) virtual worlds has drawn attention from educationists. Today, 3-dimensional (3-D) virtual worlds are exploited for online and virtual learning. Unlike the common online learning platforms, a virtual world environment closely resembles a 3-D video games environment. Thus the age of students might affect their sense of presence, interaction, and satisfaction in the said environment. Hence this study was conducted to investigate whether there are differences between students of different age groups on their sense of presence (place presence, social presence, and co-presence) and their learning satisfaction. The study was carried out for six weeks and involved 33 part-time diploma students with the use of interview and questionnaires as instruments. In this study, the researcher developed our own 3-D virtual world, known as ViEW, by using the Open Wonderland open source virtual world program. A nonparametric Mann-Whitney U analysis was applied to explore the differences between young and senior participants in terms of their sense of place presence, social presence, co-presence, and learning satisfaction. The results indicated significant differences between young and senior students in terms of place presence, co-presence, and learning satisfaction, but no differences were identified for social presence. These results might be in regard with the means of conducted the learning, which were in the forms of cooperative and synchronous learning by utilizing audio communication most of the time. Several recommendations for future research related to the study were also provided. \u00a9 2019 Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Virtual worlds are growing in popularity very quickly. This growing popularity of 3-dimensional (3-D) virtual worlds has drawn attention from educationists. Today, 3-dimensional (3-D) virtual worlds are exploited for online and virtual learning. Unlike the common online learning platforms, a virtual world environment closely resembles a 3-D video games environment. Thus the age of students might affect their sense of presence, interaction, and satisfaction in the said environment. Hence this study was conducted to investigate whether there are differences between students of different age groups on their sense of presence (place presence, social presence, and co-presence) and their learning satisfaction. The study was carried out for six weeks and involved 33 part-time diploma students with the use of interview and questionnaires as instruments. In this study, the researcher developed our own 3-D virtual world, known as ViEW, by using the Open Wonderland open source virtual world program. A nonparametric Mann-Whitney U analysis was applied to explore the differences between young and senior participants in terms of their sense of place presence, social presence, co-presence, and learning satisfaction. The results indicated significant differences between young and senior students in terms of place presence, co-presence, and learning satisfaction, but no differences were identified for social presence. These results might be in regard with the means of conducted the learning, which were in the forms of cooperative and synchronous learning by utilizing audio communication most of the time. Several recommendations for future research related to the study were also provided. \u00a9 2019 Insight Society."
        ]
    },
    {
        "judul":[
            "The Role Of Stakeholder Relations In Building Brand Awareness Study On Consumed Media Feedme Id"
        ],
        "penulis":"Damayasih, Nadiya;Mahes, Gayes;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research aimed to know the role of stakeholder relations in building brand awareness (study on consumed media feedme.id). The research method used for this study was qualitative and the methods of collecting data obtained by observation and structured interview as primary data and secondary data from literature study and company document. Analysis of data used coding data. The validity of data used t riangulation of data source. This research shows that the role of stakeholder relations in building brand awareness is to maintaining relations with consumed media relations feedme.id, otherwise stakeholder relations is doing consumer, client, and media relations on Consumed Media Feedme.id. \u00a9 2019 International Journal of Scientific and Technology Research. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research aimed to know the role of stakeholder relations in building brand awareness (study on consumed media feedme.id). The research method used for this study was qualitative and the methods of collecting data obtained by observation and structured interview as primary data and secondary data from literature study and company document. Analysis of data used coding data. The validity of data used t riangulation of data source. This research shows that the role of stakeholder relations in building brand awareness is to maintaining relations with consumed media relations feedme.id, otherwise stakeholder relations is doing consumer, client, and media relations on Consumed Media Feedme.id. \u00a9 2019 International Journal of Scientific and Technology Research. All rights reserved."
        ]
    },
    {
        "judul":[
            "Early Detection of Skin Basal Cell Carcinoma Nodular Using Extraction Methods ABCD Feature Comparison with Dermatofibroma Data"
        ],
        "penulis":"Irsyad, Firdaus;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cancer is one of the biggest causes of death now, cancer is also a disease that is very difficult to cure and still relatively difficult to treat, the skin can also be a medium that can cause cancer. Prevention and detection of skin cancer early is one of the best ways to reduce the greater risk that can be caused by the disease, in this paper will explain the making of applications to detection cancer skin Carcinoma Basal Cell type nodular using Image Processing with tested by comparing the feature dermatofibroma and Basal Cell Carcinoma features. In this paper the system is made based on Android to support input features by comparing the 4 criteria of the feature, that is Asymmetry, Border, Color, and Diameter. The extraction method used in the feature xtraction is the ABCD feature with classification using K-Nearest Neighbor.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is one of the biggest causes of death now, cancer is also a disease that is very difficult to cure and still relatively difficult to treat, the skin can also be a medium that can cause cancer. Prevention and detection of skin cancer early is one of the best ways to reduce the greater risk that can be caused by the disease, in this paper will explain the making of applications to detection cancer skin Carcinoma Basal Cell type nodular using Image Processing with tested by comparing the feature dermatofibroma and Basal Cell Carcinoma features. In this paper the system is made based on Android to support input features by comparing the 4 criteria of the feature, that is Asymmetry, Border, Color, and Diameter. The extraction method used in the feature xtraction is the ABCD feature with classification using K-Nearest Neighbor.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Detection of Gas Leaks Using the MQ-2 Gas Sensor on the Autonomous Mobile Sensor"
        ],
        "penulis":"Trisnawan, I. Kadek Nuary;Jati, Agung Nugroho;Istiqomah, Novera;Wasisto, Isro;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Gas leaks are one of the big problems in the industrial sector, even starting to spread to other sectors. One of the solutions to reduce losses due to gas leakage is to detect it early when there is a leak. There are already many technologies that help prevent gas leaks harm humans more, one of them is the mobile sensor. The development of mobile sensors is one way to overcome losses both from material and non-material. Using a gas sensor of type MQ-2 as a detector, it is expected that later it can be overcome before it has a wider impact. The gas sensor is connected to a mobile sensor and installed in four different directions. MQ-2 was chosen because it has a low price and good durability. Assisted by the SLAM method as navigation and a combination of source-seeking and active-sensing localization methods as identifiers of leak points, the mobile sensor identifies points of leakage which are on the abnormal boundary. MQ-2 is calibrated and configured using C language, which is implemented through Arduino IDE. After configuring the gas sensor, it is expected that the results of accuracy reach 80% with the distance from the gas sensor to the point of leakage about 0-10 cm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Gas leaks are one of the big problems in the industrial sector, even starting to spread to other sectors. One of the solutions to reduce losses due to gas leakage is to detect it early when there is a leak. There are already many technologies that help prevent gas leaks harm humans more, one of them is the mobile sensor. The development of mobile sensors is one way to overcome losses both from material and non-material. Using a gas sensor of type MQ-2 as a detector, it is expected that later it can be overcome before it has a wider impact. The gas sensor is connected to a mobile sensor and installed in four different directions. MQ-2 was chosen because it has a low price and good durability. Assisted by the SLAM method as navigation and a combination of source-seeking and active-sensing localization methods as identifiers of leak points, the mobile sensor identifies points of leakage which are on the abnormal boundary. MQ-2 is calibrated and configured using C language, which is implemented through Arduino IDE. After configuring the gas sensor, it is expected that the results of accuracy reach 80% with the distance from the gas sensor to the point of leakage about 0-10 cm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The effect of social media to the sustainability of short message service (SMS) and phone call"
        ],
        "penulis":"Lubis, Arif Ridho;Lubis, Muharman;Azhar, Citra Dewi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the development of increasingly advanced technology, the use of SMS and telephone has been replaced by smartphone users who are more intended to use social media, especially among students. Social media are online media where users can communicate and interact one another for social interactions conducted online through the internet such as WhatsApp, Line, Instagram, Facebook, Twitter, Skype and Telegram. The existence of social media makes SMS and telephone user switch to social media which has more features, capacities and functions. Therefore, it is interesting to investigate the effect of social media to influence the sustainability of SMS and telephone which is seen from the effectiveness of social media in terms of time, quality and quantity, cost, distance, and energy in related to the utilization of SMS and telephone among users. To determine the effect of respected social media, this study use multiple regression, which is analysed using SPSS 17.0 and has passed the validity and reliability test up to 32.7% the influence of all variants. The most dominant influence on Usage and Function variables is Quality and Quantity which has 18% with significant value of test 0,000 smaller than the value set (0.05), the cost of which has 4.7% with significant value of T test at around 0.003 smaller than the value determined (0.05), and Energy which has 2.1% with significant value of T test about 0.013 smaller than the value set (0.05). \u00a9 2019 The Authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the development of increasingly advanced technology, the use of SMS and telephone has been replaced by smartphone users who are more intended to use social media, especially among students. Social media are online media where users can communicate and interact one another for social interactions conducted online through the internet such as WhatsApp, Line, Instagram, Facebook, Twitter, Skype and Telegram. The existence of social media makes SMS and telephone user switch to social media which has more features, capacities and functions. Therefore, it is interesting to investigate the effect of social media to influence the sustainability of SMS and telephone which is seen from the effectiveness of social media in terms of time, quality and quantity, cost, distance, and energy in related to the utilization of SMS and telephone among users. To determine the effect of respected social media, this study use multiple regression, which is analysed using SPSS 17.0 and has passed the validity and reliability test up to 32.7% the influence of all variants. The most dominant influence on Usage and Function variables is Quality and Quantity which has 18% with significant value of test 0,000 smaller than the value set (0.05), the cost of which has 4.7% with significant value of T test at around 0.003 smaller than the value determined (0.05), and Energy which has 2.1% with significant value of T test about 0.013 smaller than the value set (0.05). \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Wideband Microstrip Antenna Design for Power Harvesting"
        ],
        "penulis":"Amrullah, Yahya Syukri;Gunaranti, Novia;Santiko, Arief Budi;Anwar, Radial;Wahyu, Yuyu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A 1\u00d72 array microstrip patch antenna with defected groundplane structure (DGS) has been designed and simulated. This antenna design is intended for power harvesting application. Several simulation steps have been conducted such as simulating single microstrip antenna without DGS, then simulating single microstrip antenna with DGS, and simulating 1\u00d72 array microstrip antenna without DGS. The last simulation yields wider bandwidth but the gain is still low. Antenna design still needs improvement to fulfill power harvesting requirements. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A 1\u00d72 array microstrip patch antenna with defected groundplane structure (DGS) has been designed and simulated. This antenna design is intended for power harvesting application. Several simulation steps have been conducted such as simulating single microstrip antenna without DGS, then simulating single microstrip antenna with DGS, and simulating 1\u00d72 array microstrip antenna without DGS. The last simulation yields wider bandwidth but the gain is still low. Antenna design still needs improvement to fulfill power harvesting requirements. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Application of Web-based Travel Attractions as a Marketing Strategy"
        ],
        "penulis":"Sujana A.P.;Julian M.W.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of this study is to see how web-based travel attraction in social media for improving number of tourism and building economic progress from an area. The method used in this study is collecting the data form by interviewing and internet searches. The results of this study is that social media can developed travel agents, as well as facilities for social media services in this field. Especially if you use social media, because you don't have to pay for promotions, tourists also will be provided about the information as well choosing the place according to their needs. Besides, tourism promotion on social media influence the increasing of tourists to visit an area as a tourism actors in the city. So, the tourist will be more understand tourism objects and products offered. Therefore, online media can provide information, and is very important for service providers. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to see how web-based travel attraction in social media for improving number of tourism and building economic progress from an area. The method used in this study is collecting the data form by interviewing and internet searches. The results of this study is that social media can developed travel agents, as well as facilities for social media services in this field. Especially if you use social media, because you don't have to pay for promotions, tourists also will be provided about the information as well choosing the place according to their needs. Besides, tourism promotion on social media influence the increasing of tourists to visit an area as a tourism actors in the city. So, the tourist will be more understand tourism objects and products offered. Therefore, online media can provide information, and is very important for service providers. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The accuracy of the frontal extent in stereoscopic environments: A comparison of direct selection and virtual cursor techniques"
        ],
        "penulis":"Lin, Chiuhsiang Joe;Caesaron, Dino;Woldegiorgis, Bereket Haile;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This experiment investigated the accuracy of distance judgment and perception of the frontal extent in a stereoscopic environment. Eight virtual targets were projected in a circular arrangement with two center-to-center target distances (18 cm and 36 cm) and three target sizes (0.6 cm, 1.5 cm, and 3.7 cm). Fourteen participants judged the positions of virtual targets presented at a distance of 90 cm from them by employing two different interaction techniques: the direct selection technique and the virtual cursor technique. The results showed overall higher accuracy with the virtual cursor technique than with the direct selection technique. It was also found that the target size significantly affected the frontal extent accuracy. In addition, significant interactions between technique and center-to-center target distance were observed. The direct selection technique was more accurate at the 18 cm center-to-center target distance along the horizontal (x) and vertical (y) axes, while the virtual cursor technique was more accurate for the 36 cm center-to-center target distance along the y axis. During the direct selection, estimations tended to converge to the center of the virtual space; however, this convergence was not observed in the virtual cursor condition. The accuracy of pointing estimations suffered on the left side of participants. These findings could provide direction for virtual reality developers in selecting proper interaction techniques and appropriately positioning virtual targets in stereoscopic environments. \u00a9 2019 Lin et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This experiment investigated the accuracy of distance judgment and perception of the frontal extent in a stereoscopic environment. Eight virtual targets were projected in a circular arrangement with two center-to-center target distances (18 cm and 36 cm) and three target sizes (0.6 cm, 1.5 cm, and 3.7 cm). Fourteen participants judged the positions of virtual targets presented at a distance of 90 cm from them by employing two different interaction techniques: the direct selection technique and the virtual cursor technique. The results showed overall higher accuracy with the virtual cursor technique than with the direct selection technique. It was also found that the target size significantly affected the frontal extent accuracy. In addition, significant interactions between technique and center-to-center target distance were observed. The direct selection technique was more accurate at the 18 cm center-to-center target distance along the horizontal (x) and vertical (y) axes, while the virtual cursor technique was more accurate for the 36 cm center-to-center target distance along the y axis. During the direct selection, estimations tended to converge to the center of the virtual space; however, this convergence was not observed in the virtual cursor condition. The accuracy of pointing estimations suffered on the left side of participants. These findings could provide direction for virtual reality developers in selecting proper interaction techniques and appropriately positioning virtual targets in stereoscopic environments. \u00a9 2019 Lin et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited."
        ]
    },
    {
        "judul":[
            "The Impact of Low-Pass Filter in Speaker Identification"
        ],
        "penulis":"Ahmad, Rizky;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Speaker identification model commonly uses Mel Frequency Ceptral Coefficient (MFCC) and Gaussian Mixture Model (GMM). Due to many weaknesses from previous studies for noised speech, here a low-pass-filter is proposed to reduce the high-frequency signals. The low-pass-filter is expected to calculate cut-offs. Experimental results show that the low-pass filter significantly improves the accuracy of sound detection for the high noised signal. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Speaker identification model commonly uses Mel Frequency Ceptral Coefficient (MFCC) and Gaussian Mixture Model (GMM). Due to many weaknesses from previous studies for noised speech, here a low-pass-filter is proposed to reduce the high-frequency signals. The low-pass-filter is expected to calculate cut-offs. Experimental results show that the low-pass filter significantly improves the accuracy of sound detection for the high noised signal. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Prototype of automation of organic fertilizer manufacturing systems based on internet of things"
        ],
        "penulis":"Pratama, Yogie Fajar;Ariyanto, Endro;Karimah, Siti Amatullah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Compost is an organic fertilizer made from the remnants of plants, animals and decomposable domestic waste with help from decomposers. The process to make compost is still manually done. Organic remnants and waste are piled and buried to create heat during the composting process. Then, the pile is mixed with hand and shovel to control moisture and temperature. Since ideal temperature and humidity have to be estimated manually, it will affect the decomposing duration. Compost will take more time to make if the mixing process and heat are not distributed well. Based on those problems, this research devises an automatic compost maker prototype which can detect temperature and humidity in the composting process based on Internet of Things, so the data can be processed by fuzzy logic, which also acts as the main control to run the actuator (heater and water pump). Temperature and humidity data from the sensor will be sent to a database, then the fuzzy logic will determine the optimal temperature and humidity for the composting process by activating the actuator which consists of water sprinkler, heater and mixing motor. Based on experiment results, the prototype is able to create compost in 14 days or 2,35 times faster than using the traditional tools that require 33 days. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Compost is an organic fertilizer made from the remnants of plants, animals and decomposable domestic waste with help from decomposers. The process to make compost is still manually done. Organic remnants and waste are piled and buried to create heat during the composting process. Then, the pile is mixed with hand and shovel to control moisture and temperature. Since ideal temperature and humidity have to be estimated manually, it will affect the decomposing duration. Compost will take more time to make if the mixing process and heat are not distributed well. Based on those problems, this research devises an automatic compost maker prototype which can detect temperature and humidity in the composting process based on Internet of Things, so the data can be processed by fuzzy logic, which also acts as the main control to run the actuator (heater and water pump). Temperature and humidity data from the sensor will be sent to a database, then the fuzzy logic will determine the optimal temperature and humidity for the composting process by activating the actuator which consists of water sprinkler, heater and mixing motor. Based on experiment results, the prototype is able to create compost in 14 days or 2,35 times faster than using the traditional tools that require 33 days. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Utilizing structured knowledge bases in open IE based event template extraction"
        ],
        "penulis":"Romadhony, Ade;Widyantoro, Dwi H.;Purwarianti, Ayu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Automatic template extraction including event template has been studied intensively in recent years. Researchers study the topic in order to solve the problem of manually defining a template that is required in most information extraction systems. Several studies of event template extraction rely on the documents characteristics to discover the pattern. Although there exist some structured knowledge bases, such as: FrameNet, Predicate Matrix, ACE (Automatic Content Extraction) event type keywords seeds, and FrameNet-ACE event type mapping, no previous researchers have studied combining this information for event template extraction. This paper presents an event template extraction approach that incorporates structured knowledge bases. We propose event template extraction from Open Information Extraction (Open IE) results (relation tuples) in two stages: relation tuple clustering and relation tuple filtering. Both processes utilize structured knowledge bases, as constraint sources in the clustering process and as the basis for the filtering process. The filtering process employs the word embedding representation to capture the semantic relatedness between words. We argue that by involving structured knowledge bases, the relation tuple semantic information can be enriched. Therefore, we can get groups of relation tuples with a similar event sense that represent event templates. The empirical experiment was based on an event argument extraction task and showed that our proposed approach outperforms similar methods that do not use structured knowledge bases. We also compare our proposed system performance to the performance of state-of-the-art systems. The comparison result shows that our proposed system outperforms other state-of-the-art systems, in terms of precision. \u00a9 2018, Springer Science+Business Media, LLC, part of Springer Nature.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Automatic template extraction including event template has been studied intensively in recent years. Researchers study the topic in order to solve the problem of manually defining a template that is required in most information extraction systems. Several studies of event template extraction rely on the documents characteristics to discover the pattern. Although there exist some structured knowledge bases, such as: FrameNet, Predicate Matrix, ACE (Automatic Content Extraction) event type keywords seeds, and FrameNet-ACE event type mapping, no previous researchers have studied combining this information for event template extraction. This paper presents an event template extraction approach that incorporates structured knowledge bases. We propose event template extraction from Open Information Extraction (Open IE) results (relation tuples) in two stages: relation tuple clustering and relation tuple filtering. Both processes utilize structured knowledge bases, as constraint sources in the clustering process and as the basis for the filtering process. The filtering process employs the word embedding representation to capture the semantic relatedness between words. We argue that by involving structured knowledge bases, the relation tuple semantic information can be enriched. Therefore, we can get groups of relation tuples with a similar event sense that represent event templates. The empirical experiment was based on an event argument extraction task and showed that our proposed approach outperforms similar methods that do not use structured knowledge bases. We also compare our proposed system performance to the performance of state-of-the-art systems. The comparison result shows that our proposed system outperforms other state-of-the-art systems, in terms of precision. \u00a9 2018, Springer Science+Business Media, LLC, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "Nonlinear autoregressive neural network models for sea level prediction, study case: In Semarang, Indonesia"
        ],
        "penulis":"Rizkina, Miftahul Awali;Adytia, Didit;Subasita, Nugrahinggil;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Sea level prediction is highly needed for coastal communities. Mainly driven by tidal, the sea level predictions can be used for analyzing the disposal and movements of sediments, tracers and pollutants, off-shore engineering constructions, environmental observations, as well as for ship navigation. Prediction of tides usually use tidal harmonic analysis for long term tidal predictions. However, this tide harmonic analysis has several drawbacks i.e. the method can not be used for short-term and real-time forecasting or instant prediction. Moreover, the method requires a large number of tidal data measurements to obtain accurate prediction. In this paper, we propose a sea level prediction by using Artificial Neural Network (ANN) model approach, namely the Nonlinear Autoregressive Neural Network (NAR). The method is applied for predicting sea level in Tanjung Emas Harbor in Semarang, Indonesia. We compare results of the prediction by using NAR with prediction by using tidal harmonic analysis. The accuracy of the prediction is measured by calculating the RMSE value and R value. NAR produces R value 0.9566 for training data and 0.9567 for prediction data. The choice of number of hidden layers in the NAR can also affects the results of prediction, in term of RMSE value and R value. The results show that NAR method produces a better accuracy in predicting sea level than using the tidal harmonic analysis. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sea level prediction is highly needed for coastal communities. Mainly driven by tidal, the sea level predictions can be used for analyzing the disposal and movements of sediments, tracers and pollutants, off-shore engineering constructions, environmental observations, as well as for ship navigation. Prediction of tides usually use tidal harmonic analysis for long term tidal predictions. However, this tide harmonic analysis has several drawbacks i.e. the method can not be used for short-term and real-time forecasting or instant prediction. Moreover, the method requires a large number of tidal data measurements to obtain accurate prediction. In this paper, we propose a sea level prediction by using Artificial Neural Network (ANN) model approach, namely the Nonlinear Autoregressive Neural Network (NAR). The method is applied for predicting sea level in Tanjung Emas Harbor in Semarang, Indonesia. We compare results of the prediction by using NAR with prediction by using tidal harmonic analysis. The accuracy of the prediction is measured by calculating the RMSE value and R value. NAR produces R value 0.9566 for training data and 0.9567 for prediction data. The choice of number of hidden layers in the NAR can also affects the results of prediction, in term of RMSE value and R value. The results show that NAR method produces a better accuracy in predicting sea level than using the tidal harmonic analysis. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Aperture Antennas for 5G Mobile Base Stations"
        ],
        "penulis":"Yamada, Yoshihide;Quzwain, Kamelia;Ansarudin, Farizah;Kamardin, Kamilia;Abd Rahman, Nurul Huda;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The fifth-generation (5G) mobile communication system will require the multi beam base station antennas. By taking into account a small antenna size at millimeter wave, any antenna types such as array, reflector and dielectric lens antennas become possible candidate. In this paper, aperture type antennas of reflector and lens are selected because of excellent multi beam performances. Fundamental antenna design technologies by a MATLAB software and expected radiation patterns by an electromagnetic simulator are shown. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The fifth-generation (5G) mobile communication system will require the multi beam base station antennas. By taking into account a small antenna size at millimeter wave, any antenna types such as array, reflector and dielectric lens antennas become possible candidate. In this paper, aperture type antennas of reflector and lens are selected because of excellent multi beam performances. Fundamental antenna design technologies by a MATLAB software and expected radiation patterns by an electromagnetic simulator are shown. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Digital leadership role in developing business model innovation and customer experience orientation in industry 4.0"
        ],
        "penulis":"Mihardjo, Leonardus W. W.;Sasmoko, Sasmoko;Alamsjah, Firdaus;Elidjen, Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 4.0 brings a new challenge for incumbent firms to anticipate new business model offered by emerging entries. The digital transformation is required by incumbent to develop innovation on product and service business model based on customer experience orientation. To support this transformation, strong digital leader is important to assure the development of this transformation. The study on the role of digital leadership on business model innovation and customer experience has not been explored, significantly, Hence, this research aims at assessing the role of digital leadership, whether it directly or indirectly influences the customer experience orientation in developing business model innovation. This study was conducted through survey to 88 senior leader respondents from Indonesia telecommunication firms, in which Smart-PLS application was used to analyze the data. The result show that digital leadership had direct and indirect impacts on customer experience orientation in developing business model innovation. The practical implications of these findings are recommended for the senior leader of management of telecommunications industries in Indonesia to strengthen digital leadership capability in conjunction with the development of business model innovation and customer experience orientation. Further research can be explored by expanding the sample, industry, statistical application and longitudinal study. \u00a9 2019 by the authors; licensee Growing Science, Canada. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 4.0 brings a new challenge for incumbent firms to anticipate new business model offered by emerging entries. The digital transformation is required by incumbent to develop innovation on product and service business model based on customer experience orientation. To support this transformation, strong digital leader is important to assure the development of this transformation. The study on the role of digital leadership on business model innovation and customer experience has not been explored, significantly, Hence, this research aims at assessing the role of digital leadership, whether it directly or indirectly influences the customer experience orientation in developing business model innovation. This study was conducted through survey to 88 senior leader respondents from Indonesia telecommunication firms, in which Smart-PLS application was used to analyze the data. The result show that digital leadership had direct and indirect impacts on customer experience orientation in developing business model innovation. The practical implications of these findings are recommended for the senior leader of management of telecommunications industries in Indonesia to strengthen digital leadership capability in conjunction with the development of business model innovation and customer experience orientation. Further research can be explored by expanding the sample, industry, statistical application and longitudinal study. \u00a9 2019 by the authors; licensee Growing Science, Canada. All rights reserved."
        ]
    },
    {
        "judul":[
            "Lessons learned to increase the digital startupssuccess rate"
        ],
        "penulis":"Mukti, Iqbal Yulizar;Wibowo, Ari Purno Wahyu;Galih, Savitri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose:The purpose of this paper is to explore the lessons learned to increase the startups\u2019 success rate based on a case study in Selurup, a digital startup worked on food delivery services. Design\/methodology\/approach: To systematically identify the lessons learned, and this paper adopts the hypothesis-driven entrepreneurship framework. Guides by research questions described in the introduction section, the lessons learned are elaborated by using interviews with the co-founder. Findings: Research in this paper, ultimately suggest the emerging digital startups to follow the hypothesis-driven entrepreneurship framework as the structured approach to face the extreme uncertainty that typically faced by the startups. Research limitations\/implications: Research in this paper explores the lessons learned only from one startup. Consequently, the lesson learned might not represented all the startups in Indonesia. Practical implications: It is expected that the lessons learned from this research can give positive contribution to increase the emerging digital startups success rate. Originality\/value: This study academically explores the lesson learned especially from the emerging digital startups, following the hypothesis-driven entrepreneurship framework. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose:The purpose of this paper is to explore the lessons learned to increase the startups\u2019 success rate based on a case study in Selurup, a digital startup worked on food delivery services. Design\/methodology\/approach: To systematically identify the lessons learned, and this paper adopts the hypothesis-driven entrepreneurship framework. Guides by research questions described in the introduction section, the lessons learned are elaborated by using interviews with the co-founder. Findings: Research in this paper, ultimately suggest the emerging digital startups to follow the hypothesis-driven entrepreneurship framework as the structured approach to face the extreme uncertainty that typically faced by the startups. Research limitations\/implications: Research in this paper explores the lessons learned only from one startup. Consequently, the lesson learned might not represented all the startups in Indonesia. Practical implications: It is expected that the lessons learned from this research can give positive contribution to increase the emerging digital startups success rate. Originality\/value: This study academically explores the lesson learned especially from the emerging digital startups, following the hypothesis-driven entrepreneurship framework. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "Welcome message chair of IAICT'2019"
        ],
        "penulis":"Suhendi, Asep;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Analysis of Hubs and Authorities Centrality Using Probabilistic Affinity Index (PAI) on directed-weighted graph in Social Network Analysis"
        ],
        "penulis":"Farhan, Muhammad Thomy;Darwiyanto, Eko;Asror, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Social media is a place for interaction that is connected to the internet network, Twitter is one of the most popular social media. In Twitter sometimes someone does not want to be left behind information related to a particular topic, so it is necessary to follow the user related to the topic so that the information is conveyed quickly. In this study, an analysis was carried out that applied the Hubs and Authorities Centrality method to determine user rankings and the Probabilistic Affinity Index method for weighting values. The results of authority centrality ranking can be used as a list of recommendations of a user who plays a role or has information about a particular topic and the results of centrality hub ranking can be used as a list of recommendations of a user who has an interest in a particular topic. From the testing in this study, changes in the number of other users that are related to the user have the largest average change in centrality value of 0.01188. While the change in the number of relations has the largest average change in the centrality value of 1.44087\u00d710-9. Based on these tests, the number of other users that are related to the user has a large influence on the results of ranking compared to the number of relationships to other users. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Social media is a place for interaction that is connected to the internet network, Twitter is one of the most popular social media. In Twitter sometimes someone does not want to be left behind information related to a particular topic, so it is necessary to follow the user related to the topic so that the information is conveyed quickly. In this study, an analysis was carried out that applied the Hubs and Authorities Centrality method to determine user rankings and the Probabilistic Affinity Index method for weighting values. The results of authority centrality ranking can be used as a list of recommendations of a user who plays a role or has information about a particular topic and the results of centrality hub ranking can be used as a list of recommendations of a user who has an interest in a particular topic. From the testing in this study, changes in the number of other users that are related to the user have the largest average change in centrality value of 0.01188. While the change in the number of relations has the largest average change in the centrality value of 1.44087\u00d710-9. Based on these tests, the number of other users that are related to the user has a large influence on the results of ranking compared to the number of relationships to other users. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Responsive Innovation through Perceived Shared Values and Preferences of Customers"
        ],
        "penulis":"Lubis, Muharman;Fauzi, Rahmat;Sutoyo, Edi;Abdulmana, Sahidan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Responsive Innovation can be define as the attempt from the corporate or respected individual to bring the solution from particular problem by offer more ideal practical implementation based on specific requirement in the market. This type innovation can be generated or effectuate through modifying, combining, substituting or eliminating current process of problem solving or decision making in the market to be more precise, efficient and rigid compare to the previous. This study explore the possibilities to identify the characteristics of responsive innovation by developing web and mobile application based on the demand in the market with the several criteria namely number of exist application, higher demand, user experience attachment, attractive market and small routine margin of profit. Thus, this study present the application design called eLo and FunBuz to make it easier the process of order or reservation online. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Responsive Innovation can be define as the attempt from the corporate or respected individual to bring the solution from particular problem by offer more ideal practical implementation based on specific requirement in the market. This type innovation can be generated or effectuate through modifying, combining, substituting or eliminating current process of problem solving or decision making in the market to be more precise, efficient and rigid compare to the previous. This study explore the possibilities to identify the characteristics of responsive innovation by developing web and mobile application based on the demand in the market with the several criteria namely number of exist application, higher demand, user experience attachment, attractive market and small routine margin of profit. Thus, this study present the application design called eLo and FunBuz to make it easier the process of order or reservation online. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Label Comparison Analysis Using Hybrid Similarity for Labeling Systems of Indonesian University Websites (English Menu Version)"
        ],
        "penulis":"Ady Sutrisna, I. Gusti Bagus;Kusumo, Dana S.;Asror, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Labeling systems are an important component in designing a university website. In order to avoid misinformation, website developers need to design a website labeling system that can represent information that a website owner wants to deliver to the users of her website. One way of designing a labeling system is by comparing and studying the labeling system used on competitor's websites. Syntactic similarity is usually used for comparing the websites' labels. However, it has a limitation that can only calculate similarities based on strings only, so that the possibility of two compared labels having the same meaning will be considered as different labels. To provide the meaning of the label, the comparison using semantic similarity is used. However, semantic similarity has limitations such as not being able to process two words or more and possibly having no path exists between two word senses. Therefore, this research proposes a hybrid similarity where the highest result of syntactic and semantic similarity comparison between two labels is combined and able to cover the limitation of two methods. The hybrid similarity shows the results of possibility of higher score between combined syntactic and semantic similarity score with suggestion on the list label (based on semantic result). The expert suggest output of hybrid list label to help developer create and reviewing existing label, and then participant who answers the questionnaires 82.16% agree with label that show the acceptance of the label. The list label based on hybrid score can help and assisting the web developer to create new labeling systems for a new website. It is also help developer to improving an existing website's labeling systems. Keywords: university website, labeling systems, syntactic similarity, semantic similarity, hybrid similarity, Levensthein Distance, Wu and Palmer. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Labeling systems are an important component in designing a university website. In order to avoid misinformation, website developers need to design a website labeling system that can represent information that a website owner wants to deliver to the users of her website. One way of designing a labeling system is by comparing and studying the labeling system used on competitor's websites. Syntactic similarity is usually used for comparing the websites' labels. However, it has a limitation that can only calculate similarities based on strings only, so that the possibility of two compared labels having the same meaning will be considered as different labels. To provide the meaning of the label, the comparison using semantic similarity is used. However, semantic similarity has limitations such as not being able to process two words or more and possibly having no path exists between two word senses. Therefore, this research proposes a hybrid similarity where the highest result of syntactic and semantic similarity comparison between two labels is combined and able to cover the limitation of two methods. The hybrid similarity shows the results of possibility of higher score between combined syntactic and semantic similarity score with suggestion on the list label (based on semantic result). The expert suggest output of hybrid list label to help developer create and reviewing existing label, and then participant who answers the questionnaires 82.16% agree with label that show the acceptance of the label. The list label based on hybrid score can help and assisting the web developer to create new labeling systems for a new website. It is also help developer to improving an existing website's labeling systems. Keywords: university website, labeling systems, syntactic similarity, semantic similarity, hybrid similarity, Levensthein Distance, Wu and Palmer. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Artificial neural networks (ANN)-based seismic signal source identification from MEMS accelerometer measurements"
        ],
        "penulis":"Irawan, Hendy;Prihatmanto, Ary Setijadi;Machbub, Carmadi;Widiyantoro, Sri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper reports initial findings on Artificial Neural Networks (ANN)-based methods to identify seismic signal source using only low-quality MEMS accelerometer signals. We collected annotated signals sampled at 50 Hz from several mobile devices and built an open source linear acceleration dataset. From this dataset, we performed and compared several feature extraction techniques based on signal length and spectrogram parameters. We trained the resulting features using three-layer neural networks with a hidden layer of 32 neurons and a dropout layer. Training was performed using Tensorflow 2.0 and Google Colaboratory with GPU backend. The results show 95.83% validation accuracy from spectrogram signals with length of 2 seconds and 3 seconds, and 79.17% validation accuracy from raw amplitude inputs. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper reports initial findings on Artificial Neural Networks (ANN)-based methods to identify seismic signal source using only low-quality MEMS accelerometer signals. We collected annotated signals sampled at 50 Hz from several mobile devices and built an open source linear acceleration dataset. From this dataset, we performed and compared several feature extraction techniques based on signal length and spectrogram parameters. We trained the resulting features using three-layer neural networks with a hidden layer of 32 neurons and a dropout layer. Training was performed using Tensorflow 2.0 and Google Colaboratory with GPU backend. The results show 95.83% validation accuracy from spectrogram signals with length of 2 seconds and 3 seconds, and 79.17% validation accuracy from raw amplitude inputs. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Tea leaf maturity levels based on ycbcr color space and clustering centroid"
        ],
        "penulis":"Wicaksono, Bagaskara Aji;Novamizanti, Ledya;Ibrahim, Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Technology develops very rapidly in all areas. Smart Farming 4.0 is a farming management concept that uses modern technology to increase quantity and quality. The picking of tea leaves during this time the farmer is only based on the quotes from the planting block. If the block is already arriving, then the block is taken in a thorough plucking. However, the picking time can be erratic due to weather factors. The design of the tea leaf maturity level identification system based on the digital image processing of tea leaves. The leaf image of the tea is then processed on a system that begins with segmentation preprocessing, the image that has been uniform then carried out the extraction of images transformed into the color features of YCbCr. After obtaining the luma and chroma values, the classification using Centroid is based on statistical characteristics. Then the extraction and classifying data is a system database that will then be used during the testing process. The total data of Peko tea leaves (P + 2) is used as much as 90 training images and 90 test images. The maturity classification of tea leaves uses a Centroid Clustering method with centroid 10 based on YCbCr color space and a minimum statistical feature, maximum, and variances get an accuracy value of 80% and computation time of 2.80 seconds. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Technology develops very rapidly in all areas. Smart Farming 4.0 is a farming management concept that uses modern technology to increase quantity and quality. The picking of tea leaves during this time the farmer is only based on the quotes from the planting block. If the block is already arriving, then the block is taken in a thorough plucking. However, the picking time can be erratic due to weather factors. The design of the tea leaf maturity level identification system based on the digital image processing of tea leaves. The leaf image of the tea is then processed on a system that begins with segmentation preprocessing, the image that has been uniform then carried out the extraction of images transformed into the color features of YCbCr. After obtaining the luma and chroma values, the classification using Centroid is based on statistical characteristics. Then the extraction and classifying data is a system database that will then be used during the testing process. The total data of Peko tea leaves (P + 2) is used as much as 90 training images and 90 test images. The maturity classification of tea leaves uses a Centroid Clustering method with centroid 10 based on YCbCr color space and a minimum statistical feature, maximum, and variances get an accuracy value of 80% and computation time of 2.80 seconds. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Sundanese Aksara Recognition Using Histogram of Oriented Gradients"
        ],
        "penulis":"Salsabila, Haifa;Rachmawati, Ema;Sthevanie, Febryanti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia is a famous nation for its wealth in both natural and language resources and culture. Aksara is one of the Indonesian cultures that must be preserved therefore, as not to lose its existence. To avoid the loss of the existence of letters, especially Sundanese aksara, we proposed a new approach Sundanese word recognition with considering rarangk\u00e8n characteristic using the Histogram of Oriented Gradients method and support vector machine as a classification method. The datasets used are sourced from a Sundanese dictionary book. Based on the test results obtained an accuracy 81.48 % of the recognition of word Sundanese aksara with the values pixels per cell is 10x10 and cells per block is 1x1 or the values pixels per cell is 20x20 and cells per block is 3x3. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is a famous nation for its wealth in both natural and language resources and culture. Aksara is one of the Indonesian cultures that must be preserved therefore, as not to lose its existence. To avoid the loss of the existence of letters, especially Sundanese aksara, we proposed a new approach Sundanese word recognition with considering rarangk\u00e8n characteristic using the Histogram of Oriented Gradients method and support vector machine as a classification method. The datasets used are sourced from a Sundanese dictionary book. Based on the test results obtained an accuracy 81.48 % of the recognition of word Sundanese aksara with the values pixels per cell is 10x10 and cells per block is 1x1 or the values pixels per cell is 20x20 and cells per block is 3x3. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Flow Analysis of Payment Transactions in SAP Reduction of Data with Some Testing Method in PT XYZ"
        ],
        "penulis":"Nuzuli, Rizki;Puspitasari, Warih;Hediyanto, Umar Yunan K.S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PT XYZ expands service with changing business portfolio Fixed, Mobile, and Multimedia (FMM) to Telecommunications, Information, Media and Edutainment (TIME) to be competitive in the telecommunications market. POTS services are one of those services with fixed wireline and indiehome broadband are the main products. It due to customers needs a wireline telephone service with fast connectivity. This development provided directly increase the number of customers. Accordingly, the SAP database on the currently PT XYZ server has been taking the data with large capacity. This resulted in an SAP system in organization impaired operation within a certain period (downtime). To overcome the problems, PT XYZ performs data reduction of the payment transaction from current server to a new server. A process is needed to ensure that each transaction unit using reduced and migrated data to run properly on the new server. Therefore, a testing process is needed to test every unit of the payment transaction data reduction. Tests were conducted using a black-box test, system integration test, and user acceptance test to determine if there are defects or bugs in the system. The expected results in this study are an analysis of system testing of SAP applications. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT XYZ expands service with changing business portfolio Fixed, Mobile, and Multimedia (FMM) to Telecommunications, Information, Media and Edutainment (TIME) to be competitive in the telecommunications market. POTS services are one of those services with fixed wireline and indiehome broadband are the main products. It due to customers needs a wireline telephone service with fast connectivity. This development provided directly increase the number of customers. Accordingly, the SAP database on the currently PT XYZ server has been taking the data with large capacity. This resulted in an SAP system in organization impaired operation within a certain period (downtime). To overcome the problems, PT XYZ performs data reduction of the payment transaction from current server to a new server. A process is needed to ensure that each transaction unit using reduced and migrated data to run properly on the new server. Therefore, a testing process is needed to test every unit of the payment transaction data reduction. Tests were conducted using a black-box test, system integration test, and user acceptance test to determine if there are defects or bugs in the system. The expected results in this study are an analysis of system testing of SAP applications. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Project Evaluation for Business and IT Alignment with Enterprise Architecture for Water Distribution Company"
        ],
        "penulis":"Wardani, Anita Eka;Asti Amalia N.F.;Gumilang, Soni F.;Muharman, Lubis;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Actually, there are gaps exist in the development of many large companies, which related to the automation and integration between the business and technology information systems within the company. Enterprise Architecture (EA) helps in aligning the business functions of a company with existing applications tooptimizethe existing business processes for the purpose of growth, revenue and satisfaction. For the creation of a well-integrated system, EAprovide logical design to build the sequence of connecting each function either in the structure, task and technology to achieve company goals. A well-designed information system (IS) architecture can be one of the best solutions to enhance the ability and capability of the company in serving its customers especially with the sustainability, maintainability, extendibility and maintainability. Furthermore, good information system can accommodate the company's needs to improve the company's performance process where the useful information system have been generated through careful planning and preparation. EA is a solution that can be used in designing systems within the company by integrating 4 (four) domains namely Business, Data, Applications, and Technology. This study provide the evaluation within the company that is expected to give preliminary result of process to be dealt with in order to increase the performance and support the business processes in the company. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Actually, there are gaps exist in the development of many large companies, which related to the automation and integration between the business and technology information systems within the company. Enterprise Architecture (EA) helps in aligning the business functions of a company with existing applications tooptimizethe existing business processes for the purpose of growth, revenue and satisfaction. For the creation of a well-integrated system, EAprovide logical design to build the sequence of connecting each function either in the structure, task and technology to achieve company goals. A well-designed information system (IS) architecture can be one of the best solutions to enhance the ability and capability of the company in serving its customers especially with the sustainability, maintainability, extendibility and maintainability. Furthermore, good information system can accommodate the company's needs to improve the company's performance process where the useful information system have been generated through careful planning and preparation. EA is a solution that can be used in designing systems within the company by integrating 4 (four) domains namely Business, Data, Applications, and Technology. This study provide the evaluation within the company that is expected to give preliminary result of process to be dealt with in order to increase the performance and support the business processes in the company. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparison of the Approach in the Zakat Management System"
        ],
        "penulis":"Lubis, Muharman;Ridho Lubis, Arif;Almaarif, Ahmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Zakat institution have been essential entity in the collection and distribution process of zakat management effectively and efficiently. Although, it is clear that there are some difficulties, which require great attention such as transparency, accessibility, fairness and compatibility due to cultural, geographical and political context. The purpose of this paper is to analyse the common approaches used in various countries through comparison in the best practice of managing zakat fund. It is expected to provide more understanding on the business process and visualization for the purpose of improvement. The contribution of this paper is twofold, firstly, the zakat institution, regardless the limitation or boundary should identify the primary requirement in zakat management system with focusing on the alignment between the model used and the proper application system. Secondly, the findings may provide insight on how the zakat institutions can further improve their use of technology and handle their human capital to deliver more effective and efficient process. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Zakat institution have been essential entity in the collection and distribution process of zakat management effectively and efficiently. Although, it is clear that there are some difficulties, which require great attention such as transparency, accessibility, fairness and compatibility due to cultural, geographical and political context. The purpose of this paper is to analyse the common approaches used in various countries through comparison in the best practice of managing zakat fund. It is expected to provide more understanding on the business process and visualization for the purpose of improvement. The contribution of this paper is twofold, firstly, the zakat institution, regardless the limitation or boundary should identify the primary requirement in zakat management system with focusing on the alignment between the model used and the proper application system. Secondly, the findings may provide insight on how the zakat institutions can further improve their use of technology and handle their human capital to deliver more effective and efficient process. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Strategies to increase universities\u2019 scientific publication in indonesia"
        ],
        "penulis":"Putri, Ratna Komala;Wulandari, Kartika;Nilasari, Irma;Taruna, Indra;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Objective: The paper aims to seek strategies to improve the quality of universities\u2019 scientific publications in Indonesia. Design\/ methodology\/ approach: The present research uses both quantitative and qualitative approach to establish conceptual models and strategies to improve the quality of universities\u2019 scientific publications in Indonesia through hypotheses testing. Variables subjected to analysis include learning organizations, knowledge sharing, research climate, organizational\/ institutional support, and quality of universities\u2019 scientific publications. Findings: Based on the empirical research results, it is found that there is significant relationship among learning organizations, research climate, knowledge sharing, institutional supports, and the quality of universities\u2019 scientific publications. Research limitations\/ implications: The research samples of 200 private universities were obtained from a minimum sample of studies using structural equation models. Practical implications: The findings of the study are beneficial for university management and lecturers in improving the quality of scientific publications; thus, improving the quality of Indonesian scientific publications to be the first rank in ASEAN region. Originality\/ value: This research provides a meaningful contribution since there lack studies on strategies to improve the quality of scientific publications in Indonesia. \u00a9 2019 by authors.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Objective: The paper aims to seek strategies to improve the quality of universities\u2019 scientific publications in Indonesia. Design\/ methodology\/ approach: The present research uses both quantitative and qualitative approach to establish conceptual models and strategies to improve the quality of universities\u2019 scientific publications in Indonesia through hypotheses testing. Variables subjected to analysis include learning organizations, knowledge sharing, research climate, organizational\/ institutional support, and quality of universities\u2019 scientific publications. Findings: Based on the empirical research results, it is found that there is significant relationship among learning organizations, research climate, knowledge sharing, institutional supports, and the quality of universities\u2019 scientific publications. Research limitations\/ implications: The research samples of 200 private universities were obtained from a minimum sample of studies using structural equation models. Practical implications: The findings of the study are beneficial for university management and lecturers in improving the quality of scientific publications; thus, improving the quality of Indonesian scientific publications to be the first rank in ASEAN region. Originality\/ value: This research provides a meaningful contribution since there lack studies on strategies to improve the quality of scientific publications in Indonesia. \u00a9 2019 by authors."
        ]
    },
    {
        "judul":[
            "The Effectiveness of Digital Marketing for Show Up Company: Issues and Challenges"
        ],
        "penulis":"Kusumawati, Niken Febriani;Kusumasari, Tien Fabrianti;Lubis, Muharman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this decade, start-up companies have played an essential role in the global economy and their existences have grown significantly to maintain the rise of economy domestically and internationally. Therefore, this kind of companies have struggle to gain foothold in the competitive market because some of them produce kind of complex products or weird service that find difficulty in term of engagement with market entrance and targeted customer due to several reasons. One of primary reason is that most of them cannot establish proper marketing strategy and maintain the channel for communication in order to raise attractiveness to the potential customers. The purpose of this study is aiming to investigate the effectiveness of digital marketing in a start-up company, which in this case focus on social media platform of influencers and promoters. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this decade, start-up companies have played an essential role in the global economy and their existences have grown significantly to maintain the rise of economy domestically and internationally. Therefore, this kind of companies have struggle to gain foothold in the competitive market because some of them produce kind of complex products or weird service that find difficulty in term of engagement with market entrance and targeted customer due to several reasons. One of primary reason is that most of them cannot establish proper marketing strategy and maintain the channel for communication in order to raise attractiveness to the potential customers. The purpose of this study is aiming to investigate the effectiveness of digital marketing in a start-up company, which in this case focus on social media platform of influencers and promoters. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Security document for smart parking gate based on common criteria framework"
        ],
        "penulis":"Yasirandi, Rahmat;Setyoko, Yoso Adi;Sukarno, Parman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research used Common Criteria Framework to design more complete security requirements than the previous research for smart parking gate. Common Evaluation Methodology (CEM) mentions that Common Criteria Framework must use ISO 15408. This research used ISO 15408 as a guideline for analyzing, designing, and documenting the system security requirements in a more complete and comprehensive smart parking gate. The initial stage of Common Criteria Framework is to analyze the threats that might occur on the system. This research refers to the threat tree analysis in ISO 15446 to obtain a list of threats that may occur in the system. Based on the threat tree analysis, there were 6 threats to the system built. The next step is mapping the threats to security objectives and obtaining 7 Security Objectives (SO). At the end of this study, the functional requirement of security for the system referring to the references obtained in the previous stage were analyzed. Therefore, 17 Security Functional Requirements (SFR) were obtained. Those 17 SFR can be used as references in developing a system on the smart parking gate to ward off the threats that have been identified initially. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research used Common Criteria Framework to design more complete security requirements than the previous research for smart parking gate. Common Evaluation Methodology (CEM) mentions that Common Criteria Framework must use ISO 15408. This research used ISO 15408 as a guideline for analyzing, designing, and documenting the system security requirements in a more complete and comprehensive smart parking gate. The initial stage of Common Criteria Framework is to analyze the threats that might occur on the system. This research refers to the threat tree analysis in ISO 15446 to obtain a list of threats that may occur in the system. Based on the threat tree analysis, there were 6 threats to the system built. The next step is mapping the threats to security objectives and obtaining 7 Security Objectives (SO). At the end of this study, the functional requirement of security for the system referring to the references obtained in the previous stage were analyzed. Therefore, 17 Security Functional Requirements (SFR) were obtained. Those 17 SFR can be used as references in developing a system on the smart parking gate to ward off the threats that have been identified initially. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Noise filtering framework for electronic nose signals: An application for beef quality monitoring"
        ],
        "penulis":"Wijaya, Dedy Rahman;Sarno, Riyanarto;Zulaika, Enny;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Beef is one of the most popular and widely consumed foodstuffs in the world. Nevertheless, it can easily decay if not properly treated during distribution and storage. The consumption of low quality beef causes a serious health hazard. The electronic nose (e-nose) is a rapid and low-cost instrument for beef quality classification. Hence, the development of a mobile e-nose for online meat quality monitoring is appealing. In the last few years, e-noses have been used to classify different grades of beef and to predict the number of the microbial population in beef samples. Several methods are used to deal with these classification and regression problems. Especially in multiclass beef classification and regression, signals contaminated with noise can significantly degrade the performance of the pattern recognition module. Therefore, the presence of internal and external noise in e-nose signals is a major challenge in beef quality monitoring. In this study, a noise filtering framework based on a fine-tuned discrete wavelet transform (DWT) was developed to handle noisy signals generated by an e-nose sensor array. To the best of our knowledge this is the first time the problem of e-nose signal noise in beef quality classification is tackled. The proposed framework was integrated and tested on several machine learning algorithms that were used in previous studies, i.e. k-nearest neighbor (k-NN), support vector machine (SVM), quadratic discriminant analysis (QDA), artificial neural network (ANN), and adaptive neuro fuzzy inference system (ANFIS). Furthermore, the effect of noise filtering was investigated in the classification with two, three, and four classes of beef. The effect of noise filtering was also observed in regression tasks to predict the size of microbial population in beef samples. The experimental results showed that the proposed framework provides a significant improvement in multiclass classification and regression tasks. \u00a9 2019 Elsevier B.V.",
            "CH3H3CCH3View detailsExpand Substance Isobutane",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Beef is one of the most popular and widely consumed foodstuffs in the world. Nevertheless, it can easily decay if not properly treated during distribution and storage. The consumption of low quality beef causes a serious health hazard. The electronic nose (e-nose) is a rapid and low-cost instrument for beef quality classification. Hence, the development of a mobile e-nose for online meat quality monitoring is appealing. In the last few years, e-noses have been used to classify different grades of beef and to predict the number of the microbial population in beef samples. Several methods are used to deal with these classification and regression problems. Especially in multiclass beef classification and regression, signals contaminated with noise can significantly degrade the performance of the pattern recognition module. Therefore, the presence of internal and external noise in e-nose signals is a major challenge in beef quality monitoring. In this study, a noise filtering framework based on a fine-tuned discrete wavelet transform (DWT) was developed to handle noisy signals generated by an e-nose sensor array. To the best of our knowledge this is the first time the problem of e-nose signal noise in beef quality classification is tackled. The proposed framework was integrated and tested on several machine learning algorithms that were used in previous studies, i.e. k-nearest neighbor (k-NN), support vector machine (SVM), quadratic discriminant analysis (QDA), artificial neural network (ANN), and adaptive neuro fuzzy inference system (ANFIS). Furthermore, the effect of noise filtering was investigated in the classification with two, three, and four classes of beef. The effect of noise filtering was also observed in regression tasks to predict the size of microbial population in beef samples. The experimental results showed that the proposed framework provides a significant improvement in multiclass classification and regression tasks. \u00a9 2019 Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Rule based pattern type of verb identification algorithm for the Holy Qur'an"
        ],
        "penulis":"Ramadhan, Teguh Ikhlas;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes an algorithm for identification of pattern type of verb in classical Arabic. This topic was proposed because of the problem on Arabic Al-Qur'an annotation is an important task. It is important for the processing of the Holy Qur'an data, and provides convenience for those who want to learn Arabic, especially understanding arabic on morphology aspect. Understanding verb is the first step to understand the arabic morphology. The effort is to recognize how the rules regarding the pattern type of verb with the rule based approach read the pattern with prefix, the diacritics and the suffix if the verb. Briefly entered verb (Arabic or transliteration) and its output is an attribute of verb which is pattern type of verb, pronouns and verb pattern with the main rule that is identifying pattern, getting verb attributes and determining verb pattern. Experiments show that the proposed algorithm obtained accuracy at 96.48% with soft calculation method and 89.46% with harsh method calculation method. \u00a9 2019 The Authors. Published by Elsevier B.V.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes an algorithm for identification of pattern type of verb in classical Arabic. This topic was proposed because of the problem on Arabic Al-Qur'an annotation is an important task. It is important for the processing of the Holy Qur'an data, and provides convenience for those who want to learn Arabic, especially understanding arabic on morphology aspect. Understanding verb is the first step to understand the arabic morphology. The effort is to recognize how the rules regarding the pattern type of verb with the rule based approach read the pattern with prefix, the diacritics and the suffix if the verb. Briefly entered verb (Arabic or transliteration) and its output is an attribute of verb which is pattern type of verb, pronouns and verb pattern with the main rule that is identifying pattern, getting verb attributes and determining verb pattern. Experiments show that the proposed algorithm obtained accuracy at 96.48% with soft calculation method and 89.46% with harsh method calculation method. \u00a9 2019 The Authors. Published by Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Fit-NES: Wearable bracelet for heart rate monitoring"
        ],
        "penulis":"Sani, Muhammad Ikhsan;Mutiara, Giva Andriana;Putra, Raden Sri Dewanto Wijaya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The heart is a vital organ that serves to pump blood to the whole body. A heart rate can be used as a healthy body parameter conditions. Growing evidence suggests that IT-based health records play essential role to drive medical revolution especially on data storage and processing. The heart rate measurement (HRM) process usually involves wearable sensor devices to record patient's data. This data is recorded to help the doctors to analyze and provide a better diagnose in order to determine the best treatment for the patients. Connecting the sensor system through a wireless network to a cloud server will enable the doctor to monitor remotely. This paper presents fit-NES wearable bracelet, an alternative method for integrating a HR measurement device using optical based pulse sensor and Bluetooth-based communication module. This paper is also present the benchmarking of proposed system with several various commercial HR measurement devices. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The heart is a vital organ that serves to pump blood to the whole body. A heart rate can be used as a healthy body parameter conditions. Growing evidence suggests that IT-based health records play essential role to drive medical revolution especially on data storage and processing. The heart rate measurement (HRM) process usually involves wearable sensor devices to record patient's data. This data is recorded to help the doctors to analyze and provide a better diagnose in order to determine the best treatment for the patients. Connecting the sensor system through a wireless network to a cloud server will enable the doctor to monitor remotely. This paper presents fit-NES wearable bracelet, an alternative method for integrating a HR measurement device using optical based pulse sensor and Bluetooth-based communication module. This paper is also present the benchmarking of proposed system with several various commercial HR measurement devices. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Understanding Public Opinion towards New Sharing Economy Business Model Using Content Analysis"
        ],
        "penulis":"Alamsyah, Andry;Rochmah, Wachda Yuniar;Nugroho, Ditya Dwi Adhi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hospitality, as one of the sectors in the tourism industry, continues to show positive trend every year based on its revenues. In order to understand public opinion, the legacy method such as interview, questionnaire, and other time-consuming method is still widely used in this sector. However, this method is less efficient compared to data analytics methodology using available data from online source, such as social media Therefore, we need to conduct a research to see a better method in order to understand the public opinion in hospitality sector. There are many methodologies to support content analysis based on unstructured data to understand public opinion. In this research, we use content analysis methodology which consists of Sentiment Analysis, Topic Modeling, and Text Network Analysis to process 483413 obtained tweets from January 7thuntil March 28th, 2017. The twitter data is gained using Python and R language. The whole process of the research consists of data collection, data preprocessing, and interpreting the results. We use Rstudio, Jupyter Notebook and Gephi softwares during the process. As a case study in the hospitality sector, we use Airbnb as one of the sharing economy business models that allows other people to share their space and begins to be widely used by travelers around the world. Our objective is to understand public opinion towards Airbnb as online-based sharing economy business model which becomes a disruptive innovation for tourism industry. As the result, we are able to apply the combination of content analysis methods to give a good understanding towards the public opinion. Text Network Analysis gives us the ability to summarise large-scale conversation in very fast and real-time fashion. It provides the knowledge by associate most frequent words used in social conversations. Sentiment Analysis shows the feelings and emotion from people about certain topics. Topic Modelling is able to capture popular topics, thus gives comprehensive understanding on how people react towards a new business model. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hospitality, as one of the sectors in the tourism industry, continues to show positive trend every year based on its revenues. In order to understand public opinion, the legacy method such as interview, questionnaire, and other time-consuming method is still widely used in this sector. However, this method is less efficient compared to data analytics methodology using available data from online source, such as social media Therefore, we need to conduct a research to see a better method in order to understand the public opinion in hospitality sector. There are many methodologies to support content analysis based on unstructured data to understand public opinion. In this research, we use content analysis methodology which consists of Sentiment Analysis, Topic Modeling, and Text Network Analysis to process 483413 obtained tweets from January 7thuntil March 28th, 2017. The twitter data is gained using Python and R language. The whole process of the research consists of data collection, data preprocessing, and interpreting the results. We use Rstudio, Jupyter Notebook and Gephi softwares during the process. As a case study in the hospitality sector, we use Airbnb as one of the sharing economy business models that allows other people to share their space and begins to be widely used by travelers around the world. Our objective is to understand public opinion towards Airbnb as online-based sharing economy business model which becomes a disruptive innovation for tourism industry. As the result, we are able to apply the combination of content analysis methods to give a good understanding towards the public opinion. Text Network Analysis gives us the ability to summarise large-scale conversation in very fast and real-time fashion. It provides the knowledge by associate most frequent words used in social conversations. Sentiment Analysis shows the feelings and emotion from people about certain topics. Topic Modelling is able to capture popular topics, thus gives comprehensive understanding on how people react towards a new business model. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "SCOR-BSC Integrated Model for A Small Medium Enterprise Clothing Industry Using MTS-based Production Strategy in Indonesia"
        ],
        "penulis":"Permadi B.W.;Ridwan A.Y.;Juliani W.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Small and Medium Enterprises (SME) in Indonesia continues to grow. SMEs have proven to be able to survive, and Indonesia was hit by a crisis in 1997. However, UKM has several disadvantages, one of which is the difficulty in developing its business. Hence performance measurement is needed so that SMEs can see the performance of their SMEs and can make improvements. This research will focus on one of the SMEs engaged in the clothing industry in the city of Bandung. This research also focuses on the production section that uses the make-to-stock strategy as its production strategy. The integrated SCOR-BSC model is used as the basis for determining the KPI needed by SME clothing. The results of this study can be the basis for the development of a monitoring system. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Small and Medium Enterprises (SME) in Indonesia continues to grow. SMEs have proven to be able to survive, and Indonesia was hit by a crisis in 1997. However, UKM has several disadvantages, one of which is the difficulty in developing its business. Hence performance measurement is needed so that SMEs can see the performance of their SMEs and can make improvements. This research will focus on one of the SMEs engaged in the clothing industry in the city of Bandung. This research also focuses on the production section that uses the make-to-stock strategy as its production strategy. The integrated SCOR-BSC model is used as the basis for determining the KPI needed by SME clothing. The results of this study can be the basis for the development of a monitoring system. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Prediction Stock Price Based on Different Index Factors Using LSTM"
        ],
        "penulis":"Lai, Chun Yuan;Chen, Rung-Ching;Caraka, Rezzy Eko;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Predicting stock price has been a challenging project for many researchers, investors, and analysts. Most of them are interested in knowing the stock price trend in the future. To get a precise and winning model is the wish of them. Recently, Neural Network has been a prevalent means for stock prediction. However, there are many ways and different predicting models such as Convolutional Neural Networks (CNN), Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). In this paper, we propose a novel idea that average previous five days stock market information (open, high, low, volume, close) as a new value then use this value to predict, and use the predicted value as the average of the stock price information for the next five days. Moreover, we utilize Technical Analysis Indicators to consider whether to buy stocks or continue to hold stocks or sell stocks. We use Foxconn company data collected from Taiwan Stock Exchange for testing with the Neural Network Long Short-Term Memory (LSTM). \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Predicting stock price has been a challenging project for many researchers, investors, and analysts. Most of them are interested in knowing the stock price trend in the future. To get a precise and winning model is the wish of them. Recently, Neural Network has been a prevalent means for stock prediction. However, there are many ways and different predicting models such as Convolutional Neural Networks (CNN), Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). In this paper, we propose a novel idea that average previous five days stock market information (open, high, low, volume, close) as a new value then use this value to predict, and use the predicted value as the average of the stock price information for the next five days. Moreover, we utilize Technical Analysis Indicators to consider whether to buy stocks or continue to hold stocks or sell stocks. We use Foxconn company data collected from Taiwan Stock Exchange for testing with the Neural Network Long Short-Term Memory (LSTM). \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A new metaheuristics for solving vehicle routing problem: Partial Comparison Optimization"
        ],
        "penulis":"Adhi A.;Santosa B.;Siswanto N.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Vehicle Routing Problem (VRP) is a problem of selecting shortest route from a depot to serve several nodes by considering transport capacity. In this study, a new metaheuristcs algorithm is proposed to solve VRP in order to achieve optimal solution. This metaheuristics algorithm is Partial Comparison Optimization (PCO). This new optimization algorithm was developed to solve combinatorial optimization problems such as VRP. In this study, PCO was tested to solve the problems that existed in the origin VRP. To prove PCO is a good metaheuristics for solving VRP, several of instances of symmetrical VRP were selected from the VRP library to evaluate its performance. The numerical results obtained from the calculation indicated that the proposed optimization method could achieve results that almost similar with the best-known solutions within a reasonable time calculation. It showed that PCO was a good metaheuristics to solve VRP. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Vehicle Routing Problem (VRP) is a problem of selecting shortest route from a depot to serve several nodes by considering transport capacity. In this study, a new metaheuristcs algorithm is proposed to solve VRP in order to achieve optimal solution. This metaheuristics algorithm is Partial Comparison Optimization (PCO). This new optimization algorithm was developed to solve combinatorial optimization problems such as VRP. In this study, PCO was tested to solve the problems that existed in the origin VRP. To prove PCO is a good metaheuristics for solving VRP, several of instances of symmetrical VRP were selected from the VRP library to evaluate its performance. The numerical results obtained from the calculation indicated that the proposed optimization method could achieve results that almost similar with the best-known solutions within a reasonable time calculation. It showed that PCO was a good metaheuristics to solve VRP. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "DBMS-KU interpolation for WMT19 news translation task"
        ],
        "penulis":"Budiwati, Sari Dewi;Siagian, Al Hafiz Akbar Maulana;Fatyanosa, Tirana Noor;Aritsugi, Masayoshi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents the participation of DBMS-KU Interpolation system in WMT19 shared task, namely, Kazakh-English language pair. We examine the use of interpolation method using a different language model order. Our Interpolation system combines a direct translation with Russian as a pivot language. We use 3-gram and 5-gram language model orders to perform the language translation in this work. To reduce noise in the pivot translation process, we prune the phrase table of source-pivot and pivot-target. Our experimental results show that our Interpolation system outperforms the Baseline in terms of BLEU-cased score by +0.5 and +0.1 points in Kazakh-English and English-Kazakh, respectively. In particular, using the 5-gram language model order in our system could obtain better BLEU-cased score than utilizing the 3-gram one. Interestingly, we found that by employing the Interpolation system could reduce the perplexity score of English-Kazakh when using 3-gram language model order. \u00a9 2019 Association for Computational Linguistics"
        ],
        "abstrak":[
            "This paper presents the participation of DBMS-KU Interpolation system in WMT19 shared task, namely, Kazakh-English language pair. We examine the use of interpolation method using a different language model order. Our Interpolation system combines a direct translation with Russian as a pivot language. We use 3-gram and 5-gram language model orders to perform the language translation in this work. To reduce noise in the pivot translation process, we prune the phrase table of source-pivot and pivot-target. Our experimental results show that our Interpolation system outperforms the Baseline in terms of BLEU-cased score by +0.5 and +0.1 points in Kazakh-English and English-Kazakh, respectively. In particular, using the 5-gram language model order in our system could obtain better BLEU-cased score than utilizing the 3-gram one. Interestingly, we found that by employing the Interpolation system could reduce the perplexity score of English-Kazakh when using 3-gram language model order. \u00a9 2019 Association for Computational Linguistics"
        ]
    },
    {
        "judul":[
            "Experiment of 3-Phase N-path Filter for Hum Noise Suppression"
        ],
        "penulis":"Afifah, Khilda;Retdian, Nicodimus;Arijal, Muhammad;Shima, Takeshi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One of a critical problem in the biomedical signals measurements is hum noise activity due to power line interference. Various approaches to suppress hum noise both analog and digital techniques have been proposed. However, these approaches have some disadvantages. N-path notch filter can be an alternative solution for this problem. The notch depth in a conventional N-path notch filter is limited by the number of paths to achieve deeper notch. This paper proposes a new N-path notch filter with additional sample-and-hold (S\/H) and leak buffer circuits to improve notch depth. Simulation and measurement results of 3-phase N-path filter achieve notch depth of 61.6dB and 54.5dB respectively. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of a critical problem in the biomedical signals measurements is hum noise activity due to power line interference. Various approaches to suppress hum noise both analog and digital techniques have been proposed. However, these approaches have some disadvantages. N-path notch filter can be an alternative solution for this problem. The notch depth in a conventional N-path notch filter is limited by the number of paths to achieve deeper notch. This paper proposes a new N-path notch filter with additional sample-and-hold (S\/H) and leak buffer circuits to improve notch depth. Simulation and measurement results of 3-phase N-path filter achieve notch depth of 61.6dB and 54.5dB respectively. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Design and implementation of fire detection system using fuzzy logic algorithm"
        ],
        "penulis":"Surya Devi, Anak Agung Putu Bunga;Istikmal;Karna, Nyoman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One of the features of a smart home is fire detection. There have been many developments in previous studies, but not many have implemented a detection system with the fuzzy logic method. Therefore, in this research we have developed a fire detection system that applies fuzzy logic methods and algorithms. We used Raspberry pi 3 as the embedded system, DHT-11 and MQ-2 sensors to detect fires. Detection results will be processed using a fuzzy system and the results will be notified through the WhatsApp application and monitored through the web. The test results show that the system that has been developed is running well and can be used as a fire detection system in smart homes. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the features of a smart home is fire detection. There have been many developments in previous studies, but not many have implemented a detection system with the fuzzy logic method. Therefore, in this research we have developed a fire detection system that applies fuzzy logic methods and algorithms. We used Raspberry pi 3 as the embedded system, DHT-11 and MQ-2 sensors to detect fires. Detection results will be processed using a fuzzy system and the results will be notified through the WhatsApp application and monitored through the web. The test results show that the system that has been developed is running well and can be used as a fire detection system in smart homes. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Anchor placement design for a decoupled simple trilateration algorithm"
        ],
        "penulis":"Lee, Sang C.;Rizal, Syamsul;Ahn, Heungju;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Localization is one of the main issues in wireless sensor networks (WSNs). By deploying anchor nodes, the sensor node location can be estimated. Generally, three anchor node positions should be fixed and known so that it becomes possible to estimate other sensor nodes by using a trilateration technique. This paper investigated a mobile anchor node for a real-time local positioning system (RT-LPS). The target position could be calculated directly without a limitation of the coverage area, because three anchor nodes have been equipped on the mobile robot. The proposed method involves the design of three anchors at a specific right-angled triangle position to simplify the calculation of position information. A simple equation is proposed for calculating the target position. The measurement distances between the anchor and the target node are collected by using the time-of-arrival (ToA) method. The simulation results are compared in terms of the position error with the equilateral triangle method. \u00a9 Copyright 2019",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Localization is one of the main issues in wireless sensor networks (WSNs). By deploying anchor nodes, the sensor node location can be estimated. Generally, three anchor node positions should be fixed and known so that it becomes possible to estimate other sensor nodes by using a trilateration technique. This paper investigated a mobile anchor node for a real-time local positioning system (RT-LPS). The target position could be calculated directly without a limitation of the coverage area, because three anchor nodes have been equipped on the mobile robot. The proposed method involves the design of three anchors at a specific right-angled triangle position to simplify the calculation of position information. A simple equation is proposed for calculating the target position. The measurement distances between the anchor and the target node are collected by using the time-of-arrival (ToA) method. The simulation results are compared in terms of the position error with the equilateral triangle method. \u00a9 Copyright 2019"
        ]
    },
    {
        "judul":[
            "Analyzing tourism mobile applications perceived quality using sentiment analysis and topic modeling"
        ],
        "penulis":"Masrury, Riefvan Achmad;Fannisa;Alamsyah, Andry;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Mobile application is one of the most important information platforms for international tourists. Millions of tourists use mobile applications to find information and make transactions. Two popular Online Travel Agent (OTA) mobile applications for travel-related activities providers are Traveloka and Tiket.com. These applications certainly must meet travelers' needs to achieve satisfaction. Such satisfaction related to application Mobile Application Service Quality (MappSql) dimensions can be traced from thousands of their comments on the Google Play Store. From a set of reviews, information about the perception of mobile application quality can be obtained. Knowledge on user perceptions is very useful for company's consideration in creating effective business and app features to increase users' satisfaction. We propose Text Mining models to bring up hidden information regarding users' verdict. The selected text analysis methods for this research are Sentiment Analysis and Topic Modeling. We find that positive or negative sentiments towards MappSql dimensions of online travel agent applications qualities can be revealed using sentiment analysis method. Topic Modeling method is used to bring up groups of important words of topics related to each mobile application service quality dimensions. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mobile application is one of the most important information platforms for international tourists. Millions of tourists use mobile applications to find information and make transactions. Two popular Online Travel Agent (OTA) mobile applications for travel-related activities providers are Traveloka and Tiket.com. These applications certainly must meet travelers' needs to achieve satisfaction. Such satisfaction related to application Mobile Application Service Quality (MappSql) dimensions can be traced from thousands of their comments on the Google Play Store. From a set of reviews, information about the perception of mobile application quality can be obtained. Knowledge on user perceptions is very useful for company's consideration in creating effective business and app features to increase users' satisfaction. We propose Text Mining models to bring up hidden information regarding users' verdict. The selected text analysis methods for this research are Sentiment Analysis and Topic Modeling. We find that positive or negative sentiments towards MappSql dimensions of online travel agent applications qualities can be revealed using sentiment analysis method. Topic Modeling method is used to bring up groups of important words of topics related to each mobile application service quality dimensions. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Generalized linear model multivariate poisson with artificial marginal (GLM-MPAM): Application of vehicle insurance"
        ],
        "penulis":"Jamilatuzzahro;Caraka, Rezzy Eko;Aprinaldy, Dedi;Mahadi, Asma;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At vehicle insurance companies, the determination of the appropriate pure premium will make the business run well. In this study, we were modeling claims frequency data by considering the characteristics of policyholder such as policyholder's age, marital status, sex, car engine capacity, and age. The data used in this study is a non-motor vehicle and non-truck motor vehicle insurance data, which filed claims during 2013 in a general insurance company. Explaining the significance or value of the research. We are using Generalized Linear Model Multivariate Poisson with Artificial Marginal (GLM-MPAM) to estimate model parameters. The parameter values of this model are estimated using the Maximum Likelihood Estimation method. Furthermore, the estimation result of the parameter can be alternative in the calculation of the pure premium in the next period. \u00a9 2019 Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At vehicle insurance companies, the determination of the appropriate pure premium will make the business run well. In this study, we were modeling claims frequency data by considering the characteristics of policyholder such as policyholder's age, marital status, sex, car engine capacity, and age. The data used in this study is a non-motor vehicle and non-truck motor vehicle insurance data, which filed claims during 2013 in a general insurance company. Explaining the significance or value of the research. We are using Generalized Linear Model Multivariate Poisson with Artificial Marginal (GLM-MPAM) to estimate model parameters. The parameter values of this model are estimated using the Maximum Likelihood Estimation method. Furthermore, the estimation result of the parameter can be alternative in the calculation of the pure premium in the next period. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Experimental study of load balancing on software defined network using ant-colony optimization"
        ],
        "penulis":"Mulya, Faizal;Purboyo, Tito Waluyo;Latuconsina, Roswan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of technology on internet networks is rapidly continues to grow. This development also had an impact on the server because the server had difficulty in distributing request. To meet internet needs, the technique that can be used is load balancing. Load balancing is a technique to use two or more internet connection lines and balance the request between the two internet connection lines. In this research, the main problem to be discussed is a load balancing simulation using ant colony optimization mechanism. Our experiment show that throughput value by using the ant colony optimization algorithm has a greater throughput value than the round-robin algorithm. Also, we found that ant colony optimization algorithm is more balanced because it has a difference CPU utilization lower than Round-Robin. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by"
        ],
        "abstrak":[
            "The development of technology on internet networks is rapidly continues to grow. This development also had an impact on the server because the server had difficulty in distributing request. To meet internet needs, the technique that can be used is load balancing. Load balancing is a technique to use two or more internet connection lines and balance the request between the two internet connection lines. In this research, the main problem to be discussed is a load balancing simulation using ant colony optimization mechanism. Our experiment show that throughput value by using the ant colony optimization algorithm has a greater throughput value than the round-robin algorithm. Also, we found that ant colony optimization algorithm is more balanced because it has a difference CPU utilization lower than Round-Robin. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Why Telco companies in Indonesia using social media monitoring as a way to handle feedback?"
        ],
        "penulis":"Lestari, Martha Tri;Suryana, Asep;Mulyana, Slamet;Hidayat, Mien;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Developments within industrial technology has currently become one of the phenomenon's in causing industries to use social media monitoring in handling feedback. People who work within an industry, have similar aims and purpose of the aforementioned industry, in which is usually related with the industry's vision and mission. \"Both practitioners and academics agree that the social revolution occurring through digital channels will have a profound impact on how people interact with each other and how companies manage their relationships in the changing communications landscape (Greenberg, 2010;Kletzmann et al.,2011;Dennis et al.,2009)\" (Journal of Business & Industrial Marketing, Vol. 30). Within this study, Telco Industries in Indonesia have been chosen to be the subject of research. The researcher chose several Telco industries that meets the criteria in accordance to the qualification standards and needs previously set by the researcher itself. Such a matter has become very interesting - especially in the digital era, as companies have transformed from using conventional methods in handling feedback to currently digital handling feedbacks by using social media monitoring. The research method used, includes a literature study. The data used within the results of this study, comes in the form of data collection obtained from media releases, websites, and several literatures such as journals and books. Results that are obtained from this research, includes an analysis regarding to why and how industries use as well as utilize social media monitoring to handle feedback. \u00a9 2019, Library Philosophy and Practice.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Developments within industrial technology has currently become one of the phenomenon's in causing industries to use social media monitoring in handling feedback. People who work within an industry, have similar aims and purpose of the aforementioned industry, in which is usually related with the industry's vision and mission. \"Both practitioners and academics agree that the social revolution occurring through digital channels will have a profound impact on how people interact with each other and how companies manage their relationships in the changing communications landscape (Greenberg, 2010;Kletzmann et al.,2011;Dennis et al.,2009)\" (Journal of Business & Industrial Marketing, Vol. 30). Within this study, Telco Industries in Indonesia have been chosen to be the subject of research. The researcher chose several Telco industries that meets the criteria in accordance to the qualification standards and needs previously set by the researcher itself. Such a matter has become very interesting - especially in the digital era, as companies have transformed from using conventional methods in handling feedback to currently digital handling feedbacks by using social media monitoring. The research method used, includes a literature study. The data used within the results of this study, comes in the form of data collection obtained from media releases, websites, and several literatures such as journals and books. Results that are obtained from this research, includes an analysis regarding to why and how industries use as well as utilize social media monitoring to handle feedback. \u00a9 2019, Library Philosophy and Practice."
        ]
    },
    {
        "judul":[
            "Applying deep learning models to action recognition of swimming mice with the scarcity of training data"
        ],
        "penulis":"Nguyen, Ngoc Giang;Delimayanti, Mera Kartika;Purnama, Bedy;Mahmudah, Kunti Robiatul;Kubo, Mamoru;Kakikawa, Makiko;Yamada, Yoichi;Satou, Kenji;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Deep learning models have shown their ability to model complicated problems in more efficient ways than other machine learning techniques in many application fields. For human action recognition tasks, the current state-of-the-art models are deep learning models. But they are not well-studied in applying for animal behaviour recognition due to the lack of data required for training these models. Therefore, in this research, we proposed a method to apply deep learning models to recognize the behaviours of a swimming mouse in two mouse forced swim tests with a limited amount of training data. We used deep learning models which are used in human action recognition tasks and fine-tuned them on the largest publicly available mouse behaviour dataset to give the models the knowledge about mouse behaviour recognition tasks. Then we fine-tuned the models one more time using the small amount of data that we have annotated for our swimming mouse behaviour recognition tasks. The good performance of these models in the new tasks proved the efficiency of our approach. \u00a9 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Deep learning models have shown their ability to model complicated problems in more efficient ways than other machine learning techniques in many application fields. For human action recognition tasks, the current state-of-the-art models are deep learning models. But they are not well-studied in applying for animal behaviour recognition due to the lack of data required for training these models. Therefore, in this research, we proposed a method to apply deep learning models to recognize the behaviours of a swimming mouse in two mouse forced swim tests with a limited amount of training data. We used deep learning models which are used in human action recognition tasks and fine-tuned them on the largest publicly available mouse behaviour dataset to give the models the knowledge about mouse behaviour recognition tasks. Then we fine-tuned the models one more time using the small amount of data that we have annotated for our swimming mouse behaviour recognition tasks. The good performance of these models in the new tasks proved the efficiency of our approach. \u00a9 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved."
        ]
    },
    {
        "judul":[
            "Teacher: Dedication work"
        ],
        "penulis":"Bendriyanti, Rita Prima;Dewi, Citra;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The dedication of a teacher work reflects how a person is committed and taking seriously any work or activity in the institute carried out with full responsibility that the maximum height of the attitude of loyalty, obedience, obedience, and loyalty. the schools they manage are able to be controlled and overcome every problem that is there in order to grow and grow his career in the future. It means that there is feedback that supports each aspect of education. The aims of this study to find out the teacher\u201ds dedication in Bengkulu. The method of this research is survey. The data were collected by using questionnaire. It can be concluded that the dedication work of the teacher in Senior High School of Bengkulu are in the medium level. The result indicated that the teachers have dedication to become professional teachers. From the result, it implicates towards the professionality of their works. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The dedication of a teacher work reflects how a person is committed and taking seriously any work or activity in the institute carried out with full responsibility that the maximum height of the attitude of loyalty, obedience, obedience, and loyalty. the schools they manage are able to be controlled and overcome every problem that is there in order to grow and grow his career in the future. It means that there is feedback that supports each aspect of education. The aims of this study to find out the teacher\u201ds dedication in Bengkulu. The method of this research is survey. The data were collected by using questionnaire. It can be concluded that the dedication work of the teacher in Senior High School of Bengkulu are in the medium level. The result indicated that the teachers have dedication to become professional teachers. From the result, it implicates towards the professionality of their works. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "Gap analysis of Indonesian state-owned bank internet banking website"
        ],
        "penulis":"Pradana, Mahir;Wahyuddin S.;Syarifuddin, Syarifuddin;Putra, Adrianza;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aimed to describe the level of quality perceived by internet banking customers of a state-owned bank in Indonesia. We use Website Quality (WebQual) theory for this research. By analyzing usability, information quality, and service interaction of the internet banking website, we then interpret the result with Gap Analysis method. With the participation of 100 respondents collected from all over Indonesia, we found that there are value gaps between the actual quality (performance) and ideal quality (importance). \u00a9 2019, IEOM Society International.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aimed to describe the level of quality perceived by internet banking customers of a state-owned bank in Indonesia. We use Website Quality (WebQual) theory for this research. By analyzing usability, information quality, and service interaction of the internet banking website, we then interpret the result with Gap Analysis method. With the participation of 100 respondents collected from all over Indonesia, we found that there are value gaps between the actual quality (performance) and ideal quality (importance). \u00a9 2019, IEOM Society International."
        ]
    },
    {
        "judul":[
            "Application of Transfer Learning Using Convolutional Neural Network Method for Early Detection of Terry's Nail"
        ],
        "penulis":"Yani, Muhamad;Irawan, Budhi;Setiningsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nails are one part of the fingers and toes, by observing the shape and the condition of the nails, health expert can find out information about a person's health. However, this sometimes not realized and ignored by society, even though many diseases that can be seen through the condition of the nails and the shape of the nails are one of the systemic diseases. This research was conducted to detect abnormalities in the nail based on digital images. The detected abnormalities are terry's nails in the hand which can represent systemic diseases, while the method used is the Convolutional Neural Network (CNN) method. This research uses Tensorflow Inception-V3 architecture model with the transfer learning method where the results of the experiments that have been done are obtained with 95.24% accuracy. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nails are one part of the fingers and toes, by observing the shape and the condition of the nails, health expert can find out information about a person's health. However, this sometimes not realized and ignored by society, even though many diseases that can be seen through the condition of the nails and the shape of the nails are one of the systemic diseases. This research was conducted to detect abnormalities in the nail based on digital images. The detected abnormalities are terry's nails in the hand which can represent systemic diseases, while the method used is the Convolutional Neural Network (CNN) method. This research uses Tensorflow Inception-V3 architecture model with the transfer learning method where the results of the experiments that have been done are obtained with 95.24% accuracy. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Optimized bio-inspired kernels with twin support vector machine using low identity sequences to solve imbalance multiclass classification"
        ],
        "penulis":"Guramand S.K.;Saedudin R.D.R.;Hassan R.;Kasim S.;Ramlan R.;Salim B.W.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The function of enzymes is performed differently depending on their bio-chemical mechanisms and important to the prediction of protein structure and function. In order to overcome the weaknesses of imbalance data distribution in subclasses prediction we proposed Bio-Twin Support Vector Machine (Bio-TWSVM). The TWSVM approach as also allow for kernel optimization where in this study we have introduced the bio-inspired kernels such as the Fisher, spectrum and mismatch kernels which at the same time incorporate the biological information regarding the protein evolution in the classification process. \u00a9 2019 Triveni Enterprises.",
            "OView detailsExpand Substance diphenylcyclopropenone",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The function of enzymes is performed differently depending on their bio-chemical mechanisms and important to the prediction of protein structure and function. In order to overcome the weaknesses of imbalance data distribution in subclasses prediction we proposed Bio-Twin Support Vector Machine (Bio-TWSVM). The TWSVM approach as also allow for kernel optimization where in this study we have introduced the bio-inspired kernels such as the Fisher, spectrum and mismatch kernels which at the same time incorporate the biological information regarding the protein evolution in the classification process. \u00a9 2019 Triveni Enterprises."
        ]
    },
    {
        "judul":[
            "Development of the Electronic Power Subsystem Design for Tel-USat"
        ],
        "penulis":"Kimura, Shinji Aulia;Wijanto, Heroe;Edwar;Arribat Rafsanzani, Fasny Fauzan;Prananditiya, Haris;Ichwan, Abdul Azis;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Every nanosatellite, including Tel-Usat which is currently developed by Telkom University, needs power resource to carry out its mission. Thus, a subsystem called Electrical Power System (EPS) is usually given a task to harvest and manage the power resource. One of the problems in the EPS subsystem is the design so it can work properly and effectively to convert the energy from sunlight into electric power. In this paper, two design of EPS has been done and investigated. Both design use two different concept where the model one using a pair of series SPV1040 charger module at the solar cell input while model 2 only uses single LT3652 charger module at the same point. The result shows that EPS model 2 has a better performance in charging or discharging capability although the circuit is more complex than the EPS model 1. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Every nanosatellite, including Tel-Usat which is currently developed by Telkom University, needs power resource to carry out its mission. Thus, a subsystem called Electrical Power System (EPS) is usually given a task to harvest and manage the power resource. One of the problems in the EPS subsystem is the design so it can work properly and effectively to convert the energy from sunlight into electric power. In this paper, two design of EPS has been done and investigated. Both design use two different concept where the model one using a pair of series SPV1040 charger module at the solar cell input while model 2 only uses single LT3652 charger module at the same point. The result shows that EPS model 2 has a better performance in charging or discharging capability although the circuit is more complex than the EPS model 1. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "User Interface Modelling of Sundanese Culture Introduction for Deaf Youth using User-Centered Design Method"
        ],
        "penulis":"Ulya, Andini Hanifah;Effendy, Veronikha;Junaedi, Danang;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Culture is a heritage that needs to be preserved and passed on to future generations. Cultural preservation has to be held for everyone without exception even for a person with disability, such as the deaf. Now education can not only be done using traditional way such as books, but it can be done using an application on a smartphone. The use of smartphone could make the process of education to be more efficient and effective. However not every user interfaces (UI) could meet the needs and limitations for the deaf. As with the sample of the existing application that already tested with USE Questionnaire, it still has low usability value. Therefore to design a user interface that meets the users' need, we implemented the user-centered design (UCD) to this research. The prototype was measured its usability by using USE Questionnaire method. The usability testing result showed that the value is 82.75%. This score shows that the design of the user interface already has a usability value with an excellent category, and it also could be said that the user interface has met the user's needs. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Culture is a heritage that needs to be preserved and passed on to future generations. Cultural preservation has to be held for everyone without exception even for a person with disability, such as the deaf. Now education can not only be done using traditional way such as books, but it can be done using an application on a smartphone. The use of smartphone could make the process of education to be more efficient and effective. However not every user interfaces (UI) could meet the needs and limitations for the deaf. As with the sample of the existing application that already tested with USE Questionnaire, it still has low usability value. Therefore to design a user interface that meets the users' need, we implemented the user-centered design (UCD) to this research. The prototype was measured its usability by using USE Questionnaire method. The usability testing result showed that the value is 82.75%. This score shows that the design of the user interface already has a usability value with an excellent category, and it also could be said that the user interface has met the user's needs. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "An elliptical slot loaded planar monopole antenna with tapered feed line and spline cut ground plane for super-wideband applications"
        ],
        "penulis":"Prasetyo, Agus D.;Syihabuddin, Budi;Hanuranto, Ahmad T.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, a super-wideband (SWB) planar antenna that is using the elliptical shape as a patch is presented. The elliptical patch is loaded with an elliptical slot and fed by 50 tapered feed line. A spline cut ground plane is also implemented to get the SWB response. The proposed antenna has been studied and optimized at 1-50 GHz with return loss \u2264-10 dB. The optimized size of the antenna is 44.45 mm \u00d7 46.69 mm \u00d7 1.57 mm, and it can maintain the specified return loss starting from 1.576 GHz to above 50 GHz. The gains are simulated in 5 frequencies, i.e., 5 GHz, 16.25 GHz, 27.5 GHz, 38.75 GHz, and 50 GHz. In sequence, the gain of the antenna is 2.37 dBi, 4.72 dBi, 5.89 dBi, 7.68 dBi, and 7.94 dBi. Then, the observation of the bandwidth is extended up to 140 GHz. As the results, this antenna still works on the specified return loss, and it has a bandwidth ratio higher than 88.8:1, a bandwidth percentage greater than 195.6%, and the BDR index greater than 3566. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, a super-wideband (SWB) planar antenna that is using the elliptical shape as a patch is presented. The elliptical patch is loaded with an elliptical slot and fed by 50 tapered feed line. A spline cut ground plane is also implemented to get the SWB response. The proposed antenna has been studied and optimized at 1-50 GHz with return loss \u2264-10 dB. The optimized size of the antenna is 44.45 mm \u00d7 46.69 mm \u00d7 1.57 mm, and it can maintain the specified return loss starting from 1.576 GHz to above 50 GHz. The gains are simulated in 5 frequencies, i.e., 5 GHz, 16.25 GHz, 27.5 GHz, 38.75 GHz, and 50 GHz. In sequence, the gain of the antenna is 2.37 dBi, 4.72 dBi, 5.89 dBi, 7.68 dBi, and 7.94 dBi. Then, the observation of the bandwidth is extended up to 140 GHz. As the results, this antenna still works on the specified return loss, and it has a bandwidth ratio higher than 88.8:1, a bandwidth percentage greater than 195.6%, and the BDR index greater than 3566. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The spillover effects of University to Business Growth: Evidence from Malaysia"
        ],
        "penulis":"Muhamad, Suriyani;Kusairi, Suhal;Ab Manah, Siti Khatijah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Higher education institutions (HEI) or universities are known as knowledge and learning centres that produce skilled human capital, educate productive workers and entrepreneurs. Their functions have changed with current demands of society, making significant their role in stimulating and sustaining economic growth. However, there are few studies that investigate the effects of the establishment of universities to cater for and address local economic development. This study aims to examine the spill over effects of universities in nurturing local business activities. With regards to universities, the study explores the (i) stakeholders' spending impact; faculty, staff, student and visitors; (ii) human capital impact and; (iii) knowledge and exploration impact of business growth. Using a Structural Equation Model (SEM), the research applies multistage sampling to survey 445 university stakeholders involving alumni, community and industry from three universities; (i) University of Technology Malaysia (UTM); (ii) Universiti Utara Malaysia (UUM) and; (iii) Universiti Malaysia Terengganu (UMT). The findings show that university expenditure, human capital and knowledge exploration positively influence local business growth. This affirms a positive spill-over effects of universities to regional business growth. Hence, the findings of the research suggest that the positive roles of universities to the local economic development need to be given a priority by related stakeholders. \u00a9 2019, Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Higher education institutions (HEI) or universities are known as knowledge and learning centres that produce skilled human capital, educate productive workers and entrepreneurs. Their functions have changed with current demands of society, making significant their role in stimulating and sustaining economic growth. However, there are few studies that investigate the effects of the establishment of universities to cater for and address local economic development. This study aims to examine the spill over effects of universities in nurturing local business activities. With regards to universities, the study explores the (i) stakeholders' spending impact; faculty, staff, student and visitors; (ii) human capital impact and; (iii) knowledge and exploration impact of business growth. Using a Structural Equation Model (SEM), the research applies multistage sampling to survey 445 university stakeholders involving alumni, community and industry from three universities; (i) University of Technology Malaysia (UTM); (ii) Universiti Utara Malaysia (UUM) and; (iii) Universiti Malaysia Terengganu (UMT). The findings show that university expenditure, human capital and knowledge exploration positively influence local business growth. This affirms a positive spill-over effects of universities to regional business growth. Hence, the findings of the research suggest that the positive roles of universities to the local economic development need to be given a priority by related stakeholders. \u00a9 2019, Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Design of the research problem statement"
        ],
        "penulis":"Nasution, Mahyuddin K.M.;Onrizal;Aulia, Indra;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper aims to provide an understanding of designing a problem statement that must be present in every research proposal or other scientific work. A study, from proposals to scientific papers, requires a problem statement. The design of the program statement is basically always present from research interests. Objectives as a translation of the problem statement will be described through a methodology that matches the answers to be given to the interests. In the industry 4.0 era, problem statement in research prioritize innovation or change to improve welfare. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper aims to provide an understanding of designing a problem statement that must be present in every research proposal or other scientific work. A study, from proposals to scientific papers, requires a problem statement. The design of the program statement is basically always present from research interests. Objectives as a translation of the problem statement will be described through a methodology that matches the answers to be given to the interests. In the industry 4.0 era, problem statement in research prioritize innovation or change to improve welfare. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Means of Engagement (MOE) Model of the Agreement towards the Enterprise Resource Planning (ERP) Implementation"
        ],
        "penulis":"Syafiera, Tsara;Lubis, Muharman;Witjaksono, R. Wahjoe;Anggana, Hilman Dwi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Faster economic development led to increasingly tight business competition. With the development of increasingly sophisticated technology, these companies compete in leveraging technology to enhance competitive advantage and efficiency of their company's performance compared to its competitors. ERP systems are already commonly used in large companies and companies that develop because it is considered can improve performance and can help the process efficiency of data each process in system performance for flow can be connected. ERP system implementation is not always running smoothly. When the company failed to perform some of the success factors of ERP implementation, then these companies will experience failure in implementation. Companies must have a good strategy to achieve the desired success. Business strategy is done by optimizing the company's internal resources and innovate to face competition with other companies. By applying an ERP system can help companies to keep up with changes in the business that would later show up to the new business requirements. By using the Means of Engagement (MOE) model concept, the company can know the things to be aware of and consider implementing ERP software, so that it can minimize the failures that will occur. There are three levels in the MOE model, namely Adoption, Approval, Acceptance, and Agreement. At the level of Agreement that can be used by the analysis of clustering. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Faster economic development led to increasingly tight business competition. With the development of increasingly sophisticated technology, these companies compete in leveraging technology to enhance competitive advantage and efficiency of their company's performance compared to its competitors. ERP systems are already commonly used in large companies and companies that develop because it is considered can improve performance and can help the process efficiency of data each process in system performance for flow can be connected. ERP system implementation is not always running smoothly. When the company failed to perform some of the success factors of ERP implementation, then these companies will experience failure in implementation. Companies must have a good strategy to achieve the desired success. Business strategy is done by optimizing the company's internal resources and innovate to face competition with other companies. By applying an ERP system can help companies to keep up with changes in the business that would later show up to the new business requirements. By using the Means of Engagement (MOE) model concept, the company can know the things to be aware of and consider implementing ERP software, so that it can minimize the failures that will occur. There are three levels in the MOE model, namely Adoption, Approval, Acceptance, and Agreement. At the level of Agreement that can be used by the analysis of clustering. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The effect of cache partitioning and sharing on named data network"
        ],
        "penulis":"Yovita, Leanna Vidya;Syambas, Nana Rachmana;Edward, Ian Yosef Matheus;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The IP network is inefficient to support data communication. The IP network modifications into a Content Distribution Network scheme can not accommodate consumer mobility and consumer demand patterns that is change dynamically. So that, Named Data Network has been proposed to focus on content for data communications. The Named Data Network router comes with a content store for storing data. The content store size is limited so special techniques are required to optimize content store usage and keep NDN performance in good level. In the previous study, the majority choose data to be stored in content stores based on content popularity only. Popular data will be prioritized to keep in content store and the data with less popularity will be deleted from content store when it is full. This basic technique is known as 'sharing-technique'. Sharing-technique is difficult to differentiate the treatment of the data with more than one classification requirement. In fact, it is needed to differentiate the treatment for different requirements classes, not only the content priority. In this research, simulation is conducted to analyze the influence of content storage policy with sharing-techniques and partitioning-techniques. The partitioning- technique accommodates data storage that considers to the different class of content and also popularity of the content. The results of the simulation show that partitioning-technique gives maximum 36% more cache hit ratio than sharing-technique, viewed in network level. Partitioning-technique allows flexibility of class-based settings for content based on the proportion of content store, while in the sharing-technique the difference in cache hit rate for content classes is not significant. \u00a9 2019 Internetworking Indonesia.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The IP network is inefficient to support data communication. The IP network modifications into a Content Distribution Network scheme can not accommodate consumer mobility and consumer demand patterns that is change dynamically. So that, Named Data Network has been proposed to focus on content for data communications. The Named Data Network router comes with a content store for storing data. The content store size is limited so special techniques are required to optimize content store usage and keep NDN performance in good level. In the previous study, the majority choose data to be stored in content stores based on content popularity only. Popular data will be prioritized to keep in content store and the data with less popularity will be deleted from content store when it is full. This basic technique is known as 'sharing-technique'. Sharing-technique is difficult to differentiate the treatment of the data with more than one classification requirement. In fact, it is needed to differentiate the treatment for different requirements classes, not only the content priority. In this research, simulation is conducted to analyze the influence of content storage policy with sharing-techniques and partitioning-techniques. The partitioning- technique accommodates data storage that considers to the different class of content and also popularity of the content. The results of the simulation show that partitioning-technique gives maximum 36% more cache hit ratio than sharing-technique, viewed in network level. Partitioning-technique allows flexibility of class-based settings for content based on the proportion of content store, while in the sharing-technique the difference in cache hit rate for content classes is not significant. \u00a9 2019 Internetworking Indonesia."
        ]
    },
    {
        "judul":[
            "Sustainable development of Tasik Kenyir eco-tourism using system dynamic"
        ],
        "penulis":"Lola, Muhamad Safiih;Ramlee, Mohd Noor Afiq;Hussin, Mohd Fadli;Abdullah, Mohd Tajuddin;Kamil, Anton Abdulbasah;Mohamad Yusof, Izham;Ibrahim, Yahaya;Khadar, Nur Zafirah A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The sustainable development of Tasik Kenyir eco-tourism depends on the availibility of spatially explicit information on the state and trends of ecosystems and their services. Thus, we develop an interactive dynamic model of Tasik Kenyir Eco-Tourism that links ecological and economic systems, and generated the effects of the short and long terms besides to determine the direction of development and conservation in Tasik Kenyir development policies. In this study, Tasik Kenyir eco-tourism coins Macro Management Framework for Tasik Kenyir Tourism Dynamics consist of four different subsystem; Toursim Activity, Development of Tasik Kenyir (infrastucture and tourism activities), Waste Generated and Environment Sustainability (flora and fauna). The Model developed reveals that sustainable development of Tasik Kenyir eco-tourism requires continuous prolonged effort and insight towards creating a balance between social, economic and environmental developments. \u00a9 Springer Nature Switzerland AG 2019.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The sustainable development of Tasik Kenyir eco-tourism depends on the availibility of spatially explicit information on the state and trends of ecosystems and their services. Thus, we develop an interactive dynamic model of Tasik Kenyir Eco-Tourism that links ecological and economic systems, and generated the effects of the short and long terms besides to determine the direction of development and conservation in Tasik Kenyir development policies. In this study, Tasik Kenyir eco-tourism coins Macro Management Framework for Tasik Kenyir Tourism Dynamics consist of four different subsystem; Toursim Activity, Development of Tasik Kenyir (infrastucture and tourism activities), Waste Generated and Environment Sustainability (flora and fauna). The Model developed reveals that sustainable development of Tasik Kenyir eco-tourism requires continuous prolonged effort and insight towards creating a balance between social, economic and environmental developments. \u00a9 Springer Nature Switzerland AG 2019."
        ]
    },
    {
        "judul":[
            "Controlling schedule of fiber to the home (FTTH) project using critical path and crashing method"
        ],
        "penulis":"Augyhana, Catur Fajri;Puspita, Ika Arum;Tripiawan, Wawan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research is about the project of FTTH in Bandung, West Java. One of The FTTH projects that located in Padalarang, West Java has been identified that the project was delayed by 7.8% on day 11th. This delay happened because there's some lack of managerial project in implementation, controlling, and monitoring project work during the execution. The aim of this research is to monitor and control the project by analyzing actual project performance using Earn Value Method (EVM) approach. The compression schedule is performed using Crashing Program on the activities that are critical, which has been identified before through Critical Path Method (CPM). The result of this research is to make the project will be completed in 23 days, the same amount of days according to the initial target planning even though on the 11th day the project is delayed. It is found that the activity of cable distribution could be accelerated from 4 days to 2 days by adding 4 workers and the cost slope is Rp465.224. While on the activity of installation ODP and Splitter could be accelerated from 3 days into 2 days with cost slope of Rp332.533 and the amount of additional work required is 1 person who is an expert technician\/jointer. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research is about the project of FTTH in Bandung, West Java. One of The FTTH projects that located in Padalarang, West Java has been identified that the project was delayed by 7.8% on day 11th. This delay happened because there's some lack of managerial project in implementation, controlling, and monitoring project work during the execution. The aim of this research is to monitor and control the project by analyzing actual project performance using Earn Value Method (EVM) approach. The compression schedule is performed using Crashing Program on the activities that are critical, which has been identified before through Critical Path Method (CPM). The result of this research is to make the project will be completed in 23 days, the same amount of days according to the initial target planning even though on the 11th day the project is delayed. It is found that the activity of cable distribution could be accelerated from 4 days to 2 days by adding 4 workers and the cost slope is Rp465.224. While on the activity of installation ODP and Splitter could be accelerated from 3 days into 2 days with cost slope of Rp332.533 and the amount of additional work required is 1 person who is an expert technician\/jointer. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "A cloud computing separation model based on information flow"
        ],
        "penulis":"Ma, Wei;Li, Huanqin;Witarsyah, Deden;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Separation is the primary consideration in cloud computing security. A series of security and safety problems would arise if a separation mechanism is not deployed appropriately, thus affecting the confidence of cloud end-users. In this paper, together with characteristics of cloud computing, the separation issue in cloud computing has been analyzed from the perspective of information flow. The process of information flow in cloud computing systems is formalized to propose corresponding separation rules. These rules have been verified in this paper and it is shown that the rules conform to non-interference security, thus ensuring the security and practicability of the proposed rules. \u00a9 2019 W. Ma et al., published by De Gruyter 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Separation is the primary consideration in cloud computing security. A series of security and safety problems would arise if a separation mechanism is not deployed appropriately, thus affecting the confidence of cloud end-users. In this paper, together with characteristics of cloud computing, the separation issue in cloud computing has been analyzed from the perspective of information flow. The process of information flow in cloud computing systems is formalized to propose corresponding separation rules. These rules have been verified in this paper and it is shown that the rules conform to non-interference security, thus ensuring the security and practicability of the proposed rules. \u00a9 2019 W. Ma et al., published by De Gruyter 2019."
        ]
    },
    {
        "judul":[
            "Flatbuffers implementation on MQTT publish\/subscribe communication as data delivery format"
        ],
        "penulis":"Pradana, Muhammad Adna;Rakhmatsyah, Andrian;Wardana, Aulia Arif;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Communication between devices can be done in various ways, one of them is the Publish\/Subscribe model that uses the MQTT protocol From the shortcomings that exist in JSON, such as long processing time, Google recently introduced a new data format called Flatbuffers. Flatbuffers has a better data format serialization process than other data formats. This paper will discuss the implementation and testing of the Flatbuffers data format performance compared to other data formats through the MQTT Publish\/Subscribe communication model. Testing is done by measuring the value of payload, latency, and throughput obtained from each data format. The test results show that the Flatbuffers data format is very well used as a data extraction format based on data processing latency of 0.5002 ms and throughput 518.4649 bytes\/ms with payload 0.996108949 character\/byte. \u00a9 2019, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Communication between devices can be done in various ways, one of them is the Publish\/Subscribe model that uses the MQTT protocol From the shortcomings that exist in JSON, such as long processing time, Google recently introduced a new data format called Flatbuffers. Flatbuffers has a better data format serialization process than other data formats. This paper will discuss the implementation and testing of the Flatbuffers data format performance compared to other data formats through the MQTT Publish\/Subscribe communication model. Testing is done by measuring the value of payload, latency, and throughput obtained from each data format. The test results show that the Flatbuffers data format is very well used as a data extraction format based on data processing latency of 0.5002 ms and throughput 518.4649 bytes\/ms with payload 0.996108949 character\/byte. \u00a9 2019, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "ECG based biometric using wavelet packet decomposition"
        ],
        "penulis":"Hadiyoso, Sugondo;Rizal, Achmad;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Biometric technology has been commonly used for authentication. Fingerprint or iris become one of the biometrics that is widely applied. However, this type of biometrics tends to be easily falsified and damaged. So it is misused for manipulating actions and even crime. Therefore a new biometric method is needed to overcome this problem. One potential modality is biometrics based on an electrocardiogram (ECG) signal. This research simulates a one-lead ECG waveform for person authentication. ECG waves were taken from eleven healthy adult volunteers with a length of 60 seconds. ECG waves from each person are segmented into 10 sections so that a total of 110 ECG waves are used for person authentication simulations. All noise of the ECG waves was removed using a bandpass filter to reduce artifacts and high-frequency noise. Wavelet packet decomposition (3 Level) was applied to decompose the signal in several intrinsic parts so that typical wave information can be retrieved. Entropy-based feature extraction applied to all decomposed signals. A total of 14 entropy features have been calculated and used as predictors in the classification process. Validation and performance tests are carried out by cross-validation combined with linear discriminant analysis and support vector machines with five scenarios. The proposed method provides the highest accuracy of 71.8% using discriminant analysis and cubic support vector machine. The best accuracy value was achieved if all entropy features from all wavelet decomposition levels are used as predictors in the classification process. This research is expected to be a reference that ECG has the potential to become a future biometric modality. \u00a9 BEIESP.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Biometric technology has been commonly used for authentication. Fingerprint or iris become one of the biometrics that is widely applied. However, this type of biometrics tends to be easily falsified and damaged. So it is misused for manipulating actions and even crime. Therefore a new biometric method is needed to overcome this problem. One potential modality is biometrics based on an electrocardiogram (ECG) signal. This research simulates a one-lead ECG waveform for person authentication. ECG waves were taken from eleven healthy adult volunteers with a length of 60 seconds. ECG waves from each person are segmented into 10 sections so that a total of 110 ECG waves are used for person authentication simulations. All noise of the ECG waves was removed using a bandpass filter to reduce artifacts and high-frequency noise. Wavelet packet decomposition (3 Level) was applied to decompose the signal in several intrinsic parts so that typical wave information can be retrieved. Entropy-based feature extraction applied to all decomposed signals. A total of 14 entropy features have been calculated and used as predictors in the classification process. Validation and performance tests are carried out by cross-validation combined with linear discriminant analysis and support vector machines with five scenarios. The proposed method provides the highest accuracy of 71.8% using discriminant analysis and cubic support vector machine. The best accuracy value was achieved if all entropy features from all wavelet decomposition levels are used as predictors in the classification process. This research is expected to be a reference that ECG has the potential to become a future biometric modality. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Integrated Subsurface Temperature Modeling beneath Mt. Lawu and Mt. Muriah in the Northeast Java Basin, Indonesia"
        ],
        "penulis":"Nurhandoko, Bagus Endar B.;Kurniadi, Rizal;Susilowati S.;Triyoso, Kaswandhi;Widowati, Sri;Asmara Hadi, M. Rizka;Abda, M. Rizal;Martha, Rio K.;Fatiah, Elfa;Rizal Komara, Insan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The subsurface temperature has many impacts on geological phenomena such as hydrocarbon generation, geothermal energy, mineralization, and geological hazards. The Northeast Java Basin has various interesting phenomena, such as many oil fields, active faults, mud eruptions, and some active and dormant volcanoes. We measured temperature data from tens of wells along a 130 km survey line with an average spacing of 5 km. We also measured the thermal conductivity of rocks of various lithologies along the survey line to provide geothermal heat flow data. We propose integrated modeling for profiling the subsurface temperature beneath the survey line from Mt. Lawu to Mt. Muriah in the Northeast Java Basin. The modeling of subsurface temperature integrates various input data such as a thermal conductivity model, surface temperature, gradient temperature, a geological model, and geothermal heat flow. The thermal conductivity model considers the subsurface geological model. The temperature modeling uses the finite difference of Fourier's law, with an input subsurface thermal conductivity model, geothermal heat flow, and surface temperature. The subsurface temperature profile along with survey line shows some interesting anomalies which correlate with either subsurface volcanic activity or the impact of fault activity. \u00a9 2019 Bagus Endar B. Nurhandoko et al.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Sustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The subsurface temperature has many impacts on geological phenomena such as hydrocarbon generation, geothermal energy, mineralization, and geological hazards. The Northeast Java Basin has various interesting phenomena, such as many oil fields, active faults, mud eruptions, and some active and dormant volcanoes. We measured temperature data from tens of wells along a 130 km survey line with an average spacing of 5 km. We also measured the thermal conductivity of rocks of various lithologies along the survey line to provide geothermal heat flow data. We propose integrated modeling for profiling the subsurface temperature beneath the survey line from Mt. Lawu to Mt. Muriah in the Northeast Java Basin. The modeling of subsurface temperature integrates various input data such as a thermal conductivity model, surface temperature, gradient temperature, a geological model, and geothermal heat flow. The thermal conductivity model considers the subsurface geological model. The temperature modeling uses the finite difference of Fourier's law, with an input subsurface thermal conductivity model, geothermal heat flow, and surface temperature. The subsurface temperature profile along with survey line shows some interesting anomalies which correlate with either subsurface volcanic activity or the impact of fault activity. \u00a9 2019 Bagus Endar B. Nurhandoko et al."
        ]
    },
    {
        "judul":[
            "LTE-advanced network planning using inter-band non-contiguous carrier aggregation technology at soreang-pasir koja highway"
        ],
        "penulis":"Rohmah, Yuyun Siti;Hadiyoso, Sugondo;Prasetya, Budi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Long Term Evolution-Advanced is the development of LTE technology. It can aggregate two or more carrier components to get higher throughput and spectrum efficiency. This paper discussed RF signal quality and the number of sites that is used at Soreang-Pasir Koja highway based on simulation by implementing non-contiguous carrier aggregation with two carrier components. Bandwidth with an aggregated frequency of 15 MHz has been simulated, where the fifth band is the cell that serves the main function and the third band as the cell serving the secondary function. Simulation results showed an increase in RF signal parameters such as RSRP, SINR and throughput. Then, the number of sites can be minimized by applying operator aggregation that is not close to each other. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Long Term Evolution-Advanced is the development of LTE technology. It can aggregate two or more carrier components to get higher throughput and spectrum efficiency. This paper discussed RF signal quality and the number of sites that is used at Soreang-Pasir Koja highway based on simulation by implementing non-contiguous carrier aggregation with two carrier components. Bandwidth with an aggregated frequency of 15 MHz has been simulated, where the fifth band is the cell that serves the main function and the third band as the cell serving the secondary function. Simulation results showed an increase in RF signal parameters such as RSRP, SINR and throughput. Then, the number of sites can be minimized by applying operator aggregation that is not close to each other. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Narrator's name recognition with support vector machine for indexing Indonesian hadith translations"
        ],
        "penulis":"Yusup, Fajar Achmad;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The narrator's name in the Hadith is one of the most important components in determining the validity of a hadith, but with the large number of Hadiths that exist, causing the process of determining the validity of a Hadith manually becomes difficult, especially in the Indonesian Hadith translation. Named Entity Recognition (NER) is a method that aims to find entities in a text document, in this case the entity includes the name of the person, location, organization, etc. This study will discuss the implementation of the Named Entity Recognition to the Indonesian translation of the Hadith collection to find the names of narrators from each Hadith. In this study 200 Hadiths from 9 different books consisting of 31010 tokens and 2241 narrator name entities will be used as datasets. Because of the variety of entity forms and the amount of data used, this study will use a supervised-learning approach, and to maximize performance from the NER system, Support Vector Machine (SVM) is chosen as a classifier model that is known to have good generalization capabilities in classifying data and ability to deal with high-dimensional data. Some combinations of test scenarios on the NER model showed the highest F-1 results of 0.9 with training data totaling 140 Hadiths consisting of 1564 entities and testing 60 Hadiths consisting of 677 entities. The narrator name produced by the NER system will then be used as an index of the Hadiths that have been narrated by the narrator using the Inverted Index method. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The narrator's name in the Hadith is one of the most important components in determining the validity of a hadith, but with the large number of Hadiths that exist, causing the process of determining the validity of a Hadith manually becomes difficult, especially in the Indonesian Hadith translation. Named Entity Recognition (NER) is a method that aims to find entities in a text document, in this case the entity includes the name of the person, location, organization, etc. This study will discuss the implementation of the Named Entity Recognition to the Indonesian translation of the Hadith collection to find the names of narrators from each Hadith. In this study 200 Hadiths from 9 different books consisting of 31010 tokens and 2241 narrator name entities will be used as datasets. Because of the variety of entity forms and the amount of data used, this study will use a supervised-learning approach, and to maximize performance from the NER system, Support Vector Machine (SVM) is chosen as a classifier model that is known to have good generalization capabilities in classifying data and ability to deal with high-dimensional data. Some combinations of test scenarios on the NER model showed the highest F-1 results of 0.9 with training data totaling 140 Hadiths consisting of 1564 entities and testing 60 Hadiths consisting of 677 entities. The narrator name produced by the NER system will then be used as an index of the Hadiths that have been narrated by the narrator using the Inverted Index method. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "Risk-return through financial ratios as determinants of stock price: A study from ASEAN region"
        ],
        "penulis":"Jermsittiparsert, Kittisak;Ambarita, Dedy E.;Mihardjo, Leonardus W.W.;Ghani, Erlane K.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The objective of this empirical research is to analyze the risk-return through financial ratios as determinants of stock price in ASEAN region. To address this purpose, business firms from Malaysia, Indonesia, Thailand and Singapore are selected with a sample of 10 firms in each state over 2012 to 2016. Multiple regression technique is applied to analyze the relationship between financial ratios and stock prices. It is observed that current ratio, quick ratio, assets growth, return on assets, return on equity, return on capital employed, and price to earning ratio are significant determinants of stock price. Although this study is a reasonable addition in existing literature of financial ratios as determinants of stock price. However, contribution of the study can be viewed through covering a gap from the context of ASEAN region, which is under reserachers attentions for stock price determinants. Core limitations of the study covers limited number of sample size and five years of time duration. Besides, some ratios are missing which can be reconsidered in upcoming studies. These ratios include debt ratios, interest payment ratios, and fixed cost covered ratios as well. \u00a9 2019, General Jonas Zemaitis Military Academy of Lithuania.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The objective of this empirical research is to analyze the risk-return through financial ratios as determinants of stock price in ASEAN region. To address this purpose, business firms from Malaysia, Indonesia, Thailand and Singapore are selected with a sample of 10 firms in each state over 2012 to 2016. Multiple regression technique is applied to analyze the relationship between financial ratios and stock prices. It is observed that current ratio, quick ratio, assets growth, return on assets, return on equity, return on capital employed, and price to earning ratio are significant determinants of stock price. Although this study is a reasonable addition in existing literature of financial ratios as determinants of stock price. However, contribution of the study can be viewed through covering a gap from the context of ASEAN region, which is under reserachers attentions for stock price determinants. Core limitations of the study covers limited number of sample size and five years of time duration. Besides, some ratios are missing which can be reconsidered in upcoming studies. These ratios include debt ratios, interest payment ratios, and fixed cost covered ratios as well. \u00a9 2019, General Jonas Zemaitis Military Academy of Lithuania."
        ]
    },
    {
        "judul":[
            "Development of Web Stock Opname Application with SAP Business One Using Scrum Method"
        ],
        "penulis":"Ramadhan, Aulia;Lubis, Muharman;Puspitasari, Warih;Lubis, Arif Ridho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "SME Company (Small and Medium Enterprises) is a small-scale business unit, which require to have inventory function as an important asset in the company to ensure the availability of goods and stock within the warehouse process. Thus, an inventory management process calls Stock opname that is carried out to conduct calculation and computation have been established. Previously, majority activity process have been carried out manually in which the employees check and record the available items through reporting them to the managers without using any kind of software whatsoever, only a piece of document that have no integration with other business processes. Therefore, the data that is not processed in the real-time might be different at certain period and unmatched with the real situation can lead to the wrong decision making. Thus, the application should be developed, which in this case utilizing the web application to be integrated with SAP Business One to solve existing problems within the company to provide accurate and real-time inventory information management. It also has objective to maintain updated information with other department, unit or even business modules within the SME companies. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SME Company (Small and Medium Enterprises) is a small-scale business unit, which require to have inventory function as an important asset in the company to ensure the availability of goods and stock within the warehouse process. Thus, an inventory management process calls Stock opname that is carried out to conduct calculation and computation have been established. Previously, majority activity process have been carried out manually in which the employees check and record the available items through reporting them to the managers without using any kind of software whatsoever, only a piece of document that have no integration with other business processes. Therefore, the data that is not processed in the real-time might be different at certain period and unmatched with the real situation can lead to the wrong decision making. Thus, the application should be developed, which in this case utilizing the web application to be integrated with SAP Business One to solve existing problems within the company to provide accurate and real-time inventory information management. It also has objective to maintain updated information with other department, unit or even business modules within the SME companies. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Patient engagement activities with health care professionals in continuous ambulatory peritoneal dialysis therapy: An exploratory pilot study"
        ],
        "penulis":"Darmayanti, Dahlia;Simatupang, Togar M.;Rudito, Priyantono;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Background: This pilot study aimed to explore the engagement activities between patients on continuous ambulatory peritoneal dialysis (CAPD) therapy and their health care professionals. Methods: An exploratory qualitative study was conducted. In-depth semi-structured interviews were undertaken involving four CAPD patients who were selected through purposive sampling. The participants were asked questions about their engagement experiences with their health care professionals. Results: Six main engagement activities were derived from the interview analysis: obtaining initial knowledge, developing knowledge and skills, feeling confident, following clinical advice, updating health condition, and supporting CAPD therapy. Conclusion: Patients engagement activities played an important role in CAPD therapy. The engagement activities covered the cognitive, emotional, and behavioral dimensions. Obtaining initial knowledge as well as developing knowledge and skills are essential engagement activities before patients perform CAPD therapy. \u00a9 2019 Darmayanti et al.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Background: This pilot study aimed to explore the engagement activities between patients on continuous ambulatory peritoneal dialysis (CAPD) therapy and their health care professionals. Methods: An exploratory qualitative study was conducted. In-depth semi-structured interviews were undertaken involving four CAPD patients who were selected through purposive sampling. The participants were asked questions about their engagement experiences with their health care professionals. Results: Six main engagement activities were derived from the interview analysis: obtaining initial knowledge, developing knowledge and skills, feeling confident, following clinical advice, updating health condition, and supporting CAPD therapy. Conclusion: Patients engagement activities played an important role in CAPD therapy. The engagement activities covered the cognitive, emotional, and behavioral dimensions. Obtaining initial knowledge as well as developing knowledge and skills are essential engagement activities before patients perform CAPD therapy. \u00a9 2019 Darmayanti et al."
        ]
    },
    {
        "judul":[
            "A Progress on the Personality Measurement Model using Ontology based on Social Media Text"
        ],
        "penulis":"Alamsyah, Andry;Rachman, Muhammad Fadhli;Hudaya, Cindy Septiani;Putra, Rimba Pratama;Rifkyano, Aulia Ichsan;Nurwianti, Fivi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Personality measurement (PM) has evolved from taking a personality test or expert assessment into utilizing user generated content to measure personality. Several attempts to create a model for PM has been done by the various researcher using English as the main language. While the PM model in Bahasa Indonesia is limited. Further research is required due to the unavailability of PM model in Bahasa Indonesia, lack of corpus to gain high accuracy, and the urgency of automating the measurement process. The progress of PM Ontology model is 1) we are enriching the corpus in Bahasa Indonesia in the ontology model 2) design and prototyping the PM ontology platform using Ruby programming language 3) evaluate the PM ontology model. Our proposed platform offers a fast and affordable tool to analyze large textual data to measures human personality based on big five personality traits. Extensively, the platform is beneficial to have express analysis process and utilized the insight into various areas such as human resources, CRM, marketing or another process that requires personality measurement. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Personality measurement (PM) has evolved from taking a personality test or expert assessment into utilizing user generated content to measure personality. Several attempts to create a model for PM has been done by the various researcher using English as the main language. While the PM model in Bahasa Indonesia is limited. Further research is required due to the unavailability of PM model in Bahasa Indonesia, lack of corpus to gain high accuracy, and the urgency of automating the measurement process. The progress of PM Ontology model is 1) we are enriching the corpus in Bahasa Indonesia in the ontology model 2) design and prototyping the PM ontology platform using Ruby programming language 3) evaluate the PM ontology model. Our proposed platform offers a fast and affordable tool to analyze large textual data to measures human personality based on big five personality traits. Extensively, the platform is beneficial to have express analysis process and utilized the insight into various areas such as human resources, CRM, marketing or another process that requires personality measurement. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Mapping technological trajectories of Crystalline Silicon (c-Si) PV using patent analysis"
        ],
        "penulis":"Mubarok, Muhammad Husni;Nafizah, Ully Yunita;Permana, Muhammad Yorga;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper is the first to identify the technological development of crystalline silicon (c-Si) PV technology by analyzing network patent and main trajectory. The data used is the US granted patent from 1976 until 2010, thus resulted of 1,100 patents data. The network of patent citation data is analysed based on the key network measure (i.e., number of nodes, density, in-degree centrality, and out-degree centrality) and followed by developing the network trajectory. The main path analysis is obtained by using both SPLC method (Search Path Link Count) and the SPNP method (Search Path Nodes Pair). The main path further is analyzed along with its sub-path to understand the evolution of c-Si PV technology. The results indicate that: 1) the c-Si Solar cells technology has very low network density which means the patents are sparsely connected with each other, 2) The connected patents are the representative of the 'new' thin-film solar technology, 3) The most cited patent is not a part the main trajectory, meaning that there is a low correlation between patent and technology development, 4) The US, Japan, and Germany are the main actors in c-Si solar cells technology. US and Germany are identified as key pioneers during the early stage of this technology, while Japan appears at later stages, 5) Siemens is the main actor in the initial c-Si PV technology. \u00a9 2019, International Journal of Renewable Energy Research.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document"
        ],
        "abstrak":[
            "This paper is the first to identify the technological development of crystalline silicon (c-Si) PV technology by analyzing network patent and main trajectory. The data used is the US granted patent from 1976 until 2010, thus resulted of 1,100 patents data. The network of patent citation data is analysed based on the key network measure (i.e., number of nodes, density, in-degree centrality, and out-degree centrality) and followed by developing the network trajectory. The main path analysis is obtained by using both SPLC method (Search Path Link Count) and the SPNP method (Search Path Nodes Pair). The main path further is analyzed along with its sub-path to understand the evolution of c-Si PV technology. The results indicate that: 1) the c-Si Solar cells technology has very low network density which means the patents are sparsely connected with each other, 2) The connected patents are the representative of the 'new' thin-film solar technology, 3) The most cited patent is not a part the main trajectory, meaning that there is a low correlation between patent and technology development, 4) The US, Japan, and Germany are the main actors in c-Si solar cells technology. US and Germany are identified as key pioneers during the early stage of this technology, while Japan appears at later stages, 5) Siemens is the main actor in the initial c-Si PV technology. \u00a9 2019, International Journal of Renewable Energy Research."
        ]
    },
    {
        "judul":[
            "Rainfall forecasting multi kernel support vector regression seasonal autoregressive integrated moving average (MKSVR-SARIMA)"
        ],
        "penulis":"Caraka, Rezzy Eko;Bakar, Sakhinah Abu;Tahmid, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Rainfall variation in the tropics is caused by several factors, such as: geographic, topographical, and orographic. Therefore, the importance of rainfall analysis is needed to know the factors also local characteristics that affect fluctuations in daily rainfall \/ monthly in each particular area. Rainfall is one element of weather that has a vital role in various sectors in Indonesia. In the agriculture sector, rainfall prediction is used to know the schedule prediction of cropping pattern to optimize food crop production result. In the land, sea and air transport sector, the weather factor that rainfall has a role in the level of safety. In this paper, we used daily rainfall data in Manado, North Sulawesi province in January 2017-December 2017. In short, we combined of SARIMA, and Localized Multi Kernel Support Vector Regression (LMKL SVR) with linear kernel and polynomial kernel reached accuracy model R298.76%. On the one hand, after obtained rainfall prediction, we compared with actual rainfall data in January 2018 -February 2018 (59 data). Mainly, Rainfall is difficult to predict even though the model obtained has good accuracy. Still, after validation data forecast and actual data, there is a very far different with RMSE amount 24.43 because the data climate is very dynamic also there are variables that need to be analyzed in building prediction model of rainfall \u00a9 2019 Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rainfall variation in the tropics is caused by several factors, such as: geographic, topographical, and orographic. Therefore, the importance of rainfall analysis is needed to know the factors also local characteristics that affect fluctuations in daily rainfall \/ monthly in each particular area. Rainfall is one element of weather that has a vital role in various sectors in Indonesia. In the agriculture sector, rainfall prediction is used to know the schedule prediction of cropping pattern to optimize food crop production result. In the land, sea and air transport sector, the weather factor that rainfall has a role in the level of safety. In this paper, we used daily rainfall data in Manado, North Sulawesi province in January 2017-December 2017. In short, we combined of SARIMA, and Localized Multi Kernel Support Vector Regression (LMKL SVR) with linear kernel and polynomial kernel reached accuracy model R298.76%. On the one hand, after obtained rainfall prediction, we compared with actual rainfall data in January 2018 -February 2018 (59 data). Mainly, Rainfall is difficult to predict even though the model obtained has good accuracy. Still, after validation data forecast and actual data, there is a very far different with RMSE amount 24.43 because the data climate is very dynamic also there are variables that need to be analyzed in building prediction model of rainfall \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Data processing of laboratory recruitment using K-nearest neighbor algorithm"
        ],
        "penulis":"Mustabshiroh;Latuconsina, Roswan;Purboyo, Tito Waluyo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of science and technology increasingly popular in the society. Computer technology is growing very rapidly according to the level of human needs to solve various of problems. One of the rapid development of computer science is the field of data processing that is capable of processing data and provide information to support decision, one of which is data mining. Data mining helps to extract patterns from large data to be interpreted as human-readable information. A simple example of the use of data mining is the recommendation system used in the recruitment of laboratory assistants by using the k-nearest neighbor method. The training data is in the form of the grade from previous recruitment which will be used as a reference in determining whether the candidate is declared accepted or not. \u00a9 Medwell Journals, 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of science and technology increasingly popular in the society. Computer technology is growing very rapidly according to the level of human needs to solve various of problems. One of the rapid development of computer science is the field of data processing that is capable of processing data and provide information to support decision, one of which is data mining. Data mining helps to extract patterns from large data to be interpreted as human-readable information. A simple example of the use of data mining is the recommendation system used in the recruitment of laboratory assistants by using the k-nearest neighbor method. The training data is in the form of the grade from previous recruitment which will be used as a reference in determining whether the candidate is declared accepted or not. \u00a9 Medwell Journals, 2019."
        ]
    },
    {
        "judul":[
            "Business process maturity level of MSMEs in East Java, Indonesia"
        ],
        "penulis":"Dewi, Fitriyana;Mahendrawathi E.R.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of this research is to evaluate the degree of Micro, Small and Medium Enterprises (MSMEs)'s in East Java using business process maturity model. McCormack model is fine to use for assessing the MSME's business process that brings out the business process maturity level of MSMEs. On the ninth element of information systems support on BPOM model, we try to adjust the questionnaire items based on the condition of MSMEs in Indonesia which still lagging in the implementation of IT, so it is directing to the concept of IT readiness model by combining the state of IT infrastructure and application of MSMEs. This research also assessing the IT readiness of MSMEs and analyze the result by comparing with the level of maturity. The findings result from this research shows that the maturity of MSMEs in East Java are varying. Yet, the IT readiness of these MSMEs presents high score that indicates there seems to be a strong connection between IT usage, leadership and the maturity level of business process within the organization and explained how business process maturity is relevant to MSMEs. \u00a9 2019 The Authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this research is to evaluate the degree of Micro, Small and Medium Enterprises (MSMEs)'s in East Java using business process maturity model. McCormack model is fine to use for assessing the MSME's business process that brings out the business process maturity level of MSMEs. On the ninth element of information systems support on BPOM model, we try to adjust the questionnaire items based on the condition of MSMEs in Indonesia which still lagging in the implementation of IT, so it is directing to the concept of IT readiness model by combining the state of IT infrastructure and application of MSMEs. This research also assessing the IT readiness of MSMEs and analyze the result by comparing with the level of maturity. The findings result from this research shows that the maturity of MSMEs in East Java are varying. Yet, the IT readiness of these MSMEs presents high score that indicates there seems to be a strong connection between IT usage, leadership and the maturity level of business process within the organization and explained how business process maturity is relevant to MSMEs. \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Best Concept Selection for Dry-Soybean Cracking Machine Process Optimization using TOPSIS method"
        ],
        "penulis":"Anugraha R.A.;Darmawan N.M.;Iqbal M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tempe is a traditional Indonesian food with processed soybean as the main ingredients. Indonesia is the largest tempe producer in the world with hundreds of thousands of traditional tempe maker. Currently the traditional production process is wasteful that requires the amount of water as much as 1321 liters\/production of 37,5 kg tempe. Innovative dry production process is still less desirable because the dry soybean cracker machine is not optimal with a defect of 14,4% per production. In addition, the machine is unable to separate the husk and soybeans from the outlet. There are 12 alternative production concepts to produce highest quality tempe. TOPSIS method was used for selecting best production concept which reduces defect to 6,5% while manual separation process is eliminated. Water consumption is reduced to 800 liters\/production of 35,125 kg tempe. \u00a9 Published under licence by IOP Publishing Ltd.",
            "NIOOView detailsExpand Substance N-iodo-succinimide",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tempe is a traditional Indonesian food with processed soybean as the main ingredients. Indonesia is the largest tempe producer in the world with hundreds of thousands of traditional tempe maker. Currently the traditional production process is wasteful that requires the amount of water as much as 1321 liters\/production of 37,5 kg tempe. Innovative dry production process is still less desirable because the dry soybean cracker machine is not optimal with a defect of 14,4% per production. In addition, the machine is unable to separate the husk and soybeans from the outlet. There are 12 alternative production concepts to produce highest quality tempe. TOPSIS method was used for selecting best production concept which reduces defect to 6,5% while manual separation process is eliminated. Water consumption is reduced to 800 liters\/production of 35,125 kg tempe. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Clustering and classification of breathing activities by depth image from kinect"
        ],
        "penulis":"Delimayanti, Mera Kartika;Purnama, Bedy;Nguyen, Ngoc Giang;Mahmudah, Kunti Robiatul;Kubo, Mamoru;Kakikawa, Makiko;Yamada, Yoichi;Satou, Kenji;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper describes a new approach of the non-contact capturing method of breathing activities using the Kinect depth sensor. To process the data, we utilized feature extraction on time series of mean depth value and optional feature reduction step. The next process implemented a machine learning algorithm to execute clustering on the resulted data. The classification had been realized on four different subjects and then, continued to use 10-fold cross-validation and Support Vector Machine (SVM) classifier. The most efficient classifier is SVM radial with the grid reached the best accuracy for all of the subjects. \u00a9 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper describes a new approach of the non-contact capturing method of breathing activities using the Kinect depth sensor. To process the data, we utilized feature extraction on time series of mean depth value and optional feature reduction step. The next process implemented a machine learning algorithm to execute clustering on the resulted data. The classification had been realized on four different subjects and then, continued to use 10-fold cross-validation and Support Vector Machine (SVM) classifier. The most efficient classifier is SVM radial with the grid reached the best accuracy for all of the subjects. \u00a9 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved."
        ]
    },
    {
        "judul":[
            "Zone Based School Enrollment System by Using Modified k-Means Clustering Method"
        ],
        "penulis":"Kusuma, Purba Darn;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The main goal of zone based school enrollment method is reducing the student\u2019s home to school distance. So, among its variants, student will be allocated to the school that its location is near the student\u2019s home location. Meanwhile, one biggest problem in this method is the number of out of zone students which means of the student that is accepted in school that its location is outside his own zone. This situation occurs, especially when the zoning is determined statically. In this research, we propose dynamic zone based school enrollment model to meet the variations in school location distribution, student location distribution and school capacity. This model is developed based on k-means clustering method with several modifications. This proposed model then is implemented into zone based school enrollment simulation to measure its performance. In this simulation, the performance of this proposed model is also compared with the existing static one. In this simulation, adjusted parameters are school location distribution, student location distribution, school capacity, number of schools and number of students. Meanwhile, the observed parameters are average student\u2019s home to school distance and the success ratio. Based on the test result, there are several findings. The proposed model produces higher success ratio rather than the existing static method does. In the other side, the existing static method produces lower average student\u2019s home to school distance rather than the proposed model does. The number of schools and the average school capacity has positive correlation with the success ratio. The number of students has negative correlation with the success ratio. These adjusted variables do not affect the average student\u2019s home to school distance. \u00a9 Medwell Journals, 2019",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The main goal of zone based school enrollment method is reducing the student\u2019s home to school distance. So, among its variants, student will be allocated to the school that its location is near the student\u2019s home location. Meanwhile, one biggest problem in this method is the number of out of zone students which means of the student that is accepted in school that its location is outside his own zone. This situation occurs, especially when the zoning is determined statically. In this research, we propose dynamic zone based school enrollment model to meet the variations in school location distribution, student location distribution and school capacity. This model is developed based on k-means clustering method with several modifications. This proposed model then is implemented into zone based school enrollment simulation to measure its performance. In this simulation, the performance of this proposed model is also compared with the existing static one. In this simulation, adjusted parameters are school location distribution, student location distribution, school capacity, number of schools and number of students. Meanwhile, the observed parameters are average student\u2019s home to school distance and the success ratio. Based on the test result, there are several findings. The proposed model produces higher success ratio rather than the existing static method does. In the other side, the existing static method produces lower average student\u2019s home to school distance rather than the proposed model does. The number of schools and the average school capacity has positive correlation with the success ratio. The number of students has negative correlation with the success ratio. These adjusted variables do not affect the average student\u2019s home to school distance. \u00a9 Medwell Journals, 2019"
        ]
    },
    {
        "judul":[
            "The relationship of financial factors in asset pricing: The case of Indonesian market"
        ],
        "penulis":"Aryani, Sinta;Wiryono, Sudarso Kaderi;Koesrindartoto, Deddy P.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose of the study: The study shows how the financial factor of Leverage affects the empirical model of asset pricing together with other financial factors, i.e. Size, Book to Market, Operating Profit, and Investment. The contribution of Leverage in asset pricing will be tested, and its effect will be shown in the excess return of the asset. Methodology: The methodology used in this paper is based on the Fama and French model of asset pricing with additional factors added in the model. Data processing follows the Fama-Mc Beth procedure. Data comes from the Indonesian Stock Market, which consists of more than 500 stocks for ten years period of observation. Main Findings: The financial factor of Leverage affects the empirical model of asset pricing together with, i.e. Size, Book to Market, Operating Profit, and Investment. All the financial factors in the model are stationary around their mean, or they are non-stationary due to unit-roots. All the independents' variables have P-Value less than 10%. Implications: This study will be useful for financial investors in building an effective portfolio stock investment. By applying this model to their portfolio investment, the investors could effectively manage their portfolio return. On the management side, managing their financing structure, e.g. Leverage is the objective of the firm to maximize returns of the firms. Novelty\/Originality of this study: The empirical research with the involvement of the financial factor of Leverage has not been performed in Indonesia. The Leverage as the single factor of asset pricing has been considered as a significant financial factor for asset pricing, however, how the Leverage contributes to asset pricing compares to other financial factors has not examined yet. \u00a9 Aryani et al.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose of the study: The study shows how the financial factor of Leverage affects the empirical model of asset pricing together with other financial factors, i.e. Size, Book to Market, Operating Profit, and Investment. The contribution of Leverage in asset pricing will be tested, and its effect will be shown in the excess return of the asset. Methodology: The methodology used in this paper is based on the Fama and French model of asset pricing with additional factors added in the model. Data processing follows the Fama-Mc Beth procedure. Data comes from the Indonesian Stock Market, which consists of more than 500 stocks for ten years period of observation. Main Findings: The financial factor of Leverage affects the empirical model of asset pricing together with, i.e. Size, Book to Market, Operating Profit, and Investment. All the financial factors in the model are stationary around their mean, or they are non-stationary due to unit-roots. All the independents' variables have P-Value less than 10%. Implications: This study will be useful for financial investors in building an effective portfolio stock investment. By applying this model to their portfolio investment, the investors could effectively manage their portfolio return. On the management side, managing their financing structure, e.g. Leverage is the objective of the firm to maximize returns of the firms. Novelty\/Originality of this study: The empirical research with the involvement of the financial factor of Leverage has not been performed in Indonesia. The Leverage as the single factor of asset pricing has been considered as a significant financial factor for asset pricing, however, how the Leverage contributes to asset pricing compares to other financial factors has not examined yet. \u00a9 Aryani et al."
        ]
    },
    {
        "judul":[
            "Prototype Design Mapping of kWh Meters Based on Internet of Things (IoT)"
        ],
        "penulis":"Ramdana, Fakhri;Nasrun, Muhammad;Setianingsih, Casi;Murti, Muhammad Ary;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At present electricity is one of the most widely used energy sources for humans to support their daily needs. The electricity consumption used by each customer also varies according to the power capacity obtained by each of the electricity customers. Problems with the use of electricity consumption also occur in the campus environment. in the campus environment, the use of electrical energy is included in the high usage due to the dense activity on campus. Generally, the use of high electricity consumption occurs during working hours during the day. but it does not rule out the possibility also occurs at night with additional activities such as research labs and non-academic student agendas.In the construction of the kWh meter in this study, an integration tool of digital power meter (kWh meter) was made with the internet network using a microcontroller and IoT module. By connecting the kWh meter device with IoT, the measurement data can be easily monitored remotely. To monitor the data, a web application was made to monitor the data on electricity consumption. It is expected that with this monitor system users can manage electricity consumption better in accordance with needs.In the measurement accuracy testing, the accuracy value obtained with a multimeter of 99.19% was obtained in the 1P Voltage parameter, and for the results of the throughput test the best value was obtained 100% with a delivery time span every 5 minutes.  \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At present electricity is one of the most widely used energy sources for humans to support their daily needs. The electricity consumption used by each customer also varies according to the power capacity obtained by each of the electricity customers. Problems with the use of electricity consumption also occur in the campus environment. in the campus environment, the use of electrical energy is included in the high usage due to the dense activity on campus. Generally, the use of high electricity consumption occurs during working hours during the day. but it does not rule out the possibility also occurs at night with additional activities such as research labs and non-academic student agendas.In the construction of the kWh meter in this study, an integration tool of digital power meter (kWh meter) was made with the internet network using a microcontroller and IoT module. By connecting the kWh meter device with IoT, the measurement data can be easily monitored remotely. To monitor the data, a web application was made to monitor the data on electricity consumption. It is expected that with this monitor system users can manage electricity consumption better in accordance with needs.In the measurement accuracy testing, the accuracy value obtained with a multimeter of 99.19% was obtained in the 1P Voltage parameter, and for the results of the throughput test the best value was obtained 100% with a delivery time span every 5 minutes.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Case Study of Universities Dormitory Residence Management System (DRMS) in Indonesia"
        ],
        "penulis":"Lubis, Muharman;Fauzi, Rokhman;Lubis, Arif Ridho;Fauzi, Rahmat;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study explores the problems and challenges faced by several universities in Indonesia to allow, commonly, the first year students to enroll in dormitory either online or offline. It is reasonable for prospective students to have expectation that university provide suitable facilities in term of accommodation and logistics considering that a large number of student come from different cities in various provinces. The development of Dormitory Residential Management System (DRMS) should accommodate the process of enrollment, payment and booking from student online and support the staff to control and manage integrated program or activities based on determined schedule. Besides that, the system also allow monitoring process for reporting purpose and notify or confirm certain activities or allocation process. This study investigates several systems used by respected universities to identify the level of satisfaction of students. Interestingly, there are many evidences showed bottom level of satisfaction from student towards the services offered by university for DRMS. \u00a9 2018 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study explores the problems and challenges faced by several universities in Indonesia to allow, commonly, the first year students to enroll in dormitory either online or offline. It is reasonable for prospective students to have expectation that university provide suitable facilities in term of accommodation and logistics considering that a large number of student come from different cities in various provinces. The development of Dormitory Residential Management System (DRMS) should accommodate the process of enrollment, payment and booking from student online and support the staff to control and manage integrated program or activities based on determined schedule. Besides that, the system also allow monitoring process for reporting purpose and notify or confirm certain activities or allocation process. This study investigates several systems used by respected universities to identify the level of satisfaction of students. Interestingly, there are many evidences showed bottom level of satisfaction from student towards the services offered by university for DRMS. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Classification of microarray data involves Na\u00efve Bayes and dimension reduction using haar wavelet"
        ],
        "penulis":"Rohmawati, Aniq A.;Adiwijaya;Sarmilah, Milah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A general problem solving for handling microarray data is classification process with added a selection process from huge attributes. In particular, the escalated of attributes dimensionality provides a challenge to microarray handling techniques, related to microarray represents the large amount of genes expression. The multi-dependency (multicollinearity) may affect the performance when determining the parameter of classification. Many ways of solving the multicollinearity problem exists, the variable selection technique has become particularly popular. This is the method which use wavelet transformation for a few carefully selected variable and the method which regress respond variable onto a few linier combinations (components) of the original attributes. Wavelet is commonly used in image processing, spectral data using wavelet transformation have proved very successful in capturing the distinction among hyperspectral data. This paper investigates a new method of transformation data using Haar wavelet for selection processes. Our extensive study compares the selection processes using Haar wavelet transformation and Genetic Algorithm considering the selection dataset that implemented to Na\u00efve Bayes classification. In addition, the selection-classification using Haar wavelet and Na\u00efve Bayes describes a classification cancer and non-cancer quite well related to the accuracy of confusion matrix. \u00a9 BEIESP.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A general problem solving for handling microarray data is classification process with added a selection process from huge attributes. In particular, the escalated of attributes dimensionality provides a challenge to microarray handling techniques, related to microarray represents the large amount of genes expression. The multi-dependency (multicollinearity) may affect the performance when determining the parameter of classification. Many ways of solving the multicollinearity problem exists, the variable selection technique has become particularly popular. This is the method which use wavelet transformation for a few carefully selected variable and the method which regress respond variable onto a few linier combinations (components) of the original attributes. Wavelet is commonly used in image processing, spectral data using wavelet transformation have proved very successful in capturing the distinction among hyperspectral data. This paper investigates a new method of transformation data using Haar wavelet for selection processes. Our extensive study compares the selection processes using Haar wavelet transformation and Genetic Algorithm considering the selection dataset that implemented to Na\u00efve Bayes classification. In addition, the selection-classification using Haar wavelet and Na\u00efve Bayes describes a classification cancer and non-cancer quite well related to the accuracy of confusion matrix. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Disaster victims detection system using convolutional neural network (CNN) method"
        ],
        "penulis":"Hartawan, Dean Rizki;Purboyo, Tito Waluyo;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Natural disasters are one of the things that cannot be predicted. Natural disasters can cause losses, both assets and objects can even take lives. To reduce the number of losses, rapid evacuation handling from the Search and Rescue (SAR) team is needed to help victims of natural disasters. But in fact, there are often obstacles in the evacuation process. Such obstacles are such as bad weather conditions, disconnection of telecommunications networks, difficulty access to the victims of natural disasters and the spread of SAR teams that are not evenly distributed throughout the disaster area. Convolutional Neural Network is one of the developments of Artificial Neural Networks for image classification, image segmentation, and object recognition with high accuracy and high performance. CNN can learn to detect various images according to images from the dataset studied. So, this paper designed a system for detecting victims of natural disasters using the CNN method and implemented it on a raspberry pi which can detect victims of natural disasters through streaming cameras placed on UAVs. In this paper, the Convolutional Neural Network (CNN) method with 100% accuracy with distance object 1-4 m uses the Mobile-net SSD model. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Natural disasters are one of the things that cannot be predicted. Natural disasters can cause losses, both assets and objects can even take lives. To reduce the number of losses, rapid evacuation handling from the Search and Rescue (SAR) team is needed to help victims of natural disasters. But in fact, there are often obstacles in the evacuation process. Such obstacles are such as bad weather conditions, disconnection of telecommunications networks, difficulty access to the victims of natural disasters and the spread of SAR teams that are not evenly distributed throughout the disaster area. Convolutional Neural Network is one of the developments of Artificial Neural Networks for image classification, image segmentation, and object recognition with high accuracy and high performance. CNN can learn to detect various images according to images from the dataset studied. So, this paper designed a system for detecting victims of natural disasters using the CNN method and implemented it on a raspberry pi which can detect victims of natural disasters through streaming cameras placed on UAVs. In this paper, the Convolutional Neural Network (CNN) method with 100% accuracy with distance object 1-4 m uses the Mobile-net SSD model. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Big Data Implementation of Smart Rapid Transit using CCTV Surveillance"
        ],
        "penulis":"Dahlan, Iqbal Ahmad;Hamami, Faqih;Supangkat, Suhono Harso;Hidayat, Fadhil;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents the implementation on smart system for rapid transit using CCTV surveillance. Researchers proposed deep learning algorithms to detect objects with Convolutional Neural Network (CNN) and monitoring passengers' behavior like flow analytics, avoiding dangerous areas, and preventing intruder visitor[1][2].Research of this paper also implemented in Railway Station in Bandung with multiple CCTV sources. The system aims to make station better and able to improve quality of service in many scope areas (safe, secure and convenient)[3].Objective of this research is to develop smart surveillance with CCTV in smart station. The system consists of deep learning algorithm and big data technologies such as Hadoop, Apache Kafka and Apache Spark. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents the implementation on smart system for rapid transit using CCTV surveillance. Researchers proposed deep learning algorithms to detect objects with Convolutional Neural Network (CNN) and monitoring passengers' behavior like flow analytics, avoiding dangerous areas, and preventing intruder visitor[1][2].Research of this paper also implemented in Railway Station in Bandung with multiple CCTV sources. The system aims to make station better and able to improve quality of service in many scope areas (safe, secure and convenient)[3].Objective of this research is to develop smart surveillance with CCTV in smart station. The system consists of deep learning algorithm and big data technologies such as Hadoop, Apache Kafka and Apache Spark. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Development and experimental evaluation of small concentrated solar oven"
        ],
        "penulis":"Ajiwiguna, Tri Ayodha;Andriyani, Narulita;Suwandi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this work, the small scale of solar oven was developed and its performance was evaluated. The dimension of the oven was 13.5 \u00d7 13.5 x13.5 cm of length, width, and height respectively. To concentrate the incident radiation, four flat reflectors were installed and the reflected radiation was directed to the oven. The artificial solar radiation which consisted of nine incandescent light bulbs in an array was used as a source of radiation for performance evaluation. 90 grams of water was used as tested material to be heated. The temperature of the water, oven chamber, and ambient were measured by using thermocouples and the radiation intensity was measured by using a solar power meter. Four configurations of the solar oven were compared to investigate the influence of glass cover on the top and insulation layer on the wall of the oven under various intensity of radiation. The experimental results show the highest temperature was achieved when the glass cover and insulation layer was installed at the oven. In this configuration, the increasing water temperature was observed as 7.6 \u00b0C and 26.6 \u00b0C under radiation intensity of 137 and 880 W\/m2 respectively. However, the efficiency of the oven tended to decrease when the radiation intensity was high. \u00a9 2019 Author(s).",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this work, the small scale of solar oven was developed and its performance was evaluated. The dimension of the oven was 13.5 \u00d7 13.5 x13.5 cm of length, width, and height respectively. To concentrate the incident radiation, four flat reflectors were installed and the reflected radiation was directed to the oven. The artificial solar radiation which consisted of nine incandescent light bulbs in an array was used as a source of radiation for performance evaluation. 90 grams of water was used as tested material to be heated. The temperature of the water, oven chamber, and ambient were measured by using thermocouples and the radiation intensity was measured by using a solar power meter. Four configurations of the solar oven were compared to investigate the influence of glass cover on the top and insulation layer on the wall of the oven under various intensity of radiation. The experimental results show the highest temperature was achieved when the glass cover and insulation layer was installed at the oven. In this configuration, the increasing water temperature was observed as 7.6 \u00b0C and 26.6 \u00b0C under radiation intensity of 137 and 880 W\/m2 respectively. However, the efficiency of the oven tended to decrease when the radiation intensity was high. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Bidding Price-Based Transaction: Trust Establishment for Vehicular Fog Computing Service in Rural Area"
        ],
        "penulis":"Dewanta, Favian;Mambo, Masahiro;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the time of passing through rural area, vehicles sometimes need to deal with blank spots of wireless network (4G\/5G\/WiFi\/others). As a result, vehicles are unable to access fog computing service based on road side unit (RSU) infrastructure. To deal with this situation, vehicles utilize other vehicles' huge computational resource during their travel. However, it is not easy to put trust on other unknown vehicles since it can lead to a serious consequence for both user and server of vehicular fog computing service. In this paper, we attempt to fill gaps on establishing a trusted vehicular fog computing environment by mean of bidding price-based transaction (BPT) method. Through this method, vehicles do not need to encounter any trusted third party to have fog computing transaction with other vehicles. Moreover, every malicious activity may cause actors to lose bidding and trust, and then victim will gain redeem point as the compensation for receiving loss in transaction. In the end, this novel method is effective in limiting the number of potential attacks by mean of bidding price and payoff. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the time of passing through rural area, vehicles sometimes need to deal with blank spots of wireless network (4G\/5G\/WiFi\/others). As a result, vehicles are unable to access fog computing service based on road side unit (RSU) infrastructure. To deal with this situation, vehicles utilize other vehicles' huge computational resource during their travel. However, it is not easy to put trust on other unknown vehicles since it can lead to a serious consequence for both user and server of vehicular fog computing service. In this paper, we attempt to fill gaps on establishing a trusted vehicular fog computing environment by mean of bidding price-based transaction (BPT) method. Through this method, vehicles do not need to encounter any trusted third party to have fog computing transaction with other vehicles. Moreover, every malicious activity may cause actors to lose bidding and trust, and then victim will gain redeem point as the compensation for receiving loss in transaction. In the end, this novel method is effective in limiting the number of potential attacks by mean of bidding price and payoff. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Fostering net promoter score: Crafting user experience in difference cultural ecosystem"
        ],
        "penulis":"Mihardjo, Leonardus W Wasono;Sasmoko;Rukmana, Riza A. N.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The customer research in terms of usability, usefulness and branding on User Experience (UX) design is a critical part of the success in application implementation on Information communication technology (ICT) industry. The study on impact of cultural system with similar target market into designing UX in correlation with net promoter score (NPS) has not been revealed as part of important factor, for designing and evaluation of application design. Hence, this paper has objective to assess the effect of user experience (UX) in difference cultural ecosystem in relation with NPS for Indonesia diaspora. The case of prepaid product Kartu As 2in1 was investigated. The survey done through discussion with 20 respondents of Indonesia diaspora, with 10 respondents in Indonesia and Malaysia respectively. The result found that there is some similarity pattern of customer characteristics. However, some variations due to cultural ecosystem difference is found, that the Indonesia diaspora living in Malaysia mostly focused on the easiness of the use, but in Indonesia, they focused on the functionality. \u00a9 BEIESP.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The customer research in terms of usability, usefulness and branding on User Experience (UX) design is a critical part of the success in application implementation on Information communication technology (ICT) industry. The study on impact of cultural system with similar target market into designing UX in correlation with net promoter score (NPS) has not been revealed as part of important factor, for designing and evaluation of application design. Hence, this paper has objective to assess the effect of user experience (UX) in difference cultural ecosystem in relation with NPS for Indonesia diaspora. The case of prepaid product Kartu As 2in1 was investigated. The survey done through discussion with 20 respondents of Indonesia diaspora, with 10 respondents in Indonesia and Malaysia respectively. The result found that there is some similarity pattern of customer characteristics. However, some variations due to cultural ecosystem difference is found, that the Indonesia diaspora living in Malaysia mostly focused on the easiness of the use, but in Indonesia, they focused on the functionality. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Water-Filling Random Resource Allocation (W-FRRA) using NOMA for downlink LiFi system"
        ],
        "penulis":"Pamukti, Brian;Vinsensius Sigit W.P.;Fahmi, Arfianto;Adriansyah, Nachwan Mufti;Andini, Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, we proposed random resource allocation using water filling for Light Fidelity (LiFi) system, namely Water-Filling Random Resource Allocation (W-FRRA). This paper assumes that the room has several things that can be reflected or absorbed the light from LED bulb and produce blocking probability. We consider that users always move and change, randomly in a room. We use 4x4x3 m for room dimension and power bias 1 W to transmit power for the first time. Power control is used to organise signal to noise ratio (SNR) for equality data rates in any user locations. Our simulation shows that after employee W-FRRA, all of users has similarity data rates around 90Mbps for any propagations distance. After equality data rates are achieved using power allocation, we concentrate for limited time-slot resource, unpredictable packet edge and consider to using Non-Orthogonal Multiple Access (NOMA) for increasing the throughput of LiFi. To prove that our proposed method has improve, we compare random packets transmission such as Slotted ALOHA (SA) and Contention resolution diversity slotted ALOHA (CRDSA). We validate the results using packet loss rate and throughput performances based on computer simulation. We found that W-FRRA has highest performance among SA and CRDSA with most number of user can be served. In addition, the throughput performance of W-FRRA has higher around 10% and 30% than CRDSA and SA, respectively. We also prove that our proposed has fairness system and already employee NOMA to serve users without collision for every location on LiFi system. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we proposed random resource allocation using water filling for Light Fidelity (LiFi) system, namely Water-Filling Random Resource Allocation (W-FRRA). This paper assumes that the room has several things that can be reflected or absorbed the light from LED bulb and produce blocking probability. We consider that users always move and change, randomly in a room. We use 4x4x3 m for room dimension and power bias 1 W to transmit power for the first time. Power control is used to organise signal to noise ratio (SNR) for equality data rates in any user locations. Our simulation shows that after employee W-FRRA, all of users has similarity data rates around 90Mbps for any propagations distance. After equality data rates are achieved using power allocation, we concentrate for limited time-slot resource, unpredictable packet edge and consider to using Non-Orthogonal Multiple Access (NOMA) for increasing the throughput of LiFi. To prove that our proposed method has improve, we compare random packets transmission such as Slotted ALOHA (SA) and Contention resolution diversity slotted ALOHA (CRDSA). We validate the results using packet loss rate and throughput performances based on computer simulation. We found that W-FRRA has highest performance among SA and CRDSA with most number of user can be served. In addition, the throughput performance of W-FRRA has higher around 10% and 30% than CRDSA and SA, respectively. We also prove that our proposed has fairness system and already employee NOMA to serve users without collision for every location on LiFi system. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Hotspots forecasting using autoregressive integrated moving average (ARIMA) for detecting forest fires"
        ],
        "penulis":"Slavia, Athaya Putri;Sutoyo, Edi;Witarsyah, Deden;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hotspots are indicators of forest fires that detect a location that has a relatively higher temperature than the surrounding temperature. Hotspots are usually used as indicators or forest and land fires in an area, so the more hotspots, the more potential land fires occur in an area. Although not always more and more hotspots in an area the more the potential for fires. But the hotspot point can indeed be used to identify the initial occurrence of forest and land fires. Pekanbaru Meteorological Station owned by the Meteorology, Climatology and Geophysics Agency (BMKG) via NASA's Terra and Aqua remote sensing satellite detected 103 hotspots indicating forest and land fires in Riau Province, 97 of which are located in Rokan Hilir District. Therefore, based on these problems, the hotspots forecasting model research will be conducted to prevent the expansion of forest and land fires. Forecasting time series uses historical data to predict future data. The time series forecasting model used in this study applies the Box-Jenkins procedure to build ARIMA models that are compatible with the data and applies the ARIMA models obtained to make predictions of the occurrence of hotspots in July-December 2019. Based on the research results, the best model is obtained. ARIMA (2,0,2) with non-zero mean with AICc value of 408.62. Model evaluation is used to determine the accuracy of the ARIMA model (2,0,2) in forecasting by looking at the error value. Obtained the Mean Absolute Error of 3.766891 from the test results, so that the accuracy of the model in forecasting is 96.23%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hotspots are indicators of forest fires that detect a location that has a relatively higher temperature than the surrounding temperature. Hotspots are usually used as indicators or forest and land fires in an area, so the more hotspots, the more potential land fires occur in an area. Although not always more and more hotspots in an area the more the potential for fires. But the hotspot point can indeed be used to identify the initial occurrence of forest and land fires. Pekanbaru Meteorological Station owned by the Meteorology, Climatology and Geophysics Agency (BMKG) via NASA's Terra and Aqua remote sensing satellite detected 103 hotspots indicating forest and land fires in Riau Province, 97 of which are located in Rokan Hilir District. Therefore, based on these problems, the hotspots forecasting model research will be conducted to prevent the expansion of forest and land fires. Forecasting time series uses historical data to predict future data. The time series forecasting model used in this study applies the Box-Jenkins procedure to build ARIMA models that are compatible with the data and applies the ARIMA models obtained to make predictions of the occurrence of hotspots in July-December 2019. Based on the research results, the best model is obtained. ARIMA (2,0,2) with non-zero mean with AICc value of 408.62. Model evaluation is used to determine the accuracy of the ARIMA model (2,0,2) in forecasting by looking at the error value. Obtained the Mean Absolute Error of 3.766891 from the test results, so that the accuracy of the model in forecasting is 96.23%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Internet of things: Roboboat for water area monitoring using 4g network and google firebase"
        ],
        "penulis":"Ramadan, Dadan Nur;Hadiyoso, Sugondo;Sakti, Ahmad Rizaldi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this research Roboboat implemented to monitor water area, this system uses Raspberry Pi as main controller unit, roboboat are equipped with a camera and GPS module for real time monitoring, by taking pictures of surrounding environment, then send the image to cloud real time database. Roboboat can controlled by using applications on android smartphone using the 4G network, and users can view the captured image and coordinates of the roboboat location on the application screen, roboboat has dimensions of 51.2 x 21.8 x 14.4 cm. Results of data transmission speeds for send the command from application on android smartphone to control roboboat, in outdoor obtained an average speed is 1.84 second, Time for displaying images on the application is 5.68 seconds with image file around 4 Mb. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this research Roboboat implemented to monitor water area, this system uses Raspberry Pi as main controller unit, roboboat are equipped with a camera and GPS module for real time monitoring, by taking pictures of surrounding environment, then send the image to cloud real time database. Roboboat can controlled by using applications on android smartphone using the 4G network, and users can view the captured image and coordinates of the roboboat location on the application screen, roboboat has dimensions of 51.2 x 21.8 x 14.4 cm. Results of data transmission speeds for send the command from application on android smartphone to control roboboat, in outdoor obtained an average speed is 1.84 second, Time for displaying images on the application is 5.68 seconds with image file around 4 Mb. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Analysis of Channel Effect on NC-OFDM Maritime Communication System in Indonesia Seas"
        ],
        "penulis":"Mitayani, Arumjeni;Nurkahfi, Galih Nugraha;DInata, Mochamad Mardi Marta;Mardiana, Vita Awalia;Wael, Chaeriah Bin Ali;Armi, Nasrullah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "As the largest archipelago in the world, Indonesia has an enormous potential from maritime area. The best support system for manifesting that is with establishing maritime wireless communication system in Indonesian seas and oceans. In this research, we collect the data from previous research to determine the type of most Indonesian seas and oceans. However, this research only focuses on Java Sea and Karimata Strait. From the investigation, those seas are classified in Douglas sea scale 4 and 5, which are in moderate and rough condition. Based on those data, we model the maritime channel for maritime communication system with determining the fading path parameters in the available non contiguous orthogonal frequency division multiplexing (NC-OFDM) system, then we perform the numerical simulations of the model. It can be concluded from results that the bit error rates (BER) for both models are around 10-2which still have a good potential to be developed further and implemented in Indonesian maritime communication system. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "As the largest archipelago in the world, Indonesia has an enormous potential from maritime area. The best support system for manifesting that is with establishing maritime wireless communication system in Indonesian seas and oceans. In this research, we collect the data from previous research to determine the type of most Indonesian seas and oceans. However, this research only focuses on Java Sea and Karimata Strait. From the investigation, those seas are classified in Douglas sea scale 4 and 5, which are in moderate and rough condition. Based on those data, we model the maritime channel for maritime communication system with determining the fading path parameters in the available non contiguous orthogonal frequency division multiplexing (NC-OFDM) system, then we perform the numerical simulations of the model. It can be concluded from results that the bit error rates (BER) for both models are around 10-2which still have a good potential to be developed further and implemented in Indonesian maritime communication system. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Temporal learning analytics based on triple-factor approach using self-organizing map"
        ],
        "penulis":"Laksitowening, Kusuma Ayu;Denny;Hasibuan, Zainal A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "E-learning personalization aims to deliver learning activities and materials that suits to learners' needs. Therefore, the system must have the ability to analyze the profile and characteristics of each individual learner. Characteristics of learners, among others, can be identified from their behavior in using e-learning. Their most frequent learning resource accessed, their participation on discussions, and their assessment result are some of the variables from the activity logs that can describe their learning patterns. On the other side, learners' behavior may change over time. This research aims to capture and analyze the dynamic learning pattern throughout the semester. The learning analytics are conducted using temporal clustering approach to identify the learning style, motivation, and knowledge abilities. This research performs two-level clustering analysis to acquire learning patterns from activity logs from Moodle Learning Management System using Self-Organizing Map (SOM) and k-Means. SOM enables visualization high dimensional data by projection to lower dimensions. The proto-clusters of SOM are then clustered using k-Means. The temporal clustering results show that the learning patterns of learners are changing over time. \u00a9 2019 International Center for Scientific Research and Studies.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "E-learning personalization aims to deliver learning activities and materials that suits to learners' needs. Therefore, the system must have the ability to analyze the profile and characteristics of each individual learner. Characteristics of learners, among others, can be identified from their behavior in using e-learning. Their most frequent learning resource accessed, their participation on discussions, and their assessment result are some of the variables from the activity logs that can describe their learning patterns. On the other side, learners' behavior may change over time. This research aims to capture and analyze the dynamic learning pattern throughout the semester. The learning analytics are conducted using temporal clustering approach to identify the learning style, motivation, and knowledge abilities. This research performs two-level clustering analysis to acquire learning patterns from activity logs from Moodle Learning Management System using Self-Organizing Map (SOM) and k-Means. SOM enables visualization high dimensional data by projection to lower dimensions. The proto-clusters of SOM are then clustered using k-Means. The temporal clustering results show that the learning patterns of learners are changing over time. \u00a9 2019 International Center for Scientific Research and Studies."
        ]
    },
    {
        "judul":[
            "Mediating role of co-creation strategy on the relationship between business model innovation and corporate reputation: A case study on Indonesian telecommunication firms"
        ],
        "penulis":"Mihardjo, Leonardus W W.;Sasmoko;Alamsjah, Firdaus;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 4.0 drives the changing phenomenon throughout all industries driven by digital technology. Digital technology has become an enabler in the innovation of business models. New capabilities are required to be developed, especially for incumbent firms, since new entries have more agility in establishing new business models to create value. Even though the incumbent firms have strong reputation, they need to develop new distinct capabilities to create value in the long run. The fastest way to develop new capabilities is through collaboration also known as co-creation. Co-creation is a form of economic strategy to bring mutual values from different parties as a mediating role in creating business model innovations. Since there are limited study on co-creation strategy in relation to corporate reputation and business model innovation, this paper aims to assess the mediating role of co-creation strategy on the relationship between business model innovation and corporate reputation. The unit of analysis is taken from Indonesian telecommunication firms with sample of 35 firms out of 445 firms using purposive sampling method. Smart PLS (Partial Least Square) is used as the analytical approach and solution in the study. Research results reveal that corporate reputation has an indirect effect on business model innovation, but a direct effect on co-creation strategy. Co-creation strategy also plays significant effect to business model innovation. Co-creation strategy is a moderator variable between business model innovation and corporate reputation. The paper provided insight that the enhancement of corporate reputation should be directed towards building co-creation strategy which will then help strengthen business model innovation article. \u00a9 2019, Penerbit UTHM. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 4.0 drives the changing phenomenon throughout all industries driven by digital technology. Digital technology has become an enabler in the innovation of business models. New capabilities are required to be developed, especially for incumbent firms, since new entries have more agility in establishing new business models to create value. Even though the incumbent firms have strong reputation, they need to develop new distinct capabilities to create value in the long run. The fastest way to develop new capabilities is through collaboration also known as co-creation. Co-creation is a form of economic strategy to bring mutual values from different parties as a mediating role in creating business model innovations. Since there are limited study on co-creation strategy in relation to corporate reputation and business model innovation, this paper aims to assess the mediating role of co-creation strategy on the relationship between business model innovation and corporate reputation. The unit of analysis is taken from Indonesian telecommunication firms with sample of 35 firms out of 445 firms using purposive sampling method. Smart PLS (Partial Least Square) is used as the analytical approach and solution in the study. Research results reveal that corporate reputation has an indirect effect on business model innovation, but a direct effect on co-creation strategy. Co-creation strategy also plays significant effect to business model innovation. Co-creation strategy is a moderator variable between business model innovation and corporate reputation. The paper provided insight that the enhancement of corporate reputation should be directed towards building co-creation strategy which will then help strengthen business model innovation article. \u00a9 2019, Penerbit UTHM. All rights reserved."
        ]
    },
    {
        "judul":[
            "Design of radar display of Indonesian airspace monitoring application"
        ],
        "penulis":"Sulistyaningsih;Saputera, Yussi Perdana;Wahab, Mashury;Maulana, Yudi Yulius;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this research, the design and manufacture of radar display software using Plan Position Indicator (PPI) format for air surveillance radar application are presented. The PPI display shows interpretations of echo detections of radar signal reflected from the flying objects\/targets. The detection results will be displayed on a circular 360\u00b0 area, where the radar position is at the center. System configuration is done via interface from the display, by adjusting the level of transmit signal, by setting the gain for threshold, and by enabling moving target indicator (MTI) mode. The MTI mode only displays moving objects and no non-moving objects are shown such as mountains and buildings. Based on the results of this research, the PPI display shows the targets on the display according to its position, some desired targets can also be tracked, information on target, GPS location, target ID, required parameters, and some settings. The radar display fulfills all the required capabilities for air surveillance radar. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this research, the design and manufacture of radar display software using Plan Position Indicator (PPI) format for air surveillance radar application are presented. The PPI display shows interpretations of echo detections of radar signal reflected from the flying objects\/targets. The detection results will be displayed on a circular 360\u00b0 area, where the radar position is at the center. System configuration is done via interface from the display, by adjusting the level of transmit signal, by setting the gain for threshold, and by enabling moving target indicator (MTI) mode. The MTI mode only displays moving objects and no non-moving objects are shown such as mountains and buildings. Based on the results of this research, the PPI display shows the targets on the display according to its position, some desired targets can also be tracked, information on target, GPS location, target ID, required parameters, and some settings. The radar display fulfills all the required capabilities for air surveillance radar. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "ECG based biometric using wavelet packet decomposition"
        ],
        "penulis":"Hadiyoso, Sugondo;Rizal, Achmad;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Biometric technology has been commonly used for authentication. Fingerprint or iris become one of the biometrics that is widely applied. However, this type of biometrics tends to be easily falsified and damaged. So it is misused for manipulating actions and even crime. Therefore a new biometric method is needed to overcome this problem. One potential modality is biometrics based on an electrocardiogram (ECG) signal. This research simulates a one-lead ECG waveform for person authentication. ECG waves were taken from eleven healthy adult volunteers with a length of 60 seconds. ECG waves from each person are segmented into 10 sections so that a total of 110 ECG waves are used for person authentication simulations. All noise of the ECG waves was removed using a bandpass filter to reduce artifacts and high-frequency noise. Wavelet packet decomposition (3 Level) was applied to decompose the signal in several intrinsic parts so that typical wave information can be retrieved. Entropy-based feature extraction applied to all decomposed signals. A total of 14 entropy features have been calculated and used as predictors in the classification process. Validation and performance tests are carried out by cross-validation combined with linear discriminant analysis and support vector machines with five scenarios. The proposed method provides the highest accuracy of 71.8% using discriminant analysis and cubic support vector machine. The best accuracy value was achieved if all entropy features from all wavelet decomposition levels are used as predictors in the classification process. This research is expected to be a reference that ECG has the potential to become a future biometric modality. \u00a9 BEIESP.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Biometric technology has been commonly used for authentication. Fingerprint or iris become one of the biometrics that is widely applied. However, this type of biometrics tends to be easily falsified and damaged. So it is misused for manipulating actions and even crime. Therefore a new biometric method is needed to overcome this problem. One potential modality is biometrics based on an electrocardiogram (ECG) signal. This research simulates a one-lead ECG waveform for person authentication. ECG waves were taken from eleven healthy adult volunteers with a length of 60 seconds. ECG waves from each person are segmented into 10 sections so that a total of 110 ECG waves are used for person authentication simulations. All noise of the ECG waves was removed using a bandpass filter to reduce artifacts and high-frequency noise. Wavelet packet decomposition (3 Level) was applied to decompose the signal in several intrinsic parts so that typical wave information can be retrieved. Entropy-based feature extraction applied to all decomposed signals. A total of 14 entropy features have been calculated and used as predictors in the classification process. Validation and performance tests are carried out by cross-validation combined with linear discriminant analysis and support vector machines with five scenarios. The proposed method provides the highest accuracy of 71.8% using discriminant analysis and cubic support vector machine. The best accuracy value was achieved if all entropy features from all wavelet decomposition levels are used as predictors in the classification process. This research is expected to be a reference that ECG has the potential to become a future biometric modality. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Requirements Dependency Graph Modeling on Software Requirements Specification Using Text Analysis"
        ],
        "penulis":"Priyadi, Yudi;Djunaidy, Arif;Siahaan, Daniel;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Understanding interdependency among requirements is one of the success factors in software development. Information on requirements interdependency explicitly and implicitly resided various design artifacts or diagrams. A software requirements specification document is the artifact delivered in the early phase of development. It drives its following development processes. It also contains information on interdependencies among the requirements, such as similar, part-of, and elaborate. This study proposes an approach to model the requirement dependency graph for a software requirements specification document. There is an extraction process for Text Preprocessing, which includes of Tokenization, Stopword Removal, and Stemming. Besides, there is a process of measuring semantic similarity through WS4J (WordNet Similarity for Java). The results of the extraction process, combined with Greedy Algorithms as the optimum value solution approach. Besides, a method for calculating similarity was used through the practices of Wu Palmer and Levenshtein. At the end of this process, Reliability is performed using the Gwet's AC1 formula. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Understanding interdependency among requirements is one of the success factors in software development. Information on requirements interdependency explicitly and implicitly resided various design artifacts or diagrams. A software requirements specification document is the artifact delivered in the early phase of development. It drives its following development processes. It also contains information on interdependencies among the requirements, such as similar, part-of, and elaborate. This study proposes an approach to model the requirement dependency graph for a software requirements specification document. There is an extraction process for Text Preprocessing, which includes of Tokenization, Stopword Removal, and Stemming. Besides, there is a process of measuring semantic similarity through WS4J (WordNet Similarity for Java). The results of the extraction process, combined with Greedy Algorithms as the optimum value solution approach. Besides, a method for calculating similarity was used through the practices of Wu Palmer and Levenshtein. At the end of this process, Reliability is performed using the Gwet's AC1 formula. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Object Tracking Augmented Reality Markerless using FAST Corner Detection on User Defined-Extended Target Tracking in Multivarious Intensities"
        ],
        "penulis":"Nurhadi;Saparudin;Adam N.;Purnamasari D.;Fachruddin;Ibrahim, Ali;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents a FAST Corner Detection object scanning to improve SLAM technique, which is SLAM, has a weakness in extracting features in the real-world object. The use of User Defined Target and Extended Tracking are for making this work more convenient and reliable. We can trace the object even though the object does not exist, so this improves the function of markerless itself. The use of Raycast is for the make labeling the objects or features in the scanned object. In this research, we executed multivarious intensity to test the FAST Corner Detection to increase function in real world feature extraction and prove it better than SLAM. Then, we got the result where is a brighter condition will get faster recognition. The best environments for augmentation are in the range of 80-190, they took in less than 1 second. On the contrary, the intensity outside of the range such as \u226450 or \u2265200, has a deficiency of augmentation. The range of \u226450, there was no augmentation cause of low intensity. For the range of \u2265200, we haven't made measurements as we don't have the resources yet, but we hypothesize that the object would be corrupt or we may call it was overexposure cause of the intensity is too high. So, this could also lead to augmentation will not occur. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents a FAST Corner Detection object scanning to improve SLAM technique, which is SLAM, has a weakness in extracting features in the real-world object. The use of User Defined Target and Extended Tracking are for making this work more convenient and reliable. We can trace the object even though the object does not exist, so this improves the function of markerless itself. The use of Raycast is for the make labeling the objects or features in the scanned object. In this research, we executed multivarious intensity to test the FAST Corner Detection to increase function in real world feature extraction and prove it better than SLAM. Then, we got the result where is a brighter condition will get faster recognition. The best environments for augmentation are in the range of 80-190, they took in less than 1 second. On the contrary, the intensity outside of the range such as \u226450 or \u2265200, has a deficiency of augmentation. The range of \u226450, there was no augmentation cause of low intensity. For the range of \u2265200, we haven't made measurements as we don't have the resources yet, but we hypothesize that the object would be corrupt or we may call it was overexposure cause of the intensity is too high. So, this could also lead to augmentation will not occur. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Implementation of power inverter on grid connected photovoltaic generator system"
        ],
        "penulis":"Prastyo, Argo;Ekaputri, Cahyantarie;Reza, Muhamad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The issuance of ESDM (ministry of energy and mineral resources) regulation number 49 of 2018 concerning the use of a rooftop solar power generation system by consumers of PT PLN (Persero). It is encouraging to conduct research on one method of generating electricity using solar panels. The voltage generated in the generation process using solar panels is a direct voltage (DC) and requires an inverter as a voltage converter to be an alternating voltage (AC) which is the daily consumption of Indonesian people. This research aims to develop the use of renewable energy using an inverter. This inverter uses batteries as a source of voltage, Arduino as a source of SPWM waves, and MOSFETs are arranged in a full-bridge configuration to convert 12V DC electricity into 12VAC which will then be filtered using a low-pass filter to pass a 50 Hz frequency and then increase the voltage using a transformer to 220Vmax \/ 155 Vrms. The result of designing this research is that the inverter is able to produce a sinusoidal wave output 220 Vmax with a frequency of 50 Hz. With the output signal approaching the sinusoidal signal purely from the filter output, the power loss from the use of the transformer causes the power output from the inverter to be not optimal. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The issuance of ESDM (ministry of energy and mineral resources) regulation number 49 of 2018 concerning the use of a rooftop solar power generation system by consumers of PT PLN (Persero). It is encouraging to conduct research on one method of generating electricity using solar panels. The voltage generated in the generation process using solar panels is a direct voltage (DC) and requires an inverter as a voltage converter to be an alternating voltage (AC) which is the daily consumption of Indonesian people. This research aims to develop the use of renewable energy using an inverter. This inverter uses batteries as a source of voltage, Arduino as a source of SPWM waves, and MOSFETs are arranged in a full-bridge configuration to convert 12V DC electricity into 12VAC which will then be filtered using a low-pass filter to pass a 50 Hz frequency and then increase the voltage using a transformer to 220Vmax \/ 155 Vrms. The result of designing this research is that the inverter is able to produce a sinusoidal wave output 220 Vmax with a frequency of 50 Hz. With the output signal approaching the sinusoidal signal purely from the filter output, the power loss from the use of the transformer causes the power output from the inverter to be not optimal. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Lean manufacturing performance and organizational culture: An exploratory study"
        ],
        "penulis":"Salma, Sheila Amalia;Gafigi, Mohammad Andi;Rahma, Karyma Talitha;Widyanti, Ari;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Lean manufacturing is an approach to enhancing productivity through lean thinking. The success of the lean manufacturing application is influenced by various factors, one of them is the organizational culture. This study aims to explore lean manufacturing and organizational culture in an Indonesian aircraft manufacturer. Ninety workers in three production divisions (i.e., Detailed Part Manufacturing\/DPM, Component Assembly\/CA, Final Assyline & Delivery Center\/FAL & DC) in the aircraft manufacture are involved in this study voluntarily by filling out a set of questionnaire. Lean manufacturing performance is observed using Lean Manufacturing Benchmark, whereas organizational culture is evaluated using the Organizational Culture Assessment Instrument. The result shows that lean performance for DPM is 57%, CA is 61%, FAL & DC is 59%. All divisions have no dominant culture. However, the increased of lean performance is along with the increased hierarchy and clan culture, and the decreased of market and adhocracy culture. Implications of the results are discussed. \u00a9 2019 Author(s).",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Lean manufacturing is an approach to enhancing productivity through lean thinking. The success of the lean manufacturing application is influenced by various factors, one of them is the organizational culture. This study aims to explore lean manufacturing and organizational culture in an Indonesian aircraft manufacturer. Ninety workers in three production divisions (i.e., Detailed Part Manufacturing\/DPM, Component Assembly\/CA, Final Assyline & Delivery Center\/FAL & DC) in the aircraft manufacture are involved in this study voluntarily by filling out a set of questionnaire. Lean manufacturing performance is observed using Lean Manufacturing Benchmark, whereas organizational culture is evaluated using the Organizational Culture Assessment Instrument. The result shows that lean performance for DPM is 57%, CA is 61%, FAL & DC is 59%. All divisions have no dominant culture. However, the increased of lean performance is along with the increased hierarchy and clan culture, and the decreased of market and adhocracy culture. Implications of the results are discussed. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Exploring the soft system methodology in development of knowledge management conceptual model: A sytematic literature review"
        ],
        "penulis":"Sensuse, Dana Indra;Gandhi, Arfive;Sucahyo, Yudho Giri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Soft System Methodology (SSM) is common guidance to conceptualise Knowledge Management (KM) model since its benefit to handle complex situations. This study highlights SSM implementation on KM conceptual model using Systematic Literature Review (SLR) to produce insights about current implementation and promising chances in the future. This study also concerns on KM conceptual models as created without certain features in many case studies. Many various interpretation can arise to understand how system should work. This situation affected more spending time to validate KM conceptual model with stakeholders. Using SLR, this study criticises the importance of features as provided in eligible articles. Out of 144 articles from 2009 until 2019 as delivered from Scopus query, this study selected 12 articles about SSM on KM. It classified them into several criteria: published year, sector, and related KM life cycle. By mapping them to solve research questions, this study promoted actors, activities, and sequential order of activities as recommended features. By implementing them, KM conceptual model creation can be faster and accepted by stakeholders. \u00a9 2019, DESIDOC.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Soft System Methodology (SSM) is common guidance to conceptualise Knowledge Management (KM) model since its benefit to handle complex situations. This study highlights SSM implementation on KM conceptual model using Systematic Literature Review (SLR) to produce insights about current implementation and promising chances in the future. This study also concerns on KM conceptual models as created without certain features in many case studies. Many various interpretation can arise to understand how system should work. This situation affected more spending time to validate KM conceptual model with stakeholders. Using SLR, this study criticises the importance of features as provided in eligible articles. Out of 144 articles from 2009 until 2019 as delivered from Scopus query, this study selected 12 articles about SSM on KM. It classified them into several criteria: published year, sector, and related KM life cycle. By mapping them to solve research questions, this study promoted actors, activities, and sequential order of activities as recommended features. By implementing them, KM conceptual model creation can be faster and accepted by stakeholders. \u00a9 2019, DESIDOC."
        ]
    },
    {
        "judul":[
            "Exploring relationship between headline news sentiment and stock return"
        ],
        "penulis":"Alamsyah, Andry;Ayu, Siska Prasetya;Rikumahu, Brady;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Information from news is an integral part of investment activity. Such information is widely available from online media platforms, in which we can obtain relatively easy thanks to the development of technology. Despite predicting future stock prices being a hard challenge, the availability of big data is able to support investment decisions. Any relevant news is deemed as a determinant factor for influencing the public decision making. The Efficient Market Hypothesis states that financial markets depend on the availability of information. Sentiment analysis act as assisting tool to support the sentiment classification process, which falls into positive or negative categories. The process uses Na\u00efve Bayes and Support Vector Machine method. We conduct the research to see the relationship of headlines news from 20 companies listed in the Indonesia LQ45 index (February 2013-August 2018) and stock returns. This study is carried out by Spearman rank correlation in looking at the relationship between stock returns and headline news. The findings of the study indicates that there is a correlation between headline news and stock return. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information from news is an integral part of investment activity. Such information is widely available from online media platforms, in which we can obtain relatively easy thanks to the development of technology. Despite predicting future stock prices being a hard challenge, the availability of big data is able to support investment decisions. Any relevant news is deemed as a determinant factor for influencing the public decision making. The Efficient Market Hypothesis states that financial markets depend on the availability of information. Sentiment analysis act as assisting tool to support the sentiment classification process, which falls into positive or negative categories. The process uses Na\u00efve Bayes and Support Vector Machine method. We conduct the research to see the relationship of headlines news from 20 companies listed in the Indonesia LQ45 index (February 2013-August 2018) and stock returns. This study is carried out by Spearman rank correlation in looking at the relationship between stock returns and headline news. The findings of the study indicates that there is a correlation between headline news and stock return. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Optimization of biochemical systems production using combination of newton method and particle swarm optimization"
        ],
        "penulis":"Ismail, Mohd Arfian;Mezhuyev, Vitaliy;Darmawan, Irfan;Kasim, Shahreen;Mohamad, Mohd Saberi;Ibrahim, Ashraf Osman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the presented paper, an improved method that combines the Newton method with Particle Swarm Optimization (PSO) algorithm to optimize the production of biochemical systems was discussed and presented in detail. The optimization of the biochemical system's production became difficult and complicated when it involves a large size of biochemical systems that have many components and interaction between chemical. Also, two objectives and several constraints make the optimization process difficult. To overcome these situations, the proposed method was proposed by treating the biochemical systems as a nonlinear equations system and then optimizes using PSO. The proposed method was proposed to improve the biochemical system's production and at the same time reduce the total of chemical concentration involves. In the proposed method, the Newton method was used to deal with nonlinear equations system, while the PSO algorithm was utilized to fine-tune the variables in nonlinear equations system. The main reason for using the Newton method is its simplicity in solving the nonlinear equations system. The justification of choosing PSO algorithm is its direct implementation and effectiveness in the optimization process. In order to evaluate the proposed method, two biochemical systems were used, which were E.coli pathway and S. cerevisiae pathway. The experimental results showed that the proposed method was able to achieve the best result as compared to other works. \u00a9 2019 International Journal on Advanced Science Engineering Information Technology.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the presented paper, an improved method that combines the Newton method with Particle Swarm Optimization (PSO) algorithm to optimize the production of biochemical systems was discussed and presented in detail. The optimization of the biochemical system's production became difficult and complicated when it involves a large size of biochemical systems that have many components and interaction between chemical. Also, two objectives and several constraints make the optimization process difficult. To overcome these situations, the proposed method was proposed by treating the biochemical systems as a nonlinear equations system and then optimizes using PSO. The proposed method was proposed to improve the biochemical system's production and at the same time reduce the total of chemical concentration involves. In the proposed method, the Newton method was used to deal with nonlinear equations system, while the PSO algorithm was utilized to fine-tune the variables in nonlinear equations system. The main reason for using the Newton method is its simplicity in solving the nonlinear equations system. The justification of choosing PSO algorithm is its direct implementation and effectiveness in the optimization process. In order to evaluate the proposed method, two biochemical systems were used, which were E.coli pathway and S. cerevisiae pathway. The experimental results showed that the proposed method was able to achieve the best result as compared to other works. \u00a9 2019 International Journal on Advanced Science Engineering Information Technology."
        ]
    },
    {
        "judul":[
            "Exploring the internal and external constraint of it business start up in Bandung, Indonesia"
        ],
        "penulis":"Chumaidiyah, Endang;Tripiawan, Wawan;Aurachman, Rio;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The digital era encourages a digital transformation that brings changes in the application of digital technology in all aspects of people\u2019s lives. The digital economy becomes a business opportunity that encourages the growth of various startup of IT business especially game product, content and digital application. Nevertheless, the IT startup business with all its new creativity and ideas remains vulnerable to obstacles due to its various limitations. Business management is essential to be done by startup IT by empowering internal resources owned and by always paying attention to external factors. This research aims to explore and analyze internal and external IT business startup constraints. This study uses a descriptive qualitative method by distributing questionnaires to 40 respondents selected through convenience sampling approach. The result of the research shows that the internal factors which become obstacles for a start-up IT from the are competence, capital, technology, and innovation. As for external factors that become obstacles for start-up; IT in a sequence is the regulation, competition, market structure, and market orientation. \u00a9 BEIESP.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The digital era encourages a digital transformation that brings changes in the application of digital technology in all aspects of people\u2019s lives. The digital economy becomes a business opportunity that encourages the growth of various startup of IT business especially game product, content and digital application. Nevertheless, the IT startup business with all its new creativity and ideas remains vulnerable to obstacles due to its various limitations. Business management is essential to be done by startup IT by empowering internal resources owned and by always paying attention to external factors. This research aims to explore and analyze internal and external IT business startup constraints. This study uses a descriptive qualitative method by distributing questionnaires to 40 respondents selected through convenience sampling approach. The result of the research shows that the internal factors which become obstacles for a start-up IT from the are competence, capital, technology, and innovation. As for external factors that become obstacles for start-up; IT in a sequence is the regulation, competition, market structure, and market orientation. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Towards co-creation strategy and organizational agility based on customer experience orientation to shape transformational performance"
        ],
        "penulis":"Mihardjo, Leonardus W. Wasono;Sasmoko, Firdaus Alamsyah;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 5.0 is a step after digitalization and digitation has been accomplished. The collaboration, service orientation, agility and customer experience become a critical in this dynamic environment. Hence, the firm strategy has shifted from a competition strategy to a col-laboration strategy. Collaboration with customers is effected through co-creation Strategy (CCS). It could enable the firms in accelerating digital transformation. This study of the development of co-creation strategy focuses on customer experience orientation (CXO) and organization agility (OA) to support transformational performance (TP) in terms of relationship among variables and an empirical study has been conducted. Hence, in this paper, we propose a model of digital transformation for ICT Industry based on co-creation of strategy focused on customer experience orientation and organization agility. The study is based on an empirical study of 195 Indonesian ICT firms. The findings from this analysis reveal the concept of Service Dominant logic (S-D Logic) where the Co-creation capability and organizational agilities can suffice. \u00a9 2019 Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 5.0 is a step after digitalization and digitation has been accomplished. The collaboration, service orientation, agility and customer experience become a critical in this dynamic environment. Hence, the firm strategy has shifted from a competition strategy to a col-laboration strategy. Collaboration with customers is effected through co-creation Strategy (CCS). It could enable the firms in accelerating digital transformation. This study of the development of co-creation strategy focuses on customer experience orientation (CXO) and organization agility (OA) to support transformational performance (TP) in terms of relationship among variables and an empirical study has been conducted. Hence, in this paper, we propose a model of digital transformation for ICT Industry based on co-creation of strategy focused on customer experience orientation and organization agility. The study is based on an empirical study of 195 Indonesian ICT firms. The findings from this analysis reveal the concept of Service Dominant logic (S-D Logic) where the Co-creation capability and organizational agilities can suffice. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Image Processing of IoT Based Cherry Tomato Growth Monitoring System"
        ],
        "penulis":"Anugraheni, Nadya Ayu;Suhendi, Asep;Bethanigtyas, Hertiana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Monitoring the growth of fruit in a plant is one of several important parameters to determine the phase of a plant's growth. Monitoring fruit growth in Cherry tomatoes can be done with image processing. Image processing is used to detect the ripe cherry tomatoes. To mark off the ripe one, first define the range of YCbCr value for ripe cherry's tomatoes, afterthat color segmentation needs to be done to the picture. Usually, cherry tomatoes touch each other, so separating touching cherry's tomatoes using the watershed algorithm is the next step. Next, counting the ripe fruits automatically. The value of counting needs to be shown, it will be sent to the IoT platform, in this paper, thingspeak is used for IoT platform. From this paper, the algorithm can detect 72 pictures from 100 pictures correctly with 10% error for the whole images. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Monitoring the growth of fruit in a plant is one of several important parameters to determine the phase of a plant's growth. Monitoring fruit growth in Cherry tomatoes can be done with image processing. Image processing is used to detect the ripe cherry tomatoes. To mark off the ripe one, first define the range of YCbCr value for ripe cherry's tomatoes, afterthat color segmentation needs to be done to the picture. Usually, cherry tomatoes touch each other, so separating touching cherry's tomatoes using the watershed algorithm is the next step. Next, counting the ripe fruits automatically. The value of counting needs to be shown, it will be sent to the IoT platform, in this paper, thingspeak is used for IoT platform. From this paper, the algorithm can detect 72 pictures from 100 pictures correctly with 10% error for the whole images. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Ant Colony Optimization method analyzing for Sequential Pattern Mining (Case Study: IGracias Telkom University)"
        ],
        "penulis":"Liana, Isma Dewi;Asror, Ibnu;Sardi, Indra Lukmana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "With the development of internet technology, information becomes very easy to obtain. Especially the use of web-based information systems are very widely used to disseminate information to the world. Similarly, in the Eld of education that makes the website as a source of information for all students, lecturers, to employees. In general, each user access to the website can form the access pattern. Then, the accessing pattern can be used to do the development on the website to facilitate the user get the desired menu. By using Ant Colony Optimization (ACO), the system can output the pattern of access based on the interests of all users. The selection of the Ant Colony Optimization (ACO) method due to the ow when the user accesses the website has in common with the ants while building the road to the food. In this experiment, pheromone will be modification with interest time and interest visit user to release the result that can approach the pattern of user access when accessing the website. Also, after testing the threshold was obtained 0.02 for the student group, 0.05 for the lecturer group, and 0.025 for the employee group which can produce a pattern that represents the user's habit patterns. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "With the development of internet technology, information becomes very easy to obtain. Especially the use of web-based information systems are very widely used to disseminate information to the world. Similarly, in the Eld of education that makes the website as a source of information for all students, lecturers, to employees. In general, each user access to the website can form the access pattern. Then, the accessing pattern can be used to do the development on the website to facilitate the user get the desired menu. By using Ant Colony Optimization (ACO), the system can output the pattern of access based on the interests of all users. The selection of the Ant Colony Optimization (ACO) method due to the ow when the user accesses the website has in common with the ants while building the road to the food. In this experiment, pheromone will be modification with interest time and interest visit user to release the result that can approach the pattern of user access when accessing the website. Also, after testing the threshold was obtained 0.02 for the student group, 0.05 for the lecturer group, and 0.025 for the employee group which can produce a pattern that represents the user's habit patterns. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "User Experience in Mobile Application Design: Utility Defined Context of Use"
        ],
        "penulis":"Lubis, Muharman;Sutoyo, Edi;Azuddin, Muna;Handayani, Dini;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Mobile application has been offered tremendous benefit to the user in providing solution especially related to accessibility and availability. Product functions are important but with the better user experiences, it will have more advantages, which somehow increase its level adoption and retention within context. User experience (UX) is the outcome that this study want to achieve through implementing user centred design in the process by defining the set of methods and phases, which are loosely connected each other to solve the problem arisen. This study identified the lack of integration process within driving communities to have service in motorcycle driving practice, permission letter and rental. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mobile application has been offered tremendous benefit to the user in providing solution especially related to accessibility and availability. Product functions are important but with the better user experiences, it will have more advantages, which somehow increase its level adoption and retention within context. User experience (UX) is the outcome that this study want to achieve through implementing user centred design in the process by defining the set of methods and phases, which are loosely connected each other to solve the problem arisen. This study identified the lack of integration process within driving communities to have service in motorcycle driving practice, permission letter and rental. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Reading level system on fairy tale stories for children using dolch sight word vocabulary with majority voting algorithm"
        ],
        "penulis":"Azzami, Alifa Nur;Kusumo, Dana Sulistyo;Astuti, Widi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Children need appropriate reading contents to improve their imagination and power of thought. Fairy tales become one of reading contents that are good for children growth, because it can arise children imagination. However, there is no reading content categorization for Indonesian fairy tale stories. Therefore, in this research, a Reading Level System was proposed to rank reading contents for Indonesian children. Adopting Dolch Sight Word Vocabulary, it enabled to build text clustering using the occurrences of empirical probability of words for each Dolch Sight Word Vocabulary in a fairy tale. The values of empirical probability levels were calculated for each fairy tale and the results of calculating the highest probability value for each fairy tale using the Majority Voting Algorithm. The results found that the majority of Reading Level System using Dolch Sight Word Vocabulary were level 3 and level 4, where at these levels the words component of the Dolch Sight words were larger than the rest two levels. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Children need appropriate reading contents to improve their imagination and power of thought. Fairy tales become one of reading contents that are good for children growth, because it can arise children imagination. However, there is no reading content categorization for Indonesian fairy tale stories. Therefore, in this research, a Reading Level System was proposed to rank reading contents for Indonesian children. Adopting Dolch Sight Word Vocabulary, it enabled to build text clustering using the occurrences of empirical probability of words for each Dolch Sight Word Vocabulary in a fairy tale. The values of empirical probability levels were calculated for each fairy tale and the results of calculating the highest probability value for each fairy tale using the Majority Voting Algorithm. The results found that the majority of Reading Level System using Dolch Sight Word Vocabulary were level 3 and level 4, where at these levels the words component of the Dolch Sight words were larger than the rest two levels. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Comparison of Real Time Iterative Deepening Best First Search Algorithm and A\u2217 Algorithm on Maze Chase Game NPC"
        ],
        "penulis":"Nabil, Husein;Nasution, Surya Michrandi;Nugrahaeni, Ratna Astuti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Maze Chase is a game that has a maze background. In this game there are players who have the task, which is to take all the points in the labyrinth. In the Maze Chase game there is also an NPC (Non-Playable Character) that aims to chase players so that players cannot take all the points in the labyrinth. Players can be considered to have won the game is that all the points in the labyrinth have been taken by the player. The author implements the A\u2217 and RIBS path search algorithms for NPCs so that NPCs can chase players. That way we get the travel time comparison to the players on each path search algorithm. After testing the average travel time to NPC players with the A\u2217 algorithm faster 0.116196% than NPC with the RIBS algorithm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Maze Chase is a game that has a maze background. In this game there are players who have the task, which is to take all the points in the labyrinth. In the Maze Chase game there is also an NPC (Non-Playable Character) that aims to chase players so that players cannot take all the points in the labyrinth. Players can be considered to have won the game is that all the points in the labyrinth have been taken by the player. The author implements the A\u2217 and RIBS path search algorithms for NPCs so that NPCs can chase players. That way we get the travel time comparison to the players on each path search algorithm. After testing the average travel time to NPC players with the A\u2217 algorithm faster 0.116196% than NPC with the RIBS algorithm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design Features for Gender-specific Differences in Blended Learning within Higher Education in Indonesia"
        ],
        "penulis":"Aditya, Bayu Rima;Permadi, Aditya;Nurhas, Irawan;Pawlowski, Jan M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Blended learning offers learning solutions for higher educational institutions facing the industrial revolution 4.0. In this study, we investigated the influence factors student perceptions of blended learning based on gender-specific differences in Indonesia. We applied a research model to systematically assess the effect of design features on the effectiveness of blended learning indicators (intrinsic motivation and student satisfaction). Moreover, we evaluated the research model for both genders separately. Based on the quantitative survey of 223 Indonesian students, our study confirms that the design features significantly influence the effectiveness of blended learning for male and female students. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Blended learning offers learning solutions for higher educational institutions facing the industrial revolution 4.0. In this study, we investigated the influence factors student perceptions of blended learning based on gender-specific differences in Indonesia. We applied a research model to systematically assess the effect of design features on the effectiveness of blended learning indicators (intrinsic motivation and student satisfaction). Moreover, we evaluated the research model for both genders separately. Based on the quantitative survey of 223 Indonesian students, our study confirms that the design features significantly influence the effectiveness of blended learning for male and female students. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Reasoning about the disruption patterns for train system using Bayesian Network and Prolog"
        ],
        "penulis":"Pradiawati, Yunita Rachma;Rusmawati, Yanti;Arzaki, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We construct a Prolog-based expert system to reason about the disruption patterns for train system using Bayesian network and Prolog. The disruptions dependencies are modeled using Bayesian network and the reasoning is carried on using Prolog. We choose Bayesian network because it is one of the most efficient and elegant framework to represent and reason probabilistic graphical model. The causative relationship among disruptions is represented using Directed Acyclic Graph (DAG). We use Prolog to improve the efficiency of the reasoning process by defining Bayesian network and its probabilistic information into a knowledge base. The causative relationships among disruptions are also modeled in terms of Prolog rules. Our Prolog-based expert system combines the statistical reasoning capability of Bayesian network and logic programming efficiency. The system provides comprehensive reasoning regarding the causative probability of events, the causative relationship among disruptions, as well as the most triggering and triggered disruptions in train system. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We construct a Prolog-based expert system to reason about the disruption patterns for train system using Bayesian network and Prolog. The disruptions dependencies are modeled using Bayesian network and the reasoning is carried on using Prolog. We choose Bayesian network because it is one of the most efficient and elegant framework to represent and reason probabilistic graphical model. The causative relationship among disruptions is represented using Directed Acyclic Graph (DAG). We use Prolog to improve the efficiency of the reasoning process by defining Bayesian network and its probabilistic information into a knowledge base. The causative relationships among disruptions are also modeled in terms of Prolog rules. Our Prolog-based expert system combines the statistical reasoning capability of Bayesian network and logic programming efficiency. The system provides comprehensive reasoning regarding the causative probability of events, the causative relationship among disruptions, as well as the most triggering and triggered disruptions in train system. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Livelihood resilience: The case of sungai Terengganu communities"
        ],
        "penulis":"Muhamad, Suriyani;Nawawi, Mohd Nasir;Kulub Abd Rashid, Noorhaslinda;Kusairi, Suhal;Nik Mohd Kamil, Nik Fuad;Samsudin, Hazman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Livelihood in river settings may appear simple, but upon closer examination, it is multifaceted and dynamic. The elements of uncertainty in sustaining a satisfactory livelihood are always present. The concept of resilience is about individuals, households or groups making a living and attempting to satisfy their consumption and economic necessities, surviving with uncertainties and responding to new opportunities. The earlier approaches in livelihood studies regarded poor people as inactive or passive victims. However, the trend has changed with greater interest to study on the survival strategies of the poor. In particular, consideration is given to the living experiences of households and the community. The objective of this study is to apply the concept of resilience as a diagnostic approach to the understanding of rural communities' livelihoods. The analysis highlights the resilience aspects of the rural community and their livelihood strategies for comfortable living. \u00a9 Springer Nature Switzerland AG 2019.",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Livelihood in river settings may appear simple, but upon closer examination, it is multifaceted and dynamic. The elements of uncertainty in sustaining a satisfactory livelihood are always present. The concept of resilience is about individuals, households or groups making a living and attempting to satisfy their consumption and economic necessities, surviving with uncertainties and responding to new opportunities. The earlier approaches in livelihood studies regarded poor people as inactive or passive victims. However, the trend has changed with greater interest to study on the survival strategies of the poor. In particular, consideration is given to the living experiences of households and the community. The objective of this study is to apply the concept of resilience as a diagnostic approach to the understanding of rural communities' livelihoods. The analysis highlights the resilience aspects of the rural community and their livelihood strategies for comfortable living. \u00a9 Springer Nature Switzerland AG 2019."
        ]
    },
    {
        "judul":[
            "Abusive Language Detection on Indonesian Online News Comments"
        ],
        "penulis":"Desrul, Dhamir Raniah Kiasati;Romadhony, Ade;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Abusive language is an expression used by a person with insulting delivery of any person's aspect. In the modern era, the use of harsh words is often found on the internet, one of them is in the comment section of online news articles which contains harassment, insult, or a curse. An abusive language detection system is important to prevent the negative effect of such comments. Detecting abusive language in the online comment section is a challenge since abusive languages can be expressed in various words. Moreover, only a few studies have been conducted in Indonesian language. In this paper, we present an Indonesian abusive language detection system by tackling this problem as a classification task and solving it using the following classifiers: Naive Bayes, SVM, and KNN. We also performed feature selection procedure based on Mutual Information value between words. The experimental results show that SVM is the best classifier for detecting the abusive language in news comment with an accuracy score of 90,19% and the use of Mutual Information able to improve the classification accuracy by 1.63%. Mutual Information can increase the accuracy performance of the classifier. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Abusive language is an expression used by a person with insulting delivery of any person's aspect. In the modern era, the use of harsh words is often found on the internet, one of them is in the comment section of online news articles which contains harassment, insult, or a curse. An abusive language detection system is important to prevent the negative effect of such comments. Detecting abusive language in the online comment section is a challenge since abusive languages can be expressed in various words. Moreover, only a few studies have been conducted in Indonesian language. In this paper, we present an Indonesian abusive language detection system by tackling this problem as a classification task and solving it using the following classifiers: Naive Bayes, SVM, and KNN. We also performed feature selection procedure based on Mutual Information value between words. The experimental results show that SVM is the best classifier for detecting the abusive language in news comment with an accuracy score of 90,19% and the use of Mutual Information able to improve the classification accuracy by 1.63%. Mutual Information can increase the accuracy performance of the classifier. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Developing the maturity model for gig economy business processes"
        ],
        "penulis":"Gandhi, Arfive;Budiardjo, Eko Kuswardono;Giri Sucahyo, Yudho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Actualizes the progressiveness of digital business, gig economy brings easiness for people to search and do project using platforms. This opportunity may affect many treats, such as inefficient business processes and lack of professionalism. Many operators of gig platform govern their business processes intuitively without clear method or roadmap so that their growth is not predictable. This study proposes maturity model for gig economy business process to standardize growth of gig economy by considering the differentiating factors. It encompasses five levels: Initial, Defined, Standardized, Measured, and Optimized. They are appraised using eight staged Business Process Areas, related Specific Goals, and detail Specific Practices. This model relies on the evidence as Work Product to decide the compliance on each level. This maturity model is developed through five phases with hierarchy from CMMI-Service. It produces guidance to evaluate current reflection and formulate necessary improvement towards mature and qualified business processes in gig economy. Therefore, gig economy can generate more benefits and contributions for society. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Actualizes the progressiveness of digital business, gig economy brings easiness for people to search and do project using platforms. This opportunity may affect many treats, such as inefficient business processes and lack of professionalism. Many operators of gig platform govern their business processes intuitively without clear method or roadmap so that their growth is not predictable. This study proposes maturity model for gig economy business process to standardize growth of gig economy by considering the differentiating factors. It encompasses five levels: Initial, Defined, Standardized, Measured, and Optimized. They are appraised using eight staged Business Process Areas, related Specific Goals, and detail Specific Practices. This model relies on the evidence as Work Product to decide the compliance on each level. This maturity model is developed through five phases with hierarchy from CMMI-Service. It produces guidance to evaluate current reflection and formulate necessary improvement towards mature and qualified business processes in gig economy. Therefore, gig economy can generate more benefits and contributions for society. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Knowledge sharing and transformational leadership"
        ],
        "penulis":"Mihardjo, Leonardus W.W.;Sasmoko;Alamsjah, Firdaus;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The principal objective of the current study is to explore the link between knowledge sharing transformational leadership style, team performance, and mutual trust. In addition to that moderating role of mutual trust is also examined. The study has broached the argument that knowledge sharing and transformational leadership style improves team performance. Findings of the current study suggest creativity is a process that starts in the team through the sharing of knowledge. The currents study is also of the view that the that the process of creativity starts in the situation when the team members share knowledge through coordination and it is also argued that the much of the knowledge is shared when team members meet to share knowledge in a given area, much of which is tacit. Sharing such tacit knowledge creates a flow of novel ideas that contribute to successful outcomes, such as new products, processes and patents. The findings of the study have shown agreement with the proposed or hypothesize results. The study has used PLS-SEM to analyses the data. The study will be helpful for policy makers in the researcher in understanding the issues related to supply chain, its integration, flexibility, and internal performance. \u00a9 2019, General Jonas Zemaitis Military Academy of Lithuania.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The principal objective of the current study is to explore the link between knowledge sharing transformational leadership style, team performance, and mutual trust. In addition to that moderating role of mutual trust is also examined. The study has broached the argument that knowledge sharing and transformational leadership style improves team performance. Findings of the current study suggest creativity is a process that starts in the team through the sharing of knowledge. The currents study is also of the view that the that the process of creativity starts in the situation when the team members share knowledge through coordination and it is also argued that the much of the knowledge is shared when team members meet to share knowledge in a given area, much of which is tacit. Sharing such tacit knowledge creates a flow of novel ideas that contribute to successful outcomes, such as new products, processes and patents. The findings of the study have shown agreement with the proposed or hypothesize results. The study has used PLS-SEM to analyses the data. The study will be helpful for policy makers in the researcher in understanding the issues related to supply chain, its integration, flexibility, and internal performance. \u00a9 2019, General Jonas Zemaitis Military Academy of Lithuania."
        ]
    },
    {
        "judul":[
            "Characterization of on Board Data Handling (OBDH) Subsystem"
        ],
        "penulis":"Arseno D.;Edwar, Edwar;Harfian A.R.;Salsabila J.N.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nanosatellite technology is one type of satellite weighing less than 10 Kg. There are several advantages of nanosatellite technology, one of which is less cost than the conventional or geostationary satellite, so it can be develop by universities in university-scaled. Tel-USat is nanosatellite project developed by Telkom University for research purpose. Tel-USat mission carrying remote sensing payload with serial camera. One of the subsystems in nanosatellite is On Board Data Handling (OBDH) subsystem. The main task of OBDH subsystem design to control and monitoring the nanosatellite system as main controller. The OBDH subsystem determine the health system performance by monitoring nanosatellite housekeeping consist of several parameters such as temperature system, nanosatellite gyroscope orientation, and magnetic sensing. As main controller, OBDH subsystem also synchronizing between subsystems. It controls to take pictures of the camera from payload subsystem. The Tel-USat On Board Data Handling subsystem using 32-bit ARM Cortex 3 as main controller provides with three different sensors parameters for nanosatellite housekeeping. The payload subsystem carrying serial camera produces JPEG image with 640 \u00d7 480 pixels. The result of this research is OBDH of TelU-Sat with embedded STM32F103C8T6 microcontroller can operated as main controller to monitoring housekeeping data parameters and image payload control. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nanosatellite technology is one type of satellite weighing less than 10 Kg. There are several advantages of nanosatellite technology, one of which is less cost than the conventional or geostationary satellite, so it can be develop by universities in university-scaled. Tel-USat is nanosatellite project developed by Telkom University for research purpose. Tel-USat mission carrying remote sensing payload with serial camera. One of the subsystems in nanosatellite is On Board Data Handling (OBDH) subsystem. The main task of OBDH subsystem design to control and monitoring the nanosatellite system as main controller. The OBDH subsystem determine the health system performance by monitoring nanosatellite housekeeping consist of several parameters such as temperature system, nanosatellite gyroscope orientation, and magnetic sensing. As main controller, OBDH subsystem also synchronizing between subsystems. It controls to take pictures of the camera from payload subsystem. The Tel-USat On Board Data Handling subsystem using 32-bit ARM Cortex 3 as main controller provides with three different sensors parameters for nanosatellite housekeeping. The payload subsystem carrying serial camera produces JPEG image with 640 \u00d7 480 pixels. The result of this research is OBDH of TelU-Sat with embedded STM32F103C8T6 microcontroller can operated as main controller to monitoring housekeeping data parameters and image payload control. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Automatic Detection of Argument Components in Text Using Multinomial Nave Bayes Clasiffier"
        ],
        "penulis":"Rohman, Hifdzon Nur;Asror, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Arguments are often found in various text data, for example in news, essays and articles. Argumentation Mining is a method that automatically identifies argument structures in text documents. This argument structure consists of several components that are very useful for information retrieval and processing information. In this study, a model will be built to auto-matically detect the component of argument, by using naive bayes classifer multinomial, the model will classify argument components into two classes, namely claim and premise. The evaluation uses k-fold cross validation. The most optimal result of this study is the average accuracy of 70.39 % and the average f1-score of 80.42 % with feature extraction, preprocessing and weighting words. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Arguments are often found in various text data, for example in news, essays and articles. Argumentation Mining is a method that automatically identifies argument structures in text documents. This argument structure consists of several components that are very useful for information retrieval and processing information. In this study, a model will be built to auto-matically detect the component of argument, by using naive bayes classifer multinomial, the model will classify argument components into two classes, namely claim and premise. The evaluation uses k-fold cross validation. The most optimal result of this study is the average accuracy of 70.39 % and the average f1-score of 80.42 % with feature extraction, preprocessing and weighting words. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "A New Framework for Metaheuristic Search Based on Animal Foraging"
        ],
        "penulis":"Saadi, Younes;Yanto, Iwan Tri Riyadi;Sutoyo, Edi;Mungad, Mungad;Chiroma, Haruna;Herawan, Tutut;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, a new framework for metaheuristic search for global optimization is introduced. It is suitable for continuous nonlinear optimization problems. This framework is mimicking the seal pup behavior and its ability to search and choose the best lair to escape from predators. The scenario starts once the seal mother gives birth to a new pup in a birthing lair that is constructed for this purpose. The seal pup strategy everytime consists of searching and selecting the best lair. For that, the seal pup performs a random walk to find a new lair. Stimulated by the sensitive nature of seals against external noise, the random walk is based on two search modes, normal mode and urgent mode. In normal mode, the pup moves between closely adjacent lairs via a Brownian walk. In urgent mode, the pup leaves the proximity area far away and performs a Levy walk to find a new lair from sparse targets. The switch between these two modes is realized by the random noise emitted by predators. The proposed framework can efficiently mimic seal pups behavior to find best location and provide a new approach to be used in global optimization problems. \u00a9 Springer Nature Singapore Pte Ltd. 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, a new framework for metaheuristic search for global optimization is introduced. It is suitable for continuous nonlinear optimization problems. This framework is mimicking the seal pup behavior and its ability to search and choose the best lair to escape from predators. The scenario starts once the seal mother gives birth to a new pup in a birthing lair that is constructed for this purpose. The seal pup strategy everytime consists of searching and selecting the best lair. For that, the seal pup performs a random walk to find a new lair. Stimulated by the sensitive nature of seals against external noise, the random walk is based on two search modes, normal mode and urgent mode. In normal mode, the pup moves between closely adjacent lairs via a Brownian walk. In urgent mode, the pup leaves the proximity area far away and performs a Levy walk to find a new lair from sparse targets. The switch between these two modes is realized by the random noise emitted by predators. The proposed framework can efficiently mimic seal pups behavior to find best location and provide a new approach to be used in global optimization problems. \u00a9 Springer Nature Singapore Pte Ltd. 2019."
        ]
    },
    {
        "judul":[
            "Human activity recognition using support vector machine for automatic security system"
        ],
        "penulis":"Supriyatna, Taufiq Bagaskara;Nasution, Surya Michrandi;Nugraheni, Ratna Astuti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Home is a place for human beings to live and also to socialize with the society. In this rapid technology development, a home security system is a must to prevent crimes. One of the innovation is home automation which enables controlling the doors automatically. RGB-D camera can detect human body movements which later can be used to recognize the activity through the Support Vector Machine (SVM) algorithm. The result of activity prediction can be used as home automation input for the home security system. In this paper, a security system analysis has been carried out which is beneficial for the users in maintaining the security system through combining the RGB-D Camera and Skeleton Tracking which then classified by using SVM algorithm. The result shows that the optimal data resulted through 1 meter distance with 100% accuracy, while testing variable C of SVM resulting in C = 2 as the best score for C variable with 92% accuracy. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Home is a place for human beings to live and also to socialize with the society. In this rapid technology development, a home security system is a must to prevent crimes. One of the innovation is home automation which enables controlling the doors automatically. RGB-D camera can detect human body movements which later can be used to recognize the activity through the Support Vector Machine (SVM) algorithm. The result of activity prediction can be used as home automation input for the home security system. In this paper, a security system analysis has been carried out which is beneficial for the users in maintaining the security system through combining the RGB-D Camera and Skeleton Tracking which then classified by using SVM algorithm. The result shows that the optimal data resulted through 1 meter distance with 100% accuracy, while testing variable C of SVM resulting in C = 2 as the best score for C variable with 92% accuracy. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Digital anemometer and solar power meter analysis measurements for installation of wind and solar hybrid power plants"
        ],
        "penulis":"Mulyana, Tatang;Ibrahim, Rasidi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents an analysis of the results of wind speed measurements using Digital Anemometer Model AM-4203 and solar power measurements using Digital Solar Power Meter Model SPM-1116SD from a location which will be used as a site to install a hybrid system of wind and solar power plants. The wind speed measurement data taken in 3421 seconds are recorded and displayed in graphical form between wind speed (m\/s) and time (s). Meanwhile, the solar power measurement data taken in 111 seconds are recorded and displayed in graphical form between solar powers (W\/m2) to seconds (s). The lowest wind speed measurement result is 0 m\/s for some time and the highest is 3 m\/s for 2880 seconds, while for the average measurement result is 1 m\/s. While the lowest solar power measurement results are 20 W\/m2 for some time and the highest is 770 W\/m2 at 14:14:43 (23 s), while for the average measurement is 360 W\/m2. Referring to such measurement data, the potential for wind power generation is weak, so it is almost impossible to produce energy efficiently using wind power, as the wind speed must be greater than 4 m\/s. While based on the measurement profile of solar power, from time to time can reach 770 W\/m2 which has the potential to generate electricity. In addition, based on these two measurement results, they show a nonlinear random profile. Thus the installation of hybrid wind and solar power plants must have a nonlinear control system design. \u00a9 2019 Penerbit Akademia Baru.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents an analysis of the results of wind speed measurements using Digital Anemometer Model AM-4203 and solar power measurements using Digital Solar Power Meter Model SPM-1116SD from a location which will be used as a site to install a hybrid system of wind and solar power plants. The wind speed measurement data taken in 3421 seconds are recorded and displayed in graphical form between wind speed (m\/s) and time (s). Meanwhile, the solar power measurement data taken in 111 seconds are recorded and displayed in graphical form between solar powers (W\/m2) to seconds (s). The lowest wind speed measurement result is 0 m\/s for some time and the highest is 3 m\/s for 2880 seconds, while for the average measurement result is 1 m\/s. While the lowest solar power measurement results are 20 W\/m2 for some time and the highest is 770 W\/m2 at 14:14:43 (23 s), while for the average measurement is 360 W\/m2. Referring to such measurement data, the potential for wind power generation is weak, so it is almost impossible to produce energy efficiently using wind power, as the wind speed must be greater than 4 m\/s. While based on the measurement profile of solar power, from time to time can reach 770 W\/m2 which has the potential to generate electricity. In addition, based on these two measurement results, they show a nonlinear random profile. Thus the installation of hybrid wind and solar power plants must have a nonlinear control system design. \u00a9 2019 Penerbit Akademia Baru."
        ]
    },
    {
        "judul":[
            "Platelets and hematocrit in the survival model of dengue hemorrhagic fever (Dhf) sufferers in palopo"
        ],
        "penulis":"Riska, Yanu Fa\u2019Rifah;Bobby, Poerwanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to apply cox regression analysis to predict the patient's survival to dengue disease occurring in Palopo. This study uses clinical data, namely the results of laboratory tests to determine the effect on the patient's healing period. Laboratory test results used are platelets and hematocrit. By using the maximum partial likelihood estimation (MPLE) method to obtain parameter estimates in the cox regression model, it is known that platelets have a stronger effect for patient resistance on dengue hemorrhagic fever (DHF) than hematocrit. This is based on the p-value obtained from the analysis less than alpha (0.05), which is equal to 0.0433. Patients who have an average platelet below normal when experiencing DHF are longer in their recovery period. In addition, patients with DHF \u2264 2 days, the probability to survive and recover is 90%. \u00a9 2019 Trans Tech Publications Ltd, Switzerland. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to apply cox regression analysis to predict the patient's survival to dengue disease occurring in Palopo. This study uses clinical data, namely the results of laboratory tests to determine the effect on the patient's healing period. Laboratory test results used are platelets and hematocrit. By using the maximum partial likelihood estimation (MPLE) method to obtain parameter estimates in the cox regression model, it is known that platelets have a stronger effect for patient resistance on dengue hemorrhagic fever (DHF) than hematocrit. This is based on the p-value obtained from the analysis less than alpha (0.05), which is equal to 0.0433. Patients who have an average platelet below normal when experiencing DHF are longer in their recovery period. In addition, patients with DHF \u2264 2 days, the probability to survive and recover is 90%. \u00a9 2019 Trans Tech Publications Ltd, Switzerland. All rights reserved."
        ]
    },
    {
        "judul":[
            "Water flow control system based on context aware algorithm and IoT for hydroponic"
        ],
        "penulis":"Gandhi, Otrinanda;Ramdhani, Mohamad;Murti, Muhammad Ary;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "IoT: Smart garbage monitoring using android and real time database"
        ],
        "penulis":"Putra, Riyan Hadi;Kusuma, Feri Teja;Damayanti, Tri Nopiani;Ramadan, Dadan Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Every single day, garbage is always produced and sometimes, due to the unbalance between high volume produced and the garbage volume transported to the landfill; it then leads to the buildup. To prevent any negative impact on environment, a system is needed to support the waste management process. Smart Garbage Monitoring System consists of two parts: portable garbage can and monitoring application using android smartphone. The use of ultrasonic sensor, GPS and GSM Module on the garbage can aims to provide the data on the garbage and send it to the real time database, in which the data will be processed by the monitoring application on smartphone to determine the time of garbage transport purposely to prevent any buildup. The system doesn't need a server to process, because the entire process of will be run by android application on a smartphone. Test results showed the capability of the system in monitoring the garbage can with the minimum distance between the wastes by three meters. The information on the height level of garbage can be synchronized in real time to smartphone, with an average delay on the EDGE network of 4.57 seconds, HSPA+ of 4.52 seconds and LTE of 3.85 seconds. \u00a9 2019 Universitas Ahmad Dahlan.",
            "Sustainable Development Goals mapped to this documentResponsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Every single day, garbage is always produced and sometimes, due to the unbalance between high volume produced and the garbage volume transported to the landfill; it then leads to the buildup. To prevent any negative impact on environment, a system is needed to support the waste management process. Smart Garbage Monitoring System consists of two parts: portable garbage can and monitoring application using android smartphone. The use of ultrasonic sensor, GPS and GSM Module on the garbage can aims to provide the data on the garbage and send it to the real time database, in which the data will be processed by the monitoring application on smartphone to determine the time of garbage transport purposely to prevent any buildup. The system doesn't need a server to process, because the entire process of will be run by android application on a smartphone. Test results showed the capability of the system in monitoring the garbage can with the minimum distance between the wastes by three meters. The information on the height level of garbage can be synchronized in real time to smartphone, with an average delay on the EDGE network of 4.57 seconds, HSPA+ of 4.52 seconds and LTE of 3.85 seconds. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Multilayer X-Band Wave Absorber with Enhanced Absorption Bandwidth"
        ],
        "penulis":"Syihabuddin, Budi;Effendi, Mohammad Ridwan;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electromagnetics (EM) wave absorber implemented with common pattern structure such as rectangular and circular patches on a single-layer of dielectric substrate has deficiency in performance. The use of passive components incorporated into the structure was sometimes employed to overcome the issue of deficiency. This paper proposes wave absorber composed of multilayer dielectric substrates to enhance the absorption characteristic focused on its bandwidth performance. The proposed multilayer wave absorber is designed to work at the X-band frequency with an FR4 epoxy dielectric substrate applied for each layer. A multi-impedance concept of each layer which depends on its patch dimension is implemented to acquire the bandwidth improvement. The characteristic of proposed wave absorber is investigated through its unit cell with the dimension of 5.80 mm \u00d7 5.80 mm. The characterization result shows that the fractional bandwidth for the unit cell using square patch could increase up to 127% and 169% for the double-layer and the triple-layers, respectively, compared to the single-layer of dielectric substrate at the X-band frequency of 9.5 GHz. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electromagnetics (EM) wave absorber implemented with common pattern structure such as rectangular and circular patches on a single-layer of dielectric substrate has deficiency in performance. The use of passive components incorporated into the structure was sometimes employed to overcome the issue of deficiency. This paper proposes wave absorber composed of multilayer dielectric substrates to enhance the absorption characteristic focused on its bandwidth performance. The proposed multilayer wave absorber is designed to work at the X-band frequency with an FR4 epoxy dielectric substrate applied for each layer. A multi-impedance concept of each layer which depends on its patch dimension is implemented to acquire the bandwidth improvement. The characteristic of proposed wave absorber is investigated through its unit cell with the dimension of 5.80 mm \u00d7 5.80 mm. The characterization result shows that the fractional bandwidth for the unit cell using square patch could increase up to 127% and 169% for the double-layer and the triple-layers, respectively, compared to the single-layer of dielectric substrate at the X-band frequency of 9.5 GHz. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Paraphrase construction of al quran in Indonesian language translation"
        ],
        "penulis":"Hutami, Amalia Asti;Bijaksana, Moch Arif;Suryani, Arie Ardiyanti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In order to better understand Quran one of the important things is to know the relevance and similarity of meaning between the translation sections in Quran. To carry out the process of identifying the similarities and interrelationships between texts, the construction of a paraphrase list is one of the supporting components. In this study, the technique of developing Quran paraphrase was developed using Monolingual and word Alignment. The features used in the study are identical words, word sequences, Align PPDB. The construction of this paraphrase list uses two different versions of the Quran translation which are used as input, then will produce a paraphrase database from the corpus used as the output. The system uses Precision, Recall, and F1 as evaluation metrics. The experimental results show that applying a combination of features can achieve F1 of 80%.Our source code and data are available at: https:\/\/github.com\/AmaliaHutami\/Paraphrase-Construction-of-Al-Quran-in-Indonesian-Language-Translation. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In order to better understand Quran one of the important things is to know the relevance and similarity of meaning between the translation sections in Quran. To carry out the process of identifying the similarities and interrelationships between texts, the construction of a paraphrase list is one of the supporting components. In this study, the technique of developing Quran paraphrase was developed using Monolingual and word Alignment. The features used in the study are identical words, word sequences, Align PPDB. The construction of this paraphrase list uses two different versions of the Quran translation which are used as input, then will produce a paraphrase database from the corpus used as the output. The system uses Precision, Recall, and F1 as evaluation metrics. The experimental results show that applying a combination of features can achieve F1 of 80%.Our source code and data are available at: https:\/\/github.com\/AmaliaHutami\/Paraphrase-Construction-of-Al-Quran-in-Indonesian-Language-Translation. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "An Augmented Method of Selecting Fashion Talent by Adding Social Media Characteristic"
        ],
        "penulis":"Adilah, Dwita;Alamsyah, Andry;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Fashion model plays an important role in presenting designer's work by showing how the cut of fabric interplayed with the body. In selecting the fashion models, the agency considers physical characteristics that express the aesthetic. Another subjective advantage of fashion model is the appearance on professional network. However, the emerging of social media culture has revolutionized fashion industry in producing and consuming fashion. In term of fashion modelling, social media open the opportunities for talent to \"breaking in\" and \"getting discovered\". Prior research has dealt with predicting success based on social media presence. Thus, in this paper we construct additional social media activity to predict a fashion model success. We examine prediction using classification task by utilizing Random Forest and Support Vector Machine. Our research finds that social media activity improves the accuracy by 4.55% increasing up to 84.55% performed by Random Forest. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Fashion model plays an important role in presenting designer's work by showing how the cut of fabric interplayed with the body. In selecting the fashion models, the agency considers physical characteristics that express the aesthetic. Another subjective advantage of fashion model is the appearance on professional network. However, the emerging of social media culture has revolutionized fashion industry in producing and consuming fashion. In term of fashion modelling, social media open the opportunities for talent to \"breaking in\" and \"getting discovered\". Prior research has dealt with predicting success based on social media presence. Thus, in this paper we construct additional social media activity to predict a fashion model success. We examine prediction using classification task by utilizing Random Forest and Support Vector Machine. Our research finds that social media activity improves the accuracy by 4.55% increasing up to 84.55% performed by Random Forest. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Condition-based maintenance and spare parts provisioning based on markov chains"
        ],
        "penulis":"Nurhasanah H.;Ridwan A.Y.;Santosa B.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Machine is a vital tool of the company in helping the production process. Every company expects the production to run smoothly, but sometimes it is hampered by damage that happened to the machine, so that the production process is disrupted and causes losses to the company. Engine damage can be minimized by regularly evaluating the condition of the spare parts. In practice, if the spare parts inventory policy is not accurate it will cause stock outs or overstocks, which can lead to more costs for the company. The worst case is if there is no spare part stored in the warehouse when it is needed, it can make the production floor stopped, which in the end makes the company can't fulfil their production target. This research aims to obtain an optimal preventive maintenance schedule by calculating the machine's reliability and inventory provisioning policy for the spare parts according to predicted amount that will be needed in the future calculated using Markov chains so the company can determine the reorder point (r) and the economic order quantity (EOQ). \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Machine is a vital tool of the company in helping the production process. Every company expects the production to run smoothly, but sometimes it is hampered by damage that happened to the machine, so that the production process is disrupted and causes losses to the company. Engine damage can be minimized by regularly evaluating the condition of the spare parts. In practice, if the spare parts inventory policy is not accurate it will cause stock outs or overstocks, which can lead to more costs for the company. The worst case is if there is no spare part stored in the warehouse when it is needed, it can make the production floor stopped, which in the end makes the company can't fulfil their production target. This research aims to obtain an optimal preventive maintenance schedule by calculating the machine's reliability and inventory provisioning policy for the spare parts according to predicted amount that will be needed in the future calculated using Markov chains so the company can determine the reorder point (r) and the economic order quantity (EOQ). \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "System dynamics simulation to determine financial strategy for social health insurance in Indonesia"
        ],
        "penulis":"Kurnianingtyas, Diva;Santosa, Budi;Siswanto, Nurhadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Social Health Insurance (SHI) in Indonesia is still experiencing financial constraints because the financial condition of the SHI has continued to be a loss since it was established in 2014 until present so it becomes special attention needed to get achieving the Universal Health Coverage (UHC) target by the government. Therefore, this study intends to provide an appropriate SHI financial strategy recommendation by considering the stability of the balance of income and expense. In addition, a system dynamics simulation approach is needed to find optimal SHI financial strategies with variables including participant premium rates, average cost of benefits, number of health cases, and number of insurance participants. The data used came from BPJS Health data for 2016 and 2017. Afterwards, the equation used was Income \u2265 Expenditures. In addition, there are several scenarios designed to reduce the level of financial losses that occur at SHI. The scenario of reducing the number of health cases is the best strategy recommendation decision. The results show that reducing average benefit costs and increasing premium rates also gets it can reduce financial problems. From the results that have been obtained, this study can contribute to the resolution of SHI Health financial problems in Indonesia. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Reduced inequalitiesGoal 10Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Social Health Insurance (SHI) in Indonesia is still experiencing financial constraints because the financial condition of the SHI has continued to be a loss since it was established in 2014 until present so it becomes special attention needed to get achieving the Universal Health Coverage (UHC) target by the government. Therefore, this study intends to provide an appropriate SHI financial strategy recommendation by considering the stability of the balance of income and expense. In addition, a system dynamics simulation approach is needed to find optimal SHI financial strategies with variables including participant premium rates, average cost of benefits, number of health cases, and number of insurance participants. The data used came from BPJS Health data for 2016 and 2017. Afterwards, the equation used was Income \u2265 Expenditures. In addition, there are several scenarios designed to reduce the level of financial losses that occur at SHI. The scenario of reducing the number of health cases is the best strategy recommendation decision. The results show that reducing average benefit costs and increasing premium rates also gets it can reduce financial problems. From the results that have been obtained, this study can contribute to the resolution of SHI Health financial problems in Indonesia. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "An Investigation of Aircraft Tracking through Space-based ADS-B Receiver"
        ],
        "penulis":"Caya T.V.;Hafizh M.;Benyamin S.O.;Edwar;Putra Y.D.;Widiawan A.K.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nowadays space-based Automatic Dependent Surveillance-Broadcast (ADS-B) is widely developed with various methods to improve the quality of ADS-B. The method that can be used to design a space-based ADS-B receiver is creating a system-level simulator. The system-level simulator can be used to investigate performance of the system with scenarios that have been made. This paper presents a modeling of the ADS-B signal receiver system from an aircraft with a Low Earth Orbit (LEO) Satellite. In this model, the position of the aircraft is randomly scattered within the range of the satellite's coverage at an altitude of 5 km-15 km above the ground level. The satellite's antenna used in this simulation has a 90-degree beamwidth with 5 dBi of maximum gain on the main lobe. The lowest BER value obtained from the aircraft is 1x10-8, located at the satellite nadir and the highest value obtained from the aircraft is 1x10-6, located at the farthest distance from the satellite. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays space-based Automatic Dependent Surveillance-Broadcast (ADS-B) is widely developed with various methods to improve the quality of ADS-B. The method that can be used to design a space-based ADS-B receiver is creating a system-level simulator. The system-level simulator can be used to investigate performance of the system with scenarios that have been made. This paper presents a modeling of the ADS-B signal receiver system from an aircraft with a Low Earth Orbit (LEO) Satellite. In this model, the position of the aircraft is randomly scattered within the range of the satellite's coverage at an altitude of 5 km-15 km above the ground level. The satellite's antenna used in this simulation has a 90-degree beamwidth with 5 dBi of maximum gain on the main lobe. The lowest BER value obtained from the aircraft is 1x10-8, located at the satellite nadir and the highest value obtained from the aircraft is 1x10-6, located at the farthest distance from the satellite. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Tracking telemetry and command using software defined radio with nano-satellite parameters"
        ],
        "penulis":"Wangsa, Damas Wicaksi;Syihabuddin, Budi;Edwar;Wijanto, Heroe;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Ground station is satellite sub-system for satellite communication. It has several functions such as master station and Telemetry, Tracking, and Command (TT&C). Developing a ground station is expensive but it can be reduced by using Software Defined Radio (SDR). We use SDR because it is easily to reconfigure based on system requirement. Simulation process using GNU radio and implementation using HackRF. In this paper use two scenario for design and testing. First scenario for validating the simulation process and second scenario for testing TT&C performance using SDR. The scenarios use text and image file as basic data. It transmit 2.7 kB text file and 11.5kB image file and received respectively 2.23 kB and 11.15 kB. In first scenario, there are 1.2 errors for text file and 2.3 errors for image file and in second scenario there are 5.2 errors for text file and 25.9 errors. \u00a9 2019 IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ground station is satellite sub-system for satellite communication. It has several functions such as master station and Telemetry, Tracking, and Command (TT&C). Developing a ground station is expensive but it can be reduced by using Software Defined Radio (SDR). We use SDR because it is easily to reconfigure based on system requirement. Simulation process using GNU radio and implementation using HackRF. In this paper use two scenario for design and testing. First scenario for validating the simulation process and second scenario for testing TT&C performance using SDR. The scenarios use text and image file as basic data. It transmit 2.7 kB text file and 11.5kB image file and received respectively 2.23 kB and 11.15 kB. In first scenario, there are 1.2 errors for text file and 2.3 errors for image file and in second scenario there are 5.2 errors for text file and 25.9 errors. \u00a9 2019 IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Automated Examination Timetabling Optimization Using Greedy-Late Acceptance-Hyperheuristic Algorithm"
        ],
        "penulis":"Muklason, Ahmad;Bwananesia, Putri C.;Sasmi Hidayatul Y.T.;Angresti, Nisa D.;Supoyo, Vicha Azthanty;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Due to its non-deterministic polinomial (NP)-hard nature, exam timetabling problem is one of challenging combinatorial optimisation problems. Therefore, it attracts researchers especially in operation research and artificial intelligence fields for decades. Since the problem is very complex, exam timetable in many universities is developed manually which is very time consuming. This paper presents a new hybrid algorithm, i.e. greedy-late acceptance within hyper-heuristic framework to generate and optimise exam timetable automatically. Greedy algorithm is used to generate initial solution, whereas late acceptance is used as move acceptance strategy. The algorithm is simple but proven powerfull. The algorithm is tested over two datasets from real-world exam timetabling problem from Information Systems Department, Institut Teknologi Sepuluh Nopember (ITS). Over 11 different scenarios, the experimental results show that in addition to its ability to generate feasible solution, the algorithm also could produce more optimal solutions compared to the timetables generated manually. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Due to its non-deterministic polinomial (NP)-hard nature, exam timetabling problem is one of challenging combinatorial optimisation problems. Therefore, it attracts researchers especially in operation research and artificial intelligence fields for decades. Since the problem is very complex, exam timetable in many universities is developed manually which is very time consuming. This paper presents a new hybrid algorithm, i.e. greedy-late acceptance within hyper-heuristic framework to generate and optimise exam timetable automatically. Greedy algorithm is used to generate initial solution, whereas late acceptance is used as move acceptance strategy. The algorithm is simple but proven powerfull. The algorithm is tested over two datasets from real-world exam timetabling problem from Information Systems Department, Institut Teknologi Sepuluh Nopember (ITS). Over 11 different scenarios, the experimental results show that in addition to its ability to generate feasible solution, the algorithm also could produce more optimal solutions compared to the timetables generated manually. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Evolving Customer Experience Management in Internet Service Provider Company using Text Analytics"
        ],
        "penulis":"Alamsyah, Andry;Bernatapi, Earlyan Abdiel;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Customer experience is of crucial significance to the constant growth of a business. It is necessary to ensure great customer experience, thus maintaining customer loyalty and satisfaction. An approach that intended to develop and improve customer experience is called Customer Experience Management (CEM). CEM is a strategy practiced to track, supervise, and arrange all synergy to help a business focal point on the needs of its customers. This research uses sentiment analysis and topic modeling to analyze the experience of Internet Service Provider customers. The output of this research expected to drive the strategies change in CEM. This research uses data taken from customer tweets on Twitter. It is considering that the data on social media is enormous and unstructured. Therefore, classification using Naive Bayes Classifier applied to assist and expedite in the sentiment analysis process. The classification for sentiment analysis using NBC gained accuracy above 82%. Hence, the classification models using NBC achieve excellent capability for sentiment analysis. To determining topics that often discussed by customers, this research uses the Latent Dirichlet Allocation models for Topic Modeling. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Customer experience is of crucial significance to the constant growth of a business. It is necessary to ensure great customer experience, thus maintaining customer loyalty and satisfaction. An approach that intended to develop and improve customer experience is called Customer Experience Management (CEM). CEM is a strategy practiced to track, supervise, and arrange all synergy to help a business focal point on the needs of its customers. This research uses sentiment analysis and topic modeling to analyze the experience of Internet Service Provider customers. The output of this research expected to drive the strategies change in CEM. This research uses data taken from customer tweets on Twitter. It is considering that the data on social media is enormous and unstructured. Therefore, classification using Naive Bayes Classifier applied to assist and expedite in the sentiment analysis process. The classification for sentiment analysis using NBC gained accuracy above 82%. Hence, the classification models using NBC achieve excellent capability for sentiment analysis. To determining topics that often discussed by customers, this research uses the Latent Dirichlet Allocation models for Topic Modeling. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Designing Procurement Process Monitoring Dashboard for Supporting Food Security Supply Chain Risk Management System in Indonesian Bureau of Logistics"
        ],
        "penulis":"Alfazah, Detha Aulia;Yanuar Ridwan, Ari;Yulianti, Femi;Artha Kusuma, Putu Giri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Rice as one of the main and important commodities because it can affect the economic stability in Indonesia. Indonesian Bureau of Logistics (BULOG) is a company under Indonesian Government which is responsible to manage the distribution of the Rice Commodity. BULOG Subdivre Bandung is one of the Regional Sub-Divisions located under the auspices of BULOG. Rice Commodity procurement process is the most crucial process. The high linkage of the supply chain network could make it suspectible with risk. If the procurement process of rice commodities BULOG disturbed can certainly affect the pillars of Food Security. Therefore, risk management and mitigation strategies are required in the procurement process. In this paper, strategy mitigation is formulated and monitoring dashboard is designed to maintain and monitorING the risks on procurement process of rice commodities using the Supply Chain Operation Reference (SCOR) Method, Failure Mode and Effect Analysis (FMEA) Method and Analytical Hierarchy Process(AHP). The result of the risk-identifying results gained in the field and interviews with experts there are 12 risk events and 16 risk causes divided by three pillars of food security and for mitigation strategies divided into 3 main causes with 3 Alternative to any major cause. The most risk event which should have mitigation first is low grain absorption with 0.55092 in AHP weighting. The designed monitoring dashboard was able to provide a compact summary and shows the risks which effect the pillars of Food Security. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentZero hungerGoal 2",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rice as one of the main and important commodities because it can affect the economic stability in Indonesia. Indonesian Bureau of Logistics (BULOG) is a company under Indonesian Government which is responsible to manage the distribution of the Rice Commodity. BULOG Subdivre Bandung is one of the Regional Sub-Divisions located under the auspices of BULOG. Rice Commodity procurement process is the most crucial process. The high linkage of the supply chain network could make it suspectible with risk. If the procurement process of rice commodities BULOG disturbed can certainly affect the pillars of Food Security. Therefore, risk management and mitigation strategies are required in the procurement process. In this paper, strategy mitigation is formulated and monitoring dashboard is designed to maintain and monitorING the risks on procurement process of rice commodities using the Supply Chain Operation Reference (SCOR) Method, Failure Mode and Effect Analysis (FMEA) Method and Analytical Hierarchy Process(AHP). The result of the risk-identifying results gained in the field and interviews with experts there are 12 risk events and 16 risk causes divided by three pillars of food security and for mitigation strategies divided into 3 main causes with 3 Alternative to any major cause. The most risk event which should have mitigation first is low grain absorption with 0.55092 in AHP weighting. The designed monitoring dashboard was able to provide a compact summary and shows the risks which effect the pillars of Food Security. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Optimization of heterogeneous sensor networks with clustering mechanism using game theory algorithm"
        ],
        "penulis":"Hendrarini, Nina;Asvial, Muhamad;Sari, Riri Fitri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Wireless sensor network is considered as the most applicable standards for the monitoring system. The optimization that relates to wireless sensor network planning, design, deployment, and operation has to consider many parameters so that there is no conflict among the sensor especially in a heterogenous network with various platforms. In such a network, energy consumption determines the system stability. Clustering mechanism in a wireless sensor network can also simplify network management process. Distributed energy efficient clustering (DEEC) is used as a clustering protocol. This protocol work based on residual energy. This protocol is robust enough, but in a certain condition, it has a pit of weakness. Game theory is being proposed as an optimization algorithm of the clustering process. It is used to adjust the probability of node to become a cluster head based on residual energy to prolong cluster lifetime. Threshold value can be more accurate by using selfish behavior game theory algorithm. The weighted factor is a factor that makes the resolution of probability values more real. \u00a9 2019 Association for Computing Machinery.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Wireless sensor network is considered as the most applicable standards for the monitoring system. The optimization that relates to wireless sensor network planning, design, deployment, and operation has to consider many parameters so that there is no conflict among the sensor especially in a heterogenous network with various platforms. In such a network, energy consumption determines the system stability. Clustering mechanism in a wireless sensor network can also simplify network management process. Distributed energy efficient clustering (DEEC) is used as a clustering protocol. This protocol work based on residual energy. This protocol is robust enough, but in a certain condition, it has a pit of weakness. Game theory is being proposed as an optimization algorithm of the clustering process. It is used to adjust the probability of node to become a cluster head based on residual energy to prolong cluster lifetime. Threshold value can be more accurate by using selfish behavior game theory algorithm. The weighted factor is a factor that makes the resolution of probability values more real. \u00a9 2019 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Analysis of Students Graduation Target Based on Academic Data Record Using C4.5 Algorithm Case Study: Information Systems Students of Telkom University"
        ],
        "penulis":"Putri, Dela Youlina;Andreswari, Rachmadita;Hasibuan, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Study program of Information Systems is one of the existing study programs at Telkom University which has produced many graduates until 2017. However, not all graduates produced successfully completed the study period during four years of normal study period in which may cause the decrease of study programs quality and affect the assessment of study program if there is an audit or evaluation so it can affect the achievement level of the study program. To solve the problem can be by making a prediction model of student graduation that can be obtained from data classification process using decision tree with algorithm C4.5 and implement it to the academic data record of existing student so that got two group of student, that is student which predicted pass on time and student predicted to pass late. From the results of the classification of student data can be done an analysis of what factors that can affect the graduation of students who are predicted to pass on time and plan appropriate strategies for groups of students who may not pass on time. The data classification process is done with the help of open source based tools using RapidMiner application. The result of the classification is a prediction model that has an accuracy value of 82.24% and states that the most influential factor in predicting students' graduation is GPA in the second year. The result of the student's graduation classification is expected to be used as the reference base to support the academic planner in making the right decision to the student groups generated so that all students can graduate on time. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Study program of Information Systems is one of the existing study programs at Telkom University which has produced many graduates until 2017. However, not all graduates produced successfully completed the study period during four years of normal study period in which may cause the decrease of study programs quality and affect the assessment of study program if there is an audit or evaluation so it can affect the achievement level of the study program. To solve the problem can be by making a prediction model of student graduation that can be obtained from data classification process using decision tree with algorithm C4.5 and implement it to the academic data record of existing student so that got two group of student, that is student which predicted pass on time and student predicted to pass late. From the results of the classification of student data can be done an analysis of what factors that can affect the graduation of students who are predicted to pass on time and plan appropriate strategies for groups of students who may not pass on time. The data classification process is done with the help of open source based tools using RapidMiner application. The result of the classification is a prediction model that has an accuracy value of 82.24% and states that the most influential factor in predicting students' graduation is GPA in the second year. The result of the student's graduation classification is expected to be used as the reference base to support the academic planner in making the right decision to the student groups generated so that all students can graduate on time. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Techno-economics study of spectrum sharing for mobile network operator in rural area: Study Case: Multi-Operator Core Network (MOCN) Band 1800 MHz"
        ],
        "penulis":"Hafiza, Lia;Reza, Muhamad;Mufti Adriansyah, Nachwan;Denny Setiawan, Ir.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Telecommunication is a sector regulated by the State because it uses limited natural resources namely frequency and to ensure the right of everyone to be able to communicate and obtain information in accordance with the constitution. In the other hand, the telecommunication industry which is predicted will decline in the future and needs to take precautions, there are two things that become solution; saving and entering new businesses. The solution discussed in this study is savings. More than 60% of Mobile Network Operators (MNO) in the world use Radio Access Network Sharing (RAN Sharing) to make savings. The type of RAN Sharing used in this study is the Multi-Operator Core Network (MOCN) that shared up to the frequency spectrum, and it can also be a solution to the scarcity of the spectrum, saving operator's expenses, accelerating network deployment to the regions and impacting on GDP in Indonesia. In this study, there are three aspects that will be discussed; technical, economic and legal aspects. In technical aspect, rural area use coverage dimensioning to determine the needs of telecommunication infrastructures. In the economic aspect, the calculation uses Net Present Value (NPV) which is analyzed using the Game Theory approach. For the legal aspect, several regulations in Indonesia related to spectrum sharing are explained to see the possibility of how this sharing can be implemented in Indonesia. Based on this research, sharing using MOCN may providing savings in rural areas and can affect competition between operators if only done by two competitors. In addition, in terms of regulations, this implementation is possible while obtaining ministerial permits but needs further study because there is a potential change in competition and double charge of usage rights fees (BHP).  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Telecommunication is a sector regulated by the State because it uses limited natural resources namely frequency and to ensure the right of everyone to be able to communicate and obtain information in accordance with the constitution. In the other hand, the telecommunication industry which is predicted will decline in the future and needs to take precautions, there are two things that become solution; saving and entering new businesses. The solution discussed in this study is savings. More than 60% of Mobile Network Operators (MNO) in the world use Radio Access Network Sharing (RAN Sharing) to make savings. The type of RAN Sharing used in this study is the Multi-Operator Core Network (MOCN) that shared up to the frequency spectrum, and it can also be a solution to the scarcity of the spectrum, saving operator's expenses, accelerating network deployment to the regions and impacting on GDP in Indonesia. In this study, there are three aspects that will be discussed; technical, economic and legal aspects. In technical aspect, rural area use coverage dimensioning to determine the needs of telecommunication infrastructures. In the economic aspect, the calculation uses Net Present Value (NPV) which is analyzed using the Game Theory approach. For the legal aspect, several regulations in Indonesia related to spectrum sharing are explained to see the possibility of how this sharing can be implemented in Indonesia. Based on this research, sharing using MOCN may providing savings in rural areas and can affect competition between operators if only done by two competitors. In addition, in terms of regulations, this implementation is possible while obtaining ministerial permits but needs further study because there is a potential change in competition and double charge of usage rights fees (BHP).  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Information System Architecture Planning with the Open Group Architecture Framework"
        ],
        "penulis":"Nugraha R.A.;Handoko Y.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose if this research is to develop a blueprint that can be used to build Information System Architecture that can integrate business and information technology with the aim of increasing the effectiveness and business efficiency of the company. The method used is TOGAF-ADM so that it is more flexible in verifying various types of modelling techniques used in designing information systems. The results of this study in the form of preliminary data collection from the TOGAF framework stage which in the future can be used for information system development that can be used at PT. Corocot Digital Creative. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose if this research is to develop a blueprint that can be used to build Information System Architecture that can integrate business and information technology with the aim of increasing the effectiveness and business efficiency of the company. The method used is TOGAF-ADM so that it is more flexible in verifying various types of modelling techniques used in designing information systems. The results of this study in the form of preliminary data collection from the TOGAF framework stage which in the future can be used for information system development that can be used at PT. Corocot Digital Creative. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Indicator Warning Refined Fuel Oil in A Motorcycle with Fuzzy Logic and Sound Navigaiotn through Smart Helmet"
        ],
        "penulis":"Rahman, Arif;Abdurohman, Maman;Putrada, Aji Gautama;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Even though the motorbike has a fuelmeter on its dashboard, breakdown incident due to run out of gasoline is still often encountered. This is a sign that the warning system provided by the motorbike is still insufficient. On the other hand research in the field of smart helmets is growing and advancing. This research proposes a fuel indicator that is mounted on the smart helmet. The indicator is in forms of voice warning. Fuelmeters are connected to buoys that are in the fuel tank. The buoy serves to detect the remaining fuel oil in the tank. In this design a combination of helmets and fuel oil detectors is carried out in the tank. When the fuel oil on the tank will run out, the helmet will produce output in the form of sound notification of the remaining fuel oil in the tank. In the oil fuel tank there are buoys to measure fuel levels, measurements made in this study using a microcontroller that is connected to a buoy. The microcontroller reads the current in the buoy, where when the fuel is full the voltage will be above 7 volts, when the half voltage level is between 5 volts - 7 volts and when it is almost gone or close to the voltage below 5 volts. When the fuel is half and runs out, the microcontroller in the tank will send a signal to the helmet to notify the level of available fuel. Helmets will receive signals from tank microcontrollers and helmets will provide output in the form of sound. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Even though the motorbike has a fuelmeter on its dashboard, breakdown incident due to run out of gasoline is still often encountered. This is a sign that the warning system provided by the motorbike is still insufficient. On the other hand research in the field of smart helmets is growing and advancing. This research proposes a fuel indicator that is mounted on the smart helmet. The indicator is in forms of voice warning. Fuelmeters are connected to buoys that are in the fuel tank. The buoy serves to detect the remaining fuel oil in the tank. In this design a combination of helmets and fuel oil detectors is carried out in the tank. When the fuel oil on the tank will run out, the helmet will produce output in the form of sound notification of the remaining fuel oil in the tank. In the oil fuel tank there are buoys to measure fuel levels, measurements made in this study using a microcontroller that is connected to a buoy. The microcontroller reads the current in the buoy, where when the fuel is full the voltage will be above 7 volts, when the half voltage level is between 5 volts - 7 volts and when it is almost gone or close to the voltage below 5 volts. When the fuel is half and runs out, the microcontroller in the tank will send a signal to the helmet to notify the level of available fuel. Helmets will receive signals from tank microcontrollers and helmets will provide output in the form of sound. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Removing Unvoiced Segment to Improve Text Independent Speaker Recognition"
        ],
        "penulis":"Ridha, Dzufiqar;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Speaker recognition is one of the biometric technologies to recognize humans, such as identification of fingerprints, DNA, and iris because the characteristics of human speech are unique. The characteristics of speech are dominated by voiced segment. Meanwhile, the unvoiced segments those commonly have random waveform can be seen as noise for the speaker recognition. Therefore, in this paper, a simple procedure to remove unvoiced parts is proposed to improve the accuracy. This procedure is simply implemented using the short time zero-crossing rate (STZCR) to detect and remove the unvoiced parts. It is applied before the Mel Frequency Cepstral Coefficients (MFCC)-based feature extraction and the Gaussian Mixture Model (GMM)-based classification. Evaluation on VoxForge dataset using 4-fold cross-validation show that the proposed procedure is capable of improving the accuracy from 99.94% to 100%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Speaker recognition is one of the biometric technologies to recognize humans, such as identification of fingerprints, DNA, and iris because the characteristics of human speech are unique. The characteristics of speech are dominated by voiced segment. Meanwhile, the unvoiced segments those commonly have random waveform can be seen as noise for the speaker recognition. Therefore, in this paper, a simple procedure to remove unvoiced parts is proposed to improve the accuracy. This procedure is simply implemented using the short time zero-crossing rate (STZCR) to detect and remove the unvoiced parts. It is applied before the Mel Frequency Cepstral Coefficients (MFCC)-based feature extraction and the Gaussian Mixture Model (GMM)-based classification. Evaluation on VoxForge dataset using 4-fold cross-validation show that the proposed procedure is capable of improving the accuracy from 99.94% to 100%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Seismic model estimation using particle swarm optimization"
        ],
        "penulis":"Liu, Bo;Mohandes, Mohamed;Nuha, Hilal;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Modern seismic data surveys generate terabytes of data daily leading to a significant increase of the cost for storage and transmission. Therefore, it is desired to compress seismic data. In this work, we propose a model-based compression scheme to deal with the large data volume. First, each seismic trace is modeled as a superposition of multiple exponentially decaying sinusoidal waves (EDSWs). Each EDSW represents a model component and is defined by a set of parameters. Secondly, a parameter estimation algorithm for this model is proposed using Particle Swarm Optimization (PSO) technique. In the proposed algorithm, the parameters of each EDSW are estimated sequentially wave by wave. A suitable number of model components for each trace is determined according to the level of the residuals energy. The proposed model based compression scheme is then experimentally compared with the discrete Cosine transform (DCT) on a real seismic data. The proposed model based algorithm outperforms the DCT in term of compression ratio and reconstruction quality. \u00a9 2018 SEG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Modern seismic data surveys generate terabytes of data daily leading to a significant increase of the cost for storage and transmission. Therefore, it is desired to compress seismic data. In this work, we propose a model-based compression scheme to deal with the large data volume. First, each seismic trace is modeled as a superposition of multiple exponentially decaying sinusoidal waves (EDSWs). Each EDSW represents a model component and is defined by a set of parameters. Secondly, a parameter estimation algorithm for this model is proposed using Particle Swarm Optimization (PSO) technique. In the proposed algorithm, the parameters of each EDSW are estimated sequentially wave by wave. A suitable number of model components for each trace is determined according to the level of the residuals energy. The proposed model based compression scheme is then experimentally compared with the discrete Cosine transform (DCT) on a real seismic data. The proposed model based algorithm outperforms the DCT in term of compression ratio and reconstruction quality. \u00a9 2018 SEG."
        ]
    },
    {
        "judul":[
            "The evaluation of finance module implementation of enterprise resource planning (ERP) for employee performance"
        ],
        "penulis":"Hafifah, Dayane Kamila;Witarsyah, Deden;Saputra, Muhardi;Azizah, Anik Hanifatul;Eka Saputri, Marhaeni;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Information technology can improve efficiency, effectiveness, and productivity that have an impact on individual performance. However, many companies don't have an integrated information system to support the activity. The process is only supported by individual activities on each site. This study aims to determine how the impact of the application and use of the System Applications and Product (SAP) on employee performance using Task Technology Fit (TTF) Model. Data collection methods used in this study are quantitative and qualitative methods. Data obtained based on the results of questionnaires involving 100 respondents and make some interviews with employee representatives in five divisions. Data is processed using Smart PLS and SPSS. The results of this study show a positive influence on the performance of employees who use the SAP system. The model developed by Goodhue and Thompson explains that the use and attitudes of users towards technology to support individual performance, the strengths of this model are emphasizing the importance of conformity between task and technology in its effect on performance. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information technology can improve efficiency, effectiveness, and productivity that have an impact on individual performance. However, many companies don't have an integrated information system to support the activity. The process is only supported by individual activities on each site. This study aims to determine how the impact of the application and use of the System Applications and Product (SAP) on employee performance using Task Technology Fit (TTF) Model. Data collection methods used in this study are quantitative and qualitative methods. Data obtained based on the results of questionnaires involving 100 respondents and make some interviews with employee representatives in five divisions. Data is processed using Smart PLS and SPSS. The results of this study show a positive influence on the performance of employees who use the SAP system. The model developed by Goodhue and Thompson explains that the use and attitudes of users towards technology to support individual performance, the strengths of this model are emphasizing the importance of conformity between task and technology in its effect on performance. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Human Machine Interface Design Analysis of Defect Detection Prototype by Wonderware InTouch Software"
        ],
        "penulis":"Mulyana, Tatang;Ibrahim, Rasidi;Abd Rahim, Erween;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Human Machine Interface (HMI) serves as a bridge for operators to understand the processes that occur on the machine. Without HMI, operators will have difficulty in monitoring and controlling the machine. HMI used in this study using Wonderware InTouch software. The HMI design that is used, displays the home button, as the start screen. There are two options in the home menu, which is the option to login as an identification and classification operator. To start operation and enter the monitoring window, any operator that uses this HMI must login using a username and password. The function of HMI in this research is as a connector between operators with machine. In this paper we have presented the human machine interface design of defect detection prototype by wonderware intouch software. Based on the tested results can be concluded that the designed is successfully. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Human Machine Interface (HMI) serves as a bridge for operators to understand the processes that occur on the machine. Without HMI, operators will have difficulty in monitoring and controlling the machine. HMI used in this study using Wonderware InTouch software. The HMI design that is used, displays the home button, as the start screen. There are two options in the home menu, which is the option to login as an identification and classification operator. To start operation and enter the monitoring window, any operator that uses this HMI must login using a username and password. The function of HMI in this research is as a connector between operators with machine. In this paper we have presented the human machine interface design of defect detection prototype by wonderware intouch software. Based on the tested results can be concluded that the designed is successfully. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Means of Engagement (MOE) Model of the Agreement towards the Enterprise Resource Planning (ERP) Implementation"
        ],
        "penulis":"Syafiera, Tsara;Lubis, Muharman;Witjaksono, R. Wahjoe;Anggana, Hilman Dwi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Faster economic development led to increasingly tight business competition. With the development of increasingly sophisticated technology, these companies compete in leveraging technology to enhance competitive advantage and efficiency of their company's performance compared to its competitors. ERP systems are already commonly used in large companies and companies that develop because it is considered can improve performance and can help the process efficiency of data each process in system performance for flow can be connected. ERP system implementation is not always running smoothly. When the company failed to perform some of the success factors of ERP implementation, then these companies will experience failure in implementation. Companies must have a good strategy to achieve the desired success. Business strategy is done by optimizing the company's internal resources and innovate to face competition with other companies. By applying an ERP system can help companies to keep up with changes in the business that would later show up to the new business requirements. By using the Means of Engagement (MOE) model concept, the company can know the things to be aware of and consider implementing ERP software, so that it can minimize the failures that will occur. There are three levels in the MOE model, namely Adoption, Approval, Acceptance, and Agreement. At the level of Agreement that can be used by the analysis of clustering. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Faster economic development led to increasingly tight business competition. With the development of increasingly sophisticated technology, these companies compete in leveraging technology to enhance competitive advantage and efficiency of their company's performance compared to its competitors. ERP systems are already commonly used in large companies and companies that develop because it is considered can improve performance and can help the process efficiency of data each process in system performance for flow can be connected. ERP system implementation is not always running smoothly. When the company failed to perform some of the success factors of ERP implementation, then these companies will experience failure in implementation. Companies must have a good strategy to achieve the desired success. Business strategy is done by optimizing the company's internal resources and innovate to face competition with other companies. By applying an ERP system can help companies to keep up with changes in the business that would later show up to the new business requirements. By using the Means of Engagement (MOE) model concept, the company can know the things to be aware of and consider implementing ERP software, so that it can minimize the failures that will occur. There are three levels in the MOE model, namely Adoption, Approval, Acceptance, and Agreement. At the level of Agreement that can be used by the analysis of clustering. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Prototype of Micro Reaction Wheel for Cubesat"
        ],
        "penulis":"Manggala F.H.;Ramadhan R.P.;Wijanto H.;Mayditia H.;Edwar, Edwar;Vidyaningtyas H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tel-USat is a Cubesat 1U which is designed to capture the Earth surface photograph using serial camera. To support the mission, an attitude control is needed such as Attitude and Determination Control Subsystem (ADCS). This spacecraft is designed with a Micro Reaction Wheel (MRW). This is a type of reaction wheel that has a small size which fit with cubesat dimension. It consists of flywheel attached to BLDC motor and Electronic Wheel Drive (WDE). The Micro Reaction Wheel has been designed to have a minimum speed of 64021rpm with a voltage of 8V and a duty cycle of 9.95% or 4.47% and the maximum speed with a rigid of 1, 9V and a 7.55% duty cycle or 6.69%. With these results, the Micro Reaction Wheel can generate a torque of 0.74 mNm. Consume battery energy at a maximum speed of 16,67 mAh\/minute. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tel-USat is a Cubesat 1U which is designed to capture the Earth surface photograph using serial camera. To support the mission, an attitude control is needed such as Attitude and Determination Control Subsystem (ADCS). This spacecraft is designed with a Micro Reaction Wheel (MRW). This is a type of reaction wheel that has a small size which fit with cubesat dimension. It consists of flywheel attached to BLDC motor and Electronic Wheel Drive (WDE). The Micro Reaction Wheel has been designed to have a minimum speed of 64021rpm with a voltage of 8V and a duty cycle of 9.95% or 4.47% and the maximum speed with a rigid of 1, 9V and a 7.55% duty cycle or 6.69%. With these results, the Micro Reaction Wheel can generate a torque of 0.74 mNm. Consume battery energy at a maximum speed of 16,67 mAh\/minute. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Item delivery simulation using genetic algorithm"
        ],
        "penulis":"Switrayana, I Nyoman;Osmond, Andrew Brian;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In sending items, time and costs can be minimized by selecting the shortest path. The problem of choosing the shortest path is often known as Travelling Salesman Problem (TSP). TSP in this study was not only concerned with distance but also the priority of places to be visited. Priority parameters in this research are a sign that each place has a value to be visited first than another place. This priority can also be assumed as a type of delivery service that can be chosen by the customer. Priority is divided into three groups, but it can also be more than that according to the needs of a shipping service provider. Delivery of multiple destinations in one area can be delivered with a single trip based on their priority. Search optimization of the shortest path is modeled with genetic algorithms. Hamilton path is the output of the simulation. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In sending items, time and costs can be minimized by selecting the shortest path. The problem of choosing the shortest path is often known as Travelling Salesman Problem (TSP). TSP in this study was not only concerned with distance but also the priority of places to be visited. Priority parameters in this research are a sign that each place has a value to be visited first than another place. This priority can also be assumed as a type of delivery service that can be chosen by the customer. Priority is divided into three groups, but it can also be more than that according to the needs of a shipping service provider. Delivery of multiple destinations in one area can be delivered with a single trip based on their priority. Search optimization of the shortest path is modeled with genetic algorithms. Hamilton path is the output of the simulation. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparison of Classical Interpolation Methods and Compressive Sensing for Missing Data Reconstruction"
        ],
        "penulis":"Usman, Koredianto;Ramdhani, Mohammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The emerging of a new compression technique called compressive sensing (CS) has opened various research possibility in many fields. Practically, CS consists of two main steps, which are compression step and reconstruction step. In many cases, the compression step occurs naturally, for example when several data is missing from the complete set of data. Reconstructing for complete data from incomplete data is the original aims of CS reconstruction process. It is therefore also a logical implication of CS as data interpolation method. Given this situation, a research of CS capability for data interpolation is not yet available. In this paper we investigate the capability of CS for data interpolation. Two popular CS reconstruction tools are used: orthogonal matching pursuit (OMP) and convex programming (CVX). We compared these CS reconstruction performance to the standard interpolation methods which are the linear interpolation and spline interpolation. Simulation results show that classical interpolation methods have better performance in term of general accuracy, while CS reconstruction method has advantage on accuracy in reconstructing data that has sharp changes. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The emerging of a new compression technique called compressive sensing (CS) has opened various research possibility in many fields. Practically, CS consists of two main steps, which are compression step and reconstruction step. In many cases, the compression step occurs naturally, for example when several data is missing from the complete set of data. Reconstructing for complete data from incomplete data is the original aims of CS reconstruction process. It is therefore also a logical implication of CS as data interpolation method. Given this situation, a research of CS capability for data interpolation is not yet available. In this paper we investigate the capability of CS for data interpolation. Two popular CS reconstruction tools are used: orthogonal matching pursuit (OMP) and convex programming (CVX). We compared these CS reconstruction performance to the standard interpolation methods which are the linear interpolation and spline interpolation. Simulation results show that classical interpolation methods have better performance in term of general accuracy, while CS reconstruction method has advantage on accuracy in reconstructing data that has sharp changes. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design Autonomous Drone Control for Monitoring Tea Plantation Using Dynamic Programming and Kruskal Algorithm"
        ],
        "penulis":"Wirabudi, Andri Agustav;Munadi, Rendy;Rusdinar, Angga;Rohdiana, Dadan;Lee, Dong Ho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia is a country with the largest tea producers in the world, with a very large area needed tools to be able to help monitor the area of tea plantations as a whole. Unmanned Aerial Vehicle (UAV) wash chosen as a solution for the monitoring proses. Optimum flight path calculation is needed in order to produce good quality images, and also it influence to power consumption. The algorithm proposed in this study is Dynamic Programming and Kruskal Algorithm. Implementing these two network algorithms is expected to find the optimal path in aerial photography. The experimental results showed that the algorithm produced the optimum path, and more efficient power consumption than conventional lines. Image data obtained during tea plantation monitoring produced high-quality images, with the accuracy of each map above 90% and the assumption of errors below 5%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is a country with the largest tea producers in the world, with a very large area needed tools to be able to help monitor the area of tea plantations as a whole. Unmanned Aerial Vehicle (UAV) wash chosen as a solution for the monitoring proses. Optimum flight path calculation is needed in order to produce good quality images, and also it influence to power consumption. The algorithm proposed in this study is Dynamic Programming and Kruskal Algorithm. Implementing these two network algorithms is expected to find the optimal path in aerial photography. The experimental results showed that the algorithm produced the optimum path, and more efficient power consumption than conventional lines. Image data obtained during tea plantation monitoring produced high-quality images, with the accuracy of each map above 90% and the assumption of errors below 5%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A multi-label classification on topics of Indonesian news using K-Nearest Neighbor"
        ],
        "penulis":"Isnaini, Nikmah;Adiwijaya;Mubarok, Mohamad Syahrul;Bakar, Muhammad Yuslan Abu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "News has become a basic human need along with technological and internet developments. This causes the process of disseminating information on the news that switched from print media to the digital era. Another problem that appears when classifying news is multi-label. Multi-label classification is different from single label classification. A single label classification will classify documents into one label only. While multi-label classification can group documents into more than one label. For example, news articles that discuss in detail the early detection of ovarian cancer with a bioinformatics approach may have more than one label such as health, bioinformatics, and women. In this paper, a classification model is developed that can identify classes in each multi-label news article using K-Nearest Neighbor. The advantages of K-Nearest Neighbor are algorithms that are very suitable for multi-label cases; even KNN can be superior to other classifiers. From the system created, the results of the value of system performance as measured by the size of the closeness are the comparison between Manhattan Distance, Euclidean Distance and Supremum Distance using the K = 11 parameters, resulting in a Hamming Loss value of 11.16.%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "News has become a basic human need along with technological and internet developments. This causes the process of disseminating information on the news that switched from print media to the digital era. Another problem that appears when classifying news is multi-label. Multi-label classification is different from single label classification. A single label classification will classify documents into one label only. While multi-label classification can group documents into more than one label. For example, news articles that discuss in detail the early detection of ovarian cancer with a bioinformatics approach may have more than one label such as health, bioinformatics, and women. In this paper, a classification model is developed that can identify classes in each multi-label news article using K-Nearest Neighbor. The advantages of K-Nearest Neighbor are algorithms that are very suitable for multi-label cases; even KNN can be superior to other classifiers. From the system created, the results of the value of system performance as measured by the size of the closeness are the comparison between Manhattan Distance, Euclidean Distance and Supremum Distance using the K = 11 parameters, resulting in a Hamming Loss value of 11.16.%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Quality of service (QoS) comparison analysis of snort IDS and Bro IDS application in software define network (SDN) architecture"
        ],
        "penulis":"Hendrawan, Hendrawan;Sukarno, Parman;Nugroho, Muhammad Arief;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Intrusion Detection system (IDS) was an application which was aimed to monitor network activity or system and it could find if there was a dangerous operation. Implementation of IDS on Software Define Network architecture (SDN) has drawbacks. IDS on SDN architecture might decreasing network Quality of Service (QoS). So the network could not provide services to the existing network traffic. Throughput, delay and packet loss were important parameters of QoS measurement. Snort IDS and bro IDS were tools in the application of IDS on the network. Both had differences, one of which was found in the detection method. Snort IDS used a signature based detection method while bro IDS used an anomaly based detection method. The difference between them had effects in handling the network traffic through it. In this research, we compared both tools. This comparison are done with testing parameters such as throughput, delay, packet loss, CPU usage, and memory usage. From this test, it was found that bro outperform snort IDS for throughput, delay, and packet loss parameters. However, CPU usage and memory usage on bro requires higher resource than snort. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Intrusion Detection system (IDS) was an application which was aimed to monitor network activity or system and it could find if there was a dangerous operation. Implementation of IDS on Software Define Network architecture (SDN) has drawbacks. IDS on SDN architecture might decreasing network Quality of Service (QoS). So the network could not provide services to the existing network traffic. Throughput, delay and packet loss were important parameters of QoS measurement. Snort IDS and bro IDS were tools in the application of IDS on the network. Both had differences, one of which was found in the detection method. Snort IDS used a signature based detection method while bro IDS used an anomaly based detection method. The difference between them had effects in handling the network traffic through it. In this research, we compared both tools. This comparison are done with testing parameters such as throughput, delay, packet loss, CPU usage, and memory usage. From this test, it was found that bro outperform snort IDS for throughput, delay, and packet loss parameters. However, CPU usage and memory usage on bro requires higher resource than snort. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A review of edge image detection for marker-based augmented reality"
        ],
        "penulis":"Pandiangan, Samuel P.A.H.;Purboyo, Tito Waluyo;Saputra, Randy Erfa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The earlier way to do an image detecting is to use edge image detection. Edge image detection is using some kind of mathematical expression to detect the boundaries between objects between images in real world, with media like camera phone. Many aspects have used edge image detection, one of them is Augmented Reality, especially marker-based Augmented Reality. Augmented reality used edge image detection for reading and detecting the marker in real world and transfer the data to the database in application. This paper will review how the edge detection works and how it works in Augmented Reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The earlier way to do an image detecting is to use edge image detection. Edge image detection is using some kind of mathematical expression to detect the boundaries between objects between images in real world, with media like camera phone. Many aspects have used edge image detection, one of them is Augmented Reality, especially marker-based Augmented Reality. Augmented reality used edge image detection for reading and detecting the marker in real world and transfer the data to the database in application. This paper will review how the edge detection works and how it works in Augmented Reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Implementation of python source code comparison results with Java using bubble sort method"
        ],
        "penulis":"Insanudin E.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the implementation of Python and Java source code comparison results are more focused on the scale of the ratio of the number of lines of code, file capacity, and access speed. As for the background of this writing because there are so many programming languages that can be used with the same results but overall we do not know which programming language is more optimal and efficient in terms of the number of lines of code better known in the programming language is LOC (Line of Code) capacity of file access speed. In this study, the authors focus only on Java programming language and python course as a first step to know the ratio of the number of lines of code, file capacity, and access density. To determine the comparison there is a method used is bubble short. The results of the implementation of the comparison of these programming languages for Python programming language to produce the number of LOC (line of code) or the number of lines of code as much as 10, the capacity of the file extension.py by 506 bytes and txt extension of 397 bytes and access speed approximately for less more 4 seconds. While Java produces the number of LOC (line of code) or the number of lines of code as much as 11, the capacity of the file extension. Java of 86.2 Kbytes and extension txt of 477 bytes and access speed for 7 seconds. So do not close the possibility to make other applications python programming language will be more optimal and efficient. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the implementation of Python and Java source code comparison results are more focused on the scale of the ratio of the number of lines of code, file capacity, and access speed. As for the background of this writing because there are so many programming languages that can be used with the same results but overall we do not know which programming language is more optimal and efficient in terms of the number of lines of code better known in the programming language is LOC (Line of Code) capacity of file access speed. In this study, the authors focus only on Java programming language and python course as a first step to know the ratio of the number of lines of code, file capacity, and access density. To determine the comparison there is a method used is bubble short. The results of the implementation of the comparison of these programming languages for Python programming language to produce the number of LOC (line of code) or the number of lines of code as much as 10, the capacity of the file extension.py by 506 bytes and txt extension of 397 bytes and access speed approximately for less more 4 seconds. While Java produces the number of LOC (line of code) or the number of lines of code as much as 11, the capacity of the file extension. Java of 86.2 Kbytes and extension txt of 477 bytes and access speed for 7 seconds. So do not close the possibility to make other applications python programming language will be more optimal and efficient. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "First evidence of the presence of genotype-1 of Japanese encephalitis virus in Culex gelidus in Indonesia"
        ],
        "penulis":"Garjito, Triwibowo Ambar;Prihatin, Mega Tyas;Susanti, Lulus;Prastowo, Dhian;Sa'Adah, Siti Rofiatus;Taviv, Yulian;Satoto, Tri Baskoro Tunggul;Waluyo, Joko;Manguin, Sylvie;Frutos, Roger;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Background: Japanese encephalitis has become a public health threat in Indonesia. Three genotypes have been recorded in Indonesia, i.e. genotype II (GII), genotype III (GIII) and genotype IV (GIV). Genotype I (GI) and genotype V (GV) have never been reported in Indonesia. Results: A Japanese encephalitis virus (JEV) belonging to the genotype I-a (GI-a) has been isolated for the first time from a Culex gelidus mosquito in the Province of Jambi, Indonesia. This virus is related to a 1983 isolate from Thailand whereas the infected Cx. gelidus mosquito belonged to a Chinese haplotype. Conclusions: Surveillance of JEV and mosquito dissemination is recommended. \u00a9 2019 The Author(s).",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Background: Japanese encephalitis has become a public health threat in Indonesia. Three genotypes have been recorded in Indonesia, i.e. genotype II (GII), genotype III (GIII) and genotype IV (GIV). Genotype I (GI) and genotype V (GV) have never been reported in Indonesia. Results: A Japanese encephalitis virus (JEV) belonging to the genotype I-a (GI-a) has been isolated for the first time from a Culex gelidus mosquito in the Province of Jambi, Indonesia. This virus is related to a 1983 isolate from Thailand whereas the infected Cx. gelidus mosquito belonged to a Chinese haplotype. Conclusions: Surveillance of JEV and mosquito dissemination is recommended. \u00a9 2019 The Author(s)."
        ]
    },
    {
        "judul":[
            "Noise Removal in Mild Cognitive Impairment EEG Recording using Empirical Mode Decomposition"
        ],
        "penulis":"Hadiyoso, Sugondo;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "EEG signals contain large amounts of random noise, such as artifacts and baseline changes. These noises appear at low frequencies, which may disturb the real activity of the EEG signal. Visual observation method often used to mark then removing the noise. However, this conventional method takes much time, requires experts to do the annotation, and has a huge possibility of error. One method that can be used to remove this interference is Empirical Mode Decomposition (EMD). EMD produces two essential parts of the signal, namely intrinsic mode function (IMF) and residue. This study applies EMD to remove artifacts that are present in EEG signals. The performance measured by calculating the RMSE and spectral power. From the test, obtained the average value of RMSE 0.0295 and signal power at frequencies below 1 Hz is 0.004 dB. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "EEG signals contain large amounts of random noise, such as artifacts and baseline changes. These noises appear at low frequencies, which may disturb the real activity of the EEG signal. Visual observation method often used to mark then removing the noise. However, this conventional method takes much time, requires experts to do the annotation, and has a huge possibility of error. One method that can be used to remove this interference is Empirical Mode Decomposition (EMD). EMD produces two essential parts of the signal, namely intrinsic mode function (IMF) and residue. This study applies EMD to remove artifacts that are present in EEG signals. The performance measured by calculating the RMSE and spectral power. From the test, obtained the average value of RMSE 0.0295 and signal power at frequencies below 1 Hz is 0.004 dB. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Room Map Estimation from Two-Dimensional Lidar's Point Cloud Data"
        ],
        "penulis":"Satyawan, Arief Suryadi;Kurniawan, Dayat;Armi, Nasrullah;Wijayanto, Yusuf Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "An automatic digital map estimation is not only essential for the repository of the architectural plans but also crucial for providing clear paths for a trajectory finder system, an autonomous vehicle, or a robot. Therefore, it is useful for reconstructing heritage buildings or finding a location lying in ruin after an earthquake. Rebuilding a digital map of a room can be done by using information from two-dimensional (2D) images. However, it seems to be complicated to obtain an accurate dimension directly from those images. One potential breakthrough is to make use of light detecting and ranging (LIDAR) technology. This state-of-the-art device can detect the solid surface of an object, as well as presenting an easiness of the distance measurements. This research focused on the reconstruction of a room map by utilizing 2D point cloud data obtained from a Lidar device. The results showed that by applying the conditioned random sample consensus (RANSAC) method, the 2D map of a room could be identified accurately from the 2D point cloud data. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An automatic digital map estimation is not only essential for the repository of the architectural plans but also crucial for providing clear paths for a trajectory finder system, an autonomous vehicle, or a robot. Therefore, it is useful for reconstructing heritage buildings or finding a location lying in ruin after an earthquake. Rebuilding a digital map of a room can be done by using information from two-dimensional (2D) images. However, it seems to be complicated to obtain an accurate dimension directly from those images. One potential breakthrough is to make use of light detecting and ranging (LIDAR) technology. This state-of-the-art device can detect the solid surface of an object, as well as presenting an easiness of the distance measurements. This research focused on the reconstruction of a room map by utilizing 2D point cloud data obtained from a Lidar device. The results showed that by applying the conditioned random sample consensus (RANSAC) method, the 2D map of a room could be identified accurately from the 2D point cloud data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Engaging customer experience in accelerating transformational performance through co-creation strategy"
        ],
        "penulis":"Alamsjah, Firdaus;Mihardjo, Leonardus W Wasono;Djoemadic, Faizal R.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Disruptive innovation shifts strategy from competition to collaboration. The collaboration with customers is also known as co-creation strategy and predominantly drives transformational performance. Transformational performance is based on performance management theory and transformation paradigms. However, its development to ensure the works of co-creation strategy, based on customer experience, remains unclear. To address this gap the digital transformational model based on co-creation strategy, with a focus on customer experience, was investigated to accelerate transformational performance. This study uses quantitative research, with a sample of 35 representatives from telecommunication firms. The findings demonstrate that co-creation strategy significantly supports customer experience, in driving transformational performance. Customer experience also appears to significantly impact co-creation strategy indirectly. The findings have theoretical implications for the emergence of collaboration strategy in the disruptive era. They show practitioners how co-creation strategy is becoming key in sustaining the business, as it shifts the focus onto the development of customer experience to drive transformational performance. Suggestions for future research are also included in the study. \u00a9 2019 Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Disruptive innovation shifts strategy from competition to collaboration. The collaboration with customers is also known as co-creation strategy and predominantly drives transformational performance. Transformational performance is based on performance management theory and transformation paradigms. However, its development to ensure the works of co-creation strategy, based on customer experience, remains unclear. To address this gap the digital transformational model based on co-creation strategy, with a focus on customer experience, was investigated to accelerate transformational performance. This study uses quantitative research, with a sample of 35 representatives from telecommunication firms. The findings demonstrate that co-creation strategy significantly supports customer experience, in driving transformational performance. Customer experience also appears to significantly impact co-creation strategy indirectly. The findings have theoretical implications for the emergence of collaboration strategy in the disruptive era. They show practitioners how co-creation strategy is becoming key in sustaining the business, as it shifts the focus onto the development of customer experience to drive transformational performance. Suggestions for future research are also included in the study. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Radar Software Development for the Surveillance of Indonesian Aerospace Sovereignty"
        ],
        "penulis":"Saputera, Yussi Perdana;Sulistyaningsih;Wahab, Mashury;Estu, Topik Teguh;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, design and development of air surveillance radar software using QT creator application is presented. The software manufacture was performed in two stages, where the first stage is to design a flowchart and the second stage is to create the program using codes. Radar software must be integrated with hardware to display the results of the target detection. All detection results will be shown on the plan position indicator (PPI) display. From the detection results, all flying objects that can reflect radar signals will be shown in the display, i.e., airplanes, clouds, birds, mountains, tall buildings, as long as they are still in the radar detection range. The radar software has been tested with very significant good results. To only see moving objects such as high-speed aircrafts, moving target indicator (MTI) feature is enabled. The radar software was shown to be able to track objects and to create guard zones feature as an observation area. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, design and development of air surveillance radar software using QT creator application is presented. The software manufacture was performed in two stages, where the first stage is to design a flowchart and the second stage is to create the program using codes. Radar software must be integrated with hardware to display the results of the target detection. All detection results will be shown on the plan position indicator (PPI) display. From the detection results, all flying objects that can reflect radar signals will be shown in the display, i.e., airplanes, clouds, birds, mountains, tall buildings, as long as they are still in the radar detection range. The radar software has been tested with very significant good results. To only see moving objects such as high-speed aircrafts, moving target indicator (MTI) feature is enabled. The radar software was shown to be able to track objects and to create guard zones feature as an observation area. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Classification of premature ventricular contraction based on ECG signal using multiorder r\u00e9nyi entropy"
        ],
        "penulis":"Rizal, Achmad;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electrocardiogram (ECG) signals are commonly used to analyze the heart abnormalities. Many researchers used this method due to the simplicity, inexpensive, and the non-invasiveness of the devices. The basic concept of ECG is by measuring the electrical activity of the heart using non-invasive electrodes placed in the body. Premature ventricular contraction (PVC) is one of the abnormalities of the human heart which produce extra heartbeat that started in the two lower ventricles. This 'additional' heartbeat disrupts the regular heart rhythm. Early detection for PVC is essential, so in this research, we classify the PVC from ECG signal by using multi-order R\u00e9nyi entropy as the feature extraction, and SVM as the classifier. We search for the optimum feature number needed for the detection system. Our proposed method showed a promising result, because we only use one feature extraction parameter, that is R\u00e9nyi entropy, as the only feature which calculated in the different orders, and this made the computing complexity low. We got 95.8% of accuracy using six characteristics of entropy for PVC and normal ECG classification. Our proposed method was simple, low computation and need fewer number of features. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electrocardiogram (ECG) signals are commonly used to analyze the heart abnormalities. Many researchers used this method due to the simplicity, inexpensive, and the non-invasiveness of the devices. The basic concept of ECG is by measuring the electrical activity of the heart using non-invasive electrodes placed in the body. Premature ventricular contraction (PVC) is one of the abnormalities of the human heart which produce extra heartbeat that started in the two lower ventricles. This 'additional' heartbeat disrupts the regular heart rhythm. Early detection for PVC is essential, so in this research, we classify the PVC from ECG signal by using multi-order R\u00e9nyi entropy as the feature extraction, and SVM as the classifier. We search for the optimum feature number needed for the detection system. Our proposed method showed a promising result, because we only use one feature extraction parameter, that is R\u00e9nyi entropy, as the only feature which calculated in the different orders, and this made the computing complexity low. We got 95.8% of accuracy using six characteristics of entropy for PVC and normal ECG classification. Our proposed method was simple, low computation and need fewer number of features. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The effect of implementing resonator-interdigital capacitor and Complementary Split Ring Resonator (CSRR) on MIMO antenna"
        ],
        "penulis":"Janat, Tiara Resa Mano;Astuti, Rina Pudji;Nugroho, Bambang Setia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indoor Wi-Fi networks with 4G and 5G technology can work properly on wide coverage for high data rate services. Existing Wi-Fi devices need to implement Multiple-Input Multiple-Output (MIMO) antenna technology to provide high data rate. However, the antenna bandwidth and gain are relatively small. On previous research, the MIMO antennas with Resonator and Interdigital Capacitor have wide bandwidth, but gain of the antennas is low. In previous research, Complementary Split Ring Resonator (CSRR) on MIMO antennas provides high gain but the bandwidth decreases. This paper proposes an 2x2 MIMO monopole antenna design at 2.4 GHz for indoor Wi-Fi that implementing two combined methods, i.e., Resonator-Interdigital Capacitor with CSRR to improve the antenna performances. The idea is the addition of Resonators and Interdigital Capacitors is to increase the bandwidth, while CSRR is added to increase gain. The results show the proposed antenna has better return loss and decoupling values of 0.323 dB and 2.359 dB, respectively. The bandwidth and gain of the proposed antenna increase by 73.7 MHz and 0.361 dB, respectively when compared to Resonator Interdigital Capacitor MIMO antenna. The proposed antenna has return loss of-17.784 dB and decoupling value of-12.871 dB at 2.4 GHz, with the bandwidth of 644.3 MHz and gain of 1.996 dB. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indoor Wi-Fi networks with 4G and 5G technology can work properly on wide coverage for high data rate services. Existing Wi-Fi devices need to implement Multiple-Input Multiple-Output (MIMO) antenna technology to provide high data rate. However, the antenna bandwidth and gain are relatively small. On previous research, the MIMO antennas with Resonator and Interdigital Capacitor have wide bandwidth, but gain of the antennas is low. In previous research, Complementary Split Ring Resonator (CSRR) on MIMO antennas provides high gain but the bandwidth decreases. This paper proposes an 2x2 MIMO monopole antenna design at 2.4 GHz for indoor Wi-Fi that implementing two combined methods, i.e., Resonator-Interdigital Capacitor with CSRR to improve the antenna performances. The idea is the addition of Resonators and Interdigital Capacitors is to increase the bandwidth, while CSRR is added to increase gain. The results show the proposed antenna has better return loss and decoupling values of 0.323 dB and 2.359 dB, respectively. The bandwidth and gain of the proposed antenna increase by 73.7 MHz and 0.361 dB, respectively when compared to Resonator Interdigital Capacitor MIMO antenna. The proposed antenna has return loss of-17.784 dB and decoupling value of-12.871 dB at 2.4 GHz, with the bandwidth of 644.3 MHz and gain of 1.996 dB. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Facial recognition technique with combination method of local binary pattern histogram and image euclidean distance"
        ],
        "penulis":"Erwin;Saparudin;Fachrurrozi M.;Tamaarsa, Alvin;Zhang, Andy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to determine the level of precision, recall, and accuracy of performance of local binary pattern histogram and image euclidean distance for face image recognition. This research uses local binary pattern histogram method for segmenting face image and euclidean distance image for face image recognition. The proposed method started with the process of converting pixel value into a binary value, which then the value is used as a decimal value and the histogram is calculated, for then saved in the database. The trained facial image histogram will be compared with the histogram of the test data using the euclidean distance image formula. The result of this research shows realtime test result get 0.699 recall value and 0.7 precision value. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to determine the level of precision, recall, and accuracy of performance of local binary pattern histogram and image euclidean distance for face image recognition. This research uses local binary pattern histogram method for segmenting face image and euclidean distance image for face image recognition. The proposed method started with the process of converting pixel value into a binary value, which then the value is used as a decimal value and the histogram is calculated, for then saved in the database. The trained facial image histogram will be compared with the histogram of the test data using the euclidean distance image formula. The result of this research shows realtime test result get 0.699 recall value and 0.7 precision value. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Face expression recognition using Local Gabor Binary Pattern Three Orthogonal Planes (LGBP-TOP) and Support Vector Machine (SVM) method"
        ],
        "penulis":"Dewi R.R.K.;Sthevanie F.;Arifianto A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The video expression recognition system has been created before using the Local Gabor Binary Pattern Three Orthogonal Planes (LGBP-TOP) extraction method and the Support Vector Machine (SVM) classifi-cation method. However, the recognizable facial expressions use the entire area of the face image, while the expression can be recognized from the change of face fiducial point on the eyes and lips only. In this study, the introduction of facial expressions was developed using LGBP-TOP and SVM methods by focusing on facial and lip images only. Therefore, an algorithm is needed to extract the eye and lip area of the face ima-ge using 3x3 blocks and 4x4 blocks, which will then be used as input on the LGBP-TOP method. After the image of the eyes and lips extracted its features, the extraction results are classified using the SVM method. The results obtained is the recognition of facial expressions using the eye and lip area get 80% accuracy and better than using the entire area of the face, eye area only, and lip area only. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The video expression recognition system has been created before using the Local Gabor Binary Pattern Three Orthogonal Planes (LGBP-TOP) extraction method and the Support Vector Machine (SVM) classifi-cation method. However, the recognizable facial expressions use the entire area of the face image, while the expression can be recognized from the change of face fiducial point on the eyes and lips only. In this study, the introduction of facial expressions was developed using LGBP-TOP and SVM methods by focusing on facial and lip images only. Therefore, an algorithm is needed to extract the eye and lip area of the face ima-ge using 3x3 blocks and 4x4 blocks, which will then be used as input on the LGBP-TOP method. After the image of the eyes and lips extracted its features, the extraction results are classified using the SVM method. The results obtained is the recognition of facial expressions using the eye and lip area get 80% accuracy and better than using the entire area of the face, eye area only, and lip area only. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Derivation of Matrix Transformation from Pixel Coordinates to Real-World Coordinates for Vehicle Trajectory Tracking"
        ],
        "penulis":"Mardiati, Rina;Mulyana, Edi;Maryono, Iyon;Usman, Koredianto;Priatna, Tedi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Lately, the issue of coordinate transformation has gained interest from surveyors, GIS experts, remote-sensing practitioners and especially many researchers in transportation studies. In transportation studies, coordinate transformation is important for modelling vehicle trajectories. The trajectory of a vehicle can be obtained through traffic data. Traffic data are commonly collected from a video camera fixed at an elevated position to record traffic flow. In order to display the data coordinates as if they were taken from a top-view angle, coordinate transformation is needed. The most widely applied methods of coordinate transformation are generally being developed. Mostly, existing methods have complex computation and a large number of parameters. Naturally, complex transformations with a large number of parameters (sometimes with high-order terms that are not linear) are more accurate but introduce more distortions and deformations into the data. In this paper, a novel coordinate transformation for mapping the coordinates between video images and the real world based on a mathematical approach is proposed. The proposed coordinate transformation method was written using a matrix equation. This matrix transformation is a function of several parameters, i.e. the camera's pixels, the camera's height from the ground, and the actual width and length of the road recorded on camera. Experiments were designed to verify the proposed method, which was applied to vehicle movement tracking. The results showed that the proposed matrix transformation can correctly transform pixel coordinates to real-world coordinates with a simpler calculation and fewer parameters than existing methods. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Lately, the issue of coordinate transformation has gained interest from surveyors, GIS experts, remote-sensing practitioners and especially many researchers in transportation studies. In transportation studies, coordinate transformation is important for modelling vehicle trajectories. The trajectory of a vehicle can be obtained through traffic data. Traffic data are commonly collected from a video camera fixed at an elevated position to record traffic flow. In order to display the data coordinates as if they were taken from a top-view angle, coordinate transformation is needed. The most widely applied methods of coordinate transformation are generally being developed. Mostly, existing methods have complex computation and a large number of parameters. Naturally, complex transformations with a large number of parameters (sometimes with high-order terms that are not linear) are more accurate but introduce more distortions and deformations into the data. In this paper, a novel coordinate transformation for mapping the coordinates between video images and the real world based on a mathematical approach is proposed. The proposed coordinate transformation method was written using a matrix equation. This matrix transformation is a function of several parameters, i.e. the camera's pixels, the camera's height from the ground, and the actual width and length of the road recorded on camera. Experiments were designed to verify the proposed method, which was applied to vehicle movement tracking. The results showed that the proposed matrix transformation can correctly transform pixel coordinates to real-world coordinates with a simpler calculation and fewer parameters than existing methods. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Method to estimate the temperature drop in hot fluid flow using empirical equation with experimental comparison: Case study of horizontal pipe"
        ],
        "penulis":"Rianti, Arinta;Ajiwiguna, Tri Ayodha;Ramdlan Kirom M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The piping system is used in the industry as a fluid distribution method. The temperature of hot fluid should be maintained with a certain tolerance. In the process of distribution, temperature decreasing occurs due heat loss. However, calculations of convection heat transfer by empirical equations can only be applied for constant temperature surface. In this study the calculation is performed by numerically making partitions along pipe to estimate the temperature profile along the pipe. To verify this estimation, piping configuration to stream the hot water on horizontal pipe is constructed. The dimension of pipe is 0.5 inch diameter and 1 m length. The experiment is carried out under the condition of the pipe with some various inlet temperature from 40oC to 60oC and thermal insulation thickness from 0 cm to 1.5 cm. The result shows that the calculation and experimental method have the same traits in which the temperature decreasing is minimum at the thickest insulation layer. The maximum temperature difference at the outlet pipe between the two methods is 3.2oC. The heat loss is also observed to be minimum in the lower water temperature inlet. Based on the experimental method, the maximum heat loss reduction is achieved at 63% between without insulation and 1.5 cm insulation thickness with 60oC inlet water temperature. However the change of heat loss reduction become more insignificant for thicker insulation layer.                          \u00a9 2019 American Institute of Physics Inc. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The piping system is used in the industry as a fluid distribution method. The temperature of hot fluid should be maintained with a certain tolerance. In the process of distribution, temperature decreasing occurs due heat loss. However, calculations of convection heat transfer by empirical equations can only be applied for constant temperature surface. In this study the calculation is performed by numerically making partitions along pipe to estimate the temperature profile along the pipe. To verify this estimation, piping configuration to stream the hot water on horizontal pipe is constructed. The dimension of pipe is 0.5 inch diameter and 1 m length. The experiment is carried out under the condition of the pipe with some various inlet temperature from 40oC to 60oC and thermal insulation thickness from 0 cm to 1.5 cm. The result shows that the calculation and experimental method have the same traits in which the temperature decreasing is minimum at the thickest insulation layer. The maximum temperature difference at the outlet pipe between the two methods is 3.2oC. The heat loss is also observed to be minimum in the lower water temperature inlet. Based on the experimental method, the maximum heat loss reduction is achieved at 63% between without insulation and 1.5 cm insulation thickness with 60oC inlet water temperature. However the change of heat loss reduction become more insignificant for thicker insulation layer.                          \u00a9 2019 American Institute of Physics Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "A new variant of Game Theory based Decision Making (GTDM) algorithm routing protocols to improve energy efficiency on vehicular delay tolerant network (VDTN)"
        ],
        "penulis":"Triadi, Muhammad Biben;Perdana, Doan;Munadi, Rendy;Wenzao, Li;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "These days, the application of Delay Tolerant Networks (DTN) have been expanded into various scenarios of communications field. Vehicular Ad hoc Networks (VANETs) as a communication scenario which treat its subject to disruption and disconnection with frequent partitioning and high latency. Therefore, Vehicular Delay Tolerant Network (VDTN) is introduced as a new research paradigm due to several characteristics match according to specific prerequisites. DTNs is proposed in Vehicular Network because its mechanisms which is using store-carry-forward, can be implemented to deliver the packets, without end-to-end connection, to the destination. One of challenging research of DTN in routing protocol is to meet prerequisites of many applications, especially in vehicular network (VDTN). This paper presents a new variant of Game Theory based on Decision Making (GTDM) that can deliver packet to static node due to improve the energy efficiency of DTNs in city environments. Hence, its destination node (Receiver Node) needs to go to the static node to take their packet under Working Day Movement (WDM), because relay node will be passing by the static node with continuously move to its track to deliver packet. In this paper author will analyze the new variant of GTDM (NVGTDM) which can be more useful than original GTDM for application in city environment with using transportation movement. We conclude that modification of GTDM routing algorithm (NVGTDM) improves energy efficiency as much as 10.38% than the original GTDM. Hence, it can be ensured to compare either to Epidemic or PRoPHET routing algorithm with 55.44% and 68.75% in rates of energy efficiency respectively. \u00a9 2019 Kohat University of Science and Technology.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document"
        ],
        "abstrak":[
            "These days, the application of Delay Tolerant Networks (DTN) have been expanded into various scenarios of communications field. Vehicular Ad hoc Networks (VANETs) as a communication scenario which treat its subject to disruption and disconnection with frequent partitioning and high latency. Therefore, Vehicular Delay Tolerant Network (VDTN) is introduced as a new research paradigm due to several characteristics match according to specific prerequisites. DTNs is proposed in Vehicular Network because its mechanisms which is using store-carry-forward, can be implemented to deliver the packets, without end-to-end connection, to the destination. One of challenging research of DTN in routing protocol is to meet prerequisites of many applications, especially in vehicular network (VDTN). This paper presents a new variant of Game Theory based on Decision Making (GTDM) that can deliver packet to static node due to improve the energy efficiency of DTNs in city environments. Hence, its destination node (Receiver Node) needs to go to the static node to take their packet under Working Day Movement (WDM), because relay node will be passing by the static node with continuously move to its track to deliver packet. In this paper author will analyze the new variant of GTDM (NVGTDM) which can be more useful than original GTDM for application in city environment with using transportation movement. We conclude that modification of GTDM routing algorithm (NVGTDM) improves energy efficiency as much as 10.38% than the original GTDM. Hence, it can be ensured to compare either to Epidemic or PRoPHET routing algorithm with 55.44% and 68.75% in rates of energy efficiency respectively. \u00a9 2019 Kohat University of Science and Technology."
        ]
    },
    {
        "judul":[
            "Design of reconfigurable system-on-chip architecture for optical wireless communication"
        ],
        "penulis":"Fuada, Syifaul;Adiono, Trio;Putra, Angga Pratama;Setiawan, Erwin;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "To meet the growing demands of the data communication infrastructure in the Internet-of-Things era, alternative methods are needed to complement the current technology, one of which employs optics-based communication. In this paper, we develop optical wireless communication (OWC) infrastructure focuses on digital signal processing (DSP) part. We design System-on-Chip (SoC) architecture based on the Orthogonal Frequency-Division Multiplexing (OFDM) technique with reconfigurable hardware resources. The system developed combines ARM microprocessors with FPGAs. For accelerating the digital processing, several essential parts such as Viterbi decoder, FFT, and time synchronizer are applied to the hardware IP (H\/W SoC). While the scheduling is carried out on the software (S\/W SoC). With this system, the data communication with other devices can be practiced easily, using various peripherals, i.e., Ethernet, UART, and serial-based connection. Afterward, we exploit the system performance in terms of the hardware resources utilization both for DSP Transmitter and DSP Receiver, also the system latency. \u00a9 2019 Journal of Communications.",
            "NH3CH3COCH3View detailsExpand Substance N,N-dimethyl acetamide",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "To meet the growing demands of the data communication infrastructure in the Internet-of-Things era, alternative methods are needed to complement the current technology, one of which employs optics-based communication. In this paper, we develop optical wireless communication (OWC) infrastructure focuses on digital signal processing (DSP) part. We design System-on-Chip (SoC) architecture based on the Orthogonal Frequency-Division Multiplexing (OFDM) technique with reconfigurable hardware resources. The system developed combines ARM microprocessors with FPGAs. For accelerating the digital processing, several essential parts such as Viterbi decoder, FFT, and time synchronizer are applied to the hardware IP (H\/W SoC). While the scheduling is carried out on the software (S\/W SoC). With this system, the data communication with other devices can be practiced easily, using various peripherals, i.e., Ethernet, UART, and serial-based connection. Afterward, we exploit the system performance in terms of the hardware resources utilization both for DSP Transmitter and DSP Receiver, also the system latency. \u00a9 2019 Journal of Communications."
        ]
    },
    {
        "judul":[
            "Evacuation simulation of different flow ratios in low-density state"
        ],
        "penulis":"Lian, Haitao;Hu, Yike;Saedudin, R.D. Rohmat;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The relationship between the factors of formation mechanism of stratification and the pedestrian ratio in low-density state has not been analyzed by the existing human flow evacuation simulation method, so that the simulation effect is poor. Thus, the evacuation simulation method for different flow ratios in low-density state is proposed to analyze the walking characteristics of the opposite pedestrians. On the basis of the random deviation grid gas model, the view field of pedestrian is introduced as one parameter. Considering the preference characteristics of pedestrians for the movement of open areas within the view field, the improved random deviation grid gas model is constructed. Through the model, the stratification characteristics of the opposite pedestrian flow in the simple channel scene are simulated. The results show that the proposed method can reproduce the characteristics of non-layering phenomenon of opposite pedestrian flow in low-density state. According to the probability of layer formation, the density of the opposite pedestrian flow is divided into five intervals. The opposite pedestrian flow in the critical density region is metastable, and is susceptible to interference. These results are consistent with the dynamic evolution of the actual opposite pedestrian flow. \u00a9 2019 Haitao Lian et al., published by De Gruyter 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The relationship between the factors of formation mechanism of stratification and the pedestrian ratio in low-density state has not been analyzed by the existing human flow evacuation simulation method, so that the simulation effect is poor. Thus, the evacuation simulation method for different flow ratios in low-density state is proposed to analyze the walking characteristics of the opposite pedestrians. On the basis of the random deviation grid gas model, the view field of pedestrian is introduced as one parameter. Considering the preference characteristics of pedestrians for the movement of open areas within the view field, the improved random deviation grid gas model is constructed. Through the model, the stratification characteristics of the opposite pedestrian flow in the simple channel scene are simulated. The results show that the proposed method can reproduce the characteristics of non-layering phenomenon of opposite pedestrian flow in low-density state. According to the probability of layer formation, the density of the opposite pedestrian flow is divided into five intervals. The opposite pedestrian flow in the critical density region is metastable, and is susceptible to interference. These results are consistent with the dynamic evolution of the actual opposite pedestrian flow. \u00a9 2019 Haitao Lian et al., published by De Gruyter 2019."
        ]
    },
    {
        "judul":[
            "Name indexing in Indonesian translation of hadith using named entity recognition with na\u00efve bayes classifier"
        ],
        "penulis":"Azalia, Fadhila Yasmine;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hadith is believed to be the main source of Islam after Qur'an. The simplicity of obtaining hadith information is currently supported by global access using the internet. The abundance of hadith literature sometimes finds difficulties to obtain the information that needed. Therefore, information extraction is required to facilitate the searching of information in hadith. In this study, the name indexing in Indonesian translation of hadith from nine narrators was built. The model was built using Named Entity Recognition with Na\u00efve Bayes classifier. The features used in this study are title case, POS tag and unigram. This study experimented with individual features and features that were combined. Precision, recall, and F1-Score are employed as evaluation metrics. F1-Score is used in this study to measure the performance of named entity and features. The results of experiments extracted 258 people's names from 13870 token data from 100 Indonesian hadith texts and show that implementing the combination of all features can achieve 82.63% of F1-Score. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hadith is believed to be the main source of Islam after Qur'an. The simplicity of obtaining hadith information is currently supported by global access using the internet. The abundance of hadith literature sometimes finds difficulties to obtain the information that needed. Therefore, information extraction is required to facilitate the searching of information in hadith. In this study, the name indexing in Indonesian translation of hadith from nine narrators was built. The model was built using Named Entity Recognition with Na\u00efve Bayes classifier. The features used in this study are title case, POS tag and unigram. This study experimented with individual features and features that were combined. Precision, recall, and F1-Score are employed as evaluation metrics. F1-Score is used in this study to measure the performance of named entity and features. The results of experiments extracted 258 people's names from 13870 token data from 100 Indonesian hadith texts and show that implementing the combination of all features can achieve 82.63% of F1-Score. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "Preliminary study on Bandung sustainable urban mobility policy: The contribution of public transportation on emission"
        ],
        "penulis":"Miftah A.Z.;Sasmono S.;Sunarwibowo A.;Khairani A.F.;Moroga K.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Transportation policy in Bandung has advanced to fundamental changes that are environmentally oriented. Mobility is the key driver for development, while type of transportation links between areas and connecting each other to facilitate their economic and social needs. Development of Bus Rapid Transit (BRT) is one of the solutions to reduce the use of private vehicles with the provision of mass transportation. The objective of this study was to describe the existing service of Trans Metro Bandung (TMB) and its emission. The TMB's emission factor is analyzed by using Vehicle Kilometers Travelled (VKT) and fuel consumption in a year. The results showed that the emissions of TMB have influenced the air quality of Bandung. Thus, other alternatives energy is suggested in the development of public transportation (BRT) that supports eco-transportation. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Sustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Transportation policy in Bandung has advanced to fundamental changes that are environmentally oriented. Mobility is the key driver for development, while type of transportation links between areas and connecting each other to facilitate their economic and social needs. Development of Bus Rapid Transit (BRT) is one of the solutions to reduce the use of private vehicles with the provision of mass transportation. The objective of this study was to describe the existing service of Trans Metro Bandung (TMB) and its emission. The TMB's emission factor is analyzed by using Vehicle Kilometers Travelled (VKT) and fuel consumption in a year. The results showed that the emissions of TMB have influenced the air quality of Bandung. Thus, other alternatives energy is suggested in the development of public transportation (BRT) that supports eco-transportation. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Applying Pulse Height Analysis (PHA) Technique on an Optical Particle Counter (OPC) using Commercial ADC Module"
        ],
        "penulis":"Hapidin, Dian Ahmad;Mustika, Widya Sinta;Saputra, Casmika;Maulana, Dian Syah;Khairurrijal, Khairurrijal;Iskandar, Ferry;Munir, Muhammad Miftahul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Pulse height analysis (PHA) has been designed and evaluated, which was applied to an optical particle counter (OPC, Rion KC-03), for measuring the particle size distribution. A commercial ADC module (Contec, AIO-160802AY) was employed to convert, record, and process the OPC output signal. A self-designed application processed the ADC data into distribution plot. The PHA system was calibrated using monodisperse polystyrene latex (PSL) particles with a diameter of 304, 394, and 572 nm as test particles. The PHA could obtain the particle size distribution with the measurement time interval of 10 seconds, which make it possible for the real-time application. \u00a9 2019 Elsevier Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Pulse height analysis (PHA) has been designed and evaluated, which was applied to an optical particle counter (OPC, Rion KC-03), for measuring the particle size distribution. A commercial ADC module (Contec, AIO-160802AY) was employed to convert, record, and process the OPC output signal. A self-designed application processed the ADC data into distribution plot. The PHA system was calibrated using monodisperse polystyrene latex (PSL) particles with a diameter of 304, 394, and 572 nm as test particles. The PHA could obtain the particle size distribution with the measurement time interval of 10 seconds, which make it possible for the real-time application. \u00a9 2019 Elsevier Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Examining digital government (DG) adoption in Indonesia through UTAUT framework"
        ],
        "penulis":"Jacob, Deden Witarsyah;Fudzee, Mohd Farhan Md;Salamat, Mohamad Aizi;Kasim, Shahreen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Public demand for better, accountable, fast and satisfactory services encourages the government to provide a reliable electronic service (digital-government) that can be accessed whenever and wherever. The issuance of Indonesian Presidential Instruction No. 3 of 2003 was an early milestone in the use of digital government services on a national scale. However, the challenges faced by the Indonesian government is to determine the key factors of the public satisfaction in adopting the digital-government. The goal of this paper is to explore the key factors that influences Indonesians' people in adopting the digital government based on the UTAUT framework. In this work, five hypotheses are formulated and five factors are identified that may affect the Indonesians' level of adoption towards using the digital services. Survey data from 237 citizens in five big cities in Java and Sumatra region of Indonesia were collected and used to test the proposed hypotheses. Based on the structural equation model (SEM) approach, the results present several key findings that are in line with the goal of the government to create digital-government that are compatible with citizens' needs, desires, and expectations these findings indicated, thus unveiling the key drivers of adoption level. The result of the work also presents deep insight for governmental policy-makers and practitioners to increase digital-government service via behavioral and managerial factors. Finally, implications and recommendations of these findings were discussed. \u00a9 2019, World Academy of Research in Science and Engineering. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Public demand for better, accountable, fast and satisfactory services encourages the government to provide a reliable electronic service (digital-government) that can be accessed whenever and wherever. The issuance of Indonesian Presidential Instruction No. 3 of 2003 was an early milestone in the use of digital government services on a national scale. However, the challenges faced by the Indonesian government is to determine the key factors of the public satisfaction in adopting the digital-government. The goal of this paper is to explore the key factors that influences Indonesians' people in adopting the digital government based on the UTAUT framework. In this work, five hypotheses are formulated and five factors are identified that may affect the Indonesians' level of adoption towards using the digital services. Survey data from 237 citizens in five big cities in Java and Sumatra region of Indonesia were collected and used to test the proposed hypotheses. Based on the structural equation model (SEM) approach, the results present several key findings that are in line with the goal of the government to create digital-government that are compatible with citizens' needs, desires, and expectations these findings indicated, thus unveiling the key drivers of adoption level. The result of the work also presents deep insight for governmental policy-makers and practitioners to increase digital-government service via behavioral and managerial factors. Finally, implications and recommendations of these findings were discussed. \u00a9 2019, World Academy of Research in Science and Engineering. All rights reserved."
        ]
    },
    {
        "judul":[
            "A Prototype Implementation of Visible Light Communication Based Electrocardiography Data Transmission"
        ],
        "penulis":"Hadiyoso, Sugondo;Wijayanto, Inung;Fauziah, Dila;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "VLC-based data transfer technology is one of the concepts of energy efficiency by utilizing existing light sources as media transfers. VLC is proposed to be part of the 5G technology so that its development and application is predicted to be very wide. The application of VLC is one of them in medical instrumentation. In this research, we proposed the prototype of VLC as an electrocardiograph (ECG) signal transfer media. This system consists of a transmitter and receiver using half-duplex mode. Transmitters use LEDs as light sources arranged in arrays and equipped with P-N-P type transistors as LED drivers. The receiver uses a light sensor in the form of a phototransistor. We carry out transmission testing in rooms with several lighting levels (0, 15, 30, 100, and 200 lux). From the test results, analog ECG signals able to sent with a maximum transmission distance of 450 cm. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "VLC-based data transfer technology is one of the concepts of energy efficiency by utilizing existing light sources as media transfers. VLC is proposed to be part of the 5G technology so that its development and application is predicted to be very wide. The application of VLC is one of them in medical instrumentation. In this research, we proposed the prototype of VLC as an electrocardiograph (ECG) signal transfer media. This system consists of a transmitter and receiver using half-duplex mode. Transmitters use LEDs as light sources arranged in arrays and equipped with P-N-P type transistors as LED drivers. The receiver uses a light sensor in the form of a phototransistor. We carry out transmission testing in rooms with several lighting levels (0, 15, 30, 100, and 200 lux). From the test results, analog ECG signals able to sent with a maximum transmission distance of 450 cm. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Multicast routing protocol for advanced vehicular ad hoc networks"
        ],
        "penulis":"Al Mushayt, Omar Saeed;Gharibi, Wajeb;Armi, Nasrullah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Transport sector has great impact on our daily life. Despite the huge number of vehicular models, driving process still faces many challenges due to the lack information about the roads and the surrounding sudden events, which can result in high number of accidents globally and especially in Saudi Arabia. A new technology, vehicular ad hoc networks (VANETs), has emerged to support Intelligent Transport System (ITS) and to offer advanced solutions for drivers to avoid different hazard events that occur on the road. In this paper, we discuss the multicast and broadcast communications in VANETs, Quality of Sevice (QoS) awaregroup addressing\/managing solutions to VANETs which help inclassifying different application that explore and design a new cross-layer framework, aware of high mobility and efficiency. \u00a9 2019 Universitas Ahmad Dahlan.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Transport sector has great impact on our daily life. Despite the huge number of vehicular models, driving process still faces many challenges due to the lack information about the roads and the surrounding sudden events, which can result in high number of accidents globally and especially in Saudi Arabia. A new technology, vehicular ad hoc networks (VANETs), has emerged to support Intelligent Transport System (ITS) and to offer advanced solutions for drivers to avoid different hazard events that occur on the road. In this paper, we discuss the multicast and broadcast communications in VANETs, Quality of Sevice (QoS) awaregroup addressing\/managing solutions to VANETs which help inclassifying different application that explore and design a new cross-layer framework, aware of high mobility and efficiency. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Boosting the firm transformation in industry 5.0: Experience-agility innovation model"
        ],
        "penulis":"Mihardjo, Leonardus W Wasono;Sasmoko;Alamsyah, Firdaus;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 5.0 brings collaborative and automatic environment, thus creating a new paradigm for companies in doing business. The way organizations manage resources and capability, especially in relationship with people, culture and process in creating new business models have changed. Previous studies on developing innovation based on customer experience and agility of organization focus on the concept, relationship among variables and the implication. However, in the context of industry 5.0, the study on those topics has not been revealing. Hence, this study aims to assess the concept of experience-agility innovation model to support transformation in the context of digital transformation to face Industry 5.0. The proposed model was assessed with 195 Indonesia ICT firms using SEM-PLS statistical tools. The findings demonstrate that the firm that offers compelling value proposition from customer experience while concurrently developing agility in the organization to create business model innovation could boost the transformational performance. For further researches, the study can be enhanced through expanding the model, sample, and time. \u00a9 BEIESP.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 5.0 brings collaborative and automatic environment, thus creating a new paradigm for companies in doing business. The way organizations manage resources and capability, especially in relationship with people, culture and process in creating new business models have changed. Previous studies on developing innovation based on customer experience and agility of organization focus on the concept, relationship among variables and the implication. However, in the context of industry 5.0, the study on those topics has not been revealing. Hence, this study aims to assess the concept of experience-agility innovation model to support transformation in the context of digital transformation to face Industry 5.0. The proposed model was assessed with 195 Indonesia ICT firms using SEM-PLS statistical tools. The findings demonstrate that the firm that offers compelling value proposition from customer experience while concurrently developing agility in the organization to create business model innovation could boost the transformational performance. For further researches, the study can be enhanced through expanding the model, sample, and time. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Development of Web Stock Opname Application with SAP Business One Using Scrum Method"
        ],
        "penulis":"Ramadhan, Aulia;Lubis, Muharman;Puspitasari, Warih;Lubis, Arif Ridho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "SME Company (Small and Medium Enterprises) is a small-scale business unit, which require to have inventory function as an important asset in the company to ensure the availability of goods and stock within the warehouse process. Thus, an inventory management process calls Stock opname that is carried out to conduct calculation and computation have been established. Previously, majority activity process have been carried out manually in which the employees check and record the available items through reporting them to the managers without using any kind of software whatsoever, only a piece of document that have no integration with other business processes. Therefore, the data that is not processed in the real-time might be different at certain period and unmatched with the real situation can lead to the wrong decision making. Thus, the application should be developed, which in this case utilizing the web application to be integrated with SAP Business One to solve existing problems within the company to provide accurate and real-time inventory information management. It also has objective to maintain updated information with other department, unit or even business modules within the SME companies. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SME Company (Small and Medium Enterprises) is a small-scale business unit, which require to have inventory function as an important asset in the company to ensure the availability of goods and stock within the warehouse process. Thus, an inventory management process calls Stock opname that is carried out to conduct calculation and computation have been established. Previously, majority activity process have been carried out manually in which the employees check and record the available items through reporting them to the managers without using any kind of software whatsoever, only a piece of document that have no integration with other business processes. Therefore, the data that is not processed in the real-time might be different at certain period and unmatched with the real situation can lead to the wrong decision making. Thus, the application should be developed, which in this case utilizing the web application to be integrated with SAP Business One to solve existing problems within the company to provide accurate and real-time inventory information management. It also has objective to maintain updated information with other department, unit or even business modules within the SME companies. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "What are the Indonesian Concerns about the Internet of Things (IoT)? Portraying the Profile of the Prospective Market"
        ],
        "penulis":"Suryanegara, Muhammad;Arifin, Ajib Setyo;Asvial, Muhamad;Ramli, Kalamullah;Nashiruddin, Muhammad Imam;Hayati, Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper aims to characterize the profile of the prospective IoT market in Indonesia. The primary data were collected in July 2018 through a comprehensive survey that sampled respondents representing the whole Indonesian population. The questionnaire was developed by extracting the 4 (four) main issues regarding which the potential users of the IoT technology may have concerns, i.e., willingness to use the IoT services, concerns related to rejection and worries about the IoT, the characteristics of the IoT hardware, and perceptions about the role of the IoT within the existing system. The results of the survey were analyzed to capture the profile of the prospective IoT market, and the strategic implications of the findings were considered. Several interesting results were found, ranging from answering the common question of what kinds of the IoT services are most anticipated to answering the delicate question of how the Indonesian people perceive the disruptive force that the IoT technology may exert. The contribution of this research is that it can be used as an initial guide or reference for regulators, the government and the IoT firms that will begin to deploy services in Indonesia. \u00a9 2013 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper aims to characterize the profile of the prospective IoT market in Indonesia. The primary data were collected in July 2018 through a comprehensive survey that sampled respondents representing the whole Indonesian population. The questionnaire was developed by extracting the 4 (four) main issues regarding which the potential users of the IoT technology may have concerns, i.e., willingness to use the IoT services, concerns related to rejection and worries about the IoT, the characteristics of the IoT hardware, and perceptions about the role of the IoT within the existing system. The results of the survey were analyzed to capture the profile of the prospective IoT market, and the strategic implications of the findings were considered. Several interesting results were found, ranging from answering the common question of what kinds of the IoT services are most anticipated to answering the delicate question of how the Indonesian people perceive the disruptive force that the IoT technology may exert. The contribution of this research is that it can be used as an initial guide or reference for regulators, the government and the IoT firms that will begin to deploy services in Indonesia. \u00a9 2013 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of direction control on self-driving car prototype"
        ],
        "penulis":"Fauziah N.E.;Wibawa I.P.D.;Ekaputri C.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A Self-driving car needs sturdy steering system. Therefore designing direction control must be precise to the track. This direction control will help the car know the current position and direct it to the right angle. Directional control results in a turning angle. Turning angle is obtained from the tangent value between two Region of Interest (ROI) in the frame of the camera captured. The turning angle obtained is conditioned to match the angle of the servo motor as the front actuator of the car prototype. The results of this research are the turning angles that are read in the Python program on a straight lane have an average of 90.4198 with an average error of 1,086, the right turning lane has an average turning angle of 99.5502, 112.96973 and 117.0711 with an average error 3.03727, 3.62493 and 3.0636296, the left turn lane 58.7540333, 71.218 and 80.1277667 with an average error of 1.61674, 1.88093 and 1.48696 so that they can direct the car prototype in accordance with the sharpness of the bend in the lane. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A Self-driving car needs sturdy steering system. Therefore designing direction control must be precise to the track. This direction control will help the car know the current position and direct it to the right angle. Directional control results in a turning angle. Turning angle is obtained from the tangent value between two Region of Interest (ROI) in the frame of the camera captured. The turning angle obtained is conditioned to match the angle of the servo motor as the front actuator of the car prototype. The results of this research are the turning angles that are read in the Python program on a straight lane have an average of 90.4198 with an average error of 1,086, the right turning lane has an average turning angle of 99.5502, 112.96973 and 117.0711 with an average error 3.03727, 3.62493 and 3.0636296, the left turn lane 58.7540333, 71.218 and 80.1277667 with an average error of 1.61674, 1.88093 and 1.48696 so that they can direct the car prototype in accordance with the sharpness of the bend in the lane. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Trade-off analysis for eco-tourism of the Tasik Kenyir protected area"
        ],
        "penulis":"Lola, Muhamad Safiih;Ramlee, Mohd Noor Afiq;Hussin, Mohd Fadli;Abdul Rahman, Muhamad Na'eim;Abdullah, Mohd Tajuddin;Kamil, Anton Abdulbasah;Mohamad Yusof, Izham;Ibrahim, Yahaya;Khadar, Nur Zafirah A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Continuous pandemic of sustainable development rise numerous concern, hence resulting towards integration of multidimensional principle as an underlay in order to form sound decision-making process especially in ecological-sensitive area such as Tasik Kenyir. This study develops the structural framework for decision-making inclusive of all variables in order to strive for sustainable development of Tasik Kenyir in order to promote responsible tourism practices. Several criteria are selected and analyzed using Multi-criteria Analysis (to show the corresponding trade-off); ranged from economic, ecological and social variables such as economic revenue, employment, conservation of flora and fauna and environmental quality. The results show that under different scenarios, the score of different type of variables will change accordingly. \u00a9 Springer Nature Switzerland AG 2019.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Continuous pandemic of sustainable development rise numerous concern, hence resulting towards integration of multidimensional principle as an underlay in order to form sound decision-making process especially in ecological-sensitive area such as Tasik Kenyir. This study develops the structural framework for decision-making inclusive of all variables in order to strive for sustainable development of Tasik Kenyir in order to promote responsible tourism practices. Several criteria are selected and analyzed using Multi-criteria Analysis (to show the corresponding trade-off); ranged from economic, ecological and social variables such as economic revenue, employment, conservation of flora and fauna and environmental quality. The results show that under different scenarios, the score of different type of variables will change accordingly. \u00a9 Springer Nature Switzerland AG 2019."
        ]
    },
    {
        "judul":[
            "The Quality Metric Design to Control Quality of Telecommunication Construction Project Using Internal Control Method"
        ],
        "penulis":"Nabilah, Fenita;Puspita, Ika Arum;Tripiawan, Wawan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A company has a telecommunication construction project. The company has given a contract to the vendor to carry out the project. During the execution phase, the vendor made a mistake on the installation thus reworking is required. After an observation, it turns out that in the planning phase the vendors do not carry out plan quality management that produce quality metric as a guide consists of specifications to control the quality. The absence of quality metric causes the vendor do not aware of the specifications that must be met in the project so reworking occurs. On this research, the design of quality metric using internal control methods is developed to identify possible errors and provide critical success criteria for each work activity. In addition, identification of critical activities is carried out using the Critical Path Method. To assess the results of implementation of quality metric, a quality checklist is designed. The assessment was used before and after the implementation of quality metric. The result of this research is quality metric has increased the performance of vendors by 23% but there are 10 statements that do not meet specifications and critical. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A company has a telecommunication construction project. The company has given a contract to the vendor to carry out the project. During the execution phase, the vendor made a mistake on the installation thus reworking is required. After an observation, it turns out that in the planning phase the vendors do not carry out plan quality management that produce quality metric as a guide consists of specifications to control the quality. The absence of quality metric causes the vendor do not aware of the specifications that must be met in the project so reworking occurs. On this research, the design of quality metric using internal control methods is developed to identify possible errors and provide critical success criteria for each work activity. In addition, identification of critical activities is carried out using the Critical Path Method. To assess the results of implementation of quality metric, a quality checklist is designed. The assessment was used before and after the implementation of quality metric. The result of this research is quality metric has increased the performance of vendors by 23% but there are 10 statements that do not meet specifications and critical. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Single Speaker Recognition Using Deep Belief Network Gender Classification Voices"
        ],
        "penulis":"Prasetio, Murman Dwi;Sekizaki, Shinya;Hayashida, Tomohiro;Susanto, Agus;Nishisaki, Ichiro;Abdillah, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Recently, the algorithm of machine learning are used to able to train, enhance, characterize and anticipate the data results accurately. In a way to training, the process on the algorithm can be able to produce an appropriate model based on that data; it's like supervised and unsupervised data. In this paper, we tried to trace the gender (male and female) from acoustic data i.e., pitch, median, frequency etc. The gender that would like to implement is classified on the basis of the intensity of their utterances. To analyze the utterances, the voice intensity measuring by the hamming window to make a normalize curve to obtain the peaks of the utterances where peaks are found from each frame of speech utterance when it is divided into frames of the length of 20 milliseconds. At certain amplitude levels it can be considered to find a peak. As well as making decisions about gender use a thresholds that are adapted are adjusted. If the area of an utterance is above the threshold the gender type is a female otherwise male. After that, we handle the feature learning from the utterance into deep belief network as a machine learning tool to predict single speech by gender classification voices with optimization (taboo search) to train several neurons in the initial weight vector for the accuracy of female and male voices 75.67% and 80.83% precisely.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recently, the algorithm of machine learning are used to able to train, enhance, characterize and anticipate the data results accurately. In a way to training, the process on the algorithm can be able to produce an appropriate model based on that data; it's like supervised and unsupervised data. In this paper, we tried to trace the gender (male and female) from acoustic data i.e., pitch, median, frequency etc. The gender that would like to implement is classified on the basis of the intensity of their utterances. To analyze the utterances, the voice intensity measuring by the hamming window to make a normalize curve to obtain the peaks of the utterances where peaks are found from each frame of speech utterance when it is divided into frames of the length of 20 milliseconds. At certain amplitude levels it can be considered to find a peak. As well as making decisions about gender use a thresholds that are adapted are adjusted. If the area of an utterance is above the threshold the gender type is a female otherwise male. After that, we handle the feature learning from the utterance into deep belief network as a machine learning tool to predict single speech by gender classification voices with optimization (taboo search) to train several neurons in the initial weight vector for the accuracy of female and male voices 75.67% and 80.83% precisely.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Restaurant Recommender System Using User-Based Collaborative Filtering Approach: A Case Study at Bandung Raya Region"
        ],
        "penulis":"Fakhri, Alif Azhar;Baizal Z.K.A.;Setiawan, Erwin Budi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Culinary becomes one of the needs of today's society. The large number of restaurant choices and also lack of information about the restaurant become an obstacle to people's needs in choosing a restaurant. In this paper, we build a recommender system that can recommend the restaurant in Bandung area. However, today, users want to get a restaurant with a good reputation and fit their tastes, so that restaurant ratings from other users are required in the restaurant recommendation process. We implement a user-based collaborative filtering method for recommend a restaurant personally, based on ratings given by other users. We also implement two similarities, i.e., user rating similarity and user attribute similarity to find the proximity between users. We use Mean Absolute Error (MAE) to evaluate accuration of rating prediction. The best MAE result of each performance is 1.492 for calculation without user attributes and 2.166 for calculation with user attributes. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Culinary becomes one of the needs of today's society. The large number of restaurant choices and also lack of information about the restaurant become an obstacle to people's needs in choosing a restaurant. In this paper, we build a recommender system that can recommend the restaurant in Bandung area. However, today, users want to get a restaurant with a good reputation and fit their tastes, so that restaurant ratings from other users are required in the restaurant recommendation process. We implement a user-based collaborative filtering method for recommend a restaurant personally, based on ratings given by other users. We also implement two similarities, i.e., user rating similarity and user attribute similarity to find the proximity between users. We use Mean Absolute Error (MAE) to evaluate accuration of rating prediction. The best MAE result of each performance is 1.492 for calculation without user attributes and 2.166 for calculation with user attributes. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Welcome message from general chair of ICSigSys 2019"
        ],
        "penulis":"Suratman, Fiky Y.;Save all to author list",
        "tahun":2019,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Clustering synonym sets in english wordNet"
        ],
        "penulis":"Priyatno, Jentrisi;Bijaksana, Moch Arif;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A lot of lexical research conducted by experts use existing words in the English Thesaurus. However, the English Thesaurus only gives synonyms of the words searched for and does not provide similarities between words that can be called WordNet. So in this study, a WordNet can be made that can help research that uses databases for English. The similarity between words makes many researchers today are still looking for word relations by manual method, or still use the English Thesaurus. The making of WordNet is expected to be very useful for researchers who want a lexical database for their research, which is currently still relatively small. Therefore it is better to make an English WordNet which will later accommodate words that have the same meaning or Synonym Sets and this WordNet focuses on grouping those words. So that researchers can do lexical research more broadly and unlimitedly with the existence of words that are still unclear in their similarities. Calculation with clustering gets an F1 Score Result at 10.68%, Recall at 8.53% and Precision at 14.28%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A lot of lexical research conducted by experts use existing words in the English Thesaurus. However, the English Thesaurus only gives synonyms of the words searched for and does not provide similarities between words that can be called WordNet. So in this study, a WordNet can be made that can help research that uses databases for English. The similarity between words makes many researchers today are still looking for word relations by manual method, or still use the English Thesaurus. The making of WordNet is expected to be very useful for researchers who want a lexical database for their research, which is currently still relatively small. Therefore it is better to make an English WordNet which will later accommodate words that have the same meaning or Synonym Sets and this WordNet focuses on grouping those words. So that researchers can do lexical research more broadly and unlimitedly with the existence of words that are still unclear in their similarities. Calculation with clustering gets an F1 Score Result at 10.68%, Recall at 8.53% and Precision at 14.28%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Critical Failure Factors in Enterprise Resource Planning (ERP) Implementation: Case Study of PT.Toyota Astra Motor Indonesia"
        ],
        "penulis":"Prasetyo, Sardhika Janar;Lubis, Muharman;Witjaksono, R. Wahjoe;Azizah, Anik Hanifatul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In addition to the popularity of ERP usage, the failure rate of ERP implementation in the company is quite high, the results obtained indicate that the failure of ERP implementation ranges from 67% -90%, the current study mostly discusses Critical Success Factors (CSF) rather than Critical Failure Factors (CFF), there are 6% of journals that are successfully published, which contain CSF and less than 1% that discuss CFF. The inhibiting factors of ERP implementation are more often found in ERP implementation in developing countries, because ERP systems are built and designed with and for better technology in developed countries. The main objective of this research is to identify the factors that become obstacles and classify them to help industries in developing countries, especially companies that are the object of research in this case PT. Toyota Astra Motor, consultants and implementers to prevent failure in the implementation of ERP projects using CFF (Critical Failure Factors) models with 7 variables and assisted with SPSS and SmartPLS for calculation methods. Based on the results of the study using the CFF model at PT. Toyota Astra Motor is known that variables that have no significant and strong effect are Process Variables. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In addition to the popularity of ERP usage, the failure rate of ERP implementation in the company is quite high, the results obtained indicate that the failure of ERP implementation ranges from 67% -90%, the current study mostly discusses Critical Success Factors (CSF) rather than Critical Failure Factors (CFF), there are 6% of journals that are successfully published, which contain CSF and less than 1% that discuss CFF. The inhibiting factors of ERP implementation are more often found in ERP implementation in developing countries, because ERP systems are built and designed with and for better technology in developed countries. The main objective of this research is to identify the factors that become obstacles and classify them to help industries in developing countries, especially companies that are the object of research in this case PT. Toyota Astra Motor, consultants and implementers to prevent failure in the implementation of ERP projects using CFF (Critical Failure Factors) models with 7 variables and assisted with SPSS and SmartPLS for calculation methods. Based on the results of the study using the CFF model at PT. Toyota Astra Motor is known that variables that have no significant and strong effect are Process Variables. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementing binary particle swarm optimization and C4.5 decision tree for cancer detection based on microarray data classification"
        ],
        "penulis":"Pradana A.C.;Adiwijaya;Aditsania A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cancer is one of deadly disease in the world and needed to detect the symptoms early. Cancer can be represented with microarray data with measuring the changes occured in gene expression level. Cancer detection can be done by doing classification technique for microarray data. One of most algorithm that applied for classification is C4.5 Decision Tree. It is a linier method which is easy to interpret and included into the algorithm which has given impact in classification but it is sensitive to noise data. Microarray data has a large features (high dimensional) which is not all the features has important information (high noise) and small samples which is causing the classification is difficult and affect the accuracy. Binary Particle Swarm Optimization (BPSO) is one of search optimization algorithm that could find the optimal feature. The purpose in this research consists of implementing and analysing the influence of feature selection and classification on microarray data using Binary Particle Swarm Optimization (BPSO) as feature selection and Decision Tree C4.5 as classifier. The discretization is needed for Decision Tree rule model and applied using K-Means. System is divided into two schemes such as Information Gain (IG) - C4.5 and BPSO - C4.5. The accuracy result based on IG - C4.5 and BPSO - C4.5 both are 54% and 99%. Applying feature selection before the classification could avoid the noise data in microarray data so it could form the rule accurately. With applying BPSO and Decision Tree is able to find the most significant feature and improve the accuracy. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is one of deadly disease in the world and needed to detect the symptoms early. Cancer can be represented with microarray data with measuring the changes occured in gene expression level. Cancer detection can be done by doing classification technique for microarray data. One of most algorithm that applied for classification is C4.5 Decision Tree. It is a linier method which is easy to interpret and included into the algorithm which has given impact in classification but it is sensitive to noise data. Microarray data has a large features (high dimensional) which is not all the features has important information (high noise) and small samples which is causing the classification is difficult and affect the accuracy. Binary Particle Swarm Optimization (BPSO) is one of search optimization algorithm that could find the optimal feature. The purpose in this research consists of implementing and analysing the influence of feature selection and classification on microarray data using Binary Particle Swarm Optimization (BPSO) as feature selection and Decision Tree C4.5 as classifier. The discretization is needed for Decision Tree rule model and applied using K-Means. System is divided into two schemes such as Information Gain (IG) - C4.5 and BPSO - C4.5. The accuracy result based on IG - C4.5 and BPSO - C4.5 both are 54% and 99%. Applying feature selection before the classification could avoid the noise data in microarray data so it could form the rule accurately. With applying BPSO and Decision Tree is able to find the most significant feature and improve the accuracy. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Virtual password authentication scheme in hashed domain"
        ],
        "penulis":"Rahiemy, Mohammad Zakie Faiz;Sukarno, Parman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes a virtual password authentication scheme which is able to work in the hashed domain. Many research in the area of virtual password have been proposed to overcome keylogger attacks. Unfortunately, current methods are still lack of complexities and have a short cracking time. Several research have partially overcome these problems. However, the proposed methods work only in the plain text domain which is vulnerable to the privacy and security attacks. To overcome this problem, we proposed a virtual password scheme that generates dynamic length of a random password consisting of both uppercase and lowercase alphabets, numbers, and symbols. Importantly, our method is also able to compare user's password despite it is hashed. With an efficient algorithm that help this method's computation time somewhat similar with regular login, the cracking time and complexity of this method are superior which scores 174 on password complexity and calculated to be cracked after 10,000+ and 9 centuries by brute force attack using a personal computer and conficker botnets respectively. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes a virtual password authentication scheme which is able to work in the hashed domain. Many research in the area of virtual password have been proposed to overcome keylogger attacks. Unfortunately, current methods are still lack of complexities and have a short cracking time. Several research have partially overcome these problems. However, the proposed methods work only in the plain text domain which is vulnerable to the privacy and security attacks. To overcome this problem, we proposed a virtual password scheme that generates dynamic length of a random password consisting of both uppercase and lowercase alphabets, numbers, and symbols. Importantly, our method is also able to compare user's password despite it is hashed. With an efficient algorithm that help this method's computation time somewhat similar with regular login, the cracking time and complexity of this method are superior which scores 174 on password complexity and calculated to be cracked after 10,000+ and 9 centuries by brute force attack using a personal computer and conficker botnets respectively. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Music fingerprinting based on bhattacharya distance for song and cover song recognition"
        ],
        "penulis":"Sarno, Riyanarto;Wijaya, Dedy Rahman;Mahardika, Muhammad Nezar;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "People often have trouble recognizing a song especially, if the song is sung by a not original artist which is called cover song. Hence, an identification system might be used to help recognize a song or to detect copyright violation. In this study, we try to recognize a song and a cover song by using the fingerprint of the song represented by features extracted from MPEG-7. The fingerprint of the song is represented by Audio Signature Type. Moreover, the fingerprint of the cover song is represented by Audio Spectrum Flatness and Audio Spectrum Projection. Furthermore, we propose a sliding algorithm and k-Nearest Neighbor (k-NN) with Bhattacharyya distance for song recognition and cover song recognition. The results of this experiment show that the proposed fingerprint technique has an accuracy of 100% for song recognition and an accuracy of 85.3% for cover song recognition. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "People often have trouble recognizing a song especially, if the song is sung by a not original artist which is called cover song. Hence, an identification system might be used to help recognize a song or to detect copyright violation. In this study, we try to recognize a song and a cover song by using the fingerprint of the song represented by features extracted from MPEG-7. The fingerprint of the song is represented by Audio Signature Type. Moreover, the fingerprint of the cover song is represented by Audio Spectrum Flatness and Audio Spectrum Projection. Furthermore, we propose a sliding algorithm and k-Nearest Neighbor (k-NN) with Bhattacharyya distance for song recognition and cover song recognition. The results of this experiment show that the proposed fingerprint technique has an accuracy of 100% for song recognition and an accuracy of 85.3% for cover song recognition. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "A comparative study of Hollywood movie successfulness prediction model"
        ],
        "penulis":"Masrury, Riefvan Achmad;Saputra, Muhammad Apriandito Arya;Alamsyah, Andry;Primantari, Made Ayunda Sukma;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The movie industry is a highly competitive industry with a lot of new movies are queued to be released each year. Movie making is subject to potential profits or loss in the magnitude of billion of dollars making this industry very risky. Predicting the successfulness of movie based on its financial performance prior to the release date is valuable in order to reduce number of uncertainties faced by decision makers such as producers, distributors, and exhibitors. Using the concept of machine learning, we suggest a classification model to predict the successfulness of a Hollywood Movie using Artificial Neural Network, Na\u00efve Bayes and Support Vector Machine. The objective of this research is to compare classification algorithms performance for predicting the successfulness of Hollywood movies before they are being released. Artificial Neural Network produces the best model in terms of performance in predicting a movie successfulness. Reaching 80% of accuracy and having above 80% of F-measure, precision, and recall suggests that Artificial Neural Network is a good model to assist producers, distributors and exhibitors assess risks. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The movie industry is a highly competitive industry with a lot of new movies are queued to be released each year. Movie making is subject to potential profits or loss in the magnitude of billion of dollars making this industry very risky. Predicting the successfulness of movie based on its financial performance prior to the release date is valuable in order to reduce number of uncertainties faced by decision makers such as producers, distributors, and exhibitors. Using the concept of machine learning, we suggest a classification model to predict the successfulness of a Hollywood Movie using Artificial Neural Network, Na\u00efve Bayes and Support Vector Machine. The objective of this research is to compare classification algorithms performance for predicting the successfulness of Hollywood movies before they are being released. Artificial Neural Network produces the best model in terms of performance in predicting a movie successfulness. Reaching 80% of accuracy and having above 80% of F-measure, precision, and recall suggests that Artificial Neural Network is a good model to assist producers, distributors and exhibitors assess risks. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Supply Chain Performance Measurement System Development for Shoes SME using Subcontract Production Strategy Based on Integrated SCOR-BSC Model"
        ],
        "penulis":"Fauzi A.R.;Ridwan A.Y.;Juliani W.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Textile and apparel companies are a company that is widely available in Indonesia. Small and Medium Enterprise is a business that is growing rapidly and has many competitors in Indonesia, one of which is engaged in the textile sector. SME proves as one of the businesses that can survive when the economic crisis hit the world in 1997-1998 and had an impact on the Indonesian economy [1]. Even so, SME has several problems, one of which is to develop its business. Performance measurement system required to develop its business. With a performance measurement system, SME can monitor business performance that can help companies in making future decisions to improve the performance of the company. This paper focuses on SME engaged in the shoe industry and using subcontract as its production strategy. This paper also using integrated SCOR-BSC model as the baseline to determine the KPI needed by the Shoe SME. The result of this research is integrated SCOR-BSC KPI which can be used as the basis on performance measurement system making. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Textile and apparel companies are a company that is widely available in Indonesia. Small and Medium Enterprise is a business that is growing rapidly and has many competitors in Indonesia, one of which is engaged in the textile sector. SME proves as one of the businesses that can survive when the economic crisis hit the world in 1997-1998 and had an impact on the Indonesian economy [1]. Even so, SME has several problems, one of which is to develop its business. Performance measurement system required to develop its business. With a performance measurement system, SME can monitor business performance that can help companies in making future decisions to improve the performance of the company. This paper focuses on SME engaged in the shoe industry and using subcontract as its production strategy. This paper also using integrated SCOR-BSC model as the baseline to determine the KPI needed by the Shoe SME. The result of this research is integrated SCOR-BSC KPI which can be used as the basis on performance measurement system making. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Towards humane digitization: A wellbeing-driven process of personas creation"
        ],
        "penulis":"Nurhas, Irawan;Pawlowski, Jan M.;Geisler, Stefan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Digital transformation is a process of digitizing the working and living environment in which people are at the center of digitization. In this paper, we present a personas-based guideline for system developers on how the humanization of digital transformation integrates into the design process. The proposed guideline uses the positive personas from the beginning as a basis for the transformation of the working environment into the digital form. We used the literature research as a preliminary study for the process of wellbeing-driven digital transformation design, consisting of questions for structuring the required information in the positive personas as well as a potential method that could be integrated into the wellbeing-based design process. \u00a9 2019 Copyright is held by the owner\/author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Digital transformation is a process of digitizing the working and living environment in which people are at the center of digitization. In this paper, we present a personas-based guideline for system developers on how the humanization of digital transformation integrates into the design process. The proposed guideline uses the positive personas from the beginning as a basis for the transformation of the working environment into the digital form. We used the literature research as a preliminary study for the process of wellbeing-driven digital transformation design, consisting of questions for structuring the required information in the positive personas as well as a potential method that could be integrated into the wellbeing-based design process. \u00a9 2019 Copyright is held by the owner\/author(s)."
        ]
    },
    {
        "judul":[
            "Employing Moving Average Long Short Term Memory for Predicting Rainfall"
        ],
        "penulis":"Caraka, Rezzy Eko;Chen, Rung Ching;Supatmanto, Budi Darmawan;Arnita;Tahmid, Muhammad;Toharudin, Toni;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Rainfall is significant in influencing human life. Therefore, it is necessary to predict or forecast rainfall in decision making. Forecasting rainfall can be calculated by the average rainfall of an area and by using the time-series method. Moreover, the government has a climatology station to measure rainfall at specific points or locations in various regions. In Indonesia, they are considered to have potential and represent the surrounding area. However, rainfall outside the climatology station area is not known for sure, while for specific purposes, information about rain is needed at other points. This research work focuses on the application of machine learning methods to the problem of computing prediction on time series as input variables. More specifically, we employ moving average (MA) and long short-term memory (LSTM) method to predict the rainfall in Winangun, North Sulawesi, Indonesia. LSTM is a neural network development that can be used for time-series data modelling. Based on the simulation, the combination of these methods, in-sample data reaches the R295.11%, and out-sample data reach R290.46% respectively. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rainfall is significant in influencing human life. Therefore, it is necessary to predict or forecast rainfall in decision making. Forecasting rainfall can be calculated by the average rainfall of an area and by using the time-series method. Moreover, the government has a climatology station to measure rainfall at specific points or locations in various regions. In Indonesia, they are considered to have potential and represent the surrounding area. However, rainfall outside the climatology station area is not known for sure, while for specific purposes, information about rain is needed at other points. This research work focuses on the application of machine learning methods to the problem of computing prediction on time series as input variables. More specifically, we employ moving average (MA) and long short-term memory (LSTM) method to predict the rainfall in Winangun, North Sulawesi, Indonesia. LSTM is a neural network development that can be used for time-series data modelling. Based on the simulation, the combination of these methods, in-sample data reaches the R295.11%, and out-sample data reach R290.46% respectively. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Pattern lock and the app based on context, ease of use aspect in comparison"
        ],
        "penulis":"Pulungan, Farid Fajriana;Sudiharto, Dodi Wisaksono;Brotoharsono, Tri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Smartphone has been a popular device utilized to support productivity in human life and has become an integral part of human activities such as for communication, entertainment and social interaction. Those activities can be related to the information which needs to be protected because of its high privacy. Therefore, the smartphone needs a procedure that demonstrates an ability to secure that user information. However, more protective the scheme, more difficult the usage. Based on that pattern behavior, a good security scheme which support the users for easy security feature is urgently needed. One of such kind security features is authentication feature. In that manner, the ease of use aspect for acquiring the system by using an easy authentication mechanism becomes critically important. The ease of use intended is the efficiency of interaction between the user and that security feature for doing authentication including the time needed for doing that. This study developed the app which utilizes the context data, namely Geofilock. The context data meant is the location data based on the GPS and MAC address of the Wi-Fi. The system detected both context data and determined whether the smartphone needs to show the pattern screen lock as authentication feature or not, based on the context data analysis. The functionality of Geofilock works properly as shown by less user interaction number and less time needed by the user for obtaining the access. In addition, the app is easy to operate, as suggested by the user feedback. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Smartphone has been a popular device utilized to support productivity in human life and has become an integral part of human activities such as for communication, entertainment and social interaction. Those activities can be related to the information which needs to be protected because of its high privacy. Therefore, the smartphone needs a procedure that demonstrates an ability to secure that user information. However, more protective the scheme, more difficult the usage. Based on that pattern behavior, a good security scheme which support the users for easy security feature is urgently needed. One of such kind security features is authentication feature. In that manner, the ease of use aspect for acquiring the system by using an easy authentication mechanism becomes critically important. The ease of use intended is the efficiency of interaction between the user and that security feature for doing authentication including the time needed for doing that. This study developed the app which utilizes the context data, namely Geofilock. The context data meant is the location data based on the GPS and MAC address of the Wi-Fi. The system detected both context data and determined whether the smartphone needs to show the pattern screen lock as authentication feature or not, based on the context data analysis. The functionality of Geofilock works properly as shown by less user interaction number and less time needed by the user for obtaining the access. In addition, the app is easy to operate, as suggested by the user feedback. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "A perspective of home security using wireless communication"
        ],
        "penulis":"Purboyo, Tito Waluyo;Osmond, Andrew Brian;Aryani, Ressy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Home security is security system to applied at home or at one building. A function of home security is to provide comfort, some level of protection for the inhabitants of the house and can also be implemented into the system for crime prevention. The research will be conducted using wireless communication as the communication module used in security systems. The diversity of application, technology, methods, sensors that used and many more ways can increase the level of security at home. This study aims to review and compare some paper of home security likes methods, used tools, advantages and disadvantages of a security system. At the end, the final duty is to know which system is suitable for home by using the parameters to be compared. \u00a9 2019, Medwell Journals.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Home security is security system to applied at home or at one building. A function of home security is to provide comfort, some level of protection for the inhabitants of the house and can also be implemented into the system for crime prevention. The research will be conducted using wireless communication as the communication module used in security systems. The diversity of application, technology, methods, sensors that used and many more ways can increase the level of security at home. This study aims to review and compare some paper of home security likes methods, used tools, advantages and disadvantages of a security system. At the end, the final duty is to know which system is suitable for home by using the parameters to be compared. \u00a9 2019, Medwell Journals."
        ]
    },
    {
        "judul":[
            "Selection of Vape Sensing Features in IoT-Based Gas Monitoring with Feature Importance Techniques"
        ],
        "penulis":"Saputra, Edy Syuryawan;Putrada, Aji Gautama;Abdurohman, Maman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Current smoke detection sensors are not designed to specifically detect vape smoke, resulting in ambiguity in decision making. Vape and cigarette smoke are different from each other, cigarette smoke is the result of burning from tobacco, while vape smoke comes from heating liquids that produce steam in the form of smoke. Therefore, researches have been directed to design a smart device that can detect vape smoke by combining multiple gas sensors, for example a MQ2 gas sensor, a MQ7 gas sensor, and a temperature and humidity sensor connected to the microcontroller. Previous tests have returned bad accuracy in detecting Vape. To evaluate that problem, this research proposes feature importance technique to select the appropriate sensor to detect vape smoke by providing a value for each sensor according to the effect on the outcome of the decision. For classification, a random forests method is used that matches the feature importance and firebase as storage media. By using these devices and methods, the sensor is suitable to detect vape smoke so that it gets an accuracy of 94.44% \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Current smoke detection sensors are not designed to specifically detect vape smoke, resulting in ambiguity in decision making. Vape and cigarette smoke are different from each other, cigarette smoke is the result of burning from tobacco, while vape smoke comes from heating liquids that produce steam in the form of smoke. Therefore, researches have been directed to design a smart device that can detect vape smoke by combining multiple gas sensors, for example a MQ2 gas sensor, a MQ7 gas sensor, and a temperature and humidity sensor connected to the microcontroller. Previous tests have returned bad accuracy in detecting Vape. To evaluate that problem, this research proposes feature importance technique to select the appropriate sensor to detect vape smoke by providing a value for each sensor according to the effect on the outcome of the decision. For classification, a random forests method is used that matches the feature importance and firebase as storage media. By using these devices and methods, the sensor is suitable to detect vape smoke so that it gets an accuracy of 94.44% \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Tourism recommender system using Case Based Reasoning Approach (Case Study: Bandung Raya Area)"
        ],
        "penulis":"Fatmawatie, Bamban D.;Baizal Z.K.A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Getting the expert advice to specify a reliable tourist attraction quickly and consistent to the requirements of each tourists was difficult, and the amount of experienced experts who can advise for tourism issues was insufficient. Providing an effective service in tourism sector, such as using the technology of computer system, can be the right solution and very necessary to attract foreign and local tourist to visit the tourist attractions in Bandung. In this paper, we develop the recommender system in tourism using Case Based Reasoning (CBR) method. The CBR system provides recommendations based on solutions from previously solved cases, and suitability between user requirements and features available. Recommendations are given by calculating the similarity values of previously solved cases with new cases. The solutions from previously solved cases with the greatest similarity value will be recommended. Thus, visitors can get recommendations suits to their requirements. In this observation, the given recommendations have an average level of accuracy 91% and 92% with Minimum Similarity Value 80-99%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Getting the expert advice to specify a reliable tourist attraction quickly and consistent to the requirements of each tourists was difficult, and the amount of experienced experts who can advise for tourism issues was insufficient. Providing an effective service in tourism sector, such as using the technology of computer system, can be the right solution and very necessary to attract foreign and local tourist to visit the tourist attractions in Bandung. In this paper, we develop the recommender system in tourism using Case Based Reasoning (CBR) method. The CBR system provides recommendations based on solutions from previously solved cases, and suitability between user requirements and features available. Recommendations are given by calculating the similarity values of previously solved cases with new cases. The solutions from previously solved cases with the greatest similarity value will be recommended. Thus, visitors can get recommendations suits to their requirements. In this observation, the given recommendations have an average level of accuracy 91% and 92% with Minimum Similarity Value 80-99%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Wall effect compensation for detection improvement of through the wall radar"
        ],
        "penulis":"Aliefudin, Fauzan Nur;Arseno, Dharu;Pramudita, Adya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Detecting the objects behind the wall using Through the wall radar (TWR) face several problems due to the wall effect and antenna that used in radar system. The wall effect may degrade the detection result and the reflected signal from the target is therefore difficult to distinguish. Multiple reflection, wall attenuation contribute a distortion to the transmitted signal. In order to overcome the previously mention problems, a compensation method due to the wall effect to improve the detection capability of TWR is proposed in this paper. The proposed method consists of two part. The first part is wall and antenna effect extraction and the second is deconvolution. In this research, the laboratory experiment is performed to investigate the performance of the proposed method. TWR radar is modelled using Vector Network Analyzer (VNA). The experiment results show that the proposed method successfully compensates the wall and antenna effect. So the reflected signal from target can be identified well. The effect can be extracted from received signal during the measurement. It makes the proposed method more realistic to be implemented. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Detecting the objects behind the wall using Through the wall radar (TWR) face several problems due to the wall effect and antenna that used in radar system. The wall effect may degrade the detection result and the reflected signal from the target is therefore difficult to distinguish. Multiple reflection, wall attenuation contribute a distortion to the transmitted signal. In order to overcome the previously mention problems, a compensation method due to the wall effect to improve the detection capability of TWR is proposed in this paper. The proposed method consists of two part. The first part is wall and antenna effect extraction and the second is deconvolution. In this research, the laboratory experiment is performed to investigate the performance of the proposed method. TWR radar is modelled using Vector Network Analyzer (VNA). The experiment results show that the proposed method successfully compensates the wall and antenna effect. So the reflected signal from target can be identified well. The effect can be extracted from received signal during the measurement. It makes the proposed method more realistic to be implemented. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "A cloud computing separation model based on information flow"
        ],
        "penulis":"Ma, Wei;Li, Huanqin;Witarsyah, Deden;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Separation is the primary consideration in cloud computing security. A series of security and safety problems would arise if a separation mechanism is not deployed appropriately, thus affecting the confidence of cloud end-users. In this paper, together with characteristics of cloud computing, the separation issue in cloud computing has been analyzed from the perspective of information flow. The process of information flow in cloud computing systems is formalized to propose corresponding separation rules. These rules have been verified in this paper and it is shown that the rules conform to non-interference security, thus ensuring the security and practicability of the proposed rules. \u00a9 2019 W. Ma et al., published by De Gruyter 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Separation is the primary consideration in cloud computing security. A series of security and safety problems would arise if a separation mechanism is not deployed appropriately, thus affecting the confidence of cloud end-users. In this paper, together with characteristics of cloud computing, the separation issue in cloud computing has been analyzed from the perspective of information flow. The process of information flow in cloud computing systems is formalized to propose corresponding separation rules. These rules have been verified in this paper and it is shown that the rules conform to non-interference security, thus ensuring the security and practicability of the proposed rules. \u00a9 2019 W. Ma et al., published by De Gruyter 2019."
        ]
    },
    {
        "judul":[
            "Numerical Studying of Soliton in the Korteweg-de Vries (KdV) Equation"
        ],
        "penulis":"Yuliawati, Lia;Budhi, Wono Setya;Adytia, Didit;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, we use a numerical approach for finding soliton of the Korteweg-de Vries (KdV) equation in infinite dimensionalization. The traveling wave hypothesis is used to extract the analytic soliton solution of KdV equation. Barbera (1993) shown that KdV equation is a solution of Hamiltonian energy optimization in the level set of the momentum. We numerically solve the optimization problem by using steepest descent method and adding the assumption to guarantee the constraint will be fulfilled. From this method, the dynamic system of the problem is obtained and finite difference implementation is used for solving the dynamic system. Based on the method and the hypothesis, the soliton is obtained. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we use a numerical approach for finding soliton of the Korteweg-de Vries (KdV) equation in infinite dimensionalization. The traveling wave hypothesis is used to extract the analytic soliton solution of KdV equation. Barbera (1993) shown that KdV equation is a solution of Hamiltonian energy optimization in the level set of the momentum. We numerically solve the optimization problem by using steepest descent method and adding the assumption to guarantee the constraint will be fulfilled. From this method, the dynamic system of the problem is obtained and finite difference implementation is used for solving the dynamic system. Based on the method and the hypothesis, the soliton is obtained. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "A scaffolding design for pedagogical agents within the higher-education context"
        ],
        "penulis":"Martha, Ati Suci Dian;Santoso, Harry Budi;Junus, Kasiyah;Suhartanto, Heru;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The use of scaffolding in the design of pedagogical agents has been carried out by many researchers and has a significant impact on online learning. However, how scaffolding by pedagogical agents is applied to individual and group settings is not clearly understood. The scaffolding design in this study consists of an integration of metacognitive scaffolding and motivation scaffolding. The integration of scaffolding will be utilized by a pedagogical agent to facilitate blended learning in a higher education context and we will evaluate the effectiveness of our pedagogical agent model using a quasi-experiment. In this research, we design scaffolding for pedagogical agents within the higher-education context. \u00a9 2019 Association for Computing Machinery.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of scaffolding in the design of pedagogical agents has been carried out by many researchers and has a significant impact on online learning. However, how scaffolding by pedagogical agents is applied to individual and group settings is not clearly understood. The scaffolding design in this study consists of an integration of metacognitive scaffolding and motivation scaffolding. The integration of scaffolding will be utilized by a pedagogical agent to facilitate blended learning in a higher education context and we will evaluate the effectiveness of our pedagogical agent model using a quasi-experiment. In this research, we design scaffolding for pedagogical agents within the higher-education context. \u00a9 2019 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Performance of On-Off Keying Modulation for Free Space Optics Communication"
        ],
        "penulis":"Mutaharrik, Muhammad Ihsan;Syambas, Nana Rachmana;Pamukti, Brian;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One way to support the large need for information services is by building reliable network architectures such as optical networks. The challenge faced in providing an optical network is the process of deploying cables that can change the spatial layout of an area. An alternative solution of that problem is by applying the concept of optical wireless communication such as Free Space Optics. The application of optical wireless communication is affected by barriers between transmitter and receiver. This study focuses on weather factors and atmospheric turbulence factors that affect network performances of Free Space Optics measured by Bit Error Rate (BER) values using Signal-to-Noise Ratio (SNR) calculations. SNR calculation is based on the On - Off Keying modulation scheme which is divided into two, NRZ - OOK and RZ - OOK. In addition, the use of different wavelengths between 690, 780, 850, and 1550 nm will be compared to find out the factor of wavelength selection to the value of BER obtained. The results of this study indicate that the use of the RZ-OOK modulation scheme gives around 1010lower BER value than NRZ-OOK in fog conditions. The wavelength of 1550 nm is very suitable for FSO technology because the BER value is around 1050lower than the other wavelengths. The difference is very significant. Network implementation in accordance with the parameters used in this study can only be implemented in the range of 0 - 1.2 km to get acceptable BER which is correlated to optical communication standard. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One way to support the large need for information services is by building reliable network architectures such as optical networks. The challenge faced in providing an optical network is the process of deploying cables that can change the spatial layout of an area. An alternative solution of that problem is by applying the concept of optical wireless communication such as Free Space Optics. The application of optical wireless communication is affected by barriers between transmitter and receiver. This study focuses on weather factors and atmospheric turbulence factors that affect network performances of Free Space Optics measured by Bit Error Rate (BER) values using Signal-to-Noise Ratio (SNR) calculations. SNR calculation is based on the On - Off Keying modulation scheme which is divided into two, NRZ - OOK and RZ - OOK. In addition, the use of different wavelengths between 690, 780, 850, and 1550 nm will be compared to find out the factor of wavelength selection to the value of BER obtained. The results of this study indicate that the use of the RZ-OOK modulation scheme gives around 1010lower BER value than NRZ-OOK in fog conditions. The wavelength of 1550 nm is very suitable for FSO technology because the BER value is around 1050lower than the other wavelengths. The difference is very significant. Network implementation in accordance with the parameters used in this study can only be implemented in the range of 0 - 1.2 km to get acceptable BER which is correlated to optical communication standard. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Competence classification of twitter users using support vector machine (SVM) method"
        ],
        "penulis":"Rifaldi, Muhammad Haqqi Ghufran;Setiawan, Erwin Budi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Twitter is one of the most popular social media in Indonesia. We freely share and write ideas, information or ideas into the available column (tweet). This convenience makes twitter users have different potential and behavior. In accordance with the experience of himself or his environment. Therefore, it is necessary to have the classification of twitter users to determine and obtain the competence of whether the tweet is credible and in accordance with the condition of the twitter user. The use of the Support Vector Machine method with sequential training optimization on the classification of Twitter tweet data competency, can be used to predict the level of credibility of twitter users. Based on the working principle of the method is to determine a straight line or the best hyperplane that separates two data classes. Then the results obtained in this study are in the form of classification accuracy in 5 categories in 5 scenarios of sharing training data and different testing data, and classification of competencies in each account tested. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Twitter is one of the most popular social media in Indonesia. We freely share and write ideas, information or ideas into the available column (tweet). This convenience makes twitter users have different potential and behavior. In accordance with the experience of himself or his environment. Therefore, it is necessary to have the classification of twitter users to determine and obtain the competence of whether the tweet is credible and in accordance with the condition of the twitter user. The use of the Support Vector Machine method with sequential training optimization on the classification of Twitter tweet data competency, can be used to predict the level of credibility of twitter users. Based on the working principle of the method is to determine a straight line or the best hyperplane that separates two data classes. Then the results obtained in this study are in the form of classification accuracy in 5 categories in 5 scenarios of sharing training data and different testing data, and classification of competencies in each account tested. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Dual-polarized Wideband Horn Antenna with Lower Frequency Extension for Microwave Imaging Application"
        ],
        "penulis":"Oktafiarri, Falin;Syihabuddin, Budi;Hamid, Effrina Yanti;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Horn antenna is frequently used for microwave imaging since its characteristics satisfied the required specification. However, its dimension is too large for low frequency usage and commonly produces single polarization. In this paper, a dual-polarized wideband horn antenna with lower frequency extension is investigated for microwave imaging application. This design is supposed to accommodate the requirements of high resolution. The usage of ridges and dielectric inserted into the horn is proposed to produce dual polarization of the antenna and extend the bandwidth in low frequency. The characterization results show that the proposed antenna yields reflection coefficient less than -10 dB, isolation between ports below - 25 dB and sidelobe level better than -20dB at the frequency range of 2.5-14GHz for each polarization suitable for the desired application. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Horn antenna is frequently used for microwave imaging since its characteristics satisfied the required specification. However, its dimension is too large for low frequency usage and commonly produces single polarization. In this paper, a dual-polarized wideband horn antenna with lower frequency extension is investigated for microwave imaging application. This design is supposed to accommodate the requirements of high resolution. The usage of ridges and dielectric inserted into the horn is proposed to produce dual polarization of the antenna and extend the bandwidth in low frequency. The characterization results show that the proposed antenna yields reflection coefficient less than -10 dB, isolation between ports below - 25 dB and sidelobe level better than -20dB at the frequency range of 2.5-14GHz for each polarization suitable for the desired application. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Incorporating syllabification points into a model of grapheme-to-phoneme conversion"
        ],
        "penulis":"Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A model to convert a grapheme into a phoneme (G2P) is crucial in the natural language processing area. In general, it is developed using a probabilistic-based data-driven approach and directly applied to a sequence of graphemes with no other information. Important research shows that incorporating information of syllabification point is capable of improving a probabilistic-based English G2P. However, the information should be accurately provided by a perfect orthographic syllabification. Some noises or errors of syllabification significantly reduce the G2P performance. In this paper, incorporation of syllabification points into a probabilistic-based G2P model for Bahasa Indonesia is investigated. This information is important since Bahasa Indonesia is richer than English in terms of syllables. A 5-fold cross-validating on 50 k words shows that the incorporation of syllabification points significantly improves the performance of G2P model, where the phoneme error rate (PER) can be relatively reduced by 10.75%. This PER is much lower than the G2P model based on an inductive learning algorithm. An important contribution of this research is that the proposed G2P model is quite robust to syllabification errors. A syllable error rate (SER) of 2.5% that comes from an orthographic syllabification model just slightly increases the PER of the proposed G2P model from 0.83% to be 0.90%. A higher SER up to 10% just increase the PER to be 1.14%. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A model to convert a grapheme into a phoneme (G2P) is crucial in the natural language processing area. In general, it is developed using a probabilistic-based data-driven approach and directly applied to a sequence of graphemes with no other information. Important research shows that incorporating information of syllabification point is capable of improving a probabilistic-based English G2P. However, the information should be accurately provided by a perfect orthographic syllabification. Some noises or errors of syllabification significantly reduce the G2P performance. In this paper, incorporation of syllabification points into a probabilistic-based G2P model for Bahasa Indonesia is investigated. This information is important since Bahasa Indonesia is richer than English in terms of syllables. A 5-fold cross-validating on 50 k words shows that the incorporation of syllabification points significantly improves the performance of G2P model, where the phoneme error rate (PER) can be relatively reduced by 10.75%. This PER is much lower than the G2P model based on an inductive learning algorithm. An important contribution of this research is that the proposed G2P model is quite robust to syllabification errors. A syllable error rate (SER) of 2.5% that comes from an orthographic syllabification model just slightly increases the PER of the proposed G2P model from 0.83% to be 0.90%. A higher SER up to 10% just increase the PER to be 1.14%. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "Development of Test Environment Platform for IMA using COTS components"
        ],
        "penulis":"Wijiutomo, Catur Wirawan;Trilaksono, Bambang Riyanto;Kistijantoro, Achmad Imam;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Avionics software is playing a bigger role in future aircraft. The dilemma is to have the developer grasp the idea of modern avionics based on IMA (integrate Modular Avionics) to use software component re-use on shared resources. in this paper, we propose a test environment for IMA software development that resembles the nature of IMA using a combination of COTS (Commercial of the shelf) hardware and software. We develop AFDX switch with Linux-based router that can build custom ethernet packet that resembles AFDX. We also consider LXC, a Linux container, handled with custom algorithm scheme to control CPU and memory allocation for each container to resemble ARINC 653 standard. The test environment is built as similar as IMA as whole system, as this is not an ideal IMA there is drawback in data communication. That the average jitter for data communication still does not meet ARINC 664 requirement. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Avionics software is playing a bigger role in future aircraft. The dilemma is to have the developer grasp the idea of modern avionics based on IMA (integrate Modular Avionics) to use software component re-use on shared resources. in this paper, we propose a test environment for IMA software development that resembles the nature of IMA using a combination of COTS (Commercial of the shelf) hardware and software. We develop AFDX switch with Linux-based router that can build custom ethernet packet that resembles AFDX. We also consider LXC, a Linux container, handled with custom algorithm scheme to control CPU and memory allocation for each container to resemble ARINC 653 standard. The test environment is built as similar as IMA as whole system, as this is not an ideal IMA there is drawback in data communication. That the average jitter for data communication still does not meet ARINC 664 requirement. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Designing Engineering Data Management System in Research and Development Company"
        ],
        "penulis":"Nur, Muhammad;Andrawina, Luciana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the Global Era, Management Information System has become inseparable part of the company. One of the Management Information System that has been considered important in a company is Engineering Data Management System (EDMS). The role of Engineering Data Management System is to store data as well as providing a user friendly access to the data, as long as the product lifecycle appropriates with the control rules defined before. This study took a case in XYZ Company on designing Engineering Data Management System using Windchill PLM (Product Life Management) to optimize the business process. XYZ Company is a private company that works in research engineering and manufacture. This study brought out new concept using Engineering Data Management System and explains the role of EDMS in XYZ Company's business process. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the Global Era, Management Information System has become inseparable part of the company. One of the Management Information System that has been considered important in a company is Engineering Data Management System (EDMS). The role of Engineering Data Management System is to store data as well as providing a user friendly access to the data, as long as the product lifecycle appropriates with the control rules defined before. This study took a case in XYZ Company on designing Engineering Data Management System using Windchill PLM (Product Life Management) to optimize the business process. XYZ Company is a private company that works in research engineering and manufacture. This study brought out new concept using Engineering Data Management System and explains the role of EDMS in XYZ Company's business process. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Influence of the positive Indian Ocean Dipole in 2012 and El Ni\u00f1o-southern oscillation (ENSO) in 2015 on the Indonesian Rainfall Variability"
        ],
        "penulis":"Mareta, Lesi;Hidayat, Rahmat;Hidayati, Rini;Alsepan, Givo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indian Ocean Dipole (IOD) and El Ni\u00f1o-southern oscillation (ENSO) are coupled ocean - atmosphere variability in the Indo - Pacific Oceans that play important roles to the Indonesian rainfall variability. This study is focused on the influence of the positive IOD in 2012 and El Ni\u00f1o in 2015 on the rainfall in Indonesia using satellite-derived precipitation data. Sea surface temperature (SST), rainfall and wind components, are analyzed to evaluate the detailed evaluation of those events. The results show that, in 2012, the positive IOD develops in July - October and reaches its peak in September. During the positive IOD in 2012, there is a negative SST anomaly in the eastern Indian Ocean (western Sumatra). This causes a shift in the warm water pool to the western Indian Ocean. This shifted warm pool is accompanied by a shift in the convective region, leading to deareased rainfall in the western Sumatra. Mean while, in 2015, El-Ni\u00f1o started to develop from July to November. Negative anomalies of rainfall in the transition period II and the east monsoon season are in line with the SST elevation in the eastern and central Pacific Ocean. So that the eastern and central of the Pacific Ocean become to center of low pressure which causes the air in the eastern Pacific Ocean to upward (convection) which will form a clouds that contain water, so that the eastern and central of the Pacific Ocean will experience an increase in the amount of rainfall while in the western of the Pacific Ocean or the eastern of Indonesia will experience a rainfall deficit. \u00a9 Published under licence by IOP Publishing Ltd.",
            "NNHCH3View detailsExpand Substance Desipramin",
            "Powered by",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indian Ocean Dipole (IOD) and El Ni\u00f1o-southern oscillation (ENSO) are coupled ocean - atmosphere variability in the Indo - Pacific Oceans that play important roles to the Indonesian rainfall variability. This study is focused on the influence of the positive IOD in 2012 and El Ni\u00f1o in 2015 on the rainfall in Indonesia using satellite-derived precipitation data. Sea surface temperature (SST), rainfall and wind components, are analyzed to evaluate the detailed evaluation of those events. The results show that, in 2012, the positive IOD develops in July - October and reaches its peak in September. During the positive IOD in 2012, there is a negative SST anomaly in the eastern Indian Ocean (western Sumatra). This causes a shift in the warm water pool to the western Indian Ocean. This shifted warm pool is accompanied by a shift in the convective region, leading to deareased rainfall in the western Sumatra. Mean while, in 2015, El-Ni\u00f1o started to develop from July to November. Negative anomalies of rainfall in the transition period II and the east monsoon season are in line with the SST elevation in the eastern and central Pacific Ocean. So that the eastern and central of the Pacific Ocean become to center of low pressure which causes the air in the eastern Pacific Ocean to upward (convection) which will form a clouds that contain water, so that the eastern and central of the Pacific Ocean will experience an increase in the amount of rainfall while in the western of the Pacific Ocean or the eastern of Indonesia will experience a rainfall deficit. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Sensitivity analysis of thorax imaging using two-dimensional Electrical Impedance Tomography (EIT)"
        ],
        "penulis":"Andiani L.;Rubiyanto A.;Endarko;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electrical Impedance Tomography (EIT) is a non-invasive medical imaging technique which estimates the electrical impedance distribution within some tissue. The study aimed to assess the performance of the EIT system in a thorax imaging by analysis of sensitivity distribution. Sensitivity distribution was visualized using COMSOL Multiphysics simulation in a human thorax represented as an elliptic cylinder phantom consisting of homogeneous and inhomogeneous medium with varying different dimensions of 16 electrode EIT system. Current density distribution was collected for sensitivity analysis using the neighboring method. The sensitivity distribution at each position in the phantom is different. It is caused by the interaction of current density from transmitter and receiver terminal. The different varying parameter of the system can also influence sensitivity distribution. The sensitivity of inhomogeneous phantom is very non-uniformly distributed. The performance of systems was assessed by analysis of the change of sensitivity with the change of electrode dimensions in the homogeneous and inhomogeneous medium. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electrical Impedance Tomography (EIT) is a non-invasive medical imaging technique which estimates the electrical impedance distribution within some tissue. The study aimed to assess the performance of the EIT system in a thorax imaging by analysis of sensitivity distribution. Sensitivity distribution was visualized using COMSOL Multiphysics simulation in a human thorax represented as an elliptic cylinder phantom consisting of homogeneous and inhomogeneous medium with varying different dimensions of 16 electrode EIT system. Current density distribution was collected for sensitivity analysis using the neighboring method. The sensitivity distribution at each position in the phantom is different. It is caused by the interaction of current density from transmitter and receiver terminal. The different varying parameter of the system can also influence sensitivity distribution. The sensitivity of inhomogeneous phantom is very non-uniformly distributed. The performance of systems was assessed by analysis of the change of sensitivity with the change of electrode dimensions in the homogeneous and inhomogeneous medium. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Few-Bit CSI Acquisition for Centralized Cell-Free Massive MIMO with Spatial Correlation"
        ],
        "penulis":"Maryopi, Dick;Burr, Alister;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The availability and accuracy of Channel State Information (CSI) play a crucial role for coherent detection in almost every communication system. Particularly in the recently proposed cell-free massive MIMO system, in which a large number of distributed Access Points (APs) is connected to a Central processing Unit (CPU) for joint decoding, acquiring CSI at the CPU may improve performance through the use of detection algorithms such as minimum mean square error (MMSE) or zero forcing (ZF). There are also significant challenges, especially the increase in fronthaul load arising from the transfer of high precision CSI, with the resulting complexity and scalability issues. In this paper, we address these CSI acquisition problems by utilizing vector quantization with precision of only a few bits and we show that the accuracy of the channel estimate at the CPU can be increased by exploiting the spatial correlation subject to this limited fronthaul load. Further, we derive an estimator for the simple Quantize-and-Estimate (QE) strategy based on the Bussgang theorem and compare its performance to Estimate-and-Quantize (EQ) in terms of Mean Squared Error (MSE). Our simulation results indicate that the QE with few-bit vector quantization can outperform EQ and individual scalar quantization at moderate SNR for small numbers of bits per dimension. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The availability and accuracy of Channel State Information (CSI) play a crucial role for coherent detection in almost every communication system. Particularly in the recently proposed cell-free massive MIMO system, in which a large number of distributed Access Points (APs) is connected to a Central processing Unit (CPU) for joint decoding, acquiring CSI at the CPU may improve performance through the use of detection algorithms such as minimum mean square error (MMSE) or zero forcing (ZF). There are also significant challenges, especially the increase in fronthaul load arising from the transfer of high precision CSI, with the resulting complexity and scalability issues. In this paper, we address these CSI acquisition problems by utilizing vector quantization with precision of only a few bits and we show that the accuracy of the channel estimate at the CPU can be increased by exploiting the spatial correlation subject to this limited fronthaul load. Further, we derive an estimator for the simple Quantize-and-Estimate (QE) strategy based on the Bussgang theorem and compare its performance to Estimate-and-Quantize (EQ) in terms of Mean Squared Error (MSE). Our simulation results indicate that the QE with few-bit vector quantization can outperform EQ and individual scalar quantization at moderate SNR for small numbers of bits per dimension. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design of Wood Pellet Trolley using Finite Element Method (FEM) and Design for Assembly (DFA) Approach at PT. Perkebunan Nusantara VIII Ciater"
        ],
        "penulis":"Putra R.R.;Rahayu M.;Martini S.;Kurniawan M.I.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PT. Perkebunan Nusantara VIII is a company produces orthodox black tea. The wood pellets distribution in drying station still uses human power without any tools. The process is done as far as five meters with the transport time of each sack for three minutes and the weight is 30 kg. In the previous research has produced a design that used as reference in this research. The purpose of the research is to provide trolley design by applying Finite Element Method and Design for Assembly approach. The method is chosen because the trolley force should be considered so the trolley has good strength. The initially complex and inflexible designs are expected to be simpler and more efficient. The results of this research are wooden pellet trolleys on handle, platform, frame, and stairs chunk are considered safe from the results of the test. While the wheels chunk need to be re-election of material into titanium alloy because it is considered unsafe based on the test results. Then the design of wooden pellet trolleys results in a higher assembly efficiency rating of 27.77% with 127 total components and total processing time of 928.98 seconds so it can be concluded better than reference design. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. Perkebunan Nusantara VIII is a company produces orthodox black tea. The wood pellets distribution in drying station still uses human power without any tools. The process is done as far as five meters with the transport time of each sack for three minutes and the weight is 30 kg. In the previous research has produced a design that used as reference in this research. The purpose of the research is to provide trolley design by applying Finite Element Method and Design for Assembly approach. The method is chosen because the trolley force should be considered so the trolley has good strength. The initially complex and inflexible designs are expected to be simpler and more efficient. The results of this research are wooden pellet trolleys on handle, platform, frame, and stairs chunk are considered safe from the results of the test. While the wheels chunk need to be re-election of material into titanium alloy because it is considered unsafe based on the test results. Then the design of wooden pellet trolleys results in a higher assembly efficiency rating of 27.77% with 127 total components and total processing time of 928.98 seconds so it can be concluded better than reference design. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "K-nearest neighbour classification and feature extraction GLCM for identification of terry's nail"
        ],
        "penulis":"Safira, Laura;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nails have a function or role that is very important to protect the soft fingertips and have a lot of nerves. In the medical world, several expert systems have begun to be used in helping doctors to diagnose a disease. This research was to detect abnormalities of the nails, Terry's nail. The textural characteristics are processed with grey level co-occurrence matrix (GLCM) and classifying method using KNN. The dataset in this study is taken from Google and also some of the paper that discusses the nail abnormalities. Nail pictures obtained are different from any source. Therefore, the image should be cut just one finger. Because when detecting terry's nail, the disorder usually occurs in all the nails. So we can use one finger. The photos of a nail that has been doing the extraction characteristics using GLCM then will be done using KNN classification. In this case the class will be divided into two classes, healthy and Terry's. From the experiment that have been done, the best accuracy results are 70.93% with 60-40 partition of dataset, K=1, light intensity values of 100-500 lux, a distance of 15 cm and an angle of 0\u00b0. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nails have a function or role that is very important to protect the soft fingertips and have a lot of nerves. In the medical world, several expert systems have begun to be used in helping doctors to diagnose a disease. This research was to detect abnormalities of the nails, Terry's nail. The textural characteristics are processed with grey level co-occurrence matrix (GLCM) and classifying method using KNN. The dataset in this study is taken from Google and also some of the paper that discusses the nail abnormalities. Nail pictures obtained are different from any source. Therefore, the image should be cut just one finger. Because when detecting terry's nail, the disorder usually occurs in all the nails. So we can use one finger. The photos of a nail that has been doing the extraction characteristics using GLCM then will be done using KNN classification. In this case the class will be divided into two classes, healthy and Terry's. From the experiment that have been done, the best accuracy results are 70.93% with 60-40 partition of dataset, K=1, light intensity values of 100-500 lux, a distance of 15 cm and an angle of 0\u00b0. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Factors analysis of basic human values at Indonesian insurance company"
        ],
        "penulis":"Gilang, Alini;Syarifuddin, Syarifuddin;Pradana, Mahir;Fakhri, Mahendra;Maisarah, Nabila;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Human capital is a major factor to support the productivity of the company. Value desired to motivate themselves to reach a goal. This research used descriptive type with quantitative method. The population used in this research are employees of PT. Asuransi Jiwa Bumiputera Bandung with amount of 100 employees. The data analysis technique used in this research are descriptive analysis and factor analysis. Descriptive analysis showed that basic human values are in good category and factor analysis showed that there are two new factors formed in the basic human values on employees of PT. Asuransi Jiwa Bumiputera Bandung. These factors are named as the harmony and self-enhancement factors. Harmony factors are represented by universalism, conformity, tradition, security, benevolence and self-direction variables and these factors are the highest contribution in the basic human value. \u00a9 2019 SERSC.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Human capital is a major factor to support the productivity of the company. Value desired to motivate themselves to reach a goal. This research used descriptive type with quantitative method. The population used in this research are employees of PT. Asuransi Jiwa Bumiputera Bandung with amount of 100 employees. The data analysis technique used in this research are descriptive analysis and factor analysis. Descriptive analysis showed that basic human values are in good category and factor analysis showed that there are two new factors formed in the basic human values on employees of PT. Asuransi Jiwa Bumiputera Bandung. These factors are named as the harmony and self-enhancement factors. Harmony factors are represented by universalism, conformity, tradition, security, benevolence and self-direction variables and these factors are the highest contribution in the basic human value. \u00a9 2019 SERSC."
        ]
    },
    {
        "judul":[
            "Efficiency Optimization for Single-Phase Voltage-Sourced Inverter with ZVS-CV"
        ],
        "penulis":"Chi, Pei-Chin;Purnama, Irwan;Chang, Yu-Chen;Chiu, Huang-Jen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Metal-oxide-semiconductor field-effect transistor (MOSFET) can be utilized to raise switching frequency (SF) while zero voltage switching-clamped voltage (ZVS-CV) is a simple technique to eliminate switching loss without extra resonant circuit. Then, heat sink and filter can both be so shrunk that compact inverter can fit the single-phase system in residential site while high efficiency fulfills regulation(s). In order to ensure the ZVS-CV operation, the inverter's filter inductor must flow such high ripple current that can charge or discharge parasitic capacitances of a MOSFET totem pole, however trades off conduction loss of MOSFET. This study proposes a simple scheme for adapting the SF ripple current to the profile of line frequency (LF) sinusoid meanwhile ZVS-CV operation is maintained, thus efficiency is optimized. Simulations are conducted with 220 V 60 Hz LF single phase full-bridge buck inverter to verify the efficiency enhancement on a load about 1 kW. \u00a9 2019 IEEE."
        ],
        "abstrak":[
            "Metal-oxide-semiconductor field-effect transistor (MOSFET) can be utilized to raise switching frequency (SF) while zero voltage switching-clamped voltage (ZVS-CV) is a simple technique to eliminate switching loss without extra resonant circuit. Then, heat sink and filter can both be so shrunk that compact inverter can fit the single-phase system in residential site while high efficiency fulfills regulation(s). In order to ensure the ZVS-CV operation, the inverter's filter inductor must flow such high ripple current that can charge or discharge parasitic capacitances of a MOSFET totem pole, however trades off conduction loss of MOSFET. This study proposes a simple scheme for adapting the SF ripple current to the profile of line frequency (LF) sinusoid meanwhile ZVS-CV operation is maintained, thus efficiency is optimized. Simulations are conducted with 220 V 60 Hz LF single phase full-bridge buck inverter to verify the efficiency enhancement on a load about 1 kW. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Multi Tone Modeling for Seismic Data Compression"
        ],
        "penulis":"Liu, Bo;Mohandes M.;Nuha H.;Deriche M.;Iqbal, Naveed;Fekri, Faramarz;McClellan, James H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG"
        ]
    },
    {
        "judul":[
            "C5.0 algorithm and synthetic minority oversampling technique (SMOTE) for rainfall forecasting in bandung regency"
        ],
        "penulis":"Kurniawan, Erwin;Nhita, Fhira;Aditsania, Annisa;Saepudin, Deni;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Weather is an essential aspect of life because it can affect human activities. Therefore, it is important for weather prediction to have high accuracy. One of the methods used to predict rainfall is data mining. In this study, a classification model was developed using the C5.0 algorithm to forecast rainfall in Bandung Regency. Then, the SMOTE algorithm was used to overcome imbalanced datasets. Weather data for the model development were obtained from the Meteorological, Climatological, and Geophysical Agency (BMKG) of Bandung for the years 2005 until 2017. Subsequently, the model was validated using a k-fold cross-validation. The results of the C5.0 test produced the highest accuracy of 92% for the imbalance dataset, while the accuracy of the addition of data using the SMOTE technique was 99%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Weather is an essential aspect of life because it can affect human activities. Therefore, it is important for weather prediction to have high accuracy. One of the methods used to predict rainfall is data mining. In this study, a classification model was developed using the C5.0 algorithm to forecast rainfall in Bandung Regency. Then, the SMOTE algorithm was used to overcome imbalanced datasets. Weather data for the model development were obtained from the Meteorological, Climatological, and Geophysical Agency (BMKG) of Bandung for the years 2005 until 2017. Subsequently, the model was validated using a k-fold cross-validation. The results of the C5.0 test produced the highest accuracy of 92% for the imbalance dataset, while the accuracy of the addition of data using the SMOTE technique was 99%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Optimal complex power production cost in the electric power market"
        ],
        "penulis":"Zein, Hermagasantos;Raharjo, Jangkung;Mulyadi, Ahmad Deni;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cost reduction issues have received serious attention from actors of power industries during the past decade in the power market mechanism. Appropriate management of reactive power is very essential for supporting power system security. Besides, it has also dominant effects on real energy losses. Furthermore, the reactive power can support the secure operation of the system as an ancillary service. However, most researches have focussed on a transaction of the reactive power in electricity markets. On the other hand, reactive power production of generating is highly dependent on the real power output and only absorbed by the local consumers. As a result, to accommodate a market and to maintain a secure operation of the system, a fair cost allocation method seems to be very essential. Appropriate pricing of reactive power as an ancillary service has been a challenging problem during the past decade. However, most methods proposed so far for reactive power pricing are essentially based on empirical approximations. In this paper, a new method for reducing active and reactive power cost allocations has been proposed. The method is based on optimal cost calculation, which will be imposed on generators producing reactive power. The proposed method is fair, accurate and realistic, simple and easy to be applicated in the power system. Application of the proposed method on IEEE 9-bus standard network confirms its validity and effectiveness. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cost reduction issues have received serious attention from actors of power industries during the past decade in the power market mechanism. Appropriate management of reactive power is very essential for supporting power system security. Besides, it has also dominant effects on real energy losses. Furthermore, the reactive power can support the secure operation of the system as an ancillary service. However, most researches have focussed on a transaction of the reactive power in electricity markets. On the other hand, reactive power production of generating is highly dependent on the real power output and only absorbed by the local consumers. As a result, to accommodate a market and to maintain a secure operation of the system, a fair cost allocation method seems to be very essential. Appropriate pricing of reactive power as an ancillary service has been a challenging problem during the past decade. However, most methods proposed so far for reactive power pricing are essentially based on empirical approximations. In this paper, a new method for reducing active and reactive power cost allocations has been proposed. The method is based on optimal cost calculation, which will be imposed on generators producing reactive power. The proposed method is fair, accurate and realistic, simple and easy to be applicated in the power system. Application of the proposed method on IEEE 9-bus standard network confirms its validity and effectiveness. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Simulation of design and analysis massive MIMO array microstrip rectangular patch dualband 3.5 GHz and 26 GHz for 5G communications"
        ],
        "penulis":"Ramadhan, Luthfi Muhammad;Astuti, Rina Pudji;Nugroho, Bambang Setia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In accordance with the scenario of ITU-R,IMT-2020 or fifth generation (5G) will have 3 scenarios, one of which is Enhanced Mobile Broadband (eMBB). Multi antenna by applying massive MIMO is used on eMBB. Frequency candidates used in the fifth generation (5G) are sub-6 GHz and sub-28 GHz frequencies. This paper focuses on simulating massive MIMO antenna designs that work at 3.5 GHz and 26 GHz frequencies. The antenna is arranged by rectangular patch in the form of an array with 12 patches for the 3.5 GHz frequency and 96 patches for the 26 GHz frequency, so the number of patches on the antenna is 108 patches. The designed antenna will be used as an indoor transmitter antenna. The antenna uses a proximity coupled feed with connectors and dielectric constants 2.2. The designed antenna gets s-parameter result of less than-10.8199 dB, a gain greater than 7.3 dB, and a mutual coupling of less than-32,6201 dB. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In accordance with the scenario of ITU-R,IMT-2020 or fifth generation (5G) will have 3 scenarios, one of which is Enhanced Mobile Broadband (eMBB). Multi antenna by applying massive MIMO is used on eMBB. Frequency candidates used in the fifth generation (5G) are sub-6 GHz and sub-28 GHz frequencies. This paper focuses on simulating massive MIMO antenna designs that work at 3.5 GHz and 26 GHz frequencies. The antenna is arranged by rectangular patch in the form of an array with 12 patches for the 3.5 GHz frequency and 96 patches for the 26 GHz frequency, so the number of patches on the antenna is 108 patches. The designed antenna will be used as an indoor transmitter antenna. The antenna uses a proximity coupled feed with connectors and dielectric constants 2.2. The designed antenna gets s-parameter result of less than-10.8199 dB, a gain greater than 7.3 dB, and a mutual coupling of less than-32,6201 dB. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Practical Decoding Scheme for Doubly Irregular Sparse Code Multiple Access"
        ],
        "penulis":"Hidayat, Iswahyudi;Meylani, Linda;Kurniawan, Adit;Arifianto, M. Sigit;Anwar, Khoirul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Doubly irregular sparse code multiple access (DI-SCMA) is a type of sparse code multiple access (SCMA) with irregular degree distributions both in resource node (RN) and user node (UN) to increase the overloading factor. This paper proposes a practical decoding scheme for DI-SCMA having low computational complexity based on using peeling decoding algorithm. We also use mother constellation capable of detecting 4 users simultaneously based on binary shift keying (BPSK)-like mapping leading to a total constellation similar to the 8 phase shift keying (8-PSK). We evaluate the decoding behaviour of the proposed DI-SCMA using extrinsic information transfer (EXIT) chart and computer simulations. Our results confirm the validity of achievable overloading factor using the practical decoding technique with better bit error rate (BER) performances compared to performances of 8-PSK modulations. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Doubly irregular sparse code multiple access (DI-SCMA) is a type of sparse code multiple access (SCMA) with irregular degree distributions both in resource node (RN) and user node (UN) to increase the overloading factor. This paper proposes a practical decoding scheme for DI-SCMA having low computational complexity based on using peeling decoding algorithm. We also use mother constellation capable of detecting 4 users simultaneously based on binary shift keying (BPSK)-like mapping leading to a total constellation similar to the 8 phase shift keying (8-PSK). We evaluate the decoding behaviour of the proposed DI-SCMA using extrinsic information transfer (EXIT) chart and computer simulations. Our results confirm the validity of achievable overloading factor using the practical decoding technique with better bit error rate (BER) performances compared to performances of 8-PSK modulations. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Smart tracking and fall detection for golden age's citizen"
        ],
        "penulis":"Fauziah, Ratna Juwita;Mutiara, Giva Andriana;Periyadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Senior Citizen is an elderly human in a golden age who has many limitations. The number of older people is increasing in almost every country, including in Indonesia. One of the diseases that were suffered is senile or known as Dementia. Therefore, to protect the elderly, the special care is needed in order to be able to monitor the located and to see the condition of the elderly when they are travelling outside the home. Based on that condition, a prototype of the detector is proposed in this paper namely Smart tracking for the Golden Age's Citizen. This system consists of a GPS module, a vibration sensor, a GSM Module, and a voice recorder module. GPS module will detect the location, and the vibration sensor will detect the vibration if the elderly falls. The GSM module will send the information in the form of SMS to the family. The voice recorder module is used to record and play the recorded sound. Based on the results of the prototype test, the prototype is successfully detecting the location if the elderly is outside the range. The testing was concluding that the older people position can be tracked approximately around 2-5 meters from the determination in google map application and send an SMS in 3-5 seconds, if the user falls or lost. \u00a9 2019 The Authors.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Senior Citizen is an elderly human in a golden age who has many limitations. The number of older people is increasing in almost every country, including in Indonesia. One of the diseases that were suffered is senile or known as Dementia. Therefore, to protect the elderly, the special care is needed in order to be able to monitor the located and to see the condition of the elderly when they are travelling outside the home. Based on that condition, a prototype of the detector is proposed in this paper namely Smart tracking for the Golden Age's Citizen. This system consists of a GPS module, a vibration sensor, a GSM Module, and a voice recorder module. GPS module will detect the location, and the vibration sensor will detect the vibration if the elderly falls. The GSM module will send the information in the form of SMS to the family. The voice recorder module is used to record and play the recorded sound. Based on the results of the prototype test, the prototype is successfully detecting the location if the elderly is outside the range. The testing was concluding that the older people position can be tracked approximately around 2-5 meters from the determination in google map application and send an SMS in 3-5 seconds, if the user falls or lost. \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Malmquist index productivity of Indonesian Bank: Based on commercial bank business group"
        ],
        "penulis":"Octrina, Fajra;Primiana, Ina;Anwar, Mokhamad;Herwany, Aldrin;Rusnoto Susanto, Moh.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to measure the level of productivity of conventional banks in Indonesia during the period of 2012 - 2016 using the method of Malmquist Productivity Index (MPI). Of the 50 bank samples, there are only five banks which have the composition of EFFCH, TECHCH, PECH, SECK and TFPCH \u2265 1, namely Anglomas Bank, Bank Fama, Lampung BPD, Bank of China Limited, JP Morgan Bank, and Bank of Tokyo Mitsubishi. It is because the changes in efficiency and technology are seen to less optimally contribute to enhance the productivity. Design: Malmquist Productivity Index (MPI) method using DEAP 2.1 software.Findings: It shows that banks in the category of BUKU 4 are not yet productive. Moreover, of the total, there are only five banks which indicate the composition of EFFCH, TECHCH, PECH, SECK and TFPCH \u2265 1, namely Anglomas Bank, Bank Fama, Lampung BPD, Bank of China Limited, JP Morgan Bank, and Bank of Tokyo Mitsubishi, all of which are classified into BUKU 1, 2 and 3.Originality and value: This research was conducted to analyze the extent to which the banking sector are productive when viewed based on the Commercial Bank Business Group (BUKU) classification which had not previously been carried out. \u00a9 BEIESP.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to measure the level of productivity of conventional banks in Indonesia during the period of 2012 - 2016 using the method of Malmquist Productivity Index (MPI). Of the 50 bank samples, there are only five banks which have the composition of EFFCH, TECHCH, PECH, SECK and TFPCH \u2265 1, namely Anglomas Bank, Bank Fama, Lampung BPD, Bank of China Limited, JP Morgan Bank, and Bank of Tokyo Mitsubishi. It is because the changes in efficiency and technology are seen to less optimally contribute to enhance the productivity. Design: Malmquist Productivity Index (MPI) method using DEAP 2.1 software.Findings: It shows that banks in the category of BUKU 4 are not yet productive. Moreover, of the total, there are only five banks which indicate the composition of EFFCH, TECHCH, PECH, SECK and TFPCH \u2265 1, namely Anglomas Bank, Bank Fama, Lampung BPD, Bank of China Limited, JP Morgan Bank, and Bank of Tokyo Mitsubishi, all of which are classified into BUKU 1, 2 and 3.Originality and value: This research was conducted to analyze the extent to which the banking sector are productive when viewed based on the Commercial Bank Business Group (BUKU) classification which had not previously been carried out. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Study of squeezer machine performance of cooked soy porridge"
        ],
        "penulis":"Hadi R.M.E.;Chumaidiah E.;Wulandari S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Managers of tofu craftsmen complain a lot on the issue of soybean raw materials that the more days the price is increasing so high, so the benefits gained is decreasing significantly. To anticipate the continuous soybean price increase, the tofu craftsmen plan to make a squeezer machine of cooked soybean porridge which is useful to increase the juice, reduce the time of squeeze, and can ease the squeeze. The benefits of squeezer machine of cooked soybean porridge are that from the aspect of its output it will produce more, that in terms of time it can be faster, that the energy spent is very small because the squeeze utilizes the power of the driving motor, and the tofu dregs produced will be less. The performance study of hygienic tofu making by utilizing a squeezer machine of cooked soybean porridge will be done by comparing the measurement of squeeze time which is currently done by measuring the squeeze time by utilizing the squeezer machine of cooked soybean porridge and measuring the water content in the tofu dregs after the squeeze process. The results are by utilizing the squeezer machine of cooked soybean porridge meet the requirements in accordance with the wishes of the tofu craftsmen in which the water content in the tofu dregs is little, the tofu produced is more, and the process of squeeze is quicker. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Managers of tofu craftsmen complain a lot on the issue of soybean raw materials that the more days the price is increasing so high, so the benefits gained is decreasing significantly. To anticipate the continuous soybean price increase, the tofu craftsmen plan to make a squeezer machine of cooked soybean porridge which is useful to increase the juice, reduce the time of squeeze, and can ease the squeeze. The benefits of squeezer machine of cooked soybean porridge are that from the aspect of its output it will produce more, that in terms of time it can be faster, that the energy spent is very small because the squeeze utilizes the power of the driving motor, and the tofu dregs produced will be less. The performance study of hygienic tofu making by utilizing a squeezer machine of cooked soybean porridge will be done by comparing the measurement of squeeze time which is currently done by measuring the squeeze time by utilizing the squeezer machine of cooked soybean porridge and measuring the water content in the tofu dregs after the squeeze process. The results are by utilizing the squeezer machine of cooked soybean porridge meet the requirements in accordance with the wishes of the tofu craftsmen in which the water content in the tofu dregs is little, the tofu produced is more, and the process of squeeze is quicker. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparison of multi-distance signal level difference hjorth descriptor and its variations for lung sound classifications"
        ],
        "penulis":"Rizal, Achmad;Hidayat, Risanuri;Nugroho, Hanung Adi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A biological signal has the multi-scale and signals complexity properties. Many studies have used the signal complexity calculation methods and multiscale analysis to analyze the biological signal, such as lung sound. Signal complexity methods used in the biological signal analysis include entropy, fractal analysis, and Hjorth descriptor. Meanwhile, the commonly used multiscale methods include wavelet analysis, coarse-grained procedure, and empirical mode decomposition (EMD). One of the multi-scale methods in the biological signal analysis is the multi-distance signal level difference (MSLD), which calculates a difference between two signal samples at a specific distance. In previous studies, MSLD was combined with Hjorth descriptor for lung sound classification. MSLD has the potential to be developed by modifying the fundamental equation of MSLD. This study presents the comparison of MSLD and its variations combined with Hjorth descriptor for lung sound classification. The results showed that MSLD and its variations had the highest accuracy of 98.99% for five lung sound data classes. The results of this study provided several alternatives for multi-scale signal complexity analysis method for biological signals. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A biological signal has the multi-scale and signals complexity properties. Many studies have used the signal complexity calculation methods and multiscale analysis to analyze the biological signal, such as lung sound. Signal complexity methods used in the biological signal analysis include entropy, fractal analysis, and Hjorth descriptor. Meanwhile, the commonly used multiscale methods include wavelet analysis, coarse-grained procedure, and empirical mode decomposition (EMD). One of the multi-scale methods in the biological signal analysis is the multi-distance signal level difference (MSLD), which calculates a difference between two signal samples at a specific distance. In previous studies, MSLD was combined with Hjorth descriptor for lung sound classification. MSLD has the potential to be developed by modifying the fundamental equation of MSLD. This study presents the comparison of MSLD and its variations combined with Hjorth descriptor for lung sound classification. The results showed that MSLD and its variations had the highest accuracy of 98.99% for five lung sound data classes. The results of this study provided several alternatives for multi-scale signal complexity analysis method for biological signals. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Mac-Cormack\u2019s Scheme for Shock Filtering Equation in Image Enhancement"
        ],
        "penulis":"Gunawan P.H.;Gumilar, Agung F.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Mac-Cormack\u2019s scheme is elaborated to approximate the solution of shock filtering equation in image enhancement. This scheme is in second order approximation of spatial and time variables. Here, the comparison results of upwind and Mac-Cormack\u2019s scheme are given. The results show that Mac-Cormack\u2019s scheme is able to preserve the edge discontinuity. For evaluating the performance of numerical results, the discrete L2norm error for both numerical schemes is given. From several experiments, along the increasing of image sizes, the error of Mac-Cormack\u2019s scheme is observed getting smaller. For instance, using image sizes (64,64) the error is obtained 0.13762, meanwhile using (512,512) the error is observed 0.06640. \u00a9 2019, Springer Nature Switzerland AG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mac-Cormack\u2019s scheme is elaborated to approximate the solution of shock filtering equation in image enhancement. This scheme is in second order approximation of spatial and time variables. Here, the comparison results of upwind and Mac-Cormack\u2019s scheme are given. The results show that Mac-Cormack\u2019s scheme is able to preserve the edge discontinuity. For evaluating the performance of numerical results, the discrete L2norm error for both numerical schemes is given. From several experiments, along the increasing of image sizes, the error of Mac-Cormack\u2019s scheme is observed getting smaller. For instance, using image sizes (64,64) the error is obtained 0.13762, meanwhile using (512,512) the error is observed 0.06640. \u00a9 2019, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "A multi-label classification on topics of quranic verses (english translation) using backpropagation neural network with stochastic gradient descent and adam optimizer"
        ],
        "penulis":"Huda, Nanang Saiful;Mubarok, Mohamad Syahrul;Adiwijaya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The Quran is a guideline for all Muslims. In the Quran, many things are talked about. In Quranic studies, the Quran is first classified into several topics according to the discussions of the Quranic verses. In this research, a classification model using a Back Propagation Neural Network was built based on the verses of Al-Quran and its multi-labelled topics. This allows the Back Propagation algorithm architecture to issue labels for each class in the form of 'yes' or 'no' for each output neuron. When using the Back Propagation algorithm, a sentence input that has become a vector is taken. In this way, TF-IDF will be used for feature extraction. Then, the model was evaluated via calculation of Hamming Loss. To ensure an optimal Back Propagation process, a comparison was made between the Stochastic Gradient Descent (SGD) and Adam optimizers. Based on some experiments, the proposed scheme yielded the best performance with a Hamming Loss value of 0.129. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Quran is a guideline for all Muslims. In the Quran, many things are talked about. In Quranic studies, the Quran is first classified into several topics according to the discussions of the Quranic verses. In this research, a classification model using a Back Propagation Neural Network was built based on the verses of Al-Quran and its multi-labelled topics. This allows the Back Propagation algorithm architecture to issue labels for each class in the form of 'yes' or 'no' for each output neuron. When using the Back Propagation algorithm, a sentence input that has become a vector is taken. In this way, TF-IDF will be used for feature extraction. Then, the model was evaluated via calculation of Hamming Loss. To ensure an optimal Back Propagation process, a comparison was made between the Stochastic Gradient Descent (SGD) and Adam optimizers. Based on some experiments, the proposed scheme yielded the best performance with a Hamming Loss value of 0.129. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Comparative analysis of codec G.729 and G.711 on IEEE 802.11AH with MCS and raw slot change mechanism for VOIP service"
        ],
        "penulis":"Nur'afifah, Resma Sonya;Perdana, Doan;Istikmal;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Today, the growth in the number of users is increasing with the development of advanced technology. In addition, this is also accompanied by higher community needs due to technology that is able to support the needs of the community. IEEE 802.11ah is a standardization of the development of IEEE 802.11 that is able to overcome these problems, because the coverage area of the transmission range is up to 1 km, has lower energy consumption, and is capable of serving up to 8191 stations (STA). In this research, an analysis of changes in modulation and coding scheme (MCS) and restricted access window (RAW) Slot will be carried out on the IEEE 802.11ah standard for VoIP services by comparing two codecs, namely G.729 and G.711. In this research, we used network simulators NS-3 on VoIP services by comparing two codecs namely G.729 and G.711 and investigated how they affect network performance. We compare the average delay, throughput, and packet delay ratio (PDR) as network performance parameters. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Today, the growth in the number of users is increasing with the development of advanced technology. In addition, this is also accompanied by higher community needs due to technology that is able to support the needs of the community. IEEE 802.11ah is a standardization of the development of IEEE 802.11 that is able to overcome these problems, because the coverage area of the transmission range is up to 1 km, has lower energy consumption, and is capable of serving up to 8191 stations (STA). In this research, an analysis of changes in modulation and coding scheme (MCS) and restricted access window (RAW) Slot will be carried out on the IEEE 802.11ah standard for VoIP services by comparing two codecs, namely G.729 and G.711. In this research, we used network simulators NS-3 on VoIP services by comparing two codecs namely G.729 and G.711 and investigated how they affect network performance. We compare the average delay, throughput, and packet delay ratio (PDR) as network performance parameters. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "HERO: Maximizing Student Potential to Mobilize Community Empowerment Activities around Campus"
        ],
        "penulis":"Tulloh, Rohmat;Negara, Ridha Muldina;Prasetya, Yayan Eka Yudha;Saputra, Sendy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The Indonesian government continues to strive to create a community empowerment programs, but it is still not evenly distributed and not on target because the needs between organizers and community are not well communicated. Cooperation is needed by all parties for a precise and evenly distributed program. This is what underlies the HERO mobile application built, researchers have conducted surveys on fact that impoverished communities living next to campus but untouched by empowerment program. The HERO application is a form of concern from students who want to bring change to their surroundings. HERO is made with a two-way communication method between students and society. The empowerment program can be initiated by the community directly through the application and students with the potential to help will register, then the scheduled program is carried out by mutual agreement, and vice versa. This method is expected increase empathy among students. This application can accommodate a lot of aspirations from both parties. According to the questionnaire's result, as a program was held, the MOS value of the program participants was 4.62. The functional analysis is stated as passed the test, while compatibility test results, it does not burden the performance of the user's device. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Indonesian government continues to strive to create a community empowerment programs, but it is still not evenly distributed and not on target because the needs between organizers and community are not well communicated. Cooperation is needed by all parties for a precise and evenly distributed program. This is what underlies the HERO mobile application built, researchers have conducted surveys on fact that impoverished communities living next to campus but untouched by empowerment program. The HERO application is a form of concern from students who want to bring change to their surroundings. HERO is made with a two-way communication method between students and society. The empowerment program can be initiated by the community directly through the application and students with the potential to help will register, then the scheduled program is carried out by mutual agreement, and vice versa. This method is expected increase empathy among students. This application can accommodate a lot of aspirations from both parties. According to the questionnaire's result, as a program was held, the MOS value of the program participants was 4.62. The functional analysis is stated as passed the test, while compatibility test results, it does not burden the performance of the user's device. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Typographic-Based Data Augmentation to Improve a Question Retrieval in Short Dialogue System"
        ],
        "penulis":"Nugraha, Helmi Satria;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Many questions posed by users to particular customer service with a short dialog (such as a chatbot) cause difficulties to answer. These reduce the user satisfaction level to the service. A question answering (QA) system can be developed to solve this problem by providing relevant answers to the user questions. One of the commonly used methods to build a QA is a question retrieval (QR) that provides answers based on the most relevant stored-questions. However, interpreting two questions those are essentially the same but in different words is quite challenging. Besides, the limitation of the data set to learn is also interesting. This paper investigates a data augmentation based on typographic and synonym as well as evaluates the use of sub-word (instead of word) features to get the best word-embedding in the question. The word-embedding is then used to search the cosine similarity between a query and the stored-questions. Finally, the user receives an answer based on the question with the highest cosine similarity. Evaluation on a quite low data set shows that the proposed data augmentation is capable of significantly improving the system performance. Besides, the sub-word feature is better for word-embedding in the short conversation than the whole-word one. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Many questions posed by users to particular customer service with a short dialog (such as a chatbot) cause difficulties to answer. These reduce the user satisfaction level to the service. A question answering (QA) system can be developed to solve this problem by providing relevant answers to the user questions. One of the commonly used methods to build a QA is a question retrieval (QR) that provides answers based on the most relevant stored-questions. However, interpreting two questions those are essentially the same but in different words is quite challenging. Besides, the limitation of the data set to learn is also interesting. This paper investigates a data augmentation based on typographic and synonym as well as evaluates the use of sub-word (instead of word) features to get the best word-embedding in the question. The word-embedding is then used to search the cosine similarity between a query and the stored-questions. Finally, the user receives an answer based on the question with the highest cosine similarity. Evaluation on a quite low data set shows that the proposed data augmentation is capable of significantly improving the system performance. Besides, the sub-word feature is better for word-embedding in the short conversation than the whole-word one. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "An efficient technique for cluster number prediction in graph clustering using nullity of laplacian matrix"
        ],
        "penulis":"Atastina, Imelda;Sitohang, Benhard;Saptawati, G.A.Putri;Moertini, Veronica S;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Clustering graph dataset representing users\u2019 interactions can be used to detect groups or communities. Many existing graph clustering algorithms require an initial cluster number. The closer the initial cluster numbers to the real or final ones, the faster the algorithm will converge. Hence, finding the right initial cluster number is important for increasing the efficiency of the algorithms. This research proposes a novel technique for computing the initial cluster number using the nullity of the Laplacian Matrix of Adjacency Matrix. The fact that nullity relates to the properties of the eigenvalues in the Laplacian matrix of a connected component is used to predict the best cluster numbers. By using this technique, trial and error experiments for finding the right clusters is no longer needed. The experiment results using artificial and real dataset and modularity values (for measuring the clusters quality) showed that our proposed technique is efficient in finding initial cluster numbers, which is also the real best cluster numbers. \u00a9 2005 \u2013 ongoing JATIT & LLS.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Clustering graph dataset representing users\u2019 interactions can be used to detect groups or communities. Many existing graph clustering algorithms require an initial cluster number. The closer the initial cluster numbers to the real or final ones, the faster the algorithm will converge. Hence, finding the right initial cluster number is important for increasing the efficiency of the algorithms. This research proposes a novel technique for computing the initial cluster number using the nullity of the Laplacian Matrix of Adjacency Matrix. The fact that nullity relates to the properties of the eigenvalues in the Laplacian matrix of a connected component is used to predict the best cluster numbers. By using this technique, trial and error experiments for finding the right clusters is no longer needed. The experiment results using artificial and real dataset and modularity values (for measuring the clusters quality) showed that our proposed technique is efficient in finding initial cluster numbers, which is also the real best cluster numbers. \u00a9 2005 \u2013 ongoing JATIT & LLS."
        ]
    },
    {
        "judul":[
            "Genomic Anomaly Searching with BLAST Algorithm using MapReduce Framework in Big Data Platform"
        ],
        "penulis":"Dharayani, Ramanti;Wibowo, Wahyu Catur;Ruldeviyani, Yova;Gandhi, Arfive;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Biofarma Corp should adopt big data on vaccine and serum development by analyze genomic sequencing using searching any anomaly. As the root problem, it the anomaly searching requires about 1.62 Terabytes data transient as primary data and 301 Gigabytes as secondary data to get analysis from genomic variance. Moreover Biofarma Corp spent 16 hours for one anomaly searching from 3 Terabytes vaccines. This study proposed big data implementation to handle anomaly searching processes by prioritize less time complexity and less spending storage. It was signalized by a research question, 'How big data technology is applied in searching anomalies on genomic data'. It aimed to implement big data system to facilitate large volume and complex data in order to fulfill business process on Biofarma Corp. It adopted framework architecture as brought by Demchenko, Ngo, and Membrey. This study has designed data flow from FASTA and FATQ as sources for anomalies searching processes. This data flow is facilitated in big data system as designed in this research. As main contribution, this research adopted MapReduce framework to run BLAST algorithm with less spending time. As comparison, MapReduce framework can handle 21, 33, and 55 K-Mer in four minutes respectively while 50 minutes were spent without MapReduce. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Biofarma Corp should adopt big data on vaccine and serum development by analyze genomic sequencing using searching any anomaly. As the root problem, it the anomaly searching requires about 1.62 Terabytes data transient as primary data and 301 Gigabytes as secondary data to get analysis from genomic variance. Moreover Biofarma Corp spent 16 hours for one anomaly searching from 3 Terabytes vaccines. This study proposed big data implementation to handle anomaly searching processes by prioritize less time complexity and less spending storage. It was signalized by a research question, 'How big data technology is applied in searching anomalies on genomic data'. It aimed to implement big data system to facilitate large volume and complex data in order to fulfill business process on Biofarma Corp. It adopted framework architecture as brought by Demchenko, Ngo, and Membrey. This study has designed data flow from FASTA and FATQ as sources for anomalies searching processes. This data flow is facilitated in big data system as designed in this research. As main contribution, this research adopted MapReduce framework to run BLAST algorithm with less spending time. As comparison, MapReduce framework can handle 21, 33, and 55 K-Mer in four minutes respectively while 50 minutes were spent without MapReduce. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Real-time screen sharing using web socket for presenting without projector"
        ],
        "penulis":"Darmawan, Irfan;Rahmatulloh, Alam;Gunawan, Rohmat;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The presentation is generally done using a laptop device or Personal Computer (PC) connected to a projector. Participants see a presentation slide show on a particular screen or white painted the wall. However, sometimes, problems occur when the projectors' equipment is not available to the presentation process does not run optimally. Other problems such as projector damage or dead pixel conditions and rainbow effects on the projector often interfere with the display permanently. A presentation without using a projector is one solution to overcome problems that have been proposed in previous research. However, there is still a particular server that is used by presenters and PCs to access those used by clients. The solution to overcome this problem, in this study, will be developed a system that can carry out the activity of sharing presentation between presenter and audience without using a projector. The presenter only requires an ordinary laptop or PC connected to a wireless network. Participants as clients can access the presentation display via a smartphone that is connected to the same wireless network as the server. The system built consists of two main applications: Screen Sharing Server and Screen Sharing Client, which allows sharing of views by implementing a socket web on its data communication model. Test results with 20 smartphone audiences can see the presentation results from the presenter's laptop. The presentation was successfully carried out with the concept of screen sharing in real-time without using additional projectors and computers, no need for cables and without the need for an internet connection. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The presentation is generally done using a laptop device or Personal Computer (PC) connected to a projector. Participants see a presentation slide show on a particular screen or white painted the wall. However, sometimes, problems occur when the projectors' equipment is not available to the presentation process does not run optimally. Other problems such as projector damage or dead pixel conditions and rainbow effects on the projector often interfere with the display permanently. A presentation without using a projector is one solution to overcome problems that have been proposed in previous research. However, there is still a particular server that is used by presenters and PCs to access those used by clients. The solution to overcome this problem, in this study, will be developed a system that can carry out the activity of sharing presentation between presenter and audience without using a projector. The presenter only requires an ordinary laptop or PC connected to a wireless network. Participants as clients can access the presentation display via a smartphone that is connected to the same wireless network as the server. The system built consists of two main applications: Screen Sharing Server and Screen Sharing Client, which allows sharing of views by implementing a socket web on its data communication model. Test results with 20 smartphone audiences can see the presentation results from the presenter's laptop. The presentation was successfully carried out with the concept of screen sharing in real-time without using additional projectors and computers, no need for cables and without the need for an internet connection. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of the Certainty Factor Method for Early Detection of Cirrhosis Based on Android"
        ],
        "penulis":"Safira, Laura;Irawan, Budhi;Setiningsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the digital era, computers already have an important role in the medical world. One of the roles of the computer is to help diagnose a patient's disease. Cirrhosis is a disease that attacks all parts of the liver with the formation of connective tissue characterized by nodules. Cirrhosis is also a chronic liver disease in which the liver is slowly damaged which lasts for a long time. This damage can expand so that the liver can stop functioning. This condition is called liver failure. An application to detect an illness desperately needs an expert system that functions as the brain of a machine. Accurate and precise calculations are needed to diagnose symptoms so that they can infer output using the certainty Factor (CF). This paper describes a process to detect liver disease based on weighting combinations of symptoms. A Smartphone application is produced which requires patients to answer about ten questions. The final result of this application is a diagnosis of cirrhosis. From the results of the experiment, it can be concluded that the accuracy of this application is 100% \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the digital era, computers already have an important role in the medical world. One of the roles of the computer is to help diagnose a patient's disease. Cirrhosis is a disease that attacks all parts of the liver with the formation of connective tissue characterized by nodules. Cirrhosis is also a chronic liver disease in which the liver is slowly damaged which lasts for a long time. This damage can expand so that the liver can stop functioning. This condition is called liver failure. An application to detect an illness desperately needs an expert system that functions as the brain of a machine. Accurate and precise calculations are needed to diagnose symptoms so that they can infer output using the certainty Factor (CF). This paper describes a process to detect liver disease based on weighting combinations of symptoms. A Smartphone application is produced which requires patients to answer about ten questions. The final result of this application is a diagnosis of cirrhosis. From the results of the experiment, it can be concluded that the accuracy of this application is 100% \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Estimote-based location awareness on mobile devices for visually impaired"
        ],
        "penulis":"Mutiara, Giva Andriana;Hapsari, Gita Indah;Periyadi;Pratondo, Agus;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The limitations vision that possessed by the visually impaired in interacting with their environment, causing them to have difficulties in doing traveling. But, along with the development of smartphone technology, the visually impaired people began using smartphones to help them engage in any activities. Estimote beacons are a small device that broadcast a Bluetooth signal that can be captured by a smartphone. This research contributions to provide the information to the visually impaired person in order to have easy use compatible with the smartphone since the Estimote beacons are used as a location awareness device to give the information about the surrounding environment. The systems were configured and programmed using android studio for indoor and outdoor locations. Based on the indoor result testing, it can be stated that the implementation of the Estimote beacon as a location awareness in indoor area, must be focused on the installation of the Estimote beacons. The installation must be set smoothly and the broadcast signal should not be overlap. The outdoor result testing indicates that the Estimote beacon signal is stable to receive on the smartphone at a distance 0 \u2013 31.64 meters, begin unstable at a distance of 38.61 meter and become undetected at a distance of 79.79 meters. \u00a9 2005 \u2013 ongoing JATIT & LLS.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The limitations vision that possessed by the visually impaired in interacting with their environment, causing them to have difficulties in doing traveling. But, along with the development of smartphone technology, the visually impaired people began using smartphones to help them engage in any activities. Estimote beacons are a small device that broadcast a Bluetooth signal that can be captured by a smartphone. This research contributions to provide the information to the visually impaired person in order to have easy use compatible with the smartphone since the Estimote beacons are used as a location awareness device to give the information about the surrounding environment. The systems were configured and programmed using android studio for indoor and outdoor locations. Based on the indoor result testing, it can be stated that the implementation of the Estimote beacon as a location awareness in indoor area, must be focused on the installation of the Estimote beacons. The installation must be set smoothly and the broadcast signal should not be overlap. The outdoor result testing indicates that the Estimote beacon signal is stable to receive on the smartphone at a distance 0 \u2013 31.64 meters, begin unstable at a distance of 38.61 meter and become undetected at a distance of 79.79 meters. \u00a9 2005 \u2013 ongoing JATIT & LLS."
        ]
    },
    {
        "judul":[
            "Multiple pivots in statistical machine translation for low resource languages"
        ],
        "penulis":"Budiwati, Sari Dewi;Aritsugi, Masayoshi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We investigate many combinations of multiple pivots of four phrase tables on a low resource language pair, i.e., Japanese to Indonesia, in phrase-based Statistical Machine Translation. English, Myanmar, Malay, and Filipino from Asian Language Treebank (ALT) were used as pivot languages. A combination of four phrase tables was examined with and without a source to target phrase table. Linear and Fillup Interpolation approaches were employed with two measurement parameters, namely, data types and phrase table orders. The dataset was divided into two data types, i.e., sequential and random. Furthermore, phrase table orders comprise of two, viz., descending and ascending. Experimental results show that the combination of multiple pivots outperformed the baseline. Moreover, the random type significantly improved BLEU scores, with the highest improvement by +0.23 and +1.02 for Japanese to Indonesia (Ja-Id) and Indonesia to Japanese (Id-Ja), respectively. Phrase tables order experiments show a different result for Ja-Id and Id-Ja. The descending order has a higher percentage as much as 87.5% compared to the ascending order in Ja-Id. Meanwhile, the ascending order obtained more than 90% in Id-Ja. Finally, the combination of multiple pivots attempt shows a significant effect to reduce perplexity score in Ja-Id and Id-Ja. Copyright \u00a9 2019 Sari Dewi Budiwati and Masayoshi Aritsugi.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We investigate many combinations of multiple pivots of four phrase tables on a low resource language pair, i.e., Japanese to Indonesia, in phrase-based Statistical Machine Translation. English, Myanmar, Malay, and Filipino from Asian Language Treebank (ALT) were used as pivot languages. A combination of four phrase tables was examined with and without a source to target phrase table. Linear and Fillup Interpolation approaches were employed with two measurement parameters, namely, data types and phrase table orders. The dataset was divided into two data types, i.e., sequential and random. Furthermore, phrase table orders comprise of two, viz., descending and ascending. Experimental results show that the combination of multiple pivots outperformed the baseline. Moreover, the random type significantly improved BLEU scores, with the highest improvement by +0.23 and +1.02 for Japanese to Indonesia (Ja-Id) and Indonesia to Japanese (Id-Ja), respectively. Phrase tables order experiments show a different result for Ja-Id and Id-Ja. The descending order has a higher percentage as much as 87.5% compared to the ascending order in Ja-Id. Meanwhile, the ascending order obtained more than 90% in Id-Ja. Finally, the combination of multiple pivots attempt shows a significant effect to reduce perplexity score in Ja-Id and Id-Ja. Copyright \u00a9 2019 Sari Dewi Budiwati and Masayoshi Aritsugi."
        ]
    },
    {
        "judul":[
            "Choosing The Most Optimum Text Preprocessing Method for Sentiment Analysis: Case:iPhone Tweets"
        ],
        "penulis":"Resyanto, Fero;Sibaroni, Yuliant;Romadhony, Ade;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Preprocessing is the initial stage in several text processing tasks, including sentiment analysis. Preprocessing is an important step in sentiment analysis because it could affect the result accuracy significantly. However, previous studies on preprocessing that discussed the selection of preprocessing methods were rarely conducted. In this study, we analyze the effect of preprocessing methods on sentiment analysis task. We performed the sentiment analysis as a classification on product opinion, whether the sentiment is positive or negative. We conducted an experiment using Tweets that talk about iPhone. We observed seven different preprocessing methods and the combination of it. The preprocessing methods are: casefolding, expressive lengthening, emoticons handling, removing URLs, slang handling, punctuations handling, stopwords removal and stemming. The results show that a combination of five methods: URL removal, emoticon handling, case folding, expressive lengthening and stemming is the most optimum method with an accuracy of 70.88% on sentiment analysis. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Preprocessing is the initial stage in several text processing tasks, including sentiment analysis. Preprocessing is an important step in sentiment analysis because it could affect the result accuracy significantly. However, previous studies on preprocessing that discussed the selection of preprocessing methods were rarely conducted. In this study, we analyze the effect of preprocessing methods on sentiment analysis task. We performed the sentiment analysis as a classification on product opinion, whether the sentiment is positive or negative. We conducted an experiment using Tweets that talk about iPhone. We observed seven different preprocessing methods and the combination of it. The preprocessing methods are: casefolding, expressive lengthening, emoticons handling, removing URLs, slang handling, punctuations handling, stopwords removal and stemming. The results show that a combination of five methods: URL removal, emoticon handling, case folding, expressive lengthening and stemming is the most optimum method with an accuracy of 70.88% on sentiment analysis. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Improving AdaBoost-based Intrusion Detection System (IDS) Performance on CIC IDS 2017 Dataset"
        ],
        "penulis":"Yulianto, Arif;Sukarno, Parman;Suwastika, Novian Anggis;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper considers the use of Synthetic Minority Oversampling Technique (SMOTE), Principal Component Analysis (PCA), and Ensemble Feature Selection (EFS) to improve the performance of AdaBoost-based Intrusion Detection System (IDS) on the latest and challenging CIC IDS 2017 Dataset [1]. Previous research [1] has proposed the use of AdaBoost classifier to cope with the new dataset. However, due to several problems such as imbalance of training data and inappropriate selection of classification methods, the performance is still inferior. In this research, we aim at constructing an improvement performance intrusion detection approach to handle the imbalance of training data, SMOTE is selected to tackle the problem. Moreover, Principal Component Analysis (PCA) and Ensemble Feature Selection (EFS) are applied as the feature selection to select important attributes from the new dataset. The evaluation results show that the proposed AdaBoost classifier using PCA and SMOTE yields Area Under the Receiver Operating Characteristic curve (AUROC) of 92% and the AdaBoost classifier using EFS and SMOTE produces an accuracy, precision, recall, and F1 Score of 81.83 %, 81.83%, 100%, and 90.01% respectively. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper considers the use of Synthetic Minority Oversampling Technique (SMOTE), Principal Component Analysis (PCA), and Ensemble Feature Selection (EFS) to improve the performance of AdaBoost-based Intrusion Detection System (IDS) on the latest and challenging CIC IDS 2017 Dataset [1]. Previous research [1] has proposed the use of AdaBoost classifier to cope with the new dataset. However, due to several problems such as imbalance of training data and inappropriate selection of classification methods, the performance is still inferior. In this research, we aim at constructing an improvement performance intrusion detection approach to handle the imbalance of training data, SMOTE is selected to tackle the problem. Moreover, Principal Component Analysis (PCA) and Ensemble Feature Selection (EFS) are applied as the feature selection to select important attributes from the new dataset. The evaluation results show that the proposed AdaBoost classifier using PCA and SMOTE yields Area Under the Receiver Operating Characteristic curve (AUROC) of 92% and the AdaBoost classifier using EFS and SMOTE produces an accuracy, precision, recall, and F1 Score of 81.83 %, 81.83%, 100%, and 90.01% respectively. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Person entity recognition for the Indonesian Qur'an translation with the approach hidden Markov model-viterbi"
        ],
        "penulis":"Syachrul R.M.M.A.K.;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Qur'an contains teachings about life given by Allah to the Prophet Muhammad. In the Qur'an, there are a lot of verses. With a large number of verses, it will be very difficult and take a long time for us to find a name. Manually searching for entities will be very difficult and take a long time to be searched. With NER, which is one of the techniques of information extraction that aims to detect entity names, such as people's names, locations, events, and time expected search for entity names in the Qur'an will significantly simplify and shorten the time. Indonesian Qur'an translations will later be used as Inputs, and their names are entity names. The solution to the problem above is to use NER. The Named Entity (NE) Recognition (NER) system will look for name entities people from the corpus that have been created. In applying NER requires a model to detect name entities in a text. Hidden Markov Model-Viterbi is a machine learning algorithm type Supervised Learning which will be applied. In the development of a system for searching names entities for the Indonesian translation of the Qur'an dataset have best F1 results is 76%. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Qur'an contains teachings about life given by Allah to the Prophet Muhammad. In the Qur'an, there are a lot of verses. With a large number of verses, it will be very difficult and take a long time for us to find a name. Manually searching for entities will be very difficult and take a long time to be searched. With NER, which is one of the techniques of information extraction that aims to detect entity names, such as people's names, locations, events, and time expected search for entity names in the Qur'an will significantly simplify and shorten the time. Indonesian Qur'an translations will later be used as Inputs, and their names are entity names. The solution to the problem above is to use NER. The Named Entity (NE) Recognition (NER) system will look for name entities people from the corpus that have been created. In applying NER requires a model to detect name entities in a text. Hidden Markov Model-Viterbi is a machine learning algorithm type Supervised Learning which will be applied. In the development of a system for searching names entities for the Indonesian translation of the Qur'an dataset have best F1 results is 76%. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "The synthesis of fiber membranes from High-Impact Polystyrene (HIPS) Waste using needleless electrospinning as air filtration media"
        ],
        "penulis":"Zulfi, Akmal;Hapidin, Dian Ahmad;Saputra, Casmika;Mustika, Widya Sinta;Munir, Muhammad Miftahul;Khairurrijal, Khairurrijal;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The production and characterization of air filter membranes from HIPS waste are presented. The HIPS membranes were synthesized using needleless electrospinning. The HIPS precursor solutions were made by dissolving the HIPS waste in the d-limonene:DMF solvent mixing ratio of 3:1, 1:1, and 1:3. The different mixing ratio led to different viscosity, surface tension, and fiber morphology. Beaded to fine fiber morphology were obtained by increasing the DMF concentration in the mixing solvent. The filtration test using PM2.5as test particles demonstrated the good performance of the HIPS membrane as an air filter media (filtration efficiency up to 98.75%). \u00a9 2019 Elsevier Ltd. All rights reserved.",
            "H3CH2CCH3View detailsExpand Substance D-limonene",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The production and characterization of air filter membranes from HIPS waste are presented. The HIPS membranes were synthesized using needleless electrospinning. The HIPS precursor solutions were made by dissolving the HIPS waste in the d-limonene:DMF solvent mixing ratio of 3:1, 1:1, and 1:3. The different mixing ratio led to different viscosity, surface tension, and fiber morphology. Beaded to fine fiber morphology were obtained by increasing the DMF concentration in the mixing solvent. The filtration test using PM2.5as test particles demonstrated the good performance of the HIPS membrane as an air filter media (filtration efficiency up to 98.75%). \u00a9 2019 Elsevier Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Detection of face spoofing using low-level features and shape analysis"
        ],
        "penulis":"Arini D.D.;Ramadhani K.N.;Sthevanie F.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Face as a security system has a vulnerability to the spoofing attack because by falsifying faces using certain media such as photos or videos can fool the system. In this study, we proposed a spoofing detection system on human faces that good to distinguish spoof and non- spoof face using Low-Level Feature: Speeded-Up Robust Features (SURF) and Shape Analysis: Pyramid Histogram of Oriented Gradient (PHOG) as the feature extraction. We tested our method on 2 scenarios: intra-database and cross-database, using 4 different public datasets: MSU MFSD, NUAA Imposter, CASIA FASD, and IDIAP Replay-Attack. We used Support Vector Machine (SVM) and k-Nearest Neighbors (k-NN) as classification. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Face as a security system has a vulnerability to the spoofing attack because by falsifying faces using certain media such as photos or videos can fool the system. In this study, we proposed a spoofing detection system on human faces that good to distinguish spoof and non- spoof face using Low-Level Feature: Speeded-Up Robust Features (SURF) and Shape Analysis: Pyramid Histogram of Oriented Gradient (PHOG) as the feature extraction. We tested our method on 2 scenarios: intra-database and cross-database, using 4 different public datasets: MSU MFSD, NUAA Imposter, CASIA FASD, and IDIAP Replay-Attack. We used Support Vector Machine (SVM) and k-Nearest Neighbors (k-NN) as classification. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Air transportation network robustness under random and hub-based disruptions"
        ],
        "penulis":"Alamsyah, Andry;Ramadhani, Dian Puteri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Air transportation facilitates important connectivity to drive economic growth and development. Airports and airline companies are considered as two important components in flight activities. Those components construct an interconnected air transportation network. The highly connected network is susceptible against some disruptions. We simulate disruptions in two percolation scenarios, specifically random failures and hub-based attacks. The disruption consequences are examined through network robustness approach. The size of survived connected component and survived link is used as the network robustness measurement. Understanding air transportation network robustness is necessary since the air transportation inefficiency generates a huge level of economic and social costs. Air transportation is a notable and efficient transportation mode in Indonesia since having a wide-spread maritime territory. This research presents an insight of air transportation network robustness under disruptions with domestic flights in Indonesia as a case study and experiment. We discover that flight activities form a scale-free network with heavy-tailed distribution. Air transportation network is robust under random failures but extremely fragile under hub-based attacks. Percolation scenarios facilitate better understanding of disruption consequences on complex air transportation network and support the integrated national air transportation system planning. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Air transportation facilitates important connectivity to drive economic growth and development. Airports and airline companies are considered as two important components in flight activities. Those components construct an interconnected air transportation network. The highly connected network is susceptible against some disruptions. We simulate disruptions in two percolation scenarios, specifically random failures and hub-based attacks. The disruption consequences are examined through network robustness approach. The size of survived connected component and survived link is used as the network robustness measurement. Understanding air transportation network robustness is necessary since the air transportation inefficiency generates a huge level of economic and social costs. Air transportation is a notable and efficient transportation mode in Indonesia since having a wide-spread maritime territory. This research presents an insight of air transportation network robustness under disruptions with domestic flights in Indonesia as a case study and experiment. We discover that flight activities form a scale-free network with heavy-tailed distribution. Air transportation network is robust under random failures but extremely fragile under hub-based attacks. Percolation scenarios facilitate better understanding of disruption consequences on complex air transportation network and support the integrated national air transportation system planning. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Designing of Raw Material Scheduling Supply Multi on Supplier Strategies with Price, Lead time, and Stochastic Demand Variations. Case Study: Electricity Manufacturer"
        ],
        "penulis":"Amelia P.;Ridwan A.Y.;Santosa B.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Raw Materials are one of the important things in manufacture. The availability of these items is very important for the production process to take place. The researcher will research an electricity company. The electricity company produces electricity equipment. The four types of electricity equipment are cartridges, thermocouples, tubular and mica heaters. Some of them have stochastic demand. Each of them has three components of the same raw material and used to make the product. However, the company cannot fulfil the demand because raw materials are not available, so consumers are looking for items elsewhere. This delay occurred because of the delay in sending raw materials, so the company has to wait until the ordered items arrive. This problem is being more complicated by the differences in parameters for each supplier such as price differences and lead time of arrival. Therefore, the company must determine the optimum scheduling and safety time by minimizing inventory costs as a result of Mixed Integer Linear Programming (MILP) being used in resolving these problems. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Raw Materials are one of the important things in manufacture. The availability of these items is very important for the production process to take place. The researcher will research an electricity company. The electricity company produces electricity equipment. The four types of electricity equipment are cartridges, thermocouples, tubular and mica heaters. Some of them have stochastic demand. Each of them has three components of the same raw material and used to make the product. However, the company cannot fulfil the demand because raw materials are not available, so consumers are looking for items elsewhere. This delay occurred because of the delay in sending raw materials, so the company has to wait until the ordered items arrive. This problem is being more complicated by the differences in parameters for each supplier such as price differences and lead time of arrival. Therefore, the company must determine the optimum scheduling and safety time by minimizing inventory costs as a result of Mixed Integer Linear Programming (MILP) being used in resolving these problems. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Ramadhan short-term electric load: A hybrid model of cycle spinning wavelet and group method data handling (CSW-GMDH)"
        ],
        "penulis":"Caraka, Rezzy Eko;Chen, Rung Ching;Toharudin, Toni;Pardamean, Bens;Bakar, Sakhinah Abu;Yasin, Hasbi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In general, performing a nonlinearity time series analysis in the modeling of data can reach a robust and increase the quality of the results. Wavelet methods have successfully been applied in a great variety of applications for modeling also forecasting. Wavelet Transform divided into two categories. There is continuous wavelet (CWT) and a discrete wavelet transform (DWT). Cycle spinning unlike the discrete wavelet transform (DWT), is highly redundant, non-orthogonal, also defined naturally for all sample sizes. There is a Group Method of Data Handling (GMDH) algorithm, which is a multivariate analysis method can be used in modeling and identifying uncertainty on linear also nonlinearity systems. In this paper, we aim to explain the combination of A-Trous wavelet transforms applied on cycle spinning and group method of data handling (GMDH) in data of short-term electric load holy month of Ramadhan from 2014 to 2015. \u00a9 2019, International Association of Engineers.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In general, performing a nonlinearity time series analysis in the modeling of data can reach a robust and increase the quality of the results. Wavelet methods have successfully been applied in a great variety of applications for modeling also forecasting. Wavelet Transform divided into two categories. There is continuous wavelet (CWT) and a discrete wavelet transform (DWT). Cycle spinning unlike the discrete wavelet transform (DWT), is highly redundant, non-orthogonal, also defined naturally for all sample sizes. There is a Group Method of Data Handling (GMDH) algorithm, which is a multivariate analysis method can be used in modeling and identifying uncertainty on linear also nonlinearity systems. In this paper, we aim to explain the combination of A-Trous wavelet transforms applied on cycle spinning and group method of data handling (GMDH) in data of short-term electric load holy month of Ramadhan from 2014 to 2015. \u00a9 2019, International Association of Engineers."
        ]
    },
    {
        "judul":[
            "A new metaheuristics for solving traveling salesman problem: Partial comparison optimization"
        ],
        "penulis":"Adhi, Antono;Santosa, Budi;Siswanto, Nurhadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research article proposes new metaheuristics method to solve Traveling Salesman Problem (TSP). This method is called Partial Comparison Optimization (PCO). TSP is defined as a problem where a salesman must visit all cities where each city is only visited once, and must start from and return to the origin city. The goal of solving this problem is to determine the route with minimum total distance or cost. TSP was first formulated in 1930 and it is one of the most intensively studied problems in optimization. Variants and various application of TSP have been developed and solved to accomodate industrial problems. TSP is an NP-hard combinatorial optimization problem. It means TSP can be solved in polynomial time. Exact methods are hard to solve big size TSP problem. The process of the exact method needs longer computational time to solve the problem. The limitation of exact method in dealing with complex TSP only can be solved by metaheuristics. PCO is powerful metaheuristic to solve combinatorial problems such as TSP. To test the performance of PCO, it was used to solve some TSPLIB instances. In this research PCO gave good optimum solution that almost close to the optimal solution of every TSPLIB instance. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research article proposes new metaheuristics method to solve Traveling Salesman Problem (TSP). This method is called Partial Comparison Optimization (PCO). TSP is defined as a problem where a salesman must visit all cities where each city is only visited once, and must start from and return to the origin city. The goal of solving this problem is to determine the route with minimum total distance or cost. TSP was first formulated in 1930 and it is one of the most intensively studied problems in optimization. Variants and various application of TSP have been developed and solved to accomodate industrial problems. TSP is an NP-hard combinatorial optimization problem. It means TSP can be solved in polynomial time. Exact methods are hard to solve big size TSP problem. The process of the exact method needs longer computational time to solve the problem. The limitation of exact method in dealing with complex TSP only can be solved by metaheuristics. PCO is powerful metaheuristic to solve combinatorial problems such as TSP. To test the performance of PCO, it was used to solve some TSPLIB instances. In this research PCO gave good optimum solution that almost close to the optimal solution of every TSPLIB instance. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "Defining, designing, and implementing rural smartness"
        ],
        "penulis":"Mukti, Iqbal Yulizar;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The adoption of urban smartness concept for the rural area is recently gaining attention, especially as a vehicle to improve the citizens' economic welfare. In this context, this paper presents ongoing research exploring the adoption effort through the development of e-government service platform that facilitates the entrepreneurial discovery as the key for rural area's economic growth. This research follows the design science research methodology (DSRM) as the guidance in defining, designing, and implementing the research artefacts. There are two main research artefacts will be delivered from this research that expected to fill in the gaps from the previous works. First, the theoretical model that describes the key features of urban smartness concept for the realisation of economic benefit for the citizens in a rural area. Second, the design of the e-government service platform customised to the rural context. These research artefacts will be demonstrated and validated using a case study in West Java province, Indonesia, as the region has a strong vision to improve the economic welfare of the people in their rural area through digital initiatives. As the preliminary result, this research proposes a conceptual framework that suggests the urban smartness technology, combined with the organisational and environmental capabilities, can lead to the improvement of the economic welfare of the citizens in rural area through a process that encourages innovation in the local communities. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Peace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The adoption of urban smartness concept for the rural area is recently gaining attention, especially as a vehicle to improve the citizens' economic welfare. In this context, this paper presents ongoing research exploring the adoption effort through the development of e-government service platform that facilitates the entrepreneurial discovery as the key for rural area's economic growth. This research follows the design science research methodology (DSRM) as the guidance in defining, designing, and implementing the research artefacts. There are two main research artefacts will be delivered from this research that expected to fill in the gaps from the previous works. First, the theoretical model that describes the key features of urban smartness concept for the realisation of economic benefit for the citizens in a rural area. Second, the design of the e-government service platform customised to the rural context. These research artefacts will be demonstrated and validated using a case study in West Java province, Indonesia, as the region has a strong vision to improve the economic welfare of the people in their rural area through digital initiatives. As the preliminary result, this research proposes a conceptual framework that suggests the urban smartness technology, combined with the organisational and environmental capabilities, can lead to the improvement of the economic welfare of the citizens in rural area through a process that encourages innovation in the local communities. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Price prediction of chili in bandung regency using support vector machine (SVM) optimized with an adaptive neuro-fuzzy inference system (ANFIS)"
        ],
        "penulis":"Nurcahyono, Asma Hasifa;Nhita, Fhira;Saepudin, Deni;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The price fluctuation of chili is one of the economic problems faced by every chili-producing country in the world, including in Indonesia. Chili is a vegetable that is consumed almost every day by the people of Indonesia. In Bandung district area, chili has been experiencing price fluctuations in the last four years, according to data obtained from the Bandung Regency Area Trade and Industry Service. Many factors cause the price of chili to fluctuate-one of them being the weather. This is because chili is a plant that is easily damaged if exposed to too much water. This research predicts chili prices in Bandung Regency using the Support Vector Machine (SVM) algorithm, which is optimized by an Adaptive Neuro-Fuzzy Inference System (ANFIS) and based on weather factors. The average accuracy of training and testing data was 94.07%; the training and testing data using the SVM algorithm produced 89.90% average accuracy and the average accuracy of training and testing data using the ANFIS algorithm was 92.68%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The price fluctuation of chili is one of the economic problems faced by every chili-producing country in the world, including in Indonesia. Chili is a vegetable that is consumed almost every day by the people of Indonesia. In Bandung district area, chili has been experiencing price fluctuations in the last four years, according to data obtained from the Bandung Regency Area Trade and Industry Service. Many factors cause the price of chili to fluctuate-one of them being the weather. This is because chili is a plant that is easily damaged if exposed to too much water. This research predicts chili prices in Bandung Regency using the Support Vector Machine (SVM) algorithm, which is optimized by an Adaptive Neuro-Fuzzy Inference System (ANFIS) and based on weather factors. The average accuracy of training and testing data was 94.07%; the training and testing data using the SVM algorithm produced 89.90% average accuracy and the average accuracy of training and testing data using the ANFIS algorithm was 92.68%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Complement Attributes Reduction in Soft Sets for Decision Making"
        ],
        "penulis":"Mohammed, Mohammed Adam Taheir;Mohd, Wan Maseri Wan;Arshah, Ruzaini Abdullah;Mungad M.;Sutoyo, Edi;Chiroma, Haruna;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper overcome the false parameters from soft set which focuses on original decision partitions order whereas in some cases the decision partition order not induced original set extensions or the reductions of original set maybe not significant. Based on the priority the decision partition order can be constructed to match whether the sub set is the core of optimal decision or deciding for removing a particular sub set if their complement decision partition order status is match the original classifications. The proposed method has successfully maintained the optimal and sub optimal result. This method overcome the false parameters because it directly forwarded to reduction set. It has been validated that it is effective for parameter reduction even in large sub sets. \u00a9 Springer Nature Singapore Pte Ltd. 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper overcome the false parameters from soft set which focuses on original decision partitions order whereas in some cases the decision partition order not induced original set extensions or the reductions of original set maybe not significant. Based on the priority the decision partition order can be constructed to match whether the sub set is the core of optimal decision or deciding for removing a particular sub set if their complement decision partition order status is match the original classifications. The proposed method has successfully maintained the optimal and sub optimal result. This method overcome the false parameters because it directly forwarded to reduction set. It has been validated that it is effective for parameter reduction even in large sub sets. \u00a9 Springer Nature Singapore Pte Ltd. 2019."
        ]
    },
    {
        "judul":[
            "Face recognition system Using Deep Neural Network with Convolutional Neural Networks"
        ],
        "penulis":"Fernando, Erick;Andwiyan, Denny;Fitria Murad, Dina;Touriano, Derist;Irsan, Muhamad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Face recognition has long been a hot topic and challenging research point in areas such as image processing, pattern recognition, and machine vision. The face is a biometric feature with the intrinsic nature of a human. So that the face has self-stability, deep individual differences and can be an ideal basis for verification of an identity. In this research use, Deep Learning Network method uses to perform detection or face recognition. In this study, we present a framework that can be used to detect faces. This research is also able to present a DNN model that is used to study data sources from the data stream in sequence. The most important part of this study is able to adjust the capacity of the model from the simple one. This research uses experimental design method. The first step is a collection of face image data. Then the architecture design starts from the determination of the depth of the network, layout layers, and the selection of layer types that will be used to get the model based on input dataset and label name index. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Face recognition has long been a hot topic and challenging research point in areas such as image processing, pattern recognition, and machine vision. The face is a biometric feature with the intrinsic nature of a human. So that the face has self-stability, deep individual differences and can be an ideal basis for verification of an identity. In this research use, Deep Learning Network method uses to perform detection or face recognition. In this study, we present a framework that can be used to detect faces. This research is also able to present a DNN model that is used to study data sources from the data stream in sequence. The most important part of this study is able to adjust the capacity of the model from the simple one. This research uses experimental design method. The first step is a collection of face image data. Then the architecture design starts from the determination of the depth of the network, layout layers, and the selection of layer types that will be used to get the model based on input dataset and label name index. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Computing UDCHR scheme for simulating underwater sediment movement using OpenMP"
        ],
        "penulis":"Lobma, Fadhil;Gunawan P.H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Parallel computing with OpenMP platform in numerical simulation of underwater sediment movement is elaborated. The result shown computer I with processor type Intel Core i7-7500U has better speedup performance (3.291493 times of serial computing) than Computer II with processor type AMD Ryzen 5 2400G. Meanwhile, using computer II, the speedup of parallel computing is obtained 3.751561 times of serial computing. Indeed this discrepancy occurs because of the processor type of Computer I is higher than Computer II. Moreover, the efficiency of Computer II is 11.5% lower than computer II which is conducted 91.1367% efficiency. This means using Computer II the ability of parallel codes to achieve best performance proportional to the number of processor is obtained. Furthermore, the numerical simulation using UDCHR is shown in a good agreement with the staggered grid scheme of two-layer SWE and SWE-Exner model. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Parallel computing with OpenMP platform in numerical simulation of underwater sediment movement is elaborated. The result shown computer I with processor type Intel Core i7-7500U has better speedup performance (3.291493 times of serial computing) than Computer II with processor type AMD Ryzen 5 2400G. Meanwhile, using computer II, the speedup of parallel computing is obtained 3.751561 times of serial computing. Indeed this discrepancy occurs because of the processor type of Computer I is higher than Computer II. Moreover, the efficiency of Computer II is 11.5% lower than computer II which is conducted 91.1367% efficiency. This means using Computer II the ability of parallel codes to achieve best performance proportional to the number of processor is obtained. Furthermore, the numerical simulation using UDCHR is shown in a good agreement with the staggered grid scheme of two-layer SWE and SWE-Exner model. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Flowshop Scheduling with Drum-Buffer-Rope and CDS Algorithm to Minimize Lateness and Work in Process at PT. AKS"
        ],
        "penulis":"Viady A.S.;Suryadhini P.P.;Rendra M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In many years, the problem of lateness remains a problem for companies. This problem also occurs in textile company. At PT. AKS, one of the textile company, the lateness causes by bottleneck on one of their work station, which is Split Workstation, and the other caused by large unit load. The objective of this research is to minimize lateness by reducing the bottleneck and unit load. This research purposed a Drum-Buffer-Rope method and CDS algorithm to solve the problem. The constraint work station which is Split Workstation as the drum which is the control point of the whole system. The rope systematic which is backward scheduling applied at work stations before Split Workstation to minimize the queue time and to control the work in process. CDS Algorithm used in the interest of jobs sequencing to be processes after Split Workstation by using a forward scheduling. To solve the large unit load, we determine the unit load by trial and error. The result of this research manufacturing lead time decrease is by 61.88 percent from the current condition, queue time decrease is by 82.45 percent from current condition and the lateness decrease is by 35.71 percent from current condition. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In many years, the problem of lateness remains a problem for companies. This problem also occurs in textile company. At PT. AKS, one of the textile company, the lateness causes by bottleneck on one of their work station, which is Split Workstation, and the other caused by large unit load. The objective of this research is to minimize lateness by reducing the bottleneck and unit load. This research purposed a Drum-Buffer-Rope method and CDS algorithm to solve the problem. The constraint work station which is Split Workstation as the drum which is the control point of the whole system. The rope systematic which is backward scheduling applied at work stations before Split Workstation to minimize the queue time and to control the work in process. CDS Algorithm used in the interest of jobs sequencing to be processes after Split Workstation by using a forward scheduling. To solve the large unit load, we determine the unit load by trial and error. The result of this research manufacturing lead time decrease is by 61.88 percent from the current condition, queue time decrease is by 82.45 percent from current condition and the lateness decrease is by 35.71 percent from current condition. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Analysis of Project Integration on Smart Parking System in Telkom University"
        ],
        "penulis":"Lubis, Muharman;Fauzi, Rahmat;Lubis, Arif Ridho;Fauzi, Rokhman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The parking process is common attempt to eliminate traffic in the road by providing certain spot for vehicle to stay for certain time. Considering the increase of amount of population, large parking area horizontally or vertically is not necessary proper solution because it requires enormous expenses to acquire vacant land or to construct high-rise building. Therefore, smart parking system is one solution to provide information on the availability of vacant parking locations efficiently and conduct identification and transaction process quickly. Telkom University has been adopted this system by using physical card with RFID built-in for handling, convenience and security purposes since October 2014. Even though, it deliver an easy way for verification and validation but some problem occurred that raise several complaints from student and staff. This study has objective to explore the challenges and to addresses the issues faced by smart parking system, which has been implemented in subsequent years. By identifying the solution, it can improve the quality of the system for greater purpose in the future. \u00a9 2018 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The parking process is common attempt to eliminate traffic in the road by providing certain spot for vehicle to stay for certain time. Considering the increase of amount of population, large parking area horizontally or vertically is not necessary proper solution because it requires enormous expenses to acquire vacant land or to construct high-rise building. Therefore, smart parking system is one solution to provide information on the availability of vacant parking locations efficiently and conduct identification and transaction process quickly. Telkom University has been adopted this system by using physical card with RFID built-in for handling, convenience and security purposes since October 2014. Even though, it deliver an easy way for verification and validation but some problem occurred that raise several complaints from student and staff. This study has objective to explore the challenges and to addresses the issues faced by smart parking system, which has been implemented in subsequent years. By identifying the solution, it can improve the quality of the system for greater purpose in the future. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Frequency Domain-Extended Coded Random Access Scheme for Spectrum Sharing between 5G and Fixed Satellite Services"
        ],
        "penulis":"Haryanti, Tita;Anwar, Khoirul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes a new scheme of Coded Random Access (CRA) with extension to frequency domain, called Frequency Domain-Extended Coded Random Access (FDE-CRA) to make the coexistence possible between the fifth telecommunication generation (5G) and Fixed Satellite Services (FSS). Original CRA uses time-slots to serve users, while FDE-CRA uses both time-slots and frequencies to serve larger number of users. The proposed FDE-CRA is highly motivated by the necessity of spectrum sharing between 5G and FSS in bands of 3.4-4.2 GHz such that many interfering frequencies to the FSS can be reduced. FDE-CRA makes spectrum sharing possible by the use of multiuser detection (MUD) based on the available frequencies. We optimize degree distribution by maximizing the bandwidth efficiency and minimizing loss of random access using extrinsic information transfer (EXIT) chart. We also validate the results using practical simulation of packet loss rate (PLR) and throughput performances based on computer simulations. We found that the time consumption for decoding is small when the number of frequencies (K) used in MUD is large. This is because the decoding process is faster since many signals received at the same time-slot can be decoded simultaneously. We analyze the network performances in terms of PLR and throughputs using a series of computer simulations for K={1,2, \u00b7, 10}. We found that MUD of K=5 is optimal for bandwidth sharing efficiency beyond 50%. These results are expected to make the coexistence between 5G and FSS possible and practical. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes a new scheme of Coded Random Access (CRA) with extension to frequency domain, called Frequency Domain-Extended Coded Random Access (FDE-CRA) to make the coexistence possible between the fifth telecommunication generation (5G) and Fixed Satellite Services (FSS). Original CRA uses time-slots to serve users, while FDE-CRA uses both time-slots and frequencies to serve larger number of users. The proposed FDE-CRA is highly motivated by the necessity of spectrum sharing between 5G and FSS in bands of 3.4-4.2 GHz such that many interfering frequencies to the FSS can be reduced. FDE-CRA makes spectrum sharing possible by the use of multiuser detection (MUD) based on the available frequencies. We optimize degree distribution by maximizing the bandwidth efficiency and minimizing loss of random access using extrinsic information transfer (EXIT) chart. We also validate the results using practical simulation of packet loss rate (PLR) and throughput performances based on computer simulations. We found that the time consumption for decoding is small when the number of frequencies (K) used in MUD is large. This is because the decoding process is faster since many signals received at the same time-slot can be decoded simultaneously. We analyze the network performances in terms of PLR and throughputs using a series of computer simulations for K={1,2, \u00b7, 10}. We found that MUD of K=5 is optimal for bandwidth sharing efficiency beyond 50%. These results are expected to make the coexistence between 5G and FSS possible and practical. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Increasing the Capacity of Listega Based on Syllable Pattern Using Multicolumn and Bigram Mapping"
        ],
        "penulis":"Munzi, Gugy Guztaman;Barmawi, Ari Moesriami;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Due to the increasing use of internet, preserving confidentiality and integrity becomes important. One method for preserving them is steganography. There are two types of steganography, noisy and noiseless. One of noiseless steganography method is List Steganography based on syllable pattern proposed by David et al. Since List Steganography based on syllable pattern only embed one character into one column, then the capacity is still low. For increasing the capacity, the proposed method introduced embedding method for two columns where one column can be embedded with up to two characters (one bigram). The characters are embedded based on the syllable and code mapping. Syllable mapping is designed based on the occurrence frequency of syllable in the cover and English dictionary, while code mapping is designed based on the occurrence frequency of the code in the cover. Based on the experiment result, the embedding capacity using English secret message is increased with the rate of 17% to 55%. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Due to the increasing use of internet, preserving confidentiality and integrity becomes important. One method for preserving them is steganography. There are two types of steganography, noisy and noiseless. One of noiseless steganography method is List Steganography based on syllable pattern proposed by David et al. Since List Steganography based on syllable pattern only embed one character into one column, then the capacity is still low. For increasing the capacity, the proposed method introduced embedding method for two columns where one column can be embedded with up to two characters (one bigram). The characters are embedded based on the syllable and code mapping. Syllable mapping is designed based on the occurrence frequency of syllable in the cover and English dictionary, while code mapping is designed based on the occurrence frequency of the code in the cover. Based on the experiment result, the embedding capacity using English secret message is increased with the rate of 17% to 55%. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Potential detection application of nodular melanoma on melanocytic nevi image based on android"
        ],
        "penulis":"Alhakim, Muhammad;Purboyo, Tito Waluyo;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nodular melanoma is a deadly rare type of skin cancer. Nodular Melanoma has characteristics asymmetrical shape, border irregularity, nonhomogeneous or has several color variations and the diameter is more than 6 millimeters. Nodular melanoma has a physical form similar to melanocytic nevi, therefore nodular melanoma can be detected from melanocytic nevi spread throughout the body. This research aims to detect nodular melanoma through melanocytic nevi by utilizing the android system in order to ease the user by using camera smartphone in detecting cancer. This application uses image processing and feature extraction of the ABCD method to process images with decision tree c4.5 classification method to detect potential of nodular melanoma diagnosis from melanocytic nevi image. The ABCD method is a medical method used to detect the possibility of skin cancer using 4 parameters including asymmetrical shape, border irregularity, color and diameter. Decision tree c4.5 is classification method that using entropy and gain to make rules of decision tree. The image data test is obtained from the results of the android-based smartphone camera shooting and from medical record. Output of this application is a diagnosis condition of melanocytic nevi is healthy or nodular melanoma potentially. The accuracy of this application is 97.5%. \u00a9BEIESP.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nodular melanoma is a deadly rare type of skin cancer. Nodular Melanoma has characteristics asymmetrical shape, border irregularity, nonhomogeneous or has several color variations and the diameter is more than 6 millimeters. Nodular melanoma has a physical form similar to melanocytic nevi, therefore nodular melanoma can be detected from melanocytic nevi spread throughout the body. This research aims to detect nodular melanoma through melanocytic nevi by utilizing the android system in order to ease the user by using camera smartphone in detecting cancer. This application uses image processing and feature extraction of the ABCD method to process images with decision tree c4.5 classification method to detect potential of nodular melanoma diagnosis from melanocytic nevi image. The ABCD method is a medical method used to detect the possibility of skin cancer using 4 parameters including asymmetrical shape, border irregularity, color and diameter. Decision tree c4.5 is classification method that using entropy and gain to make rules of decision tree. The image data test is obtained from the results of the android-based smartphone camera shooting and from medical record. Output of this application is a diagnosis condition of melanocytic nevi is healthy or nodular melanoma potentially. The accuracy of this application is 97.5%. \u00a9BEIESP."
        ]
    },
    {
        "judul":[
            "Monitoring and classification system of river water pollution conditions with fuzzy logic"
        ],
        "penulis":"Khalid Waleed A.S.;Kusuma, Purba Daru;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of the current era, and the rapid development of technology and the need for a significant increase in demand, as well as pollution, the water sector, especially the river has experienced a decline in water quality even to the occurrence of pollution, resulting in water can no longer be consumed either by human body also for other needs. Some of the systems that were developed began to be able to process existing data, be it conditions from water, chemical observations or physically. This is done because water is a necessity that cannot be tolerated, so this research is done to help fulfill or even provide a calm warning of water quality. With the development of Intemet of Things (IoT) the monitoring system will develop, because with the existence of technology such as low-power wide-area network (LPWAN) as specific as possible, short data can be sent using lower power. In this research, it was proven that the author could make a monitoring system and classification of river water pollution. By using an artificial intelligence, using the fuzzy logic method. The results of system testing show that the average accuracy of the monitoring system results is 99.7% and the results of the appropriate classification values are based on the results of system testing. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentClean water and sanitationGoal 6",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of the current era, and the rapid development of technology and the need for a significant increase in demand, as well as pollution, the water sector, especially the river has experienced a decline in water quality even to the occurrence of pollution, resulting in water can no longer be consumed either by human body also for other needs. Some of the systems that were developed began to be able to process existing data, be it conditions from water, chemical observations or physically. This is done because water is a necessity that cannot be tolerated, so this research is done to help fulfill or even provide a calm warning of water quality. With the development of Intemet of Things (IoT) the monitoring system will develop, because with the existence of technology such as low-power wide-area network (LPWAN) as specific as possible, short data can be sent using lower power. In this research, it was proven that the author could make a monitoring system and classification of river water pollution. By using an artificial intelligence, using the fuzzy logic method. The results of system testing show that the average accuracy of the monitoring system results is 99.7% and the results of the appropriate classification values are based on the results of system testing. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Multiple Face Image Feature Extraction Using Geometric Moment Invariants Method"
        ],
        "penulis":"Fachrurrozi, Muhammad;Saparudin;Lestari, Ayu;Arsalan, Osvari;Samsuryadi;Ermatita;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Research on human facial expression recognition has become a growing field. One important step in the recognition of facial expressions is feature extraction. This research uses Geometric Moment Invariants (GMI) as a feature extraction method. Research on facial expression recognition using either the GMI method or another method use single face image as the dataset. Therefore, in this study uses GMI feature extraction to classify facial expressions on multiple face images. Face detection process uses Viola-Jones method on OpenCV and classification process uses Multi Class SVM method. The results are features for each expression and a small average accuracy of 5 times. Therefore, the classification is also done with the k-fold cross validation technique with another classification method. The average accuracy results are still small. It caused by the training image also using outer area of face in the image, so the background included as the image features. It is tested from k value 2 to10, and produce Multi Class SVM 10.2%, Decision Tree Classifier 14.73%, Random Forest Classifier 14.78%, Gaussian Naive Bayes 14.73%, Nearest Centroid 14.66%, MLP Classifier 11.09%, and Stochastic Gradient Descent Classifier 14.19%. The highest accuracy result is Random Forest Classifier method 14.78%. In Random Forest method, the best k value obtained is 4 with an average accuracy 16.18%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Research on human facial expression recognition has become a growing field. One important step in the recognition of facial expressions is feature extraction. This research uses Geometric Moment Invariants (GMI) as a feature extraction method. Research on facial expression recognition using either the GMI method or another method use single face image as the dataset. Therefore, in this study uses GMI feature extraction to classify facial expressions on multiple face images. Face detection process uses Viola-Jones method on OpenCV and classification process uses Multi Class SVM method. The results are features for each expression and a small average accuracy of 5 times. Therefore, the classification is also done with the k-fold cross validation technique with another classification method. The average accuracy results are still small. It caused by the training image also using outer area of face in the image, so the background included as the image features. It is tested from k value 2 to10, and produce Multi Class SVM 10.2%, Decision Tree Classifier 14.73%, Random Forest Classifier 14.78%, Gaussian Naive Bayes 14.73%, Nearest Centroid 14.66%, MLP Classifier 11.09%, and Stochastic Gradient Descent Classifier 14.19%. The highest accuracy result is Random Forest Classifier method 14.78%. In Random Forest method, the best k value obtained is 4 with an average accuracy 16.18%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "System dynamics simulation to determine financial strategy for social health insurance in Indonesia"
        ],
        "penulis":"Kurnianingtyas, Diva;Santosa, Budi;Siswanto, Nurhadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Social Health Insurance (SHI) in Indonesia is still experiencing financial constraints because the financial condition of the SHI has continued to be a loss since it was established in 2014 until present so it becomes special attention needed to get achieving the Universal Health Coverage (UHC) target by the government. Therefore, this study intends to provide an appropriate SHI financial strategy recommendation by considering the stability of the balance of income and expense. In addition, a system dynamics simulation approach is needed to find optimal SHI financial strategies with variables including participant premium rates, average cost of benefits, number of health cases, and number of insurance participants. The data used came from BPJS Health data for 2016 and 2017. Afterwards, the equation used was Income \u2265 Expenditures. In addition, there are several scenarios designed to reduce the level of financial losses that occur at SHI. The scenario of reducing the number of health cases is the best strategy recommendation decision. The results show that reducing average benefit costs and increasing premium rates also gets it can reduce financial problems. From the results that have been obtained, this study can contribute to the resolution of SHI Health financial problems in Indonesia. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Reduced inequalitiesGoal 10Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Social Health Insurance (SHI) in Indonesia is still experiencing financial constraints because the financial condition of the SHI has continued to be a loss since it was established in 2014 until present so it becomes special attention needed to get achieving the Universal Health Coverage (UHC) target by the government. Therefore, this study intends to provide an appropriate SHI financial strategy recommendation by considering the stability of the balance of income and expense. In addition, a system dynamics simulation approach is needed to find optimal SHI financial strategies with variables including participant premium rates, average cost of benefits, number of health cases, and number of insurance participants. The data used came from BPJS Health data for 2016 and 2017. Afterwards, the equation used was Income \u2265 Expenditures. In addition, there are several scenarios designed to reduce the level of financial losses that occur at SHI. The scenario of reducing the number of health cases is the best strategy recommendation decision. The results show that reducing average benefit costs and increasing premium rates also gets it can reduce financial problems. From the results that have been obtained, this study can contribute to the resolution of SHI Health financial problems in Indonesia. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "An Investigation of Aircraft Tracking through Space-based ADS-B Receiver"
        ],
        "penulis":"Caya T.V.;Hafizh M.;Benyamin S.O.;Edwar;Putra Y.D.;Widiawan A.K.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nowadays space-based Automatic Dependent Surveillance-Broadcast (ADS-B) is widely developed with various methods to improve the quality of ADS-B. The method that can be used to design a space-based ADS-B receiver is creating a system-level simulator. The system-level simulator can be used to investigate performance of the system with scenarios that have been made. This paper presents a modeling of the ADS-B signal receiver system from an aircraft with a Low Earth Orbit (LEO) Satellite. In this model, the position of the aircraft is randomly scattered within the range of the satellite's coverage at an altitude of 5 km-15 km above the ground level. The satellite's antenna used in this simulation has a 90-degree beamwidth with 5 dBi of maximum gain on the main lobe. The lowest BER value obtained from the aircraft is 1x10-8, located at the satellite nadir and the highest value obtained from the aircraft is 1x10-6, located at the farthest distance from the satellite. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays space-based Automatic Dependent Surveillance-Broadcast (ADS-B) is widely developed with various methods to improve the quality of ADS-B. The method that can be used to design a space-based ADS-B receiver is creating a system-level simulator. The system-level simulator can be used to investigate performance of the system with scenarios that have been made. This paper presents a modeling of the ADS-B signal receiver system from an aircraft with a Low Earth Orbit (LEO) Satellite. In this model, the position of the aircraft is randomly scattered within the range of the satellite's coverage at an altitude of 5 km-15 km above the ground level. The satellite's antenna used in this simulation has a 90-degree beamwidth with 5 dBi of maximum gain on the main lobe. The lowest BER value obtained from the aircraft is 1x10-8, located at the satellite nadir and the highest value obtained from the aircraft is 1x10-6, located at the farthest distance from the satellite. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Gender differences in students' e-learning usage outcomes"
        ],
        "penulis":"Aditya, Bayu Rima;Permadi, Aditya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The importance of studying gender differences in student skills has been demonstrated by the emergence of various results of previous studies that discussed the recommendations for developing learning by considering gender. The question that raised in this study is whether there is a difference between the assessment of male and female students on aspects related to the learning outcomes in the context of e-learning. The main contribution of this study was to provide evidence about matters considered necessary by male and female students towards achieving their learning outcomes. This research is based on a sample of 223 students that registered as e-learning class participants on two different campuses in Indonesia. This study concludes that there are two out of six aspects of learning outcomes that shows the significant difference between the assessment of male and female students: usefulness and course content. These results confirm that there are still gaps between male and female students about the learning outcomes.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGender equalityGoal 5Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The importance of studying gender differences in student skills has been demonstrated by the emergence of various results of previous studies that discussed the recommendations for developing learning by considering gender. The question that raised in this study is whether there is a difference between the assessment of male and female students on aspects related to the learning outcomes in the context of e-learning. The main contribution of this study was to provide evidence about matters considered necessary by male and female students towards achieving their learning outcomes. This research is based on a sample of 223 students that registered as e-learning class participants on two different campuses in Indonesia. This study concludes that there are two out of six aspects of learning outcomes that shows the significant difference between the assessment of male and female students: usefulness and course content. These results confirm that there are still gaps between male and female students about the learning outcomes.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Overhead Analysis on the Use of Digital Signature in MQTT Protocol"
        ],
        "penulis":"Hidayat, Husnul;Sukarno, Parman;Wardana, Aulia Arif;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study proposes a digital signature scheme to secure messages sent by the publish\/subscribe middleware Message Queue Telemetry Transport (MQTT) protocol. In which, it uses the Advanced Encryption System (AES) and Secure Hash Algorithm (SHA) with the end-to-end method and analyze the overhead of application of digital signature. Because, the disadvantage of MQTT is that there is no encryption process on the payload. In which, allows one to be able to find out the payload content that causes no privacy in the data. Data integrity is also a problem with MQTT. The purpose of this digital signature is to verify that the payload sent is a genuine one, which does not change during the transmission process, and the secrecy of the payload. After evaluating and testing the proposed system, the program can secure the MQTT payload. The addition of a security mechanism in MQTT such as the encryption process, decryption, verification results produces overhead in several aspects. The overhead used in this study is to measure the size of the payload, the time of sending messages, the process of the mechanism of digital signature security, memory consumption, and CPU usage. In an overhead analysis, overhead is carried out by examining various types of AES keys and multiple types of SHA. After examination, there is an increase in size for several aspects that have been mentioned because of the digital signature scheme. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study proposes a digital signature scheme to secure messages sent by the publish\/subscribe middleware Message Queue Telemetry Transport (MQTT) protocol. In which, it uses the Advanced Encryption System (AES) and Secure Hash Algorithm (SHA) with the end-to-end method and analyze the overhead of application of digital signature. Because, the disadvantage of MQTT is that there is no encryption process on the payload. In which, allows one to be able to find out the payload content that causes no privacy in the data. Data integrity is also a problem with MQTT. The purpose of this digital signature is to verify that the payload sent is a genuine one, which does not change during the transmission process, and the secrecy of the payload. After evaluating and testing the proposed system, the program can secure the MQTT payload. The addition of a security mechanism in MQTT such as the encryption process, decryption, verification results produces overhead in several aspects. The overhead used in this study is to measure the size of the payload, the time of sending messages, the process of the mechanism of digital signature security, memory consumption, and CPU usage. In an overhead analysis, overhead is carried out by examining various types of AES keys and multiple types of SHA. After examination, there is an increase in size for several aspects that have been mentioned because of the digital signature scheme. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Firm Innovation Capability through Knowledge Sharing at Indonesian Small and Medium Industries: Impact of Tacit and Explicit Knowledge Perspective"
        ],
        "penulis":"Rumanti, Augustina Asih;Wiratmadja, Iwan Inrawan;Sunaryo, Indryati;Ajidarma, Praditya;Ari Samadhi T.M.A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tacit knowledge is an asset that is embedded in an individual, while explicit knowledge is a type of knowledge that can be readily documented in an organization. Both types of knowledge are crucial for knowledge sharing within any organization as both are primary factors to boost innovation capability. Knowledge sharing process requires an enabler in its process. This research studies Small and Medium Industries (SMI), where knowledge sharing between one SMI to another is necessary, which enables a group of SMIs within a certain area to grow altogether. This research aims to analyze how the innovation capability of a company is influenced by knowledge sharing with the perspective of both tacit and explicit knowledge. The result shows that each indicator in every construct has a good validity, reliability, and significance level, which evidently suggests that a company's capacity to share knowledge, both tacitly and explicitly, is indeed significant and influential towards the innovation capability of such company in this case, SMI. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tacit knowledge is an asset that is embedded in an individual, while explicit knowledge is a type of knowledge that can be readily documented in an organization. Both types of knowledge are crucial for knowledge sharing within any organization as both are primary factors to boost innovation capability. Knowledge sharing process requires an enabler in its process. This research studies Small and Medium Industries (SMI), where knowledge sharing between one SMI to another is necessary, which enables a group of SMIs within a certain area to grow altogether. This research aims to analyze how the innovation capability of a company is influenced by knowledge sharing with the perspective of both tacit and explicit knowledge. The result shows that each indicator in every construct has a good validity, reliability, and significance level, which evidently suggests that a company's capacity to share knowledge, both tacitly and explicitly, is indeed significant and influential towards the innovation capability of such company in this case, SMI. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Clustering data in power management system using k-means clustering algorithm"
        ],
        "penulis":"Aryani, Ressy;Nasrun, Muhammad;Setianingsih, Casi;Murti, Muhammad Ary;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electricity is a source of current that cannot be released from life because it is needed as a means of production and helps solve problems in daily life. Most users use electricity without realizing the amount of electricity used in that period, it can make electricity usage soar because there is no control of electricity usage. The problem of the amount of electricity usage also occurs in campus buildings, logistics staff cannot control the use of electricity because there is no history of electricity usage in certain buildings. To solve this problem, an IOT-based KWH electricity usage monitoring system was built. Furthermore, this application has a data clustering calculation using the KMeans algorithm which aims to classify campus area data according to its electricity usage whether it enters areas that use large, normal or low loads. By using information from the data clustering, logistics employees can make a policy to make electricity savings. This system has three main parts, namely the hardware system, IoT server, and website monitoring application. In this research focuses on making website monitoring and clustering data applications. From the results of tests conducted by the K-Means algorithm has the highest accuracy value of 83.3%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electricity is a source of current that cannot be released from life because it is needed as a means of production and helps solve problems in daily life. Most users use electricity without realizing the amount of electricity used in that period, it can make electricity usage soar because there is no control of electricity usage. The problem of the amount of electricity usage also occurs in campus buildings, logistics staff cannot control the use of electricity because there is no history of electricity usage in certain buildings. To solve this problem, an IOT-based KWH electricity usage monitoring system was built. Furthermore, this application has a data clustering calculation using the KMeans algorithm which aims to classify campus area data according to its electricity usage whether it enters areas that use large, normal or low loads. By using information from the data clustering, logistics employees can make a policy to make electricity savings. This system has three main parts, namely the hardware system, IoT server, and website monitoring application. In this research focuses on making website monitoring and clustering data applications. From the results of tests conducted by the K-Means algorithm has the highest accuracy value of 83.3%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Assessment of Team Based Learning: The Use of Student Centred Learning for Interaction Design Class"
        ],
        "penulis":"Lubis, Muharman;Azizah, Anik Hanifatul;Fauzi, Rahmat;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Student-centred learning has been defined as small approach to improve learning objective through variety of process where students not only choose what to learn, but how and why. Moreover, the essence of the learning environment is the responsibility and activities of students, in contrast to the focus on coach control and the scope of academic content in the teaching with the traditional teaching. In this case, the use of Team based learning can take into account the aspects of the time of tasks termination and student activities to learn the subject content in the maximum way to enrich the other concepts outside the learning module. This study investigate the utilization of Team Based Learning in the subject of Interaction Design to improve the understanding from the student towards the curriculum objective and target. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Student-centred learning has been defined as small approach to improve learning objective through variety of process where students not only choose what to learn, but how and why. Moreover, the essence of the learning environment is the responsibility and activities of students, in contrast to the focus on coach control and the scope of academic content in the teaching with the traditional teaching. In this case, the use of Team based learning can take into account the aspects of the time of tasks termination and student activities to learn the subject content in the maximum way to enrich the other concepts outside the learning module. This study investigate the utilization of Team Based Learning in the subject of Interaction Design to improve the understanding from the student towards the curriculum objective and target. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Smart security and safety index measurement: A case study in Bandung Indonesia"
        ],
        "penulis":"Indrawati;Dayarani, Tania;Amani, Husni;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose: Nowadays, the development of technology is very fast and increasingly sophisticated; no doubt all the problems in a city can be solved quickly and well. Hence, facing a huge number of the urban population, the city must adopt the strategy of smart city so that the standard of life can be improved. Some of the cities in the world have applied the concept of smart city. One of the dimensions in smart city concept is smart security and safety. This study aims to know the indicators and index level of smart security and safety in Bandung city of Indonesia. This research explores the indicators and measures the index level of smart security and safety in Bandung. Methodology: The research method characteristics applied in this study is the exploratory sequential mixed method. Main Findings: This study finds that there are 20 indicators to measure the index level of smart security and safety. The smart security and safety level of Bandung city is 72% which is considered that on average the measured indicators are already good enough and satisfied, but there are some indicators that should be improved. The variable that should be improved is variable of Awareness and Understanding which has score of 49%. Implications\/Applications: It is suggested by this study that the socialization of smart security and safety program such as Panic Button Application, LAPOR! The website should be more effective through making socialization more targeted and real. \u00a9 Indrawati et al.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: Nowadays, the development of technology is very fast and increasingly sophisticated; no doubt all the problems in a city can be solved quickly and well. Hence, facing a huge number of the urban population, the city must adopt the strategy of smart city so that the standard of life can be improved. Some of the cities in the world have applied the concept of smart city. One of the dimensions in smart city concept is smart security and safety. This study aims to know the indicators and index level of smart security and safety in Bandung city of Indonesia. This research explores the indicators and measures the index level of smart security and safety in Bandung. Methodology: The research method characteristics applied in this study is the exploratory sequential mixed method. Main Findings: This study finds that there are 20 indicators to measure the index level of smart security and safety. The smart security and safety level of Bandung city is 72% which is considered that on average the measured indicators are already good enough and satisfied, but there are some indicators that should be improved. The variable that should be improved is variable of Awareness and Understanding which has score of 49%. Implications\/Applications: It is suggested by this study that the socialization of smart security and safety program such as Panic Button Application, LAPOR! The website should be more effective through making socialization more targeted and real. \u00a9 Indrawati et al."
        ]
    },
    {
        "judul":[
            "Hate speech detection on twitter using multinomial logistic regression classification method"
        ],
        "penulis":"Br Ginting, Purnama Sari;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In today's social media, especially Twitter is very important for the success and destruction of one's image due to the many sentences of opinion that can compete the users. Examples of phrases that mean evil refer to hate speech to others. Evil perspectives can be categorized in hate speech, which hate speech is regulated in Article 28 of the ITE Law. Not a few people who intentionally and unintentionally oppose a social media that contains hate speech. Unfortunately social media does not have the ability to aggregate information about an existing conversation into a conclusion. One way to draw conclusion from aggregation results is to use text mining. In this paper to classify whether the text in the sentence contains elements of hate speech or not. The author hopes in this paper can make how to classify element of hate speech in text by computer, which later speech of the can be recognized. By using Multinomial Logistic Regression method. The author hopes after this application the computer can know and classify the existence of hate speech on a text from social media Twitter. From the results of tests that have been done the average precision of 80.02, recall 82%, and accuracy of 87.68%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In today's social media, especially Twitter is very important for the success and destruction of one's image due to the many sentences of opinion that can compete the users. Examples of phrases that mean evil refer to hate speech to others. Evil perspectives can be categorized in hate speech, which hate speech is regulated in Article 28 of the ITE Law. Not a few people who intentionally and unintentionally oppose a social media that contains hate speech. Unfortunately social media does not have the ability to aggregate information about an existing conversation into a conclusion. One way to draw conclusion from aggregation results is to use text mining. In this paper to classify whether the text in the sentence contains elements of hate speech or not. The author hopes in this paper can make how to classify element of hate speech in text by computer, which later speech of the can be recognized. By using Multinomial Logistic Regression method. The author hopes after this application the computer can know and classify the existence of hate speech on a text from social media Twitter. From the results of tests that have been done the average precision of 80.02, recall 82%, and accuracy of 87.68%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Towards Successful Implementation of a Virtual Classroom for Vocational Higher Education in Indonesia"
        ],
        "penulis":"Aditya, Bayu Rima;Nurhas, Irawan;Pawlowski, Jan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The virtual classroom continues to grow, but it is becoming more and more the norm, and it is fundamentally different from the vocational students at the Indonesian university. With the promised benefits of the virtual classroom, many challenges and difficulties come in the implementation. Although there are already successful design principles for virtual classrooms that support organizations in overcoming the challenges, the approach to implementing the design principles of virtual classroom at the vocational higher education in Indonesia is still lacking. In this study, we aim to answer the research gap and used the design sciences research by interviewing the lecturers to design the solutions. The proposed design approaches were implemented in a course and evaluated with students from two different groups. Overall, the evaluation of the proposed approaches shows 1 significant results as an indicator of the benefits of the implementation of a virtual classroom for vocational students in Indonesia. \u00a9 2019, Springer Nature Switzerland AG.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The virtual classroom continues to grow, but it is becoming more and more the norm, and it is fundamentally different from the vocational students at the Indonesian university. With the promised benefits of the virtual classroom, many challenges and difficulties come in the implementation. Although there are already successful design principles for virtual classrooms that support organizations in overcoming the challenges, the approach to implementing the design principles of virtual classroom at the vocational higher education in Indonesia is still lacking. In this study, we aim to answer the research gap and used the design sciences research by interviewing the lecturers to design the solutions. The proposed design approaches were implemented in a course and evaluated with students from two different groups. Overall, the evaluation of the proposed approaches shows 1 significant results as an indicator of the benefits of the implementation of a virtual classroom for vocational students in Indonesia. \u00a9 2019, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Predicting staple food materials price using multivariables factors (regression and fourier models with ARIMA)"
        ],
        "penulis":"Asnhari, Said Fadlan;Gunawan P.H.;Rusmawati, Yanti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Staple food material prices can be a trending topic in the market. The fluctuation of the price is influenced by many factors. For instance, the weather, oil price, and etc are the external factors of the staple food price. Indeed, the prediction of staple food fluctuation price is important for the farmers, consumers, even government. In this paper, the Linear Regression and Fourier model with ARIMA (Autoregressive Integrated Moving Average) will be used to predict the staple food price which consider the external influences. Here, the results using those two methods are shown in a good agreement with the observation price at market. However, the highest accuracy in predicting price using Fourier regression with ARIMA is obtained for staple food onion which is 96.57%. Meanwhile, using multiple linear regression with ARIMA, the highest accuracy is obtained for staple food red chili with 99.84%. Overall, in this research, Fourier regression with ARIMA is observed better than multiple linear regression with ARIMA method, since the accuracy of Fourier regression with ARIMA is quite stable without disturbance of fluctuation existing data. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Staple food material prices can be a trending topic in the market. The fluctuation of the price is influenced by many factors. For instance, the weather, oil price, and etc are the external factors of the staple food price. Indeed, the prediction of staple food fluctuation price is important for the farmers, consumers, even government. In this paper, the Linear Regression and Fourier model with ARIMA (Autoregressive Integrated Moving Average) will be used to predict the staple food price which consider the external influences. Here, the results using those two methods are shown in a good agreement with the observation price at market. However, the highest accuracy in predicting price using Fourier regression with ARIMA is obtained for staple food onion which is 96.57%. Meanwhile, using multiple linear regression with ARIMA, the highest accuracy is obtained for staple food red chili with 99.84%. Overall, in this research, Fourier regression with ARIMA is observed better than multiple linear regression with ARIMA method, since the accuracy of Fourier regression with ARIMA is quite stable without disturbance of fluctuation existing data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The effects of the quality of service and social media on the interests of Argo Parahyangan train passengers on Bandung-Jakarta"
        ],
        "penulis":"Hidayah, Riski Taufik;Yolinda, Syindria;Nugraha, Deden Novan Setiawan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Argo Parahyangan Railway Transports Passengers is currently one of the best choices in traveling the Bandung-Jakarta and Jakarta-Bandung route. The purpose of this study was to find out how much influence the quality of services provided to passengers in traveling, and promotional activities through social media are used to interest passengers to use the Argo Parahyangan Railway. This research involved descriptive verification with a total sample of 100 Bandung people who conduct activities in Jakarta. Results of the study indicated that 44.89% of Purchase interest is contributed by the quality of service and 51.84% is contributed by promotional activities through Social media. \u00a9 2019 Primrose Hall Publishing Group.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Argo Parahyangan Railway Transports Passengers is currently one of the best choices in traveling the Bandung-Jakarta and Jakarta-Bandung route. The purpose of this study was to find out how much influence the quality of services provided to passengers in traveling, and promotional activities through social media are used to interest passengers to use the Argo Parahyangan Railway. This research involved descriptive verification with a total sample of 100 Bandung people who conduct activities in Jakarta. Results of the study indicated that 44.89% of Purchase interest is contributed by the quality of service and 51.84% is contributed by promotional activities through Social media. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Framework for measuring it service capability"
        ],
        "penulis":"Falahah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Measuring Information Technology (IT) Capability is not as easy as measuring others capability, especially on non-IT organization, in term that the organization does not put IT service as their primary business process. This organization, of course, still need IT support, whether from internal IT function or from external organization. In local government organization, usually there is an organization that should support all IT services, which usually called as IT Office. But, practically, it is hard for local IT office to provide all IT service for all organization unit in delivering the business service for the citizen, because of lack of resources. Some of local organizations usually try to provide the IT services by themselves. The others, usually still ask for services from local IT office. This condition put the local IT service in a problem how to assess the capability of the other organizations in IT services so they can set priority in IT services, and give some recommendation to resolve the services request. The aim of this research is to provide the framework for assess the IT service capability of the non-IT organization. The framework uses previous research from Zhang who provide the approach on assessing IT Service Capability in 4 domains, which are IT Architecture, IT Infrastructure, IT Human Resources and IT Relationship Resources. The proposed framework then combined with IT Service Delivery Maturity Model (SDMM) to assess the service maturity. The result of this research can be used as a tool to assess IT services capability. By knowing the IT services capability, the local IT office can have the map of local government IT capability and get some strategy for better IT planning. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Measuring Information Technology (IT) Capability is not as easy as measuring others capability, especially on non-IT organization, in term that the organization does not put IT service as their primary business process. This organization, of course, still need IT support, whether from internal IT function or from external organization. In local government organization, usually there is an organization that should support all IT services, which usually called as IT Office. But, practically, it is hard for local IT office to provide all IT service for all organization unit in delivering the business service for the citizen, because of lack of resources. Some of local organizations usually try to provide the IT services by themselves. The others, usually still ask for services from local IT office. This condition put the local IT service in a problem how to assess the capability of the other organizations in IT services so they can set priority in IT services, and give some recommendation to resolve the services request. The aim of this research is to provide the framework for assess the IT service capability of the non-IT organization. The framework uses previous research from Zhang who provide the approach on assessing IT Service Capability in 4 domains, which are IT Architecture, IT Infrastructure, IT Human Resources and IT Relationship Resources. The proposed framework then combined with IT Service Delivery Maturity Model (SDMM) to assess the service maturity. The result of this research can be used as a tool to assess IT services capability. By knowing the IT services capability, the local IT office can have the map of local government IT capability and get some strategy for better IT planning. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "Analysis of the maintainability and portability of ERP host to host system using ISO 9126 model"
        ],
        "penulis":"Syamranata, Tommy;Witjaksono, R Wahjoe;Suputra, Muhardi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Telecommunication industry in Indonesia that have a complex system and interconnected for the payment transaction to each vendor. the quality of the system is very influential on each division in the company and the goals are to analyzed host to host quality system. The implementation process of the new system in terms of internal portability and also in terms of the quality system if changes are made, according to the requirements of certain conditions in this case including in terms of internal maintainability, in this case, to be in line with the company that is helping companies in managing business processes according to with company goals and able to carry out operational activities more efficient and more effective. In the process, the analysis of system quality this time was carried out in the system. To analyze the quality system, it was carried out with the ISO 9126 standard as a model and to analyze the internal variables are using Maintainability and Portability. In the analysis, the process is using SPSS 25 and SMARTPLS 3 as processing tools. The results of this analysis process are in the form of recommendations in terms of stability contained in internal maintainability and portability testing, which is taken from the results of the hypothesis and also measurement testing for each related variable. The recommendations proposed are the Improvement System, from the existing SAP ECC 6.0 to SAP S \/ 4 HANA which has advantages in system stability. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Telecommunication industry in Indonesia that have a complex system and interconnected for the payment transaction to each vendor. the quality of the system is very influential on each division in the company and the goals are to analyzed host to host quality system. The implementation process of the new system in terms of internal portability and also in terms of the quality system if changes are made, according to the requirements of certain conditions in this case including in terms of internal maintainability, in this case, to be in line with the company that is helping companies in managing business processes according to with company goals and able to carry out operational activities more efficient and more effective. In the process, the analysis of system quality this time was carried out in the system. To analyze the quality system, it was carried out with the ISO 9126 standard as a model and to analyze the internal variables are using Maintainability and Portability. In the analysis, the process is using SPSS 25 and SMARTPLS 3 as processing tools. The results of this analysis process are in the form of recommendations in terms of stability contained in internal maintainability and portability testing, which is taken from the results of the hypothesis and also measurement testing for each related variable. The recommendations proposed are the Improvement System, from the existing SAP ECC 6.0 to SAP S \/ 4 HANA which has advantages in system stability. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Approximating earthquake source of Italy using Steepest Descent method"
        ],
        "penulis":"Aziz F.A.;Gunawan P.H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper describes the comparison of Newton's method and Steepest Descent method for determining the coordinates of earthquake source. Here, the Steepest Descent method is used because it is a Newton-based method. The earthquake case used in this research is Italian earthquake August 24, 2016, which has a seismic phase of Pg. The calculation was supported by Azimuth Coordinate equations to find the coordinates and Haversine formula to find the distance between five earthquake stations to the earthquake source. The final result of calculations was path's graph from the iteration of Steepest Descent method. Moreover, the results will be compared with the results of Newton's method that has been successfully approaching the point of earthquake source in the same case study of previous research. The result shows the number of final iterations of two methods using tolerance number 0.01, minimum velocity number 3093 m\/s and three cases of initial guess in the form of city coordinate of Rome, Milan, and Palermo. Newton's method generates 12 iterations in every case, Steepest Descent method generate 7, 6, 5 iteration respectively. However, the final numerical errors for Rome, Milan and Palermo initial guess are 0.1598 by Newton's method, while Steepest Descent method are 0.1566, 0.1567 and 0.1567. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper describes the comparison of Newton's method and Steepest Descent method for determining the coordinates of earthquake source. Here, the Steepest Descent method is used because it is a Newton-based method. The earthquake case used in this research is Italian earthquake August 24, 2016, which has a seismic phase of Pg. The calculation was supported by Azimuth Coordinate equations to find the coordinates and Haversine formula to find the distance between five earthquake stations to the earthquake source. The final result of calculations was path's graph from the iteration of Steepest Descent method. Moreover, the results will be compared with the results of Newton's method that has been successfully approaching the point of earthquake source in the same case study of previous research. The result shows the number of final iterations of two methods using tolerance number 0.01, minimum velocity number 3093 m\/s and three cases of initial guess in the form of city coordinate of Rome, Milan, and Palermo. Newton's method generates 12 iterations in every case, Steepest Descent method generate 7, 6, 5 iteration respectively. However, the final numerical errors for Rome, Milan and Palermo initial guess are 0.1598 by Newton's method, while Steepest Descent method are 0.1566, 0.1567 and 0.1567. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Vowel Sound Analysis in the Indonesian Language using Multilevel Wavelet Entropy"
        ],
        "penulis":"Hidayat, Risanuri;Rizal, Achmad;Bejo, Agus;Sumaryono, Sujoko;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "vowel is an integral part of speech signal processing. It can stand alone or be combined with a consonant to form specific sound. Previous studies have used wavelet transformation as sound vowel analysis method; however, these studies generally only used one level of wavelet decomposition in analyzing lung sound. This study, in turn, proposed entropy wavelet method with various levels of decomposition to obtain more comprehensive results of vowel sounds in various resolutions. It used the methods of multilevel wavelet entropy (MWE) and multilevel wavelet packet entropy (MWPE) in which the results showed 100% accuracy of MWE in the seventh level of Bior2.4 wavelet. Meanwhile, Haar wavelet and seventh level of Bior1.5 wavelet had 93.33% accuracy in MPWE. The combination of MWE and MWPE had 100% accuracy in the seventh level of Bior2.4 wavelet. Proposed method in this study can be used in a more extensive speech analysis. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "vowel is an integral part of speech signal processing. It can stand alone or be combined with a consonant to form specific sound. Previous studies have used wavelet transformation as sound vowel analysis method; however, these studies generally only used one level of wavelet decomposition in analyzing lung sound. This study, in turn, proposed entropy wavelet method with various levels of decomposition to obtain more comprehensive results of vowel sounds in various resolutions. It used the methods of multilevel wavelet entropy (MWE) and multilevel wavelet packet entropy (MWPE) in which the results showed 100% accuracy of MWE in the seventh level of Bior2.4 wavelet. Meanwhile, Haar wavelet and seventh level of Bior1.5 wavelet had 93.33% accuracy in MPWE. The combination of MWE and MWPE had 100% accuracy in the seventh level of Bior2.4 wavelet. Proposed method in this study can be used in a more extensive speech analysis. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The mediating effect of knowledge sharing on the relationship between organizational support and performance scientific publication lecturers"
        ],
        "penulis":"Putri, Ratna Komala;Amalia, Shendy;Simatupang, Ervina C.M.;Rusnoto Susanto, Moh;Putrianti, Flora Grace;Triyono;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to produce a study of the effect of organizational support on the performance of scientific publications of lecturers at private universities in West Java mediated by knowledge sharing. Research Methods - In this study, respondents consisted of 275 lecturers from 15 private universities accredited in West Java. Male respondents were 34.3% while 65.7% were female. This research uses quantitative method and structural equation model (SEM) is used as an analytical tool. Originality - The study of organizational support by sharing knowledge on the performance of scholarly scientific publications in private universities in West Java has never been done by previous researchers, so the current research has high originality. Thus, this study may contribute to improving the performance of scientific publications of lecturers at private universities. Findings-Optimum organizational support through knowledge sharing can improve the performance of scientific publications of lecturers at private universities. \u00a9 BEIESP",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to produce a study of the effect of organizational support on the performance of scientific publications of lecturers at private universities in West Java mediated by knowledge sharing. Research Methods - In this study, respondents consisted of 275 lecturers from 15 private universities accredited in West Java. Male respondents were 34.3% while 65.7% were female. This research uses quantitative method and structural equation model (SEM) is used as an analytical tool. Originality - The study of organizational support by sharing knowledge on the performance of scholarly scientific publications in private universities in West Java has never been done by previous researchers, so the current research has high originality. Thus, this study may contribute to improving the performance of scientific publications of lecturers at private universities. Findings-Optimum organizational support through knowledge sharing can improve the performance of scientific publications of lecturers at private universities. \u00a9 BEIESP"
        ]
    },
    {
        "judul":[
            "Secure Service Computing System Platform Based on Blockchain-A Systematic Literature Review"
        ],
        "penulis":"Rizal, Saiful;Andrian, Henry Rossi;Kurniawan, Novianto Budi;Suhardi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The decentralized storage system has problems in terms of secure data and access control issues have an important role in storage security on the service computing system platform. New challenges in data storage provide an opportunity for technology blockchain to be able to solve them. At present, there are several methods in the blockchain that have been implemented. Each method used has different technical characteristics. In this paper, we discuss the implementation of blockchain technology to secure a service computing system platform. In this research, it can be used as an understanding to develop a service computing system platform to produce reliable security. Ethereum blockchain platform is the most used choice in research. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The decentralized storage system has problems in terms of secure data and access control issues have an important role in storage security on the service computing system platform. New challenges in data storage provide an opportunity for technology blockchain to be able to solve them. At present, there are several methods in the blockchain that have been implemented. Each method used has different technical characteristics. In this paper, we discuss the implementation of blockchain technology to secure a service computing system platform. In this research, it can be used as an understanding to develop a service computing system platform to produce reliable security. Ethereum blockchain platform is the most used choice in research. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The effect of brand image on customer satisfaction in pizza hut Alam Sutera (quantitative study on Bina Nusantara University student batch 2018-2021)"
        ],
        "penulis":"Prameswari, Andini Anindya;Mahestu, Gayes;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of this study is to examine is there influence of brand image to customer satisfaction on Pizza Hut Alam Sutera. The approach used in this research is quantitative approach with explanative type and the method for data collection used in this research is survey by distributing questionnaires to students of Bina Nusantara Alam Sutera University with 100 respondents. The result of this research shows that there is influence of brand image to customer satisfaction with result of equal to 67,3% with unidirectional relationship. So, it can be concluded that the brand image has a strong influence on customer satisfaction. \u00a9 2019, International Journal of Scientific and Technology Research. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to examine is there influence of brand image to customer satisfaction on Pizza Hut Alam Sutera. The approach used in this research is quantitative approach with explanative type and the method for data collection used in this research is survey by distributing questionnaires to students of Bina Nusantara Alam Sutera University with 100 respondents. The result of this research shows that there is influence of brand image to customer satisfaction with result of equal to 67,3% with unidirectional relationship. So, it can be concluded that the brand image has a strong influence on customer satisfaction. \u00a9 2019, International Journal of Scientific and Technology Research. All rights reserved."
        ]
    },
    {
        "judul":[
            "Effect of dynamical downscaling to cyclone simulation: A study case for Haiyan typhoon"
        ],
        "penulis":"Latifah, Arnida L.;Adytia, Didit;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The capacity of a global gridded climate data in describing tropical cyclone (TC) activity might be still less adequate due to its coarse resolution or the TC intensity itself. Grid refinement method such as a dynamical downscaling is one way to add values of the climate attributes in the data. However, the performance of the dynamical downscaling itself still con-tains many uncertainties. This paper aims to evaluate the effect of the dynamical downscaling model on the climate simulation during a strong tropical cyclone Haiyan. The snapshots and the best track data from the historical satellite imagery will be used for validation. In general the downscaled cyclone simulation does not give a significant change to the driven data, but it results in more finer resolution of wind field and improves the time and the position of the eye of the cyclone. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The capacity of a global gridded climate data in describing tropical cyclone (TC) activity might be still less adequate due to its coarse resolution or the TC intensity itself. Grid refinement method such as a dynamical downscaling is one way to add values of the climate attributes in the data. However, the performance of the dynamical downscaling itself still con-tains many uncertainties. This paper aims to evaluate the effect of the dynamical downscaling model on the climate simulation during a strong tropical cyclone Haiyan. The snapshots and the best track data from the historical satellite imagery will be used for validation. In general the downscaled cyclone simulation does not give a significant change to the driven data, but it results in more finer resolution of wind field and improves the time and the position of the eye of the cyclone. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Model for accelerating discharge of lane traffic to facilitate intersection access by EVs"
        ],
        "penulis":"Sumaryo, Sony;Halim, Abdul;Ramli, Kalamullah;Joelianto, Endra;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Intelligent Transportation System (ITS) is the synergy of information technology, real-time control, and communication networks. The system is expected to perform more complex traffic arrangements, in particular, traffic management of Emergency Vehicles (EV) such as fire trucks, ambulances, and so forth. Implementation of traffic management using only Traffic Signal Pre-emption does not give enough space for an EV to cross an intersection safely, especially on streets where there is only one lane. This paper proposes a model of accelerated emptying of traffic in front of EVs. Accelerated emptying model uses historical approach, based on current characteristics of traffic. For example, if the normal vehicle speed is equal to the EV speed before accelerated emptying, the system indicator will be 0%, thereby indicating no need for accelerated emptying. Similarly, a negative system indicator result means an accelerated emptying process is not necessary. However, if the system indicator is close to 100%, this result indicates accelerated emptying is necessary. \u00a9 IJTech 2019.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Intelligent Transportation System (ITS) is the synergy of information technology, real-time control, and communication networks. The system is expected to perform more complex traffic arrangements, in particular, traffic management of Emergency Vehicles (EV) such as fire trucks, ambulances, and so forth. Implementation of traffic management using only Traffic Signal Pre-emption does not give enough space for an EV to cross an intersection safely, especially on streets where there is only one lane. This paper proposes a model of accelerated emptying of traffic in front of EVs. Accelerated emptying model uses historical approach, based on current characteristics of traffic. For example, if the normal vehicle speed is equal to the EV speed before accelerated emptying, the system indicator will be 0%, thereby indicating no need for accelerated emptying. Similarly, a negative system indicator result means an accelerated emptying process is not necessary. However, if the system indicator is close to 100%, this result indicates accelerated emptying is necessary. \u00a9 IJTech 2019."
        ]
    },
    {
        "judul":[
            "Development of rule-based feature extraction in multi-label text classification"
        ],
        "penulis":"Mediamer, Gugun;Adiwijaya, adiwijaya@telkomuniversity.ac.id;Faraby, Said Al;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hadith is the second main guidelines after the Holy Quran in the Islamic religion, which was revealed through the Messenger of Allah. Today, Hadith can classified by more than one class such as advice class, prohibited, and information to facilitate readers of Hadith in filtering the appropriate classes for each Hadith of Rasulullah SAW. In the course of research, there are many kinds of data involved in a text classification study. Therefore, special handling that fit with the characteristics of certain data is required. This study investigates the handling of multi-label data-Hadith Bukhari in Indonesian translation-focusing on feature extraction, feature weighted, and preprocessing methods. This study uses a rule-based feature extraction combined with several types of preprocessing along with three types of feature-weighted methods: TF-IDF, Word2vec, and Word2vec weighted with TF-IDF, the five preprocessing stages in this research: Case Folding, Tokenization, Remove Punctuation, Stopword Removal, and Stemming. From the 13 experiments conducted in this study consist of 2000 hadiths, it was found that the best performance for multi-label classification of Hadith data produced by the combination of the proposed rule-based feature extraction, Word2vec feature weighted method, and without using Stemming and Stopword Removal in the preprocessing phase. The Hamming Loss value obtained from this combination was 0.0623. The results show that our rule-based feature extraction method better than baseline method. \u00a9 2019 Tech Science Press.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hadith is the second main guidelines after the Holy Quran in the Islamic religion, which was revealed through the Messenger of Allah. Today, Hadith can classified by more than one class such as advice class, prohibited, and information to facilitate readers of Hadith in filtering the appropriate classes for each Hadith of Rasulullah SAW. In the course of research, there are many kinds of data involved in a text classification study. Therefore, special handling that fit with the characteristics of certain data is required. This study investigates the handling of multi-label data-Hadith Bukhari in Indonesian translation-focusing on feature extraction, feature weighted, and preprocessing methods. This study uses a rule-based feature extraction combined with several types of preprocessing along with three types of feature-weighted methods: TF-IDF, Word2vec, and Word2vec weighted with TF-IDF, the five preprocessing stages in this research: Case Folding, Tokenization, Remove Punctuation, Stopword Removal, and Stemming. From the 13 experiments conducted in this study consist of 2000 hadiths, it was found that the best performance for multi-label classification of Hadith data produced by the combination of the proposed rule-based feature extraction, Word2vec feature weighted method, and without using Stemming and Stopword Removal in the preprocessing phase. The Hamming Loss value obtained from this combination was 0.0623. The results show that our rule-based feature extraction method better than baseline method. \u00a9 2019 Tech Science Press."
        ]
    },
    {
        "judul":[
            "Constructing the ideal SRI (sustainability reporting index) framework for Indonesian market: combined perspectives from rating agencies, academics, and practitioners"
        ],
        "penulis":"Firmialy, Sita deliyana;Nainggolan, Yunieta Anny;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose: This study aims to focus on developing the sustainability reporting index (SRI) with combined perspectives from varied social rating agencies, along with integrated combined perspectives from academics experts and Indonesian companies. Design\/methodology\/approach: The first section discusses the theoretical framework along with the sustainability challenges faced by companies in Indonesia. The second section develops the methodology of the study to measure the SRI by considering practical and theoretical perspectives, starting from the identification of initial disclosure, selecting the final disclosure and developing the hierarchical framework. Lastly, the third section confirms the validity of the study\u2019s framework by the exploratory factor analysis method and its comparability by comparing the content analysis result of the study with the Kinder\u2013Lydenberg\u2013Domini (KLD) method. The content analysis was used to analyze annual reports, sustainability reports and companies\u2019 websites based on indicators found in the resulted model. Findings: The main finding is the SRI framework (SRIF) of the study, which is built on the basis of the stakeholder relationship theory and is focused on three main dimensions (social, economic and environmental). Specifically, the framework consists of 17 indicators and 93 sub-indicators. On the basis of factor analysis method, it can be safely said that the study\u2019s SRIF is quite valid. The high score of correlations between the SRIF and KLD results at the composite and dimension levels, along with the statistically significant results show that the study\u2019s SRIF results and KLD results are fairly similar. Research limitations\/implications: The present study has its limitation as it only gathers data from publicly available reports issued by the firms (secondary data). Owing to time limitation, primary data are not collected. However, this is also the strength of this research as it will allow investors to replicate the study\u2019s methodology to measure companies\u2019 sustainability. Practical implications: The study is useful to organizations and statutory bodies toward finding a replicable method to measure the Indonesian companies\u2019 social performance. In addition, the study also introduced the usefulness of the qualitative program Atlas TI to perform content analysis, the exploratory factor analysis method to ensure validity and comparability by comparing it to the KLD methodology, which is known globally as the most widely accepted methodology to measures social performance. Lastly, this study will provide implications to the Government to ascertain the level of SRI reporting among the Indonesian public-listed companies. Originality\/value: The resulted framework in this study simultaneously considers social, environmental and economic factors in the context of companies in Indonesia, while previous researchers have constructed reporting index separately (i.e. Sumiani et al., 2007; Zhao et al., 2012). Especially in the context of Indonesia, there is no such index simultaneously focused on the three main dimensions, namely, social, environmental and economics. The current study tries to fill the gap by using the constructed SRI index based on three perspectives combined, namely, social rating agencies, academic theorist and Indonesian companies. \u00a9 2018, Emerald Publishing Limited.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: This study aims to focus on developing the sustainability reporting index (SRI) with combined perspectives from varied social rating agencies, along with integrated combined perspectives from academics experts and Indonesian companies. Design\/methodology\/approach: The first section discusses the theoretical framework along with the sustainability challenges faced by companies in Indonesia. The second section develops the methodology of the study to measure the SRI by considering practical and theoretical perspectives, starting from the identification of initial disclosure, selecting the final disclosure and developing the hierarchical framework. Lastly, the third section confirms the validity of the study\u2019s framework by the exploratory factor analysis method and its comparability by comparing the content analysis result of the study with the Kinder\u2013Lydenberg\u2013Domini (KLD) method. The content analysis was used to analyze annual reports, sustainability reports and companies\u2019 websites based on indicators found in the resulted model. Findings: The main finding is the SRI framework (SRIF) of the study, which is built on the basis of the stakeholder relationship theory and is focused on three main dimensions (social, economic and environmental). Specifically, the framework consists of 17 indicators and 93 sub-indicators. On the basis of factor analysis method, it can be safely said that the study\u2019s SRIF is quite valid. The high score of correlations between the SRIF and KLD results at the composite and dimension levels, along with the statistically significant results show that the study\u2019s SRIF results and KLD results are fairly similar. Research limitations\/implications: The present study has its limitation as it only gathers data from publicly available reports issued by the firms (secondary data). Owing to time limitation, primary data are not collected. However, this is also the strength of this research as it will allow investors to replicate the study\u2019s methodology to measure companies\u2019 sustainability. Practical implications: The study is useful to organizations and statutory bodies toward finding a replicable method to measure the Indonesian companies\u2019 social performance. In addition, the study also introduced the usefulness of the qualitative program Atlas TI to perform content analysis, the exploratory factor analysis method to ensure validity and comparability by comparing it to the KLD methodology, which is known globally as the most widely accepted methodology to measures social performance. Lastly, this study will provide implications to the Government to ascertain the level of SRI reporting among the Indonesian public-listed companies. Originality\/value: The resulted framework in this study simultaneously considers social, environmental and economic factors in the context of companies in Indonesia, while previous researchers have constructed reporting index separately (i.e. Sumiani et al., 2007; Zhao et al., 2012). Especially in the context of Indonesia, there is no such index simultaneously focused on the three main dimensions, namely, social, environmental and economics. The current study tries to fill the gap by using the constructed SRI index based on three perspectives combined, namely, social rating agencies, academic theorist and Indonesian companies. \u00a9 2018, Emerald Publishing Limited."
        ]
    },
    {
        "judul":[
            "Motion Artifact Contaminated Functional Near-infrared Spectroscopy Signals Classification using K-Nearest Neighbor (KNN)"
        ],
        "penulis":"Sumantri, Airita Fajarnarita;Wijayanto, Inung;Patmasari, Raditiana;Ibrahim, Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research reports the use of K-Nearest Neighbor (KNN) method for classifying clean and motion artifact contaminated functional near-infrared spectroscopy (fNIRS) signals. fNIRS is one of the non-invasive methods to monitor brain activity by looking at the oxy-Hemoglobin (oxy-Hb) and deoxy-Hemoglobin (deoxy-Hb) levels. fNIRS data consists of 18 clean signals and 18 contaminated signals which needs to be classified by extracting its features. The feature extraction process uses a first-order statistical method such as kurtosis, skewness, mean, variance, standard deviation, and interquartile range. These features are then processed with weighted K-Nearest Neighbor (wKNN), one of the methods under KNN, to classify the artifact contaminated and clean fNIRS signals. The performance of the classification measured by accuracy, sensitivity, specificity, and AUC. Based on the trial, the highest performance result was obtained when using five features except for skewness with k=5, also when using four features except for skewness and kurtosis with k=9, which result in an accuracy of 88.9%, a sensitivity of 85%, specificity of 93.7%, and AUC of 0.90 \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research reports the use of K-Nearest Neighbor (KNN) method for classifying clean and motion artifact contaminated functional near-infrared spectroscopy (fNIRS) signals. fNIRS is one of the non-invasive methods to monitor brain activity by looking at the oxy-Hemoglobin (oxy-Hb) and deoxy-Hemoglobin (deoxy-Hb) levels. fNIRS data consists of 18 clean signals and 18 contaminated signals which needs to be classified by extracting its features. The feature extraction process uses a first-order statistical method such as kurtosis, skewness, mean, variance, standard deviation, and interquartile range. These features are then processed with weighted K-Nearest Neighbor (wKNN), one of the methods under KNN, to classify the artifact contaminated and clean fNIRS signals. The performance of the classification measured by accuracy, sensitivity, specificity, and AUC. Based on the trial, the highest performance result was obtained when using five features except for skewness with k=5, also when using four features except for skewness and kurtosis with k=9, which result in an accuracy of 88.9%, a sensitivity of 85%, specificity of 93.7%, and AUC of 0.90 \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Incorporating syllabification points into a model of grapheme-to-phoneme conversion"
        ],
        "penulis":"Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A model to convert a grapheme into a phoneme (G2P) is crucial in the natural language processing area. In general, it is developed using a probabilistic-based data-driven approach and directly applied to a sequence of graphemes with no other information. Important research shows that incorporating information of syllabification point is capable of improving a probabilistic-based English G2P. However, the information should be accurately provided by a perfect orthographic syllabification. Some noises or errors of syllabification significantly reduce the G2P performance. In this paper, incorporation of syllabification points into a probabilistic-based G2P model for Bahasa Indonesia is investigated. This information is important since Bahasa Indonesia is richer than English in terms of syllables. A 5-fold cross-validating on 50 k words shows that the incorporation of syllabification points significantly improves the performance of G2P model, where the phoneme error rate (PER) can be relatively reduced by 10.75%. This PER is much lower than the G2P model based on an inductive learning algorithm. An important contribution of this research is that the proposed G2P model is quite robust to syllabification errors. A syllable error rate (SER) of 2.5% that comes from an orthographic syllabification model just slightly increases the PER of the proposed G2P model from 0.83% to be 0.90%. A higher SER up to 10% just increase the PER to be 1.14%. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A model to convert a grapheme into a phoneme (G2P) is crucial in the natural language processing area. In general, it is developed using a probabilistic-based data-driven approach and directly applied to a sequence of graphemes with no other information. Important research shows that incorporating information of syllabification point is capable of improving a probabilistic-based English G2P. However, the information should be accurately provided by a perfect orthographic syllabification. Some noises or errors of syllabification significantly reduce the G2P performance. In this paper, incorporation of syllabification points into a probabilistic-based G2P model for Bahasa Indonesia is investigated. This information is important since Bahasa Indonesia is richer than English in terms of syllables. A 5-fold cross-validating on 50 k words shows that the incorporation of syllabification points significantly improves the performance of G2P model, where the phoneme error rate (PER) can be relatively reduced by 10.75%. This PER is much lower than the G2P model based on an inductive learning algorithm. An important contribution of this research is that the proposed G2P model is quite robust to syllabification errors. A syllable error rate (SER) of 2.5% that comes from an orthographic syllabification model just slightly increases the PER of the proposed G2P model from 0.83% to be 0.90%. A higher SER up to 10% just increase the PER to be 1.14%. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "A stochastic dairy transportation problem considering collection and delivery phases"
        ],
        "penulis":"Huang, Kuancheng;Wu, Kun-Feng;Ardiansyah, Muhammad Nashir;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Based on the dairy cooperatives in Indonesia, this study formulates a stochastic programming model to handle the milk collection and delivery process with the maximum route duration limitation, the external cooling facility option, and travel time uncertainty. Besides, the local practice of sharing the fleet for both collection and delivery further complicates the decision. A set covering-based solution approach is used, due to its flexibility in handling complicated operational requirements and alignment with the decision environment. According to the numerical experiment, the proposed solution algorithm can provide quality solutions with a reasonable computational time for the cooperative operators. \u00a9 2018 Elsevier Ltd",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Based on the dairy cooperatives in Indonesia, this study formulates a stochastic programming model to handle the milk collection and delivery process with the maximum route duration limitation, the external cooling facility option, and travel time uncertainty. Besides, the local practice of sharing the fleet for both collection and delivery further complicates the decision. A set covering-based solution approach is used, due to its flexibility in handling complicated operational requirements and alignment with the decision environment. According to the numerical experiment, the proposed solution algorithm can provide quality solutions with a reasonable computational time for the cooperative operators. \u00a9 2018 Elsevier Ltd"
        ]
    },
    {
        "judul":[
            "Evaluate number of LED on reflector room for optical wireless communication"
        ],
        "penulis":"Ramadhanti, Dyndra Anindita;Sujatmoko, Kris;Pamukti, Brian;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Optical fiber communication system is the most implemented technology for backbone and access network telecommunication. However, the mobility of users has forced technology wired to wireless technology and one of the newest research is Optical Wireless Communication (OWC). The OWC has no longer using fiber optic as propagation media and using air for its transmission. In this paper, we evaluate number of Light Emitting Diode (LED) with comparison for one and two transmitters towards light communication distribution in a 5 m \u00d7 5 m \u00d7 4 m on closed room with reflector. We also use reflector mirror in the wall and using On Off Keying-Non Return to Zero (OOK-NRZ) as a modulation system. In addition, we evaluate wall reflector for impact of communication coverage area. From computer simulation, the results show that two LEDs used with reflector has 29.9 % larger coverage area than one LED. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Optical fiber communication system is the most implemented technology for backbone and access network telecommunication. However, the mobility of users has forced technology wired to wireless technology and one of the newest research is Optical Wireless Communication (OWC). The OWC has no longer using fiber optic as propagation media and using air for its transmission. In this paper, we evaluate number of Light Emitting Diode (LED) with comparison for one and two transmitters towards light communication distribution in a 5 m \u00d7 5 m \u00d7 4 m on closed room with reflector. We also use reflector mirror in the wall and using On Off Keying-Non Return to Zero (OOK-NRZ) as a modulation system. In addition, we evaluate wall reflector for impact of communication coverage area. From computer simulation, the results show that two LEDs used with reflector has 29.9 % larger coverage area than one LED. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Developing Wood Identification System by Local Binary Pattern and Hough Transform Method"
        ],
        "penulis":"Hadiwidjaja, M. Luthfi;Gunawan P.H.;Prakasa, Esa;Rianto, Yan;Sugiarto, Bambang;Wardoyo, Riyo;Damayanti, Ratih;Sugiyanto, Krisdianto;Dewi, L. Mustika;Astutiputri, Vidya Fatimah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The aim of this paper is to develop the wood identification system using two methods, called, Local Binary Pattern (LBP) and Hough Transform (HT). Here, 12 (twelve) varies of wood species form Indonesia will be used as the data sets. The wood species are taken from wood anatomy laboratory, Puslitbang Hasil Hutan (P3HH). Here, the classification method of this research uses Euclidean Distance (ED) to determine the distance of two images of wood. From the classification results, using LBP method is shown better than HT. The weakness of HT method in this paper is HT method can only detecting the circle shape rather than arbitrary shape. By using LBP method, 6 of 12 species are 100% accurate detected. Beside, using HT method, only one species (Cratoxylon formosum) has accuracy 90%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aim of this paper is to develop the wood identification system using two methods, called, Local Binary Pattern (LBP) and Hough Transform (HT). Here, 12 (twelve) varies of wood species form Indonesia will be used as the data sets. The wood species are taken from wood anatomy laboratory, Puslitbang Hasil Hutan (P3HH). Here, the classification method of this research uses Euclidean Distance (ED) to determine the distance of two images of wood. From the classification results, using LBP method is shown better than HT. The weakness of HT method in this paper is HT method can only detecting the circle shape rather than arbitrary shape. By using LBP method, 6 of 12 species are 100% accurate detected. Beside, using HT method, only one species (Cratoxylon formosum) has accuracy 90%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Water flow control system based on context aware algorithm and IoT for hydroponic"
        ],
        "penulis":"Gandhi, Otrinanda;Ramdhani, Mohamad;Murti, Muhammad Ary;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementing principal component analysis and multinomial logit for cancer detection based on microarray data classification"
        ],
        "penulis":"Khoirunnisa, Azka;Adiwijaya;Rohmawati, Aniq A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cancer is the second largest cause of death in the world; in 2018, a total of 9.6 million mortalities were recorder, due to cancer alone. It is important to detect this deadly disease early. In the medical field, there are many methods that can be used to detect cancer. One of these methods is microarray data technology. Microarray data reads thousands of gene expressions at the same time. However, this method has a major problem; data with high dimensions can affect classification performance and consume a lot of computational time. Therefore, this research used Principal Component Analysis as the dimensional reduction method. This method performed feature extraction based on a Principal Component (PC) obtained from the calculation of eigenvalues and eigenvectors. Moreover, the data reduction was implemented using a Multinomial Logit Classifier by modifying the parameters estimator using Maximum Likelihood Estimation. The cancer data used in this research consists of Colon Cancer, Leukemia, Lung Cancer, and Ovarian Cancer datasets. The test results for the Ovarian Cancer dataset gave an accuracy of 100% using a Proportion of Variance (PPV) of 90%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is the second largest cause of death in the world; in 2018, a total of 9.6 million mortalities were recorder, due to cancer alone. It is important to detect this deadly disease early. In the medical field, there are many methods that can be used to detect cancer. One of these methods is microarray data technology. Microarray data reads thousands of gene expressions at the same time. However, this method has a major problem; data with high dimensions can affect classification performance and consume a lot of computational time. Therefore, this research used Principal Component Analysis as the dimensional reduction method. This method performed feature extraction based on a Principal Component (PC) obtained from the calculation of eigenvalues and eigenvectors. Moreover, the data reduction was implemented using a Multinomial Logit Classifier by modifying the parameters estimator using Maximum Likelihood Estimation. The cancer data used in this research consists of Colon Cancer, Leukemia, Lung Cancer, and Ovarian Cancer datasets. The test results for the Ovarian Cancer dataset gave an accuracy of 100% using a Proportion of Variance (PPV) of 90%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "IoT: Smart garbage monitoring using android and real time database"
        ],
        "penulis":"Putra, Riyan Hadi;Kusuma, Feri Teja;Damayanti, Tri Nopiani;Ramadan, Dadan Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Every single day, garbage is always produced and sometimes, due to the unbalance between high volume produced and the garbage volume transported to the landfill; it then leads to the buildup. To prevent any negative impact on environment, a system is needed to support the waste management process. Smart Garbage Monitoring System consists of two parts: portable garbage can and monitoring application using android smartphone. The use of ultrasonic sensor, GPS and GSM Module on the garbage can aims to provide the data on the garbage and send it to the real time database, in which the data will be processed by the monitoring application on smartphone to determine the time of garbage transport purposely to prevent any buildup. The system doesn't need a server to process, because the entire process of will be run by android application on a smartphone. Test results showed the capability of the system in monitoring the garbage can with the minimum distance between the wastes by three meters. The information on the height level of garbage can be synchronized in real time to smartphone, with an average delay on the EDGE network of 4.57 seconds, HSPA+ of 4.52 seconds and LTE of 3.85 seconds. \u00a9 2019 Universitas Ahmad Dahlan.",
            "Sustainable Development Goals mapped to this documentResponsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Every single day, garbage is always produced and sometimes, due to the unbalance between high volume produced and the garbage volume transported to the landfill; it then leads to the buildup. To prevent any negative impact on environment, a system is needed to support the waste management process. Smart Garbage Monitoring System consists of two parts: portable garbage can and monitoring application using android smartphone. The use of ultrasonic sensor, GPS and GSM Module on the garbage can aims to provide the data on the garbage and send it to the real time database, in which the data will be processed by the monitoring application on smartphone to determine the time of garbage transport purposely to prevent any buildup. The system doesn't need a server to process, because the entire process of will be run by android application on a smartphone. Test results showed the capability of the system in monitoring the garbage can with the minimum distance between the wastes by three meters. The information on the height level of garbage can be synchronized in real time to smartphone, with an average delay on the EDGE network of 4.57 seconds, HSPA+ of 4.52 seconds and LTE of 3.85 seconds. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Multilayer X-Band Wave Absorber with Enhanced Absorption Bandwidth"
        ],
        "penulis":"Syihabuddin, Budi;Effendi, Mohammad Ridwan;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electromagnetics (EM) wave absorber implemented with common pattern structure such as rectangular and circular patches on a single-layer of dielectric substrate has deficiency in performance. The use of passive components incorporated into the structure was sometimes employed to overcome the issue of deficiency. This paper proposes wave absorber composed of multilayer dielectric substrates to enhance the absorption characteristic focused on its bandwidth performance. The proposed multilayer wave absorber is designed to work at the X-band frequency with an FR4 epoxy dielectric substrate applied for each layer. A multi-impedance concept of each layer which depends on its patch dimension is implemented to acquire the bandwidth improvement. The characteristic of proposed wave absorber is investigated through its unit cell with the dimension of 5.80 mm \u00d7 5.80 mm. The characterization result shows that the fractional bandwidth for the unit cell using square patch could increase up to 127% and 169% for the double-layer and the triple-layers, respectively, compared to the single-layer of dielectric substrate at the X-band frequency of 9.5 GHz. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electromagnetics (EM) wave absorber implemented with common pattern structure such as rectangular and circular patches on a single-layer of dielectric substrate has deficiency in performance. The use of passive components incorporated into the structure was sometimes employed to overcome the issue of deficiency. This paper proposes wave absorber composed of multilayer dielectric substrates to enhance the absorption characteristic focused on its bandwidth performance. The proposed multilayer wave absorber is designed to work at the X-band frequency with an FR4 epoxy dielectric substrate applied for each layer. A multi-impedance concept of each layer which depends on its patch dimension is implemented to acquire the bandwidth improvement. The characteristic of proposed wave absorber is investigated through its unit cell with the dimension of 5.80 mm \u00d7 5.80 mm. The characterization result shows that the fractional bandwidth for the unit cell using square patch could increase up to 127% and 169% for the double-layer and the triple-layers, respectively, compared to the single-layer of dielectric substrate at the X-band frequency of 9.5 GHz. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Designing Green Procurement System Based on Enterprise Resources Planning for the Rubber Processing Industry"
        ],
        "penulis":"Karlina, Octa;Ridwan, Ari Yanuar;Fajrillah, Asti Amalia Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The rubber processing industry is one of the manufacturing industries that pay attention to every activity on its production process that occurs during rubber processing. The work done in the production process at manufacturing, such as the rubber processing industry, produces waste that harms the environment. Therefore, it is necessary to monitor business activities. In this study focuses on designing application based on Enterprise Resource Planning (ERP) by running a green procurement system therein. Green procurement provides solutions to the selection of materials and services that can minimize the impact on the environment and provide benefits for the company. In implementing of green procurement system, ISO 14000 standardization data to determine the green supplier and the green material attributes data are needed to use for the Key Performance Indicator (KPI) report. The ERP-based application can generate report Key Performance Indicator (KPI) for green materials and green suppliers to help the company to monitor business processes in green procurement. However, the process of measuring the percentage of green materials and green suppliers is out of the scope of the discussion in this study, because this study only provides designing an application to implement green procurement. The selection of application based on Enterprise Resources Planning (ERP) is due to an ERP system that can add and also update data and information without duplication so that it can improve employee efficiency in monitoring business process activities with data integration in application based on Enterprise Resources Planning (ERP). The design of this application is tailored to the user requirements for green procurement that focus on the ability of the application system to provide purchase requisition, request for quotation, supplier selection, purchase order and integrating data such as payment of materials with the finance division, integrating data material that enters warehouse with the warehouse division. In addition, the aim of this study is to have an information system in monitoring business process activities carried out during the procurement process in the rubber processing industry using the Key Performance Indicator report, to assist in the management of procurement business processes using Enterprise Resource Planning (ERP) system. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The rubber processing industry is one of the manufacturing industries that pay attention to every activity on its production process that occurs during rubber processing. The work done in the production process at manufacturing, such as the rubber processing industry, produces waste that harms the environment. Therefore, it is necessary to monitor business activities. In this study focuses on designing application based on Enterprise Resource Planning (ERP) by running a green procurement system therein. Green procurement provides solutions to the selection of materials and services that can minimize the impact on the environment and provide benefits for the company. In implementing of green procurement system, ISO 14000 standardization data to determine the green supplier and the green material attributes data are needed to use for the Key Performance Indicator (KPI) report. The ERP-based application can generate report Key Performance Indicator (KPI) for green materials and green suppliers to help the company to monitor business processes in green procurement. However, the process of measuring the percentage of green materials and green suppliers is out of the scope of the discussion in this study, because this study only provides designing an application to implement green procurement. The selection of application based on Enterprise Resources Planning (ERP) is due to an ERP system that can add and also update data and information without duplication so that it can improve employee efficiency in monitoring business process activities with data integration in application based on Enterprise Resources Planning (ERP). The design of this application is tailored to the user requirements for green procurement that focus on the ability of the application system to provide purchase requisition, request for quotation, supplier selection, purchase order and integrating data such as payment of materials with the finance division, integrating data material that enters warehouse with the warehouse division. In addition, the aim of this study is to have an information system in monitoring business process activities carried out during the procurement process in the rubber processing industry using the Key Performance Indicator report, to assist in the management of procurement business processes using Enterprise Resource Planning (ERP) system. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Systematic Literature Review: Framework Design of Student Performance Monitoring System in Higher Education"
        ],
        "penulis":"Finata R.A.;Andrawina L.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In many organizations and institution particularly college, monitoring of students is a very important factor especially in identifying every problem that faced student in college. Various kinds of problems faced by the student can cause a high number of students to retake courses. Because of the alarming situation of the quality in higher education caused some measure has to be taken. In this paper will be focused on student monitoring framework design in higher education. Systematic literature review (SLR) used as a methodology in reviewing literature. This paper will be classified of each research on primary studies by object of research, indicators, variables, and methods. From the literature review results it is known that student monitoring framework design in higher education can be explored further by considering their assignment point and quiz at each class meeting with the aim to reduce number of students to retake courses especially in freshman students. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In many organizations and institution particularly college, monitoring of students is a very important factor especially in identifying every problem that faced student in college. Various kinds of problems faced by the student can cause a high number of students to retake courses. Because of the alarming situation of the quality in higher education caused some measure has to be taken. In this paper will be focused on student monitoring framework design in higher education. Systematic literature review (SLR) used as a methodology in reviewing literature. This paper will be classified of each research on primary studies by object of research, indicators, variables, and methods. From the literature review results it is known that student monitoring framework design in higher education can be explored further by considering their assignment point and quiz at each class meeting with the aim to reduce number of students to retake courses especially in freshman students. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Characteristics of two mesoscale convective systems (MCSs) over the Greater Jakarta: case of heavy rainfall period 15\u201318 January 2013"
        ],
        "penulis":"Nuryanto, Danang Eko;Pawitan, Hidayat;Hidayat, Rahmat;Aldrian, Edvin;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Two different mesoscale convective system (MCS) events that produced the heavy rainfall over the Greater Jakarta (GJ) during 15\u201318 January 2013 period were investigated. The purpose of the present study is to analyze the atmospheric conditions of two different MCSs during the heavy rainfall. Data consist of 3\u00a0hourly rainfalls of meteorological stations, infrared satellite, sounding, 6-hourly surface wind and reanalysis data. The first MCS was developed at 16:00 LT on 14 January 2013 over the eastern coast of Sumatra covered an area of 249,732\u00a0km2at maximum size, with about 16\u00a0h durations. The next MCS was developed at 22:00 LT on 16 January 2013 over the northern coast of the GJ in 9\u00a0h of duration, and maximum covered area around 55,829\u00a0km2. A warmer and moist air was observed on the low-level layer in the evening of 16 January 2013 (prior of second MCS), in comparison to 14 January 2013 event. Combination of both the surface strong wind perturbation and equivalent potential temperature in the second MCS might be contributed to heavy rainfall over the GJ than the first one. \u00a9 2019, The Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Two different mesoscale convective system (MCS) events that produced the heavy rainfall over the Greater Jakarta (GJ) during 15\u201318 January 2013 period were investigated. The purpose of the present study is to analyze the atmospheric conditions of two different MCSs during the heavy rainfall. Data consist of 3\u00a0hourly rainfalls of meteorological stations, infrared satellite, sounding, 6-hourly surface wind and reanalysis data. The first MCS was developed at 16:00 LT on 14 January 2013 over the eastern coast of Sumatra covered an area of 249,732\u00a0km2at maximum size, with about 16\u00a0h durations. The next MCS was developed at 22:00 LT on 16 January 2013 over the northern coast of the GJ in 9\u00a0h of duration, and maximum covered area around 55,829\u00a0km2. A warmer and moist air was observed on the low-level layer in the evening of 16 January 2013 (prior of second MCS), in comparison to 14 January 2013 event. Combination of both the surface strong wind perturbation and equivalent potential temperature in the second MCS might be contributed to heavy rainfall over the GJ than the first one. \u00a9 2019, The Author(s)."
        ]
    },
    {
        "judul":[
            "Detecting Hand, Foot and Mouth Disease in Earlier Stage Using C4.5 Algorithm as Expert System Based on Android"
        ],
        "penulis":"Syahrial, Farisa Hafida;Irawan, Budhi;Prasasti, Anggunmeka Luhur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hand, Foot and Mouth Disease (HFMD) is an infectious diseases caused by enterovirus virus 71 (EV 71). The symptoms of HFMD is similar to several other disease that caused by a virus, especially disease that have a fever and rash symptoms which people usually underestimate diseases that have early symptoms like that. Therefore, in this system we classify the HFMD with the intention of detecting the disease from an earlier stage. And we use Android based application since at this present time, smartphone is the closest device that is always used by many people. The classification used in this paper is Decision Tree C4.5 Algorithm. Dataset used in this research is as many as 256 which divided into training data and testing data, that formed based on symptoms that had previously been validated by the doctor. The result shows that data partitions of 90%:10%, 80%:20% and 70%:30% has accuracy, precision and recall value are 100%. Thus, data partition 70%:30% has the best result because this partition has less training data but can still classify diseases effectively. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hand, Foot and Mouth Disease (HFMD) is an infectious diseases caused by enterovirus virus 71 (EV 71). The symptoms of HFMD is similar to several other disease that caused by a virus, especially disease that have a fever and rash symptoms which people usually underestimate diseases that have early symptoms like that. Therefore, in this system we classify the HFMD with the intention of detecting the disease from an earlier stage. And we use Android based application since at this present time, smartphone is the closest device that is always used by many people. The classification used in this paper is Decision Tree C4.5 Algorithm. Dataset used in this research is as many as 256 which divided into training data and testing data, that formed based on symptoms that had previously been validated by the doctor. The result shows that data partitions of 90%:10%, 80%:20% and 70%:30% has accuracy, precision and recall value are 100%. Thus, data partition 70%:30% has the best result because this partition has less training data but can still classify diseases effectively. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Gap analysis of Indonesian state-owned bank internet banking website"
        ],
        "penulis":"Pradana, Mahir;Wahyuddin S.;Syarifuddin, Syarifuddin;Putra, Adrianza;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aimed to describe the level of quality perceived by internet banking customers of a state-owned bank in Indonesia. We use Website Quality (WebQual) theory for this research. By analyzing usability, information quality, and service interaction of the internet banking website, we then interpret the result with Gap Analysis method. With the participation of 100 respondents collected from all over Indonesia, we found that there are value gaps between the actual quality (performance) and ideal quality (importance). \u00a9 2019, IEOM Society International.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aimed to describe the level of quality perceived by internet banking customers of a state-owned bank in Indonesia. We use Website Quality (WebQual) theory for this research. By analyzing usability, information quality, and service interaction of the internet banking website, we then interpret the result with Gap Analysis method. With the participation of 100 respondents collected from all over Indonesia, we found that there are value gaps between the actual quality (performance) and ideal quality (importance). \u00a9 2019, IEOM Society International."
        ]
    },
    {
        "judul":[
            "Relationship among Knowledge Management, Innovation, and Performance: A Systematic Literature Review"
        ],
        "penulis":"Kurniawati, Amelia;Wiratmadja, Iwan Inrawan;Sunaryo, Indryati;Ari Samadhi T.M.A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The role of knowledge management in improving organizational performance has been discussed in previous studies. Some other studies indicate that innovation is the enabler for organizational performance. Therefore, this study aims to identify the current research main findings related to the relationship among knowledge management, innovation, and performance. The methodology approach used in this study is the systematic literature review. There are 22 primary articles published from 2005 until 2018. The primary articles are classified according to the study context, research variables, and statistical tools used. The target sample population discussed in the 22 primary articles is both service and manufacturing industry with various size of the organization. Six of the primary articles identify the mediating role of innovation in the relationship between knowledge management and performance. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The role of knowledge management in improving organizational performance has been discussed in previous studies. Some other studies indicate that innovation is the enabler for organizational performance. Therefore, this study aims to identify the current research main findings related to the relationship among knowledge management, innovation, and performance. The methodology approach used in this study is the systematic literature review. There are 22 primary articles published from 2005 until 2018. The primary articles are classified according to the study context, research variables, and statistical tools used. The target sample population discussed in the 22 primary articles is both service and manufacturing industry with various size of the organization. Six of the primary articles identify the mediating role of innovation in the relationship between knowledge management and performance. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Welcome Message from IEEE ComSoc Indonesia Chapter"
        ],
        "penulis":"Astuti, Rina Pudji;Agung, Wiseto;Murti, Muhammad Ary;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "GSR-MAR: Global super-resolution for person multi-attribute recognition"
        ],
        "penulis":"Siadari, Thomhert Suprapto;Han, Mikyong;Yoon, Hyunjin;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Person attribute recognition aims to predict attribute labels based on person's appearance usually captured from surveillance cameras. It is a challenging problem in computer vision due to poor imaging quality with complex background clutter and unconstrained viewing conditions from various angles and distances between person and surveillance cameras. In this paper, we address such a problem using an end-to-end network called Global Super-Resolution for Multi Attribute Recognition (GSR-MAR). GSR-MAR integrates a conversion process of low-resolution input images into high-resolution images and predicts person attributes from input images. Before performing the classification process, GSR-MAR not only converts low-resolution images to high-resolution images to recover details of image textures but also captures larger context information by using large separable convolutional layers. The experiment results on two popular benchmark datasets demonstrate the performance improvement and effectiveness of our GSR-MAR model over competing baselines. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Person attribute recognition aims to predict attribute labels based on person's appearance usually captured from surveillance cameras. It is a challenging problem in computer vision due to poor imaging quality with complex background clutter and unconstrained viewing conditions from various angles and distances between person and surveillance cameras. In this paper, we address such a problem using an end-to-end network called Global Super-Resolution for Multi Attribute Recognition (GSR-MAR). GSR-MAR integrates a conversion process of low-resolution input images into high-resolution images and predicts person attributes from input images. Before performing the classification process, GSR-MAR not only converts low-resolution images to high-resolution images to recover details of image textures but also captures larger context information by using large separable convolutional layers. The experiment results on two popular benchmark datasets demonstrate the performance improvement and effectiveness of our GSR-MAR model over competing baselines. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Does gamification motivate gig workers? a critical issue in ride-sharing industries"
        ],
        "penulis":"Prabowo, Rahmanto;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The gamification in ride-sharing applications is actualized in a point system for incentives and ratings for feedback. By growth of driver's number, the current gamification is facing problems. Drivers should spend more time and serve more orders to achieve targeted points. As the impact, their performance got worse, and their customers' satisfaction was reduced. To analyze the gamification effect on driver motivation, this study synthesizes Self Determination Theory (SDT) and Motivational Affordance Perspective (MAP). This study is a case study based on empirical data using a quantitative approach. By involving 103 participants, this study examines seven variables: Identified Regulation, External Regulation, Need for Autonomy, Self-Efficacy, Playfulness, Extrinsic Motivation, and Intrinsic Motivation. After mapping them into nine hypotheses, there were five accepted ones. The results unveiled that gamification can influence extrinsic motivation, but it cannot influence intrinsic motivation. As general interpretation, gamification motivates drivers to take more orders since they are forced to reach targeted points. This study provides recommendations for ride-sharing operators to improve gamification by adding new features to cover self-efficacy, need for autonomy, and playfulness in order to influence drivers' intrinsic motivation. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The gamification in ride-sharing applications is actualized in a point system for incentives and ratings for feedback. By growth of driver's number, the current gamification is facing problems. Drivers should spend more time and serve more orders to achieve targeted points. As the impact, their performance got worse, and their customers' satisfaction was reduced. To analyze the gamification effect on driver motivation, this study synthesizes Self Determination Theory (SDT) and Motivational Affordance Perspective (MAP). This study is a case study based on empirical data using a quantitative approach. By involving 103 participants, this study examines seven variables: Identified Regulation, External Regulation, Need for Autonomy, Self-Efficacy, Playfulness, Extrinsic Motivation, and Intrinsic Motivation. After mapping them into nine hypotheses, there were five accepted ones. The results unveiled that gamification can influence extrinsic motivation, but it cannot influence intrinsic motivation. As general interpretation, gamification motivates drivers to take more orders since they are forced to reach targeted points. This study provides recommendations for ride-sharing operators to improve gamification by adding new features to cover self-efficacy, need for autonomy, and playfulness in order to influence drivers' intrinsic motivation. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Performance evaluation of query response time in the document stored nosql database"
        ],
        "penulis":"Gunawan, Rohmat;Rahmatulloh, Alam;Darmawan, Irfan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "NoSQL Database is one solution that can be used to store large amounts of data and have an excellent performance during the reading and writing process. Analysis of data with large volumes increasingly feels the benefits. Database exploration is one of the activities carried out in data analysis. Information on estimated response time queries can help in planning database exploration. This study aims to evaluate the response time of each query for the process of creating, read, update, delete (CRUD) on a document stored, NoSQL Database. MongoDB, ArangoDB, and CouchDB were selected for use in experiments. Experiments are carried out by processing queries for repeated create, read, update, and delete commands with different quantities. The experimental results in the study revealed that MongoDB had the lowest average query response time for the read process (0.017 seconds), update (25,358 seconds) and delete (0.055 seconds) compared to ArangoDB and CouchDB. However, for the creation process, the ArangoDB response time is the smallest, which is 28,493 seconds compared to MongoDB and CouchDB. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "NoSQL Database is one solution that can be used to store large amounts of data and have an excellent performance during the reading and writing process. Analysis of data with large volumes increasingly feels the benefits. Database exploration is one of the activities carried out in data analysis. Information on estimated response time queries can help in planning database exploration. This study aims to evaluate the response time of each query for the process of creating, read, update, delete (CRUD) on a document stored, NoSQL Database. MongoDB, ArangoDB, and CouchDB were selected for use in experiments. Experiments are carried out by processing queries for repeated create, read, update, and delete commands with different quantities. The experimental results in the study revealed that MongoDB had the lowest average query response time for the read process (0.017 seconds), update (25,358 seconds) and delete (0.055 seconds) compared to ArangoDB and CouchDB. However, for the creation process, the ArangoDB response time is the smallest, which is 28,493 seconds compared to MongoDB and CouchDB. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Transforming into sustainable innovation-driven digital co-creation: The role of experience, community and agility"
        ],
        "penulis":"Mihardjo, Leonardus W Wasono;Sasmoko;Alamsjah, Firdaus;Rukmana, Riza A. N.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Sustainability is a critical element in creating long-term values for service creation, especially for in-service providers in the Information Communication and Technology (ICT) industry. Sustainable values through co-creation involve crucial stakeholders, especially customers, organizations, and social communities to maximise the captured total value. Past studies have explored the concept, system and role of those stakeholders, however the sustainability of co-creation in the digital era has not been covered. Therefore, this paper aims to provide an understanding of the key concepts and models that would support practitioners in building sustainable innovation-driven digital co-creation. The study was conducted using 195 samples representing Indonesian ICT firms. Findings demonstrate that digital co-creation plays a significant role as an intervening variable in the relationship between customer experience orientation, social community, and organization agility and transformational performance. \u00a9BEIESP.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sustainability is a critical element in creating long-term values for service creation, especially for in-service providers in the Information Communication and Technology (ICT) industry. Sustainable values through co-creation involve crucial stakeholders, especially customers, organizations, and social communities to maximise the captured total value. Past studies have explored the concept, system and role of those stakeholders, however the sustainability of co-creation in the digital era has not been covered. Therefore, this paper aims to provide an understanding of the key concepts and models that would support practitioners in building sustainable innovation-driven digital co-creation. The study was conducted using 195 samples representing Indonesian ICT firms. Findings demonstrate that digital co-creation plays a significant role as an intervening variable in the relationship between customer experience orientation, social community, and organization agility and transformational performance. \u00a9BEIESP."
        ]
    },
    {
        "judul":[
            "Sleep monitoring system based on body posture movement using Microsoft Kinect sensor"
        ],
        "penulis":"Febriana, Nityacas;Rizal, Achmad;Susanto, Erwin;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Sleep activity is one of important factor to determine quality of human life and closely related with sleep quality, which is influenced by several factors such as daily activities, stress, and fatigue. Current sleep monitoring device is called polysomnography, which is commonly used on sleep monitoring systems in hospital by attaching several electrodes to the subject's head. However, physical contacts between device and subject may leads to disruption of sleep activity because subject feels uncomfortable. Goal of this study is to design a sleep monitoring system using Microsoft Kinect v.2. This device is able to track movements made by the subject. The subject's sleep quality is determined by the number of movements during bedtime. Joints displacement in time unit is calculated using the Euclidean distance method to calculate activities during sleep. The sleep monitoring system is designed to recognize subject's dominant sleep posture by using the boundary location method to divide captured body into three parts that separated with three baseline algorithms. Analysis results of sleep monitoring system output are classification of subject's sleep quality and the dominant sleep posture. Designed system is tested for 105 minutes and subject's posture changes per minute are called Minutely Posture Movement (MPM). Sleep quality is classified into 3 categories, namely \"Good\", \"Normal\", and \"Bad\". The classification constants of \"Good\", \"Normal\", and \"Bad\" are obtained from Q1 and Q3 of 10 subjects MPM. Value Q1 is 0.08 and value Q3 is 0.15. Subject's sleep quality is categorized as follows: \"Good\" on MPM <0.08; \"Normal\" on 0.08\u2264MPM <0.15; and \"Bad\" on MPM\u2265 0.15. Based on test results of 10 subjects, categorization of subject's sleep quality are: 20% \"Good\", 50% \"Normal\", and 30% \"Bad\". Based on dominant posture, the results are 70% yearner, 20% soldier, and 10% fetus. The designed system has 87.38% accuracy and 12.62% relative error. \u00a9 2019 Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sleep activity is one of important factor to determine quality of human life and closely related with sleep quality, which is influenced by several factors such as daily activities, stress, and fatigue. Current sleep monitoring device is called polysomnography, which is commonly used on sleep monitoring systems in hospital by attaching several electrodes to the subject's head. However, physical contacts between device and subject may leads to disruption of sleep activity because subject feels uncomfortable. Goal of this study is to design a sleep monitoring system using Microsoft Kinect v.2. This device is able to track movements made by the subject. The subject's sleep quality is determined by the number of movements during bedtime. Joints displacement in time unit is calculated using the Euclidean distance method to calculate activities during sleep. The sleep monitoring system is designed to recognize subject's dominant sleep posture by using the boundary location method to divide captured body into three parts that separated with three baseline algorithms. Analysis results of sleep monitoring system output are classification of subject's sleep quality and the dominant sleep posture. Designed system is tested for 105 minutes and subject's posture changes per minute are called Minutely Posture Movement (MPM). Sleep quality is classified into 3 categories, namely \"Good\", \"Normal\", and \"Bad\". The classification constants of \"Good\", \"Normal\", and \"Bad\" are obtained from Q1 and Q3 of 10 subjects MPM. Value Q1 is 0.08 and value Q3 is 0.15. Subject's sleep quality is categorized as follows: \"Good\" on MPM <0.08; \"Normal\" on 0.08\u2264MPM <0.15; and \"Bad\" on MPM\u2265 0.15. Based on test results of 10 subjects, categorization of subject's sleep quality are: 20% \"Good\", 50% \"Normal\", and 30% \"Bad\". Based on dominant posture, the results are 70% yearner, 20% soldier, and 10% fetus. The designed system has 87.38% accuracy and 12.62% relative error. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Named entity recognition on Indonesian tweets using hidden markov model"
        ],
        "penulis":"Azarine, Indira Suri;Bijaksana, Moch Arif;Asror, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tweets are short messages that can load up to 140 characters, posted by Twitter users. To meet this limit, users usually use abbreviation to express their thoughts, so that produce unstructured and inappropriate sentences grammar. As a result, it is difficult to identify which entity are needed, such as people's names, locations, and organizations. On this research, developed an entity named recognition system on Indonesian-language tweets using Hidden Markov Model with the addition of the POS Tag feature. Using metrics evaluation, the biggest F1score is 64.06%.Our source code and data are available at: https:\/\/github.com\/dirazarine\/Named-Entity-Recognition-on-Indonesian-Tweets-using-Hidden-Markov-Model. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tweets are short messages that can load up to 140 characters, posted by Twitter users. To meet this limit, users usually use abbreviation to express their thoughts, so that produce unstructured and inappropriate sentences grammar. As a result, it is difficult to identify which entity are needed, such as people's names, locations, and organizations. On this research, developed an entity named recognition system on Indonesian-language tweets using Hidden Markov Model with the addition of the POS Tag feature. Using metrics evaluation, the biggest F1score is 64.06%.Our source code and data are available at: https:\/\/github.com\/dirazarine\/Named-Entity-Recognition-on-Indonesian-Tweets-using-Hidden-Markov-Model. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Slope, humidity and vibration sensors performance for landslide monitoring system"
        ],
        "penulis":"Susanto, Erwin;Budiman, Faisal;Mukhtar, Doan Perdana Husneni;Latief, Muhammad Hamdan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A design of landslide disaster monitoring system, that embedded with Internet of Things (IoT) are presented. Several monitoring studies on landslide detection were carried out onto soil displacement caused by artificial rainfall and earthquake, in online and real time mode. Three sensors performance for soil movement monitoring that investigated were slope, humidity and vibration. Data measurement on sensors shows that all parameter has potential presentation for landslide monitoring. The system was built using sensors detection, and data was processed to be completed on the web server through cloud services. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A design of landslide disaster monitoring system, that embedded with Internet of Things (IoT) are presented. Several monitoring studies on landslide detection were carried out onto soil displacement caused by artificial rainfall and earthquake, in online and real time mode. Three sensors performance for soil movement monitoring that investigated were slope, humidity and vibration. Data measurement on sensors shows that all parameter has potential presentation for landslide monitoring. The system was built using sensors detection, and data was processed to be completed on the web server through cloud services. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Cholesterol level measurement through Iris image using gray level co-occurrence matrix and linear regression"
        ],
        "penulis":"Raharjo, Jangkung;Novamizanti, Ledya;Ramatryana, I. Nyoman Apraz;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cholesterol is a waxy fat compound that is mostly produced by the liver and the other part is obtained from food. The ideal cholesterol level in the human body is <200. High cholesterol can increase the risk of getting serious diseases such as strokes and heart attacks. Checking cholesterol levels through checking blood sugar requires the patient to undergo fasting for 10-12 hours first and processing the results of the examination also requires not a short time. Because of the seriousness of the disease that can be caused, an early examination is needed and it is also practical to determine the level of excess cholesterol in the human body. Iris has specific advantages which can record all organ conditions, body construction and psychological conditions. Therefore, Iridology as a science based on the arrangement of the iris can be an alternative for medical analysis. In this study, the author designed a system in the matrix simulator which is expected to be able to detect excess cholesterol levels with input in the form of iris images and then through the pre-processing stage then extracted features with the Gray Level Co-Occurrence Matrix method and classified using the Linear Regression method. The result from the modeling process can inform about cholesterol level. These processes make early detection of human body cholesterol level becomes easier. The cholesterol data level is classified into: normal cholesterol, at risk of cholesterol and high cholesterol. Each class was represented by 30 images, and each of it divided into two data types, 20 images used as training data and the remaining as testing data. The optimum result can be obtained on 45 degree angle, two pixels gap and correlation feture, which give 88.52% accuracy with 6.9595 standard deviation and 0.0365 seconds computation time for each image. \u00a9 2006-2019 Asian Research Publishing Network (ARPN). All rights reserved.",
            "OHH2NView detailsExpand Substance hydroxylamineCH3CH3CH3HOCH3CH3HHHHHView detailsExpand Substance cholesterol",
            "Powered by",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cholesterol is a waxy fat compound that is mostly produced by the liver and the other part is obtained from food. The ideal cholesterol level in the human body is <200. High cholesterol can increase the risk of getting serious diseases such as strokes and heart attacks. Checking cholesterol levels through checking blood sugar requires the patient to undergo fasting for 10-12 hours first and processing the results of the examination also requires not a short time. Because of the seriousness of the disease that can be caused, an early examination is needed and it is also practical to determine the level of excess cholesterol in the human body. Iris has specific advantages which can record all organ conditions, body construction and psychological conditions. Therefore, Iridology as a science based on the arrangement of the iris can be an alternative for medical analysis. In this study, the author designed a system in the matrix simulator which is expected to be able to detect excess cholesterol levels with input in the form of iris images and then through the pre-processing stage then extracted features with the Gray Level Co-Occurrence Matrix method and classified using the Linear Regression method. The result from the modeling process can inform about cholesterol level. These processes make early detection of human body cholesterol level becomes easier. The cholesterol data level is classified into: normal cholesterol, at risk of cholesterol and high cholesterol. Each class was represented by 30 images, and each of it divided into two data types, 20 images used as training data and the remaining as testing data. The optimum result can be obtained on 45 degree angle, two pixels gap and correlation feture, which give 88.52% accuracy with 6.9595 standard deviation and 0.0365 seconds computation time for each image. \u00a9 2006-2019 Asian Research Publishing Network (ARPN). All rights reserved."
        ]
    },
    {
        "judul":[
            "Missing data problem in predictive analytics"
        ],
        "penulis":"Nugroho, Heru;Surendro, Kridanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A revolution in computational methods and statistics to process and analyse data into insight and knowledge is along with the growth of data. The paradigm of data analytic is changed from explicit to implicit raises the way to extract knowledge from data through a prospective approach to determine the value of new observations based on the structure of the relationship between input and output (predictive analytics). In the cycle of predictive analytics, data preparation is a very important stage. The main challenge faced is that raw data cannot be directly used for analysis and related to the quality of the data. Completeness is arising related to data quality. Missing data is one that often causes data to become incomplete. As a result, predictive analytics generated from these data becomes inaccurate. In this paper, the issues related to the missing data in predictive analytics will be discussed through a literature study from related research. Also, the challenges and direction that might occur in the predictive analytics domain with problems related to missing data will be presented. \u00a9 2019 Association for Computing Machinery.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A revolution in computational methods and statistics to process and analyse data into insight and knowledge is along with the growth of data. The paradigm of data analytic is changed from explicit to implicit raises the way to extract knowledge from data through a prospective approach to determine the value of new observations based on the structure of the relationship between input and output (predictive analytics). In the cycle of predictive analytics, data preparation is a very important stage. The main challenge faced is that raw data cannot be directly used for analysis and related to the quality of the data. Completeness is arising related to data quality. Missing data is one that often causes data to become incomplete. As a result, predictive analytics generated from these data becomes inaccurate. In this paper, the issues related to the missing data in predictive analytics will be discussed through a literature study from related research. Also, the challenges and direction that might occur in the predictive analytics domain with problems related to missing data will be presented. \u00a9 2019 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Sentiment analysis on hotel reviews using Multinomial Na\u00efve Bayes classifier"
        ],
        "penulis":"Farisi, Arif Abdurrahman;Sibaroni, Yuliant;Faraby, Said Al;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this modern age where the internet is growing rapidly, the existence of the internet can make it easier for tourist to find any information. In the field of tourism hotel, internet is very helpful in promotion of hotel. Tourists usually tell the experience during the hotel by writing reviews on the internet. Hence many hotel's reviews are found on the internet. The impact on hotel owners is that they can take advantage of reviews on the internet to improve and evaluate their hotels. With the availability of reviews on the internet with large numbers, tourists can't understand all the reviews they read whether they contain positive or negative opinions. It takes a sentiment analysis to quickly detect if the reviews is a positive or negative reviews. This study provides a solution by classifying positive opinion reviews and negative opinions using the Multinomial Na\u00efve Bayes Classifier method and comparing models using preprocessing, feature extraction and feature selection. The best experimental results using preprocessing and feature selection with 10 fold cross validation have an average F1-Score more than 91%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this modern age where the internet is growing rapidly, the existence of the internet can make it easier for tourist to find any information. In the field of tourism hotel, internet is very helpful in promotion of hotel. Tourists usually tell the experience during the hotel by writing reviews on the internet. Hence many hotel's reviews are found on the internet. The impact on hotel owners is that they can take advantage of reviews on the internet to improve and evaluate their hotels. With the availability of reviews on the internet with large numbers, tourists can't understand all the reviews they read whether they contain positive or negative opinions. It takes a sentiment analysis to quickly detect if the reviews is a positive or negative reviews. This study provides a solution by classifying positive opinion reviews and negative opinions using the Multinomial Na\u00efve Bayes Classifier method and comparing models using preprocessing, feature extraction and feature selection. The best experimental results using preprocessing and feature selection with 10 fold cross validation have an average F1-Score more than 91%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Hijabers on instagram: Visualising the ideal muslim woman"
        ],
        "penulis":"Baulch, Emma;Pramiyanti, Alila;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Analysis of the influence of Minimum Redundancy Maximum Relevance as dimensionality reduction method on cancer classification based on microarray data using Support Vector Machine classifier"
        ],
        "penulis":"Ma'Ruf, Firda Aminy;Adiwijaya;Wisesty, Untari Novia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Microarray technology provides a way to monitor thousands of gene expressions at the same time. However, microarray data has a high dimensionality. This high dimensionality will affect the classification performance. In order to solve this issue, this research proposed the use of Minimum Redundancy Maximum Relevance (MRMR) as the dimension reduction method and Support Vector Machine (SVM) as the classifier. Principal Component Analysis (PCA) method was also used as a comparison to MRMR. Tests on lung cancer and ovarian cancer data with MRMR and SVM linear kernel classifier as well as polynomial kernel resulted in an F1-score of 1, with the number of features used for the classification was 20% of the original feature dataset. This means that the accuracy of the classification was 100% and the system built has an excellent performance. As for the colon cancer classification, the F1-score result using MRMR and SVM polynomial kernel classifier was greater than the classification without the dimension reduction method, which is 0.84. It is the same with the classification of leukemia cancer, where the MRMR and SVM polynomial kernel classifier obtained greater result than the result of leukemia classification without dimension reduction method, which the F1-score was 0.9657. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Microarray technology provides a way to monitor thousands of gene expressions at the same time. However, microarray data has a high dimensionality. This high dimensionality will affect the classification performance. In order to solve this issue, this research proposed the use of Minimum Redundancy Maximum Relevance (MRMR) as the dimension reduction method and Support Vector Machine (SVM) as the classifier. Principal Component Analysis (PCA) method was also used as a comparison to MRMR. Tests on lung cancer and ovarian cancer data with MRMR and SVM linear kernel classifier as well as polynomial kernel resulted in an F1-score of 1, with the number of features used for the classification was 20% of the original feature dataset. This means that the accuracy of the classification was 100% and the system built has an excellent performance. As for the colon cancer classification, the F1-score result using MRMR and SVM polynomial kernel classifier was greater than the classification without the dimension reduction method, which is 0.84. It is the same with the classification of leukemia cancer, where the MRMR and SVM polynomial kernel classifier obtained greater result than the result of leukemia classification without dimension reduction method, which the F1-score was 0.9657. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Description calculation of production costs and cost of good sold for the cattle ranchers in North Bandung regency, Indonesia"
        ],
        "penulis":"Barus, Irene Sukma Lestari;Arsalan, Syakieb;Edison, Acep;Sukmawati, Fitri;Silviana;Putri, Ratna Komala;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research was conducted based on the complaints from the cattle ranchers about the income from selling their livestock products. They often suffer livestock farming losses. The selling price they received from the parties of supplier of cow\u2019s milk where they distribute their products are various. The selling price for milk is around IDR 4,600 to IDR 5,000 per liter depending on the quality of milk. Likewise, for beef, the selling price is around IDR 80,000 to IDR 120,000 per kilogram depending on the period of selling. The selling price they received is considered unable to cover the costs for manufacturing process so that the cattle ranchers felt damaged. Therefore, this research gave a contribution in form of knowledge for the cattle ranchers about determining and calculating the cost of the product, and establishing the selling price by using traditional or conventional method and activity based costing method. In traditional method, all costs were charged against the product, including production costs that were not caused by the product. Meanwhile, the activity based costing method explained about the classification of costs, driver, and the cost driver of the product. Hence, this research suggested the cattle ranchers to adopt the activity based costing method since the ABC (activity-based costing) method is more accurate in determining the classification of costs. In addition, this research also gave a contribution for appropriate selling price for milk and beef. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research was conducted based on the complaints from the cattle ranchers about the income from selling their livestock products. They often suffer livestock farming losses. The selling price they received from the parties of supplier of cow\u2019s milk where they distribute their products are various. The selling price for milk is around IDR 4,600 to IDR 5,000 per liter depending on the quality of milk. Likewise, for beef, the selling price is around IDR 80,000 to IDR 120,000 per kilogram depending on the period of selling. The selling price they received is considered unable to cover the costs for manufacturing process so that the cattle ranchers felt damaged. Therefore, this research gave a contribution in form of knowledge for the cattle ranchers about determining and calculating the cost of the product, and establishing the selling price by using traditional or conventional method and activity based costing method. In traditional method, all costs were charged against the product, including production costs that were not caused by the product. Meanwhile, the activity based costing method explained about the classification of costs, driver, and the cost driver of the product. Hence, this research suggested the cattle ranchers to adopt the activity based costing method since the ABC (activity-based costing) method is more accurate in determining the classification of costs. In addition, this research also gave a contribution for appropriate selling price for milk and beef. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "DBMS-KU interpolation for WMT19 news translation task"
        ],
        "penulis":"Budiwati, Sari Dewi;Siagian, Al Hafiz Akbar Maulana;Fatyanosa, Tirana Noor;Aritsugi, Masayoshi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents the participation of DBMS-KU Interpolation system in WMT19 shared task, namely, Kazakh-English language pair. We examine the use of interpolation method using a different language model order. Our Interpolation system combines a direct translation with Russian as a pivot language. We use 3-gram and 5-gram language model orders to perform the language translation in this work. To reduce noise in the pivot translation process, we prune the phrase table of source-pivot and pivot-target. Our experimental results show that our Interpolation system outperforms the Baseline in terms of BLEU-cased score by +0.5 and +0.1 points in Kazakh-English and English-Kazakh, respectively. In particular, using the 5-gram language model order in our system could obtain better BLEU-cased score than utilizing the 3-gram one. Interestingly, we found that by employing the Interpolation system could reduce the perplexity score of English-Kazakh when using 3-gram language model order. \u00a9 2019 Association for Computational Linguistics"
        ],
        "abstrak":[
            "This paper presents the participation of DBMS-KU Interpolation system in WMT19 shared task, namely, Kazakh-English language pair. We examine the use of interpolation method using a different language model order. Our Interpolation system combines a direct translation with Russian as a pivot language. We use 3-gram and 5-gram language model orders to perform the language translation in this work. To reduce noise in the pivot translation process, we prune the phrase table of source-pivot and pivot-target. Our experimental results show that our Interpolation system outperforms the Baseline in terms of BLEU-cased score by +0.5 and +0.1 points in Kazakh-English and English-Kazakh, respectively. In particular, using the 5-gram language model order in our system could obtain better BLEU-cased score than utilizing the 3-gram one. Interestingly, we found that by employing the Interpolation system could reduce the perplexity score of English-Kazakh when using 3-gram language model order. \u00a9 2019 Association for Computational Linguistics"
        ]
    },
    {
        "judul":[
            "Experiment of 3-Phase N-path Filter for Hum Noise Suppression"
        ],
        "penulis":"Afifah, Khilda;Retdian, Nicodimus;Arijal, Muhammad;Shima, Takeshi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One of a critical problem in the biomedical signals measurements is hum noise activity due to power line interference. Various approaches to suppress hum noise both analog and digital techniques have been proposed. However, these approaches have some disadvantages. N-path notch filter can be an alternative solution for this problem. The notch depth in a conventional N-path notch filter is limited by the number of paths to achieve deeper notch. This paper proposes a new N-path notch filter with additional sample-and-hold (S\/H) and leak buffer circuits to improve notch depth. Simulation and measurement results of 3-phase N-path filter achieve notch depth of 61.6dB and 54.5dB respectively. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of a critical problem in the biomedical signals measurements is hum noise activity due to power line interference. Various approaches to suppress hum noise both analog and digital techniques have been proposed. However, these approaches have some disadvantages. N-path notch filter can be an alternative solution for this problem. The notch depth in a conventional N-path notch filter is limited by the number of paths to achieve deeper notch. This paper proposes a new N-path notch filter with additional sample-and-hold (S\/H) and leak buffer circuits to improve notch depth. Simulation and measurement results of 3-phase N-path filter achieve notch depth of 61.6dB and 54.5dB respectively. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Design and implementation of fire detection system using fuzzy logic algorithm"
        ],
        "penulis":"Surya Devi, Anak Agung Putu Bunga;Istikmal;Karna, Nyoman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One of the features of a smart home is fire detection. There have been many developments in previous studies, but not many have implemented a detection system with the fuzzy logic method. Therefore, in this research we have developed a fire detection system that applies fuzzy logic methods and algorithms. We used Raspberry pi 3 as the embedded system, DHT-11 and MQ-2 sensors to detect fires. Detection results will be processed using a fuzzy system and the results will be notified through the WhatsApp application and monitored through the web. The test results show that the system that has been developed is running well and can be used as a fire detection system in smart homes. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the features of a smart home is fire detection. There have been many developments in previous studies, but not many have implemented a detection system with the fuzzy logic method. Therefore, in this research we have developed a fire detection system that applies fuzzy logic methods and algorithms. We used Raspberry pi 3 as the embedded system, DHT-11 and MQ-2 sensors to detect fires. Detection results will be processed using a fuzzy system and the results will be notified through the WhatsApp application and monitored through the web. The test results show that the system that has been developed is running well and can be used as a fire detection system in smart homes. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Anchor placement design for a decoupled simple trilateration algorithm"
        ],
        "penulis":"Lee, Sang C.;Rizal, Syamsul;Ahn, Heungju;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Localization is one of the main issues in wireless sensor networks (WSNs). By deploying anchor nodes, the sensor node location can be estimated. Generally, three anchor node positions should be fixed and known so that it becomes possible to estimate other sensor nodes by using a trilateration technique. This paper investigated a mobile anchor node for a real-time local positioning system (RT-LPS). The target position could be calculated directly without a limitation of the coverage area, because three anchor nodes have been equipped on the mobile robot. The proposed method involves the design of three anchors at a specific right-angled triangle position to simplify the calculation of position information. A simple equation is proposed for calculating the target position. The measurement distances between the anchor and the target node are collected by using the time-of-arrival (ToA) method. The simulation results are compared in terms of the position error with the equilateral triangle method. \u00a9 Copyright 2019",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Localization is one of the main issues in wireless sensor networks (WSNs). By deploying anchor nodes, the sensor node location can be estimated. Generally, three anchor node positions should be fixed and known so that it becomes possible to estimate other sensor nodes by using a trilateration technique. This paper investigated a mobile anchor node for a real-time local positioning system (RT-LPS). The target position could be calculated directly without a limitation of the coverage area, because three anchor nodes have been equipped on the mobile robot. The proposed method involves the design of three anchors at a specific right-angled triangle position to simplify the calculation of position information. A simple equation is proposed for calculating the target position. The measurement distances between the anchor and the target node are collected by using the time-of-arrival (ToA) method. The simulation results are compared in terms of the position error with the equilateral triangle method. \u00a9 Copyright 2019"
        ]
    },
    {
        "judul":[
            "Analyzing tourism mobile applications perceived quality using sentiment analysis and topic modeling"
        ],
        "penulis":"Masrury, Riefvan Achmad;Fannisa;Alamsyah, Andry;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Mobile application is one of the most important information platforms for international tourists. Millions of tourists use mobile applications to find information and make transactions. Two popular Online Travel Agent (OTA) mobile applications for travel-related activities providers are Traveloka and Tiket.com. These applications certainly must meet travelers' needs to achieve satisfaction. Such satisfaction related to application Mobile Application Service Quality (MappSql) dimensions can be traced from thousands of their comments on the Google Play Store. From a set of reviews, information about the perception of mobile application quality can be obtained. Knowledge on user perceptions is very useful for company's consideration in creating effective business and app features to increase users' satisfaction. We propose Text Mining models to bring up hidden information regarding users' verdict. The selected text analysis methods for this research are Sentiment Analysis and Topic Modeling. We find that positive or negative sentiments towards MappSql dimensions of online travel agent applications qualities can be revealed using sentiment analysis method. Topic Modeling method is used to bring up groups of important words of topics related to each mobile application service quality dimensions. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mobile application is one of the most important information platforms for international tourists. Millions of tourists use mobile applications to find information and make transactions. Two popular Online Travel Agent (OTA) mobile applications for travel-related activities providers are Traveloka and Tiket.com. These applications certainly must meet travelers' needs to achieve satisfaction. Such satisfaction related to application Mobile Application Service Quality (MappSql) dimensions can be traced from thousands of their comments on the Google Play Store. From a set of reviews, information about the perception of mobile application quality can be obtained. Knowledge on user perceptions is very useful for company's consideration in creating effective business and app features to increase users' satisfaction. We propose Text Mining models to bring up hidden information regarding users' verdict. The selected text analysis methods for this research are Sentiment Analysis and Topic Modeling. We find that positive or negative sentiments towards MappSql dimensions of online travel agent applications qualities can be revealed using sentiment analysis method. Topic Modeling method is used to bring up groups of important words of topics related to each mobile application service quality dimensions. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Generalized linear model multivariate poisson with artificial marginal (GLM-MPAM): Application of vehicle insurance"
        ],
        "penulis":"Jamilatuzzahro;Caraka, Rezzy Eko;Aprinaldy, Dedi;Mahadi, Asma;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At vehicle insurance companies, the determination of the appropriate pure premium will make the business run well. In this study, we were modeling claims frequency data by considering the characteristics of policyholder such as policyholder's age, marital status, sex, car engine capacity, and age. The data used in this study is a non-motor vehicle and non-truck motor vehicle insurance data, which filed claims during 2013 in a general insurance company. Explaining the significance or value of the research. We are using Generalized Linear Model Multivariate Poisson with Artificial Marginal (GLM-MPAM) to estimate model parameters. The parameter values of this model are estimated using the Maximum Likelihood Estimation method. Furthermore, the estimation result of the parameter can be alternative in the calculation of the pure premium in the next period. \u00a9 2019 Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At vehicle insurance companies, the determination of the appropriate pure premium will make the business run well. In this study, we were modeling claims frequency data by considering the characteristics of policyholder such as policyholder's age, marital status, sex, car engine capacity, and age. The data used in this study is a non-motor vehicle and non-truck motor vehicle insurance data, which filed claims during 2013 in a general insurance company. Explaining the significance or value of the research. We are using Generalized Linear Model Multivariate Poisson with Artificial Marginal (GLM-MPAM) to estimate model parameters. The parameter values of this model are estimated using the Maximum Likelihood Estimation method. Furthermore, the estimation result of the parameter can be alternative in the calculation of the pure premium in the next period. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Prototype of Visible Light Communication Transceiver Using Array Photo Transistor for Real Time Digital Media Transfer"
        ],
        "penulis":"Wijayanto, Inung;Hadiyoso, Sugondo;Renggani, Retno;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Previous research about low cost visible light communication (VLC) transceiver prototype was conducted which able to reach 98 cm, 70\u00b0 and 19200 bps of transmitting distance, maximum transmission angle and transmission rate, respectively. The next prototype is built to get better performance by adding a reflector to the array phototransistor and split the power of the transceiver in order to maximize the light of the LED. This new prototype surpasses our target by reaching 134 cm of transmission distance. The system is also able to send digital multimedia files such as text, images, video in MPEG format and audio files in WAV and Mp3 format. The maximum bit rate of our prototype is 9600 bps and acceptance angle is 87\u00b0. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Previous research about low cost visible light communication (VLC) transceiver prototype was conducted which able to reach 98 cm, 70\u00b0 and 19200 bps of transmitting distance, maximum transmission angle and transmission rate, respectively. The next prototype is built to get better performance by adding a reflector to the array phototransistor and split the power of the transceiver in order to maximize the light of the LED. This new prototype surpasses our target by reaching 134 cm of transmission distance. The system is also able to send digital multimedia files such as text, images, video in MPEG format and audio files in WAV and Mp3 format. The maximum bit rate of our prototype is 9600 bps and acceptance angle is 87\u00b0. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Gender differences in students' e-learning usage outcomes"
        ],
        "penulis":"Aditya, Bayu Rima;Permadi, Aditya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The importance of studying gender differences in student skills has been demonstrated by the emergence of various results of previous studies that discussed the recommendations for developing learning by considering gender. The question that raised in this study is whether there is a difference between the assessment of male and female students on aspects related to the learning outcomes in the context of e-learning. The main contribution of this study was to provide evidence about matters considered necessary by male and female students towards achieving their learning outcomes. This research is based on a sample of 223 students that registered as e-learning class participants on two different campuses in Indonesia. This study concludes that there are two out of six aspects of learning outcomes that shows the significant difference between the assessment of male and female students: usefulness and course content. These results confirm that there are still gaps between male and female students about the learning outcomes.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGender equalityGoal 5Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The importance of studying gender differences in student skills has been demonstrated by the emergence of various results of previous studies that discussed the recommendations for developing learning by considering gender. The question that raised in this study is whether there is a difference between the assessment of male and female students on aspects related to the learning outcomes in the context of e-learning. The main contribution of this study was to provide evidence about matters considered necessary by male and female students towards achieving their learning outcomes. This research is based on a sample of 223 students that registered as e-learning class participants on two different campuses in Indonesia. This study concludes that there are two out of six aspects of learning outcomes that shows the significant difference between the assessment of male and female students: usefulness and course content. These results confirm that there are still gaps between male and female students about the learning outcomes.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Lexical and Syntactic Simplification for Indonesian Text"
        ],
        "penulis":"Wibowo, Muhammad Satrio;Romadhony, Ade;Sa'Adah, Siti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents a text simplification approach for Indonesian text by incorporating lexical and syntactic features that aims to improve documents accessibility for children. We employed the similar words information from word-embeddings model in lexical simplification and manually defined rules in syntactic simplification. We conducted the evaluation by presenting the simplified texts and several questions regarding text simplicity, fluency, and adequacy in form of a questionnaire to 137 fourth to sixth grade elementary students. The evaluation results show that our system is able to reduce the lexical and syntactic complexity, based on the simplicity and adequacy parameters, while we need to study the fluency parameter further. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents a text simplification approach for Indonesian text by incorporating lexical and syntactic features that aims to improve documents accessibility for children. We employed the similar words information from word-embeddings model in lexical simplification and manually defined rules in syntactic simplification. We conducted the evaluation by presenting the simplified texts and several questions regarding text simplicity, fluency, and adequacy in form of a questionnaire to 137 fourth to sixth grade elementary students. The evaluation results show that our system is able to reduce the lexical and syntactic complexity, based on the simplicity and adequacy parameters, while we need to study the fluency parameter further. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Quantitative eeg based on renyi entropy for epileptic classification"
        ],
        "penulis":"Hadiyoso, Sugondo;Aulia, Suci;Rizal, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "\u2013Analysis on Electroencephalogram (EEG) signal can provide important information related to the clinical pathology of epilepsy. Detecting the onset, prediction and type of seizures based on EEG signals is very important to determine an appropriate treatment for the patients. However, EEGs have the high complexity with non-linear and non-stationary characteristics; hence, an analysis will be very difficult to do through a visual inspection. Signal processing applications are, therefore, needed to make the interpretation easier. In this study, we proposed a method for EEG analysis based on signal complexity for the epileptic EEG classification. The Renyi entropy was used to extract the data of EEG features, which consist of seizure, interictal and normal features. Then, these features became the input to a classification algorithm. SVM (Support vector machine) classifier was applied to determine the type of that epileptic EEG signal and achieved accuracy of 85 %. This study can be a reference for neurology as an efficient method for epileptic EEG classification. \u00a9 2019, Editura Universitatii din Oradea. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "\u2013Analysis on Electroencephalogram (EEG) signal can provide important information related to the clinical pathology of epilepsy. Detecting the onset, prediction and type of seizures based on EEG signals is very important to determine an appropriate treatment for the patients. However, EEGs have the high complexity with non-linear and non-stationary characteristics; hence, an analysis will be very difficult to do through a visual inspection. Signal processing applications are, therefore, needed to make the interpretation easier. In this study, we proposed a method for EEG analysis based on signal complexity for the epileptic EEG classification. The Renyi entropy was used to extract the data of EEG features, which consist of seizure, interictal and normal features. Then, these features became the input to a classification algorithm. SVM (Support vector machine) classifier was applied to determine the type of that epileptic EEG signal and achieved accuracy of 85 %. This study can be a reference for neurology as an efficient method for epileptic EEG classification. \u00a9 2019, Editura Universitatii din Oradea. All rights reserved."
        ]
    },
    {
        "judul":[
            "A study of arousal classification based on EEG signal and support vector machine"
        ],
        "penulis":"Sofyan, Nur Arviah;Wijayanto, Inung;Hadiyoso, Sugondo;Purnamasari, Rita;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of Brain-Computer Interface technology nowadays has spread out in a case of classifying emotions based on brain signal (EEG) in human. One of the emotion parameters being focused in this research is arousal with the range from low (uninterested) to high (excited). A total of 32 EEG signals were observed in this study, consisting of 20 signals representing excited conditions and the other 12 being uninterested. This study was applied Principal Component Analysis (PCA) as feature extraction from both EEG signal groups. Then, statistical calculations are applied to reduce the dimensions of features. The support vector machine (SVM) algorithm was used for classification. The results of this preliminary study obtained the highest accuracy of 60% with PCA, entropy, and kurtosis as features. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of Brain-Computer Interface technology nowadays has spread out in a case of classifying emotions based on brain signal (EEG) in human. One of the emotion parameters being focused in this research is arousal with the range from low (uninterested) to high (excited). A total of 32 EEG signals were observed in this study, consisting of 20 signals representing excited conditions and the other 12 being uninterested. This study was applied Principal Component Analysis (PCA) as feature extraction from both EEG signal groups. Then, statistical calculations are applied to reduce the dimensions of features. The support vector machine (SVM) algorithm was used for classification. The results of this preliminary study obtained the highest accuracy of 60% with PCA, entropy, and kurtosis as features. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "ECG based person authentication using empirical mode decomposition and discriminant analysis"
        ],
        "penulis":"Hadiyoso, Sugondo;Rizal, Achmad;Aulia, Suci;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Person identification or authentication through biometric features has been widely applied for basic access and high-level security. But conventional biometrics such as fingerprints and irises tend to be easily faked or duplicated. Therefore a new biometric modality is needed to overcome that problem. In this paper, we simulate a new model of biometric systems using physical signals of the body. The proposed biometric system is based on ECG signals as a characteristic of each subject. A total of 110 raw ECG signals with a duration of 5 seconds from 11 participants were demonstrated in the proposed system. Empirical mode decomposition (EMD) and statistical analysis are used for feature extraction. Discriminant analysis with cross-validation was applied to test the performance of the proposed method. In this research, the highest accuracy of 93.6% was obtained using subspace discriminant in the scenario of all feature attributes as predictors. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Person identification or authentication through biometric features has been widely applied for basic access and high-level security. But conventional biometrics such as fingerprints and irises tend to be easily faked or duplicated. Therefore a new biometric modality is needed to overcome that problem. In this paper, we simulate a new model of biometric systems using physical signals of the body. The proposed biometric system is based on ECG signals as a characteristic of each subject. A total of 110 raw ECG signals with a duration of 5 seconds from 11 participants were demonstrated in the proposed system. Empirical mode decomposition (EMD) and statistical analysis are used for feature extraction. Discriminant analysis with cross-validation was applied to test the performance of the proposed method. In this research, the highest accuracy of 93.6% was obtained using subspace discriminant in the scenario of all feature attributes as predictors. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Inhibiting motivating factors on online gig economy client in Indonesia"
        ],
        "penulis":"Asih, Sinta Nur;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Online Gig Economy (OGE) as a result of digitalization results in a group of freelancers called gig workers. The rapid growth of the OGE platform and the high number of internet users in Indonesia has the potential to open up online job market opportunities and can lead to an excess supply of online gig workers. The growth of OGE in Indonesia needs to be balanced with the existence of research to find solutions to factors that influence people's interest in using online gig worker services. Data collection is done by distributing online questionnaires. Based on the results of the study, the factors that are motivating the interest of the public to use the gig worker online services are the Perceived Usefulness, and Social Influence while the inhibiting factor is the Perceived of Risk. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Online Gig Economy (OGE) as a result of digitalization results in a group of freelancers called gig workers. The rapid growth of the OGE platform and the high number of internet users in Indonesia has the potential to open up online job market opportunities and can lead to an excess supply of online gig workers. The growth of OGE in Indonesia needs to be balanced with the existence of research to find solutions to factors that influence people's interest in using online gig worker services. Data collection is done by distributing online questionnaires. Based on the results of the study, the factors that are motivating the interest of the public to use the gig worker online services are the Perceived Usefulness, and Social Influence while the inhibiting factor is the Perceived of Risk. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "An efficient technique for cluster number prediction in graph clustering using nullity of laplacian matrix"
        ],
        "penulis":"Atastina, Imelda;Sitohang, Benhard;Saptawati, G.A.Putri;Moertini, Veronica S;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Clustering graph dataset representing users\u2019 interactions can be used to detect groups or communities. Many existing graph clustering algorithms require an initial cluster number. The closer the initial cluster numbers to the real or final ones, the faster the algorithm will converge. Hence, finding the right initial cluster number is important for increasing the efficiency of the algorithms. This research proposes a novel technique for computing the initial cluster number using the nullity of the Laplacian Matrix of Adjacency Matrix. The fact that nullity relates to the properties of the eigenvalues in the Laplacian matrix of a connected component is used to predict the best cluster numbers. By using this technique, trial and error experiments for finding the right clusters is no longer needed. The experiment results using artificial and real dataset and modularity values (for measuring the clusters quality) showed that our proposed technique is efficient in finding initial cluster numbers, which is also the real best cluster numbers. \u00a9 2005 \u2013 ongoing JATIT & LLS.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Clustering graph dataset representing users\u2019 interactions can be used to detect groups or communities. Many existing graph clustering algorithms require an initial cluster number. The closer the initial cluster numbers to the real or final ones, the faster the algorithm will converge. Hence, finding the right initial cluster number is important for increasing the efficiency of the algorithms. This research proposes a novel technique for computing the initial cluster number using the nullity of the Laplacian Matrix of Adjacency Matrix. The fact that nullity relates to the properties of the eigenvalues in the Laplacian matrix of a connected component is used to predict the best cluster numbers. By using this technique, trial and error experiments for finding the right clusters is no longer needed. The experiment results using artificial and real dataset and modularity values (for measuring the clusters quality) showed that our proposed technique is efficient in finding initial cluster numbers, which is also the real best cluster numbers. \u00a9 2005 \u2013 ongoing JATIT & LLS."
        ]
    },
    {
        "judul":[
            "Real-time screen sharing using web socket for presenting without projector"
        ],
        "penulis":"Darmawan, Irfan;Rahmatulloh, Alam;Gunawan, Rohmat;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The presentation is generally done using a laptop device or Personal Computer (PC) connected to a projector. Participants see a presentation slide show on a particular screen or white painted the wall. However, sometimes, problems occur when the projectors' equipment is not available to the presentation process does not run optimally. Other problems such as projector damage or dead pixel conditions and rainbow effects on the projector often interfere with the display permanently. A presentation without using a projector is one solution to overcome problems that have been proposed in previous research. However, there is still a particular server that is used by presenters and PCs to access those used by clients. The solution to overcome this problem, in this study, will be developed a system that can carry out the activity of sharing presentation between presenter and audience without using a projector. The presenter only requires an ordinary laptop or PC connected to a wireless network. Participants as clients can access the presentation display via a smartphone that is connected to the same wireless network as the server. The system built consists of two main applications: Screen Sharing Server and Screen Sharing Client, which allows sharing of views by implementing a socket web on its data communication model. Test results with 20 smartphone audiences can see the presentation results from the presenter's laptop. The presentation was successfully carried out with the concept of screen sharing in real-time without using additional projectors and computers, no need for cables and without the need for an internet connection. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The presentation is generally done using a laptop device or Personal Computer (PC) connected to a projector. Participants see a presentation slide show on a particular screen or white painted the wall. However, sometimes, problems occur when the projectors' equipment is not available to the presentation process does not run optimally. Other problems such as projector damage or dead pixel conditions and rainbow effects on the projector often interfere with the display permanently. A presentation without using a projector is one solution to overcome problems that have been proposed in previous research. However, there is still a particular server that is used by presenters and PCs to access those used by clients. The solution to overcome this problem, in this study, will be developed a system that can carry out the activity of sharing presentation between presenter and audience without using a projector. The presenter only requires an ordinary laptop or PC connected to a wireless network. Participants as clients can access the presentation display via a smartphone that is connected to the same wireless network as the server. The system built consists of two main applications: Screen Sharing Server and Screen Sharing Client, which allows sharing of views by implementing a socket web on its data communication model. Test results with 20 smartphone audiences can see the presentation results from the presenter's laptop. The presentation was successfully carried out with the concept of screen sharing in real-time without using additional projectors and computers, no need for cables and without the need for an internet connection. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Asterisk and radio over ip integration at voice communication system air traffic control"
        ],
        "penulis":"Hendrawan, Hendrawan;Aditya, Bagus;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Asterisk, the most popular open source VoIP core software in telecommunications technology that is integrated with Radio Over IP (RoIP) and Voice over IP (VoIP) gateway devices can be cheap and powerful solution for small airports usually located in rural areas. This paper reports the configuration and implementation of Internet Protocol (IP)-based voice communication system (VCS) for air traffic control using Asterisk VoIP server integrated with MySQL database, Apache webserver and Transceiver Radio PTT devices. The radio gateway that was selected for the prototype did not fulfil several of the chosen requirements, since it was using a different frequency with airport radio frequency standard usage. The prototype is click to call and report via web interface application and allowing 2 way voice communication between Air Traffic Controller (ATC) with airport telecommunication device (PTT Radio Transceiver telephony). At this report, we will discuss about the prototype of VCS web interface at ATC and communication of Radio Transceiver Device with asterisk VoIP server. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Asterisk, the most popular open source VoIP core software in telecommunications technology that is integrated with Radio Over IP (RoIP) and Voice over IP (VoIP) gateway devices can be cheap and powerful solution for small airports usually located in rural areas. This paper reports the configuration and implementation of Internet Protocol (IP)-based voice communication system (VCS) for air traffic control using Asterisk VoIP server integrated with MySQL database, Apache webserver and Transceiver Radio PTT devices. The radio gateway that was selected for the prototype did not fulfil several of the chosen requirements, since it was using a different frequency with airport radio frequency standard usage. The prototype is click to call and report via web interface application and allowing 2 way voice communication between Air Traffic Controller (ATC) with airport telecommunication device (PTT Radio Transceiver telephony). At this report, we will discuss about the prototype of VCS web interface at ATC and communication of Radio Transceiver Device with asterisk VoIP server. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Metamaterial Antenna on Electro-Optic Modulator for Wireless Terra-Hertz Detection Through Radio-Over-Fibre Technology"
        ],
        "penulis":"Wijayanto, Yusuf Nur;Fathnan, Ashif Aminulloh;Kanno, Atsushi;Mahmudin, Dadin;Daud, Pamungkas;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We propose a new metamaterial antenna on electro-optic (EO) modulator for wireless terra-hertz detection through radio-over-fibre (ROF) technology. By wireless terra-hertz signal irradiation to the proposed device, strong terra-hertz electric field can be induced on the electric- LC metamaterial resonator. The induced terra-hertz electric field can be used for optical modulation through EO effects when a light-wave propagates into an optical waveguide located under the capacitive gap which the strongest induced terra-hertz electric field. Analysis of optical modulation is presented in details for operational frequency of 0.1 THz. The device fabrication process and the results of its measured characteristics are also reported. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We propose a new metamaterial antenna on electro-optic (EO) modulator for wireless terra-hertz detection through radio-over-fibre (ROF) technology. By wireless terra-hertz signal irradiation to the proposed device, strong terra-hertz electric field can be induced on the electric- LC metamaterial resonator. The induced terra-hertz electric field can be used for optical modulation through EO effects when a light-wave propagates into an optical waveguide located under the capacitive gap which the strongest induced terra-hertz electric field. Analysis of optical modulation is presented in details for operational frequency of 0.1 THz. The device fabrication process and the results of its measured characteristics are also reported. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Why Telco companies in Indonesia using social media monitoring as a way to handle feedback?"
        ],
        "penulis":"Lestari, Martha Tri;Suryana, Asep;Mulyana, Slamet;Hidayat, Mien;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Developments within industrial technology has currently become one of the phenomenon's in causing industries to use social media monitoring in handling feedback. People who work within an industry, have similar aims and purpose of the aforementioned industry, in which is usually related with the industry's vision and mission. \"Both practitioners and academics agree that the social revolution occurring through digital channels will have a profound impact on how people interact with each other and how companies manage their relationships in the changing communications landscape (Greenberg, 2010;Kletzmann et al.,2011;Dennis et al.,2009)\" (Journal of Business & Industrial Marketing, Vol. 30). Within this study, Telco Industries in Indonesia have been chosen to be the subject of research. The researcher chose several Telco industries that meets the criteria in accordance to the qualification standards and needs previously set by the researcher itself. Such a matter has become very interesting - especially in the digital era, as companies have transformed from using conventional methods in handling feedback to currently digital handling feedbacks by using social media monitoring. The research method used, includes a literature study. The data used within the results of this study, comes in the form of data collection obtained from media releases, websites, and several literatures such as journals and books. Results that are obtained from this research, includes an analysis regarding to why and how industries use as well as utilize social media monitoring to handle feedback. \u00a9 2019, Library Philosophy and Practice.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Developments within industrial technology has currently become one of the phenomenon's in causing industries to use social media monitoring in handling feedback. People who work within an industry, have similar aims and purpose of the aforementioned industry, in which is usually related with the industry's vision and mission. \"Both practitioners and academics agree that the social revolution occurring through digital channels will have a profound impact on how people interact with each other and how companies manage their relationships in the changing communications landscape (Greenberg, 2010;Kletzmann et al.,2011;Dennis et al.,2009)\" (Journal of Business & Industrial Marketing, Vol. 30). Within this study, Telco Industries in Indonesia have been chosen to be the subject of research. The researcher chose several Telco industries that meets the criteria in accordance to the qualification standards and needs previously set by the researcher itself. Such a matter has become very interesting - especially in the digital era, as companies have transformed from using conventional methods in handling feedback to currently digital handling feedbacks by using social media monitoring. The research method used, includes a literature study. The data used within the results of this study, comes in the form of data collection obtained from media releases, websites, and several literatures such as journals and books. Results that are obtained from this research, includes an analysis regarding to why and how industries use as well as utilize social media monitoring to handle feedback. \u00a9 2019, Library Philosophy and Practice."
        ]
    },
    {
        "judul":[
            "Applying deep learning models to action recognition of swimming mice with the scarcity of training data"
        ],
        "penulis":"Nguyen, Ngoc Giang;Delimayanti, Mera Kartika;Purnama, Bedy;Mahmudah, Kunti Robiatul;Kubo, Mamoru;Kakikawa, Makiko;Yamada, Yoichi;Satou, Kenji;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Deep learning models have shown their ability to model complicated problems in more efficient ways than other machine learning techniques in many application fields. For human action recognition tasks, the current state-of-the-art models are deep learning models. But they are not well-studied in applying for animal behaviour recognition due to the lack of data required for training these models. Therefore, in this research, we proposed a method to apply deep learning models to recognize the behaviours of a swimming mouse in two mouse forced swim tests with a limited amount of training data. We used deep learning models which are used in human action recognition tasks and fine-tuned them on the largest publicly available mouse behaviour dataset to give the models the knowledge about mouse behaviour recognition tasks. Then we fine-tuned the models one more time using the small amount of data that we have annotated for our swimming mouse behaviour recognition tasks. The good performance of these models in the new tasks proved the efficiency of our approach. \u00a9 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Deep learning models have shown their ability to model complicated problems in more efficient ways than other machine learning techniques in many application fields. For human action recognition tasks, the current state-of-the-art models are deep learning models. But they are not well-studied in applying for animal behaviour recognition due to the lack of data required for training these models. Therefore, in this research, we proposed a method to apply deep learning models to recognize the behaviours of a swimming mouse in two mouse forced swim tests with a limited amount of training data. We used deep learning models which are used in human action recognition tasks and fine-tuned them on the largest publicly available mouse behaviour dataset to give the models the knowledge about mouse behaviour recognition tasks. Then we fine-tuned the models one more time using the small amount of data that we have annotated for our swimming mouse behaviour recognition tasks. The good performance of these models in the new tasks proved the efficiency of our approach. \u00a9 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved."
        ]
    },
    {
        "judul":[
            "Entrepreneurial orientation and church performance in the Roman Catholic Archdiocese of Jakarta"
        ],
        "penulis":"Wulandari, Respati;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Encompassing the cities of Jakarta, Bekasi, and Tangerang, the Roman Catholic Archdiocese of Jakarta has existed in Indonesia for more than 200 years. Yet Roman Catholics make up less than 3% of the population there. To achieve their objectives, local parish priests need to act not only as religious leaders, but also as business managers. Guided by the theoretical framework of entrepreneurial orientation, interviews with 19 priests in the Archdiocese of Jakarta reveal how they have employed entrepreneurial techniques to improve their church's performance in terms of social outreach in a predominantly Muslim nation. Demonstrating the importance of such behavior for nonprofit organizations that operate in inimical environments, their experiences offer guidance to managers and practitioners who conduct operations in similar situations. \u00a9 2019 Wiley Periodicals, Inc.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Encompassing the cities of Jakarta, Bekasi, and Tangerang, the Roman Catholic Archdiocese of Jakarta has existed in Indonesia for more than 200 years. Yet Roman Catholics make up less than 3% of the population there. To achieve their objectives, local parish priests need to act not only as religious leaders, but also as business managers. Guided by the theoretical framework of entrepreneurial orientation, interviews with 19 priests in the Archdiocese of Jakarta reveal how they have employed entrepreneurial techniques to improve their church's performance in terms of social outreach in a predominantly Muslim nation. Demonstrating the importance of such behavior for nonprofit organizations that operate in inimical environments, their experiences offer guidance to managers and practitioners who conduct operations in similar situations. \u00a9 2019 Wiley Periodicals, Inc."
        ]
    },
    {
        "judul":[
            "An Integrated Human Resources Model in Manufacturing Companies: A Case of Indonesia"
        ],
        "penulis":"Permatasari A.;Amadea C.;Anggadwita G.;Alamanda D.T.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of manufacturing companies in Indonesia has a significant impact towards job availability for local people. This research analysis the human capital aspect in manufacturing companies. Data collection using questionnaire two manufacturing companies in Cikarang Industrial Area. There are 300 respondents that participated in this research, employees in manufacturing companies. The results found there are significant influences between internal service quality towards employee performances, mediating by employee satisfaction, employee commitment, and employee well-being. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of manufacturing companies in Indonesia has a significant impact towards job availability for local people. This research analysis the human capital aspect in manufacturing companies. Data collection using questionnaire two manufacturing companies in Cikarang Industrial Area. There are 300 respondents that participated in this research, employees in manufacturing companies. The results found there are significant influences between internal service quality towards employee performances, mediating by employee satisfaction, employee commitment, and employee well-being. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Fully integrated transceiver module with a temperature compensation for high bit rate contactless smart card"
        ],
        "penulis":"Adiono, Trio;Afifah, Khilda;Harimurti, Suksmandhira;Prasetiyo;Salman, Amy Hamidah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Contactless smart card has been applied in various applications, including electronic transaction and personal identification. These applications particularly require a big data transfer, as compared to other applications. Hence, it is very important that the card supports a high-speed data transfer rate. In this paper, we propose a design of a fully integrated transceiver module for contactless smart card that supports a high bit rate data communication, up to 848 kbps. Furthermore, to increase the stability and security of the card, the module is also designed to compensate the applied temperature variation, ranging from \u221225 to 125 \u00b0C. \u00a9 2018 Elsevier B.V.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Contactless smart card has been applied in various applications, including electronic transaction and personal identification. These applications particularly require a big data transfer, as compared to other applications. Hence, it is very important that the card supports a high-speed data transfer rate. In this paper, we propose a design of a fully integrated transceiver module for contactless smart card that supports a high bit rate data communication, up to 848 kbps. Furthermore, to increase the stability and security of the card, the module is also designed to compensate the applied temperature variation, ranging from \u221225 to 125 \u00b0C. \u00a9 2018 Elsevier B.V."
        ]
    },
    {
        "judul":[
            "A new mobility model for multi-UAVs reconnaissance based on partitioned zone"
        ],
        "penulis":"Jo, Yong-Il;Fathoni, Muhammad Faris;Kim, KyongHoon;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Activities on Unmanned Aerial Vehicle (UAV) have increased over the last years and there are many fields in which UAVs can be used. One of the basic applications is reconnaissance of a given area using multiple UAVs. To perform reconnaissance mission, there are two methods: (i) path planning to navigate the pre-determined route; and (ii) random mobility method to explore without prior knowledge. In this paper, we indicate the imbalance problem of existing random mobility models for reconnaissance and propose a new model considering reconnaissance balance based on the number of visits.We divide the scanning area into N zones and then select a zone stochastically in which the search is insufficient. We evaluated the performance of the model by focusing on the coverage rate and average inter-visiting time. The proposed model shows that the 90%-coverage reaching time is improved by about 25% and the average inter-visiting time is improved by up to 15% compared to the previous approach. \u00a9 2019 by the authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Activities on Unmanned Aerial Vehicle (UAV) have increased over the last years and there are many fields in which UAVs can be used. One of the basic applications is reconnaissance of a given area using multiple UAVs. To perform reconnaissance mission, there are two methods: (i) path planning to navigate the pre-determined route; and (ii) random mobility method to explore without prior knowledge. In this paper, we indicate the imbalance problem of existing random mobility models for reconnaissance and propose a new model considering reconnaissance balance based on the number of visits.We divide the scanning area into N zones and then select a zone stochastically in which the search is insufficient. We evaluated the performance of the model by focusing on the coverage rate and average inter-visiting time. The proposed model shows that the 90%-coverage reaching time is improved by about 25% and the average inter-visiting time is improved by up to 15% compared to the previous approach. \u00a9 2019 by the authors."
        ]
    },
    {
        "judul":[
            "The analysis of skin surface temperature and water vapor on volcanic eruption (case study: Mt. Kelud)"
        ],
        "penulis":"Noor A.B.S.;Hidayat R.;Perdinan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The post-volcanic eruption can be one of main factors in climate variability. The last incident of Kelud eruption had been occurred at 22:50 WIB, 13 February 2014. This paper aims to analyze the climatology of skin surface temperature (SKT), total column water vapor (TCWV), and mixing ratio at 500 mb before eruption from ERA-Interim and the processes before and after eruptions from Weather Research Forecasting (WRF) model simulation. Global Forecast System (GFS) data was used for WRF as initial condition and boundary condition, while ERA-Interim reanalysis dataset was used as a comparison. Bias correction was used to adjust WRF output with ERA-Interim on SKT and TCWV. SKT interval between day and night ranges from 21-23\u00b0C (WRF) and 12\u00b0C (ERA-Interim). There are 56 SKT WRF and 5 SKT ERA-Interim anomalous day before eruption. TCWV anomalies from WRF have consistent variation with ERA-Interim and there are 2 TCWV anomalies exceed 2 standard deviation. There were no TCWV anomalies detected on ERA-Interim, but were detected on WRF 2 days before and 3 days after eruption above 2 standard deviations. Mixing ratio shows a downward trend before and after the eruption. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The post-volcanic eruption can be one of main factors in climate variability. The last incident of Kelud eruption had been occurred at 22:50 WIB, 13 February 2014. This paper aims to analyze the climatology of skin surface temperature (SKT), total column water vapor (TCWV), and mixing ratio at 500 mb before eruption from ERA-Interim and the processes before and after eruptions from Weather Research Forecasting (WRF) model simulation. Global Forecast System (GFS) data was used for WRF as initial condition and boundary condition, while ERA-Interim reanalysis dataset was used as a comparison. Bias correction was used to adjust WRF output with ERA-Interim on SKT and TCWV. SKT interval between day and night ranges from 21-23\u00b0C (WRF) and 12\u00b0C (ERA-Interim). There are 56 SKT WRF and 5 SKT ERA-Interim anomalous day before eruption. TCWV anomalies from WRF have consistent variation with ERA-Interim and there are 2 TCWV anomalies exceed 2 standard deviation. There were no TCWV anomalies detected on ERA-Interim, but were detected on WRF 2 days before and 3 days after eruption above 2 standard deviations. Mixing ratio shows a downward trend before and after the eruption. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Prototype of Hand Gesture Recognition for Elderly People to Control Connected Home Devices"
        ],
        "penulis":"Ayubi, Shalahudin Al;Sudiharto, Dodi Wisaksono;Jadied, Erwid Musthofa;Aryanto, Endro;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nowadays, the technology development makes a human can create a tool which is used to recognize an object and it becomes a popular technology device. It happens because this tool has an important role for interaction between a human and a computer. One example of this technology usage is to recognize a hand gesture for controlling a home automation system. The existing of this technology creates the change related to how the human controls any tools in a house and it also reduces the complexity including an effort when it is used for controlling. This feature is very useful, especially for elderly people who stay in independent living. This study is going to develop a controller prototype by using FAST (Features from Accelerated Segment Test) algorithm to detect hand gesture for operating the connected home devices. This controller uses an embedded system to translate a command which is created by using the hand gesture of senior captured by the cam for controlling the lamps. The lamps itself are represented as several tools in the house. The observation gives a result that the hand gesture is potential to be implemented as a command for controlling the proposed system prototype in the range which is not far than 1 meter with the percentage average recognition accuracy is almost 80%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, the technology development makes a human can create a tool which is used to recognize an object and it becomes a popular technology device. It happens because this tool has an important role for interaction between a human and a computer. One example of this technology usage is to recognize a hand gesture for controlling a home automation system. The existing of this technology creates the change related to how the human controls any tools in a house and it also reduces the complexity including an effort when it is used for controlling. This feature is very useful, especially for elderly people who stay in independent living. This study is going to develop a controller prototype by using FAST (Features from Accelerated Segment Test) algorithm to detect hand gesture for operating the connected home devices. This controller uses an embedded system to translate a command which is created by using the hand gesture of senior captured by the cam for controlling the lamps. The lamps itself are represented as several tools in the house. The observation gives a result that the hand gesture is potential to be implemented as a command for controlling the proposed system prototype in the range which is not far than 1 meter with the percentage average recognition accuracy is almost 80%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Analysis of LFCC feature extraction in baby crying classification using KNN"
        ],
        "penulis":"Dewi, Sita Purnama;Prasasti, Anggunmeka Luhur;Irawan, Budhi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cry is a form of communication for children to express their feeling. Baby's cry can be characterized according to its natural periodic tone and the change of voice. It has a base frequency (pitch) in range 250Hz to 600Hz. Through their baby's cries detection, parents can monitor their baby remotely only in important condition. This study of sound recognition has two main processes, the first process is feature extraction and the second process is classification or determining the sound pattern. In the Linear Frequency Cepstral Coefficient (LFCC) method, the analysis of changes in pre-emphasis, numbers of filter bank and numbers of cepstral are conducted. The selection of the filter bank value which applied must be greater than the cepstral value which applied. Cepstral values is adjusted to get the better accuracy. The highest percentage of accuracy is 90% when this system uses 8 as the cepstral value and 3 as the nearest neighbor value, and all rules are considered the best value based on the test results. The use of LFCC as feature extraction method and K-Nearest Neighbor (K-NN) classification can be implemented to detect the baby is crying or not so that it can be applied as a solution for parents to monitor their children remotely only in certain condition. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cry is a form of communication for children to express their feeling. Baby's cry can be characterized according to its natural periodic tone and the change of voice. It has a base frequency (pitch) in range 250Hz to 600Hz. Through their baby's cries detection, parents can monitor their baby remotely only in important condition. This study of sound recognition has two main processes, the first process is feature extraction and the second process is classification or determining the sound pattern. In the Linear Frequency Cepstral Coefficient (LFCC) method, the analysis of changes in pre-emphasis, numbers of filter bank and numbers of cepstral are conducted. The selection of the filter bank value which applied must be greater than the cepstral value which applied. Cepstral values is adjusted to get the better accuracy. The highest percentage of accuracy is 90% when this system uses 8 as the cepstral value and 3 as the nearest neighbor value, and all rules are considered the best value based on the test results. The use of LFCC as feature extraction method and K-Nearest Neighbor (K-NN) classification can be implemented to detect the baby is crying or not so that it can be applied as a solution for parents to monitor their children remotely only in certain condition. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A perspective of home security using wireless communication"
        ],
        "penulis":"Purboyo, Tito Waluyo;Osmond, Andrew Brian;Aryani, Ressy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Home security is security system to applied at home or at one building. A function of home security is to provide comfort, some level of protection for the inhabitants of the house and can also be implemented into the system for crime prevention. The research will be conducted using wireless communication as the communication module used in security systems. The diversity of application, technology, methods, sensors that used and many more ways can increase the level of security at home. This study aims to review and compare some paper of home security likes methods, used tools, advantages and disadvantages of a security system. At the end, the final duty is to know which system is suitable for home by using the parameters to be compared. \u00a9 2019, Medwell Journals.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Home security is security system to applied at home or at one building. A function of home security is to provide comfort, some level of protection for the inhabitants of the house and can also be implemented into the system for crime prevention. The research will be conducted using wireless communication as the communication module used in security systems. The diversity of application, technology, methods, sensors that used and many more ways can increase the level of security at home. This study aims to review and compare some paper of home security likes methods, used tools, advantages and disadvantages of a security system. At the end, the final duty is to know which system is suitable for home by using the parameters to be compared. \u00a9 2019, Medwell Journals."
        ]
    },
    {
        "judul":[
            "Evaluation of Sustainability on Indonesia Historical Streets"
        ],
        "penulis":"Harsritanto B.I.R.;Rusyda H.F.S.;Prabowo A.R.;Jamila R.F.;Putra G.P.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Sustainable development mandates a user friendly design. Universal Design is sustainable concept that aimed to facilitate full range of human diversity. The evaluation based of universal design on built infrastructure can suggest more sustainable, functional and user-friendly environment. One of main infrastructure is streetscape. This study examined three historical streets of Indonesia. This study aimed to examine and compare the Indonesia cases using sustainable universal design guidelines. The research methods of this research are comparison study, site observation, and GIS-based mapping. The results of this study are: Indonesia historical street cases are averages; the local street regulations need to be improved; and the urgency of user oriented design on next improvement. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sustainable development mandates a user friendly design. Universal Design is sustainable concept that aimed to facilitate full range of human diversity. The evaluation based of universal design on built infrastructure can suggest more sustainable, functional and user-friendly environment. One of main infrastructure is streetscape. This study examined three historical streets of Indonesia. This study aimed to examine and compare the Indonesia cases using sustainable universal design guidelines. The research methods of this research are comparison study, site observation, and GIS-based mapping. The results of this study are: Indonesia historical street cases are averages; the local street regulations need to be improved; and the urgency of user oriented design on next improvement. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Effectiveness Analysis of Social Media Ads as A Promotional Media (Case Study: Instagram Taya.Id)"
        ],
        "penulis":"Tripiawan W.;Amani, Husni;Wijaya A.T.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Technological development at the moment affected the trend in the global marketing. This development makes the marketers to change marketing strategy them into the internet marketing one of which is taya.id who want to focus on online shop course in the hope of products marketed can penetrate the global market. The sample techniques used to research is purposive sampling on ever buy taya.id products and get information about the product taya.id through account social official media taya.id. In total, 100 respondents were collected as the sample of this research. This research using the EPIC model as a method calculation effectiveness consisting of four namely empathy dimension, persuasion, impact, and communication. The result of this research and examining evidence and proving that the call social media taya.id is considered effective with a value of up 2,752 as to dimensions empathy, the value of 2,742 as to dimensions persuasion, the value of 2,722 as to dimensions impact, and value of 2,895 as to dimensions communication. In overall, this finding concludes that the advertising of Taya.id through Instagram is effective. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Technological development at the moment affected the trend in the global marketing. This development makes the marketers to change marketing strategy them into the internet marketing one of which is taya.id who want to focus on online shop course in the hope of products marketed can penetrate the global market. The sample techniques used to research is purposive sampling on ever buy taya.id products and get information about the product taya.id through account social official media taya.id. In total, 100 respondents were collected as the sample of this research. This research using the EPIC model as a method calculation effectiveness consisting of four namely empathy dimension, persuasion, impact, and communication. The result of this research and examining evidence and proving that the call social media taya.id is considered effective with a value of up 2,752 as to dimensions empathy, the value of 2,742 as to dimensions persuasion, the value of 2,722 as to dimensions impact, and value of 2,895 as to dimensions communication. In overall, this finding concludes that the advertising of Taya.id through Instagram is effective. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparison of Classical Interpolation Methods and Compressive Sensing for Missing Data Reconstruction"
        ],
        "penulis":"Usman, Koredianto;Ramdhani, Mohammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The emerging of a new compression technique called compressive sensing (CS) has opened various research possibility in many fields. Practically, CS consists of two main steps, which are compression step and reconstruction step. In many cases, the compression step occurs naturally, for example when several data is missing from the complete set of data. Reconstructing for complete data from incomplete data is the original aims of CS reconstruction process. It is therefore also a logical implication of CS as data interpolation method. Given this situation, a research of CS capability for data interpolation is not yet available. In this paper we investigate the capability of CS for data interpolation. Two popular CS reconstruction tools are used: orthogonal matching pursuit (OMP) and convex programming (CVX). We compared these CS reconstruction performance to the standard interpolation methods which are the linear interpolation and spline interpolation. Simulation results show that classical interpolation methods have better performance in term of general accuracy, while CS reconstruction method has advantage on accuracy in reconstructing data that has sharp changes. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The emerging of a new compression technique called compressive sensing (CS) has opened various research possibility in many fields. Practically, CS consists of two main steps, which are compression step and reconstruction step. In many cases, the compression step occurs naturally, for example when several data is missing from the complete set of data. Reconstructing for complete data from incomplete data is the original aims of CS reconstruction process. It is therefore also a logical implication of CS as data interpolation method. Given this situation, a research of CS capability for data interpolation is not yet available. In this paper we investigate the capability of CS for data interpolation. Two popular CS reconstruction tools are used: orthogonal matching pursuit (OMP) and convex programming (CVX). We compared these CS reconstruction performance to the standard interpolation methods which are the linear interpolation and spline interpolation. Simulation results show that classical interpolation methods have better performance in term of general accuracy, while CS reconstruction method has advantage on accuracy in reconstructing data that has sharp changes. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Enterprise Resource Planning (ERP) using Integrated Model of Extended Technology Acceptance Model (TAM) 2: Case Study of PT. Toyota Astra Motor"
        ],
        "penulis":"Ike Wahyuning W.;Lubis, Muharman;Witjaksono, Wahjoe;Azizah, Anik Hanifatul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "ERP (Enterprise Resource Planning) is an integrated information system that can accommodate information system needs specifically for different departments in a company. The use of ERP makes all systems within a company into a system that is integrated with one database so that some departments become easier in sharing data and communication. PT. Toyota Astra Motor is a company that has implemented an ERP system since 2000, but the success rate is still around 75% and 25% failure. Therefore, this study was designed to analyze what are the determinants of success that can be used as reference materials to make PT. Toyota Astra Motor is a better company and can improve the sales and customer service system. To analyze the determinants of the success of ERP implementation at PT. Toyota Astra Motor researchers used the Extended Technology Acceptance Model (TAM) 2 model to integrate the combined Technology Acceptance Model and the IS success model. This study uses quantitative design with hypotheses and analyzes using IBM AMOS software. Based on the results of the study using the Extended Technology Acceptance Model (TAM) 2 to find out success factors it is known that the influential variables are job relevance, compatibility, perceived ease of use, perceived usefulness, function, internal support and intention to use, which means if the variable can be used as a determining factor for the success of ERP implementation by PT. Toyota Astra Motor. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "ERP (Enterprise Resource Planning) is an integrated information system that can accommodate information system needs specifically for different departments in a company. The use of ERP makes all systems within a company into a system that is integrated with one database so that some departments become easier in sharing data and communication. PT. Toyota Astra Motor is a company that has implemented an ERP system since 2000, but the success rate is still around 75% and 25% failure. Therefore, this study was designed to analyze what are the determinants of success that can be used as reference materials to make PT. Toyota Astra Motor is a better company and can improve the sales and customer service system. To analyze the determinants of the success of ERP implementation at PT. Toyota Astra Motor researchers used the Extended Technology Acceptance Model (TAM) 2 model to integrate the combined Technology Acceptance Model and the IS success model. This study uses quantitative design with hypotheses and analyzes using IBM AMOS software. Based on the results of the study using the Extended Technology Acceptance Model (TAM) 2 to find out success factors it is known that the influential variables are job relevance, compatibility, perceived ease of use, perceived usefulness, function, internal support and intention to use, which means if the variable can be used as a determining factor for the success of ERP implementation by PT. Toyota Astra Motor. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Seismic model estimation using particle swarm optimization"
        ],
        "penulis":"Liu, Bo;Mohandes, Mohamed;Nuha, Hilal;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Modern seismic data surveys generate terabytes of data daily leading to a significant increase of the cost for storage and transmission. Therefore, it is desired to compress seismic data. In this work, we propose a model-based compression scheme to deal with the large data volume. First, each seismic trace is modeled as a superposition of multiple exponentially decaying sinusoidal waves (EDSWs). Each EDSW represents a model component and is defined by a set of parameters. Secondly, a parameter estimation algorithm for this model is proposed using Particle Swarm Optimization (PSO) technique. In the proposed algorithm, the parameters of each EDSW are estimated sequentially wave by wave. A suitable number of model components for each trace is determined according to the level of the residuals energy. The proposed model based compression scheme is then experimentally compared with the discrete Cosine transform (DCT) on a real seismic data. The proposed model based algorithm outperforms the DCT in term of compression ratio and reconstruction quality. \u00a9 2018 SEG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Modern seismic data surveys generate terabytes of data daily leading to a significant increase of the cost for storage and transmission. Therefore, it is desired to compress seismic data. In this work, we propose a model-based compression scheme to deal with the large data volume. First, each seismic trace is modeled as a superposition of multiple exponentially decaying sinusoidal waves (EDSWs). Each EDSW represents a model component and is defined by a set of parameters. Secondly, a parameter estimation algorithm for this model is proposed using Particle Swarm Optimization (PSO) technique. In the proposed algorithm, the parameters of each EDSW are estimated sequentially wave by wave. A suitable number of model components for each trace is determined according to the level of the residuals energy. The proposed model based compression scheme is then experimentally compared with the discrete Cosine transform (DCT) on a real seismic data. The proposed model based algorithm outperforms the DCT in term of compression ratio and reconstruction quality. \u00a9 2018 SEG."
        ]
    },
    {
        "judul":[
            "On developing a network scheduling simulator: IR-TASA visualization"
        ],
        "penulis":"Aulia, Arief Luthfi;Ramli, Kalamullah;Santoso, Iman Hedi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One of the difficult challenge of the presence of the Internet of Things (IoT) is resource allocation. This happens because large numbers of nodes are simultaneously connected to networks, while the existing bandwidth is limited. Therefore, an efficient scheduling algorithm is needed. However, unfortunately, current research on network scheduling, especially 802.15.4e, is still constrained by simulator tools. Thus, this study proposes an open simulator platform for implementing network scheduling. This platform can be used by anyone who wishes to conduct a scheduling algorithm simulation. This platform is developed using PHP and javascript. In this study the researchers used the IR-TASA algorithm to test the performance of the proposed simulator. The results of testing from two variables-the number of active time slots and the number of iterations\/cycles-showed the same result, 100%, between network simulators and heuristic testing. \u00a9 2019 IEEE."
        ],
        "abstrak":[
            "One of the difficult challenge of the presence of the Internet of Things (IoT) is resource allocation. This happens because large numbers of nodes are simultaneously connected to networks, while the existing bandwidth is limited. Therefore, an efficient scheduling algorithm is needed. However, unfortunately, current research on network scheduling, especially 802.15.4e, is still constrained by simulator tools. Thus, this study proposes an open simulator platform for implementing network scheduling. This platform can be used by anyone who wishes to conduct a scheduling algorithm simulation. This platform is developed using PHP and javascript. In this study the researchers used the IR-TASA algorithm to test the performance of the proposed simulator. The results of testing from two variables-the number of active time slots and the number of iterations\/cycles-showed the same result, 100%, between network simulators and heuristic testing. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "SENTIMENT ANALYSIS of 'Indonesian NO DATING CAMPAIGNS' on TWITTER USING NA\u00cfVE BAYES ALGORITHM"
        ],
        "penulis":"Ardhianie, Nadia;Andreswari, Rachmadita;Hs, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The modern world has witnessed the widespread emergence of online social media. Many people use this kind of technology to share their view about anything. As consequence, it is easy to know public opinions on certain issue by utilizing social media data. One of trending issue in Indonesian Twitter user is about 'Indonesian No Dating Campaign. It is interesting to know effectiveness of that campaign by analyzing public sentiment. In order to analyze the campaign, this study employ sentiment analysis using Na\u00efve Bayes algorithm. This algorithm was chosen by considering its accuracy in several related studies. This research starts with data collection process, by crawling twitter's data that related to the campaign. The collected data will go through the data preprocessing, data classification based on its sentiment using Na\u00efve Bayes. As the result, Na\u00efve Bayes algorithm successfully classifies the twitter's data into 56% positive sentiment, negative sentiment 32% and neutral sentiment 12%. The accuracy of this classification is 74.77%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The modern world has witnessed the widespread emergence of online social media. Many people use this kind of technology to share their view about anything. As consequence, it is easy to know public opinions on certain issue by utilizing social media data. One of trending issue in Indonesian Twitter user is about 'Indonesian No Dating Campaign. It is interesting to know effectiveness of that campaign by analyzing public sentiment. In order to analyze the campaign, this study employ sentiment analysis using Na\u00efve Bayes algorithm. This algorithm was chosen by considering its accuracy in several related studies. This research starts with data collection process, by crawling twitter's data that related to the campaign. The collected data will go through the data preprocessing, data classification based on its sentiment using Na\u00efve Bayes. As the result, Na\u00efve Bayes algorithm successfully classifies the twitter's data into 56% positive sentiment, negative sentiment 32% and neutral sentiment 12%. The accuracy of this classification is 74.77%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "An electrical power control system for explorer-class remotely operated underwater vehicle (ROV)"
        ],
        "penulis":"Sani, Muhammad Ikhsan;Siregar, Simon;Kurnia, Muhammad Muchlis;Hasbialloh, Dzikri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The importance of an optimal method for electric power transmission is crucial for ROV operation. Meanwhile, only few studies have shown the effect of electrical power system from power supply to ROV.This paper proposes a design and implementation of electrical power system for ROV that developed by Tech_SAS team from Telkom University, Bandung, Indonesia. This work aims to obtain the optimal power system to supply ROV's electrical and electronic components. Tech_SAS ROV is developed to compete on 1st and 2nd ASEAN MATE Underwater Robotic Competition. The system has demonstrated that 48V electric voltage can be transmitted to ROV with negligible voltage drop when using 20 meter 12AWG cable. The voltage is converted to 12V using DC-DC converter in order to supply various ROV's electronic devices ROV safely and efficiently. Meanwhile, the microcontroller was used to as thrust control to manage current flow to DC motor. The system has been evaluated and demonstrates optimal results and provides a design consideration about ROV's power system especially on tether cable and power distribution scheme. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The importance of an optimal method for electric power transmission is crucial for ROV operation. Meanwhile, only few studies have shown the effect of electrical power system from power supply to ROV.This paper proposes a design and implementation of electrical power system for ROV that developed by Tech_SAS team from Telkom University, Bandung, Indonesia. This work aims to obtain the optimal power system to supply ROV's electrical and electronic components. Tech_SAS ROV is developed to compete on 1st and 2nd ASEAN MATE Underwater Robotic Competition. The system has demonstrated that 48V electric voltage can be transmitted to ROV with negligible voltage drop when using 20 meter 12AWG cable. The voltage is converted to 12V using DC-DC converter in order to supply various ROV's electronic devices ROV safely and efficiently. Meanwhile, the microcontroller was used to as thrust control to manage current flow to DC motor. The system has been evaluated and demonstrates optimal results and provides a design consideration about ROV's power system especially on tether cable and power distribution scheme. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Flatbuffers implementation on MQTT publish\/subscribe communication as data delivery format"
        ],
        "penulis":"Pradana, Muhammad Adna;Rakhmatsyah, Andrian;Wardana, Aulia Arif;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Communication between devices can be done in various ways, one of them is the Publish\/Subscribe model that uses the MQTT protocol From the shortcomings that exist in JSON, such as long processing time, Google recently introduced a new data format called Flatbuffers. Flatbuffers has a better data format serialization process than other data formats. This paper will discuss the implementation and testing of the Flatbuffers data format performance compared to other data formats through the MQTT Publish\/Subscribe communication model. Testing is done by measuring the value of payload, latency, and throughput obtained from each data format. The test results show that the Flatbuffers data format is very well used as a data extraction format based on data processing latency of 0.5002 ms and throughput 518.4649 bytes\/ms with payload 0.996108949 character\/byte. \u00a9 2019, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Communication between devices can be done in various ways, one of them is the Publish\/Subscribe model that uses the MQTT protocol From the shortcomings that exist in JSON, such as long processing time, Google recently introduced a new data format called Flatbuffers. Flatbuffers has a better data format serialization process than other data formats. This paper will discuss the implementation and testing of the Flatbuffers data format performance compared to other data formats through the MQTT Publish\/Subscribe communication model. Testing is done by measuring the value of payload, latency, and throughput obtained from each data format. The test results show that the Flatbuffers data format is very well used as a data extraction format based on data processing latency of 0.5002 ms and throughput 518.4649 bytes\/ms with payload 0.996108949 character\/byte. \u00a9 2019, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Platelets and hematocrit in the survival model of dengue hemorrhagic fever (Dhf) sufferers in palopo"
        ],
        "penulis":"Riska, Yanu Fa\u2019Rifah;Bobby, Poerwanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to apply cox regression analysis to predict the patient's survival to dengue disease occurring in Palopo. This study uses clinical data, namely the results of laboratory tests to determine the effect on the patient's healing period. Laboratory test results used are platelets and hematocrit. By using the maximum partial likelihood estimation (MPLE) method to obtain parameter estimates in the cox regression model, it is known that platelets have a stronger effect for patient resistance on dengue hemorrhagic fever (DHF) than hematocrit. This is based on the p-value obtained from the analysis less than alpha (0.05), which is equal to 0.0433. Patients who have an average platelet below normal when experiencing DHF are longer in their recovery period. In addition, patients with DHF \u2264 2 days, the probability to survive and recover is 90%. \u00a9 2019 Trans Tech Publications Ltd, Switzerland. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to apply cox regression analysis to predict the patient's survival to dengue disease occurring in Palopo. This study uses clinical data, namely the results of laboratory tests to determine the effect on the patient's healing period. Laboratory test results used are platelets and hematocrit. By using the maximum partial likelihood estimation (MPLE) method to obtain parameter estimates in the cox regression model, it is known that platelets have a stronger effect for patient resistance on dengue hemorrhagic fever (DHF) than hematocrit. This is based on the p-value obtained from the analysis less than alpha (0.05), which is equal to 0.0433. Patients who have an average platelet below normal when experiencing DHF are longer in their recovery period. In addition, patients with DHF \u2264 2 days, the probability to survive and recover is 90%. \u00a9 2019 Trans Tech Publications Ltd, Switzerland. All rights reserved."
        ]
    },
    {
        "judul":[
            "Water flow control system based on context aware algorithm and IoT for hydroponic"
        ],
        "penulis":"Gandhi, Otrinanda;Ramdhani, Mohamad;Murti, Muhammad Ary;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementing principal component analysis and multinomial logit for cancer detection based on microarray data classification"
        ],
        "penulis":"Khoirunnisa, Azka;Adiwijaya;Rohmawati, Aniq A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cancer is the second largest cause of death in the world; in 2018, a total of 9.6 million mortalities were recorder, due to cancer alone. It is important to detect this deadly disease early. In the medical field, there are many methods that can be used to detect cancer. One of these methods is microarray data technology. Microarray data reads thousands of gene expressions at the same time. However, this method has a major problem; data with high dimensions can affect classification performance and consume a lot of computational time. Therefore, this research used Principal Component Analysis as the dimensional reduction method. This method performed feature extraction based on a Principal Component (PC) obtained from the calculation of eigenvalues and eigenvectors. Moreover, the data reduction was implemented using a Multinomial Logit Classifier by modifying the parameters estimator using Maximum Likelihood Estimation. The cancer data used in this research consists of Colon Cancer, Leukemia, Lung Cancer, and Ovarian Cancer datasets. The test results for the Ovarian Cancer dataset gave an accuracy of 100% using a Proportion of Variance (PPV) of 90%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is the second largest cause of death in the world; in 2018, a total of 9.6 million mortalities were recorder, due to cancer alone. It is important to detect this deadly disease early. In the medical field, there are many methods that can be used to detect cancer. One of these methods is microarray data technology. Microarray data reads thousands of gene expressions at the same time. However, this method has a major problem; data with high dimensions can affect classification performance and consume a lot of computational time. Therefore, this research used Principal Component Analysis as the dimensional reduction method. This method performed feature extraction based on a Principal Component (PC) obtained from the calculation of eigenvalues and eigenvectors. Moreover, the data reduction was implemented using a Multinomial Logit Classifier by modifying the parameters estimator using Maximum Likelihood Estimation. The cancer data used in this research consists of Colon Cancer, Leukemia, Lung Cancer, and Ovarian Cancer datasets. The test results for the Ovarian Cancer dataset gave an accuracy of 100% using a Proportion of Variance (PPV) of 90%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "IoT: Smart garbage monitoring using android and real time database"
        ],
        "penulis":"Putra, Riyan Hadi;Kusuma, Feri Teja;Damayanti, Tri Nopiani;Ramadan, Dadan Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Every single day, garbage is always produced and sometimes, due to the unbalance between high volume produced and the garbage volume transported to the landfill; it then leads to the buildup. To prevent any negative impact on environment, a system is needed to support the waste management process. Smart Garbage Monitoring System consists of two parts: portable garbage can and monitoring application using android smartphone. The use of ultrasonic sensor, GPS and GSM Module on the garbage can aims to provide the data on the garbage and send it to the real time database, in which the data will be processed by the monitoring application on smartphone to determine the time of garbage transport purposely to prevent any buildup. The system doesn't need a server to process, because the entire process of will be run by android application on a smartphone. Test results showed the capability of the system in monitoring the garbage can with the minimum distance between the wastes by three meters. The information on the height level of garbage can be synchronized in real time to smartphone, with an average delay on the EDGE network of 4.57 seconds, HSPA+ of 4.52 seconds and LTE of 3.85 seconds. \u00a9 2019 Universitas Ahmad Dahlan.",
            "Sustainable Development Goals mapped to this documentResponsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Every single day, garbage is always produced and sometimes, due to the unbalance between high volume produced and the garbage volume transported to the landfill; it then leads to the buildup. To prevent any negative impact on environment, a system is needed to support the waste management process. Smart Garbage Monitoring System consists of two parts: portable garbage can and monitoring application using android smartphone. The use of ultrasonic sensor, GPS and GSM Module on the garbage can aims to provide the data on the garbage and send it to the real time database, in which the data will be processed by the monitoring application on smartphone to determine the time of garbage transport purposely to prevent any buildup. The system doesn't need a server to process, because the entire process of will be run by android application on a smartphone. Test results showed the capability of the system in monitoring the garbage can with the minimum distance between the wastes by three meters. The information on the height level of garbage can be synchronized in real time to smartphone, with an average delay on the EDGE network of 4.57 seconds, HSPA+ of 4.52 seconds and LTE of 3.85 seconds. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Multilayer X-Band Wave Absorber with Enhanced Absorption Bandwidth"
        ],
        "penulis":"Syihabuddin, Budi;Effendi, Mohammad Ridwan;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electromagnetics (EM) wave absorber implemented with common pattern structure such as rectangular and circular patches on a single-layer of dielectric substrate has deficiency in performance. The use of passive components incorporated into the structure was sometimes employed to overcome the issue of deficiency. This paper proposes wave absorber composed of multilayer dielectric substrates to enhance the absorption characteristic focused on its bandwidth performance. The proposed multilayer wave absorber is designed to work at the X-band frequency with an FR4 epoxy dielectric substrate applied for each layer. A multi-impedance concept of each layer which depends on its patch dimension is implemented to acquire the bandwidth improvement. The characteristic of proposed wave absorber is investigated through its unit cell with the dimension of 5.80 mm \u00d7 5.80 mm. The characterization result shows that the fractional bandwidth for the unit cell using square patch could increase up to 127% and 169% for the double-layer and the triple-layers, respectively, compared to the single-layer of dielectric substrate at the X-band frequency of 9.5 GHz. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electromagnetics (EM) wave absorber implemented with common pattern structure such as rectangular and circular patches on a single-layer of dielectric substrate has deficiency in performance. The use of passive components incorporated into the structure was sometimes employed to overcome the issue of deficiency. This paper proposes wave absorber composed of multilayer dielectric substrates to enhance the absorption characteristic focused on its bandwidth performance. The proposed multilayer wave absorber is designed to work at the X-band frequency with an FR4 epoxy dielectric substrate applied for each layer. A multi-impedance concept of each layer which depends on its patch dimension is implemented to acquire the bandwidth improvement. The characteristic of proposed wave absorber is investigated through its unit cell with the dimension of 5.80 mm \u00d7 5.80 mm. The characterization result shows that the fractional bandwidth for the unit cell using square patch could increase up to 127% and 169% for the double-layer and the triple-layers, respectively, compared to the single-layer of dielectric substrate at the X-band frequency of 9.5 GHz. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Designing Green Procurement System Based on Enterprise Resources Planning for the Rubber Processing Industry"
        ],
        "penulis":"Karlina, Octa;Ridwan, Ari Yanuar;Fajrillah, Asti Amalia Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The rubber processing industry is one of the manufacturing industries that pay attention to every activity on its production process that occurs during rubber processing. The work done in the production process at manufacturing, such as the rubber processing industry, produces waste that harms the environment. Therefore, it is necessary to monitor business activities. In this study focuses on designing application based on Enterprise Resource Planning (ERP) by running a green procurement system therein. Green procurement provides solutions to the selection of materials and services that can minimize the impact on the environment and provide benefits for the company. In implementing of green procurement system, ISO 14000 standardization data to determine the green supplier and the green material attributes data are needed to use for the Key Performance Indicator (KPI) report. The ERP-based application can generate report Key Performance Indicator (KPI) for green materials and green suppliers to help the company to monitor business processes in green procurement. However, the process of measuring the percentage of green materials and green suppliers is out of the scope of the discussion in this study, because this study only provides designing an application to implement green procurement. The selection of application based on Enterprise Resources Planning (ERP) is due to an ERP system that can add and also update data and information without duplication so that it can improve employee efficiency in monitoring business process activities with data integration in application based on Enterprise Resources Planning (ERP). The design of this application is tailored to the user requirements for green procurement that focus on the ability of the application system to provide purchase requisition, request for quotation, supplier selection, purchase order and integrating data such as payment of materials with the finance division, integrating data material that enters warehouse with the warehouse division. In addition, the aim of this study is to have an information system in monitoring business process activities carried out during the procurement process in the rubber processing industry using the Key Performance Indicator report, to assist in the management of procurement business processes using Enterprise Resource Planning (ERP) system. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The rubber processing industry is one of the manufacturing industries that pay attention to every activity on its production process that occurs during rubber processing. The work done in the production process at manufacturing, such as the rubber processing industry, produces waste that harms the environment. Therefore, it is necessary to monitor business activities. In this study focuses on designing application based on Enterprise Resource Planning (ERP) by running a green procurement system therein. Green procurement provides solutions to the selection of materials and services that can minimize the impact on the environment and provide benefits for the company. In implementing of green procurement system, ISO 14000 standardization data to determine the green supplier and the green material attributes data are needed to use for the Key Performance Indicator (KPI) report. The ERP-based application can generate report Key Performance Indicator (KPI) for green materials and green suppliers to help the company to monitor business processes in green procurement. However, the process of measuring the percentage of green materials and green suppliers is out of the scope of the discussion in this study, because this study only provides designing an application to implement green procurement. The selection of application based on Enterprise Resources Planning (ERP) is due to an ERP system that can add and also update data and information without duplication so that it can improve employee efficiency in monitoring business process activities with data integration in application based on Enterprise Resources Planning (ERP). The design of this application is tailored to the user requirements for green procurement that focus on the ability of the application system to provide purchase requisition, request for quotation, supplier selection, purchase order and integrating data such as payment of materials with the finance division, integrating data material that enters warehouse with the warehouse division. In addition, the aim of this study is to have an information system in monitoring business process activities carried out during the procurement process in the rubber processing industry using the Key Performance Indicator report, to assist in the management of procurement business processes using Enterprise Resource Planning (ERP) system. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Systematic Literature Review: Framework Design of Student Performance Monitoring System in Higher Education"
        ],
        "penulis":"Finata R.A.;Andrawina L.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In many organizations and institution particularly college, monitoring of students is a very important factor especially in identifying every problem that faced student in college. Various kinds of problems faced by the student can cause a high number of students to retake courses. Because of the alarming situation of the quality in higher education caused some measure has to be taken. In this paper will be focused on student monitoring framework design in higher education. Systematic literature review (SLR) used as a methodology in reviewing literature. This paper will be classified of each research on primary studies by object of research, indicators, variables, and methods. From the literature review results it is known that student monitoring framework design in higher education can be explored further by considering their assignment point and quiz at each class meeting with the aim to reduce number of students to retake courses especially in freshman students. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In many organizations and institution particularly college, monitoring of students is a very important factor especially in identifying every problem that faced student in college. Various kinds of problems faced by the student can cause a high number of students to retake courses. Because of the alarming situation of the quality in higher education caused some measure has to be taken. In this paper will be focused on student monitoring framework design in higher education. Systematic literature review (SLR) used as a methodology in reviewing literature. This paper will be classified of each research on primary studies by object of research, indicators, variables, and methods. From the literature review results it is known that student monitoring framework design in higher education can be explored further by considering their assignment point and quiz at each class meeting with the aim to reduce number of students to retake courses especially in freshman students. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Characteristics of two mesoscale convective systems (MCSs) over the Greater Jakarta: case of heavy rainfall period 15\u201318 January 2013"
        ],
        "penulis":"Nuryanto, Danang Eko;Pawitan, Hidayat;Hidayat, Rahmat;Aldrian, Edvin;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Two different mesoscale convective system (MCS) events that produced the heavy rainfall over the Greater Jakarta (GJ) during 15\u201318 January 2013 period were investigated. The purpose of the present study is to analyze the atmospheric conditions of two different MCSs during the heavy rainfall. Data consist of 3\u00a0hourly rainfalls of meteorological stations, infrared satellite, sounding, 6-hourly surface wind and reanalysis data. The first MCS was developed at 16:00 LT on 14 January 2013 over the eastern coast of Sumatra covered an area of 249,732\u00a0km2at maximum size, with about 16\u00a0h durations. The next MCS was developed at 22:00 LT on 16 January 2013 over the northern coast of the GJ in 9\u00a0h of duration, and maximum covered area around 55,829\u00a0km2. A warmer and moist air was observed on the low-level layer in the evening of 16 January 2013 (prior of second MCS), in comparison to 14 January 2013 event. Combination of both the surface strong wind perturbation and equivalent potential temperature in the second MCS might be contributed to heavy rainfall over the GJ than the first one. \u00a9 2019, The Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Two different mesoscale convective system (MCS) events that produced the heavy rainfall over the Greater Jakarta (GJ) during 15\u201318 January 2013 period were investigated. The purpose of the present study is to analyze the atmospheric conditions of two different MCSs during the heavy rainfall. Data consist of 3\u00a0hourly rainfalls of meteorological stations, infrared satellite, sounding, 6-hourly surface wind and reanalysis data. The first MCS was developed at 16:00 LT on 14 January 2013 over the eastern coast of Sumatra covered an area of 249,732\u00a0km2at maximum size, with about 16\u00a0h durations. The next MCS was developed at 22:00 LT on 16 January 2013 over the northern coast of the GJ in 9\u00a0h of duration, and maximum covered area around 55,829\u00a0km2. A warmer and moist air was observed on the low-level layer in the evening of 16 January 2013 (prior of second MCS), in comparison to 14 January 2013 event. Combination of both the surface strong wind perturbation and equivalent potential temperature in the second MCS might be contributed to heavy rainfall over the GJ than the first one. \u00a9 2019, The Author(s)."
        ]
    },
    {
        "judul":[
            "Detecting Hand, Foot and Mouth Disease in Earlier Stage Using C4.5 Algorithm as Expert System Based on Android"
        ],
        "penulis":"Syahrial, Farisa Hafida;Irawan, Budhi;Prasasti, Anggunmeka Luhur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hand, Foot and Mouth Disease (HFMD) is an infectious diseases caused by enterovirus virus 71 (EV 71). The symptoms of HFMD is similar to several other disease that caused by a virus, especially disease that have a fever and rash symptoms which people usually underestimate diseases that have early symptoms like that. Therefore, in this system we classify the HFMD with the intention of detecting the disease from an earlier stage. And we use Android based application since at this present time, smartphone is the closest device that is always used by many people. The classification used in this paper is Decision Tree C4.5 Algorithm. Dataset used in this research is as many as 256 which divided into training data and testing data, that formed based on symptoms that had previously been validated by the doctor. The result shows that data partitions of 90%:10%, 80%:20% and 70%:30% has accuracy, precision and recall value are 100%. Thus, data partition 70%:30% has the best result because this partition has less training data but can still classify diseases effectively. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hand, Foot and Mouth Disease (HFMD) is an infectious diseases caused by enterovirus virus 71 (EV 71). The symptoms of HFMD is similar to several other disease that caused by a virus, especially disease that have a fever and rash symptoms which people usually underestimate diseases that have early symptoms like that. Therefore, in this system we classify the HFMD with the intention of detecting the disease from an earlier stage. And we use Android based application since at this present time, smartphone is the closest device that is always used by many people. The classification used in this paper is Decision Tree C4.5 Algorithm. Dataset used in this research is as many as 256 which divided into training data and testing data, that formed based on symptoms that had previously been validated by the doctor. The result shows that data partitions of 90%:10%, 80%:20% and 70%:30% has accuracy, precision and recall value are 100%. Thus, data partition 70%:30% has the best result because this partition has less training data but can still classify diseases effectively. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Gap analysis of Indonesian state-owned bank internet banking website"
        ],
        "penulis":"Pradana, Mahir;Wahyuddin S.;Syarifuddin, Syarifuddin;Putra, Adrianza;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aimed to describe the level of quality perceived by internet banking customers of a state-owned bank in Indonesia. We use Website Quality (WebQual) theory for this research. By analyzing usability, information quality, and service interaction of the internet banking website, we then interpret the result with Gap Analysis method. With the participation of 100 respondents collected from all over Indonesia, we found that there are value gaps between the actual quality (performance) and ideal quality (importance). \u00a9 2019, IEOM Society International.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aimed to describe the level of quality perceived by internet banking customers of a state-owned bank in Indonesia. We use Website Quality (WebQual) theory for this research. By analyzing usability, information quality, and service interaction of the internet banking website, we then interpret the result with Gap Analysis method. With the participation of 100 respondents collected from all over Indonesia, we found that there are value gaps between the actual quality (performance) and ideal quality (importance). \u00a9 2019, IEOM Society International."
        ]
    },
    {
        "judul":[
            "SENTIMENT ANALYSIS of 'Indonesian NO DATING CAMPAIGNS' on TWITTER USING NA\u00cfVE BAYES ALGORITHM"
        ],
        "penulis":"Ardhianie, Nadia;Andreswari, Rachmadita;Hs, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The modern world has witnessed the widespread emergence of online social media. Many people use this kind of technology to share their view about anything. As consequence, it is easy to know public opinions on certain issue by utilizing social media data. One of trending issue in Indonesian Twitter user is about 'Indonesian No Dating Campaign. It is interesting to know effectiveness of that campaign by analyzing public sentiment. In order to analyze the campaign, this study employ sentiment analysis using Na\u00efve Bayes algorithm. This algorithm was chosen by considering its accuracy in several related studies. This research starts with data collection process, by crawling twitter's data that related to the campaign. The collected data will go through the data preprocessing, data classification based on its sentiment using Na\u00efve Bayes. As the result, Na\u00efve Bayes algorithm successfully classifies the twitter's data into 56% positive sentiment, negative sentiment 32% and neutral sentiment 12%. The accuracy of this classification is 74.77%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The modern world has witnessed the widespread emergence of online social media. Many people use this kind of technology to share their view about anything. As consequence, it is easy to know public opinions on certain issue by utilizing social media data. One of trending issue in Indonesian Twitter user is about 'Indonesian No Dating Campaign. It is interesting to know effectiveness of that campaign by analyzing public sentiment. In order to analyze the campaign, this study employ sentiment analysis using Na\u00efve Bayes algorithm. This algorithm was chosen by considering its accuracy in several related studies. This research starts with data collection process, by crawling twitter's data that related to the campaign. The collected data will go through the data preprocessing, data classification based on its sentiment using Na\u00efve Bayes. As the result, Na\u00efve Bayes algorithm successfully classifies the twitter's data into 56% positive sentiment, negative sentiment 32% and neutral sentiment 12%. The accuracy of this classification is 74.77%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Management maintenance system for remote control based on microcontroller and virtual private serve"
        ],
        "penulis":"Kamil, Idham;Julham;Lubis, Muharman;Lubis, Arif Ridho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Open loop shaped control system is a form of system control without any feedback from the system. One example is the on-off condition which functions to connect and disconnect electricity. The condition to be studied is a dc motor that can be set to live and die via internet server-based client service. The server in this system is a virtual private server (VPS) device that will provide a source of service to the client in the form of a collection of information on dc motor conditions. In addition, its function is also to record the working time of the dc motor. So that a schedule can be determined when the dc motor is maintained. While the client is a control unit consisting of a microcontroller device, an ethernet module enc28j60 and a dc motor. In general the working principle of the system is beginning with the user accessing the desired VPS IP address through a web browser application. From the web browser the user chooses a dc motor to be activated. But before the client has been connected to the VPS regularly (every second), the point is to always get the latest dc motor condition information. Then the microcontroller will set the dc motor in active or off condition. The research method used is research and development. The results obtained from this study are that the amount of bandwidth needed for communication between VPS and microcontrollers via the internet network, when the control unit works is 6.02 kbps, while the response time for dc motor is 3.16 seconds and the response time for dc motor 2 is 3.46 seconds. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "CH3OHH3CCH3OHHHView detailsExpand Substance 17-methyltestosterone",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Open loop shaped control system is a form of system control without any feedback from the system. One example is the on-off condition which functions to connect and disconnect electricity. The condition to be studied is a dc motor that can be set to live and die via internet server-based client service. The server in this system is a virtual private server (VPS) device that will provide a source of service to the client in the form of a collection of information on dc motor conditions. In addition, its function is also to record the working time of the dc motor. So that a schedule can be determined when the dc motor is maintained. While the client is a control unit consisting of a microcontroller device, an ethernet module enc28j60 and a dc motor. In general the working principle of the system is beginning with the user accessing the desired VPS IP address through a web browser application. From the web browser the user chooses a dc motor to be activated. But before the client has been connected to the VPS regularly (every second), the point is to always get the latest dc motor condition information. Then the microcontroller will set the dc motor in active or off condition. The research method used is research and development. The results obtained from this study are that the amount of bandwidth needed for communication between VPS and microcontrollers via the internet network, when the control unit works is 6.02 kbps, while the response time for dc motor is 3.16 seconds and the response time for dc motor 2 is 3.46 seconds. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Indonesian abstractive text summarization using bidirectional gated recurrent unit"
        ],
        "penulis":"Adelia, Rike;Suyanto, Suyanto;Wisesty, Untari Novia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "ive text summarization is more challenging than the extractive one since it is performed by paraphrasing the entire contents of the text, which has a higher difficulty. But, it produces a more natural summary and higher inter-sentence cohesion. Recurrent Neural Network (RNN) has experienced success in summarizing abstractive texts for English and Chinese texts. The Bidirectional Gated Recurrent Unit (BiGRU) RNN architecture is used so that the resulted summaries are influenced by the surrounding words. In this research, such a method is applied for Bahasa Indonesia to improve the text summarizations those are commonly developed using some extractive methods with low inter-sentence cohesion. An evaluation on a dataset of Indonesian journal documents shows that the proposed model is capable of summarizing the overall contents of testing documents into some summaries with high similarities to the provided abstracts. The proposed model resulting success in understanding source text for generating summarization. \u00a9 2019 The Authors. Published by Elsevier B.V.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "ive text summarization is more challenging than the extractive one since it is performed by paraphrasing the entire contents of the text, which has a higher difficulty. But, it produces a more natural summary and higher inter-sentence cohesion. Recurrent Neural Network (RNN) has experienced success in summarizing abstractive texts for English and Chinese texts. The Bidirectional Gated Recurrent Unit (BiGRU) RNN architecture is used so that the resulted summaries are influenced by the surrounding words. In this research, such a method is applied for Bahasa Indonesia to improve the text summarizations those are commonly developed using some extractive methods with low inter-sentence cohesion. An evaluation on a dataset of Indonesian journal documents shows that the proposed model is capable of summarizing the overall contents of testing documents into some summaries with high similarities to the provided abstracts. The proposed model resulting success in understanding source text for generating summarization. \u00a9 2019 The Authors. Published by Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Knowledge management practices and innovation performance: A study at Indonesian Government apparatus research and training center"
        ],
        "penulis":"Susanty, Ade Irma;Yuningsih, Yuyu;Anggadwita, Grisna;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose: This paper aims to concentrate on the conscious and systematic managerial activities associated with handling knowledge in an organization [i.e. knowledge management (KM) practices] for the purpose of improving innovation performance through proactive management of knowledge assets. This study explores the impact of KM practices on innovation performance in the research and training center of government apparatus. Design\/methodology\/approach: This research provides empirical evidence on how various KM practices influence innovation performance. The results are based on the survey data collected in four areas of research and training centers of government apparatuses in Indonesia. Partial least squares are used to test the hypothesized relationships between KM practices and innovation performance. Findings: The study found that IT practices and work organizations are positively and significantly related to innovation performance. This means that better implementation of information and technology will push innovation performance. The study also points out that knowledge-based compensation practice is one of the KM practice variables which is negatively and significantly related to innovation performance. This result shows that innovation performance will decrease by compensating knowledge improvement. Practical implications: This study implies that in developing innovation performance, the research and training center should not focus on providing compensation, as it will only increase the costs rather than the innovation performance itself. Originality\/value: This study adds a knowledge-based view of government agencies by demonstrating the significance of KM for innovation performance. This study is also valuable from a managerial perspective, as it highlights the most effective KM practice to improve organizational innovation performance. \u00a9 2018, Emerald Publishing Limited.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: This paper aims to concentrate on the conscious and systematic managerial activities associated with handling knowledge in an organization [i.e. knowledge management (KM) practices] for the purpose of improving innovation performance through proactive management of knowledge assets. This study explores the impact of KM practices on innovation performance in the research and training center of government apparatus. Design\/methodology\/approach: This research provides empirical evidence on how various KM practices influence innovation performance. The results are based on the survey data collected in four areas of research and training centers of government apparatuses in Indonesia. Partial least squares are used to test the hypothesized relationships between KM practices and innovation performance. Findings: The study found that IT practices and work organizations are positively and significantly related to innovation performance. This means that better implementation of information and technology will push innovation performance. The study also points out that knowledge-based compensation practice is one of the KM practice variables which is negatively and significantly related to innovation performance. This result shows that innovation performance will decrease by compensating knowledge improvement. Practical implications: This study implies that in developing innovation performance, the research and training center should not focus on providing compensation, as it will only increase the costs rather than the innovation performance itself. Originality\/value: This study adds a knowledge-based view of government agencies by demonstrating the significance of KM for innovation performance. This study is also valuable from a managerial perspective, as it highlights the most effective KM practice to improve organizational innovation performance. \u00a9 2018, Emerald Publishing Limited."
        ]
    },
    {
        "judul":[
            "Business process analysis of academic information system application using process mining (case study: Final project module)"
        ],
        "penulis":"Fitriansah, Ilham Akbar;Andreswari, Rachmadita;Hasibuan, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of information technology is currently influencing the organization; one of them is Telkom University. Online-Based information technology at Telkom University, namely the Integrated Academic Information System (I-Gracias). I-Gracias is an Academic Information System owned by Telkom University that provides services both academically and non-academically. One of the menus in i-Gracias is the TA \/ PA application; this menu intends for students who will take the bachelor degree final project and will carry out the bachelor degree final project. Based on the current procedure, the service standards for the TA \/ PA I-Gracias application provided do not have specific service time limits. There are differences in service for each user in the TA \/ PA application activity. Therefore, to find out the actual operations in this application, a modeling process is needed to find out the activities that have the longest time. Identification of the modeling process is made by using the process mining approach and utilizing the I-Gracias log event. The modeling process uses the Heuristic Miner modeling technique aimed at modeling the process and finding the best fitness value. The heuristic miner algorithm is chosen because of its ability to handle event logs with noise and can display primary behavior from existing business processes. After getting the modeling, then analyzing the bottleneck for the procedure. Based on the conformance checking results, the best fitness value is 0.98492914, the precision value is 0.7015873, and the structure value is 1. Modeling in performance analysis shows that there are bottlenecks in the activity of uploading proposals and completeness of print trial activities. Bottleneck shows the problem related to the bachelor degree final project guidance application. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of information technology is currently influencing the organization; one of them is Telkom University. Online-Based information technology at Telkom University, namely the Integrated Academic Information System (I-Gracias). I-Gracias is an Academic Information System owned by Telkom University that provides services both academically and non-academically. One of the menus in i-Gracias is the TA \/ PA application; this menu intends for students who will take the bachelor degree final project and will carry out the bachelor degree final project. Based on the current procedure, the service standards for the TA \/ PA I-Gracias application provided do not have specific service time limits. There are differences in service for each user in the TA \/ PA application activity. Therefore, to find out the actual operations in this application, a modeling process is needed to find out the activities that have the longest time. Identification of the modeling process is made by using the process mining approach and utilizing the I-Gracias log event. The modeling process uses the Heuristic Miner modeling technique aimed at modeling the process and finding the best fitness value. The heuristic miner algorithm is chosen because of its ability to handle event logs with noise and can display primary behavior from existing business processes. After getting the modeling, then analyzing the bottleneck for the procedure. Based on the conformance checking results, the best fitness value is 0.98492914, the precision value is 0.7015873, and the structure value is 1. Modeling in performance analysis shows that there are bottlenecks in the activity of uploading proposals and completeness of print trial activities. Bottleneck shows the problem related to the bachelor degree final project guidance application. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Enhancing the performance of smote algorithm by using attribute weighting scheme and new selective sampling method for imbalanced data set"
        ],
        "penulis":"Fahrudin, Tora;Buliali, Joko Lianto;Fatichah, Chastine;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "SMOTE is one of the well-known algorithms for balancing train data by adding synthetic data on minor class data. One of the stages in SMOTE is finding the nearest neighbors (kNN) as the basis for creating synthetic data using Euclidean dis- tance. In cases where a small number of attributes having high correlation value than others, finding kNN using Euclidean without considering this correlation may not find representative neighbors. This paper introduces AWH-SMOTE (Attribute Weighted and kNN Hub on SMOTE), which enhances SMOTE in improving neighbors and noise identification using attribute weighting and also improving selective sampling method using occurrence data in the kNN hub. Wojna and Information Gain methods are used for attribute weighting. A small number of occurrences in the kNN hub results in more syn- thetic data generated so that minority data in dangerous region are more represented. Nine public datasets from Keel repository are used to evaluate AWH-SMOTE. Evaluation shows AWH-SMOTE has better performance on minority precision and minority f-measure for both pruned and unpruned condition than other oversampling algorithms. Information Gain as attribute weighting method in AWH-SMOTE achieves best perfor- mance in unpruned condition when compared to other weighting methods for minority recall, minority precision and minority f-measure. \u00a9 2019 ICIC International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SMOTE is one of the well-known algorithms for balancing train data by adding synthetic data on minor class data. One of the stages in SMOTE is finding the nearest neighbors (kNN) as the basis for creating synthetic data using Euclidean dis- tance. In cases where a small number of attributes having high correlation value than others, finding kNN using Euclidean without considering this correlation may not find representative neighbors. This paper introduces AWH-SMOTE (Attribute Weighted and kNN Hub on SMOTE), which enhances SMOTE in improving neighbors and noise identification using attribute weighting and also improving selective sampling method using occurrence data in the kNN hub. Wojna and Information Gain methods are used for attribute weighting. A small number of occurrences in the kNN hub results in more syn- thetic data generated so that minority data in dangerous region are more represented. Nine public datasets from Keel repository are used to evaluate AWH-SMOTE. Evaluation shows AWH-SMOTE has better performance on minority precision and minority f-measure for both pruned and unpruned condition than other oversampling algorithms. Information Gain as attribute weighting method in AWH-SMOTE achieves best perfor- mance in unpruned condition when compared to other weighting methods for minority recall, minority precision and minority f-measure. \u00a9 2019 ICIC International."
        ]
    },
    {
        "judul":[
            "The Study of Baby Crying Analysis Using MFCC and LFCC in Different Classification Methods"
        ],
        "penulis":"Dewi, Sita Purnama;Prasasti, Anggunmeka Luhur;Irawan, Budhi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nowadays, there are so many researches about the baby crying detection for many purposes. The right interpretation of the crying baby is notable for the medical objective so caregiver knows how to treat baby well. Babies within the first three months of age use Dustan Baby Language (DBL) to communicate. Based on some researches, there are five words to express their needs, such as \"Neh\" (I am hungry), \"Eh\" (burp is needed), \"Owh\/Oah\" (fatigue), \"Eair\/Eargghh\" (cramps), \"Heh\" (physical discomfort; feel hot or wet). Beside that purpose, smart home technology implements baby crying detection for monitoring the baby. Several stages to detect crying baby are preprocessing, feature extraction, and classification. Popular feature extractions for voice or sound recognition are Mel Frequency Cepstral Coefficient (MFCC) and Linear Frequency Cepstral Coefficient (LFCC). In this study, both of that feature extraction have been analyzed to know the appropriate condition when using one of those feature extractions. Classification methods (KNN classification, Vector Quantization, and Simple Neural Network) affect the accuracy in detecting and recognizing of baby crying. KNN classification with LFCC results better accuracy than using MFCC one with the sample data is female voice. If using baby voice, there is no significant different accuracy in both of feature extractions. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, there are so many researches about the baby crying detection for many purposes. The right interpretation of the crying baby is notable for the medical objective so caregiver knows how to treat baby well. Babies within the first three months of age use Dustan Baby Language (DBL) to communicate. Based on some researches, there are five words to express their needs, such as \"Neh\" (I am hungry), \"Eh\" (burp is needed), \"Owh\/Oah\" (fatigue), \"Eair\/Eargghh\" (cramps), \"Heh\" (physical discomfort; feel hot or wet). Beside that purpose, smart home technology implements baby crying detection for monitoring the baby. Several stages to detect crying baby are preprocessing, feature extraction, and classification. Popular feature extractions for voice or sound recognition are Mel Frequency Cepstral Coefficient (MFCC) and Linear Frequency Cepstral Coefficient (LFCC). In this study, both of that feature extraction have been analyzed to know the appropriate condition when using one of those feature extractions. Classification methods (KNN classification, Vector Quantization, and Simple Neural Network) affect the accuracy in detecting and recognizing of baby crying. KNN classification with LFCC results better accuracy than using MFCC one with the sample data is female voice. If using baby voice, there is no significant different accuracy in both of feature extractions. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The design and impact of the pedagogical agent: A systematic literature review"
        ],
        "penulis":"Martha, Ati Suci Dian;Santoso, Harry B.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A pedagogical agent is an anthropomorphic virtual character used in an online learning environment to serve instructional purposes. The design of pedagogical agents changes over time depending on the desired objectives for them. This article is a systematic review of the research from 2007 to 2017 related to the design factors of pedagogical agents and their impact on learning environments. The objective of this review is to identify and analyze pedagogical agents through the context in which they are constructed, the independent variables used in pedagogical agent research, and the impact of the pedagogical agent implementation. The review found that research on the design of pedagogical agents has different forms, namely text, voice, 2-D character, 3-D character, and human. The independent variables used in the studies are categorized into the appearance of agents and the role of agents. Moreover, the combination of pedagogical agent designs and role designs of pedagogical agents has significant positive impacts on student learning and student behavior. Recommendations are also provided at the end of this review. \u00a9 2019, Grand Canyon University. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A pedagogical agent is an anthropomorphic virtual character used in an online learning environment to serve instructional purposes. The design of pedagogical agents changes over time depending on the desired objectives for them. This article is a systematic review of the research from 2007 to 2017 related to the design factors of pedagogical agents and their impact on learning environments. The objective of this review is to identify and analyze pedagogical agents through the context in which they are constructed, the independent variables used in pedagogical agent research, and the impact of the pedagogical agent implementation. The review found that research on the design of pedagogical agents has different forms, namely text, voice, 2-D character, 3-D character, and human. The independent variables used in the studies are categorized into the appearance of agents and the role of agents. Moreover, the combination of pedagogical agent designs and role designs of pedagogical agents has significant positive impacts on student learning and student behavior. Recommendations are also provided at the end of this review. \u00a9 2019, Grand Canyon University. All rights reserved."
        ]
    },
    {
        "judul":[
            "Increasing Passive RFID-Based Smart Shopping Cart Performance using Decision Tree"
        ],
        "penulis":"Yusuf, Khalid;Abdurohman, Maman;Putrada, Aji Gautama;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes the smart shopping cart based on passive RFID. While on peak season market, queues are often found at clothing store. This happens because the service time between consumers takes a long time; the cashier must scan all items one by one, and make the transaction process at the cashier slow. In proposed system, each item be equipped with an RFID tag, and the shopping cart be equipped with an RFID reader, so the items that are inserted into the shopping cart will be scanned and calculated in the system. This system makes the service time shorter and minimize the number of queues at the cashier. To support the performance of smart shopping cart, a decision tree algorithm is implemented for classifying consumer shopping lists and determine discounts. The author tests and analyzes the performance of the decision tree ID3 algorithm in the smart shopping cart. The test results show that decision tree algorithms can determine discounts with a 90% accuracy rate and 100% precision rate.  \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes the smart shopping cart based on passive RFID. While on peak season market, queues are often found at clothing store. This happens because the service time between consumers takes a long time; the cashier must scan all items one by one, and make the transaction process at the cashier slow. In proposed system, each item be equipped with an RFID tag, and the shopping cart be equipped with an RFID reader, so the items that are inserted into the shopping cart will be scanned and calculated in the system. This system makes the service time shorter and minimize the number of queues at the cashier. To support the performance of smart shopping cart, a decision tree algorithm is implemented for classifying consumer shopping lists and determine discounts. The author tests and analyzes the performance of the decision tree ID3 algorithm in the smart shopping cart. The test results show that decision tree algorithms can determine discounts with a 90% accuracy rate and 100% precision rate.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Performance analysis of RAW impact on IEEE 802.11ah standard affected by Doppler Effect"
        ],
        "penulis":"Marwan, Abdul Aziz;Perdana, Doan;Sanjoyo, Danu Dwi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Internet of Things (IOT) offers a new dimension of technology and information where connectivity is available anywhere, anytime, and for any purpose. IEEE 802.11 Wireless Local Area Network group is a standard that developed to answer the needs of wireless communication technology (WI-Fi). Recently, IEEE 802.11 working group released the 802.11ah technology or Wi-Fi HaLow as a Wi-fi standard. This standard works on the 1 GHz frequency band with a broader coverage area, massive device and the energy efficiency issues. This research addresses, the influence of Doppler Effect using Random Waypoint mobility model on 802.11ah with different RAW slot and RAW slot duration are analyzed. The design of the simulation system is done by changing RAW slot and RAW slot duration. Based on the result, it can be concluded that the overall performance of the network with all of the parameter scenarios is decreasing along with the increasing RAW slot, RAW slot duration, and fluctuation. In the RAW slot = 5 scenario with v = 10 km\/h has the worst performance with an average delay which is about 0.128225 s, and average throughput is about 0.284337 Mbps while for RAW slot = 1 with an average PDR which is about 99.1076 %. While in the RAW slot duration = 0.020 s scenario with v = 10 km\/h has the worst performance with an average delay which is about 0.135581 s, average throughput is about 0.286828 Mbps, and average PDR which is about 99.3165 %. \u00a9 2019 CC BY-NC.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet of Things (IOT) offers a new dimension of technology and information where connectivity is available anywhere, anytime, and for any purpose. IEEE 802.11 Wireless Local Area Network group is a standard that developed to answer the needs of wireless communication technology (WI-Fi). Recently, IEEE 802.11 working group released the 802.11ah technology or Wi-Fi HaLow as a Wi-fi standard. This standard works on the 1 GHz frequency band with a broader coverage area, massive device and the energy efficiency issues. This research addresses, the influence of Doppler Effect using Random Waypoint mobility model on 802.11ah with different RAW slot and RAW slot duration are analyzed. The design of the simulation system is done by changing RAW slot and RAW slot duration. Based on the result, it can be concluded that the overall performance of the network with all of the parameter scenarios is decreasing along with the increasing RAW slot, RAW slot duration, and fluctuation. In the RAW slot = 5 scenario with v = 10 km\/h has the worst performance with an average delay which is about 0.128225 s, and average throughput is about 0.284337 Mbps while for RAW slot = 1 with an average PDR which is about 99.1076 %. While in the RAW slot duration = 0.020 s scenario with v = 10 km\/h has the worst performance with an average delay which is about 0.135581 s, average throughput is about 0.286828 Mbps, and average PDR which is about 99.3165 %. \u00a9 2019 CC BY-NC."
        ]
    },
    {
        "judul":[
            "Floating robot control system for monitoring water quality levels in citarum river"
        ],
        "penulis":"Pratama, Reza Putra;Rusdinar, Angga;Wibawa, Ig. Prasetya Dwi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Water is the primary need of every living thing, with the availability of water for living things, it is very helpful for daily needs. Especially river water in Indonesia has been heavily polluted, the pollution can come from industrial, household, agricultural and fishery waste. Therefore, the purpose of this research is to make a robotic solution to monitor river water quality regularly and can be monitored in real-time. The results obtained from this test are spherical robots and for fuzzy logic controller systems use 5 membership functions for yaw parameters with a sensor reading angle limit value [-90\u00b0, 90\u00b0]. For the pitch parameter, there are 3 membership functions with the limitation of sensor reading angle value [-32\u00b0, 32\u00b0]. There is a moving average as a filter to process the reading value of the gyroscope with a sample value of 10 times the reading because the response is following the actual reading and minimal noise. Dispatch of robot control commands can be sent and received in real-time. Haversine Formula calculation results have an accuracy of 92.67076% compared to the calculation of the distance from google maps. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentClean water and sanitationGoal 6",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Water is the primary need of every living thing, with the availability of water for living things, it is very helpful for daily needs. Especially river water in Indonesia has been heavily polluted, the pollution can come from industrial, household, agricultural and fishery waste. Therefore, the purpose of this research is to make a robotic solution to monitor river water quality regularly and can be monitored in real-time. The results obtained from this test are spherical robots and for fuzzy logic controller systems use 5 membership functions for yaw parameters with a sensor reading angle limit value [-90\u00b0, 90\u00b0]. For the pitch parameter, there are 3 membership functions with the limitation of sensor reading angle value [-32\u00b0, 32\u00b0]. There is a moving average as a filter to process the reading value of the gyroscope with a sample value of 10 times the reading because the response is following the actual reading and minimal noise. Dispatch of robot control commands can be sent and received in real-time. Haversine Formula calculation results have an accuracy of 92.67076% compared to the calculation of the distance from google maps. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A multilabel classification on topics of qur'anic verses in English translation using K-Nearest Neighbor method with Weighted TF-IDF"
        ],
        "penulis":"Ulumudin G.I.;Adiwijaya A.;Mubarok M.S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "There are so many information contained in the Qur'an, it will be difficult to bring up the information manually, moreover if someone wants to know more about the Qur'an. Therefore, there is a need to find information with a certain topic that already classified in the Qur'an, especially in one verse of the Qur'an may have more than one topic (multilabel). This research examined how to build classifier to classify multilabel data which is topics of Qur'anic verses with k-Nearest Neighbor method. In this research, there is a comparison between feature extraction, Weighted TF-IDF and TF-IDF. The result of that comparison is that Weigthed TF-IDF has better performance compared to normal TF-IDF. The highest result by finding the most optimal k score is k=25 with the average score of hamming loss = 0.134875. There will be a test to measure the effect of stopword removal and lemmatization with optimal k value, for a case without stopword removal, the result is 0.136375, whereas without the lemmatization the result is 0.13537. For not using stopword removal and lemmatization the average hamming loss is 0.1373125. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "There are so many information contained in the Qur'an, it will be difficult to bring up the information manually, moreover if someone wants to know more about the Qur'an. Therefore, there is a need to find information with a certain topic that already classified in the Qur'an, especially in one verse of the Qur'an may have more than one topic (multilabel). This research examined how to build classifier to classify multilabel data which is topics of Qur'anic verses with k-Nearest Neighbor method. In this research, there is a comparison between feature extraction, Weighted TF-IDF and TF-IDF. The result of that comparison is that Weigthed TF-IDF has better performance compared to normal TF-IDF. The highest result by finding the most optimal k score is k=25 with the average score of hamming loss = 0.134875. There will be a test to measure the effect of stopword removal and lemmatization with optimal k value, for a case without stopword removal, the result is 0.136375, whereas without the lemmatization the result is 0.13537. For not using stopword removal and lemmatization the average hamming loss is 0.1373125. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Design and Implementation of Smart Advertisement Display Board Prototype"
        ],
        "penulis":"Murtadho, Fauzi;Sudiharto, Dodi Wisaksono;Wijiutomo, Catur Wirawan;Ariyanto, Endro;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Habitually, the traditional advertisement display exhibits no feature which informs the user intention. The owner just predicts the advertisement effectiveness based on the product selling or the visitors. Therefore, there is a requirement related to a signage which demonstrates an ability to detect user attention and enables to record it instantly. Early detection according to user fascination to the advertisement display is not only for gathering data but also for providing feedback to the user about its detail. For example, if there are advertisement presents which are a bag, a hat, and jewelry. Those presents are still the random pattern. Since the target user fascinates to one of the advertisements, such as a hat, then the system is going to exhibit only the hat and anything related to the hat. The frames recorded are going to be processed to find the face and eyes features for potential intention marking. The potential intention defined then is sensed by counting the appearance rate to define the intention more accurately. The success rate of the proposed system is 68.57% for identifying user intention. In addition, the proposed system also performs the ability to collect data related to the advertisement which the most popular. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Habitually, the traditional advertisement display exhibits no feature which informs the user intention. The owner just predicts the advertisement effectiveness based on the product selling or the visitors. Therefore, there is a requirement related to a signage which demonstrates an ability to detect user attention and enables to record it instantly. Early detection according to user fascination to the advertisement display is not only for gathering data but also for providing feedback to the user about its detail. For example, if there are advertisement presents which are a bag, a hat, and jewelry. Those presents are still the random pattern. Since the target user fascinates to one of the advertisements, such as a hat, then the system is going to exhibit only the hat and anything related to the hat. The frames recorded are going to be processed to find the face and eyes features for potential intention marking. The potential intention defined then is sensed by counting the appearance rate to define the intention more accurately. The success rate of the proposed system is 68.57% for identifying user intention. In addition, the proposed system also performs the ability to collect data related to the advertisement which the most popular. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Cluster model study of the Indonesian defense industry towards encouraging industry independence"
        ],
        "penulis":"Hartati, Sri;Muhamad, Ade;Firmialy, Sita Deliyana;Tasrif, Muhamad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of this research is to find out how the defense industry and stakeholders are involved in developing defense industry clusters via comparative qualitative research methods. The results of the research show that the defense industry sector has 4 cluster stages. In conclusion, in the medium term, increasing industrial competitiveness is carried out by building and developing priority industry clusters while in the long run, it is more focused on integrating cluster approaches with efforts to manage demand (management demand) and build core competencies in each cluster. \u00a9 2019, Universidad del Zulia. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this research is to find out how the defense industry and stakeholders are involved in developing defense industry clusters via comparative qualitative research methods. The results of the research show that the defense industry sector has 4 cluster stages. In conclusion, in the medium term, increasing industrial competitiveness is carried out by building and developing priority industry clusters while in the long run, it is more focused on integrating cluster approaches with efforts to manage demand (management demand) and build core competencies in each cluster. \u00a9 2019, Universidad del Zulia. All rights reserved."
        ]
    },
    {
        "judul":[
            "A multi-label classification on topics of quranic verses (english translation) using backpropagation neural network with stochastic gradient descent and adam optimizer"
        ],
        "penulis":"Huda, Nanang Saiful;Mubarok, Mohamad Syahrul;Adiwijaya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The Quran is a guideline for all Muslims. In the Quran, many things are talked about. In Quranic studies, the Quran is first classified into several topics according to the discussions of the Quranic verses. In this research, a classification model using a Back Propagation Neural Network was built based on the verses of Al-Quran and its multi-labelled topics. This allows the Back Propagation algorithm architecture to issue labels for each class in the form of 'yes' or 'no' for each output neuron. When using the Back Propagation algorithm, a sentence input that has become a vector is taken. In this way, TF-IDF will be used for feature extraction. Then, the model was evaluated via calculation of Hamming Loss. To ensure an optimal Back Propagation process, a comparison was made between the Stochastic Gradient Descent (SGD) and Adam optimizers. Based on some experiments, the proposed scheme yielded the best performance with a Hamming Loss value of 0.129. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Quran is a guideline for all Muslims. In the Quran, many things are talked about. In Quranic studies, the Quran is first classified into several topics according to the discussions of the Quranic verses. In this research, a classification model using a Back Propagation Neural Network was built based on the verses of Al-Quran and its multi-labelled topics. This allows the Back Propagation algorithm architecture to issue labels for each class in the form of 'yes' or 'no' for each output neuron. When using the Back Propagation algorithm, a sentence input that has become a vector is taken. In this way, TF-IDF will be used for feature extraction. Then, the model was evaluated via calculation of Hamming Loss. To ensure an optimal Back Propagation process, a comparison was made between the Stochastic Gradient Descent (SGD) and Adam optimizers. Based on some experiments, the proposed scheme yielded the best performance with a Hamming Loss value of 0.129. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Business process analysis and academic information system audit of helpdesk application using genetic algorithms a process mining approach"
        ],
        "penulis":"Dzihni, Astrid Shofi;Andreswari, Rachmadita;Hasibuan, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of making an Academic Information System is to support the process of academic activities effectively and efficiently. Telkom University is an institution that already has an Academic Information System called Integrated Academic Information System or I-Gracias. I-Gracias uses a single sign-on system which means one user for all applications. The Helpdesk application is one application that supports this institution. The Helpdesk application has 4 categories of complaints, namely Serial Number License, Website \/ Subdomain, Academic I-Gracias, and Non-Academic I-Gracias. With the various complaints categories in the Helpdesk application, Helpdesk application actually promises time with the same service standards, its 3 days for a maximum by filling in the same format in each category. The time is considered not enough to describe the process of handling the services of the Helpdesk application. Therefore, to find out the student activities in the Helpdesk application, a modeling process is carried out to find activities that have the longest time. To find out the time of each activity by the user, an audit process is to find out activities that have the longest time by the process mining approach to obtain modeling. Identification of the modeling process using process mining approach by utilizing the event log on i-Gracias. This modeling process uses a genetic algorithm because it is considered capable of making business process modeling accurately. After obtaining a process model, an audit is carried out by analyzing the bottleneck for each activity. The results show that the resulting process model is good with fitness values, precision and structure are 0.9994142, 0.7653061 and 1 respectively. Modeling in performance analysis shows the bottleneck in two activities, Input Ticket and See Ticket Progress. Bottlenecks show that business processes in the Helpdesk application has problems in resolving complaints through academic information systems. \u00a9 2019 The Authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of making an Academic Information System is to support the process of academic activities effectively and efficiently. Telkom University is an institution that already has an Academic Information System called Integrated Academic Information System or I-Gracias. I-Gracias uses a single sign-on system which means one user for all applications. The Helpdesk application is one application that supports this institution. The Helpdesk application has 4 categories of complaints, namely Serial Number License, Website \/ Subdomain, Academic I-Gracias, and Non-Academic I-Gracias. With the various complaints categories in the Helpdesk application, Helpdesk application actually promises time with the same service standards, its 3 days for a maximum by filling in the same format in each category. The time is considered not enough to describe the process of handling the services of the Helpdesk application. Therefore, to find out the student activities in the Helpdesk application, a modeling process is carried out to find activities that have the longest time. To find out the time of each activity by the user, an audit process is to find out activities that have the longest time by the process mining approach to obtain modeling. Identification of the modeling process using process mining approach by utilizing the event log on i-Gracias. This modeling process uses a genetic algorithm because it is considered capable of making business process modeling accurately. After obtaining a process model, an audit is carried out by analyzing the bottleneck for each activity. The results show that the resulting process model is good with fitness values, precision and structure are 0.9994142, 0.7653061 and 1 respectively. Modeling in performance analysis shows the bottleneck in two activities, Input Ticket and See Ticket Progress. Bottlenecks show that business processes in the Helpdesk application has problems in resolving complaints through academic information systems. \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Detection of Children's Personality with Fingerprint Using K-Nearest Neighbor (Knn) and Decision Tree Methods"
        ],
        "penulis":"Haniffah, Ziqra;Dirgantoro, Burhanuddin;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Now in many parts of the world technology has been developed that is able to identify individuals from individual biological characters known as Biometrics. Biometrics itself is a way of identifying and verifying individuals based on their physical characteristics or behavior. So fingerprints are an option to detect a child's personality. The desire of parents to print their children into superior seeds is getting bigger. Questions about how to maximize talent, potential, and children from the start often haunt the minds of today's parents. Realizing the importance of this, psychologists continue to perfect tests to analyze children's intelligence and personality.With the occurrence of these problems, this study will design a system that can read fingerprints with the results knowing the child's personality and Learning style. This system is designed by using the Gray Level Co-Occurance (GLCM) feature extraction and is classified by the K-Nearest Neighbor (KNN) Method and Decision Tree which can go through a data or a fact that moves forward to a conclusion.In this research, the two classification methods have different accuracy, KNN has an accuracy of 85% and 89% Decision Tree has more accuracy than KNN because it uses a decision tree.  \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Now in many parts of the world technology has been developed that is able to identify individuals from individual biological characters known as Biometrics. Biometrics itself is a way of identifying and verifying individuals based on their physical characteristics or behavior. So fingerprints are an option to detect a child's personality. The desire of parents to print their children into superior seeds is getting bigger. Questions about how to maximize talent, potential, and children from the start often haunt the minds of today's parents. Realizing the importance of this, psychologists continue to perfect tests to analyze children's intelligence and personality.With the occurrence of these problems, this study will design a system that can read fingerprints with the results knowing the child's personality and Learning style. This system is designed by using the Gray Level Co-Occurance (GLCM) feature extraction and is classified by the K-Nearest Neighbor (KNN) Method and Decision Tree which can go through a data or a fact that moves forward to a conclusion.In this research, the two classification methods have different accuracy, KNN has an accuracy of 85% and 89% Decision Tree has more accuracy than KNN because it uses a decision tree.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Why do enterprises adopt natural language processing services? startups' landscape and opportunities in artificial intelligence"
        ],
        "penulis":"Ruliputra, Ricky Nauvaldy;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The large number of internet users in Indonesia contributes to Indonesia's growth potential in general in the digital economy. This rapid growth urged the government to plan for the industrial 4.0 revolution with artificial intelligence (AI) technology as its basis. Innovations in the field of AI come from many startup companies. Despite many benefits, only 40 percent companies in Asia-Pacific utilized the AI technology in functional areas, such as chatbot services and customer service robots. This gap needs to be addressed considering that more than 87 percent of internet users in Indonesia utilize chat services and social media. AI utilization can be implemented by using the services of companies engaged in AI, including startups. However, AI-based startups in Indonesia are not yet mapped. Furthermore, practical impact of AI implementation needs to be surveyed as knowledge to implement AI in business. This research mapped 68 Indonesian startups of AI service providers. In addition, this study evaluates the implementation of AI in the Natural Language Processing (NLP) category for companies from the perspective of the service provider. Of all 8 mapped NLP service providers, 4 of them are chosen as the research objects. The impacts of its implementation are categorized into eight categories: motivation, profit, interest, change in strategy, competition, satisfaction, trust, and ethics. Recommendations are given to companies related to NLP with the most important things which are defining purposes and dare to try. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The large number of internet users in Indonesia contributes to Indonesia's growth potential in general in the digital economy. This rapid growth urged the government to plan for the industrial 4.0 revolution with artificial intelligence (AI) technology as its basis. Innovations in the field of AI come from many startup companies. Despite many benefits, only 40 percent companies in Asia-Pacific utilized the AI technology in functional areas, such as chatbot services and customer service robots. This gap needs to be addressed considering that more than 87 percent of internet users in Indonesia utilize chat services and social media. AI utilization can be implemented by using the services of companies engaged in AI, including startups. However, AI-based startups in Indonesia are not yet mapped. Furthermore, practical impact of AI implementation needs to be surveyed as knowledge to implement AI in business. This research mapped 68 Indonesian startups of AI service providers. In addition, this study evaluates the implementation of AI in the Natural Language Processing (NLP) category for companies from the perspective of the service provider. Of all 8 mapped NLP service providers, 4 of them are chosen as the research objects. The impacts of its implementation are categorized into eight categories: motivation, profit, interest, change in strategy, competition, satisfaction, trust, and ethics. Recommendations are given to companies related to NLP with the most important things which are defining purposes and dare to try. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Ina-BWR: Indonesian bigram word rule for multi-label student complaints"
        ],
        "penulis":"Fahrudin, Tora;Buliali, Joko Lianto;Fatichah, Chastine;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Handling multi-label student complaints is one of interesting research topics. One of techniques used for handling multi-label student complaints is Bag of Word (BoW) method. In this research bigram word rule and preprocess are proposed to increase the accuracy of multi-label classification results. To show the effectiveness of the proposed method, data from Telkom University student data and additional relevant data by using hashtag are used as testing data. We develop Indonesian Bigram Word Rule for Multi-label Student Complaints (Ina-BWR) to identify multi-label student problems based on Bigram Word Rule. Ina-BWR consists of three processes such as preprocessing informal text, identifying complaint and object from text. Additional preprocessing techniques are conducted to formalize the text such as parsing a hashtag, correcting affixes word, correcting a conjunction word, parsing suffix people pronoun and correcting typo words. Indonesian bigram word rule is adopted from opinion identification rules with 3 additional corpuses (-)NN, (-)JJ and (-)VB to identify student complaints. To identify complaints, four label corpuses have been created manually. The experimental results show that Ina-BWR can increase Personal, Subject and Relation label accuracies. The best accuracy for four labels is obtained when Ina-BWR is combined with BoW method. \u00a9 2019",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Handling multi-label student complaints is one of interesting research topics. One of techniques used for handling multi-label student complaints is Bag of Word (BoW) method. In this research bigram word rule and preprocess are proposed to increase the accuracy of multi-label classification results. To show the effectiveness of the proposed method, data from Telkom University student data and additional relevant data by using hashtag are used as testing data. We develop Indonesian Bigram Word Rule for Multi-label Student Complaints (Ina-BWR) to identify multi-label student problems based on Bigram Word Rule. Ina-BWR consists of three processes such as preprocessing informal text, identifying complaint and object from text. Additional preprocessing techniques are conducted to formalize the text such as parsing a hashtag, correcting affixes word, correcting a conjunction word, parsing suffix people pronoun and correcting typo words. Indonesian bigram word rule is adopted from opinion identification rules with 3 additional corpuses (-)NN, (-)JJ and (-)VB to identify student complaints. To identify complaints, four label corpuses have been created manually. The experimental results show that Ina-BWR can increase Personal, Subject and Relation label accuracies. The best accuracy for four labels is obtained when Ina-BWR is combined with BoW method. \u00a9 2019"
        ]
    },
    {
        "judul":[
            "A survey of licensed assisted access implementation in Indonesia"
        ],
        "penulis":"Saputra, Mukhammad Ajie;Nashiruddin, Muhammad Imam;Adriansyah, Nachwan Mufti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nowadays, users of cellular are increasing rapidly, proven by an internet network that is accessed mostly through mobile broadband usage. Wireless mobile broadband technology uses limited resources, namely the frequency spectrum. It is an interesting problem because the frequency spectrum regulates by government, so the allocation is restricted. Not requiring a longer time, the licensed frequency for mobile broadband is becoming increasingly full and facing a problem, namely spectrum scarcity. 3GPP saw this opportunity by launching LTE-Advanced Pro (4.9 G) technology through 3GPP Release-13, namely Licensed Assisted Access (LAA). LAA uses carrier aggregation technology between the licensed band and unlicensed band of 5 GHz. The 5 GHz frequency allocation is for ISM needs. LAA aims to increase network capacity, increase efficiency, and increase downlink speed. Several countries in the world already deploy LAA. However, many countries are still doing a trial of LAA technology, including Indonesia. Indonesia represents one of the largest countries in the world, and the number of a mobile broadband user is one of the largest with the rapid growth of mobile user. Thus LAA deployment in Indonesia is required to face spectrum scarcity. This work is intended to examine the technology and the regulation and market readiness of LAA implementation, especially in Indonesia. In this paper, we do study briefly about LAA implementation in several countries based on their frequency regulation requirement, market, and how the technical challenge goes on. Thus LAA implementation in Indonesia could be considered based on existing conditions above. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, users of cellular are increasing rapidly, proven by an internet network that is accessed mostly through mobile broadband usage. Wireless mobile broadband technology uses limited resources, namely the frequency spectrum. It is an interesting problem because the frequency spectrum regulates by government, so the allocation is restricted. Not requiring a longer time, the licensed frequency for mobile broadband is becoming increasingly full and facing a problem, namely spectrum scarcity. 3GPP saw this opportunity by launching LTE-Advanced Pro (4.9 G) technology through 3GPP Release-13, namely Licensed Assisted Access (LAA). LAA uses carrier aggregation technology between the licensed band and unlicensed band of 5 GHz. The 5 GHz frequency allocation is for ISM needs. LAA aims to increase network capacity, increase efficiency, and increase downlink speed. Several countries in the world already deploy LAA. However, many countries are still doing a trial of LAA technology, including Indonesia. Indonesia represents one of the largest countries in the world, and the number of a mobile broadband user is one of the largest with the rapid growth of mobile user. Thus LAA deployment in Indonesia is required to face spectrum scarcity. This work is intended to examine the technology and the regulation and market readiness of LAA implementation, especially in Indonesia. In this paper, we do study briefly about LAA implementation in several countries based on their frequency regulation requirement, market, and how the technical challenge goes on. Thus LAA implementation in Indonesia could be considered based on existing conditions above. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Adaptation of indigenous community agricultural systems on climate change (case study of Kasepuhan Ciptagelar, Sukabumi Regency, West Java)"
        ],
        "penulis":"Hapsari H.;Hapsari D.;Karyani T.;Fatimah S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Climate change is a threat to indigenous farming systems that rely on nature. Indigenous society has idiosyncrasies in managing agricultural systems that relate to nature. This study aims to examine the adaptation mechanism of indigenous farming systems to climate change in terms of social, economic, and technological aspects. The study was conducted in Indigenous Village of Kasepuhan Ciptagelar of Sukabumi Regency West Java. The research method is case study. The technique of collecting data through in-depth interviews with selected informants, participant observation, and focus group discussion (FGD). The results showed that the indigenous society of Kasepuhan Ciptagelar experienced the changes that occur in the environment as a result of climate change. Strategies to adapt to these changes, among others: (1) use natural resources in a sustainable manner, (2) preserve the customary positive impact on the environment, (3) do a crop rotation system, (4) managing the communal granary community food security system, (5) maintaining social values in the society, (6) establish cooperation with the agricultural institutions; (7) utilizing communication networks and information systems; (8) with some help from external parties in the repair of facilities and infrastructure, such as transportation and irrigation; (9) perform the processing of non-rice farming profit-oriented, and (10) instilling the values of local wisdom to the younger generation from an early age. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentZero hungerGoal 2Decent work and economic growthGoal 8Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Climate change is a threat to indigenous farming systems that rely on nature. Indigenous society has idiosyncrasies in managing agricultural systems that relate to nature. This study aims to examine the adaptation mechanism of indigenous farming systems to climate change in terms of social, economic, and technological aspects. The study was conducted in Indigenous Village of Kasepuhan Ciptagelar of Sukabumi Regency West Java. The research method is case study. The technique of collecting data through in-depth interviews with selected informants, participant observation, and focus group discussion (FGD). The results showed that the indigenous society of Kasepuhan Ciptagelar experienced the changes that occur in the environment as a result of climate change. Strategies to adapt to these changes, among others: (1) use natural resources in a sustainable manner, (2) preserve the customary positive impact on the environment, (3) do a crop rotation system, (4) managing the communal granary community food security system, (5) maintaining social values in the society, (6) establish cooperation with the agricultural institutions; (7) utilizing communication networks and information systems; (8) with some help from external parties in the repair of facilities and infrastructure, such as transportation and irrigation; (9) perform the processing of non-rice farming profit-oriented, and (10) instilling the values of local wisdom to the younger generation from an early age. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "A review of edge image detection for marker-based augmented reality"
        ],
        "penulis":"Pandiangan, Samuel P.A.H.;Purboyo, Tito Waluyo;Saputra, Randy Erfa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The earlier way to do an image detecting is to use edge image detection. Edge image detection is using some kind of mathematical expression to detect the boundaries between objects between images in real world, with media like camera phone. Many aspects have used edge image detection, one of them is Augmented Reality, especially marker-based Augmented Reality. Augmented reality used edge image detection for reading and detecting the marker in real world and transfer the data to the database in application. This paper will review how the edge detection works and how it works in Augmented Reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The earlier way to do an image detecting is to use edge image detection. Edge image detection is using some kind of mathematical expression to detect the boundaries between objects between images in real world, with media like camera phone. Many aspects have used edge image detection, one of them is Augmented Reality, especially marker-based Augmented Reality. Augmented reality used edge image detection for reading and detecting the marker in real world and transfer the data to the database in application. This paper will review how the edge detection works and how it works in Augmented Reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Implementation of python source code comparison results with Java using bubble sort method"
        ],
        "penulis":"Insanudin E.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the implementation of Python and Java source code comparison results are more focused on the scale of the ratio of the number of lines of code, file capacity, and access speed. As for the background of this writing because there are so many programming languages that can be used with the same results but overall we do not know which programming language is more optimal and efficient in terms of the number of lines of code better known in the programming language is LOC (Line of Code) capacity of file access speed. In this study, the authors focus only on Java programming language and python course as a first step to know the ratio of the number of lines of code, file capacity, and access density. To determine the comparison there is a method used is bubble short. The results of the implementation of the comparison of these programming languages for Python programming language to produce the number of LOC (line of code) or the number of lines of code as much as 10, the capacity of the file extension.py by 506 bytes and txt extension of 397 bytes and access speed approximately for less more 4 seconds. While Java produces the number of LOC (line of code) or the number of lines of code as much as 11, the capacity of the file extension. Java of 86.2 Kbytes and extension txt of 477 bytes and access speed for 7 seconds. So do not close the possibility to make other applications python programming language will be more optimal and efficient. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the implementation of Python and Java source code comparison results are more focused on the scale of the ratio of the number of lines of code, file capacity, and access speed. As for the background of this writing because there are so many programming languages that can be used with the same results but overall we do not know which programming language is more optimal and efficient in terms of the number of lines of code better known in the programming language is LOC (Line of Code) capacity of file access speed. In this study, the authors focus only on Java programming language and python course as a first step to know the ratio of the number of lines of code, file capacity, and access density. To determine the comparison there is a method used is bubble short. The results of the implementation of the comparison of these programming languages for Python programming language to produce the number of LOC (line of code) or the number of lines of code as much as 10, the capacity of the file extension.py by 506 bytes and txt extension of 397 bytes and access speed approximately for less more 4 seconds. While Java produces the number of LOC (line of code) or the number of lines of code as much as 11, the capacity of the file extension. Java of 86.2 Kbytes and extension txt of 477 bytes and access speed for 7 seconds. So do not close the possibility to make other applications python programming language will be more optimal and efficient. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "First evidence of the presence of genotype-1 of Japanese encephalitis virus in Culex gelidus in Indonesia"
        ],
        "penulis":"Garjito, Triwibowo Ambar;Prihatin, Mega Tyas;Susanti, Lulus;Prastowo, Dhian;Sa'Adah, Siti Rofiatus;Taviv, Yulian;Satoto, Tri Baskoro Tunggul;Waluyo, Joko;Manguin, Sylvie;Frutos, Roger;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Background: Japanese encephalitis has become a public health threat in Indonesia. Three genotypes have been recorded in Indonesia, i.e. genotype II (GII), genotype III (GIII) and genotype IV (GIV). Genotype I (GI) and genotype V (GV) have never been reported in Indonesia. Results: A Japanese encephalitis virus (JEV) belonging to the genotype I-a (GI-a) has been isolated for the first time from a Culex gelidus mosquito in the Province of Jambi, Indonesia. This virus is related to a 1983 isolate from Thailand whereas the infected Cx. gelidus mosquito belonged to a Chinese haplotype. Conclusions: Surveillance of JEV and mosquito dissemination is recommended. \u00a9 2019 The Author(s).",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Background: Japanese encephalitis has become a public health threat in Indonesia. Three genotypes have been recorded in Indonesia, i.e. genotype II (GII), genotype III (GIII) and genotype IV (GIV). Genotype I (GI) and genotype V (GV) have never been reported in Indonesia. Results: A Japanese encephalitis virus (JEV) belonging to the genotype I-a (GI-a) has been isolated for the first time from a Culex gelidus mosquito in the Province of Jambi, Indonesia. This virus is related to a 1983 isolate from Thailand whereas the infected Cx. gelidus mosquito belonged to a Chinese haplotype. Conclusions: Surveillance of JEV and mosquito dissemination is recommended. \u00a9 2019 The Author(s)."
        ]
    },
    {
        "judul":[
            "Noise Removal in Mild Cognitive Impairment EEG Recording using Empirical Mode Decomposition"
        ],
        "penulis":"Hadiyoso, Sugondo;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "EEG signals contain large amounts of random noise, such as artifacts and baseline changes. These noises appear at low frequencies, which may disturb the real activity of the EEG signal. Visual observation method often used to mark then removing the noise. However, this conventional method takes much time, requires experts to do the annotation, and has a huge possibility of error. One method that can be used to remove this interference is Empirical Mode Decomposition (EMD). EMD produces two essential parts of the signal, namely intrinsic mode function (IMF) and residue. This study applies EMD to remove artifacts that are present in EEG signals. The performance measured by calculating the RMSE and spectral power. From the test, obtained the average value of RMSE 0.0295 and signal power at frequencies below 1 Hz is 0.004 dB. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "EEG signals contain large amounts of random noise, such as artifacts and baseline changes. These noises appear at low frequencies, which may disturb the real activity of the EEG signal. Visual observation method often used to mark then removing the noise. However, this conventional method takes much time, requires experts to do the annotation, and has a huge possibility of error. One method that can be used to remove this interference is Empirical Mode Decomposition (EMD). EMD produces two essential parts of the signal, namely intrinsic mode function (IMF) and residue. This study applies EMD to remove artifacts that are present in EEG signals. The performance measured by calculating the RMSE and spectral power. From the test, obtained the average value of RMSE 0.0295 and signal power at frequencies below 1 Hz is 0.004 dB. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Room Map Estimation from Two-Dimensional Lidar's Point Cloud Data"
        ],
        "penulis":"Satyawan, Arief Suryadi;Kurniawan, Dayat;Armi, Nasrullah;Wijayanto, Yusuf Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "An automatic digital map estimation is not only essential for the repository of the architectural plans but also crucial for providing clear paths for a trajectory finder system, an autonomous vehicle, or a robot. Therefore, it is useful for reconstructing heritage buildings or finding a location lying in ruin after an earthquake. Rebuilding a digital map of a room can be done by using information from two-dimensional (2D) images. However, it seems to be complicated to obtain an accurate dimension directly from those images. One potential breakthrough is to make use of light detecting and ranging (LIDAR) technology. This state-of-the-art device can detect the solid surface of an object, as well as presenting an easiness of the distance measurements. This research focused on the reconstruction of a room map by utilizing 2D point cloud data obtained from a Lidar device. The results showed that by applying the conditioned random sample consensus (RANSAC) method, the 2D map of a room could be identified accurately from the 2D point cloud data. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An automatic digital map estimation is not only essential for the repository of the architectural plans but also crucial for providing clear paths for a trajectory finder system, an autonomous vehicle, or a robot. Therefore, it is useful for reconstructing heritage buildings or finding a location lying in ruin after an earthquake. Rebuilding a digital map of a room can be done by using information from two-dimensional (2D) images. However, it seems to be complicated to obtain an accurate dimension directly from those images. One potential breakthrough is to make use of light detecting and ranging (LIDAR) technology. This state-of-the-art device can detect the solid surface of an object, as well as presenting an easiness of the distance measurements. This research focused on the reconstruction of a room map by utilizing 2D point cloud data obtained from a Lidar device. The results showed that by applying the conditioned random sample consensus (RANSAC) method, the 2D map of a room could be identified accurately from the 2D point cloud data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Engaging customer experience in accelerating transformational performance through co-creation strategy"
        ],
        "penulis":"Alamsjah, Firdaus;Mihardjo, Leonardus W Wasono;Djoemadic, Faizal R.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Disruptive innovation shifts strategy from competition to collaboration. The collaboration with customers is also known as co-creation strategy and predominantly drives transformational performance. Transformational performance is based on performance management theory and transformation paradigms. However, its development to ensure the works of co-creation strategy, based on customer experience, remains unclear. To address this gap the digital transformational model based on co-creation strategy, with a focus on customer experience, was investigated to accelerate transformational performance. This study uses quantitative research, with a sample of 35 representatives from telecommunication firms. The findings demonstrate that co-creation strategy significantly supports customer experience, in driving transformational performance. Customer experience also appears to significantly impact co-creation strategy indirectly. The findings have theoretical implications for the emergence of collaboration strategy in the disruptive era. They show practitioners how co-creation strategy is becoming key in sustaining the business, as it shifts the focus onto the development of customer experience to drive transformational performance. Suggestions for future research are also included in the study. \u00a9 2019 Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Disruptive innovation shifts strategy from competition to collaboration. The collaboration with customers is also known as co-creation strategy and predominantly drives transformational performance. Transformational performance is based on performance management theory and transformation paradigms. However, its development to ensure the works of co-creation strategy, based on customer experience, remains unclear. To address this gap the digital transformational model based on co-creation strategy, with a focus on customer experience, was investigated to accelerate transformational performance. This study uses quantitative research, with a sample of 35 representatives from telecommunication firms. The findings demonstrate that co-creation strategy significantly supports customer experience, in driving transformational performance. Customer experience also appears to significantly impact co-creation strategy indirectly. The findings have theoretical implications for the emergence of collaboration strategy in the disruptive era. They show practitioners how co-creation strategy is becoming key in sustaining the business, as it shifts the focus onto the development of customer experience to drive transformational performance. Suggestions for future research are also included in the study. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Radar Software Development for the Surveillance of Indonesian Aerospace Sovereignty"
        ],
        "penulis":"Saputera, Yussi Perdana;Sulistyaningsih;Wahab, Mashury;Estu, Topik Teguh;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, design and development of air surveillance radar software using QT creator application is presented. The software manufacture was performed in two stages, where the first stage is to design a flowchart and the second stage is to create the program using codes. Radar software must be integrated with hardware to display the results of the target detection. All detection results will be shown on the plan position indicator (PPI) display. From the detection results, all flying objects that can reflect radar signals will be shown in the display, i.e., airplanes, clouds, birds, mountains, tall buildings, as long as they are still in the radar detection range. The radar software has been tested with very significant good results. To only see moving objects such as high-speed aircrafts, moving target indicator (MTI) feature is enabled. The radar software was shown to be able to track objects and to create guard zones feature as an observation area. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, design and development of air surveillance radar software using QT creator application is presented. The software manufacture was performed in two stages, where the first stage is to design a flowchart and the second stage is to create the program using codes. Radar software must be integrated with hardware to display the results of the target detection. All detection results will be shown on the plan position indicator (PPI) display. From the detection results, all flying objects that can reflect radar signals will be shown in the display, i.e., airplanes, clouds, birds, mountains, tall buildings, as long as they are still in the radar detection range. The radar software has been tested with very significant good results. To only see moving objects such as high-speed aircrafts, moving target indicator (MTI) feature is enabled. The radar software was shown to be able to track objects and to create guard zones feature as an observation area. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Classification of premature ventricular contraction based on ECG signal using multiorder r\u00e9nyi entropy"
        ],
        "penulis":"Rizal, Achmad;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electrocardiogram (ECG) signals are commonly used to analyze the heart abnormalities. Many researchers used this method due to the simplicity, inexpensive, and the non-invasiveness of the devices. The basic concept of ECG is by measuring the electrical activity of the heart using non-invasive electrodes placed in the body. Premature ventricular contraction (PVC) is one of the abnormalities of the human heart which produce extra heartbeat that started in the two lower ventricles. This 'additional' heartbeat disrupts the regular heart rhythm. Early detection for PVC is essential, so in this research, we classify the PVC from ECG signal by using multi-order R\u00e9nyi entropy as the feature extraction, and SVM as the classifier. We search for the optimum feature number needed for the detection system. Our proposed method showed a promising result, because we only use one feature extraction parameter, that is R\u00e9nyi entropy, as the only feature which calculated in the different orders, and this made the computing complexity low. We got 95.8% of accuracy using six characteristics of entropy for PVC and normal ECG classification. Our proposed method was simple, low computation and need fewer number of features. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electrocardiogram (ECG) signals are commonly used to analyze the heart abnormalities. Many researchers used this method due to the simplicity, inexpensive, and the non-invasiveness of the devices. The basic concept of ECG is by measuring the electrical activity of the heart using non-invasive electrodes placed in the body. Premature ventricular contraction (PVC) is one of the abnormalities of the human heart which produce extra heartbeat that started in the two lower ventricles. This 'additional' heartbeat disrupts the regular heart rhythm. Early detection for PVC is essential, so in this research, we classify the PVC from ECG signal by using multi-order R\u00e9nyi entropy as the feature extraction, and SVM as the classifier. We search for the optimum feature number needed for the detection system. Our proposed method showed a promising result, because we only use one feature extraction parameter, that is R\u00e9nyi entropy, as the only feature which calculated in the different orders, and this made the computing complexity low. We got 95.8% of accuracy using six characteristics of entropy for PVC and normal ECG classification. Our proposed method was simple, low computation and need fewer number of features. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Facial recognition technique with combination method of local binary pattern histogram and image euclidean distance"
        ],
        "penulis":"Erwin;Saparudin;Fachrurrozi M.;Tamaarsa, Alvin;Zhang, Andy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to determine the level of precision, recall, and accuracy of performance of local binary pattern histogram and image euclidean distance for face image recognition. This research uses local binary pattern histogram method for segmenting face image and euclidean distance image for face image recognition. The proposed method started with the process of converting pixel value into a binary value, which then the value is used as a decimal value and the histogram is calculated, for then saved in the database. The trained facial image histogram will be compared with the histogram of the test data using the euclidean distance image formula. The result of this research shows realtime test result get 0.699 recall value and 0.7 precision value. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to determine the level of precision, recall, and accuracy of performance of local binary pattern histogram and image euclidean distance for face image recognition. This research uses local binary pattern histogram method for segmenting face image and euclidean distance image for face image recognition. The proposed method started with the process of converting pixel value into a binary value, which then the value is used as a decimal value and the histogram is calculated, for then saved in the database. The trained facial image histogram will be compared with the histogram of the test data using the euclidean distance image formula. The result of this research shows realtime test result get 0.699 recall value and 0.7 precision value. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Face recognition system Using Deep Neural Network with Convolutional Neural Networks"
        ],
        "penulis":"Fernando, Erick;Andwiyan, Denny;Fitria Murad, Dina;Touriano, Derist;Irsan, Muhamad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Face recognition has long been a hot topic and challenging research point in areas such as image processing, pattern recognition, and machine vision. The face is a biometric feature with the intrinsic nature of a human. So that the face has self-stability, deep individual differences and can be an ideal basis for verification of an identity. In this research use, Deep Learning Network method uses to perform detection or face recognition. In this study, we present a framework that can be used to detect faces. This research is also able to present a DNN model that is used to study data sources from the data stream in sequence. The most important part of this study is able to adjust the capacity of the model from the simple one. This research uses experimental design method. The first step is a collection of face image data. Then the architecture design starts from the determination of the depth of the network, layout layers, and the selection of layer types that will be used to get the model based on input dataset and label name index. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Face recognition has long been a hot topic and challenging research point in areas such as image processing, pattern recognition, and machine vision. The face is a biometric feature with the intrinsic nature of a human. So that the face has self-stability, deep individual differences and can be an ideal basis for verification of an identity. In this research use, Deep Learning Network method uses to perform detection or face recognition. In this study, we present a framework that can be used to detect faces. This research is also able to present a DNN model that is used to study data sources from the data stream in sequence. The most important part of this study is able to adjust the capacity of the model from the simple one. This research uses experimental design method. The first step is a collection of face image data. Then the architecture design starts from the determination of the depth of the network, layout layers, and the selection of layer types that will be used to get the model based on input dataset and label name index. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Computing UDCHR scheme for simulating underwater sediment movement using OpenMP"
        ],
        "penulis":"Lobma, Fadhil;Gunawan P.H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Parallel computing with OpenMP platform in numerical simulation of underwater sediment movement is elaborated. The result shown computer I with processor type Intel Core i7-7500U has better speedup performance (3.291493 times of serial computing) than Computer II with processor type AMD Ryzen 5 2400G. Meanwhile, using computer II, the speedup of parallel computing is obtained 3.751561 times of serial computing. Indeed this discrepancy occurs because of the processor type of Computer I is higher than Computer II. Moreover, the efficiency of Computer II is 11.5% lower than computer II which is conducted 91.1367% efficiency. This means using Computer II the ability of parallel codes to achieve best performance proportional to the number of processor is obtained. Furthermore, the numerical simulation using UDCHR is shown in a good agreement with the staggered grid scheme of two-layer SWE and SWE-Exner model. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Parallel computing with OpenMP platform in numerical simulation of underwater sediment movement is elaborated. The result shown computer I with processor type Intel Core i7-7500U has better speedup performance (3.291493 times of serial computing) than Computer II with processor type AMD Ryzen 5 2400G. Meanwhile, using computer II, the speedup of parallel computing is obtained 3.751561 times of serial computing. Indeed this discrepancy occurs because of the processor type of Computer I is higher than Computer II. Moreover, the efficiency of Computer II is 11.5% lower than computer II which is conducted 91.1367% efficiency. This means using Computer II the ability of parallel codes to achieve best performance proportional to the number of processor is obtained. Furthermore, the numerical simulation using UDCHR is shown in a good agreement with the staggered grid scheme of two-layer SWE and SWE-Exner model. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Flowshop Scheduling with Drum-Buffer-Rope and CDS Algorithm to Minimize Lateness and Work in Process at PT. AKS"
        ],
        "penulis":"Viady A.S.;Suryadhini P.P.;Rendra M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In many years, the problem of lateness remains a problem for companies. This problem also occurs in textile company. At PT. AKS, one of the textile company, the lateness causes by bottleneck on one of their work station, which is Split Workstation, and the other caused by large unit load. The objective of this research is to minimize lateness by reducing the bottleneck and unit load. This research purposed a Drum-Buffer-Rope method and CDS algorithm to solve the problem. The constraint work station which is Split Workstation as the drum which is the control point of the whole system. The rope systematic which is backward scheduling applied at work stations before Split Workstation to minimize the queue time and to control the work in process. CDS Algorithm used in the interest of jobs sequencing to be processes after Split Workstation by using a forward scheduling. To solve the large unit load, we determine the unit load by trial and error. The result of this research manufacturing lead time decrease is by 61.88 percent from the current condition, queue time decrease is by 82.45 percent from current condition and the lateness decrease is by 35.71 percent from current condition. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In many years, the problem of lateness remains a problem for companies. This problem also occurs in textile company. At PT. AKS, one of the textile company, the lateness causes by bottleneck on one of their work station, which is Split Workstation, and the other caused by large unit load. The objective of this research is to minimize lateness by reducing the bottleneck and unit load. This research purposed a Drum-Buffer-Rope method and CDS algorithm to solve the problem. The constraint work station which is Split Workstation as the drum which is the control point of the whole system. The rope systematic which is backward scheduling applied at work stations before Split Workstation to minimize the queue time and to control the work in process. CDS Algorithm used in the interest of jobs sequencing to be processes after Split Workstation by using a forward scheduling. To solve the large unit load, we determine the unit load by trial and error. The result of this research manufacturing lead time decrease is by 61.88 percent from the current condition, queue time decrease is by 82.45 percent from current condition and the lateness decrease is by 35.71 percent from current condition. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Analysis of Project Integration on Smart Parking System in Telkom University"
        ],
        "penulis":"Lubis, Muharman;Fauzi, Rahmat;Lubis, Arif Ridho;Fauzi, Rokhman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The parking process is common attempt to eliminate traffic in the road by providing certain spot for vehicle to stay for certain time. Considering the increase of amount of population, large parking area horizontally or vertically is not necessary proper solution because it requires enormous expenses to acquire vacant land or to construct high-rise building. Therefore, smart parking system is one solution to provide information on the availability of vacant parking locations efficiently and conduct identification and transaction process quickly. Telkom University has been adopted this system by using physical card with RFID built-in for handling, convenience and security purposes since October 2014. Even though, it deliver an easy way for verification and validation but some problem occurred that raise several complaints from student and staff. This study has objective to explore the challenges and to addresses the issues faced by smart parking system, which has been implemented in subsequent years. By identifying the solution, it can improve the quality of the system for greater purpose in the future. \u00a9 2018 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The parking process is common attempt to eliminate traffic in the road by providing certain spot for vehicle to stay for certain time. Considering the increase of amount of population, large parking area horizontally or vertically is not necessary proper solution because it requires enormous expenses to acquire vacant land or to construct high-rise building. Therefore, smart parking system is one solution to provide information on the availability of vacant parking locations efficiently and conduct identification and transaction process quickly. Telkom University has been adopted this system by using physical card with RFID built-in for handling, convenience and security purposes since October 2014. Even though, it deliver an easy way for verification and validation but some problem occurred that raise several complaints from student and staff. This study has objective to explore the challenges and to addresses the issues faced by smart parking system, which has been implemented in subsequent years. By identifying the solution, it can improve the quality of the system for greater purpose in the future. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Frequency Domain-Extended Coded Random Access Scheme for Spectrum Sharing between 5G and Fixed Satellite Services"
        ],
        "penulis":"Haryanti, Tita;Anwar, Khoirul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes a new scheme of Coded Random Access (CRA) with extension to frequency domain, called Frequency Domain-Extended Coded Random Access (FDE-CRA) to make the coexistence possible between the fifth telecommunication generation (5G) and Fixed Satellite Services (FSS). Original CRA uses time-slots to serve users, while FDE-CRA uses both time-slots and frequencies to serve larger number of users. The proposed FDE-CRA is highly motivated by the necessity of spectrum sharing between 5G and FSS in bands of 3.4-4.2 GHz such that many interfering frequencies to the FSS can be reduced. FDE-CRA makes spectrum sharing possible by the use of multiuser detection (MUD) based on the available frequencies. We optimize degree distribution by maximizing the bandwidth efficiency and minimizing loss of random access using extrinsic information transfer (EXIT) chart. We also validate the results using practical simulation of packet loss rate (PLR) and throughput performances based on computer simulations. We found that the time consumption for decoding is small when the number of frequencies (K) used in MUD is large. This is because the decoding process is faster since many signals received at the same time-slot can be decoded simultaneously. We analyze the network performances in terms of PLR and throughputs using a series of computer simulations for K={1,2, \u00b7, 10}. We found that MUD of K=5 is optimal for bandwidth sharing efficiency beyond 50%. These results are expected to make the coexistence between 5G and FSS possible and practical. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes a new scheme of Coded Random Access (CRA) with extension to frequency domain, called Frequency Domain-Extended Coded Random Access (FDE-CRA) to make the coexistence possible between the fifth telecommunication generation (5G) and Fixed Satellite Services (FSS). Original CRA uses time-slots to serve users, while FDE-CRA uses both time-slots and frequencies to serve larger number of users. The proposed FDE-CRA is highly motivated by the necessity of spectrum sharing between 5G and FSS in bands of 3.4-4.2 GHz such that many interfering frequencies to the FSS can be reduced. FDE-CRA makes spectrum sharing possible by the use of multiuser detection (MUD) based on the available frequencies. We optimize degree distribution by maximizing the bandwidth efficiency and minimizing loss of random access using extrinsic information transfer (EXIT) chart. We also validate the results using practical simulation of packet loss rate (PLR) and throughput performances based on computer simulations. We found that the time consumption for decoding is small when the number of frequencies (K) used in MUD is large. This is because the decoding process is faster since many signals received at the same time-slot can be decoded simultaneously. We analyze the network performances in terms of PLR and throughputs using a series of computer simulations for K={1,2, \u00b7, 10}. We found that MUD of K=5 is optimal for bandwidth sharing efficiency beyond 50%. These results are expected to make the coexistence between 5G and FSS possible and practical. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Increasing the Capacity of Listega Based on Syllable Pattern Using Multicolumn and Bigram Mapping"
        ],
        "penulis":"Munzi, Gugy Guztaman;Barmawi, Ari Moesriami;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Due to the increasing use of internet, preserving confidentiality and integrity becomes important. One method for preserving them is steganography. There are two types of steganography, noisy and noiseless. One of noiseless steganography method is List Steganography based on syllable pattern proposed by David et al. Since List Steganography based on syllable pattern only embed one character into one column, then the capacity is still low. For increasing the capacity, the proposed method introduced embedding method for two columns where one column can be embedded with up to two characters (one bigram). The characters are embedded based on the syllable and code mapping. Syllable mapping is designed based on the occurrence frequency of syllable in the cover and English dictionary, while code mapping is designed based on the occurrence frequency of the code in the cover. Based on the experiment result, the embedding capacity using English secret message is increased with the rate of 17% to 55%. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Due to the increasing use of internet, preserving confidentiality and integrity becomes important. One method for preserving them is steganography. There are two types of steganography, noisy and noiseless. One of noiseless steganography method is List Steganography based on syllable pattern proposed by David et al. Since List Steganography based on syllable pattern only embed one character into one column, then the capacity is still low. For increasing the capacity, the proposed method introduced embedding method for two columns where one column can be embedded with up to two characters (one bigram). The characters are embedded based on the syllable and code mapping. Syllable mapping is designed based on the occurrence frequency of syllable in the cover and English dictionary, while code mapping is designed based on the occurrence frequency of the code in the cover. Based on the experiment result, the embedding capacity using English secret message is increased with the rate of 17% to 55%. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Potential detection application of nodular melanoma on melanocytic nevi image based on android"
        ],
        "penulis":"Alhakim, Muhammad;Purboyo, Tito Waluyo;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nodular melanoma is a deadly rare type of skin cancer. Nodular Melanoma has characteristics asymmetrical shape, border irregularity, nonhomogeneous or has several color variations and the diameter is more than 6 millimeters. Nodular melanoma has a physical form similar to melanocytic nevi, therefore nodular melanoma can be detected from melanocytic nevi spread throughout the body. This research aims to detect nodular melanoma through melanocytic nevi by utilizing the android system in order to ease the user by using camera smartphone in detecting cancer. This application uses image processing and feature extraction of the ABCD method to process images with decision tree c4.5 classification method to detect potential of nodular melanoma diagnosis from melanocytic nevi image. The ABCD method is a medical method used to detect the possibility of skin cancer using 4 parameters including asymmetrical shape, border irregularity, color and diameter. Decision tree c4.5 is classification method that using entropy and gain to make rules of decision tree. The image data test is obtained from the results of the android-based smartphone camera shooting and from medical record. Output of this application is a diagnosis condition of melanocytic nevi is healthy or nodular melanoma potentially. The accuracy of this application is 97.5%. \u00a9BEIESP.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nodular melanoma is a deadly rare type of skin cancer. Nodular Melanoma has characteristics asymmetrical shape, border irregularity, nonhomogeneous or has several color variations and the diameter is more than 6 millimeters. Nodular melanoma has a physical form similar to melanocytic nevi, therefore nodular melanoma can be detected from melanocytic nevi spread throughout the body. This research aims to detect nodular melanoma through melanocytic nevi by utilizing the android system in order to ease the user by using camera smartphone in detecting cancer. This application uses image processing and feature extraction of the ABCD method to process images with decision tree c4.5 classification method to detect potential of nodular melanoma diagnosis from melanocytic nevi image. The ABCD method is a medical method used to detect the possibility of skin cancer using 4 parameters including asymmetrical shape, border irregularity, color and diameter. Decision tree c4.5 is classification method that using entropy and gain to make rules of decision tree. The image data test is obtained from the results of the android-based smartphone camera shooting and from medical record. Output of this application is a diagnosis condition of melanocytic nevi is healthy or nodular melanoma potentially. The accuracy of this application is 97.5%. \u00a9BEIESP."
        ]
    },
    {
        "judul":[
            "The implementation of traffic analytics using deep learning and big data technology with garuda smart city framework"
        ],
        "penulis":"Supangkat, Suhono Harso;Hidayat, Fadhil;Dahlan, Iqbal Ahmad;Hamami, Faqih;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nowadays the population in the city grow rapidly [1]. It may cause many problems and those must be tackled with smart city solution because manual policy cannot handle that situation due to limited physical supporting tools [1] [2]. One of the problems is traffic congestion and its management. Moreover, other smart city initiatives such as traffic control and violence detection are applied to solve that issue in order to improve quality of life [3]. In this paper, a cloud-based with big data and video analytics with deep learning are proposed in the context of efficiency where accuracy and speed of processing and transmissions play a critical role into access policy and control with our integration platform based on Garuda Smart City Framework (GSCF) [1] [4]. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays the population in the city grow rapidly [1]. It may cause many problems and those must be tackled with smart city solution because manual policy cannot handle that situation due to limited physical supporting tools [1] [2]. One of the problems is traffic congestion and its management. Moreover, other smart city initiatives such as traffic control and violence detection are applied to solve that issue in order to improve quality of life [3]. In this paper, a cloud-based with big data and video analytics with deep learning are proposed in the context of efficiency where accuracy and speed of processing and transmissions play a critical role into access policy and control with our integration platform based on Garuda Smart City Framework (GSCF) [1] [4]. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "What do customers really need in ride-hailing applications? : signaling electronic service quality via E-CRM features"
        ],
        "penulis":"Nabarian, Tifanny;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Fierce competition on ride-hailing applications in Indonesia encourages the development of the application that is not only reliable but also has to be customer-oriented. In the context of gig economy, customers consist of clients and gig workers. Lack of customer engagement can reduce competitiveness, images, and profit. In 2017, Indonesian Consumers Foundation exposed that 13 percent ride-hailing customer's disappointment was caused by the application. This research evaluated Electronic Customer Relationship Management (E-CRM) features in ride-hailing applications, and then found out if those affect electronic service quality (ESERVQUAL); in other words, it is about customers' perception. Data analysis was conducted using Partial Least Square Structural Equation Modelling (PLS-SEM) method with the total number of valid responses processed was 204 respondents. The results implied that navigation, privacy and security, online community, and customer service are the E-CRM features that are really needed by the customers. By knowing the results, the researchers want to show the asymmetry signal between the providers and customers' perception. Thus, it can lead providers to develop better E-CRM features in ride-hailing application and conquering the customers' dissatisfactions in the context of gig economy. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Fierce competition on ride-hailing applications in Indonesia encourages the development of the application that is not only reliable but also has to be customer-oriented. In the context of gig economy, customers consist of clients and gig workers. Lack of customer engagement can reduce competitiveness, images, and profit. In 2017, Indonesian Consumers Foundation exposed that 13 percent ride-hailing customer's disappointment was caused by the application. This research evaluated Electronic Customer Relationship Management (E-CRM) features in ride-hailing applications, and then found out if those affect electronic service quality (ESERVQUAL); in other words, it is about customers' perception. Data analysis was conducted using Partial Least Square Structural Equation Modelling (PLS-SEM) method with the total number of valid responses processed was 204 respondents. The results implied that navigation, privacy and security, online community, and customer service are the E-CRM features that are really needed by the customers. By knowing the results, the researchers want to show the asymmetry signal between the providers and customers' perception. Thus, it can lead providers to develop better E-CRM features in ride-hailing application and conquering the customers' dissatisfactions in the context of gig economy. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Wireless sensor network for illegal logging application: A systematic literature review"
        ],
        "penulis":"Mutiara, Giva Andriana;Suryana, Nanna;Mohd, Othman Bin;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Wireless Sensor Networks (WSN) is a technology available for outdoor area application. The characteristic of illegal logging application is suitable to apply WSN-based application. Because the illegal logging application is implemented in a wide range area, supervised the environment forest, and consists of hundreds of sensor nodes. This paper aims to review and summarize as systematically the contribution of WSN Technology in illegal logging area research as a long-range network application especially in detection and identification method, timber tracking methods, data exchange, and transmission method. A Systematic Literature Review (SLR) were outlined in this paper as a standard methodology of predefined research strategy to solve the problems by tracing the previous research. By defining the Research Question (RQ) to guidelines the SLR process and inserting the search string in the database reputation journal, the previous research can be configured. There are 42 previous studies applied WSN to used it in the illegal logging application. The result stated that WSN has biggest contributions since 33% researcher using WSN to tracking application, 41% use the WSN as a data exchange in their system, and 48% used WSN as data transmission between sensor nodes. This paper is expected to give a contribution to the researcher who wants to build the system to tackle illegal logging since the illegal logging has been hot issues in the world. \u00a9 2005 \u2013 ongoing JATIT & LLS.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Wireless Sensor Networks (WSN) is a technology available for outdoor area application. The characteristic of illegal logging application is suitable to apply WSN-based application. Because the illegal logging application is implemented in a wide range area, supervised the environment forest, and consists of hundreds of sensor nodes. This paper aims to review and summarize as systematically the contribution of WSN Technology in illegal logging area research as a long-range network application especially in detection and identification method, timber tracking methods, data exchange, and transmission method. A Systematic Literature Review (SLR) were outlined in this paper as a standard methodology of predefined research strategy to solve the problems by tracing the previous research. By defining the Research Question (RQ) to guidelines the SLR process and inserting the search string in the database reputation journal, the previous research can be configured. There are 42 previous studies applied WSN to used it in the illegal logging application. The result stated that WSN has biggest contributions since 33% researcher using WSN to tracking application, 41% use the WSN as a data exchange in their system, and 48% used WSN as data transmission between sensor nodes. This paper is expected to give a contribution to the researcher who wants to build the system to tackle illegal logging since the illegal logging has been hot issues in the world. \u00a9 2005 \u2013 ongoing JATIT & LLS."
        ]
    },
    {
        "judul":[
            "Ethical leaderships and organizational culture of student organization at Indonesian Private University"
        ],
        "penulis":"Gilang, Alini;Fakhri, Mahendra;Syarifuddin, Syarifuddin;Pradana, Mahir;Utami, Dita Puri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to determine the effect of the ethical leaderships toward organizational culture at Himpunan Mahasiswa (Student Organization) of Business Administration on Faculty of Communication and Business at Telkom University or known as 'HIMA ADBIS'. This research uses quantitative method with the types of data required are the combination between primary and secondary data. This research uses saturation sampling method with 52 respondents consisting of all organizers of HIMA ADBIS, and simple linear regression analysis for data analyzing. The results showed that ethical leadership is in the position of 84,08% with a number of very high category and organizational culture in the position of 86,27% with a number of very high category. The result of partially showed that ethical leadership influence organizational culture amounted to 22,5% and from other variables amounted 77,5% are not researched in this research. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to determine the effect of the ethical leaderships toward organizational culture at Himpunan Mahasiswa (Student Organization) of Business Administration on Faculty of Communication and Business at Telkom University or known as 'HIMA ADBIS'. This research uses quantitative method with the types of data required are the combination between primary and secondary data. This research uses saturation sampling method with 52 respondents consisting of all organizers of HIMA ADBIS, and simple linear regression analysis for data analyzing. The results showed that ethical leadership is in the position of 84,08% with a number of very high category and organizational culture in the position of 86,27% with a number of very high category. The result of partially showed that ethical leadership influence organizational culture amounted to 22,5% and from other variables amounted 77,5% are not researched in this research. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "The Effect of Consumer Dispersed in Spatially Dispersed Caching Strategy for Information-Centric Networking"
        ],
        "penulis":"Annisa, Sarah Chairul;Yovita, Leanna Vidya;Syambas, Nana Rachmana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nowadays, there has been a lot of research on Information-Centric Networking (ICN) that is looking for the most efficient way to the content stored on the network. And, the goal is for network user easily to access various content effectively and efficiently. Currently, Spatial Dispersed Caching (SDC) is one of the newest cache strategies on the ICN. Therefore, in this paper, it will further deepen the concept of the SDC strategy, namely by analyzing the path stretch value generated when the consumer condition dispersed and non-dispersed. The results of this study indicate that if consumers are non-dispersed the path stretch value is 2.03. In addition, if consumers are dispersed the path stretch value is 1.13. Thus, average the path stretch value if consumers are dispersed will be smaller than the non-dispersed, this indicates that consumers are more easily get the requested content from the nearest router. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, there has been a lot of research on Information-Centric Networking (ICN) that is looking for the most efficient way to the content stored on the network. And, the goal is for network user easily to access various content effectively and efficiently. Currently, Spatial Dispersed Caching (SDC) is one of the newest cache strategies on the ICN. Therefore, in this paper, it will further deepen the concept of the SDC strategy, namely by analyzing the path stretch value generated when the consumer condition dispersed and non-dispersed. The results of this study indicate that if consumers are non-dispersed the path stretch value is 2.03. In addition, if consumers are dispersed the path stretch value is 1.13. Thus, average the path stretch value if consumers are dispersed will be smaller than the non-dispersed, this indicates that consumers are more easily get the requested content from the nearest router. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Towards humane digitization: A wellbeing-driven process of personas creation"
        ],
        "penulis":"Nurhas, Irawan;Pawlowski, Jan M.;Geisler, Stefan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Digital transformation is a process of digitizing the working and living environment in which people are at the center of digitization. In this paper, we present a personas-based guideline for system developers on how the humanization of digital transformation integrates into the design process. The proposed guideline uses the positive personas from the beginning as a basis for the transformation of the working environment into the digital form. We used the literature research as a preliminary study for the process of wellbeing-driven digital transformation design, consisting of questions for structuring the required information in the positive personas as well as a potential method that could be integrated into the wellbeing-based design process. \u00a9 2019 Copyright is held by the owner\/author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Digital transformation is a process of digitizing the working and living environment in which people are at the center of digitization. In this paper, we present a personas-based guideline for system developers on how the humanization of digital transformation integrates into the design process. The proposed guideline uses the positive personas from the beginning as a basis for the transformation of the working environment into the digital form. We used the literature research as a preliminary study for the process of wellbeing-driven digital transformation design, consisting of questions for structuring the required information in the positive personas as well as a potential method that could be integrated into the wellbeing-based design process. \u00a9 2019 Copyright is held by the owner\/author(s)."
        ]
    },
    {
        "judul":[
            "Lung sound classification using hjorth descriptor measurement on wavelet sub-bands"
        ],
        "penulis":"Rizal, Achmad;Hidayat, Risanuri;Nugroho, Hanung Adi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Signal complexity is one point of view to analyze the biological signal. It arises as a result of the physiological signal produced by biological systems. Signal complexity can be used as a method in extracting the feature for a biological signal to differentiate a pathological signal from a normal signal. In this research, Hjorth descriptors, one of the signal complexity measurement techniques, were measured on signal sub-band as the features for lung sounds classification. Lung sound signal was decomposed using two wavelet analyses: discrete wavelet transform (DWT) and wavelet packet decomposition (WPD). Meanwhile, multi-layer perceptron and N-fold cross-validation were used in the classification stage. Using DWT, the highest accuracy was obtained at 97.98%, while using WPD, the highest one was found at 98.99%. This result was found better than the multiscale Hjorth descriptor as in previous studies. \u00a9 2019 KIPS.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Signal complexity is one point of view to analyze the biological signal. It arises as a result of the physiological signal produced by biological systems. Signal complexity can be used as a method in extracting the feature for a biological signal to differentiate a pathological signal from a normal signal. In this research, Hjorth descriptors, one of the signal complexity measurement techniques, were measured on signal sub-band as the features for lung sounds classification. Lung sound signal was decomposed using two wavelet analyses: discrete wavelet transform (DWT) and wavelet packet decomposition (WPD). Meanwhile, multi-layer perceptron and N-fold cross-validation were used in the classification stage. Using DWT, the highest accuracy was obtained at 97.98%, while using WPD, the highest one was found at 98.99%. This result was found better than the multiscale Hjorth descriptor as in previous studies. \u00a9 2019 KIPS."
        ]
    },
    {
        "judul":[
            "Study of External Force and Impedance Scheme on Stroke Rehabilitation Robot Manipulator"
        ],
        "penulis":"Sumarso, Ade Hasan;Widyotriatmo, Augie;Purnama, Irwan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents rehabilitation robot with torque control with impedance scheme for post-stroke patients in the upper limb of the shoulder. This impedance scheme consists of external force input and impedance value. The external force input comes from the load cell at the end of the robot (the end effector), which is generated by the patient's force. The input force consists of two Cartesian directions, which will affect the robot dynamic torque for the X-axis and Y-axis. Meanwhile, the value of the impedance in the robotic system is provided by the therapist who handles the stroke patients. The amount of impedance in the robotic system can be adjusted according to the patient's condition. In this paper, we used 3 DOF (Degree of Freedom) self-produced robots. The rehabilitation trajectory consists of two parameters, the position parameter, and the torque control parameter in the impedance system. The impedance scheme in the robotic system use impedance characteristics and Proportional Integral (PI) controller. Proportional Integral (PI) controller is used as a simulation control in tracking errors of position and the torque impedance of the robot. With a simple controller, the characteristics relationship between the changes in the magnitude of the external force produced by the patient and the change in impedance values given to the robot system are obtained. By knowing these characteristics, robots can interact with various types of stroke patients. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents rehabilitation robot with torque control with impedance scheme for post-stroke patients in the upper limb of the shoulder. This impedance scheme consists of external force input and impedance value. The external force input comes from the load cell at the end of the robot (the end effector), which is generated by the patient's force. The input force consists of two Cartesian directions, which will affect the robot dynamic torque for the X-axis and Y-axis. Meanwhile, the value of the impedance in the robotic system is provided by the therapist who handles the stroke patients. The amount of impedance in the robotic system can be adjusted according to the patient's condition. In this paper, we used 3 DOF (Degree of Freedom) self-produced robots. The rehabilitation trajectory consists of two parameters, the position parameter, and the torque control parameter in the impedance system. The impedance scheme in the robotic system use impedance characteristics and Proportional Integral (PI) controller. Proportional Integral (PI) controller is used as a simulation control in tracking errors of position and the torque impedance of the robot. With a simple controller, the characteristics relationship between the changes in the magnitude of the external force produced by the patient and the change in impedance values given to the robot system are obtained. By knowing these characteristics, robots can interact with various types of stroke patients. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Air pollution distribution in Telkom University: Spatial interpolation map"
        ],
        "penulis":"Oktaviani I.D.;Erfianto B.;Rakhmatsyah A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Currently, air quality information in a region becomes an important thing to know. Some efforts have been conducted to show air quality in certain region. One of the efforts that has been done is information regarding air quality in several big cities in Indonesia which can be seen in the official website of the Ministry of Environment and Forestry that have several weaknesses. One of the problems to be overcome in this research is visualization of air quality data that is monitored at one point only in which that point is the placement location of air quality monitoring station. Because of that, we need an application that can display a map of air pollution distribution using the spatial interpolation method. The solution offered is the depiction of air quality by using heatmap on the map. The method used to produce heatmap with smooth result is natural cubic spline interpolation method. The production of heatmap uses API which is provided by Google Maps. The final result obtained is the map view with the coloration in the form of color gradation in accordance with the air quality value that is obtained. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Currently, air quality information in a region becomes an important thing to know. Some efforts have been conducted to show air quality in certain region. One of the efforts that has been done is information regarding air quality in several big cities in Indonesia which can be seen in the official website of the Ministry of Environment and Forestry that have several weaknesses. One of the problems to be overcome in this research is visualization of air quality data that is monitored at one point only in which that point is the placement location of air quality monitoring station. Because of that, we need an application that can display a map of air pollution distribution using the spatial interpolation method. The solution offered is the depiction of air quality by using heatmap on the map. The method used to produce heatmap with smooth result is natural cubic spline interpolation method. The production of heatmap uses API which is provided by Google Maps. The final result obtained is the map view with the coloration in the form of color gradation in accordance with the air quality value that is obtained. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Grazing enhances species diversity in grassland communities"
        ],
        "penulis":"Pulungan, Muhammad Almaududi;Suzuki, Shota;Gavina, Maica Krizna Areja;Tubay, Jerrold M.;Ito, Hiromu;Nii, Momoka;Ichinose, Genki;Okabe, Takuya;Ishida, Atsushi;Shiyomi, Masae;Togashi, Tatsuya;Yoshimura, Jin;Morita, Satoru;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In grassland studies, an intermediate level of grazing often results in the highest species diversity. Although a few hypotheses have been proposed to explain this unimodal response of species diversity to grazing intensity, no convincing explanation has been provided. Here, we build a lattice model of a grassland community comprising multiple species with various levels of grazing. We analyze the relationship between grazing and plant diversity in grasslands under variable intensities of grazing pressure. The highest species diversity is observed at an intermediate grazing intensity. Grazers suppress domination by the most superior species in birth rate, resulting in the coexistence of inferior species. This unimodal grazing effect disappears with the introduction of a small amount of nongrazing natural mortality. Unimodal patterns of species diversity may be limited to the case where grazers are the principal source of natural mortality. \u00a9 2019, The Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In grassland studies, an intermediate level of grazing often results in the highest species diversity. Although a few hypotheses have been proposed to explain this unimodal response of species diversity to grazing intensity, no convincing explanation has been provided. Here, we build a lattice model of a grassland community comprising multiple species with various levels of grazing. We analyze the relationship between grazing and plant diversity in grasslands under variable intensities of grazing pressure. The highest species diversity is observed at an intermediate grazing intensity. Grazers suppress domination by the most superior species in birth rate, resulting in the coexistence of inferior species. This unimodal grazing effect disappears with the introduction of a small amount of nongrazing natural mortality. Unimodal patterns of species diversity may be limited to the case where grazers are the principal source of natural mortality. \u00a9 2019, The Author(s)."
        ]
    },
    {
        "judul":[
            "Design and implementation of water level control for two coupled tank as a simple and low cost apparatus in automatic control engineering education"
        ],
        "penulis":"Iskandar, Reza Fauzi;Bahari, Baktiaji;Vira, Cut;Ramadhan, Faiz Auliya;Firdaus, Mochamad Roffa;Fitriyanti, Nurwulan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The aim of this paper is to design a simple and low cost prototype apparatus for automatic control engineering education. The activities were arranged in order to support the development of student skill, particularly in control design for water level system. The system was developed from many parts such as coupled water tank, water level sensor, flow actuator and microcontroller. The integrated system characteristic was observed in order to understand the dynamics response and design the proper control law. The open loop system was approximated as first order system and has time constant \u03c4 about 7.59 second. The control scheme was designed using the conventional proportional and integral (PI) strategy. The proportional gain and integral gain were derived from dynamic characteristic, resulting 1.96 and 0.25 respectively. The experimental result showed rise time (Tr) 0.06 second, settling time (Ts) 0.17 second and steady state error around 8.55% relative to set point value. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aim of this paper is to design a simple and low cost prototype apparatus for automatic control engineering education. The activities were arranged in order to support the development of student skill, particularly in control design for water level system. The system was developed from many parts such as coupled water tank, water level sensor, flow actuator and microcontroller. The integrated system characteristic was observed in order to understand the dynamics response and design the proper control law. The open loop system was approximated as first order system and has time constant \u03c4 about 7.59 second. The control scheme was designed using the conventional proportional and integral (PI) strategy. The proportional gain and integral gain were derived from dynamic characteristic, resulting 1.96 and 0.25 respectively. The experimental result showed rise time (Tr) 0.06 second, settling time (Ts) 0.17 second and steady state error around 8.55% relative to set point value. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Performance evaluation of M-ary modulated DCO-OFDM in an indoor visible light communication system"
        ],
        "penulis":"Milia, Nurul Fatma;Sugesti, Erna Sri;Saputri, Desti Madya;Pamukti, Brian;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper reports the performance of an indoor Visible Light Communication (VLC) system using a Direct Current-biased Optical Orthogonal Frequency Division Multiplexing (DCO-OFDM) scheme with a single Light Emitting Diode (LED). The DCO-OFDM is assigned to alter the bipolar signals produced by ordinary OFDM into unipolar signals. We simulate some M-ary modulations and employ Line-of-Sight (LOS) propagation model. The results show that the Quadrature Phase Shift Keying (QPSK) modulation is the most extensive one, with BER \u2264 10-3with lower SNR. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper reports the performance of an indoor Visible Light Communication (VLC) system using a Direct Current-biased Optical Orthogonal Frequency Division Multiplexing (DCO-OFDM) scheme with a single Light Emitting Diode (LED). The DCO-OFDM is assigned to alter the bipolar signals produced by ordinary OFDM into unipolar signals. We simulate some M-ary modulations and employ Line-of-Sight (LOS) propagation model. The results show that the Quadrature Phase Shift Keying (QPSK) modulation is the most extensive one, with BER \u2264 10-3with lower SNR. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Application design of farmbot based on Internet of Things (IoT)"
        ],
        "penulis":"Murdyantoro, Bagus;Atmaja, Denny Sukma Eka;Rachmat, Haris;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The agribusiness sector is the largest economic sector and the most important part of the Indonesian national economy, but the agribusiness sector begins to experience threats in fulfilling human food. Fulfillment of food faced some challenges including an increase in population, which means rising food, urbanization resulting in a decrease in the number of farmers and dietary changes, limited resources (land and air), changes to facilitate and waste food. This corresponds to the data issued by the United Nations, which is the fulfillment of food from approximately 9.6 billion people in the world in 2050 [2]. Along with that, the agricultural land area also decreased due to the transfer of agricultural land function. Farmbot can increase agricultural production to solve human food because it can manage crops within 24 hours without stopping. Farmbot is liquid of agricultural robots that can plant seeds with regular, watering plants and monitoring plant growth. Farmbot can be controlled through an application interface that allows remote access from any location in easy Internet-connected devices. In this study, it will create an automation system that can plant seeds, watering agricultural crops by controlling air production, monitoring plant conditions, plant databases by using applications and designing algorithms to detect crops. Besides, other ways can measure the moisture of the soil to scheduling watering as a watering parameter. To implement this feature can work using a robotic hand with a CNC (Computer Numeric Control) gesture system that would be controlled by the Arduino and Raspberry PI. Following are the procedures for implementing agricultural automation with IoT applications (Internet of Things), seedlings with the help of seeders that stored in plant databases, watering and direct monitoring by users who use camera help. \u00a9 2019, Insight Society.",
            "Sustainable Development Goals mapped to this documentZero hungerGoal 2",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The agribusiness sector is the largest economic sector and the most important part of the Indonesian national economy, but the agribusiness sector begins to experience threats in fulfilling human food. Fulfillment of food faced some challenges including an increase in population, which means rising food, urbanization resulting in a decrease in the number of farmers and dietary changes, limited resources (land and air), changes to facilitate and waste food. This corresponds to the data issued by the United Nations, which is the fulfillment of food from approximately 9.6 billion people in the world in 2050 [2]. Along with that, the agricultural land area also decreased due to the transfer of agricultural land function. Farmbot can increase agricultural production to solve human food because it can manage crops within 24 hours without stopping. Farmbot is liquid of agricultural robots that can plant seeds with regular, watering plants and monitoring plant growth. Farmbot can be controlled through an application interface that allows remote access from any location in easy Internet-connected devices. In this study, it will create an automation system that can plant seeds, watering agricultural crops by controlling air production, monitoring plant conditions, plant databases by using applications and designing algorithms to detect crops. Besides, other ways can measure the moisture of the soil to scheduling watering as a watering parameter. To implement this feature can work using a robotic hand with a CNC (Computer Numeric Control) gesture system that would be controlled by the Arduino and Raspberry PI. Following are the procedures for implementing agricultural automation with IoT applications (Internet of Things), seedlings with the help of seeders that stored in plant databases, watering and direct monitoring by users who use camera help. \u00a9 2019, Insight Society."
        ]
    },
    {
        "judul":[
            "Confusion around e-ID Card Service, Public Obligation versus Public Service"
        ],
        "penulis":"Kania I.;Alamanda D.T.;Anggadwita G.;Permatasari A.;Hasyim S.B.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The issues of public services are complained by most people, one of them is the population problem. E-ID card as the identity of the population is the biggest public complaint reported to the State institution in charge of overseeing public services. Unavailability of the blanks, the uncertainty of the information and the non-proactive nature in providing services are the most common issues in the public complaints box for e-ID cards. This study aims to find out public opinion concerning e-ID card recording service. The method used by the researchers is descriptive survey in which the data were collected through observation, interview and questionnaire distribution. The sample in this study 578 respondents. Simple linear regression is used as a tool to measure the level of public satisfaction based on the services provided to them when signing up for e-ID cards. The result shows work culture influence the service quality by 0,35. The benefits of this research could have an impact on the policy of Garut regency government, especially in assessing the government performance in e-ID card recording service comprehensively. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The issues of public services are complained by most people, one of them is the population problem. E-ID card as the identity of the population is the biggest public complaint reported to the State institution in charge of overseeing public services. Unavailability of the blanks, the uncertainty of the information and the non-proactive nature in providing services are the most common issues in the public complaints box for e-ID cards. This study aims to find out public opinion concerning e-ID card recording service. The method used by the researchers is descriptive survey in which the data were collected through observation, interview and questionnaire distribution. The sample in this study 578 respondents. Simple linear regression is used as a tool to measure the level of public satisfaction based on the services provided to them when signing up for e-ID cards. The result shows work culture influence the service quality by 0,35. The benefits of this research could have an impact on the policy of Garut regency government, especially in assessing the government performance in e-ID card recording service comprehensively. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Predictive business process monitoring - Remaining time prediction using deep neural network with entity embedding"
        ],
        "penulis":"Wahid, Nur Ahmad;Adi, Taufik Nur;Bae, Hyerim;Choi, Yulim;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Most process mining study focuses on analysis of past data. This differs from predictive process monitoring, which, as a part of operational support, has as one of its focuses on the prediction of a running case [1]. Although there are several measures of interest that can be provided, in the present study, we focused on the remaining time of a running case. Results produced by Deep Neural Network (DNN) [2], despite its acknowledged power for various problems, typically are no better than those of other supervised algorithms with problems involving categorical variables in tabular data [3]. Because the dataset extracted from event logs that contain categorical variables can be constructed and categorized in tabular form, it is unwise to use only ordinary DNN. In this study, we showed that we can increase the accuracy of DNN on tabular data that contains categorical variables by using a technique known as Entity Embedding. To show the robustness of the method, we conducted experiments with two types of dataset, synthesis data and real-world data, and also compared its performance with other supervised learning algorithms for regression problems. The experimental results showed that it is true that the proposed method can increase the accuracy of DNN predictions on remaining time prediction problem involving categorical variables and beats all baseline methods used as comparison. \u00a9 2019 The Authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Most process mining study focuses on analysis of past data. This differs from predictive process monitoring, which, as a part of operational support, has as one of its focuses on the prediction of a running case [1]. Although there are several measures of interest that can be provided, in the present study, we focused on the remaining time of a running case. Results produced by Deep Neural Network (DNN) [2], despite its acknowledged power for various problems, typically are no better than those of other supervised algorithms with problems involving categorical variables in tabular data [3]. Because the dataset extracted from event logs that contain categorical variables can be constructed and categorized in tabular form, it is unwise to use only ordinary DNN. In this study, we showed that we can increase the accuracy of DNN on tabular data that contains categorical variables by using a technique known as Entity Embedding. To show the robustness of the method, we conducted experiments with two types of dataset, synthesis data and real-world data, and also compared its performance with other supervised learning algorithms for regression problems. The experimental results showed that it is true that the proposed method can increase the accuracy of DNN predictions on remaining time prediction problem involving categorical variables and beats all baseline methods used as comparison. \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Item delivery simulation using genetic algorithm"
        ],
        "penulis":"Switrayana, I Nyoman;Osmond, Andrew Brian;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In sending items, time and costs can be minimized by selecting the shortest path. The problem of choosing the shortest path is often known as Travelling Salesman Problem (TSP). TSP in this study was not only concerned with distance but also the priority of places to be visited. Priority parameters in this research are a sign that each place has a value to be visited first than another place. This priority can also be assumed as a type of delivery service that can be chosen by the customer. Priority is divided into three groups, but it can also be more than that according to the needs of a shipping service provider. Delivery of multiple destinations in one area can be delivered with a single trip based on their priority. Search optimization of the shortest path is modeled with genetic algorithms. Hamilton path is the output of the simulation. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In sending items, time and costs can be minimized by selecting the shortest path. The problem of choosing the shortest path is often known as Travelling Salesman Problem (TSP). TSP in this study was not only concerned with distance but also the priority of places to be visited. Priority parameters in this research are a sign that each place has a value to be visited first than another place. This priority can also be assumed as a type of delivery service that can be chosen by the customer. Priority is divided into three groups, but it can also be more than that according to the needs of a shipping service provider. Delivery of multiple destinations in one area can be delivered with a single trip based on their priority. Search optimization of the shortest path is modeled with genetic algorithms. Hamilton path is the output of the simulation. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Water flow control system based on context aware algorithm and IoT for hydroponic"
        ],
        "penulis":"Gandhi, Otrinanda;Ramdhani, Mohamad;Murti, Muhammad Ary;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Solar radio burst in National Space Agency of Malaysia (ANGKASA)"
        ],
        "penulis":"Nadirah Ishak, Asnor;Zulaikha Mohd Afandi, Nur;Umar, Roslan;Hazmin Sabri, Nor;Mohd Radzi, Zahira;Juraiza Ishak, Asnor;Anwar, Radial;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The sun is an active star that produces large-scale energetic events, such as solar flares and coronal mass ejections (CMEs). These phenomena are observable across the electromagnetic spectrum, from gamma rays at hundreds of MeV to radio waves with wavelengths of tens of metres. Solar flares and CMEs can excite plasma oscillations which can emit radiation at metric and decametric wavelengths. These radio bursts are classified in five main types. This paper gives a solar radio burst type III (16 July 2017) in National Space Agency (ANGKASA), Banting, Selangor, Malaysia. Compact Astronomical Low-Cost Instrument for Spectroscopy in Transportable Observatories (CALLISTO) is used in this system to observe solar radio activities. The main applications for this CALLISTO is to observe a solar radio bursts and radio frequency interference (RFI) monitoring for astronomical science, education and outreach. The CALLISTO natively operates between 45MHz to 870MHz and its observed daily. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The sun is an active star that produces large-scale energetic events, such as solar flares and coronal mass ejections (CMEs). These phenomena are observable across the electromagnetic spectrum, from gamma rays at hundreds of MeV to radio waves with wavelengths of tens of metres. Solar flares and CMEs can excite plasma oscillations which can emit radiation at metric and decametric wavelengths. These radio bursts are classified in five main types. This paper gives a solar radio burst type III (16 July 2017) in National Space Agency (ANGKASA), Banting, Selangor, Malaysia. Compact Astronomical Low-Cost Instrument for Spectroscopy in Transportable Observatories (CALLISTO) is used in this system to observe solar radio activities. The main applications for this CALLISTO is to observe a solar radio bursts and radio frequency interference (RFI) monitoring for astronomical science, education and outreach. The CALLISTO natively operates between 45MHz to 870MHz and its observed daily. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Secondary Metabolite Diversity Analysis of Three Mangifera Foetida L. Varieties Based on Liquid Chromatography-Mass Spectrometry (LC-MS)"
        ],
        "penulis":"Fitmawati F.;Khairunnisa K.;Resida, Esi;Emrizal E.;Mustika Roza, Rodesia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Mangifera foetida L. (Macang) is the type of mangoes that contains the highest levels of mangiferin which has activity of antioxidant, analgesic, anti-drip, anti-inflammatory, antitumor, immunomodulatory and anti-HIV. The potential of Macang as a drug needs to be assessed through phytochemical studies to obtain information on the diversity of Macang secondary metabolite content that is potential to be developed. The purpose of this study was to reveal the diversity of total secondary metabolite compounds contained in Macang with three varieties (Limus, Batu and Manis) using LC-MS analysis. Sampling was carried out use survey method at Remban and Lesung Batu, Kecamatan Rawas Ulu, Kabupaten Musi Rawas Utara, South Sumatra Province. The chromatogram was analyzed using the MassLynx program to obtain the compounds contained in the sample. Names determination of compounds based on Chemspider database and compound classes based on PubChem. The number of metabolite compounds that become characteristic of three Macang varieties in this study was 667 compounds. Limus has a specific compound of 191 compounds, Batu of 162 compounds, and Manis has a specific compound of 202 compounds. The metabolites found in this study are expected to be useful in phytopharmaca and support Macang conservation efforts that rarely found. \u00a9 Published under licence by IOP Publishing Ltd.",
            "OH3COOOH3CHOOView detailsExpand Substance [(8-Methoxy-4-Methyl-6-Oxo-6H-Benzo[C]Chromen-3-Yl)Oxy]Acetic AcidCH3CH3CH3HHHView detailsExpand Substance pregnaneCH3OHOH3CCH2View detailsExpand Substance methyl 4-allyl-2-methoxyphenolOOHOOHView detailsExpand Substance liquiritigeninH3CHOOOView detailsExpand Substance loxoprofenOOOCH3H3CView detailsExpand Substance 4-Methoxyphenyl 4- butylcyclohexanecarboxylateOHH3CH3CCH3OH3COHOView detailsExpand Substance Abscisic acidH3CHOOCH3H3CView detailsExpand Substance ibuprofenCH3CH3CH3H3CCH3H3CView detailsExpand Substance HexamethylbenzeneH3CH3COHOH3COView detailsExpand Substance Campher-carbonsaeure-(4)CH3H3CH3CHOOCH3View detailsExpand Substance 3-t-butyl-4-hydroxyanisoleNH2OHONHH2NNHView detailsExpand Substance ArgNH2OHOHOOView detailsExpand Substance Glutamic acidOOHOOView detailsExpand Substance isoxepacNH2OHCH3HOOView detailsExpand Substance DL-ThreonineONH2View detailsExpand Substance 2-phenoxyanilineNH2OHOHOOView detailsExpand Substance aspartic AcidH3COCH3View detailsExpand Substance anetholeCH3H3CH3CHOOHView detailsExpand Substance tert-butylhydroquinoneOHHOView detailsExpand Substance hydroquinoneOOOHOHHOHOOHView detailsExpand Substance morinOOOHHOOHOHView detailsExpand Substance 2-(3,4-Dihydroxy-phenyl)-5,7-dihydroxy-chromen-4-onOOHOOHView detailsExpand Substance daidzeinOHOOHOView detailsExpand Substance aesculetinOCH3CH3View detailsExpand Substance 2,2-dimethyl-2H-chromeneNHView detailsExpand Substance indoleOOOHHOOHView detailsExpand Substance naringeninOOOOOHOHOHOHHOOHH3COHView detailsExpand Substance quercitrinOHOOOOHOHHOOHHOOHHOView detailsExpand Substance mangiferinNHNNHNView detailsExpand Substance porphyrinTanninView detailsExpand Substance tannin",
            "Powered by",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mangifera foetida L. (Macang) is the type of mangoes that contains the highest levels of mangiferin which has activity of antioxidant, analgesic, anti-drip, anti-inflammatory, antitumor, immunomodulatory and anti-HIV. The potential of Macang as a drug needs to be assessed through phytochemical studies to obtain information on the diversity of Macang secondary metabolite content that is potential to be developed. The purpose of this study was to reveal the diversity of total secondary metabolite compounds contained in Macang with three varieties (Limus, Batu and Manis) using LC-MS analysis. Sampling was carried out use survey method at Remban and Lesung Batu, Kecamatan Rawas Ulu, Kabupaten Musi Rawas Utara, South Sumatra Province. The chromatogram was analyzed using the MassLynx program to obtain the compounds contained in the sample. Names determination of compounds based on Chemspider database and compound classes based on PubChem. The number of metabolite compounds that become characteristic of three Macang varieties in this study was 667 compounds. Limus has a specific compound of 191 compounds, Batu of 162 compounds, and Manis has a specific compound of 202 compounds. The metabolites found in this study are expected to be useful in phytopharmaca and support Macang conservation efforts that rarely found. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Effect of Hydrophilic Coating on Concrete Pile Surface in Pile Driving: Field Test"
        ],
        "penulis":"Amalia, Nadya;Yuliza, Elfi;Rokhmat, Mamat;Wibowo, Edy;Viridi, Sparisoma;Abdullah, Mikrajuddin;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At laboratory scale, hydrophilic coating on the surface of precast concrete piles is capable of affecting the piles to be installed into a certain depth level with less number of hammer strokes than piles without coating. In this work, a preliminary study of pile driving tests in the field, the origin of the soil at laboratory scale, has been carried out. Based on our analysis result of the measurement data, it is found that the hydrophilic coating has different effects on pile driving at laboratory and field scales. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At laboratory scale, hydrophilic coating on the surface of precast concrete piles is capable of affecting the piles to be installed into a certain depth level with less number of hammer strokes than piles without coating. In this work, a preliminary study of pile driving tests in the field, the origin of the soil at laboratory scale, has been carried out. Based on our analysis result of the measurement data, it is found that the hydrophilic coating has different effects on pile driving at laboratory and field scales. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Potential GQM+strategies improvement using balanced scorecard perspectives"
        ],
        "penulis":"Husen, Jati H.;Washizaki, Hironori;Fukazawa, Yoshiaki;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Business-information technology (IT) alignment, which links IT-based strategies to higher business goals, is becoming more critical as organizations rely more on IT solutions to conduct their business activities. While GQM+Strategies provides a platform to achieve good business-IT alignment, lack of attention to different aspects of an organization may lead to failure to do so. In this paper, we evaluated three cases of GQM+Strategies implementation to find possibilities of integrating balanced scorecard perspectives into the GQM+Strategies framework by classifying the goals and strategies into balanced scorecard perspectives and evaluating them based on rules of the balanced scorecard framework. We found that GQM+Strategies has a problem in maintaining balanced distribution of goals and strategies across different perspectives. We also saw signs that inexperienced grid developers may align the goals and strategies poorly when classifying the goals and strategies into perspectives. Lastly, we found that transitions between different balanced scorecard perspectives happen exclusively at the derivation of goals from strategies. Based on those findings, we propose three potential methods to improve GQM+Strategies in order to detect potential problems. On top of that, we explain what is needed for each method before we finally utilize them. \u00a9 2019 Institute of Electronics and Information Engineers. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Business-information technology (IT) alignment, which links IT-based strategies to higher business goals, is becoming more critical as organizations rely more on IT solutions to conduct their business activities. While GQM+Strategies provides a platform to achieve good business-IT alignment, lack of attention to different aspects of an organization may lead to failure to do so. In this paper, we evaluated three cases of GQM+Strategies implementation to find possibilities of integrating balanced scorecard perspectives into the GQM+Strategies framework by classifying the goals and strategies into balanced scorecard perspectives and evaluating them based on rules of the balanced scorecard framework. We found that GQM+Strategies has a problem in maintaining balanced distribution of goals and strategies across different perspectives. We also saw signs that inexperienced grid developers may align the goals and strategies poorly when classifying the goals and strategies into perspectives. Lastly, we found that transitions between different balanced scorecard perspectives happen exclusively at the derivation of goals from strategies. Based on those findings, we propose three potential methods to improve GQM+Strategies in order to detect potential problems. On top of that, we explain what is needed for each method before we finally utilize them. \u00a9 2019 Institute of Electronics and Information Engineers. All rights reserved."
        ]
    },
    {
        "judul":[
            "Melanoma Cancer Classification Using ResNet with Data Augmentation"
        ],
        "penulis":"Budhiman, Arief;Suyanto, Suyanto;Arifianto, Anditya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Melanoma skin cancer is cancer that difficult to detect. In this study, have been done melanoma cancer classification using Convolutional Neural Network (CNN). CNN is a class of Deep Neural Network (Deep Learning) and commonly used to analyzing images data. A lot of data used on CNN can greatly affect accuracy. In this study, the objective is to get best ResNet model for classifying melanoma cancer and normal skin images. The dataset that used is ISIC 2018. ResNet is used because the model winning the ILSVRC competition at 2015. ResNet architecture model that used are ResNet 50, 40, 25, 10 and 7 models. The architecture trained using data train that has been augmented and undersampling. The validation result on each model calculated using F1 Score. After validation and F1 Score result from the model obtained, the result compared each other to select the best model. The best architecture is ResNet 50 without augmentation that gives a validation accuracy of 0.83 and f1 score of 0.46. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Melanoma skin cancer is cancer that difficult to detect. In this study, have been done melanoma cancer classification using Convolutional Neural Network (CNN). CNN is a class of Deep Neural Network (Deep Learning) and commonly used to analyzing images data. A lot of data used on CNN can greatly affect accuracy. In this study, the objective is to get best ResNet model for classifying melanoma cancer and normal skin images. The dataset that used is ISIC 2018. ResNet is used because the model winning the ILSVRC competition at 2015. ResNet architecture model that used are ResNet 50, 40, 25, 10 and 7 models. The architecture trained using data train that has been augmented and undersampling. The validation result on each model calculated using F1 Score. After validation and F1 Score result from the model obtained, the result compared each other to select the best model. The best architecture is ResNet 50 without augmentation that gives a validation accuracy of 0.83 and f1 score of 0.46. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Queueing theory based accelerated traffic discharging model in front of emergency vehicle on intersection"
        ],
        "penulis":"Sumaryo, Sony;Halim, Abdul;Ramli, Kalamullah;Joelianto, Endra;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Intelligent Transportation System (ITS) is the integration between communication networks, real-time control, and information technology. The system is expected to perform more complex traffic arrangements, in particular traffic management of emergency vehicles. Implementation with traffic signal pre-emption alone is not enough to give space for the emergency vehicle to cross an intersection safely, especially if the lane street has only one lane. The paper proposes a new model of traffic discharge acceleration based on queueing theory approach. In the proposed model, two performance indicators are introduced which are: speed of normal traffic in front of the emergency vehicle and travelling time of the emergency vehicle. The aim is that the emergency vehicle could reach a destination within a certain time and a constant speed. Moreover, the delay should be managed to a minimum. Linear and exponential acceleration formulas of the traffic in front of the emergency vehicle are derived and then validated. Performances of the model are tested against the models in the literature. Simulation results show the proposed model leads to better assurance that emergency vehicle is not delayed significantly. Based on the validation test, a formula has also been developed according to the proposed model. Copyright \u00a9 2019 Inderscience Enterprises Ltd.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Intelligent Transportation System (ITS) is the integration between communication networks, real-time control, and information technology. The system is expected to perform more complex traffic arrangements, in particular traffic management of emergency vehicles. Implementation with traffic signal pre-emption alone is not enough to give space for the emergency vehicle to cross an intersection safely, especially if the lane street has only one lane. The paper proposes a new model of traffic discharge acceleration based on queueing theory approach. In the proposed model, two performance indicators are introduced which are: speed of normal traffic in front of the emergency vehicle and travelling time of the emergency vehicle. The aim is that the emergency vehicle could reach a destination within a certain time and a constant speed. Moreover, the delay should be managed to a minimum. Linear and exponential acceleration formulas of the traffic in front of the emergency vehicle are derived and then validated. Performances of the model are tested against the models in the literature. Simulation results show the proposed model leads to better assurance that emergency vehicle is not delayed significantly. Based on the validation test, a formula has also been developed according to the proposed model. Copyright \u00a9 2019 Inderscience Enterprises Ltd."
        ]
    },
    {
        "judul":[
            "Modified-LRU algorithm for caching in named data network on mobile network"
        ],
        "penulis":"Kurniawan, Fandi Setio;Yovita, Leanna Vidya;Wibowo, Tody Ariefianto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "It is estimated that the annual internet network traffic will exceed the threshold of 3.3 zettabytes by 2021. However, internet architecture is currently inefficient to support the distribution of information-sharing content. Thus, a new internet architecture is designed, namely Named Data Network. Named Data Network (NDN) can store data that has been accessed by consumers in the content store so that when the data is requested by other consumers, it will be fast in distributing data. Nonetheless, it is not possible to store all the content in the content store. Optimization should be made, the existing optimization technique based on the replacement algorithm is Least Recent Used (LRU). However, LRU has a weakness, which only uses the latest reference time and cannot distinguish between frequent or rare objects that are being accessed. Previous research has been conducted on modified-LRU but only on fixed networks, while currently the majority of users use mobile networks, and the condition of mobile networks is very different from the condition of fixed networks. In this research, scenario 5 testing was carried out relating to packet ratio, delay, and packet drop on mobile networks. Modified-LRU show great improvement by the performance of the Hit ratio, 3.6% greater than the LRU, reducing delay by 19.67%, and packet drop by 94% better than LRU. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "It is estimated that the annual internet network traffic will exceed the threshold of 3.3 zettabytes by 2021. However, internet architecture is currently inefficient to support the distribution of information-sharing content. Thus, a new internet architecture is designed, namely Named Data Network. Named Data Network (NDN) can store data that has been accessed by consumers in the content store so that when the data is requested by other consumers, it will be fast in distributing data. Nonetheless, it is not possible to store all the content in the content store. Optimization should be made, the existing optimization technique based on the replacement algorithm is Least Recent Used (LRU). However, LRU has a weakness, which only uses the latest reference time and cannot distinguish between frequent or rare objects that are being accessed. Previous research has been conducted on modified-LRU but only on fixed networks, while currently the majority of users use mobile networks, and the condition of mobile networks is very different from the condition of fixed networks. In this research, scenario 5 testing was carried out relating to packet ratio, delay, and packet drop on mobile networks. Modified-LRU show great improvement by the performance of the Hit ratio, 3.6% greater than the LRU, reducing delay by 19.67%, and packet drop by 94% better than LRU. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "First evidence of the presence of genotype-1 of Japanese encephalitis virus in Culex gelidus in Indonesia"
        ],
        "penulis":"Garjito, Triwibowo Ambar;Prihatin, Mega Tyas;Susanti, Lulus;Prastowo, Dhian;Sa'Adah, Siti Rofiatus;Taviv, Yulian;Satoto, Tri Baskoro Tunggul;Waluyo, Joko;Manguin, Sylvie;Frutos, Roger;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Background: Japanese encephalitis has become a public health threat in Indonesia. Three genotypes have been recorded in Indonesia, i.e. genotype II (GII), genotype III (GIII) and genotype IV (GIV). Genotype I (GI) and genotype V (GV) have never been reported in Indonesia. Results: A Japanese encephalitis virus (JEV) belonging to the genotype I-a (GI-a) has been isolated for the first time from a Culex gelidus mosquito in the Province of Jambi, Indonesia. This virus is related to a 1983 isolate from Thailand whereas the infected Cx. gelidus mosquito belonged to a Chinese haplotype. Conclusions: Surveillance of JEV and mosquito dissemination is recommended. \u00a9 2019 The Author(s).",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Background: Japanese encephalitis has become a public health threat in Indonesia. Three genotypes have been recorded in Indonesia, i.e. genotype II (GII), genotype III (GIII) and genotype IV (GIV). Genotype I (GI) and genotype V (GV) have never been reported in Indonesia. Results: A Japanese encephalitis virus (JEV) belonging to the genotype I-a (GI-a) has been isolated for the first time from a Culex gelidus mosquito in the Province of Jambi, Indonesia. This virus is related to a 1983 isolate from Thailand whereas the infected Cx. gelidus mosquito belonged to a Chinese haplotype. Conclusions: Surveillance of JEV and mosquito dissemination is recommended. \u00a9 2019 The Author(s)."
        ]
    },
    {
        "judul":[
            "IoT based photovoltaic monitoring system application"
        ],
        "penulis":"Priharti W.;Rosmawati A.F.K.;Wibawa I.P.D.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Solar photovoltaic (PV) system has become the greatest attraction in the clean, renewable electricity generation. However, the performance is varying due to various parameters and environmental conditions. Hence, a remote and real-time monitoring system is needed to assess its performance. Implementation of the Internet of Things (IoT) in the monitoring of the solar PV system was proposed and its performance was studied. The system consists of data acquisition, data gateway, and smartphone application display. The data acquisition was successfully collect the data with 98.49% accuracy and was uploaded to the data gateway. The data gateway was able to send the graphical representation of the data to the smartphone application with a mean transmission time of 52.34 seconds. The results demonstrate that the proposed monitoring system can be a promising solution for intelligent remote and real-time monitoring of a solar PV system. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Solar photovoltaic (PV) system has become the greatest attraction in the clean, renewable electricity generation. However, the performance is varying due to various parameters and environmental conditions. Hence, a remote and real-time monitoring system is needed to assess its performance. Implementation of the Internet of Things (IoT) in the monitoring of the solar PV system was proposed and its performance was studied. The system consists of data acquisition, data gateway, and smartphone application display. The data acquisition was successfully collect the data with 98.49% accuracy and was uploaded to the data gateway. The data gateway was able to send the graphical representation of the data to the smartphone application with a mean transmission time of 52.34 seconds. The results demonstrate that the proposed monitoring system can be a promising solution for intelligent remote and real-time monitoring of a solar PV system. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Flowshop Scheduling with Drum-Buffer-Rope and CDS Algorithm to Minimize Lateness and Work in Process at PT. AKS"
        ],
        "penulis":"Viady A.S.;Suryadhini P.P.;Rendra M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In many years, the problem of lateness remains a problem for companies. This problem also occurs in textile company. At PT. AKS, one of the textile company, the lateness causes by bottleneck on one of their work station, which is Split Workstation, and the other caused by large unit load. The objective of this research is to minimize lateness by reducing the bottleneck and unit load. This research purposed a Drum-Buffer-Rope method and CDS algorithm to solve the problem. The constraint work station which is Split Workstation as the drum which is the control point of the whole system. The rope systematic which is backward scheduling applied at work stations before Split Workstation to minimize the queue time and to control the work in process. CDS Algorithm used in the interest of jobs sequencing to be processes after Split Workstation by using a forward scheduling. To solve the large unit load, we determine the unit load by trial and error. The result of this research manufacturing lead time decrease is by 61.88 percent from the current condition, queue time decrease is by 82.45 percent from current condition and the lateness decrease is by 35.71 percent from current condition. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In many years, the problem of lateness remains a problem for companies. This problem also occurs in textile company. At PT. AKS, one of the textile company, the lateness causes by bottleneck on one of their work station, which is Split Workstation, and the other caused by large unit load. The objective of this research is to minimize lateness by reducing the bottleneck and unit load. This research purposed a Drum-Buffer-Rope method and CDS algorithm to solve the problem. The constraint work station which is Split Workstation as the drum which is the control point of the whole system. The rope systematic which is backward scheduling applied at work stations before Split Workstation to minimize the queue time and to control the work in process. CDS Algorithm used in the interest of jobs sequencing to be processes after Split Workstation by using a forward scheduling. To solve the large unit load, we determine the unit load by trial and error. The result of this research manufacturing lead time decrease is by 61.88 percent from the current condition, queue time decrease is by 82.45 percent from current condition and the lateness decrease is by 35.71 percent from current condition. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Increasing the Capacity of Listega Based on Syllable Pattern Using Multicolumn and Bigram Mapping"
        ],
        "penulis":"Munzi, Gugy Guztaman;Barmawi, Ari Moesriami;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Due to the increasing use of internet, preserving confidentiality and integrity becomes important. One method for preserving them is steganography. There are two types of steganography, noisy and noiseless. One of noiseless steganography method is List Steganography based on syllable pattern proposed by David et al. Since List Steganography based on syllable pattern only embed one character into one column, then the capacity is still low. For increasing the capacity, the proposed method introduced embedding method for two columns where one column can be embedded with up to two characters (one bigram). The characters are embedded based on the syllable and code mapping. Syllable mapping is designed based on the occurrence frequency of syllable in the cover and English dictionary, while code mapping is designed based on the occurrence frequency of the code in the cover. Based on the experiment result, the embedding capacity using English secret message is increased with the rate of 17% to 55%. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Due to the increasing use of internet, preserving confidentiality and integrity becomes important. One method for preserving them is steganography. There are two types of steganography, noisy and noiseless. One of noiseless steganography method is List Steganography based on syllable pattern proposed by David et al. Since List Steganography based on syllable pattern only embed one character into one column, then the capacity is still low. For increasing the capacity, the proposed method introduced embedding method for two columns where one column can be embedded with up to two characters (one bigram). The characters are embedded based on the syllable and code mapping. Syllable mapping is designed based on the occurrence frequency of syllable in the cover and English dictionary, while code mapping is designed based on the occurrence frequency of the code in the cover. Based on the experiment result, the embedding capacity using English secret message is increased with the rate of 17% to 55%. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Price prediction of chili in bandung regency using support vector machine (SVM) optimized with an adaptive neuro-fuzzy inference system (ANFIS)"
        ],
        "penulis":"Nurcahyono, Asma Hasifa;Nhita, Fhira;Saepudin, Deni;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The price fluctuation of chili is one of the economic problems faced by every chili-producing country in the world, including in Indonesia. Chili is a vegetable that is consumed almost every day by the people of Indonesia. In Bandung district area, chili has been experiencing price fluctuations in the last four years, according to data obtained from the Bandung Regency Area Trade and Industry Service. Many factors cause the price of chili to fluctuate-one of them being the weather. This is because chili is a plant that is easily damaged if exposed to too much water. This research predicts chili prices in Bandung Regency using the Support Vector Machine (SVM) algorithm, which is optimized by an Adaptive Neuro-Fuzzy Inference System (ANFIS) and based on weather factors. The average accuracy of training and testing data was 94.07%; the training and testing data using the SVM algorithm produced 89.90% average accuracy and the average accuracy of training and testing data using the ANFIS algorithm was 92.68%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The price fluctuation of chili is one of the economic problems faced by every chili-producing country in the world, including in Indonesia. Chili is a vegetable that is consumed almost every day by the people of Indonesia. In Bandung district area, chili has been experiencing price fluctuations in the last four years, according to data obtained from the Bandung Regency Area Trade and Industry Service. Many factors cause the price of chili to fluctuate-one of them being the weather. This is because chili is a plant that is easily damaged if exposed to too much water. This research predicts chili prices in Bandung Regency using the Support Vector Machine (SVM) algorithm, which is optimized by an Adaptive Neuro-Fuzzy Inference System (ANFIS) and based on weather factors. The average accuracy of training and testing data was 94.07%; the training and testing data using the SVM algorithm produced 89.90% average accuracy and the average accuracy of training and testing data using the ANFIS algorithm was 92.68%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A review of edge image detection for marker-based augmented reality"
        ],
        "penulis":"Pandiangan, Samuel P.A.H.;Purboyo, Tito Waluyo;Saputra, Randy Erfa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The earlier way to do an image detecting is to use edge image detection. Edge image detection is using some kind of mathematical expression to detect the boundaries between objects between images in real world, with media like camera phone. Many aspects have used edge image detection, one of them is Augmented Reality, especially marker-based Augmented Reality. Augmented reality used edge image detection for reading and detecting the marker in real world and transfer the data to the database in application. This paper will review how the edge detection works and how it works in Augmented Reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The earlier way to do an image detecting is to use edge image detection. Edge image detection is using some kind of mathematical expression to detect the boundaries between objects between images in real world, with media like camera phone. Many aspects have used edge image detection, one of them is Augmented Reality, especially marker-based Augmented Reality. Augmented reality used edge image detection for reading and detecting the marker in real world and transfer the data to the database in application. This paper will review how the edge detection works and how it works in Augmented Reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Design and realization of node MCU module based on NB-IoT for general IoT purpose"
        ],
        "penulis":"Rasyad, Rifqi Muhammad;Murti, Muhammad Ary;Rizki, Ardianto P.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At present, the NB-IoT module has begun to be traded as one of the IoT devices. However, NB-IoT modules that are sold in the market are stand-alone modules or shields that require Arduino boards, so that in use they require wiring which can cause complicated and irregular, even wiring errors can occur. Therefore the purpose of this research is to design the NB-IoT module which has been integrated with a microcontroller unit (MCU), so that it is as practical as the NodeMCU module. The prototype design of the NB-IoT module uses the capstone design method, including PCB design and embedded systems also needed for implementing low power devices, then a specification test is performed with the result of power consumption obtained that with a 10,000mAh battery it can last for 5 days, with a cycle the work of 0.0575%, and the spectrum profile where the magnitude of the transmission power with an average of-15,804dBm, bandwidth with an average of 103.07 kHz at a measured frequency of 905.1 MHz. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At present, the NB-IoT module has begun to be traded as one of the IoT devices. However, NB-IoT modules that are sold in the market are stand-alone modules or shields that require Arduino boards, so that in use they require wiring which can cause complicated and irregular, even wiring errors can occur. Therefore the purpose of this research is to design the NB-IoT module which has been integrated with a microcontroller unit (MCU), so that it is as practical as the NodeMCU module. The prototype design of the NB-IoT module uses the capstone design method, including PCB design and embedded systems also needed for implementing low power devices, then a specification test is performed with the result of power consumption obtained that with a 10,000mAh battery it can last for 5 days, with a cycle the work of 0.0575%, and the spectrum profile where the magnitude of the transmission power with an average of-15,804dBm, bandwidth with an average of 103.07 kHz at a measured frequency of 905.1 MHz. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Hypnagogia based smart alarm system using PIR sensors"
        ],
        "penulis":"Nusantara, Fitrah Bima;Putrada, Aji Gautama;Abdurohman, Maman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposed a smart alarm system based on sleep hypnagogia phase. Hypnagogia phase is an almost wakeful phase or mild sleep state. Waking up in this phase causes people to feel refreshed. This phase is indicated by sudden body movements during sleep or changes in position during sleep. This phase can be detected automatically by a Passive Infrared (PIR) Sensor. In this paper smart alarm system designed to wake the user based on the hypnagogia phase. This system is equipped with LED screens, Real-Time Clock (RTC) modules, buzzers, Wi-Fi modules, and Wemos D1 Microcontrollers. Hypnagogia phase is calculated with a sleep phase detection algorithm that utilizes body movement data captured by the PIR Sensor. This system is designed to adjust the alarm time to the best moment based on the hypnagogic sleep phase that has been calculated. Through several tests, the results show that this system can awaken users with a higher success rate than conventional alarm systems. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposed a smart alarm system based on sleep hypnagogia phase. Hypnagogia phase is an almost wakeful phase or mild sleep state. Waking up in this phase causes people to feel refreshed. This phase is indicated by sudden body movements during sleep or changes in position during sleep. This phase can be detected automatically by a Passive Infrared (PIR) Sensor. In this paper smart alarm system designed to wake the user based on the hypnagogia phase. This system is equipped with LED screens, Real-Time Clock (RTC) modules, buzzers, Wi-Fi modules, and Wemos D1 Microcontrollers. Hypnagogia phase is calculated with a sleep phase detection algorithm that utilizes body movement data captured by the PIR Sensor. This system is designed to adjust the alarm time to the best moment based on the hypnagogic sleep phase that has been calculated. Through several tests, the results show that this system can awaken users with a higher success rate than conventional alarm systems. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Classification of premature ventricular contraction based on ECG signal using multiorder r\u00e9nyi entropy"
        ],
        "penulis":"Rizal, Achmad;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electrocardiogram (ECG) signals are commonly used to analyze the heart abnormalities. Many researchers used this method due to the simplicity, inexpensive, and the non-invasiveness of the devices. The basic concept of ECG is by measuring the electrical activity of the heart using non-invasive electrodes placed in the body. Premature ventricular contraction (PVC) is one of the abnormalities of the human heart which produce extra heartbeat that started in the two lower ventricles. This 'additional' heartbeat disrupts the regular heart rhythm. Early detection for PVC is essential, so in this research, we classify the PVC from ECG signal by using multi-order R\u00e9nyi entropy as the feature extraction, and SVM as the classifier. We search for the optimum feature number needed for the detection system. Our proposed method showed a promising result, because we only use one feature extraction parameter, that is R\u00e9nyi entropy, as the only feature which calculated in the different orders, and this made the computing complexity low. We got 95.8% of accuracy using six characteristics of entropy for PVC and normal ECG classification. Our proposed method was simple, low computation and need fewer number of features. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electrocardiogram (ECG) signals are commonly used to analyze the heart abnormalities. Many researchers used this method due to the simplicity, inexpensive, and the non-invasiveness of the devices. The basic concept of ECG is by measuring the electrical activity of the heart using non-invasive electrodes placed in the body. Premature ventricular contraction (PVC) is one of the abnormalities of the human heart which produce extra heartbeat that started in the two lower ventricles. This 'additional' heartbeat disrupts the regular heart rhythm. Early detection for PVC is essential, so in this research, we classify the PVC from ECG signal by using multi-order R\u00e9nyi entropy as the feature extraction, and SVM as the classifier. We search for the optimum feature number needed for the detection system. Our proposed method showed a promising result, because we only use one feature extraction parameter, that is R\u00e9nyi entropy, as the only feature which calculated in the different orders, and this made the computing complexity low. We got 95.8% of accuracy using six characteristics of entropy for PVC and normal ECG classification. Our proposed method was simple, low computation and need fewer number of features. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Improving the accuracy of fuzzy vault scheme in fingerprint biometric"
        ],
        "penulis":"Saputra, Joni;Sukarno, Parman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At present, authentication techniques using fingerprint biometrics have been widely used in various fields. This is because the authentication techniques using biometrics are safer and more comfortable than using traditional passwords. In order to realize this, a technique in the biometric cryptosystem is proposed in the research, called the fuzzy vault scheme. Although the fingerprint data in the form of minutiae can be protected with a fuzzy vault scheme compared to traditional authentication systems, it can reduce user convenience. Previous studies proposed a distance-based method in the fuzzy vault scheme. The distance-based method is proposed because it is no need to align and rotate the fingerprint image during registration or authentication. Then with the distance-based method also does not produce a helper data that can lead to information leakage that can be exploited by impostor. In the research, the distance-based method is proposed with several modifications, which are the minutiae filter and candidate points identification techniques. The previous method produces FRR 13.4375% and FAR 0.4515% and the proposed method produced FRR 8.9475% and FAR 0.3520%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At present, authentication techniques using fingerprint biometrics have been widely used in various fields. This is because the authentication techniques using biometrics are safer and more comfortable than using traditional passwords. In order to realize this, a technique in the biometric cryptosystem is proposed in the research, called the fuzzy vault scheme. Although the fingerprint data in the form of minutiae can be protected with a fuzzy vault scheme compared to traditional authentication systems, it can reduce user convenience. Previous studies proposed a distance-based method in the fuzzy vault scheme. The distance-based method is proposed because it is no need to align and rotate the fingerprint image during registration or authentication. Then with the distance-based method also does not produce a helper data that can lead to information leakage that can be exploited by impostor. In the research, the distance-based method is proposed with several modifications, which are the minutiae filter and candidate points identification techniques. The previous method produces FRR 13.4375% and FAR 0.4515% and the proposed method produced FRR 8.9475% and FAR 0.3520%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Recent development in electronic nose data processing for beef quality assessment"
        ],
        "penulis":"Sarno, Riyanarto;Wijaya, Dedy Rahman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Beef is kind of perishable food that easily to decay. Hence, a rapid system for beef quality assessment is needed to guarantee the quality of beef. In the last few years, electronic nose (e-nose) is developed for beef spoilage detection. In this paper, we discuss the challenges of e-nose application to beef quality assessment, especially in e-nose data processing. We also provide a summary of our previous studies that explains several methods to deal with gas sensor noise, sensor array optimization problem, beef quality classification, and prediction of the microbial population in beef sample. This paper might be useful for researchers and practitioners to understand the challenges and methods of e-nose data processing for beef quality assessment. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Beef is kind of perishable food that easily to decay. Hence, a rapid system for beef quality assessment is needed to guarantee the quality of beef. In the last few years, electronic nose (e-nose) is developed for beef spoilage detection. In this paper, we discuss the challenges of e-nose application to beef quality assessment, especially in e-nose data processing. We also provide a summary of our previous studies that explains several methods to deal with gas sensor noise, sensor array optimization problem, beef quality classification, and prediction of the microbial population in beef sample. This paper might be useful for researchers and practitioners to understand the challenges and methods of e-nose data processing for beef quality assessment. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Bit-parallelism score computation with multi integer weight"
        ],
        "penulis":"Setyorini;Kuspriyanto;Widyantoro, Dwi Hendratmo;Pancoro, Adi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Dynamic Programming (DP) is still the core algorithm in many biological analysis tools, especially similarity analysis. DP always promises optimal solutions, but as the size and number of sequences increase, time performance decreases. This makes various researches related to the improvement of time performance offered. Performance improvement is offered by adding process units that work together in parallel environments or reducing the accuracy by only calculating the input part. Bit-parallelism offers an increase in speed by changing the score matrix process unit to a larger process unit, namely word. Then this word unit will be processed in parallel like word processing on a computer system. Bit-parallelism has been successfully applied to cases with simple weights such as LCS and Edit Distance. Applications in more complex cases, namely with integer weights also exist, but still assume an integer weight for match representation. In the case of protein alignment where there is more than one integer value to represent the match of the residual pair, this solution cannot be applied directly. This paper presents a preliminary research on how to formulate a computational algorithm score bitparallelism with multi-integer weights. The solution offered is the development of General Integer scoring, by applying functional multi tables. The results show that the algorithm is able to obtain the same score matrix as the DP score matrix, with computing O(m), m is size of the sequence, and O(b) space where b is the range of integer set weights. \u00a9 2019, School of Electrical Engineering and Informatics. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Dynamic Programming (DP) is still the core algorithm in many biological analysis tools, especially similarity analysis. DP always promises optimal solutions, but as the size and number of sequences increase, time performance decreases. This makes various researches related to the improvement of time performance offered. Performance improvement is offered by adding process units that work together in parallel environments or reducing the accuracy by only calculating the input part. Bit-parallelism offers an increase in speed by changing the score matrix process unit to a larger process unit, namely word. Then this word unit will be processed in parallel like word processing on a computer system. Bit-parallelism has been successfully applied to cases with simple weights such as LCS and Edit Distance. Applications in more complex cases, namely with integer weights also exist, but still assume an integer weight for match representation. In the case of protein alignment where there is more than one integer value to represent the match of the residual pair, this solution cannot be applied directly. This paper presents a preliminary research on how to formulate a computational algorithm score bitparallelism with multi-integer weights. The solution offered is the development of General Integer scoring, by applying functional multi tables. The results show that the algorithm is able to obtain the same score matrix as the DP score matrix, with computing O(m), m is size of the sequence, and O(b) space where b is the range of integer set weights. \u00a9 2019, School of Electrical Engineering and Informatics. All rights reserved."
        ]
    },
    {
        "judul":[
            "Study on Multilayer em Wave Absorber Composed of Metasurface for X-band Application"
        ],
        "penulis":"Syihabuddin, Budi;Gunawan, Arief Hamdani;Effendi, Mohammad Ridwan;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In recent years, researches on electromagnetics (EM) wave absorber have been intensively investigated for numerous applications. One of essential issues in the EM wave absorber is the deficiency in its performance particularly bandwidth and absorption characteristics. In this paper, a multilayer EM wave absorber composed of metasurface is studied for X-band application. The utilization of metasurface and multilayer structures is aimed to enhance the characteristics of absorber in bandwidth and absorption performances. The structure of metasurface is configured by combining split ring resonator (SRR) and narrow thin strip deployed on different layers of 0.8mm thick FR4 epoxy dielectric substrate. The proposed EM wave absorber is characterized through its unit cell with the dimension of 3.80mm \u00d7 3.80mm. Some attempts by inserting another layer with varied thickness between the SRR layer and the narrow thin strip layer is performed to investigate the absorber characteristics. The characterization result shows that the insertion of another layer could improve the characteristics of proposed EM wave absorber. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In recent years, researches on electromagnetics (EM) wave absorber have been intensively investigated for numerous applications. One of essential issues in the EM wave absorber is the deficiency in its performance particularly bandwidth and absorption characteristics. In this paper, a multilayer EM wave absorber composed of metasurface is studied for X-band application. The utilization of metasurface and multilayer structures is aimed to enhance the characteristics of absorber in bandwidth and absorption performances. The structure of metasurface is configured by combining split ring resonator (SRR) and narrow thin strip deployed on different layers of 0.8mm thick FR4 epoxy dielectric substrate. The proposed EM wave absorber is characterized through its unit cell with the dimension of 3.80mm \u00d7 3.80mm. Some attempts by inserting another layer with varied thickness between the SRR layer and the narrow thin strip layer is performed to investigate the absorber characteristics. The characterization result shows that the insertion of another layer could improve the characteristics of proposed EM wave absorber. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "An Augmented Method of Selecting Fashion Talent by Adding Social Media Characteristic"
        ],
        "penulis":"Adilah, Dwita;Alamsyah, Andry;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Fashion model plays an important role in presenting designer's work by showing how the cut of fabric interplayed with the body. In selecting the fashion models, the agency considers physical characteristics that express the aesthetic. Another subjective advantage of fashion model is the appearance on professional network. However, the emerging of social media culture has revolutionized fashion industry in producing and consuming fashion. In term of fashion modelling, social media open the opportunities for talent to \"breaking in\" and \"getting discovered\". Prior research has dealt with predicting success based on social media presence. Thus, in this paper we construct additional social media activity to predict a fashion model success. We examine prediction using classification task by utilizing Random Forest and Support Vector Machine. Our research finds that social media activity improves the accuracy by 4.55% increasing up to 84.55% performed by Random Forest. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Fashion model plays an important role in presenting designer's work by showing how the cut of fabric interplayed with the body. In selecting the fashion models, the agency considers physical characteristics that express the aesthetic. Another subjective advantage of fashion model is the appearance on professional network. However, the emerging of social media culture has revolutionized fashion industry in producing and consuming fashion. In term of fashion modelling, social media open the opportunities for talent to \"breaking in\" and \"getting discovered\". Prior research has dealt with predicting success based on social media presence. Thus, in this paper we construct additional social media activity to predict a fashion model success. We examine prediction using classification task by utilizing Random Forest and Support Vector Machine. Our research finds that social media activity improves the accuracy by 4.55% increasing up to 84.55% performed by Random Forest. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Condition-based maintenance and spare parts provisioning based on markov chains"
        ],
        "penulis":"Nurhasanah H.;Ridwan A.Y.;Santosa B.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Machine is a vital tool of the company in helping the production process. Every company expects the production to run smoothly, but sometimes it is hampered by damage that happened to the machine, so that the production process is disrupted and causes losses to the company. Engine damage can be minimized by regularly evaluating the condition of the spare parts. In practice, if the spare parts inventory policy is not accurate it will cause stock outs or overstocks, which can lead to more costs for the company. The worst case is if there is no spare part stored in the warehouse when it is needed, it can make the production floor stopped, which in the end makes the company can't fulfil their production target. This research aims to obtain an optimal preventive maintenance schedule by calculating the machine's reliability and inventory provisioning policy for the spare parts according to predicted amount that will be needed in the future calculated using Markov chains so the company can determine the reorder point (r) and the economic order quantity (EOQ). \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Machine is a vital tool of the company in helping the production process. Every company expects the production to run smoothly, but sometimes it is hampered by damage that happened to the machine, so that the production process is disrupted and causes losses to the company. Engine damage can be minimized by regularly evaluating the condition of the spare parts. In practice, if the spare parts inventory policy is not accurate it will cause stock outs or overstocks, which can lead to more costs for the company. The worst case is if there is no spare part stored in the warehouse when it is needed, it can make the production floor stopped, which in the end makes the company can't fulfil their production target. This research aims to obtain an optimal preventive maintenance schedule by calculating the machine's reliability and inventory provisioning policy for the spare parts according to predicted amount that will be needed in the future calculated using Markov chains so the company can determine the reorder point (r) and the economic order quantity (EOQ). \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Study on Various Simple Power Tracking Methods for Thermoelectric Generator"
        ],
        "penulis":"Simatupang, Joni Welman;Purnama, Irwan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "For wireless sensor networks (WSN) applications, harvesting energy source is important since the sensor does not utilize power from the main power line. Among all harvesting energy sources, thermoelectric generator (TEG) becomes interesting because of its unlimited self-life (self-sufficient in energy). However, to maximize the TEG output power, then ratio between input resistance and load resistance should be maintained to be unity. For that purpose, this paper presents study on various simple power tracking such as perturbed and observe (PO), Incremental Conductance (INC) and Three-Point Weight Comparison (TPWC). Simulation results show that all methods can keep the TEG maximum power, but with different level of power oscillation at the maximum power point (MPP) \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "For wireless sensor networks (WSN) applications, harvesting energy source is important since the sensor does not utilize power from the main power line. Among all harvesting energy sources, thermoelectric generator (TEG) becomes interesting because of its unlimited self-life (self-sufficient in energy). However, to maximize the TEG output power, then ratio between input resistance and load resistance should be maintained to be unity. For that purpose, this paper presents study on various simple power tracking such as perturbed and observe (PO), Incremental Conductance (INC) and Three-Point Weight Comparison (TPWC). Simulation results show that all methods can keep the TEG maximum power, but with different level of power oscillation at the maximum power point (MPP) \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of advanced encryption standard for file security in stego-object"
        ],
        "penulis":"Yuliani S.Y.;Atmadja A.R.;Nurjanah Y.S.;Fauzy D.;Utomo R.G.;Nur D.R.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Security issues and data confidentiality are very important in the digital and internet era today. Important files circulating on the internet, both in the form of documents, images, and videos need to be supported with good security. This article aims to secure files by utilizing steganography technology, both in encryption and decryption of the file. The method used was the Advanced Encryption Standard (AES) which was applied to Stego-Object. Experiments were done on document files with extensions .doc, .xlsx, .pdf, and .txt, also on image files with extensions .jpeg, .png, and. bitmap. The experimental results showed that AES can encrypt and decrypt quite effectively without changing the quality of files both images and documents. This research could develop for video files. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Security issues and data confidentiality are very important in the digital and internet era today. Important files circulating on the internet, both in the form of documents, images, and videos need to be supported with good security. This article aims to secure files by utilizing steganography technology, both in encryption and decryption of the file. The method used was the Advanced Encryption Standard (AES) which was applied to Stego-Object. Experiments were done on document files with extensions .doc, .xlsx, .pdf, and .txt, also on image files with extensions .jpeg, .png, and. bitmap. The experimental results showed that AES can encrypt and decrypt quite effectively without changing the quality of files both images and documents. This research could develop for video files. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Seismic Data Compression Using Deep Neural Network Predictors"
        ],
        "penulis":"Nuha H.;Balghonaim A.;Mohandes M.;Liu, Bo;Fekri, Faramarz;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Seismic data compression is highly demanded to reduce the cost for transmission and storage due to an enormous volume of collected data. This paper presents a prediction based compression for seismic data using deep neural networks (DNN) and entropy encoding. First, a DNN with multiple hidden layers is pre-trained using restricted Boltzmann machines (RBMs) to obtain good initial weights. The DNN is then fine-tuned in a supervised fashion to achieve a better prediction precision. The residual between actual and predicted samples are quantized to achieve smaller data representation. The quantized residuals are further encoded using the Huffman coding. Our experiments with a real data set show that the DNN significantly outperforms the Linear Predictive Compression (LPC) in term of reconstruction quality. \u00a9 2019 SEG",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Seismic data compression is highly demanded to reduce the cost for transmission and storage due to an enormous volume of collected data. This paper presents a prediction based compression for seismic data using deep neural networks (DNN) and entropy encoding. First, a DNN with multiple hidden layers is pre-trained using restricted Boltzmann machines (RBMs) to obtain good initial weights. The DNN is then fine-tuned in a supervised fashion to achieve a better prediction precision. The residual between actual and predicted samples are quantized to achieve smaller data representation. The quantized residuals are further encoded using the Huffman coding. Our experiments with a real data set show that the DNN significantly outperforms the Linear Predictive Compression (LPC) in term of reconstruction quality. \u00a9 2019 SEG"
        ]
    },
    {
        "judul":[
            "Comparison between Dry, MQL, and cryogenic cooling technique on surface integrity of burnished surface"
        ],
        "penulis":"Rachmat, Haris;Mahalil, Khairuddin;Mohid, Zazuli;Rahim, Erween Abd;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Abstract: Environmental concerns has contributed towards higher demands for green products. Therefore, various machining conditions, such as dry and near dry machining have been introduced to resolve the cutting fluid problem. However, the application of cryogenic cooling still not well understood especially for burnishing process. It is essential to initiate a study on the effect of cryogenic cooling technique to substitute other techniques to improvement burnishing process. Carbon dioxide is used as the cryogenic gas under supercritical state, and compare with dry and minimal quantity lubricant. Solid carbide burnishing tool is used with a diameter and corner radius of 16 mm and 1 mm, respectively. The result shows that burnishing process under cryogenic condition recorded less burn mark and better tool wear than dry and MQL conditions. In addition, cryogenic condition exhibits significant grain refinement and surface hardness. In conclusion, the performance of carbon dioxide gas under supercritical state outperformed other coolant conditions. \u00a9 2019 UTHM Publisher. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Abstract: Environmental concerns has contributed towards higher demands for green products. Therefore, various machining conditions, such as dry and near dry machining have been introduced to resolve the cutting fluid problem. However, the application of cryogenic cooling still not well understood especially for burnishing process. It is essential to initiate a study on the effect of cryogenic cooling technique to substitute other techniques to improvement burnishing process. Carbon dioxide is used as the cryogenic gas under supercritical state, and compare with dry and minimal quantity lubricant. Solid carbide burnishing tool is used with a diameter and corner radius of 16 mm and 1 mm, respectively. The result shows that burnishing process under cryogenic condition recorded less burn mark and better tool wear than dry and MQL conditions. In addition, cryogenic condition exhibits significant grain refinement and surface hardness. In conclusion, the performance of carbon dioxide gas under supercritical state outperformed other coolant conditions. \u00a9 2019 UTHM Publisher. All rights reserved."
        ]
    },
    {
        "judul":[
            "Comparison of A\u2217 Algorithm and Time Bounded A\u2217 Algorithm on Maze Chase Game NPC"
        ],
        "penulis":"Putra, Fahryandi Herlasmara;Michrandi Nasution, Surya;Nugrahaeni, Ratna Astuti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The application of artificial intelligence in computer games has increased in recent years. Maze chase game is a game that takes place in a maze. The aim of the game is that the player must take all the points in the maze. Inside the labyrinth there are four Non-Playable Characters (NPCs) that move to chase the player. The shortest path algorithm is applied to the NPC in order to determine the shortest path from the current position of the NPC to the player position. In this study the author will compare the optimal level of path retrieval and the length of time needed in selecting the shortest path using the A\u2217 algorithm and the Time-Bounded A\u2217 algorithm. With the implementation of the A\u2217 algorithm and the TBA\u2217 algorithm on the Maze Chase game NPCs, the authors found that the A\u2217 algorithm has a faster travel time of 0.3% when compared to the TBA\u2217 algorithm, while the TBA\u2217 algorithm expands the nodes 73.2% less compared to the A\u2217 algorithm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The application of artificial intelligence in computer games has increased in recent years. Maze chase game is a game that takes place in a maze. The aim of the game is that the player must take all the points in the maze. Inside the labyrinth there are four Non-Playable Characters (NPCs) that move to chase the player. The shortest path algorithm is applied to the NPC in order to determine the shortest path from the current position of the NPC to the player position. In this study the author will compare the optimal level of path retrieval and the length of time needed in selecting the shortest path using the A\u2217 algorithm and the Time-Bounded A\u2217 algorithm. With the implementation of the A\u2217 algorithm and the TBA\u2217 algorithm on the Maze Chase game NPCs, the authors found that the A\u2217 algorithm has a faster travel time of 0.3% when compared to the TBA\u2217 algorithm, while the TBA\u2217 algorithm expands the nodes 73.2% less compared to the A\u2217 algorithm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Reasoning about the disruption patterns for train system using Bayesian Network and Prolog"
        ],
        "penulis":"Pradiawati, Yunita Rachma;Rusmawati, Yanti;Arzaki, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We construct a Prolog-based expert system to reason about the disruption patterns for train system using Bayesian network and Prolog. The disruptions dependencies are modeled using Bayesian network and the reasoning is carried on using Prolog. We choose Bayesian network because it is one of the most efficient and elegant framework to represent and reason probabilistic graphical model. The causative relationship among disruptions is represented using Directed Acyclic Graph (DAG). We use Prolog to improve the efficiency of the reasoning process by defining Bayesian network and its probabilistic information into a knowledge base. The causative relationships among disruptions are also modeled in terms of Prolog rules. Our Prolog-based expert system combines the statistical reasoning capability of Bayesian network and logic programming efficiency. The system provides comprehensive reasoning regarding the causative probability of events, the causative relationship among disruptions, as well as the most triggering and triggered disruptions in train system. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We construct a Prolog-based expert system to reason about the disruption patterns for train system using Bayesian network and Prolog. The disruptions dependencies are modeled using Bayesian network and the reasoning is carried on using Prolog. We choose Bayesian network because it is one of the most efficient and elegant framework to represent and reason probabilistic graphical model. The causative relationship among disruptions is represented using Directed Acyclic Graph (DAG). We use Prolog to improve the efficiency of the reasoning process by defining Bayesian network and its probabilistic information into a knowledge base. The causative relationships among disruptions are also modeled in terms of Prolog rules. Our Prolog-based expert system combines the statistical reasoning capability of Bayesian network and logic programming efficiency. The system provides comprehensive reasoning regarding the causative probability of events, the causative relationship among disruptions, as well as the most triggering and triggered disruptions in train system. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Sense of presence and learning satisfaction among students of different age groups in a 3-D virtual world"
        ],
        "penulis":"Rahman, Mohd Hishamuddin Abdul;Phon, Danakorn Nincarean Eh;Utama, Nur Ichsan;Yahaya, Noraffandy;Halim, Noor Dayana Abd;Kasim, Shahreen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Virtual worlds are growing in popularity very quickly. This growing popularity of 3-dimensional (3-D) virtual worlds has drawn attention from educationists. Today, 3-dimensional (3-D) virtual worlds are exploited for online and virtual learning. Unlike the common online learning platforms, a virtual world environment closely resembles a 3-D video games environment. Thus the age of students might affect their sense of presence, interaction, and satisfaction in the said environment. Hence this study was conducted to investigate whether there are differences between students of different age groups on their sense of presence (place presence, social presence, and co-presence) and their learning satisfaction. The study was carried out for six weeks and involved 33 part-time diploma students with the use of interview and questionnaires as instruments. In this study, the researcher developed our own 3-D virtual world, known as ViEW, by using the Open Wonderland open source virtual world program. A nonparametric Mann-Whitney U analysis was applied to explore the differences between young and senior participants in terms of their sense of place presence, social presence, co-presence, and learning satisfaction. The results indicated significant differences between young and senior students in terms of place presence, co-presence, and learning satisfaction, but no differences were identified for social presence. These results might be in regard with the means of conducted the learning, which were in the forms of cooperative and synchronous learning by utilizing audio communication most of the time. Several recommendations for future research related to the study were also provided. \u00a9 2019 Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Virtual worlds are growing in popularity very quickly. This growing popularity of 3-dimensional (3-D) virtual worlds has drawn attention from educationists. Today, 3-dimensional (3-D) virtual worlds are exploited for online and virtual learning. Unlike the common online learning platforms, a virtual world environment closely resembles a 3-D video games environment. Thus the age of students might affect their sense of presence, interaction, and satisfaction in the said environment. Hence this study was conducted to investigate whether there are differences between students of different age groups on their sense of presence (place presence, social presence, and co-presence) and their learning satisfaction. The study was carried out for six weeks and involved 33 part-time diploma students with the use of interview and questionnaires as instruments. In this study, the researcher developed our own 3-D virtual world, known as ViEW, by using the Open Wonderland open source virtual world program. A nonparametric Mann-Whitney U analysis was applied to explore the differences between young and senior participants in terms of their sense of place presence, social presence, co-presence, and learning satisfaction. The results indicated significant differences between young and senior students in terms of place presence, co-presence, and learning satisfaction, but no differences were identified for social presence. These results might be in regard with the means of conducted the learning, which were in the forms of cooperative and synchronous learning by utilizing audio communication most of the time. Several recommendations for future research related to the study were also provided. \u00a9 2019 Insight Society."
        ]
    },
    {
        "judul":[
            "The Role Of Stakeholder Relations In Building Brand Awareness Study On Consumed Media Feedme Id"
        ],
        "penulis":"Damayasih, Nadiya;Mahes, Gayes;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research aimed to know the role of stakeholder relations in building brand awareness (study on consumed media feedme.id). The research method used for this study was qualitative and the methods of collecting data obtained by observation and structured interview as primary data and secondary data from literature study and company document. Analysis of data used coding data. The validity of data used t riangulation of data source. This research shows that the role of stakeholder relations in building brand awareness is to maintaining relations with consumed media relations feedme.id, otherwise stakeholder relations is doing consumer, client, and media relations on Consumed Media Feedme.id. \u00a9 2019 International Journal of Scientific and Technology Research. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research aimed to know the role of stakeholder relations in building brand awareness (study on consumed media feedme.id). The research method used for this study was qualitative and the methods of collecting data obtained by observation and structured interview as primary data and secondary data from literature study and company document. Analysis of data used coding data. The validity of data used t riangulation of data source. This research shows that the role of stakeholder relations in building brand awareness is to maintaining relations with consumed media relations feedme.id, otherwise stakeholder relations is doing consumer, client, and media relations on Consumed Media Feedme.id. \u00a9 2019 International Journal of Scientific and Technology Research. All rights reserved."
        ]
    },
    {
        "judul":[
            "Rule based pattern type of verb identification algorithm for the Holy Qur'an"
        ],
        "penulis":"Ramadhan, Teguh Ikhlas;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes an algorithm for identification of pattern type of verb in classical Arabic. This topic was proposed because of the problem on Arabic Al-Qur'an annotation is an important task. It is important for the processing of the Holy Qur'an data, and provides convenience for those who want to learn Arabic, especially understanding arabic on morphology aspect. Understanding verb is the first step to understand the arabic morphology. The effort is to recognize how the rules regarding the pattern type of verb with the rule based approach read the pattern with prefix, the diacritics and the suffix if the verb. Briefly entered verb (Arabic or transliteration) and its output is an attribute of verb which is pattern type of verb, pronouns and verb pattern with the main rule that is identifying pattern, getting verb attributes and determining verb pattern. Experiments show that the proposed algorithm obtained accuracy at 96.48% with soft calculation method and 89.46% with harsh method calculation method. \u00a9 2019 The Authors. Published by Elsevier B.V.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes an algorithm for identification of pattern type of verb in classical Arabic. This topic was proposed because of the problem on Arabic Al-Qur'an annotation is an important task. It is important for the processing of the Holy Qur'an data, and provides convenience for those who want to learn Arabic, especially understanding arabic on morphology aspect. Understanding verb is the first step to understand the arabic morphology. The effort is to recognize how the rules regarding the pattern type of verb with the rule based approach read the pattern with prefix, the diacritics and the suffix if the verb. Briefly entered verb (Arabic or transliteration) and its output is an attribute of verb which is pattern type of verb, pronouns and verb pattern with the main rule that is identifying pattern, getting verb attributes and determining verb pattern. Experiments show that the proposed algorithm obtained accuracy at 96.48% with soft calculation method and 89.46% with harsh method calculation method. \u00a9 2019 The Authors. Published by Elsevier B.V."
        ]
    },
    {
        "judul":[
            "The effects of augmented reality interaction techniques on egocentric distance estimation accuracy"
        ],
        "penulis":"Lin, Chiuhsiang Joe;Caesaron, Dino;Woldegiorgis, Bereket Haile;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Recent developments in virtual environment applications allow users to interact with three-dimensional (3D) objects in virtual environments. As interaction with 3D objects in virtual environments becomes more established, it is important to investigate user performance with such interaction techniques within a specific task. This study investigated two interaction modes, direct and indirect, depending on how the users interacted with the 3D objects, by measuring the accuracy of egocentric distance estimation in a stereoscopic environment. Fourteen participants were recruited to perform an acquisition task with both direct pointing and indirect cursor techniques at three egocentric distances and three task diffculty levels. The accuracy of the egocentric distance estimation, throughput, and task completion time were analyzed for each interaction technique. The indirect cursor technique was found to be more accurate than the direct pointing one. On the other hand, a higher throughput was observed with the direct pointing technique than with the indirect cursor technique. However, there were no significant differences in task completion time between the two interaction techniques. The results also showed accuracy to be higher at the greatest distance (150 cm from the participant) than at the closer distances of 90 cm and 120 cm. Furthermore, the diffculty of the task also significantly affected the accuracy, with accuracy lower in the highest diffculty condition than in the medium and low diffculty conditions. The findings of this study contribute to the understanding of user-interaction techniques in a stereoscopic environment. Furthermore, developers of virtual environments may refer to these findings in designing effective user interactions, especially those in which performance relies on accuracy. \u00a9 2019 by the authors. Licensee MDPI, Basel, Switzerland.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recent developments in virtual environment applications allow users to interact with three-dimensional (3D) objects in virtual environments. As interaction with 3D objects in virtual environments becomes more established, it is important to investigate user performance with such interaction techniques within a specific task. This study investigated two interaction modes, direct and indirect, depending on how the users interacted with the 3D objects, by measuring the accuracy of egocentric distance estimation in a stereoscopic environment. Fourteen participants were recruited to perform an acquisition task with both direct pointing and indirect cursor techniques at three egocentric distances and three task diffculty levels. The accuracy of the egocentric distance estimation, throughput, and task completion time were analyzed for each interaction technique. The indirect cursor technique was found to be more accurate than the direct pointing one. On the other hand, a higher throughput was observed with the direct pointing technique than with the indirect cursor technique. However, there were no significant differences in task completion time between the two interaction techniques. The results also showed accuracy to be higher at the greatest distance (150 cm from the participant) than at the closer distances of 90 cm and 120 cm. Furthermore, the diffculty of the task also significantly affected the accuracy, with accuracy lower in the highest diffculty condition than in the medium and low diffculty conditions. The findings of this study contribute to the understanding of user-interaction techniques in a stereoscopic environment. Furthermore, developers of virtual environments may refer to these findings in designing effective user interactions, especially those in which performance relies on accuracy. \u00a9 2019 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "K-nearest neighbour classification and feature extraction GLCM for identification of terry's nail"
        ],
        "penulis":"Safira, Laura;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nails have a function or role that is very important to protect the soft fingertips and have a lot of nerves. In the medical world, several expert systems have begun to be used in helping doctors to diagnose a disease. This research was to detect abnormalities of the nails, Terry's nail. The textural characteristics are processed with grey level co-occurrence matrix (GLCM) and classifying method using KNN. The dataset in this study is taken from Google and also some of the paper that discusses the nail abnormalities. Nail pictures obtained are different from any source. Therefore, the image should be cut just one finger. Because when detecting terry's nail, the disorder usually occurs in all the nails. So we can use one finger. The photos of a nail that has been doing the extraction characteristics using GLCM then will be done using KNN classification. In this case the class will be divided into two classes, healthy and Terry's. From the experiment that have been done, the best accuracy results are 70.93% with 60-40 partition of dataset, K=1, light intensity values of 100-500 lux, a distance of 15 cm and an angle of 0\u00b0. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nails have a function or role that is very important to protect the soft fingertips and have a lot of nerves. In the medical world, several expert systems have begun to be used in helping doctors to diagnose a disease. This research was to detect abnormalities of the nails, Terry's nail. The textural characteristics are processed with grey level co-occurrence matrix (GLCM) and classifying method using KNN. The dataset in this study is taken from Google and also some of the paper that discusses the nail abnormalities. Nail pictures obtained are different from any source. Therefore, the image should be cut just one finger. Because when detecting terry's nail, the disorder usually occurs in all the nails. So we can use one finger. The photos of a nail that has been doing the extraction characteristics using GLCM then will be done using KNN classification. In this case the class will be divided into two classes, healthy and Terry's. From the experiment that have been done, the best accuracy results are 70.93% with 60-40 partition of dataset, K=1, light intensity values of 100-500 lux, a distance of 15 cm and an angle of 0\u00b0. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Selection of Vape Sensing Features in IoT-Based Gas Monitoring with Feature Importance Techniques"
        ],
        "penulis":"Saputra, Edy Syuryawan;Putrada, Aji Gautama;Abdurohman, Maman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Current smoke detection sensors are not designed to specifically detect vape smoke, resulting in ambiguity in decision making. Vape and cigarette smoke are different from each other, cigarette smoke is the result of burning from tobacco, while vape smoke comes from heating liquids that produce steam in the form of smoke. Therefore, researches have been directed to design a smart device that can detect vape smoke by combining multiple gas sensors, for example a MQ2 gas sensor, a MQ7 gas sensor, and a temperature and humidity sensor connected to the microcontroller. Previous tests have returned bad accuracy in detecting Vape. To evaluate that problem, this research proposes feature importance technique to select the appropriate sensor to detect vape smoke by providing a value for each sensor according to the effect on the outcome of the decision. For classification, a random forests method is used that matches the feature importance and firebase as storage media. By using these devices and methods, the sensor is suitable to detect vape smoke so that it gets an accuracy of 94.44% \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Current smoke detection sensors are not designed to specifically detect vape smoke, resulting in ambiguity in decision making. Vape and cigarette smoke are different from each other, cigarette smoke is the result of burning from tobacco, while vape smoke comes from heating liquids that produce steam in the form of smoke. Therefore, researches have been directed to design a smart device that can detect vape smoke by combining multiple gas sensors, for example a MQ2 gas sensor, a MQ7 gas sensor, and a temperature and humidity sensor connected to the microcontroller. Previous tests have returned bad accuracy in detecting Vape. To evaluate that problem, this research proposes feature importance technique to select the appropriate sensor to detect vape smoke by providing a value for each sensor according to the effect on the outcome of the decision. For classification, a random forests method is used that matches the feature importance and firebase as storage media. By using these devices and methods, the sensor is suitable to detect vape smoke so that it gets an accuracy of 94.44% \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Array Antenna for Doppler Spread Compensator on High Speed Railway"
        ],
        "penulis":"Anbela, Dano Seto;Anwar, Khoirul;Yunita, Trasma;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Train movements on the high speed railway causes signal damage due to the Doppler effect. In this situation, The Doppler Spread Compensator (DSC) technique plays an important role in the rapid train technology. This paper proposes an array antenna as DSC. The antenna is designed based on a rectangular patch microstrip array antenna for high speed railway. As a Doppler spread compensator, antennas is designed for the Future Railway for Mobile Communication System technology (FRMCS). The material used on the substrate is FR4 Epoxy and the ground plane and patch using copper. The antenna is designed to have a large dimension suitable for covering along the train. The realization of the antenna was good enough. The simulated and measured results of the antenna, such as magnitude of the reflection coefficient (S11), Gain, and Radiation Patterns are all presented in this paper. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Train movements on the high speed railway causes signal damage due to the Doppler effect. In this situation, The Doppler Spread Compensator (DSC) technique plays an important role in the rapid train technology. This paper proposes an array antenna as DSC. The antenna is designed based on a rectangular patch microstrip array antenna for high speed railway. As a Doppler spread compensator, antennas is designed for the Future Railway for Mobile Communication System technology (FRMCS). The material used on the substrate is FR4 Epoxy and the ground plane and patch using copper. The antenna is designed to have a large dimension suitable for covering along the train. The realization of the antenna was good enough. The simulated and measured results of the antenna, such as magnitude of the reflection coefficient (S11), Gain, and Radiation Patterns are all presented in this paper. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Patient necessity notification system based on gesture recognition (Kinect V2) and internet of things using selection frame method"
        ],
        "penulis":"Febriansyah F.;Suwastika N.A.;Fakhrurroja H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The use of gesture recognition integrated with Internet of Things (IoT) as a system for detecting patient needs provides information speed and accuracy for nurses. One tool that is widely used to implement gesture recognition is Kinect (Version 2). For data communication, Kinect will be collaborated with IoT in the process of sending data from the start after gesture recognition to the presentation of information to end users. The problem that arises when Kinect is integrated with IoT is the burden on the network because the average number of frames read by Kinect in one second is 30 frames. In this study, a frame selection method was developed to minimize the number of frames sent to IoT networks by minimizing the number of duplicate frames. The selection frame method on gesture recognition integrated with IoT is then tested for performance with distance and delay parameters. The system implementation results are able to read 100% gesture recognition, and the accuracy of the information sent by the nurse is 100% in the testing environment. The optimal distance that can provide a reading of more than 95% is 2.5 meters. The optimal value of 100% is not achieved because some testing of the falling position cannot read the whole skeleton. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of gesture recognition integrated with Internet of Things (IoT) as a system for detecting patient needs provides information speed and accuracy for nurses. One tool that is widely used to implement gesture recognition is Kinect (Version 2). For data communication, Kinect will be collaborated with IoT in the process of sending data from the start after gesture recognition to the presentation of information to end users. The problem that arises when Kinect is integrated with IoT is the burden on the network because the average number of frames read by Kinect in one second is 30 frames. In this study, a frame selection method was developed to minimize the number of frames sent to IoT networks by minimizing the number of duplicate frames. The selection frame method on gesture recognition integrated with IoT is then tested for performance with distance and delay parameters. The system implementation results are able to read 100% gesture recognition, and the accuracy of the information sent by the nurse is 100% in the testing environment. The optimal distance that can provide a reading of more than 95% is 2.5 meters. The optimal value of 100% is not achieved because some testing of the falling position cannot read the whole skeleton. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Quality of service (QoS) comparison analysis of snort IDS and Bro IDS application in software define network (SDN) architecture"
        ],
        "penulis":"Hendrawan, Hendrawan;Sukarno, Parman;Nugroho, Muhammad Arief;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Intrusion Detection system (IDS) was an application which was aimed to monitor network activity or system and it could find if there was a dangerous operation. Implementation of IDS on Software Define Network architecture (SDN) has drawbacks. IDS on SDN architecture might decreasing network Quality of Service (QoS). So the network could not provide services to the existing network traffic. Throughput, delay and packet loss were important parameters of QoS measurement. Snort IDS and bro IDS were tools in the application of IDS on the network. Both had differences, one of which was found in the detection method. Snort IDS used a signature based detection method while bro IDS used an anomaly based detection method. The difference between them had effects in handling the network traffic through it. In this research, we compared both tools. This comparison are done with testing parameters such as throughput, delay, packet loss, CPU usage, and memory usage. From this test, it was found that bro outperform snort IDS for throughput, delay, and packet loss parameters. However, CPU usage and memory usage on bro requires higher resource than snort. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Intrusion Detection system (IDS) was an application which was aimed to monitor network activity or system and it could find if there was a dangerous operation. Implementation of IDS on Software Define Network architecture (SDN) has drawbacks. IDS on SDN architecture might decreasing network Quality of Service (QoS). So the network could not provide services to the existing network traffic. Throughput, delay and packet loss were important parameters of QoS measurement. Snort IDS and bro IDS were tools in the application of IDS on the network. Both had differences, one of which was found in the detection method. Snort IDS used a signature based detection method while bro IDS used an anomaly based detection method. The difference between them had effects in handling the network traffic through it. In this research, we compared both tools. This comparison are done with testing parameters such as throughput, delay, packet loss, CPU usage, and memory usage. From this test, it was found that bro outperform snort IDS for throughput, delay, and packet loss parameters. However, CPU usage and memory usage on bro requires higher resource than snort. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Alignment Recovery for General Integer Scoring"
        ],
        "penulis":"Setyorini;Kuspriyanto;Widyantoro, Dwi H.;Pancoro, Adi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Alignment recovery is the process of recovering optimal alignment results based on weighted computational scores. Alignment recovery in classical dynamic programming (DP) is obtained by backtracking a trace created in the computational scoring phase. Bit parallelism is a parallel computing technique done by increasing the size of the word processing unit. The actual value of the score in the DP matrix is replaced by the difference of the adjacent matrix cell values. This requires adjustment of the scoring computation and its alignment recovery mechanism, especially for integer weights. General integer scoring involves a set of integers as its weights in bit-parallelism score computation that are not yet accompanied by alignment recovery. This paper presents an algorithm to recover the final alignment results from interpreting the horizontal and vertical adjacent-cell bit parallelism score values. The results show that the algorithm produces the same match pair result as the classical backtracking DP algorithm with less gap insertion. The algorithm requires O(m) space and time. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Alignment recovery is the process of recovering optimal alignment results based on weighted computational scores. Alignment recovery in classical dynamic programming (DP) is obtained by backtracking a trace created in the computational scoring phase. Bit parallelism is a parallel computing technique done by increasing the size of the word processing unit. The actual value of the score in the DP matrix is replaced by the difference of the adjacent matrix cell values. This requires adjustment of the scoring computation and its alignment recovery mechanism, especially for integer weights. General integer scoring involves a set of integers as its weights in bit-parallelism score computation that are not yet accompanied by alignment recovery. This paper presents an algorithm to recover the final alignment results from interpreting the horizontal and vertical adjacent-cell bit parallelism score values. The results show that the algorithm produces the same match pair result as the classical backtracking DP algorithm with less gap insertion. The algorithm requires O(m) space and time. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Comparative Study of Business-to-Government Information Sharing Arrangements for Tax Reporting"
        ],
        "penulis":"Kurnia, Rizky Amalia;Praditya, Dhata;Janssen, Marijn;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Having tax transparency is getting more important and enforced by more and more countries around the world. To deal with tax evasion, OECD has developed an Automatic Exchange of Information (AEOI) standard. The implementation of this standard differs among countries. In this study, we explore factors explaining the differences between two information sharing arrangements in implementing the AEOI standard. In both cases, the information sharing architecture and the accompanying governance arrangement are investigated. The findings of the exploratory study show that the differences are influenced by available IT capabilities, interoperability, trust among information sharing partners, power difference, inter-organizational relationship, and perceived benefits of implementing such arrangements. Ten propositions are derived explaining the differences which can be tested in further research. \u00a9 2019, IFIP International Federation for Information Processing.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Having tax transparency is getting more important and enforced by more and more countries around the world. To deal with tax evasion, OECD has developed an Automatic Exchange of Information (AEOI) standard. The implementation of this standard differs among countries. In this study, we explore factors explaining the differences between two information sharing arrangements in implementing the AEOI standard. In both cases, the information sharing architecture and the accompanying governance arrangement are investigated. The findings of the exploratory study show that the differences are influenced by available IT capabilities, interoperability, trust among information sharing partners, power difference, inter-organizational relationship, and perceived benefits of implementing such arrangements. Ten propositions are derived explaining the differences which can be tested in further research. \u00a9 2019, IFIP International Federation for Information Processing."
        ]
    },
    {
        "judul":[
            "Tracking telemetry and command using software defined radio with nano-satellite parameters"
        ],
        "penulis":"Wangsa, Damas Wicaksi;Syihabuddin, Budi;Edwar;Wijanto, Heroe;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Ground station is satellite sub-system for satellite communication. It has several functions such as master station and Telemetry, Tracking, and Command (TT&C). Developing a ground station is expensive but it can be reduced by using Software Defined Radio (SDR). We use SDR because it is easily to reconfigure based on system requirement. Simulation process using GNU radio and implementation using HackRF. In this paper use two scenario for design and testing. First scenario for validating the simulation process and second scenario for testing TT&C performance using SDR. The scenarios use text and image file as basic data. It transmit 2.7 kB text file and 11.5kB image file and received respectively 2.23 kB and 11.15 kB. In first scenario, there are 1.2 errors for text file and 2.3 errors for image file and in second scenario there are 5.2 errors for text file and 25.9 errors. \u00a9 2019 IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ground station is satellite sub-system for satellite communication. It has several functions such as master station and Telemetry, Tracking, and Command (TT&C). Developing a ground station is expensive but it can be reduced by using Software Defined Radio (SDR). We use SDR because it is easily to reconfigure based on system requirement. Simulation process using GNU radio and implementation using HackRF. In this paper use two scenario for design and testing. First scenario for validating the simulation process and second scenario for testing TT&C performance using SDR. The scenarios use text and image file as basic data. It transmit 2.7 kB text file and 11.5kB image file and received respectively 2.23 kB and 11.15 kB. In first scenario, there are 1.2 errors for text file and 2.3 errors for image file and in second scenario there are 5.2 errors for text file and 25.9 errors. \u00a9 2019 IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Path Reference Generation for Upper-Limb Rehabilitation with Kinematic Model"
        ],
        "penulis":"Barri, Muhammad Hablul;Widyotriatmo, Augie;Suprijanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "An upper-limb kinematic model is studied for generating a path reference for rehabilitation. An eight-degrees-of-freedom (8-DOF) model of the upper-limb is presented and a path reference is generated based on the model. The path reference is generated with regards to the subject parameters, such as the length from the chest to shoulder, the length of upper arm, and the length of lower arm that can be implemented for individual subjects. Different with trajectory generation, the time is not considered when a subject is asked to follow the desired movement. In other words, the subject needs to follow an ideal movement with no constraints to the time when a configuration of upper-limb should be achieved. The implementation of the path reference generation and the comparison between the path reference and the actual measurement of a healthy subject is conducted performing shoulder forward flexion motion. The result shows the potential use of the proposed method for upper limb rehabilitation. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An upper-limb kinematic model is studied for generating a path reference for rehabilitation. An eight-degrees-of-freedom (8-DOF) model of the upper-limb is presented and a path reference is generated based on the model. The path reference is generated with regards to the subject parameters, such as the length from the chest to shoulder, the length of upper arm, and the length of lower arm that can be implemented for individual subjects. Different with trajectory generation, the time is not considered when a subject is asked to follow the desired movement. In other words, the subject needs to follow an ideal movement with no constraints to the time when a configuration of upper-limb should be achieved. The implementation of the path reference generation and the comparison between the path reference and the actual measurement of a healthy subject is conducted performing shoulder forward flexion motion. The result shows the potential use of the proposed method for upper limb rehabilitation. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Evolving Customer Experience Management in Internet Service Provider Company using Text Analytics"
        ],
        "penulis":"Alamsyah, Andry;Bernatapi, Earlyan Abdiel;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Customer experience is of crucial significance to the constant growth of a business. It is necessary to ensure great customer experience, thus maintaining customer loyalty and satisfaction. An approach that intended to develop and improve customer experience is called Customer Experience Management (CEM). CEM is a strategy practiced to track, supervise, and arrange all synergy to help a business focal point on the needs of its customers. This research uses sentiment analysis and topic modeling to analyze the experience of Internet Service Provider customers. The output of this research expected to drive the strategies change in CEM. This research uses data taken from customer tweets on Twitter. It is considering that the data on social media is enormous and unstructured. Therefore, classification using Naive Bayes Classifier applied to assist and expedite in the sentiment analysis process. The classification for sentiment analysis using NBC gained accuracy above 82%. Hence, the classification models using NBC achieve excellent capability for sentiment analysis. To determining topics that often discussed by customers, this research uses the Latent Dirichlet Allocation models for Topic Modeling. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Customer experience is of crucial significance to the constant growth of a business. It is necessary to ensure great customer experience, thus maintaining customer loyalty and satisfaction. An approach that intended to develop and improve customer experience is called Customer Experience Management (CEM). CEM is a strategy practiced to track, supervise, and arrange all synergy to help a business focal point on the needs of its customers. This research uses sentiment analysis and topic modeling to analyze the experience of Internet Service Provider customers. The output of this research expected to drive the strategies change in CEM. This research uses data taken from customer tweets on Twitter. It is considering that the data on social media is enormous and unstructured. Therefore, classification using Naive Bayes Classifier applied to assist and expedite in the sentiment analysis process. The classification for sentiment analysis using NBC gained accuracy above 82%. Hence, the classification models using NBC achieve excellent capability for sentiment analysis. To determining topics that often discussed by customers, this research uses the Latent Dirichlet Allocation models for Topic Modeling. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Designing Procurement Process Monitoring Dashboard for Supporting Food Security Supply Chain Risk Management System in Indonesian Bureau of Logistics"
        ],
        "penulis":"Alfazah, Detha Aulia;Yanuar Ridwan, Ari;Yulianti, Femi;Artha Kusuma, Putu Giri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Rice as one of the main and important commodities because it can affect the economic stability in Indonesia. Indonesian Bureau of Logistics (BULOG) is a company under Indonesian Government which is responsible to manage the distribution of the Rice Commodity. BULOG Subdivre Bandung is one of the Regional Sub-Divisions located under the auspices of BULOG. Rice Commodity procurement process is the most crucial process. The high linkage of the supply chain network could make it suspectible with risk. If the procurement process of rice commodities BULOG disturbed can certainly affect the pillars of Food Security. Therefore, risk management and mitigation strategies are required in the procurement process. In this paper, strategy mitigation is formulated and monitoring dashboard is designed to maintain and monitorING the risks on procurement process of rice commodities using the Supply Chain Operation Reference (SCOR) Method, Failure Mode and Effect Analysis (FMEA) Method and Analytical Hierarchy Process(AHP). The result of the risk-identifying results gained in the field and interviews with experts there are 12 risk events and 16 risk causes divided by three pillars of food security and for mitigation strategies divided into 3 main causes with 3 Alternative to any major cause. The most risk event which should have mitigation first is low grain absorption with 0.55092 in AHP weighting. The designed monitoring dashboard was able to provide a compact summary and shows the risks which effect the pillars of Food Security. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentZero hungerGoal 2",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rice as one of the main and important commodities because it can affect the economic stability in Indonesia. Indonesian Bureau of Logistics (BULOG) is a company under Indonesian Government which is responsible to manage the distribution of the Rice Commodity. BULOG Subdivre Bandung is one of the Regional Sub-Divisions located under the auspices of BULOG. Rice Commodity procurement process is the most crucial process. The high linkage of the supply chain network could make it suspectible with risk. If the procurement process of rice commodities BULOG disturbed can certainly affect the pillars of Food Security. Therefore, risk management and mitigation strategies are required in the procurement process. In this paper, strategy mitigation is formulated and monitoring dashboard is designed to maintain and monitorING the risks on procurement process of rice commodities using the Supply Chain Operation Reference (SCOR) Method, Failure Mode and Effect Analysis (FMEA) Method and Analytical Hierarchy Process(AHP). The result of the risk-identifying results gained in the field and interviews with experts there are 12 risk events and 16 risk causes divided by three pillars of food security and for mitigation strategies divided into 3 main causes with 3 Alternative to any major cause. The most risk event which should have mitigation first is low grain absorption with 0.55092 in AHP weighting. The designed monitoring dashboard was able to provide a compact summary and shows the risks which effect the pillars of Food Security. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Automated Bahasa Indonesia essay evaluation with latent semantic analysis"
        ],
        "penulis":"Amalia A.;Gunawan D.;Fithri Y.;Aulia I.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Essay Examination is one of many ways to evaluate the learning process of students. The Essay test can measure a student's capability of memory and to develop an idea. With the vast development of Information Technology, an essay test is done in a more sophisticated way with a platform called e-learning. This research implemented an e-learning interface to conduct an essay test, starting with giving out questions, answering it and marking it. The system will generate an automatic mark, using the Latent Semantic Analysis (LSA) method by measuring the relevance of the key answer and the student's answer. Before entering the LSA phase, the answer will go through pre-processing step which is cleansing, case folding, tokenization, stop word, convert negation and stemming. The result of the accuracy of this system compared to teacher's manual assessment is 83.3%. Expectedly, this research will help teachers in making their assessment process more efficient. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Essay Examination is one of many ways to evaluate the learning process of students. The Essay test can measure a student's capability of memory and to develop an idea. With the vast development of Information Technology, an essay test is done in a more sophisticated way with a platform called e-learning. This research implemented an e-learning interface to conduct an essay test, starting with giving out questions, answering it and marking it. The system will generate an automatic mark, using the Latent Semantic Analysis (LSA) method by measuring the relevance of the key answer and the student's answer. Before entering the LSA phase, the answer will go through pre-processing step which is cleansing, case folding, tokenization, stop word, convert negation and stemming. The result of the accuracy of this system compared to teacher's manual assessment is 83.3%. Expectedly, this research will help teachers in making their assessment process more efficient. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Efficiency Optimization for Single-Phase Voltage-Sourced Inverter with ZVS-CV"
        ],
        "penulis":"Chi, Pei-Chin;Purnama, Irwan;Chang, Yu-Chen;Chiu, Huang-Jen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Metal-oxide-semiconductor field-effect transistor (MOSFET) can be utilized to raise switching frequency (SF) while zero voltage switching-clamped voltage (ZVS-CV) is a simple technique to eliminate switching loss without extra resonant circuit. Then, heat sink and filter can both be so shrunk that compact inverter can fit the single-phase system in residential site while high efficiency fulfills regulation(s). In order to ensure the ZVS-CV operation, the inverter's filter inductor must flow such high ripple current that can charge or discharge parasitic capacitances of a MOSFET totem pole, however trades off conduction loss of MOSFET. This study proposes a simple scheme for adapting the SF ripple current to the profile of line frequency (LF) sinusoid meanwhile ZVS-CV operation is maintained, thus efficiency is optimized. Simulations are conducted with 220 V 60 Hz LF single phase full-bridge buck inverter to verify the efficiency enhancement on a load about 1 kW. \u00a9 2019 IEEE."
        ],
        "abstrak":[
            "Metal-oxide-semiconductor field-effect transistor (MOSFET) can be utilized to raise switching frequency (SF) while zero voltage switching-clamped voltage (ZVS-CV) is a simple technique to eliminate switching loss without extra resonant circuit. Then, heat sink and filter can both be so shrunk that compact inverter can fit the single-phase system in residential site while high efficiency fulfills regulation(s). In order to ensure the ZVS-CV operation, the inverter's filter inductor must flow such high ripple current that can charge or discharge parasitic capacitances of a MOSFET totem pole, however trades off conduction loss of MOSFET. This study proposes a simple scheme for adapting the SF ripple current to the profile of line frequency (LF) sinusoid meanwhile ZVS-CV operation is maintained, thus efficiency is optimized. Simulations are conducted with 220 V 60 Hz LF single phase full-bridge buck inverter to verify the efficiency enhancement on a load about 1 kW. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Multi Tone Modeling for Seismic Data Compression"
        ],
        "penulis":"Liu, Bo;Mohandes M.;Nuha H.;Deriche M.;Iqbal, Naveed;Fekri, Faramarz;McClellan, James H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG"
        ]
    },
    {
        "judul":[
            "Competence classification of twitter users using support vector machine (SVM) method"
        ],
        "penulis":"Rifaldi, Muhammad Haqqi Ghufran;Setiawan, Erwin Budi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Twitter is one of the most popular social media in Indonesia. We freely share and write ideas, information or ideas into the available column (tweet). This convenience makes twitter users have different potential and behavior. In accordance with the experience of himself or his environment. Therefore, it is necessary to have the classification of twitter users to determine and obtain the competence of whether the tweet is credible and in accordance with the condition of the twitter user. The use of the Support Vector Machine method with sequential training optimization on the classification of Twitter tweet data competency, can be used to predict the level of credibility of twitter users. Based on the working principle of the method is to determine a straight line or the best hyperplane that separates two data classes. Then the results obtained in this study are in the form of classification accuracy in 5 categories in 5 scenarios of sharing training data and different testing data, and classification of competencies in each account tested. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Twitter is one of the most popular social media in Indonesia. We freely share and write ideas, information or ideas into the available column (tweet). This convenience makes twitter users have different potential and behavior. In accordance with the experience of himself or his environment. Therefore, it is necessary to have the classification of twitter users to determine and obtain the competence of whether the tweet is credible and in accordance with the condition of the twitter user. The use of the Support Vector Machine method with sequential training optimization on the classification of Twitter tweet data competency, can be used to predict the level of credibility of twitter users. Based on the working principle of the method is to determine a straight line or the best hyperplane that separates two data classes. Then the results obtained in this study are in the form of classification accuracy in 5 categories in 5 scenarios of sharing training data and different testing data, and classification of competencies in each account tested. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Rule based pattern type of verb identification algorithm for the Holy Qur'an"
        ],
        "penulis":"Ramadhan, Teguh Ikhlas;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes an algorithm for identification of pattern type of verb in classical Arabic. This topic was proposed because of the problem on Arabic Al-Qur'an annotation is an important task. It is important for the processing of the Holy Qur'an data, and provides convenience for those who want to learn Arabic, especially understanding arabic on morphology aspect. Understanding verb is the first step to understand the arabic morphology. The effort is to recognize how the rules regarding the pattern type of verb with the rule based approach read the pattern with prefix, the diacritics and the suffix if the verb. Briefly entered verb (Arabic or transliteration) and its output is an attribute of verb which is pattern type of verb, pronouns and verb pattern with the main rule that is identifying pattern, getting verb attributes and determining verb pattern. Experiments show that the proposed algorithm obtained accuracy at 96.48% with soft calculation method and 89.46% with harsh method calculation method. \u00a9 2019 The Authors. Published by Elsevier B.V.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes an algorithm for identification of pattern type of verb in classical Arabic. This topic was proposed because of the problem on Arabic Al-Qur'an annotation is an important task. It is important for the processing of the Holy Qur'an data, and provides convenience for those who want to learn Arabic, especially understanding arabic on morphology aspect. Understanding verb is the first step to understand the arabic morphology. The effort is to recognize how the rules regarding the pattern type of verb with the rule based approach read the pattern with prefix, the diacritics and the suffix if the verb. Briefly entered verb (Arabic or transliteration) and its output is an attribute of verb which is pattern type of verb, pronouns and verb pattern with the main rule that is identifying pattern, getting verb attributes and determining verb pattern. Experiments show that the proposed algorithm obtained accuracy at 96.48% with soft calculation method and 89.46% with harsh method calculation method. \u00a9 2019 The Authors. Published by Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Comparison between the stemmer porter effect and nazief-adriani on the performance of winnowing algorithms for measuring plagiarism"
        ],
        "penulis":"Rahmatulloh, Alam;Kurniati, Neng Ika;Darmawan, Irfan;Asyikin, Adi Zaenal;Witarsyah, J. Deden;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Current technological developments change physical paper patterns into digital, and this has a very high impact. Positive impact because paper waste is reduced, on the other hand, the rampant copying of digital data raises the amount of plagiarism that is increasing. At present, there are many efforts made by experts to overcome the problem of plagiarism, one of which is by utilizing the winnowing algorithm as a tool to detect plagiarism data. In its development, many optimizing winnowing algorithms used stemming techniques. The most widely used stemmer algorithms include stemmer porter and nazief-adriani. However, there has not been a discussion on the comparison of the effect of performance using stemmer on the winnowing algorithm in measuring the value of plagiarism. So it is necessary to research the effect of stemmer algorithms on winnowing algorithms so that the results of plagiarism detection are more optimal. The results of this study indicate that the effect of nazief-adriani stemmer on the winnowing algorithm is superior to the stemmer porter, only decreasing the detection performance of the 0.28% similarity value while the Porter stemmer is superior in increasing the processing time to 69% faster. \u00a9 2019, Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Current technological developments change physical paper patterns into digital, and this has a very high impact. Positive impact because paper waste is reduced, on the other hand, the rampant copying of digital data raises the amount of plagiarism that is increasing. At present, there are many efforts made by experts to overcome the problem of plagiarism, one of which is by utilizing the winnowing algorithm as a tool to detect plagiarism data. In its development, many optimizing winnowing algorithms used stemming techniques. The most widely used stemmer algorithms include stemmer porter and nazief-adriani. However, there has not been a discussion on the comparison of the effect of performance using stemmer on the winnowing algorithm in measuring the value of plagiarism. So it is necessary to research the effect of stemmer algorithms on winnowing algorithms so that the results of plagiarism detection are more optimal. The results of this study indicate that the effect of nazief-adriani stemmer on the winnowing algorithm is superior to the stemmer porter, only decreasing the detection performance of the 0.28% similarity value while the Porter stemmer is superior in increasing the processing time to 69% faster. \u00a9 2019, Insight Society."
        ]
    },
    {
        "judul":[
            "Defining and prioritizing software requirement using gIBIS and AHP method"
        ],
        "penulis":"Falahah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Requirement engineering is an important process in a software development project. During the process there are two activities that are very significant that determine the success of the software development: requirement definition and requirement prioritization. Through this process we can set the scope of the software product and the limitations of product features for each released version. Defining and prioritizing requirements can be done using same approach. gIBIS (graphical Issue-Based Information System) is a proposed approach for the design rationale to describe the reasoning process for the solution that is chosen in order to answer a problem or issue. The graphical representation of the reasoning process using gIBIS can be supported by tools such as Compendium. This paper proposes the implementation of the gIBIS approach in defining software requirements by assigning a score for each alternative and selecting the highest score as a solution. The approach is combined with AHP (Analytical Hierarchical Process) method to set the priority and as the result we can determine the software requirements and also rank the requirements based on its priority. The criteria used in setting the priority include cost, risk, difficulty and stability. The proposed approach (combining of gIBIS and AHP) is demonstrated with a case study of prioritizing requirements for a website development of \"IndoSoccerSchool\". The result show that the proposed approach can help us generate a list of requirements and give them a score based on priority and the list can give a reference for developing the software based on credible priorities and then manage the software release. \u00a9 2019 Horizon Research Publishing.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Requirement engineering is an important process in a software development project. During the process there are two activities that are very significant that determine the success of the software development: requirement definition and requirement prioritization. Through this process we can set the scope of the software product and the limitations of product features for each released version. Defining and prioritizing requirements can be done using same approach. gIBIS (graphical Issue-Based Information System) is a proposed approach for the design rationale to describe the reasoning process for the solution that is chosen in order to answer a problem or issue. The graphical representation of the reasoning process using gIBIS can be supported by tools such as Compendium. This paper proposes the implementation of the gIBIS approach in defining software requirements by assigning a score for each alternative and selecting the highest score as a solution. The approach is combined with AHP (Analytical Hierarchical Process) method to set the priority and as the result we can determine the software requirements and also rank the requirements based on its priority. The criteria used in setting the priority include cost, risk, difficulty and stability. The proposed approach (combining of gIBIS and AHP) is demonstrated with a case study of prioritizing requirements for a website development of \"IndoSoccerSchool\". The result show that the proposed approach can help us generate a list of requirements and give them a score based on priority and the list can give a reference for developing the software based on credible priorities and then manage the software release. \u00a9 2019 Horizon Research Publishing."
        ]
    },
    {
        "judul":[
            "A new metaheuristics for solving vehicle routing problem: Partial Comparison Optimization"
        ],
        "penulis":"Adhi A.;Santosa B.;Siswanto N.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Vehicle Routing Problem (VRP) is a problem of selecting shortest route from a depot to serve several nodes by considering transport capacity. In this study, a new metaheuristcs algorithm is proposed to solve VRP in order to achieve optimal solution. This metaheuristics algorithm is Partial Comparison Optimization (PCO). This new optimization algorithm was developed to solve combinatorial optimization problems such as VRP. In this study, PCO was tested to solve the problems that existed in the origin VRP. To prove PCO is a good metaheuristics for solving VRP, several of instances of symmetrical VRP were selected from the VRP library to evaluate its performance. The numerical results obtained from the calculation indicated that the proposed optimization method could achieve results that almost similar with the best-known solutions within a reasonable time calculation. It showed that PCO was a good metaheuristics to solve VRP. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Vehicle Routing Problem (VRP) is a problem of selecting shortest route from a depot to serve several nodes by considering transport capacity. In this study, a new metaheuristcs algorithm is proposed to solve VRP in order to achieve optimal solution. This metaheuristics algorithm is Partial Comparison Optimization (PCO). This new optimization algorithm was developed to solve combinatorial optimization problems such as VRP. In this study, PCO was tested to solve the problems that existed in the origin VRP. To prove PCO is a good metaheuristics for solving VRP, several of instances of symmetrical VRP were selected from the VRP library to evaluate its performance. The numerical results obtained from the calculation indicated that the proposed optimization method could achieve results that almost similar with the best-known solutions within a reasonable time calculation. It showed that PCO was a good metaheuristics to solve VRP. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "UDP Protocol for multi-task assignment in \"void loop\" robot soccer"
        ],
        "penulis":"Damayanti, Irma;Siregar, Simon;Sani, Muhammad Ikhsan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The communication system is a very important part of the robot soccer. It is because the robots must be able to move together, alternate and individual. The communication system that would be discussed is about the process of sending data from one robot to another robot using coach computer. It started with the reception of data from coach computer to both robots that had been installed Wi-Fi Communication module that had been connected to the router. Then, the data is processed using Arduino Mega2560. After that, the robot would detect the existence of the ball. The protocol used for the communication system is a UDP protocol (User Datagram Protocol) because UDP has several characteristics that support the occurrence of communication robots such as connection-less and unreliable. Both of characteristics have a faster connection, they do not require handshaking and UDP protocol provides a mechanism for sending a message to a specific process. The result shows that the communication system between coach computer and both robots is successful. This is indicated by the start button and stop button is 100% with repeating data transfer system on UDP protocol. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The communication system is a very important part of the robot soccer. It is because the robots must be able to move together, alternate and individual. The communication system that would be discussed is about the process of sending data from one robot to another robot using coach computer. It started with the reception of data from coach computer to both robots that had been installed Wi-Fi Communication module that had been connected to the router. Then, the data is processed using Arduino Mega2560. After that, the robot would detect the existence of the ball. The protocol used for the communication system is a UDP protocol (User Datagram Protocol) because UDP has several characteristics that support the occurrence of communication robots such as connection-less and unreliable. Both of characteristics have a faster connection, they do not require handshaking and UDP protocol provides a mechanism for sending a message to a specific process. The result shows that the communication system between coach computer and both robots is successful. This is indicated by the start button and stop button is 100% with repeating data transfer system on UDP protocol. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Patient necessity notification system based on gesture recognition (Kinect V2) and internet of things using selection frame method"
        ],
        "penulis":"Febriansyah F.;Suwastika N.A.;Fakhrurroja H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The use of gesture recognition integrated with Internet of Things (IoT) as a system for detecting patient needs provides information speed and accuracy for nurses. One tool that is widely used to implement gesture recognition is Kinect (Version 2). For data communication, Kinect will be collaborated with IoT in the process of sending data from the start after gesture recognition to the presentation of information to end users. The problem that arises when Kinect is integrated with IoT is the burden on the network because the average number of frames read by Kinect in one second is 30 frames. In this study, a frame selection method was developed to minimize the number of frames sent to IoT networks by minimizing the number of duplicate frames. The selection frame method on gesture recognition integrated with IoT is then tested for performance with distance and delay parameters. The system implementation results are able to read 100% gesture recognition, and the accuracy of the information sent by the nurse is 100% in the testing environment. The optimal distance that can provide a reading of more than 95% is 2.5 meters. The optimal value of 100% is not achieved because some testing of the falling position cannot read the whole skeleton. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of gesture recognition integrated with Internet of Things (IoT) as a system for detecting patient needs provides information speed and accuracy for nurses. One tool that is widely used to implement gesture recognition is Kinect (Version 2). For data communication, Kinect will be collaborated with IoT in the process of sending data from the start after gesture recognition to the presentation of information to end users. The problem that arises when Kinect is integrated with IoT is the burden on the network because the average number of frames read by Kinect in one second is 30 frames. In this study, a frame selection method was developed to minimize the number of frames sent to IoT networks by minimizing the number of duplicate frames. The selection frame method on gesture recognition integrated with IoT is then tested for performance with distance and delay parameters. The system implementation results are able to read 100% gesture recognition, and the accuracy of the information sent by the nurse is 100% in the testing environment. The optimal distance that can provide a reading of more than 95% is 2.5 meters. The optimal value of 100% is not achieved because some testing of the falling position cannot read the whole skeleton. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The ClearPath Method for Care Pathway Process Mining and Simulation"
        ],
        "penulis":"Johnson, Owen A.;Ba Dhafari, Thamer;Kurniati, Angelina;Fox, Frank;Rojas, Eric;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Process mining of routine electronic healthcare records can help inform the management of care pathways. Combining process mining with simulation creates a rich set of tools for care pathway improvement. Healthcare process mining creates insight into the reality of patients\u2019 journeys through care pathways while healthcare process simulation can help communicate those insights and explore \u201cwhat if\u201d options for improvement. In this paper, we outline the ClearPath method, which extends the PM2process mining method with a process simulation approach that address issues of poor quality and missing data and supports rich stakeholder engagement. We review the literature that informed the development of ClearPath and illustrate the method with case studies of pathways for alcohol-related illness, giant-cell arteritis and functional neurological symptoms. We designed an evidence template that we use to underpin the fidelity of our simulation models by tracing each model element back to literature sources, data and process mining outputs and insights from qualitative research. Our approach may be of benefit to others using process-oriented data science to improve healthcare.                          \u00a9 2019, Springer Nature Switzerland AG.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Process mining of routine electronic healthcare records can help inform the management of care pathways. Combining process mining with simulation creates a rich set of tools for care pathway improvement. Healthcare process mining creates insight into the reality of patients\u2019 journeys through care pathways while healthcare process simulation can help communicate those insights and explore \u201cwhat if\u201d options for improvement. In this paper, we outline the ClearPath method, which extends the PM2process mining method with a process simulation approach that address issues of poor quality and missing data and supports rich stakeholder engagement. We review the literature that informed the development of ClearPath and illustrate the method with case studies of pathways for alcohol-related illness, giant-cell arteritis and functional neurological symptoms. We designed an evidence template that we use to underpin the fidelity of our simulation models by tracing each model element back to literature sources, data and process mining outputs and insights from qualitative research. Our approach may be of benefit to others using process-oriented data science to improve healthcare.                          \u00a9 2019, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Sentiment analysis on hotel reviews using Multinomial Na\u00efve Bayes classifier"
        ],
        "penulis":"Farisi, Arif Abdurrahman;Sibaroni, Yuliant;Faraby, Said Al;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this modern age where the internet is growing rapidly, the existence of the internet can make it easier for tourist to find any information. In the field of tourism hotel, internet is very helpful in promotion of hotel. Tourists usually tell the experience during the hotel by writing reviews on the internet. Hence many hotel's reviews are found on the internet. The impact on hotel owners is that they can take advantage of reviews on the internet to improve and evaluate their hotels. With the availability of reviews on the internet with large numbers, tourists can't understand all the reviews they read whether they contain positive or negative opinions. It takes a sentiment analysis to quickly detect if the reviews is a positive or negative reviews. This study provides a solution by classifying positive opinion reviews and negative opinions using the Multinomial Na\u00efve Bayes Classifier method and comparing models using preprocessing, feature extraction and feature selection. The best experimental results using preprocessing and feature selection with 10 fold cross validation have an average F1-Score more than 91%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this modern age where the internet is growing rapidly, the existence of the internet can make it easier for tourist to find any information. In the field of tourism hotel, internet is very helpful in promotion of hotel. Tourists usually tell the experience during the hotel by writing reviews on the internet. Hence many hotel's reviews are found on the internet. The impact on hotel owners is that they can take advantage of reviews on the internet to improve and evaluate their hotels. With the availability of reviews on the internet with large numbers, tourists can't understand all the reviews they read whether they contain positive or negative opinions. It takes a sentiment analysis to quickly detect if the reviews is a positive or negative reviews. This study provides a solution by classifying positive opinion reviews and negative opinions using the Multinomial Na\u00efve Bayes Classifier method and comparing models using preprocessing, feature extraction and feature selection. The best experimental results using preprocessing and feature selection with 10 fold cross validation have an average F1-Score more than 91%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Hijabers on instagram: Visualising the ideal muslim woman"
        ],
        "penulis":"Baulch, Emma;Pramiyanti, Alila;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Revisiting measure of absorptive capacity: Applying the scales in spanish wine industry"
        ],
        "penulis":"Pradana, Mahir;P\u00e9rez-Lu\u00f1o, Ana;Fuentes-Blasco, Mar\u00eda;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of this study is to investigate aspects of absorptive capacity (ACAP) as a driver for innovation among Spanish wine industry. We use Exploratory Factor Analysis (EFA) followed by Confirmatory Factor Analysis (CFA) to review the existing theories related to ACAP. From the research we conducted out of 111 wine companies in Spain, three factors are empirically proven to be in accordance with the theory, knowledge acquisition, assimilation and transformation. One other factor, knowledge exploitation, does not correspond with our empirical result. We have come to the conclusion that using other indicators related to knowledge exploitation capabilities might lead to more fit research model. \u00a9 2019 Allied Business Academies.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to investigate aspects of absorptive capacity (ACAP) as a driver for innovation among Spanish wine industry. We use Exploratory Factor Analysis (EFA) followed by Confirmatory Factor Analysis (CFA) to review the existing theories related to ACAP. From the research we conducted out of 111 wine companies in Spain, three factors are empirically proven to be in accordance with the theory, knowledge acquisition, assimilation and transformation. One other factor, knowledge exploitation, does not correspond with our empirical result. We have come to the conclusion that using other indicators related to knowledge exploitation capabilities might lead to more fit research model. \u00a9 2019 Allied Business Academies."
        ]
    },
    {
        "judul":[
            "Typographic-Based Data Augmentation to Improve a Question Retrieval in Short Dialogue System"
        ],
        "penulis":"Nugraha, Helmi Satria;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Many questions posed by users to particular customer service with a short dialog (such as a chatbot) cause difficulties to answer. These reduce the user satisfaction level to the service. A question answering (QA) system can be developed to solve this problem by providing relevant answers to the user questions. One of the commonly used methods to build a QA is a question retrieval (QR) that provides answers based on the most relevant stored-questions. However, interpreting two questions those are essentially the same but in different words is quite challenging. Besides, the limitation of the data set to learn is also interesting. This paper investigates a data augmentation based on typographic and synonym as well as evaluates the use of sub-word (instead of word) features to get the best word-embedding in the question. The word-embedding is then used to search the cosine similarity between a query and the stored-questions. Finally, the user receives an answer based on the question with the highest cosine similarity. Evaluation on a quite low data set shows that the proposed data augmentation is capable of significantly improving the system performance. Besides, the sub-word feature is better for word-embedding in the short conversation than the whole-word one. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Many questions posed by users to particular customer service with a short dialog (such as a chatbot) cause difficulties to answer. These reduce the user satisfaction level to the service. A question answering (QA) system can be developed to solve this problem by providing relevant answers to the user questions. One of the commonly used methods to build a QA is a question retrieval (QR) that provides answers based on the most relevant stored-questions. However, interpreting two questions those are essentially the same but in different words is quite challenging. Besides, the limitation of the data set to learn is also interesting. This paper investigates a data augmentation based on typographic and synonym as well as evaluates the use of sub-word (instead of word) features to get the best word-embedding in the question. The word-embedding is then used to search the cosine similarity between a query and the stored-questions. Finally, the user receives an answer based on the question with the highest cosine similarity. Evaluation on a quite low data set shows that the proposed data augmentation is capable of significantly improving the system performance. Besides, the sub-word feature is better for word-embedding in the short conversation than the whole-word one. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Traffic simulation in an intersection by using integrated vissim-matlab"
        ],
        "penulis":"Istiqomah, Novera;Qidun, Maulana B.S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper describes the coupling scheme between Matlab and commercial tool for traffic simulation, PTV Vissim, which can be integrated and performed in realtime simulation. A step-by-step procedure of the scheme by using amenities that provided by the tool, Vissim Component Object Model (COM) interface, is also presented. This research succeed to read and store the outcomes in. txt file. These outcomes are the number of vehicles that enter and exit an intersection, also the queue length of vehicles in an intersection each road. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper describes the coupling scheme between Matlab and commercial tool for traffic simulation, PTV Vissim, which can be integrated and performed in realtime simulation. A step-by-step procedure of the scheme by using amenities that provided by the tool, Vissim Component Object Model (COM) interface, is also presented. This research succeed to read and store the outcomes in. txt file. These outcomes are the number of vehicles that enter and exit an intersection, also the queue length of vehicles in an intersection each road. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Mapping of Communal Waste Water Treatment Plant User Group in Citarum River Areas Using Geographic Information System"
        ],
        "penulis":"Priscilla, Ayu Saskia;Kurniawati, Amelia;Rizana, Afrin Fauzya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Citarum River is the largest and longest river in the province of West Java. The Citarum River flows along 269 km which starts from Situ Cisanti and empties into the Java Sea. The river is contaminated due to waste dumped into the river, one of which is an industrial waste. Thus, the local government needs to provide a Waste Water Treatment Plant (WWTP) that can be used simultaneously by several adjacent industries. The proximity between industries can be seen through mapping of location points using Geographic Information Systems (GIS). This study aims to design a web-based GIS application for determining groups of industries that will use the WWTP simultaneously. GIS application is designed to map industrial location points and placement of WWTP through determination of location coordinates on Google Maps API. Users of this application can see the display of groups of communal WWTPs as well as points that are in a certain area of coverage. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentClean water and sanitationGoal 6Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Citarum River is the largest and longest river in the province of West Java. The Citarum River flows along 269 km which starts from Situ Cisanti and empties into the Java Sea. The river is contaminated due to waste dumped into the river, one of which is an industrial waste. Thus, the local government needs to provide a Waste Water Treatment Plant (WWTP) that can be used simultaneously by several adjacent industries. The proximity between industries can be seen through mapping of location points using Geographic Information Systems (GIS). This study aims to design a web-based GIS application for determining groups of industries that will use the WWTP simultaneously. GIS application is designed to map industrial location points and placement of WWTP through determination of location coordinates on Google Maps API. Users of this application can see the display of groups of communal WWTPs as well as points that are in a certain area of coverage. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "K-Nearest Neighbor for colon cancer identification"
        ],
        "penulis":"Caecar Pratiwi, Nor Kumalasari;Magdalena, Rita;Fuadah, Yunendah Nur;Saidah, Sofia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Colon cancer or colorectal cancer is a type of cancer that attacks the last part of the human digestive system. Lymphoma and carcinoma are types of cancer that attack humans colon. Colon cancer causes deaths about half a million people every year. In Indonesia, colon cancer is the third largest cancer case for women and second in men. Unhealthy lifestyles such as minimum consumption of fiber, rarely exercising and lack of awareness for early detection are factors that cause high cases of colon cancer. The aim of this study is to produce a system that can detect and classify images into type of colon cancer lymphoma, carcinoma, or normal. The designed system used 198 data colon cancer tissue pathology, consist of 66 images for Lymphoma cancer, 66 images for carcinoma cancer and 66 for normal\/healthy colon condition. This system will classify colon cancer starts from image preprocessing, feature extraction using Principal Component Analysis (PCA) and classification using K-Nearest Neighbor (K-NN) method. Several stages in preprocessing are resized, convert RGB image to grayscale, edge detection, and last histogram equalization. Tests will be done by trying some K-NN input parameter settings. The result of this study is an image processing system that can detect and classify type of colon cancer with high accuracy and low computation time. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Colon cancer or colorectal cancer is a type of cancer that attacks the last part of the human digestive system. Lymphoma and carcinoma are types of cancer that attack humans colon. Colon cancer causes deaths about half a million people every year. In Indonesia, colon cancer is the third largest cancer case for women and second in men. Unhealthy lifestyles such as minimum consumption of fiber, rarely exercising and lack of awareness for early detection are factors that cause high cases of colon cancer. The aim of this study is to produce a system that can detect and classify images into type of colon cancer lymphoma, carcinoma, or normal. The designed system used 198 data colon cancer tissue pathology, consist of 66 images for Lymphoma cancer, 66 images for carcinoma cancer and 66 for normal\/healthy colon condition. This system will classify colon cancer starts from image preprocessing, feature extraction using Principal Component Analysis (PCA) and classification using K-Nearest Neighbor (K-NN) method. Several stages in preprocessing are resized, convert RGB image to grayscale, edge detection, and last histogram equalization. Tests will be done by trying some K-NN input parameter settings. The result of this study is an image processing system that can detect and classify type of colon cancer with high accuracy and low computation time. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Prototype of Telemetry, Tracking, and Command module for Tel-USat with BCH code"
        ],
        "penulis":"Medina, Fachrul Reiza;Wijanto, Heroe;Edwar;Rahmadani, Camila Putri;Holy Bagas Pangestu, Bramandika;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tel-USat is an underdevelopment CubeSat of Telkom University. The satellite consists of various subsystems. Telemetry, Tracking and Command (TTC) is one of satellite subsystem which is used to transmits the housekeeping data of the satellite and periodically sends beacon signal to the earth. However, the satellite communication system is a long-distance communication so that any disturbance, interference, and attenuation of communication channels are possible to disrupt the data. Therefore, an Error Detection and Control (EDAC) or Forward Error Correction (FEC) is implemented to control and minimise errors without the need for re-Transmission. This work has designed and developed the prototype of the TTC subsystem integrated with the AX.25 protocol as EDAC and the BCH (63.45) coding method as FEC. The BCH used in this research is capable to correct a maximum of 3 bits per frame. Moreover, the BCH code can reduce the Eb\/No needed to get the corresponding BER value that equal to 106. The Eb\/No peak value reduces from-6.56 dBm to-12.71 dBm using BCH coding with the 4-FSK modulation. The range test was performed to ensure the functionality of the prototype with the highest success rate in 1200kBaud and-30 dBm configuration at approximately 80 metres. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tel-USat is an underdevelopment CubeSat of Telkom University. The satellite consists of various subsystems. Telemetry, Tracking and Command (TTC) is one of satellite subsystem which is used to transmits the housekeeping data of the satellite and periodically sends beacon signal to the earth. However, the satellite communication system is a long-distance communication so that any disturbance, interference, and attenuation of communication channels are possible to disrupt the data. Therefore, an Error Detection and Control (EDAC) or Forward Error Correction (FEC) is implemented to control and minimise errors without the need for re-Transmission. This work has designed and developed the prototype of the TTC subsystem integrated with the AX.25 protocol as EDAC and the BCH (63.45) coding method as FEC. The BCH used in this research is capable to correct a maximum of 3 bits per frame. Moreover, the BCH code can reduce the Eb\/No needed to get the corresponding BER value that equal to 106. The Eb\/No peak value reduces from-6.56 dBm to-12.71 dBm using BCH coding with the 4-FSK modulation. The range test was performed to ensure the functionality of the prototype with the highest success rate in 1200kBaud and-30 dBm configuration at approximately 80 metres. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Estimote-based location awareness on mobile devices for visually impaired"
        ],
        "penulis":"Mutiara, Giva Andriana;Hapsari, Gita Indah;Periyadi;Pratondo, Agus;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The limitations vision that possessed by the visually impaired in interacting with their environment, causing them to have difficulties in doing traveling. But, along with the development of smartphone technology, the visually impaired people began using smartphones to help them engage in any activities. Estimote beacons are a small device that broadcast a Bluetooth signal that can be captured by a smartphone. This research contributions to provide the information to the visually impaired person in order to have easy use compatible with the smartphone since the Estimote beacons are used as a location awareness device to give the information about the surrounding environment. The systems were configured and programmed using android studio for indoor and outdoor locations. Based on the indoor result testing, it can be stated that the implementation of the Estimote beacon as a location awareness in indoor area, must be focused on the installation of the Estimote beacons. The installation must be set smoothly and the broadcast signal should not be overlap. The outdoor result testing indicates that the Estimote beacon signal is stable to receive on the smartphone at a distance 0 \u2013 31.64 meters, begin unstable at a distance of 38.61 meter and become undetected at a distance of 79.79 meters. \u00a9 2005 \u2013 ongoing JATIT & LLS.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The limitations vision that possessed by the visually impaired in interacting with their environment, causing them to have difficulties in doing traveling. But, along with the development of smartphone technology, the visually impaired people began using smartphones to help them engage in any activities. Estimote beacons are a small device that broadcast a Bluetooth signal that can be captured by a smartphone. This research contributions to provide the information to the visually impaired person in order to have easy use compatible with the smartphone since the Estimote beacons are used as a location awareness device to give the information about the surrounding environment. The systems were configured and programmed using android studio for indoor and outdoor locations. Based on the indoor result testing, it can be stated that the implementation of the Estimote beacon as a location awareness in indoor area, must be focused on the installation of the Estimote beacons. The installation must be set smoothly and the broadcast signal should not be overlap. The outdoor result testing indicates that the Estimote beacon signal is stable to receive on the smartphone at a distance 0 \u2013 31.64 meters, begin unstable at a distance of 38.61 meter and become undetected at a distance of 79.79 meters. \u00a9 2005 \u2013 ongoing JATIT & LLS."
        ]
    },
    {
        "judul":[
            "ADS-B microstrip antenna receiver design for CubeSat with SLOT"
        ],
        "penulis":"Suteja E.A.;Prasetyo A.D.;Satriyotomo B.;Dafiq D.H.;Edwar;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nanosatellite is one of several satellite classes that have a size that generally refers to the standardization of cubesat which is 10\u00d710\u00d710 cm3. Nowadays nanosatellite is widely developed for various purposes such as air traffic monitoring using Automatic Dependent Surveillance-Broadcast (ADS-B) receiver as the mission. Telkom University and the nanosatellite Laboratory are researching ADSB on nanosatellite. The nanosatellite uses a frequency of 1090 MHz which functions as ADS-B receiver, and air traffic control as the primary mission. This paper presents a microstrip antenna design for nanosatellite with the mission as ADS-B signals receiver. the antenna has voltage standing wave ratio (VSWR) = 1,9 in the frequency of 1090 MHz. Then have unidirectional as the radiation pattern and right hand circular polarization (RHCP) as the polarization, gain 1,02 dB, 52 MHz bandwidth and range is 189 km. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nanosatellite is one of several satellite classes that have a size that generally refers to the standardization of cubesat which is 10\u00d710\u00d710 cm3. Nowadays nanosatellite is widely developed for various purposes such as air traffic monitoring using Automatic Dependent Surveillance-Broadcast (ADS-B) receiver as the mission. Telkom University and the nanosatellite Laboratory are researching ADSB on nanosatellite. The nanosatellite uses a frequency of 1090 MHz which functions as ADS-B receiver, and air traffic control as the primary mission. This paper presents a microstrip antenna design for nanosatellite with the mission as ADS-B signals receiver. the antenna has voltage standing wave ratio (VSWR) = 1,9 in the frequency of 1090 MHz. Then have unidirectional as the radiation pattern and right hand circular polarization (RHCP) as the polarization, gain 1,02 dB, 52 MHz bandwidth and range is 189 km. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "The energy due to confinement of one-dimensional cylindrical quantum wire"
        ],
        "penulis":"Wibowo E.;Ulya N.;Rokhmat M.;Suwandi;Sutisna;Othaman Z.;Marwoto P.;Aji M.P.;Astuti B.;Sumpono I.;Sulhadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We have determined the energy due to confinement of one-dimensional cylindrical quantum wire by solving Schr\u00f6's equation. By considering some boundaries conditions, the Schr\u00f6's equation has been transformed to the second-order linear differential equation. From this transformation, the wave function and the expression of the energy due to confinement are easily described. We obtained the energy due to confinement of 1D-CQW is inversely proportional to the square of the wire's radius. Smaller wires have stronger energy due to confinement than bigger ones. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We have determined the energy due to confinement of one-dimensional cylindrical quantum wire by solving Schr\u00f6's equation. By considering some boundaries conditions, the Schr\u00f6's equation has been transformed to the second-order linear differential equation. From this transformation, the wave function and the expression of the energy due to confinement are easily described. We obtained the energy due to confinement of 1D-CQW is inversely proportional to the square of the wire's radius. Smaller wires have stronger energy due to confinement than bigger ones. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Scientific Documents Classification Using Support Vector Machine Algorithm"
        ],
        "penulis":"Jaya I.;Aulia I.;Hardi S.M.;Tarigan J.T.;Lydia M.S.;Caroline;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One of the ways to publish scientific paper is to present it in a conference. Before being presented in the conference, the registered scientific paper has to be grouped into categories. Because there are so many scientific papers that have been registered, it is an urgent need to establish a system that can automatically identify the topic of scientific papers and classify them according to recognized topics. One method that can be used to organize documents according to their categories is classification. In this study, Support Vector Machine algorithm is used as a method to classify documents into 5 categories of computer science. System test is done by taking 150 documents as data sample and 50 documents as data testing. This study produced a classification system of scientific documents and showed the method used was able to classify documents with 90% accuracy results. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the ways to publish scientific paper is to present it in a conference. Before being presented in the conference, the registered scientific paper has to be grouped into categories. Because there are so many scientific papers that have been registered, it is an urgent need to establish a system that can automatically identify the topic of scientific papers and classify them according to recognized topics. One method that can be used to organize documents according to their categories is classification. In this study, Support Vector Machine algorithm is used as a method to classify documents into 5 categories of computer science. System test is done by taking 150 documents as data sample and 50 documents as data testing. This study produced a classification system of scientific documents and showed the method used was able to classify documents with 90% accuracy results. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Patient necessity notification system based on gesture recognition (Kinect V2) and internet of things using selection frame method"
        ],
        "penulis":"Febriansyah F.;Suwastika N.A.;Fakhrurroja H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The use of gesture recognition integrated with Internet of Things (IoT) as a system for detecting patient needs provides information speed and accuracy for nurses. One tool that is widely used to implement gesture recognition is Kinect (Version 2). For data communication, Kinect will be collaborated with IoT in the process of sending data from the start after gesture recognition to the presentation of information to end users. The problem that arises when Kinect is integrated with IoT is the burden on the network because the average number of frames read by Kinect in one second is 30 frames. In this study, a frame selection method was developed to minimize the number of frames sent to IoT networks by minimizing the number of duplicate frames. The selection frame method on gesture recognition integrated with IoT is then tested for performance with distance and delay parameters. The system implementation results are able to read 100% gesture recognition, and the accuracy of the information sent by the nurse is 100% in the testing environment. The optimal distance that can provide a reading of more than 95% is 2.5 meters. The optimal value of 100% is not achieved because some testing of the falling position cannot read the whole skeleton. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of gesture recognition integrated with Internet of Things (IoT) as a system for detecting patient needs provides information speed and accuracy for nurses. One tool that is widely used to implement gesture recognition is Kinect (Version 2). For data communication, Kinect will be collaborated with IoT in the process of sending data from the start after gesture recognition to the presentation of information to end users. The problem that arises when Kinect is integrated with IoT is the burden on the network because the average number of frames read by Kinect in one second is 30 frames. In this study, a frame selection method was developed to minimize the number of frames sent to IoT networks by minimizing the number of duplicate frames. The selection frame method on gesture recognition integrated with IoT is then tested for performance with distance and delay parameters. The system implementation results are able to read 100% gesture recognition, and the accuracy of the information sent by the nurse is 100% in the testing environment. The optimal distance that can provide a reading of more than 95% is 2.5 meters. The optimal value of 100% is not achieved because some testing of the falling position cannot read the whole skeleton. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Experimental study of load balancing on software defined network using ant-colony optimization"
        ],
        "penulis":"Mulya, Faizal;Purboyo, Tito Waluyo;Latuconsina, Roswan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of technology on internet networks is rapidly continues to grow. This development also had an impact on the server because the server had difficulty in distributing request. To meet internet needs, the technique that can be used is load balancing. Load balancing is a technique to use two or more internet connection lines and balance the request between the two internet connection lines. In this research, the main problem to be discussed is a load balancing simulation using ant colony optimization mechanism. Our experiment show that throughput value by using the ant colony optimization algorithm has a greater throughput value than the round-robin algorithm. Also, we found that ant colony optimization algorithm is more balanced because it has a difference CPU utilization lower than Round-Robin. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by"
        ],
        "abstrak":[
            "The development of technology on internet networks is rapidly continues to grow. This development also had an impact on the server because the server had difficulty in distributing request. To meet internet needs, the technique that can be used is load balancing. Load balancing is a technique to use two or more internet connection lines and balance the request between the two internet connection lines. In this research, the main problem to be discussed is a load balancing simulation using ant colony optimization mechanism. Our experiment show that throughput value by using the ant colony optimization algorithm has a greater throughput value than the round-robin algorithm. Also, we found that ant colony optimization algorithm is more balanced because it has a difference CPU utilization lower than Round-Robin. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Hijabers on instagram: Visualising the ideal muslim woman"
        ],
        "penulis":"Baulch, Emma;Pramiyanti, Alila;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Experiment of 3-Phase N-path Filter for Hum Noise Suppression"
        ],
        "penulis":"Afifah, Khilda;Retdian, Nicodimus;Arijal, Muhammad;Shima, Takeshi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One of a critical problem in the biomedical signals measurements is hum noise activity due to power line interference. Various approaches to suppress hum noise both analog and digital techniques have been proposed. However, these approaches have some disadvantages. N-path notch filter can be an alternative solution for this problem. The notch depth in a conventional N-path notch filter is limited by the number of paths to achieve deeper notch. This paper proposes a new N-path notch filter with additional sample-and-hold (S\/H) and leak buffer circuits to improve notch depth. Simulation and measurement results of 3-phase N-path filter achieve notch depth of 61.6dB and 54.5dB respectively. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of a critical problem in the biomedical signals measurements is hum noise activity due to power line interference. Various approaches to suppress hum noise both analog and digital techniques have been proposed. However, these approaches have some disadvantages. N-path notch filter can be an alternative solution for this problem. The notch depth in a conventional N-path notch filter is limited by the number of paths to achieve deeper notch. This paper proposes a new N-path notch filter with additional sample-and-hold (S\/H) and leak buffer circuits to improve notch depth. Simulation and measurement results of 3-phase N-path filter achieve notch depth of 61.6dB and 54.5dB respectively. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Anchor placement design for a decoupled simple trilateration algorithm"
        ],
        "penulis":"Lee, Sang C.;Rizal, Syamsul;Ahn, Heungju;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Localization is one of the main issues in wireless sensor networks (WSNs). By deploying anchor nodes, the sensor node location can be estimated. Generally, three anchor node positions should be fixed and known so that it becomes possible to estimate other sensor nodes by using a trilateration technique. This paper investigated a mobile anchor node for a real-time local positioning system (RT-LPS). The target position could be calculated directly without a limitation of the coverage area, because three anchor nodes have been equipped on the mobile robot. The proposed method involves the design of three anchors at a specific right-angled triangle position to simplify the calculation of position information. A simple equation is proposed for calculating the target position. The measurement distances between the anchor and the target node are collected by using the time-of-arrival (ToA) method. The simulation results are compared in terms of the position error with the equilateral triangle method. \u00a9 Copyright 2019",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Localization is one of the main issues in wireless sensor networks (WSNs). By deploying anchor nodes, the sensor node location can be estimated. Generally, three anchor node positions should be fixed and known so that it becomes possible to estimate other sensor nodes by using a trilateration technique. This paper investigated a mobile anchor node for a real-time local positioning system (RT-LPS). The target position could be calculated directly without a limitation of the coverage area, because three anchor nodes have been equipped on the mobile robot. The proposed method involves the design of three anchors at a specific right-angled triangle position to simplify the calculation of position information. A simple equation is proposed for calculating the target position. The measurement distances between the anchor and the target node are collected by using the time-of-arrival (ToA) method. The simulation results are compared in terms of the position error with the equilateral triangle method. \u00a9 Copyright 2019"
        ]
    },
    {
        "judul":[
            "Automatic Detection of Argument Components in Text Using Multinomial Nave Bayes Clasiffier"
        ],
        "penulis":"Rohman, Hifdzon Nur;Asror, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Arguments are often found in various text data, for example in news, essays and articles. Argumentation Mining is a method that automatically identifies argument structures in text documents. This argument structure consists of several components that are very useful for information retrieval and processing information. In this study, a model will be built to auto-matically detect the component of argument, by using naive bayes classifer multinomial, the model will classify argument components into two classes, namely claim and premise. The evaluation uses k-fold cross validation. The most optimal result of this study is the average accuracy of 70.39 % and the average f1-score of 80.42 % with feature extraction, preprocessing and weighting words. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Arguments are often found in various text data, for example in news, essays and articles. Argumentation Mining is a method that automatically identifies argument structures in text documents. This argument structure consists of several components that are very useful for information retrieval and processing information. In this study, a model will be built to auto-matically detect the component of argument, by using naive bayes classifer multinomial, the model will classify argument components into two classes, namely claim and premise. The evaluation uses k-fold cross validation. The most optimal result of this study is the average accuracy of 70.39 % and the average f1-score of 80.42 % with feature extraction, preprocessing and weighting words. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Detecting Hand, Foot and Mouth Disease in Earlier Stage Using C4.5 Algorithm as Expert System Based on Android"
        ],
        "penulis":"Syahrial, Farisa Hafida;Irawan, Budhi;Prasasti, Anggunmeka Luhur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hand, Foot and Mouth Disease (HFMD) is an infectious diseases caused by enterovirus virus 71 (EV 71). The symptoms of HFMD is similar to several other disease that caused by a virus, especially disease that have a fever and rash symptoms which people usually underestimate diseases that have early symptoms like that. Therefore, in this system we classify the HFMD with the intention of detecting the disease from an earlier stage. And we use Android based application since at this present time, smartphone is the closest device that is always used by many people. The classification used in this paper is Decision Tree C4.5 Algorithm. Dataset used in this research is as many as 256 which divided into training data and testing data, that formed based on symptoms that had previously been validated by the doctor. The result shows that data partitions of 90%:10%, 80%:20% and 70%:30% has accuracy, precision and recall value are 100%. Thus, data partition 70%:30% has the best result because this partition has less training data but can still classify diseases effectively. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hand, Foot and Mouth Disease (HFMD) is an infectious diseases caused by enterovirus virus 71 (EV 71). The symptoms of HFMD is similar to several other disease that caused by a virus, especially disease that have a fever and rash symptoms which people usually underestimate diseases that have early symptoms like that. Therefore, in this system we classify the HFMD with the intention of detecting the disease from an earlier stage. And we use Android based application since at this present time, smartphone is the closest device that is always used by many people. The classification used in this paper is Decision Tree C4.5 Algorithm. Dataset used in this research is as many as 256 which divided into training data and testing data, that formed based on symptoms that had previously been validated by the doctor. The result shows that data partitions of 90%:10%, 80%:20% and 70%:30% has accuracy, precision and recall value are 100%. Thus, data partition 70%:30% has the best result because this partition has less training data but can still classify diseases effectively. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The analysis of skin surface temperature and water vapor on volcanic eruption (case study: Mt. Kelud)"
        ],
        "penulis":"Noor A.B.S.;Hidayat R.;Perdinan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The post-volcanic eruption can be one of main factors in climate variability. The last incident of Kelud eruption had been occurred at 22:50 WIB, 13 February 2014. This paper aims to analyze the climatology of skin surface temperature (SKT), total column water vapor (TCWV), and mixing ratio at 500 mb before eruption from ERA-Interim and the processes before and after eruptions from Weather Research Forecasting (WRF) model simulation. Global Forecast System (GFS) data was used for WRF as initial condition and boundary condition, while ERA-Interim reanalysis dataset was used as a comparison. Bias correction was used to adjust WRF output with ERA-Interim on SKT and TCWV. SKT interval between day and night ranges from 21-23\u00b0C (WRF) and 12\u00b0C (ERA-Interim). There are 56 SKT WRF and 5 SKT ERA-Interim anomalous day before eruption. TCWV anomalies from WRF have consistent variation with ERA-Interim and there are 2 TCWV anomalies exceed 2 standard deviation. There were no TCWV anomalies detected on ERA-Interim, but were detected on WRF 2 days before and 3 days after eruption above 2 standard deviations. Mixing ratio shows a downward trend before and after the eruption. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The post-volcanic eruption can be one of main factors in climate variability. The last incident of Kelud eruption had been occurred at 22:50 WIB, 13 February 2014. This paper aims to analyze the climatology of skin surface temperature (SKT), total column water vapor (TCWV), and mixing ratio at 500 mb before eruption from ERA-Interim and the processes before and after eruptions from Weather Research Forecasting (WRF) model simulation. Global Forecast System (GFS) data was used for WRF as initial condition and boundary condition, while ERA-Interim reanalysis dataset was used as a comparison. Bias correction was used to adjust WRF output with ERA-Interim on SKT and TCWV. SKT interval between day and night ranges from 21-23\u00b0C (WRF) and 12\u00b0C (ERA-Interim). There are 56 SKT WRF and 5 SKT ERA-Interim anomalous day before eruption. TCWV anomalies from WRF have consistent variation with ERA-Interim and there are 2 TCWV anomalies exceed 2 standard deviation. There were no TCWV anomalies detected on ERA-Interim, but were detected on WRF 2 days before and 3 days after eruption above 2 standard deviations. Mixing ratio shows a downward trend before and after the eruption. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "A gesture-based recognition system for augmented reality"
        ],
        "penulis":"Kasinathan, Vinothini;Mustapha, Aida;Fajrillah, Asti Amalia Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "With the geometrical improvement in Information Technology, current conventional input devices are becoming increasingly obsolete and lacking. Experts in Human Computer Interaction (HCI) are convinced that input devices remain the bottleneck of information acquisition specifically in when using Augmented Reality (AR) technology. Current input mechanisms are unable to compete with this trend towards naturalness and expressivity which allows users to perform natural gestures or operations and convert them as input. Hence, a more natural and intuitive input device is imperative, specifically gestural inputs that have been widely perceived by HCI experts as the next big input device. To address this gap, this project is set to develop a prototype of hand gesture recognition system based on computer vision in modeling basic human-computer interactions. The main motivation in this work is a technology that requires no outfitting of additional equipment whatsoever by the users. The gesture-based had recognition system was implemented using the Rapid Application Development (RAD) methodology and was evaluated in terms of its usability and performance through five levels of testing, which are unit testing, integration testing, system testing, recognition accuracy testing, and user acceptance testing. The test results of unit, integration, system testing as well as user acceptance testing produced favorable results. In conclusion, current conventional input devices will continue to bottleneck this advancement in technology; therefore, a better alternative input technique should be looked into, in particularly, gesture-based input technique which offers user a more natural and intuitive control. \u00a9 ExcelingTech Pub, UK.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "With the geometrical improvement in Information Technology, current conventional input devices are becoming increasingly obsolete and lacking. Experts in Human Computer Interaction (HCI) are convinced that input devices remain the bottleneck of information acquisition specifically in when using Augmented Reality (AR) technology. Current input mechanisms are unable to compete with this trend towards naturalness and expressivity which allows users to perform natural gestures or operations and convert them as input. Hence, a more natural and intuitive input device is imperative, specifically gestural inputs that have been widely perceived by HCI experts as the next big input device. To address this gap, this project is set to develop a prototype of hand gesture recognition system based on computer vision in modeling basic human-computer interactions. The main motivation in this work is a technology that requires no outfitting of additional equipment whatsoever by the users. The gesture-based had recognition system was implemented using the Rapid Application Development (RAD) methodology and was evaluated in terms of its usability and performance through five levels of testing, which are unit testing, integration testing, system testing, recognition accuracy testing, and user acceptance testing. The test results of unit, integration, system testing as well as user acceptance testing produced favorable results. In conclusion, current conventional input devices will continue to bottleneck this advancement in technology; therefore, a better alternative input technique should be looked into, in particularly, gesture-based input technique which offers user a more natural and intuitive control. \u00a9 ExcelingTech Pub, UK."
        ]
    },
    {
        "judul":[
            "Prediction of agriculture and mining stock value listed in kompas100 index using artificial neural network backpropagation"
        ],
        "penulis":"Meizir;Rikumahu, Brady;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Company's stock prices in the market are very fluctuating, where its value experiences up and down according to market condition. Based on that fact, stock price become very difficult to be predicted or even estimated. Therefore, analysis of stock price movement predictions is heavily required as investment decision reference for investor. This paper uses technical analysis with Artificial Neural Network Backpropagation method as one of machine learning methodology which has commonly used along with rapid development of data mining and big data analytic that produces a prediction with high accuracy and the least error. The objects in this paper were four companies in the agricultural and mining sector, which was among Kompas100 index with the largest market capitalization in the period of 2013 to 2018. Based on the results of research with several variations of the experiment using varying hidden layer values 10, 20, 30 with variations in SGD values: 0.01, 0.001 and 0.0001 as well as variations in epoch 100, 200 and 300 values, resulting in network predictive models that provide training with error rates the minimum error is in the 5-20-1 model with a value of SGD 0.01 and epoch 300. Accuracy performance prediction of using MAE, MSE, RMSE and MAPE shows that the deviation of the predicted values of Artificial Neural Network Backpropagation from the actual values at agricultural and mining stock prices is low enough to conclude that stock predictions are accurate \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Company's stock prices in the market are very fluctuating, where its value experiences up and down according to market condition. Based on that fact, stock price become very difficult to be predicted or even estimated. Therefore, analysis of stock price movement predictions is heavily required as investment decision reference for investor. This paper uses technical analysis with Artificial Neural Network Backpropagation method as one of machine learning methodology which has commonly used along with rapid development of data mining and big data analytic that produces a prediction with high accuracy and the least error. The objects in this paper were four companies in the agricultural and mining sector, which was among Kompas100 index with the largest market capitalization in the period of 2013 to 2018. Based on the results of research with several variations of the experiment using varying hidden layer values 10, 20, 30 with variations in SGD values: 0.01, 0.001 and 0.0001 as well as variations in epoch 100, 200 and 300 values, resulting in network predictive models that provide training with error rates the minimum error is in the 5-20-1 model with a value of SGD 0.01 and epoch 300. Accuracy performance prediction of using MAE, MSE, RMSE and MAPE shows that the deviation of the predicted values of Artificial Neural Network Backpropagation from the actual values at agricultural and mining stock prices is low enough to conclude that stock predictions are accurate \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Evaluation of Baby Carriers in Indonesia: Physiological and Biomechanical Approach"
        ],
        "penulis":"Fista B.;Widyanti A.;Muslim K.;Salma S.A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Baby carrying is among the most performed activities during mothering and caring for children. Researches showed that baby carrying activities may increase the risk of musculoskeletal disorders among mothers. This study aimed to evaluate three types of baby carrier often used by mothers in Indonesia, namely Soft Structured Carrier (SSC), ring sling, and jarik based on the posture analysis approach, Rate of Perceived Discomfort (RPD), Activities-Specific Balanced Confidence Scale (ABC Scale) and heart rate. This research was conducted through laboratory experiments involving 12 respondents. Each respondent was asked to carry out a simulation carrying a 6 months old baby (weighing 7.3 kg) by walking on a treadmill for 10 minutes using three different types of baby carrier. Body markers for posture analysis and heart rate sensor were installed prior to the experiment to record body motion and heart rate, respectively. At the end of the experiment, respondents were asked to provide an assessment of the perceived pain using the RPD questionnaire, as well as the ABC Scale questionnaire to obtain the level of confidence in balance when carrying a baby. The results indicated that through posture analysis, all types of baby carrier produced an average value of 490- 520at the sagittal shoulder angle, which falls in the normal posture category. Whereas in the craniohorizontal angle, the SSC type sling provided the best change in posture. Based on the RPD questionnaire, ring sling and jarik resulted in higher pain to the left shoulder than the SSC sling. Based on the results of the ABC scale questionnaire, the SSC sling provided a higher level of trust than the jarik and ring sling. However, no significant difference found in terms of heart rate for the three types of baby carrier. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Baby carrying is among the most performed activities during mothering and caring for children. Researches showed that baby carrying activities may increase the risk of musculoskeletal disorders among mothers. This study aimed to evaluate three types of baby carrier often used by mothers in Indonesia, namely Soft Structured Carrier (SSC), ring sling, and jarik based on the posture analysis approach, Rate of Perceived Discomfort (RPD), Activities-Specific Balanced Confidence Scale (ABC Scale) and heart rate. This research was conducted through laboratory experiments involving 12 respondents. Each respondent was asked to carry out a simulation carrying a 6 months old baby (weighing 7.3 kg) by walking on a treadmill for 10 minutes using three different types of baby carrier. Body markers for posture analysis and heart rate sensor were installed prior to the experiment to record body motion and heart rate, respectively. At the end of the experiment, respondents were asked to provide an assessment of the perceived pain using the RPD questionnaire, as well as the ABC Scale questionnaire to obtain the level of confidence in balance when carrying a baby. The results indicated that through posture analysis, all types of baby carrier produced an average value of 490- 520at the sagittal shoulder angle, which falls in the normal posture category. Whereas in the craniohorizontal angle, the SSC type sling provided the best change in posture. Based on the RPD questionnaire, ring sling and jarik resulted in higher pain to the left shoulder than the SSC sling. Based on the results of the ABC scale questionnaire, the SSC sling provided a higher level of trust than the jarik and ring sling. However, no significant difference found in terms of heart rate for the three types of baby carrier. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Wood quality classification based on texture and fiber pattern recognition using HOG feature and SVM classifier"
        ],
        "penulis":"Nurthohari, Zayyana;Murti, Muhammad Ary;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Wood as a material for household appliance needs to be considered of quality. Quality of wood can be classified according to colours, texture, and wood fibre pattern differences. In general, wood industries have been doing the wood quality classified process using a conventional method with a sense of vision in which the results are subjective in terms of accuracy and time efficiency. Machine Learning is a solution to this problem of predicting and classifying data of wood quality. In this paper, the wood will be recognized using Histogram of Oriented Gradient to know the pattern and texture. Meanwhile, the classification method uses Support Vector Machine which will be compared to find the best accuracy and time computation. This system is given image input with five types of cedar classification such as Class A, Class B, Class C, Class D, and Class E took using Logitech C930e HD which is integrated with Arduino Uno for object detection process and conveyor. The Experiment achieve 90% of accuracy with time computation 1,40 s. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Wood as a material for household appliance needs to be considered of quality. Quality of wood can be classified according to colours, texture, and wood fibre pattern differences. In general, wood industries have been doing the wood quality classified process using a conventional method with a sense of vision in which the results are subjective in terms of accuracy and time efficiency. Machine Learning is a solution to this problem of predicting and classifying data of wood quality. In this paper, the wood will be recognized using Histogram of Oriented Gradient to know the pattern and texture. Meanwhile, the classification method uses Support Vector Machine which will be compared to find the best accuracy and time computation. This system is given image input with five types of cedar classification such as Class A, Class B, Class C, Class D, and Class E took using Logitech C930e HD which is integrated with Arduino Uno for object detection process and conveyor. The Experiment achieve 90% of accuracy with time computation 1,40 s. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Quality image enhancement from low resolution camera using convolutional neural network"
        ],
        "penulis":"Patmawati, Nopita Pratiwi;Arifianto, Anditya;Ramadhani, Kurniawan Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Images captured with various cameras have different qualities especially low-resolution images which generally have deficiencies in terms of quality. The uses of Convolutional Neural Network (CNN) in Super Resolution has been widely applied and has impressive performance results. It encourages the use of CNN to translate the captured images by low-resolution into a better resolution. In this paper, we propose a new architecture to perform image translation from low-resolution into a higher one using DenseNet with Skip-connections. The dataset used is taken from the DPED (DSLR-Photo Enhancement Dataset) which contains images captured from different cameras simultaneously. To get results that can be used by all camera models, a transfer learning scenario is added. Using our architecture, we were able to achieve results with average PSNR of 20,86 dB and 0,9307 SSIM which was better than the comparison architecture. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Images captured with various cameras have different qualities especially low-resolution images which generally have deficiencies in terms of quality. The uses of Convolutional Neural Network (CNN) in Super Resolution has been widely applied and has impressive performance results. It encourages the use of CNN to translate the captured images by low-resolution into a better resolution. In this paper, we propose a new architecture to perform image translation from low-resolution into a higher one using DenseNet with Skip-connections. The dataset used is taken from the DPED (DSLR-Photo Enhancement Dataset) which contains images captured from different cameras simultaneously. To get results that can be used by all camera models, a transfer learning scenario is added. Using our architecture, we were able to achieve results with average PSNR of 20,86 dB and 0,9307 SSIM which was better than the comparison architecture. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Clustering data in power management system using k-means clustering algorithm"
        ],
        "penulis":"Aryani, Ressy;Nasrun, Muhammad;Setianingsih, Casi;Murti, Muhammad Ary;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electricity is a source of current that cannot be released from life because it is needed as a means of production and helps solve problems in daily life. Most users use electricity without realizing the amount of electricity used in that period, it can make electricity usage soar because there is no control of electricity usage. The problem of the amount of electricity usage also occurs in campus buildings, logistics staff cannot control the use of electricity because there is no history of electricity usage in certain buildings. To solve this problem, an IOT-based KWH electricity usage monitoring system was built. Furthermore, this application has a data clustering calculation using the KMeans algorithm which aims to classify campus area data according to its electricity usage whether it enters areas that use large, normal or low loads. By using information from the data clustering, logistics employees can make a policy to make electricity savings. This system has three main parts, namely the hardware system, IoT server, and website monitoring application. In this research focuses on making website monitoring and clustering data applications. From the results of tests conducted by the K-Means algorithm has the highest accuracy value of 83.3%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electricity is a source of current that cannot be released from life because it is needed as a means of production and helps solve problems in daily life. Most users use electricity without realizing the amount of electricity used in that period, it can make electricity usage soar because there is no control of electricity usage. The problem of the amount of electricity usage also occurs in campus buildings, logistics staff cannot control the use of electricity because there is no history of electricity usage in certain buildings. To solve this problem, an IOT-based KWH electricity usage monitoring system was built. Furthermore, this application has a data clustering calculation using the KMeans algorithm which aims to classify campus area data according to its electricity usage whether it enters areas that use large, normal or low loads. By using information from the data clustering, logistics employees can make a policy to make electricity savings. This system has three main parts, namely the hardware system, IoT server, and website monitoring application. In this research focuses on making website monitoring and clustering data applications. From the results of tests conducted by the K-Means algorithm has the highest accuracy value of 83.3%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Sparse and Low Rank Matrices based Algorithm for Anomaly Detection and Classification in Network Traffic Monitoring"
        ],
        "penulis":"Nugraheni, Pravita Dwi;Wahidah, Ida;Suratman, Fiky Y.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Increasing demands of users and internet services that occur at this time causes increasingly complex network infrastructure as well as more possible congested traffic on the network. It has an impact on the possibility of a system or network failure, and a decrease in QoS and the performance of a network, such as the occurrence of transient congestion on the network, which can cause many data packets to be dropped. To overcome this problem, the detection of anomalies on network traffic monitoring was carried out by utilizing the sparsity of the anomaly traffic matrix and low-rank property of the nominal traffic matrix, using the Batch Block Coordinate Descent (BCD) algorithm. Another important issue is the level of anomalies that occur on a network. To overcome the anomalies in the network, it will be more optimal if the severity is known. The advantage obtained by knowing the level of the anomaly is that it can prioritize anomalies that must be addressed first, so that early high losses due to anomalies can be avoided. Then, after the estimated anomaly is obtained, A, anomaly level classification is carried out. The level of the anomaly is divided into normal, low, medium and high levels. Constant values is used to generate anomaly data. In the process of determining the algorithm for classification of anomalies, the threshold-1 (low), \u03c41, is fixed based on the probability of false alarm, PFA=0.05. Then, threshold-2 (medium), \u03c42, and threshold-3 (high), \u03c43, are determined based on brute-force or exhausted search, by trying to shift the data sequences one by one to get the threshold with the most optimal accuracy. Performance tests with synthetic network data affirm the effectiveness of the proposed algorithms and their accuracy for anomaly level classification. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Increasing demands of users and internet services that occur at this time causes increasingly complex network infrastructure as well as more possible congested traffic on the network. It has an impact on the possibility of a system or network failure, and a decrease in QoS and the performance of a network, such as the occurrence of transient congestion on the network, which can cause many data packets to be dropped. To overcome this problem, the detection of anomalies on network traffic monitoring was carried out by utilizing the sparsity of the anomaly traffic matrix and low-rank property of the nominal traffic matrix, using the Batch Block Coordinate Descent (BCD) algorithm. Another important issue is the level of anomalies that occur on a network. To overcome the anomalies in the network, it will be more optimal if the severity is known. The advantage obtained by knowing the level of the anomaly is that it can prioritize anomalies that must be addressed first, so that early high losses due to anomalies can be avoided. Then, after the estimated anomaly is obtained, A, anomaly level classification is carried out. The level of the anomaly is divided into normal, low, medium and high levels. Constant values is used to generate anomaly data. In the process of determining the algorithm for classification of anomalies, the threshold-1 (low), \u03c41, is fixed based on the probability of false alarm, PFA=0.05. Then, threshold-2 (medium), \u03c42, and threshold-3 (high), \u03c43, are determined based on brute-force or exhausted search, by trying to shift the data sequences one by one to get the threshold with the most optimal accuracy. Performance tests with synthetic network data affirm the effectiveness of the proposed algorithms and their accuracy for anomaly level classification. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Security System ATM Machine with One-Time Passcode on M-Banking Application"
        ],
        "penulis":"Munadi, Rendy;Irawan, Arif Indra;Romiadi, Yuman Fariz;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Automated Teller Machine (ATM) security system currently still uses magnetic cards and static PIN as its security system, which create many security holes. This security hole in many cases caused many bank customers to lose money mysteriously. In this paper a two-factor authentication system which uses ATM card and dynamic PIN is proposed to overcome this security hole. In this paper, a prototype of an ATM and m-banking application were built. The ATM prototype uses several components such as the Raspberry Pi 3B, smart card, smart card reader \/ writer, keypad number and LCD monitor. Dynamic PINs are generated using the CSPRNG-SHA1-MWC random number generator. In developing the prototypes, the framework used in this study is based on mobile applications and cloud computing. To evaluate the quality of the prototype, we performed qualitative and quantitative tests. Qualitatively we tested the prototype using a questionnaire using 165 sample respondents to provide an opinion about the safety and comfort of our prototype and quantitatively we measured the prototype to find out the level of randomness of the generated PIN and the QoS of the designed prototype. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Automated Teller Machine (ATM) security system currently still uses magnetic cards and static PIN as its security system, which create many security holes. This security hole in many cases caused many bank customers to lose money mysteriously. In this paper a two-factor authentication system which uses ATM card and dynamic PIN is proposed to overcome this security hole. In this paper, a prototype of an ATM and m-banking application were built. The ATM prototype uses several components such as the Raspberry Pi 3B, smart card, smart card reader \/ writer, keypad number and LCD monitor. Dynamic PINs are generated using the CSPRNG-SHA1-MWC random number generator. In developing the prototypes, the framework used in this study is based on mobile applications and cloud computing. To evaluate the quality of the prototype, we performed qualitative and quantitative tests. Qualitatively we tested the prototype using a questionnaire using 165 sample respondents to provide an opinion about the safety and comfort of our prototype and quantitatively we measured the prototype to find out the level of randomness of the generated PIN and the QoS of the designed prototype. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The impact of Information and Communication Technology capability on the competitive advantage of small businesses"
        ],
        "penulis":"Qosasi, Achsanul;Maulina, Erna;Purnomo, Margo;Muftiadi, Anang;Permana, Erwin;Febrian, Fajri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The aim of this paper is to establish how Information and Communication Technology (ICT) capability has no effect on competitive advantage through the entrepreneurial orientation and organizational agility of Indonesian SMEs in the apparel retail sector. The study is based on resources that cannot be directly converted into the competitive advantage of companies but must instead be subjected to an entrepreneurial process and offer new insights into the use of ICT as a valuable corporate resource. The paper is based on a quantitative approach using a population comprising apparel retailers from traditional markets in Jakarta, Indonesia. The sample was obtained using random sampling. The survey was conducted among 462 small businesses across five traditional apparel markets managed by PD. Pasar Jaya. The data were processed using Structural Equation Modeling?Partial Least Squares. The results show that ICT capability has no significant effect on competitive advantage, although it does have a significant effect on entrepreneurial orientation and organizational agility. Organizational agility and entrepreneurial orientation have a significant effect on competitive advantage, thus indicating that ICT capability in small businesses cannot be directly converted into a competitive advantage. The finding of the research is that ICT capability is able to create competitive advantage in small businesses but only when present in conjunction with entrepreneurial orientation and organizational agility. \u00a9 IJTech 2019.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aim of this paper is to establish how Information and Communication Technology (ICT) capability has no effect on competitive advantage through the entrepreneurial orientation and organizational agility of Indonesian SMEs in the apparel retail sector. The study is based on resources that cannot be directly converted into the competitive advantage of companies but must instead be subjected to an entrepreneurial process and offer new insights into the use of ICT as a valuable corporate resource. The paper is based on a quantitative approach using a population comprising apparel retailers from traditional markets in Jakarta, Indonesia. The sample was obtained using random sampling. The survey was conducted among 462 small businesses across five traditional apparel markets managed by PD. Pasar Jaya. The data were processed using Structural Equation Modeling?Partial Least Squares. The results show that ICT capability has no significant effect on competitive advantage, although it does have a significant effect on entrepreneurial orientation and organizational agility. Organizational agility and entrepreneurial orientation have a significant effect on competitive advantage, thus indicating that ICT capability in small businesses cannot be directly converted into a competitive advantage. The finding of the research is that ICT capability is able to create competitive advantage in small businesses but only when present in conjunction with entrepreneurial orientation and organizational agility. \u00a9 IJTech 2019."
        ]
    },
    {
        "judul":[
            "Analysis of the Word2Vec model for semantic similarities in Indonesian words"
        ],
        "penulis":"Manalu, Louisten Novandi T;Bijaksana, Moch Arif;Suryani, Arie Ardiyanti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper examines the calculation of similarity between words in Indonesian by using the Word2Vec representation technique. Word2Vec is a model used to represent words into vector shapes. The model in this experiment was formed using the 4GB Indonesian Wikipedia corpus and then used the cosine similarity calculation method to determine its similarity value. This model is then tested with the gold standard set WordSim-353 and SimLex-999 which have been labeled with similarity values according to human ratings. To find out the accuracy of the correlation using the Pearson correlation. The results of the correlation of this study are 0.5663 for WordSim-353 test data using window size 14 and dimensions vector 150, and 0.3472 for SimLex-999 test data using window size 2 and dimensions vector 300. The results of the experiments show that the correlation between the gold standard and system techniques is still relatively weak.Our source code and data are available at: https:\/\/github.com\/louistenmanalu\/Word2Vec-Analysis-for-Indonesia-Languange.git. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper examines the calculation of similarity between words in Indonesian by using the Word2Vec representation technique. Word2Vec is a model used to represent words into vector shapes. The model in this experiment was formed using the 4GB Indonesian Wikipedia corpus and then used the cosine similarity calculation method to determine its similarity value. This model is then tested with the gold standard set WordSim-353 and SimLex-999 which have been labeled with similarity values according to human ratings. To find out the accuracy of the correlation using the Pearson correlation. The results of the correlation of this study are 0.5663 for WordSim-353 test data using window size 14 and dimensions vector 150, and 0.3472 for SimLex-999 test data using window size 2 and dimensions vector 300. The results of the experiments show that the correlation between the gold standard and system techniques is still relatively weak.Our source code and data are available at: https:\/\/github.com\/louistenmanalu\/Word2Vec-Analysis-for-Indonesia-Languange.git. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Comparison between least effort and random walk in combined shipping service"
        ],
        "penulis":"Kusuma, Purba Dam;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Now a days, city courier service is very popular, especially in Indonesia. This popularity is also boosted by the rise of online motorcycle taxi service. By using city courier service, local shipment can be delivered faster rather than regular courier service. One problem in this service is the combined shipping method has not implemented yet. So, for customer who sends more than one package to more than one destination, the cost is still calculated in regular price without any reduction. The other problem is even there is more than one shipment, customer has to create order one by one and the packages will be delivered by different driver. So, developing combined shipping system will benefit the customer and the driver. In this research, we propose combined shipping model for city courier service by comparing two methods: least effort and random walk algorithm. In this study, we compare the performance of combined shipping that uses least effort or random walk method and conventional one to one shipping model. In this research, we found that combined shipping that implements least effort algorithm produces the best performance both in non financial aspect and financial aspect. By using least effort algorithm, system generates lowest total driver travel distance and highest average driver's travel distance. The financial consequence is lowest total cost that must be paid by customer and highest average driver's revenue. \u00a9 Medwell Journals, 2019.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Now a days, city courier service is very popular, especially in Indonesia. This popularity is also boosted by the rise of online motorcycle taxi service. By using city courier service, local shipment can be delivered faster rather than regular courier service. One problem in this service is the combined shipping method has not implemented yet. So, for customer who sends more than one package to more than one destination, the cost is still calculated in regular price without any reduction. The other problem is even there is more than one shipment, customer has to create order one by one and the packages will be delivered by different driver. So, developing combined shipping system will benefit the customer and the driver. In this research, we propose combined shipping model for city courier service by comparing two methods: least effort and random walk algorithm. In this study, we compare the performance of combined shipping that uses least effort or random walk method and conventional one to one shipping model. In this research, we found that combined shipping that implements least effort algorithm produces the best performance both in non financial aspect and financial aspect. By using least effort algorithm, system generates lowest total driver travel distance and highest average driver's travel distance. The financial consequence is lowest total cost that must be paid by customer and highest average driver's revenue. \u00a9 Medwell Journals, 2019."
        ]
    },
    {
        "judul":[
            "Examining the Means of Engagement (MOE) for Enterprise Resource Planning (ERP) Adoption in Indonesia: Factors and Measures"
        ],
        "penulis":"Lubis, Muharman;Wardhani, Isty Rachmi;Witjaksono, Wahjoe;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research aims to develop a model that explain the means of engagement towards the usage of product service software of ERP by specifying the degree or intensification in term of agreement, acceptance, approval and adaption, which the latter has been focused on. Actually, by looking at the current engagement ways, there are many strategies measurement has been executed such as subscription, interaction, promotion, exploration and retention in order to maintain the loyalty of the user and developing complementary bond through understanding users' characteristics. This study focused on the implementation of a successful product adoption that applied in two companies. The analysis method uses in this study will be regression analysis with survey collection, which specified F test value, T-Test and significance value. The results of this research show that an involvement of the users in adopting ERP by simultaneously is affected by a product implementation with R Square values 91.4% for user decision, user characteristics factors and user convenience. It can be break down related to the significance usage approach that associated with a successful ERP adoption namely a submission of use factor, system performance, and satisfaction of use as well process of achievement. Based on the results, it can be concluded that to increase the success of ERP adoption in both companies, the training of ERP functionality system can support the process of increasing the ease of users in term of system performance and company's business although the assessment should be done regularly. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research aims to develop a model that explain the means of engagement towards the usage of product service software of ERP by specifying the degree or intensification in term of agreement, acceptance, approval and adaption, which the latter has been focused on. Actually, by looking at the current engagement ways, there are many strategies measurement has been executed such as subscription, interaction, promotion, exploration and retention in order to maintain the loyalty of the user and developing complementary bond through understanding users' characteristics. This study focused on the implementation of a successful product adoption that applied in two companies. The analysis method uses in this study will be regression analysis with survey collection, which specified F test value, T-Test and significance value. The results of this research show that an involvement of the users in adopting ERP by simultaneously is affected by a product implementation with R Square values 91.4% for user decision, user characteristics factors and user convenience. It can be break down related to the significance usage approach that associated with a successful ERP adoption namely a submission of use factor, system performance, and satisfaction of use as well process of achievement. Based on the results, it can be concluded that to increase the success of ERP adoption in both companies, the training of ERP functionality system can support the process of increasing the ease of users in term of system performance and company's business although the assessment should be done regularly. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The development of archery games using motion capture and VR devices on archery virtual reality"
        ],
        "penulis":"Aprial, Riki Prasetia;Purboyo, Tito Waluyo;Ansori, Anton Raharjo Siswo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Motion capture is the process of capturing motion information, and the location of the subject over time. Animation production is the largest user of the Motion Capture system, examples of applications like movies, broadcasts, games, production stages, demonstration, and more. Motion capture is an attractive method for making movements in computer animation. Motion capture techniques rely on recording and retrieval of movements of humans, animals and inanimate objects as 3-dimensional data. This motion capture technique has various ways of applying it. With the development of technology as it is today, a new technology has been created, namely virtual reality. Virtual reality is a technology that allows us to interact with objects of imagination by using computers and displaying a 3-dimensional atmosphere that seems real. Virtual reality technology has also been widely used in the game world. Game is one of the entertainment media that is the choice of the community to eliminate boredom or just to fill their spare time. In addition to being an entertainment medium, games can also be a learning media to improve one's brain development. In this study, we will discuss archery games using motion capture and virtual reality (VR) devices on archery virtual reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Motion capture is the process of capturing motion information, and the location of the subject over time. Animation production is the largest user of the Motion Capture system, examples of applications like movies, broadcasts, games, production stages, demonstration, and more. Motion capture is an attractive method for making movements in computer animation. Motion capture techniques rely on recording and retrieval of movements of humans, animals and inanimate objects as 3-dimensional data. This motion capture technique has various ways of applying it. With the development of technology as it is today, a new technology has been created, namely virtual reality. Virtual reality is a technology that allows us to interact with objects of imagination by using computers and displaying a 3-dimensional atmosphere that seems real. Virtual reality technology has also been widely used in the game world. Game is one of the entertainment media that is the choice of the community to eliminate boredom or just to fill their spare time. In addition to being an entertainment medium, games can also be a learning media to improve one's brain development. In this study, we will discuss archery games using motion capture and virtual reality (VR) devices on archery virtual reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Adaptation of indigenous community agricultural systems on climate change (case study of Kasepuhan Ciptagelar, Sukabumi Regency, West Java)"
        ],
        "penulis":"Hapsari H.;Hapsari D.;Karyani T.;Fatimah S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Climate change is a threat to indigenous farming systems that rely on nature. Indigenous society has idiosyncrasies in managing agricultural systems that relate to nature. This study aims to examine the adaptation mechanism of indigenous farming systems to climate change in terms of social, economic, and technological aspects. The study was conducted in Indigenous Village of Kasepuhan Ciptagelar of Sukabumi Regency West Java. The research method is case study. The technique of collecting data through in-depth interviews with selected informants, participant observation, and focus group discussion (FGD). The results showed that the indigenous society of Kasepuhan Ciptagelar experienced the changes that occur in the environment as a result of climate change. Strategies to adapt to these changes, among others: (1) use natural resources in a sustainable manner, (2) preserve the customary positive impact on the environment, (3) do a crop rotation system, (4) managing the communal granary community food security system, (5) maintaining social values in the society, (6) establish cooperation with the agricultural institutions; (7) utilizing communication networks and information systems; (8) with some help from external parties in the repair of facilities and infrastructure, such as transportation and irrigation; (9) perform the processing of non-rice farming profit-oriented, and (10) instilling the values of local wisdom to the younger generation from an early age. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentZero hungerGoal 2Decent work and economic growthGoal 8Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Climate change is a threat to indigenous farming systems that rely on nature. Indigenous society has idiosyncrasies in managing agricultural systems that relate to nature. This study aims to examine the adaptation mechanism of indigenous farming systems to climate change in terms of social, economic, and technological aspects. The study was conducted in Indigenous Village of Kasepuhan Ciptagelar of Sukabumi Regency West Java. The research method is case study. The technique of collecting data through in-depth interviews with selected informants, participant observation, and focus group discussion (FGD). The results showed that the indigenous society of Kasepuhan Ciptagelar experienced the changes that occur in the environment as a result of climate change. Strategies to adapt to these changes, among others: (1) use natural resources in a sustainable manner, (2) preserve the customary positive impact on the environment, (3) do a crop rotation system, (4) managing the communal granary community food security system, (5) maintaining social values in the society, (6) establish cooperation with the agricultural institutions; (7) utilizing communication networks and information systems; (8) with some help from external parties in the repair of facilities and infrastructure, such as transportation and irrigation; (9) perform the processing of non-rice farming profit-oriented, and (10) instilling the values of local wisdom to the younger generation from an early age. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Implementation of python source code comparison results with Java using bubble sort method"
        ],
        "penulis":"Insanudin E.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the implementation of Python and Java source code comparison results are more focused on the scale of the ratio of the number of lines of code, file capacity, and access speed. As for the background of this writing because there are so many programming languages that can be used with the same results but overall we do not know which programming language is more optimal and efficient in terms of the number of lines of code better known in the programming language is LOC (Line of Code) capacity of file access speed. In this study, the authors focus only on Java programming language and python course as a first step to know the ratio of the number of lines of code, file capacity, and access density. To determine the comparison there is a method used is bubble short. The results of the implementation of the comparison of these programming languages for Python programming language to produce the number of LOC (line of code) or the number of lines of code as much as 10, the capacity of the file extension.py by 506 bytes and txt extension of 397 bytes and access speed approximately for less more 4 seconds. While Java produces the number of LOC (line of code) or the number of lines of code as much as 11, the capacity of the file extension. Java of 86.2 Kbytes and extension txt of 477 bytes and access speed for 7 seconds. So do not close the possibility to make other applications python programming language will be more optimal and efficient. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the implementation of Python and Java source code comparison results are more focused on the scale of the ratio of the number of lines of code, file capacity, and access speed. As for the background of this writing because there are so many programming languages that can be used with the same results but overall we do not know which programming language is more optimal and efficient in terms of the number of lines of code better known in the programming language is LOC (Line of Code) capacity of file access speed. In this study, the authors focus only on Java programming language and python course as a first step to know the ratio of the number of lines of code, file capacity, and access density. To determine the comparison there is a method used is bubble short. The results of the implementation of the comparison of these programming languages for Python programming language to produce the number of LOC (line of code) or the number of lines of code as much as 10, the capacity of the file extension.py by 506 bytes and txt extension of 397 bytes and access speed approximately for less more 4 seconds. While Java produces the number of LOC (line of code) or the number of lines of code as much as 11, the capacity of the file extension. Java of 86.2 Kbytes and extension txt of 477 bytes and access speed for 7 seconds. So do not close the possibility to make other applications python programming language will be more optimal and efficient. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "First evidence of the presence of genotype-1 of Japanese encephalitis virus in Culex gelidus in Indonesia"
        ],
        "penulis":"Garjito, Triwibowo Ambar;Prihatin, Mega Tyas;Susanti, Lulus;Prastowo, Dhian;Sa'Adah, Siti Rofiatus;Taviv, Yulian;Satoto, Tri Baskoro Tunggul;Waluyo, Joko;Manguin, Sylvie;Frutos, Roger;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Background: Japanese encephalitis has become a public health threat in Indonesia. Three genotypes have been recorded in Indonesia, i.e. genotype II (GII), genotype III (GIII) and genotype IV (GIV). Genotype I (GI) and genotype V (GV) have never been reported in Indonesia. Results: A Japanese encephalitis virus (JEV) belonging to the genotype I-a (GI-a) has been isolated for the first time from a Culex gelidus mosquito in the Province of Jambi, Indonesia. This virus is related to a 1983 isolate from Thailand whereas the infected Cx. gelidus mosquito belonged to a Chinese haplotype. Conclusions: Surveillance of JEV and mosquito dissemination is recommended. \u00a9 2019 The Author(s).",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Background: Japanese encephalitis has become a public health threat in Indonesia. Three genotypes have been recorded in Indonesia, i.e. genotype II (GII), genotype III (GIII) and genotype IV (GIV). Genotype I (GI) and genotype V (GV) have never been reported in Indonesia. Results: A Japanese encephalitis virus (JEV) belonging to the genotype I-a (GI-a) has been isolated for the first time from a Culex gelidus mosquito in the Province of Jambi, Indonesia. This virus is related to a 1983 isolate from Thailand whereas the infected Cx. gelidus mosquito belonged to a Chinese haplotype. Conclusions: Surveillance of JEV and mosquito dissemination is recommended. \u00a9 2019 The Author(s)."
        ]
    },
    {
        "judul":[
            "Noise Removal in Mild Cognitive Impairment EEG Recording using Empirical Mode Decomposition"
        ],
        "penulis":"Hadiyoso, Sugondo;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "EEG signals contain large amounts of random noise, such as artifacts and baseline changes. These noises appear at low frequencies, which may disturb the real activity of the EEG signal. Visual observation method often used to mark then removing the noise. However, this conventional method takes much time, requires experts to do the annotation, and has a huge possibility of error. One method that can be used to remove this interference is Empirical Mode Decomposition (EMD). EMD produces two essential parts of the signal, namely intrinsic mode function (IMF) and residue. This study applies EMD to remove artifacts that are present in EEG signals. The performance measured by calculating the RMSE and spectral power. From the test, obtained the average value of RMSE 0.0295 and signal power at frequencies below 1 Hz is 0.004 dB. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "EEG signals contain large amounts of random noise, such as artifacts and baseline changes. These noises appear at low frequencies, which may disturb the real activity of the EEG signal. Visual observation method often used to mark then removing the noise. However, this conventional method takes much time, requires experts to do the annotation, and has a huge possibility of error. One method that can be used to remove this interference is Empirical Mode Decomposition (EMD). EMD produces two essential parts of the signal, namely intrinsic mode function (IMF) and residue. This study applies EMD to remove artifacts that are present in EEG signals. The performance measured by calculating the RMSE and spectral power. From the test, obtained the average value of RMSE 0.0295 and signal power at frequencies below 1 Hz is 0.004 dB. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Room Map Estimation from Two-Dimensional Lidar's Point Cloud Data"
        ],
        "penulis":"Satyawan, Arief Suryadi;Kurniawan, Dayat;Armi, Nasrullah;Wijayanto, Yusuf Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "An automatic digital map estimation is not only essential for the repository of the architectural plans but also crucial for providing clear paths for a trajectory finder system, an autonomous vehicle, or a robot. Therefore, it is useful for reconstructing heritage buildings or finding a location lying in ruin after an earthquake. Rebuilding a digital map of a room can be done by using information from two-dimensional (2D) images. However, it seems to be complicated to obtain an accurate dimension directly from those images. One potential breakthrough is to make use of light detecting and ranging (LIDAR) technology. This state-of-the-art device can detect the solid surface of an object, as well as presenting an easiness of the distance measurements. This research focused on the reconstruction of a room map by utilizing 2D point cloud data obtained from a Lidar device. The results showed that by applying the conditioned random sample consensus (RANSAC) method, the 2D map of a room could be identified accurately from the 2D point cloud data. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An automatic digital map estimation is not only essential for the repository of the architectural plans but also crucial for providing clear paths for a trajectory finder system, an autonomous vehicle, or a robot. Therefore, it is useful for reconstructing heritage buildings or finding a location lying in ruin after an earthquake. Rebuilding a digital map of a room can be done by using information from two-dimensional (2D) images. However, it seems to be complicated to obtain an accurate dimension directly from those images. One potential breakthrough is to make use of light detecting and ranging (LIDAR) technology. This state-of-the-art device can detect the solid surface of an object, as well as presenting an easiness of the distance measurements. This research focused on the reconstruction of a room map by utilizing 2D point cloud data obtained from a Lidar device. The results showed that by applying the conditioned random sample consensus (RANSAC) method, the 2D map of a room could be identified accurately from the 2D point cloud data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Engaging customer experience in accelerating transformational performance through co-creation strategy"
        ],
        "penulis":"Alamsjah, Firdaus;Mihardjo, Leonardus W Wasono;Djoemadic, Faizal R.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Disruptive innovation shifts strategy from competition to collaboration. The collaboration with customers is also known as co-creation strategy and predominantly drives transformational performance. Transformational performance is based on performance management theory and transformation paradigms. However, its development to ensure the works of co-creation strategy, based on customer experience, remains unclear. To address this gap the digital transformational model based on co-creation strategy, with a focus on customer experience, was investigated to accelerate transformational performance. This study uses quantitative research, with a sample of 35 representatives from telecommunication firms. The findings demonstrate that co-creation strategy significantly supports customer experience, in driving transformational performance. Customer experience also appears to significantly impact co-creation strategy indirectly. The findings have theoretical implications for the emergence of collaboration strategy in the disruptive era. They show practitioners how co-creation strategy is becoming key in sustaining the business, as it shifts the focus onto the development of customer experience to drive transformational performance. Suggestions for future research are also included in the study. \u00a9 2019 Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Disruptive innovation shifts strategy from competition to collaboration. The collaboration with customers is also known as co-creation strategy and predominantly drives transformational performance. Transformational performance is based on performance management theory and transformation paradigms. However, its development to ensure the works of co-creation strategy, based on customer experience, remains unclear. To address this gap the digital transformational model based on co-creation strategy, with a focus on customer experience, was investigated to accelerate transformational performance. This study uses quantitative research, with a sample of 35 representatives from telecommunication firms. The findings demonstrate that co-creation strategy significantly supports customer experience, in driving transformational performance. Customer experience also appears to significantly impact co-creation strategy indirectly. The findings have theoretical implications for the emergence of collaboration strategy in the disruptive era. They show practitioners how co-creation strategy is becoming key in sustaining the business, as it shifts the focus onto the development of customer experience to drive transformational performance. Suggestions for future research are also included in the study. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Radar Software Development for the Surveillance of Indonesian Aerospace Sovereignty"
        ],
        "penulis":"Saputera, Yussi Perdana;Sulistyaningsih;Wahab, Mashury;Estu, Topik Teguh;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, design and development of air surveillance radar software using QT creator application is presented. The software manufacture was performed in two stages, where the first stage is to design a flowchart and the second stage is to create the program using codes. Radar software must be integrated with hardware to display the results of the target detection. All detection results will be shown on the plan position indicator (PPI) display. From the detection results, all flying objects that can reflect radar signals will be shown in the display, i.e., airplanes, clouds, birds, mountains, tall buildings, as long as they are still in the radar detection range. The radar software has been tested with very significant good results. To only see moving objects such as high-speed aircrafts, moving target indicator (MTI) feature is enabled. The radar software was shown to be able to track objects and to create guard zones feature as an observation area. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, design and development of air surveillance radar software using QT creator application is presented. The software manufacture was performed in two stages, where the first stage is to design a flowchart and the second stage is to create the program using codes. Radar software must be integrated with hardware to display the results of the target detection. All detection results will be shown on the plan position indicator (PPI) display. From the detection results, all flying objects that can reflect radar signals will be shown in the display, i.e., airplanes, clouds, birds, mountains, tall buildings, as long as they are still in the radar detection range. The radar software has been tested with very significant good results. To only see moving objects such as high-speed aircrafts, moving target indicator (MTI) feature is enabled. The radar software was shown to be able to track objects and to create guard zones feature as an observation area. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Design of IoT-based river water monitoring robot data transmission model using low power wide area network (LPWAN) communication technology"
        ],
        "penulis":"Lestari, Rahayu Dwi;Rusdinar, Angga;Murti, Muhammad Ary;Tawaqal, Gilang;Lee, Dongho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "River water monitoring system is one of the efforts as a contribution to control the pollution and\/or damage of the Citarum watershed in Indonesia based on Presidential Decree Number 15 of 2018. Monitoring of Citarum River water quality is essential because it is to know its condition. Despite that, regular monitoring requires water samples to be taken to the laboratory to be tested. Therefore it is not real-time and wasteful of energy. In this paper, a design of IoT-based river water quality monitoring-system using LPWAN communication technology will be proposed so that monitoring points on the Citarum watershed can be monitored in real-time and the results of monitoring data will be stored in the server for data logging. A test about communication range is performed with four nodes and one gateway with LoRa transceiver paired with Arduino boards, as LPWAN communication method, to be able to exchange information in terms of hardware and implement network mesh topologies to widen monitoring points in terms of software. It is shown from the test result that the communication range for the transmission between node to node or node to gateway reaches a maximum of 500 m close on the surface of the water. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentClean water and sanitationGoal 6Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "River water monitoring system is one of the efforts as a contribution to control the pollution and\/or damage of the Citarum watershed in Indonesia based on Presidential Decree Number 15 of 2018. Monitoring of Citarum River water quality is essential because it is to know its condition. Despite that, regular monitoring requires water samples to be taken to the laboratory to be tested. Therefore it is not real-time and wasteful of energy. In this paper, a design of IoT-based river water quality monitoring-system using LPWAN communication technology will be proposed so that monitoring points on the Citarum watershed can be monitored in real-time and the results of monitoring data will be stored in the server for data logging. A test about communication range is performed with four nodes and one gateway with LoRa transceiver paired with Arduino boards, as LPWAN communication method, to be able to exchange information in terms of hardware and implement network mesh topologies to widen monitoring points in terms of software. It is shown from the test result that the communication range for the transmission between node to node or node to gateway reaches a maximum of 500 m close on the surface of the water. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Facial recognition technique with combination method of local binary pattern histogram and image euclidean distance"
        ],
        "penulis":"Erwin;Saparudin;Fachrurrozi M.;Tamaarsa, Alvin;Zhang, Andy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to determine the level of precision, recall, and accuracy of performance of local binary pattern histogram and image euclidean distance for face image recognition. This research uses local binary pattern histogram method for segmenting face image and euclidean distance image for face image recognition. The proposed method started with the process of converting pixel value into a binary value, which then the value is used as a decimal value and the histogram is calculated, for then saved in the database. The trained facial image histogram will be compared with the histogram of the test data using the euclidean distance image formula. The result of this research shows realtime test result get 0.699 recall value and 0.7 precision value. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to determine the level of precision, recall, and accuracy of performance of local binary pattern histogram and image euclidean distance for face image recognition. This research uses local binary pattern histogram method for segmenting face image and euclidean distance image for face image recognition. The proposed method started with the process of converting pixel value into a binary value, which then the value is used as a decimal value and the histogram is calculated, for then saved in the database. The trained facial image histogram will be compared with the histogram of the test data using the euclidean distance image formula. The result of this research shows realtime test result get 0.699 recall value and 0.7 precision value. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "ECG based person authentication using empirical mode decomposition and discriminant analysis"
        ],
        "penulis":"Hadiyoso, Sugondo;Rizal, Achmad;Aulia, Suci;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Person identification or authentication through biometric features has been widely applied for basic access and high-level security. But conventional biometrics such as fingerprints and irises tend to be easily faked or duplicated. Therefore a new biometric modality is needed to overcome that problem. In this paper, we simulate a new model of biometric systems using physical signals of the body. The proposed biometric system is based on ECG signals as a characteristic of each subject. A total of 110 raw ECG signals with a duration of 5 seconds from 11 participants were demonstrated in the proposed system. Empirical mode decomposition (EMD) and statistical analysis are used for feature extraction. Discriminant analysis with cross-validation was applied to test the performance of the proposed method. In this research, the highest accuracy of 93.6% was obtained using subspace discriminant in the scenario of all feature attributes as predictors. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Person identification or authentication through biometric features has been widely applied for basic access and high-level security. But conventional biometrics such as fingerprints and irises tend to be easily faked or duplicated. Therefore a new biometric modality is needed to overcome that problem. In this paper, we simulate a new model of biometric systems using physical signals of the body. The proposed biometric system is based on ECG signals as a characteristic of each subject. A total of 110 raw ECG signals with a duration of 5 seconds from 11 participants were demonstrated in the proposed system. Empirical mode decomposition (EMD) and statistical analysis are used for feature extraction. Discriminant analysis with cross-validation was applied to test the performance of the proposed method. In this research, the highest accuracy of 93.6% was obtained using subspace discriminant in the scenario of all feature attributes as predictors. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Electronic Loads Control and Management Using Priority Queue Algorithm on Android Based Smartphone"
        ],
        "penulis":"Widhiono, Shofyan Arsyad;Murti, Muhammad Ary;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this modern age, electricity has become essential things in every aspect of living. To ensure its proper use, a program created to help regulate electricity usage based on user defined priority. In this study Priority Queue Algorithm is used to measure how long every can stay active so it will not drain user's monthly electricity target usage. The calculation process is done on android device then the execution order to turn the devices on or off are sent to database MySQL The result obtained from this research that priority queue algorithm is able to regulate electricity usage based on rule testing and fast response time to control and retrieve data from the database, 0.006s average time on manual control system, 0.005s average time on automatic control system, and 0.004s average time on retrieving data. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this modern age, electricity has become essential things in every aspect of living. To ensure its proper use, a program created to help regulate electricity usage based on user defined priority. In this study Priority Queue Algorithm is used to measure how long every can stay active so it will not drain user's monthly electricity target usage. The calculation process is done on android device then the execution order to turn the devices on or off are sent to database MySQL The result obtained from this research that priority queue algorithm is able to regulate electricity usage based on rule testing and fast response time to control and retrieve data from the database, 0.006s average time on manual control system, 0.005s average time on automatic control system, and 0.004s average time on retrieving data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Detecting the position of the sealring and the edge on the sensor chip"
        ],
        "penulis":"Panjaitan G.R.;Lhaksmana K.M.;Prakasa E.;Musa L.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "ALICE (A Large Ion Collider Experiment) is one of the physics projects developed by CERN. The project aims to observe the results of collisions between proton and proton, proton and nucleus, and nucleus with nucleus. Thousands of sensor chips are used to record the collision trajectory. Visual inspection with digital image processing has been developed to analyze the conditions of cutting the sensor chip, using the Hough Transform, Edge Detection, and Template Matching methods. The distance from the edge to the sealring chip will be used as a reference to determine how the condition of chip cutting. The results obtained are quite good and give a support for the next research process. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "ALICE (A Large Ion Collider Experiment) is one of the physics projects developed by CERN. The project aims to observe the results of collisions between proton and proton, proton and nucleus, and nucleus with nucleus. Thousands of sensor chips are used to record the collision trajectory. Visual inspection with digital image processing has been developed to analyze the conditions of cutting the sensor chip, using the Hough Transform, Edge Detection, and Template Matching methods. The distance from the edge to the sealring chip will be used as a reference to determine how the condition of chip cutting. The results obtained are quite good and give a support for the next research process. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparison of modulation schemes toward coverage area in indoor visible light communication"
        ],
        "penulis":"Supadiyanto, Andrik;Saputri, Desti Madya;Pamukti, Brian;Andini, Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper discusses about the effect of different modulation schemes on the coverage area of an indoor visible light communication. The idea of this research is based on the importance of using modulation techniques as needed. The main subject of this paper is power efficiency of each modulation referring to the coverage area. The modulation techniques used in this paper included On-Off keying Non return to zero (OOK-NRZ), On-Off Keying Return to Zero (OOK-RZ), Direct-current Biased Optical OFDM (DCO-OFDM), and Unipolar OFDM (U-OFDM). This paper presents the result of power efficiency, coverage area and Bit Error Rate performance of each modulation technique. The modulation technique producing the best performance in this paper was U-OFDM that had the highest power efficiency and the widest coverage area. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper discusses about the effect of different modulation schemes on the coverage area of an indoor visible light communication. The idea of this research is based on the importance of using modulation techniques as needed. The main subject of this paper is power efficiency of each modulation referring to the coverage area. The modulation techniques used in this paper included On-Off keying Non return to zero (OOK-NRZ), On-Off Keying Return to Zero (OOK-RZ), Direct-current Biased Optical OFDM (DCO-OFDM), and Unipolar OFDM (U-OFDM). This paper presents the result of power efficiency, coverage area and Bit Error Rate performance of each modulation technique. The modulation technique producing the best performance in this paper was U-OFDM that had the highest power efficiency and the widest coverage area. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design of IoT-based river water monitoring robot data transmission model using low power wide area network (LPWAN) communication technology"
        ],
        "penulis":"Lestari, Rahayu Dwi;Rusdinar, Angga;Murti, Muhammad Ary;Tawaqal, Gilang;Lee, Dongho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "River water monitoring system is one of the efforts as a contribution to control the pollution and\/or damage of the Citarum watershed in Indonesia based on Presidential Decree Number 15 of 2018. Monitoring of Citarum River water quality is essential because it is to know its condition. Despite that, regular monitoring requires water samples to be taken to the laboratory to be tested. Therefore it is not real-time and wasteful of energy. In this paper, a design of IoT-based river water quality monitoring-system using LPWAN communication technology will be proposed so that monitoring points on the Citarum watershed can be monitored in real-time and the results of monitoring data will be stored in the server for data logging. A test about communication range is performed with four nodes and one gateway with LoRa transceiver paired with Arduino boards, as LPWAN communication method, to be able to exchange information in terms of hardware and implement network mesh topologies to widen monitoring points in terms of software. It is shown from the test result that the communication range for the transmission between node to node or node to gateway reaches a maximum of 500 m close on the surface of the water. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentClean water and sanitationGoal 6Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "River water monitoring system is one of the efforts as a contribution to control the pollution and\/or damage of the Citarum watershed in Indonesia based on Presidential Decree Number 15 of 2018. Monitoring of Citarum River water quality is essential because it is to know its condition. Despite that, regular monitoring requires water samples to be taken to the laboratory to be tested. Therefore it is not real-time and wasteful of energy. In this paper, a design of IoT-based river water quality monitoring-system using LPWAN communication technology will be proposed so that monitoring points on the Citarum watershed can be monitored in real-time and the results of monitoring data will be stored in the server for data logging. A test about communication range is performed with four nodes and one gateway with LoRa transceiver paired with Arduino boards, as LPWAN communication method, to be able to exchange information in terms of hardware and implement network mesh topologies to widen monitoring points in terms of software. It is shown from the test result that the communication range for the transmission between node to node or node to gateway reaches a maximum of 500 m close on the surface of the water. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis LTE Picocell Design in Tamansari Parama Office Building PT Wika Realty"
        ],
        "penulis":"Hidayat, Aulia;Sujatmoko, Kris;Usman, Uke Kurniawan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Internet services with realtime Broadband Wireless Access technology such as freecall, instant messages, social media, video calls and so on nowadays are a common thing. But sometimes the signal is weak or the receiving power level is lacking which causes the maximum use of services. Tamansari Parama is an office building from PT WIKA which also serves for leasing other company offices. Employees and guests in the area complained about the problem of poor signal quality because the structure of the building dampened the signal from the outdoor site. So it is necessary to plan a picocell network in the Tamansari Parama building. Lack of signal strength in a place can be overcome by capacity planning and coverage planning as appropriate, such as using a picocell antenna. Planning results obtained RSRP value for basement floor which is equal to -74,67 dBm, 1st and mezzanine floors amounting to -73,12 dBm, 2nd to 5th floor of -73,70 dBm, and 6th to 16th floor which is equal to - 70,91 dBm. For SIR values on the basement floor are 8,90 dB, 1st floor and mezzanine is 10,88 dB, floors 2 to 5 are 38.96 dB, and floors 6 to 16 are 12.70 dB. From the simulation results, it meets the Key Performance Indicator (KPI). (Abstract) \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet services with realtime Broadband Wireless Access technology such as freecall, instant messages, social media, video calls and so on nowadays are a common thing. But sometimes the signal is weak or the receiving power level is lacking which causes the maximum use of services. Tamansari Parama is an office building from PT WIKA which also serves for leasing other company offices. Employees and guests in the area complained about the problem of poor signal quality because the structure of the building dampened the signal from the outdoor site. So it is necessary to plan a picocell network in the Tamansari Parama building. Lack of signal strength in a place can be overcome by capacity planning and coverage planning as appropriate, such as using a picocell antenna. Planning results obtained RSRP value for basement floor which is equal to -74,67 dBm, 1st and mezzanine floors amounting to -73,12 dBm, 2nd to 5th floor of -73,70 dBm, and 6th to 16th floor which is equal to - 70,91 dBm. For SIR values on the basement floor are 8,90 dB, 1st floor and mezzanine is 10,88 dB, floors 2 to 5 are 38.96 dB, and floors 6 to 16 are 12.70 dB. From the simulation results, it meets the Key Performance Indicator (KPI). (Abstract) \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Data Reconstruction Accuracy of Compressive Sleeping Scheme with Modified S-MAC for Body Sensor Networks"
        ],
        "penulis":"Astuti, Elsa Nur Fitri;Wahidah, Ida;Suratman, Fiky Y.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Today the main difficulty in Body Sensor Network (BSN) is the limited battery power and accuracy of the data. Some cases in health monitoring requires a long sensor life time such as health monitoring of critical patients, so that the data is needed by doctors or hospitals can be fulfilled. The Compressive Sleeping algorithm and the scheduling scheme using the Medium Access Control Sensor (S-MAC) are proposed in this research, to reduce power consumption. First, Compressive Sleeping algorithm is applied to select a several of the sensor to be activated and a several of it will go into sleeping mode, the selection is based on the sensor type and remaining battery of each sensor. The output of this algorithm is several sensors that are suitable for active. Furthermore, the active sensor will be scheduling data transmission using S-MAC, scheduling is based on the sensor priority and remaining batteries of each priority. Sensors that do not transmit data will go into temporary sleep mode, then the sensor will be reactivated if it gets a turn to transmit data to the fusion center (FC). The calculation of energy consumption is carried out on each process block. We calculated the accuracy of all reconstructed data in the FC using the Orthogonal Matching pursuit algorithm (OMP). The results of this research produce a good energy efficiency, that is, for the sensor selection ratio of 40%, the energy efficiency is 67.03 % and data accuracy is 95.5%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Today the main difficulty in Body Sensor Network (BSN) is the limited battery power and accuracy of the data. Some cases in health monitoring requires a long sensor life time such as health monitoring of critical patients, so that the data is needed by doctors or hospitals can be fulfilled. The Compressive Sleeping algorithm and the scheduling scheme using the Medium Access Control Sensor (S-MAC) are proposed in this research, to reduce power consumption. First, Compressive Sleeping algorithm is applied to select a several of the sensor to be activated and a several of it will go into sleeping mode, the selection is based on the sensor type and remaining battery of each sensor. The output of this algorithm is several sensors that are suitable for active. Furthermore, the active sensor will be scheduling data transmission using S-MAC, scheduling is based on the sensor priority and remaining batteries of each priority. Sensors that do not transmit data will go into temporary sleep mode, then the sensor will be reactivated if it gets a turn to transmit data to the fusion center (FC). The calculation of energy consumption is carried out on each process block. We calculated the accuracy of all reconstructed data in the FC using the Orthogonal Matching pursuit algorithm (OMP). The results of this research produce a good energy efficiency, that is, for the sensor selection ratio of 40%, the energy efficiency is 67.03 % and data accuracy is 95.5%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Throughput improvement of an autocorrelation block for time synchronization in OFDM-based LiFi"
        ],
        "penulis":"Setiawan, Erwin;Adiono, Trio;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, the throughput improvement of an autocorrelation block is presented. The improvement is carried out by employing pipeline architecture. The autocorrelation block is used for time synchronization in OFDM-based Visible Light Communication (VLC) system. The autocorrelation block estimates the coarse time offset of the received OFDM data symbol. By adding pipeline registers, we can reduce the critical path of the combinational circuits by dividing it into smaller critical path, therefore the clock frequency can be increased. We show three times throughput improvement by using four stages pipeline architecture. The maximum clock frequency of the block is 188 MHz. The block has been implemented and verified on Xilinx Zynq-7000 FPGA. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, the throughput improvement of an autocorrelation block is presented. The improvement is carried out by employing pipeline architecture. The autocorrelation block is used for time synchronization in OFDM-based Visible Light Communication (VLC) system. The autocorrelation block estimates the coarse time offset of the received OFDM data symbol. By adding pipeline registers, we can reduce the critical path of the combinational circuits by dividing it into smaller critical path, therefore the clock frequency can be increased. We show three times throughput improvement by using four stages pipeline architecture. The maximum clock frequency of the block is 188 MHz. The block has been implemented and verified on Xilinx Zynq-7000 FPGA. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Context-aware based restaurant recommender system: A prescriptive analytics"
        ],
        "penulis":"Achmad, Kusuma Adi;Nugroho, Lukito Edi;Djunaedi, Achmad;Widyawan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Providing recommendations for products or services based on users\u2019 preferences and current conditions could be more efficient by using a context-based recommender system. It is important and useful to understand the consideration of what should be done by users to visit (prescriptive analytics) based on processed input data optimization. However, discussions and analysis of this system use are still limited. It is noted that prescriptive models can be developed by utilizing or optimizing inputs based on the chosen class rating. In the prediction function, the context-based recommender system can not only be used to predict Good, Neutral, and Bad rating values to produce predictive analytics, but also can be used to optimize input to produce prescriptive analytics. It can be seen that the evaluation of rating predictions using Deep Learning Models showed high accuracy in the performance compared to the Decision Tree and Random Forest. In this model, classification errors were considered the smallest compared to other models. Evaluation of input optimization for prescriptive analytics for class rating predictions showed the highest performance. The research contributes to a better understanding of developing a predictive and prescriptive analytics approach to a context-based recommender system model. \u00a9 School of Engineering, Taylor\u2019s University.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Providing recommendations for products or services based on users\u2019 preferences and current conditions could be more efficient by using a context-based recommender system. It is important and useful to understand the consideration of what should be done by users to visit (prescriptive analytics) based on processed input data optimization. However, discussions and analysis of this system use are still limited. It is noted that prescriptive models can be developed by utilizing or optimizing inputs based on the chosen class rating. In the prediction function, the context-based recommender system can not only be used to predict Good, Neutral, and Bad rating values to produce predictive analytics, but also can be used to optimize input to produce prescriptive analytics. It can be seen that the evaluation of rating predictions using Deep Learning Models showed high accuracy in the performance compared to the Decision Tree and Random Forest. In this model, classification errors were considered the smallest compared to other models. Evaluation of input optimization for prescriptive analytics for class rating predictions showed the highest performance. The research contributes to a better understanding of developing a predictive and prescriptive analytics approach to a context-based recommender system model. \u00a9 School of Engineering, Taylor\u2019s University."
        ]
    },
    {
        "judul":[
            "Analysis of attribute selection and classification algorithm applied to hepatitis patients"
        ],
        "penulis":"Samsuddin, Sherylaidah;Shah, Zuraini Ali;Rohmat Saedudin R.D.;Kasim, Shahreen;Seah, Choon Sen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Data mining techniques are widely used in classification, attribute selection and prediction in the field of bioinformatics because it helps to discover meaningful new correlations, patterns and trends by sifting through large volume of data, using pattern recognition technologies as well as statistical and mathematical techniques. Hepatitis is one of the most important health problem in the world. Many studies have been performed in the diagnosis of hepatitis disease but medical diagnosis is quite difficult and visual task which is mostly done by doctors. Therefore, this research is conducted to analyse the attribute selection and classification algorithm that applied to hepatitis patients. In order to achieve goals, WEKA tool is used to conduct the experiment with different attribute selector and classification algorithm . Hepatitis dataset that are used is taken from UC Irvine repository. This research deals with various attribute selector namely CfsSubsetEval, WrapperSubsetEval, GainRatioSubsetEval and CorrelationAttributeEval. The classification algorithm that used in this research are NaiveBayesUpdatable, SMO, KStar, RandomTree and SimpleLogistic. The results of the classification model are time and accuracy. Finally, it concludes that the best attribute selector is CfsSubsetEval while the best classifier is given to SMO because SMO performance is better than other classification techniques for hepatitis patients. \u00a9 2019 International Journal on Advanced Science Engineering Information Technology.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Affordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data mining techniques are widely used in classification, attribute selection and prediction in the field of bioinformatics because it helps to discover meaningful new correlations, patterns and trends by sifting through large volume of data, using pattern recognition technologies as well as statistical and mathematical techniques. Hepatitis is one of the most important health problem in the world. Many studies have been performed in the diagnosis of hepatitis disease but medical diagnosis is quite difficult and visual task which is mostly done by doctors. Therefore, this research is conducted to analyse the attribute selection and classification algorithm that applied to hepatitis patients. In order to achieve goals, WEKA tool is used to conduct the experiment with different attribute selector and classification algorithm . Hepatitis dataset that are used is taken from UC Irvine repository. This research deals with various attribute selector namely CfsSubsetEval, WrapperSubsetEval, GainRatioSubsetEval and CorrelationAttributeEval. The classification algorithm that used in this research are NaiveBayesUpdatable, SMO, KStar, RandomTree and SimpleLogistic. The results of the classification model are time and accuracy. Finally, it concludes that the best attribute selector is CfsSubsetEval while the best classifier is given to SMO because SMO performance is better than other classification techniques for hepatitis patients. \u00a9 2019 International Journal on Advanced Science Engineering Information Technology."
        ]
    },
    {
        "judul":[
            "Design of radar display of Indonesian airspace monitoring application"
        ],
        "penulis":"Sulistyaningsih;Saputera, Yussi Perdana;Wahab, Mashury;Maulana, Yudi Yulius;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this research, the design and manufacture of radar display software using Plan Position Indicator (PPI) format for air surveillance radar application are presented. The PPI display shows interpretations of echo detections of radar signal reflected from the flying objects\/targets. The detection results will be displayed on a circular 360\u00b0 area, where the radar position is at the center. System configuration is done via interface from the display, by adjusting the level of transmit signal, by setting the gain for threshold, and by enabling moving target indicator (MTI) mode. The MTI mode only displays moving objects and no non-moving objects are shown such as mountains and buildings. Based on the results of this research, the PPI display shows the targets on the display according to its position, some desired targets can also be tracked, information on target, GPS location, target ID, required parameters, and some settings. The radar display fulfills all the required capabilities for air surveillance radar. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this research, the design and manufacture of radar display software using Plan Position Indicator (PPI) format for air surveillance radar application are presented. The PPI display shows interpretations of echo detections of radar signal reflected from the flying objects\/targets. The detection results will be displayed on a circular 360\u00b0 area, where the radar position is at the center. System configuration is done via interface from the display, by adjusting the level of transmit signal, by setting the gain for threshold, and by enabling moving target indicator (MTI) mode. The MTI mode only displays moving objects and no non-moving objects are shown such as mountains and buildings. Based on the results of this research, the PPI display shows the targets on the display according to its position, some desired targets can also be tracked, information on target, GPS location, target ID, required parameters, and some settings. The radar display fulfills all the required capabilities for air surveillance radar. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Smart Lamp Control Based on User Behavior for Two Lamps Using K-Nearest Neighbour"
        ],
        "penulis":"Nugroho, Triono;Nasrun, Muhammad;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The number of housing needs each year increases. And these problems have an impact on the use of electricity every year. This condition results in the expense of excess electricity. To anticipate electricity energy savings, management of electronic devices is needed. With the existence of modern technology, the concept of home itself is starting to be integrated with the automation system, one of which is a smart home. In this study an automation system will be created to record user behavior in using electronic devices. By using the K-Nearest Neighbor classification method, data on user behavior recorded will be used as a set of information processed by the system to make predictions on a device. So that the automation system can work according to user behavior. The results of system performance testing in classifying data produce an average accuracy of 97.62% for lamp one, and 98.36% for lamp two. These results are predictive results that are not necessarily accurate according to the actual conditions, due to different user behavior.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The number of housing needs each year increases. And these problems have an impact on the use of electricity every year. This condition results in the expense of excess electricity. To anticipate electricity energy savings, management of electronic devices is needed. With the existence of modern technology, the concept of home itself is starting to be integrated with the automation system, one of which is a smart home. In this study an automation system will be created to record user behavior in using electronic devices. By using the K-Nearest Neighbor classification method, data on user behavior recorded will be used as a set of information processed by the system to make predictions on a device. So that the automation system can work according to user behavior. The results of system performance testing in classifying data produce an average accuracy of 97.62% for lamp one, and 98.36% for lamp two. These results are predictive results that are not necessarily accurate according to the actual conditions, due to different user behavior.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Object Tracking Augmented Reality Markerless using FAST Corner Detection on User Defined-Extended Target Tracking in Multivarious Intensities"
        ],
        "penulis":"Nurhadi;Saparudin;Adam N.;Purnamasari D.;Fachruddin;Ibrahim, Ali;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents a FAST Corner Detection object scanning to improve SLAM technique, which is SLAM, has a weakness in extracting features in the real-world object. The use of User Defined Target and Extended Tracking are for making this work more convenient and reliable. We can trace the object even though the object does not exist, so this improves the function of markerless itself. The use of Raycast is for the make labeling the objects or features in the scanned object. In this research, we executed multivarious intensity to test the FAST Corner Detection to increase function in real world feature extraction and prove it better than SLAM. Then, we got the result where is a brighter condition will get faster recognition. The best environments for augmentation are in the range of 80-190, they took in less than 1 second. On the contrary, the intensity outside of the range such as \u226450 or \u2265200, has a deficiency of augmentation. The range of \u226450, there was no augmentation cause of low intensity. For the range of \u2265200, we haven't made measurements as we don't have the resources yet, but we hypothesize that the object would be corrupt or we may call it was overexposure cause of the intensity is too high. So, this could also lead to augmentation will not occur. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents a FAST Corner Detection object scanning to improve SLAM technique, which is SLAM, has a weakness in extracting features in the real-world object. The use of User Defined Target and Extended Tracking are for making this work more convenient and reliable. We can trace the object even though the object does not exist, so this improves the function of markerless itself. The use of Raycast is for the make labeling the objects or features in the scanned object. In this research, we executed multivarious intensity to test the FAST Corner Detection to increase function in real world feature extraction and prove it better than SLAM. Then, we got the result where is a brighter condition will get faster recognition. The best environments for augmentation are in the range of 80-190, they took in less than 1 second. On the contrary, the intensity outside of the range such as \u226450 or \u2265200, has a deficiency of augmentation. The range of \u226450, there was no augmentation cause of low intensity. For the range of \u2265200, we haven't made measurements as we don't have the resources yet, but we hypothesize that the object would be corrupt or we may call it was overexposure cause of the intensity is too high. So, this could also lead to augmentation will not occur. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Implementation of power inverter on grid connected photovoltaic generator system"
        ],
        "penulis":"Prastyo, Argo;Ekaputri, Cahyantarie;Reza, Muhamad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The issuance of ESDM (ministry of energy and mineral resources) regulation number 49 of 2018 concerning the use of a rooftop solar power generation system by consumers of PT PLN (Persero). It is encouraging to conduct research on one method of generating electricity using solar panels. The voltage generated in the generation process using solar panels is a direct voltage (DC) and requires an inverter as a voltage converter to be an alternating voltage (AC) which is the daily consumption of Indonesian people. This research aims to develop the use of renewable energy using an inverter. This inverter uses batteries as a source of voltage, Arduino as a source of SPWM waves, and MOSFETs are arranged in a full-bridge configuration to convert 12V DC electricity into 12VAC which will then be filtered using a low-pass filter to pass a 50 Hz frequency and then increase the voltage using a transformer to 220Vmax \/ 155 Vrms. The result of designing this research is that the inverter is able to produce a sinusoidal wave output 220 Vmax with a frequency of 50 Hz. With the output signal approaching the sinusoidal signal purely from the filter output, the power loss from the use of the transformer causes the power output from the inverter to be not optimal. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The issuance of ESDM (ministry of energy and mineral resources) regulation number 49 of 2018 concerning the use of a rooftop solar power generation system by consumers of PT PLN (Persero). It is encouraging to conduct research on one method of generating electricity using solar panels. The voltage generated in the generation process using solar panels is a direct voltage (DC) and requires an inverter as a voltage converter to be an alternating voltage (AC) which is the daily consumption of Indonesian people. This research aims to develop the use of renewable energy using an inverter. This inverter uses batteries as a source of voltage, Arduino as a source of SPWM waves, and MOSFETs are arranged in a full-bridge configuration to convert 12V DC electricity into 12VAC which will then be filtered using a low-pass filter to pass a 50 Hz frequency and then increase the voltage using a transformer to 220Vmax \/ 155 Vrms. The result of designing this research is that the inverter is able to produce a sinusoidal wave output 220 Vmax with a frequency of 50 Hz. With the output signal approaching the sinusoidal signal purely from the filter output, the power loss from the use of the transformer causes the power output from the inverter to be not optimal. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Lean manufacturing performance and organizational culture: An exploratory study"
        ],
        "penulis":"Salma, Sheila Amalia;Gafigi, Mohammad Andi;Rahma, Karyma Talitha;Widyanti, Ari;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Lean manufacturing is an approach to enhancing productivity through lean thinking. The success of the lean manufacturing application is influenced by various factors, one of them is the organizational culture. This study aims to explore lean manufacturing and organizational culture in an Indonesian aircraft manufacturer. Ninety workers in three production divisions (i.e., Detailed Part Manufacturing\/DPM, Component Assembly\/CA, Final Assyline & Delivery Center\/FAL & DC) in the aircraft manufacture are involved in this study voluntarily by filling out a set of questionnaire. Lean manufacturing performance is observed using Lean Manufacturing Benchmark, whereas organizational culture is evaluated using the Organizational Culture Assessment Instrument. The result shows that lean performance for DPM is 57%, CA is 61%, FAL & DC is 59%. All divisions have no dominant culture. However, the increased of lean performance is along with the increased hierarchy and clan culture, and the decreased of market and adhocracy culture. Implications of the results are discussed. \u00a9 2019 Author(s).",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Lean manufacturing is an approach to enhancing productivity through lean thinking. The success of the lean manufacturing application is influenced by various factors, one of them is the organizational culture. This study aims to explore lean manufacturing and organizational culture in an Indonesian aircraft manufacturer. Ninety workers in three production divisions (i.e., Detailed Part Manufacturing\/DPM, Component Assembly\/CA, Final Assyline & Delivery Center\/FAL & DC) in the aircraft manufacture are involved in this study voluntarily by filling out a set of questionnaire. Lean manufacturing performance is observed using Lean Manufacturing Benchmark, whereas organizational culture is evaluated using the Organizational Culture Assessment Instrument. The result shows that lean performance for DPM is 57%, CA is 61%, FAL & DC is 59%. All divisions have no dominant culture. However, the increased of lean performance is along with the increased hierarchy and clan culture, and the decreased of market and adhocracy culture. Implications of the results are discussed. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Coverage and capacity analysis of LoRa WAN deployment for massive IoT in urban and suburban scenario"
        ],
        "penulis":"Nashiruddin, Muhammad Imam;Hidayati, Amriane;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Choosing connectivity technologies for the Internet of Things (IoT) is the most important aspect in the early stages of network planning. Long Range (LoRa) Wide Area Network (WAN) that categorized into Low Power Wide Area (LPWA) network is a potential connectivity technology for typical massive IoT applications like a smart meter, smart manufacturing, environmental monitoring, etc. This paper aims to provide coverage and capacity analysis of LoRa WAN for typical massive IoT application. The urban and suburban areas were chosen to observe the differences between those two scenarios. The results shown the capacity calculation in terms of the gateways needed is mainly influenced by the value of the bandwidth (BW), spreading factor (SF) and Coding Rate (CR). Coverage simulation is done by calculating the link budget, followed by a simulation using Forsk Atoll 3.3.2. It can be concluded that the whole determined areas can be served within acceptable levels with values > -137 dBm as the minimum sensitivity of the highest SF. While the mean of best signal level is -84.58 dBm and -90.9 dBm for the urban and suburban scenario, respectively.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Choosing connectivity technologies for the Internet of Things (IoT) is the most important aspect in the early stages of network planning. Long Range (LoRa) Wide Area Network (WAN) that categorized into Low Power Wide Area (LPWA) network is a potential connectivity technology for typical massive IoT applications like a smart meter, smart manufacturing, environmental monitoring, etc. This paper aims to provide coverage and capacity analysis of LoRa WAN for typical massive IoT application. The urban and suburban areas were chosen to observe the differences between those two scenarios. The results shown the capacity calculation in terms of the gateways needed is mainly influenced by the value of the bandwidth (BW), spreading factor (SF) and Coding Rate (CR). Coverage simulation is done by calculating the link budget, followed by a simulation using Forsk Atoll 3.3.2. It can be concluded that the whole determined areas can be served within acceptable levels with values > -137 dBm as the minimum sensitivity of the highest SF. While the mean of best signal level is -84.58 dBm and -90.9 dBm for the urban and suburban scenario, respectively.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Air quality monitoring system based internet of things (IoT) using LPWAN LoRa"
        ],
        "penulis":"Firdaus, Rizky;Murti, Muhammad Ary;Alinursafa, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Air has an important function and role in the lives of humans and other living beings. Every living things needs clean air to support its life optimally, its quality needs to be maintained. A good and healthy level of air quality is one of the main factors in creating a healthy and comfortable environment if the air quality is bad then there will be pollution that will interfere with the health of every population that inhaled. In this research, the author utilizes the Internet of Things (IoT) technology to monitor the condition of air quality levels such as temperature, air humidity, CO and CO2. The system uses ATmega328P-AU as a controller, DHT22 sensor for temperature and air humidity, MQ-7 sensor for CO gas, MQ-135 sensor for CO2 gas, LPWAN LoRa for data transmission communication and Antares as a cloud service for storing data to be displayed on Android. The test results obtained the average error value for temperatures \u00b1 0.8 \u00b0C, humidity \u00b1 3.1 % RH, CO \u00b1 10 ppm and CO2 \u00b1 16 ppm. The results of sensor data are stored in the Antares cloud and displayed on Android. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Air has an important function and role in the lives of humans and other living beings. Every living things needs clean air to support its life optimally, its quality needs to be maintained. A good and healthy level of air quality is one of the main factors in creating a healthy and comfortable environment if the air quality is bad then there will be pollution that will interfere with the health of every population that inhaled. In this research, the author utilizes the Internet of Things (IoT) technology to monitor the condition of air quality levels such as temperature, air humidity, CO and CO2. The system uses ATmega328P-AU as a controller, DHT22 sensor for temperature and air humidity, MQ-7 sensor for CO gas, MQ-135 sensor for CO2 gas, LPWAN LoRa for data transmission communication and Antares as a cloud service for storing data to be displayed on Android. The test results obtained the average error value for temperatures \u00b1 0.8 \u00b0C, humidity \u00b1 3.1 % RH, CO \u00b1 10 ppm and CO2 \u00b1 16 ppm. The results of sensor data are stored in the Antares cloud and displayed on Android. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Speed and steering control system for self-driving car prototype"
        ],
        "penulis":"Rafsanjani;Wibawa I.P.D.;Ekaputri C.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A self-driving car is a vehicle that can run autonomously using a control. There are two systems that are controlled in this research. The first-speed control functions to regulate the speed and movement of the self-driving car prototype by adjusting the PWM value on the DC motor and second, the steering control uses the Ackerman steering system with a servo motor as an actuator. Both are arranged using fuzzy logic control methods that adapt from the habits in driving a car. the goal self-driving car prototype can walk to follow the track, maintain the robot car in the middle of the lane, can adjust the speed when turning and can stop when there are obstacles or traffic lights. The results of the control design testing in this study are, the average error value in the simulation is 0.771008 for the servo angle and 0.392072 for the speed. The error value in the programming algorithm is 0.149712 for servo angles and 0.198168 for PWM DC motors. Robot cars in accordance with the logic of the fuzzy rules made. Self-driving car prototypes can run turns and follow trajectories with a success rate of 93.33%. The distance between the robot car and the track is 1.83 cm inside the track and 0.03 cm outside the track. The self-driving car prototype can adjust its speed and can stop when there are obstacles with an average distance of 29.89 cm. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A self-driving car is a vehicle that can run autonomously using a control. There are two systems that are controlled in this research. The first-speed control functions to regulate the speed and movement of the self-driving car prototype by adjusting the PWM value on the DC motor and second, the steering control uses the Ackerman steering system with a servo motor as an actuator. Both are arranged using fuzzy logic control methods that adapt from the habits in driving a car. the goal self-driving car prototype can walk to follow the track, maintain the robot car in the middle of the lane, can adjust the speed when turning and can stop when there are obstacles or traffic lights. The results of the control design testing in this study are, the average error value in the simulation is 0.771008 for the servo angle and 0.392072 for the speed. The error value in the programming algorithm is 0.149712 for servo angles and 0.198168 for PWM DC motors. Robot cars in accordance with the logic of the fuzzy rules made. Self-driving car prototypes can run turns and follow trajectories with a success rate of 93.33%. The distance between the robot car and the track is 1.83 cm inside the track and 0.03 cm outside the track. The self-driving car prototype can adjust its speed and can stop when there are obstacles with an average distance of 29.89 cm. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "The evaluation of finance module implementation of enterprise resource planning (ERP) for employee performance"
        ],
        "penulis":"Hafifah, Dayane Kamila;Witarsyah, Deden;Saputra, Muhardi;Azizah, Anik Hanifatul;Eka Saputri, Marhaeni;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Information technology can improve efficiency, effectiveness, and productivity that have an impact on individual performance. However, many companies don't have an integrated information system to support the activity. The process is only supported by individual activities on each site. This study aims to determine how the impact of the application and use of the System Applications and Product (SAP) on employee performance using Task Technology Fit (TTF) Model. Data collection methods used in this study are quantitative and qualitative methods. Data obtained based on the results of questionnaires involving 100 respondents and make some interviews with employee representatives in five divisions. Data is processed using Smart PLS and SPSS. The results of this study show a positive influence on the performance of employees who use the SAP system. The model developed by Goodhue and Thompson explains that the use and attitudes of users towards technology to support individual performance, the strengths of this model are emphasizing the importance of conformity between task and technology in its effect on performance. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information technology can improve efficiency, effectiveness, and productivity that have an impact on individual performance. However, many companies don't have an integrated information system to support the activity. The process is only supported by individual activities on each site. This study aims to determine how the impact of the application and use of the System Applications and Product (SAP) on employee performance using Task Technology Fit (TTF) Model. Data collection methods used in this study are quantitative and qualitative methods. Data obtained based on the results of questionnaires involving 100 respondents and make some interviews with employee representatives in five divisions. Data is processed using Smart PLS and SPSS. The results of this study show a positive influence on the performance of employees who use the SAP system. The model developed by Goodhue and Thompson explains that the use and attitudes of users towards technology to support individual performance, the strengths of this model are emphasizing the importance of conformity between task and technology in its effect on performance. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Evaluation study of unsupervised face-to-face translation using generative adversarial networks"
        ],
        "penulis":"Iqbal, Muhamad;Widyanto, M. Rahmat;Adnan, Risman;Basaruddin T.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cross-domain image-to-image translation provides mechanism to capture special characteristics of one image collection and convert into other image collection with different representations. Recent research on generative learning have produced powerful image-toimage translation methods in supervised setting, where paired training datasets are available. However, collecting paired training data is difficult, expensive and required manual authoring. We present an evaluation study of recent unsupervised Generative Adversarial Network (GAN) models that can learn to translate a facial image from a source domain X to a target domain Y without paired labeled training dataset. Each GAN model is trained on the same facial image dataset and comparable hyperparameters. We report a comparison result using same GAN model evaluation metrics. \u00a9 2019 Association for Computing Machinery.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cross-domain image-to-image translation provides mechanism to capture special characteristics of one image collection and convert into other image collection with different representations. Recent research on generative learning have produced powerful image-toimage translation methods in supervised setting, where paired training datasets are available. However, collecting paired training data is difficult, expensive and required manual authoring. We present an evaluation study of recent unsupervised Generative Adversarial Network (GAN) models that can learn to translate a facial image from a source domain X to a target domain Y without paired labeled training dataset. Each GAN model is trained on the same facial image dataset and comparable hyperparameters. We report a comparison result using same GAN model evaluation metrics. \u00a9 2019 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Ramadhan short-term electric load: A hybrid model of cycle spinning wavelet and group method data handling (CSW-GMDH)"
        ],
        "penulis":"Caraka, Rezzy Eko;Chen, Rung Ching;Toharudin, Toni;Pardamean, Bens;Bakar, Sakhinah Abu;Yasin, Hasbi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In general, performing a nonlinearity time series analysis in the modeling of data can reach a robust and increase the quality of the results. Wavelet methods have successfully been applied in a great variety of applications for modeling also forecasting. Wavelet Transform divided into two categories. There is continuous wavelet (CWT) and a discrete wavelet transform (DWT). Cycle spinning unlike the discrete wavelet transform (DWT), is highly redundant, non-orthogonal, also defined naturally for all sample sizes. There is a Group Method of Data Handling (GMDH) algorithm, which is a multivariate analysis method can be used in modeling and identifying uncertainty on linear also nonlinearity systems. In this paper, we aim to explain the combination of A-Trous wavelet transforms applied on cycle spinning and group method of data handling (GMDH) in data of short-term electric load holy month of Ramadhan from 2014 to 2015. \u00a9 2019, International Association of Engineers.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In general, performing a nonlinearity time series analysis in the modeling of data can reach a robust and increase the quality of the results. Wavelet methods have successfully been applied in a great variety of applications for modeling also forecasting. Wavelet Transform divided into two categories. There is continuous wavelet (CWT) and a discrete wavelet transform (DWT). Cycle spinning unlike the discrete wavelet transform (DWT), is highly redundant, non-orthogonal, also defined naturally for all sample sizes. There is a Group Method of Data Handling (GMDH) algorithm, which is a multivariate analysis method can be used in modeling and identifying uncertainty on linear also nonlinearity systems. In this paper, we aim to explain the combination of A-Trous wavelet transforms applied on cycle spinning and group method of data handling (GMDH) in data of short-term electric load holy month of Ramadhan from 2014 to 2015. \u00a9 2019, International Association of Engineers."
        ]
    },
    {
        "judul":[
            "From citizen science to citizen action: Analysing the potential for a digital platform to cultivate attachments to nature"
        ],
        "penulis":"Sharma, Nirwan;Greaves, Sam;Siddharthan, Advaith;Anderson, Helen B.;Robinson, Annie;Colucci-Gray, Laura;Wibowo, Agung Toto;Bostock, Helen;Salisbury, Andrew;Roberts, Stuart;Slawson, David;van der Wal, Ren\u00e9;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Identifying private gardens in the U.K. as key sites of environmental engagement, we look at how a longer-term online citizen science programme facilitated the development of new and personal attachments of nature. These were visible through new or renewed interest in wildlife-friendly gardening practices and attitudinal shifts in a large proportion of its participants. Qualitative and quantitative data, collected via interviews, focus groups, surveys and logging of user behaviours, revealed that cultivating a fascination with species identification was key to both 'helping nature' and wider learning, with the programme creating a space where scientific and non-scientific knowledge could co-exist and reinforce one another. \u00a9 2019, Scuola Internazionale Superiore di Studi Avanzati.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Identifying private gardens in the U.K. as key sites of environmental engagement, we look at how a longer-term online citizen science programme facilitated the development of new and personal attachments of nature. These were visible through new or renewed interest in wildlife-friendly gardening practices and attitudinal shifts in a large proportion of its participants. Qualitative and quantitative data, collected via interviews, focus groups, surveys and logging of user behaviours, revealed that cultivating a fascination with species identification was key to both 'helping nature' and wider learning, with the programme creating a space where scientific and non-scientific knowledge could co-exist and reinforce one another. \u00a9 2019, Scuola Internazionale Superiore di Studi Avanzati."
        ]
    },
    {
        "judul":[
            "A Review of Data Mining Implementation in Various Fields"
        ],
        "penulis":"Mustabshiroh M.;Latuconsina, Roswan;Purboyo, Tito Waluyo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Data mining is the process of searching patterns in big data sets and then will be converted into information that is easy to understand. A lot of research has developed the use of data mining to create something that is beneficial to society. Data mining has two general uses for defining patterns to be easily understood by explaining the characteristics of data and predicting. Data mining can be utilized in areas such as business, science, entertainment, etc. with different methods depending on needs. \u00a9 Medwell Journals, 2019",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data mining is the process of searching patterns in big data sets and then will be converted into information that is easy to understand. A lot of research has developed the use of data mining to create something that is beneficial to society. Data mining has two general uses for defining patterns to be easily understood by explaining the characteristics of data and predicting. Data mining can be utilized in areas such as business, science, entertainment, etc. with different methods depending on needs. \u00a9 Medwell Journals, 2019"
        ]
    },
    {
        "judul":[
            "Analysis Operation NLSR with Ubuntu as NDN Router"
        ],
        "penulis":"Friyanto, Angga;Ariefianto, W. Tody;Syambas, Nana Rachmana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Named Data Networking (NDN) need routing to build NDN systems. Similar IP protocol, NDN has routing protocols intra-domain and inter-domain routing protocol. Named-data Link State Routing (NLSR) is one of the NDN intra-domain routing protocols in NDN. Deployment NLSR on actual hardware and operating systems give more performance feedback which might not be obtained in a simulation. This paper explain how a NLSR work and performance use Ubuntu installed as NDN router. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Named Data Networking (NDN) need routing to build NDN systems. Similar IP protocol, NDN has routing protocols intra-domain and inter-domain routing protocol. Named-data Link State Routing (NLSR) is one of the NDN intra-domain routing protocols in NDN. Deployment NLSR on actual hardware and operating systems give more performance feedback which might not be obtained in a simulation. This paper explain how a NLSR work and performance use Ubuntu installed as NDN router. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Effect of Burnishing Tool Diameter and Coolant Strategies on Burnishing-Performance"
        ],
        "penulis":"Rachmat, Haris;Rahim, Erween Abd;Mohid, Zazuli;Mahalil, Khairuddin;Kasah, Amirun Akmal Kasah Feisal;Nadzri, Azamuddin;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A burnishing process is employed to improve the surface integrity of the component, especially for aerospace, medical, and nuclear industries. It requires proper cooling and lubricating techniques, usually flood cooling technique. However, this technique is harmful to the working environment. Therefore, this study introduces the application of minimal quantity lubrication (MQL) and cryogenic cooling using CO2gas. Two burnishing tools made from carbide with a diameter of 10 mm and 16 mm were used to burnish a SS400 carbon steel. Dry burnishing condition is employed and its performance is compared with MQL and supercritical CO2+MQL (SCCO2) conditions. The result shows that the SCCO2+MQL outperformed dry and MQL in terms of burnishing force, temperature and surface roughness. \u00a9 Published under licence by IOP Publishing Ltd.",
            "CCCaView detailsExpand Substance calcium carbideHOOHOHCH3View detailsExpand Substance 1,1,1-tri(hydroxymethyl)propane",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A burnishing process is employed to improve the surface integrity of the component, especially for aerospace, medical, and nuclear industries. It requires proper cooling and lubricating techniques, usually flood cooling technique. However, this technique is harmful to the working environment. Therefore, this study introduces the application of minimal quantity lubrication (MQL) and cryogenic cooling using CO2gas. Two burnishing tools made from carbide with a diameter of 10 mm and 16 mm were used to burnish a SS400 carbon steel. Dry burnishing condition is employed and its performance is compared with MQL and supercritical CO2+MQL (SCCO2) conditions. The result shows that the SCCO2+MQL outperformed dry and MQL in terms of burnishing force, temperature and surface roughness. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Smart light recommending system using artificial neural network algorithm"
        ],
        "penulis":"Akbar, Muchammad Ferdian;Putrada, Aji Gautama;Abdurohman, Maman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes smart light recommending system based on sleep monitoring data using Artificial Neural Network (ANN) algorithm. lights are one of the biggest contributors to the power consumption of electrical equipment. The effort to reduce the use of lights is related to not using them when they are not in use. One of the moments when the lights are not used is when we are sleeping but some user sleep styles keep the lights on even when they are sleeping so the idea is how to turn off the lights after the user sleeps. To realize this idea, it is necessary to detect sleep which can be derived from the detection of heart rate by certain sensors. The sensors that are needed are those already embedded in Fitbit, a bracelet-shaped device that can detect various kinds of conditions in the human body. However, Fitbit cannot directly provide the sleep condition to the user or the lamp, but it can provide information in the form of logs, so that the lamp settings cannot be instantaneous. To overcome this problem a learning method can be applied to know sleep patterns that appear in logs produced by Fitbit. This paper applies ANN back propagation to learn the sleep patterns of users, especially sleep start time and sleep end time. Nine ANN models made from user sleep data are applied to 60 days of testing. From these models, the best results were given by the model which gave 82.27% accuracy for sleep start time and 98.28% for sleep end time. Accuracy is largely determined by the user's sleep style. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes smart light recommending system based on sleep monitoring data using Artificial Neural Network (ANN) algorithm. lights are one of the biggest contributors to the power consumption of electrical equipment. The effort to reduce the use of lights is related to not using them when they are not in use. One of the moments when the lights are not used is when we are sleeping but some user sleep styles keep the lights on even when they are sleeping so the idea is how to turn off the lights after the user sleeps. To realize this idea, it is necessary to detect sleep which can be derived from the detection of heart rate by certain sensors. The sensors that are needed are those already embedded in Fitbit, a bracelet-shaped device that can detect various kinds of conditions in the human body. However, Fitbit cannot directly provide the sleep condition to the user or the lamp, but it can provide information in the form of logs, so that the lamp settings cannot be instantaneous. To overcome this problem a learning method can be applied to know sleep patterns that appear in logs produced by Fitbit. This paper applies ANN back propagation to learn the sleep patterns of users, especially sleep start time and sleep end time. Nine ANN models made from user sleep data are applied to 60 days of testing. From these models, the best results were given by the model which gave 82.27% accuracy for sleep start time and 98.28% for sleep end time. Accuracy is largely determined by the user's sleep style. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Schedule Control System for Wearable Medicine Box Using Bluetooth Low Energy"
        ],
        "penulis":"Ramadhan, Fahru Adi;Rakhmatsyah, Andrian;Yasirandi, Rahmat;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of technology can facilitate human work in many fields, one of that is health, its use has many benefits, for example in drug administration. This applies to people who do not obey the rules of taking medication that have been given by doctors or other medical personnel, other cases patients often experience forgetfulness to take the medicine even though treatment is important for the recovery of his illness and some cases of people who forget to bring the medicine while being traveling or going to work, in the above case an electronic device is needed which helps in reminding to take drugs which are connected to an Android-based smartphone using Bluetooth Low Energy. Therefore, researchers conducted research by implementing Bluetooth Low Energy in real life. In designing this system using Bluetooth Low Energy is used to control the medicine box that is connected to the user's cell phone or patient. Bluetooth Low Energy contained in the ESP32 microcontroller to connect the smartphone with a medicine box, LED and Buzzer as a marker and alarm when taking medication. Infrared sensors to detect the presence of drugs and become sensors to ensure the drug is taken at a predetermined time. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of technology can facilitate human work in many fields, one of that is health, its use has many benefits, for example in drug administration. This applies to people who do not obey the rules of taking medication that have been given by doctors or other medical personnel, other cases patients often experience forgetfulness to take the medicine even though treatment is important for the recovery of his illness and some cases of people who forget to bring the medicine while being traveling or going to work, in the above case an electronic device is needed which helps in reminding to take drugs which are connected to an Android-based smartphone using Bluetooth Low Energy. Therefore, researchers conducted research by implementing Bluetooth Low Energy in real life. In designing this system using Bluetooth Low Energy is used to control the medicine box that is connected to the user's cell phone or patient. Bluetooth Low Energy contained in the ESP32 microcontroller to connect the smartphone with a medicine box, LED and Buzzer as a marker and alarm when taking medication. Infrared sensors to detect the presence of drugs and become sensors to ensure the drug is taken at a predetermined time. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Flipping onsets to enhance syllabification"
        ],
        "penulis":"Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Two-year-old children who start learning to speak generally spell a polysyllabic word by flipping onsets of consecutive syllables. Sometimes they speak unclearly, hard to understand since the flipped onsets produce another word that has a much different meaning. For instance, two onsets in an English word \u201cme.lon\u201d (large round fruit of a plant of the gourd family) are flipped to produce another word \u201cle.mon\u201d (an acid fruit). In Bahasa Indonesia, such cases are quite common. For examples, two onsets in word \u201cba.tu\u201d (stone) are swapped to be \u201cta.bu\u201d (taboo), two onsets in \u201cbe.sar\u201d (big) are flipped to be \u201cse.bar\u201d (spread), two onsets in \u201cru.mah\u201d (house) are swapped to be \u201cmu.rah\u201d (cheap), etc. A preliminary study on 50k Indonesian formal words shows that the ratio between frequencies of the flipped-onset-bigrams and the 50 most frequent original syllable-bigrams is quite high, up to 13.09%. This research investigates the adoption of such phenomenon to enhances a bigram orthographic syllabification model that is commonly poor for out-of-vocabulary words. A five-fold cross-validation on 50k Indonesian formal words proves that the flipping onsets enhances the bigram orthographic syllabification, where the syllable error rate (SER) is relatively reduced by 18.02%. The method is also capable of producing quite low SER for a tiny trainset of 1k words to generalize 10k unseen words. Besides, it can be simply generalized to be applied to other languages as well as named-entities using a few specific knowledge related to the sets of vowels, diphthongs, and consonants. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Two-year-old children who start learning to speak generally spell a polysyllabic word by flipping onsets of consecutive syllables. Sometimes they speak unclearly, hard to understand since the flipped onsets produce another word that has a much different meaning. For instance, two onsets in an English word \u201cme.lon\u201d (large round fruit of a plant of the gourd family) are flipped to produce another word \u201cle.mon\u201d (an acid fruit). In Bahasa Indonesia, such cases are quite common. For examples, two onsets in word \u201cba.tu\u201d (stone) are swapped to be \u201cta.bu\u201d (taboo), two onsets in \u201cbe.sar\u201d (big) are flipped to be \u201cse.bar\u201d (spread), two onsets in \u201cru.mah\u201d (house) are swapped to be \u201cmu.rah\u201d (cheap), etc. A preliminary study on 50k Indonesian formal words shows that the ratio between frequencies of the flipped-onset-bigrams and the 50 most frequent original syllable-bigrams is quite high, up to 13.09%. This research investigates the adoption of such phenomenon to enhances a bigram orthographic syllabification model that is commonly poor for out-of-vocabulary words. A five-fold cross-validation on 50k Indonesian formal words proves that the flipping onsets enhances the bigram orthographic syllabification, where the syllable error rate (SER) is relatively reduced by 18.02%. The method is also capable of producing quite low SER for a tiny trainset of 1k words to generalize 10k unseen words. Besides, it can be simply generalized to be applied to other languages as well as named-entities using a few specific knowledge related to the sets of vowels, diphthongs, and consonants. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "The Maturity Assessment of e-Government in Bandung District Area"
        ],
        "penulis":"Rizana, Afrin F.;Muhammad, Fadel;Umar Hediyanto Y.K.S.;Andrawina, Luciana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In order to achieve better governance of the country, the implementation of e-government becomes essential. The Indonesian government has started to adopt e-government to improve their performance. The implementation of e-government is a continuous process where there are some developments that are often conceptualized in the form of maturity stages. In Indonesia, the implementation of e-government is expected to reach stage 3 of maturity level but in practice, most of the government websites only reach stage 2 of maturity level especially for the practice of e-government in district area of Indonesia. The purpose of this study is to evaluate the maturity level of e-government in Bandung district area. The result obtained from this study is expected to help the government to identify the improvement that should be done to e-government practice in Bandung district area. The result of this study found that from 11 websites of Bandung district area, 9 of the websites reach stage 2 of maturity level while the remaining websites only reach stage 1 of maturity level. Some improvements that can be taken by the government are also discussed in this paper. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In order to achieve better governance of the country, the implementation of e-government becomes essential. The Indonesian government has started to adopt e-government to improve their performance. The implementation of e-government is a continuous process where there are some developments that are often conceptualized in the form of maturity stages. In Indonesia, the implementation of e-government is expected to reach stage 3 of maturity level but in practice, most of the government websites only reach stage 2 of maturity level especially for the practice of e-government in district area of Indonesia. The purpose of this study is to evaluate the maturity level of e-government in Bandung district area. The result obtained from this study is expected to help the government to identify the improvement that should be done to e-government practice in Bandung district area. The result of this study found that from 11 websites of Bandung district area, 9 of the websites reach stage 2 of maturity level while the remaining websites only reach stage 1 of maturity level. Some improvements that can be taken by the government are also discussed in this paper. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "E-Marketplace Prototype for Tailor and Confection SMEs in Indonesia"
        ],
        "penulis":"Rosmansyah, Yusep;Habibi, Farid Fadhil;Bakhrun, Akhmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The field of e-commerce is currently on the rise, but it has not been able to be enjoyed by the majority of SME tailors and confection in Indonesia. On the contrary, fashion is one of the most purchased items via e-commerce. Inability of SME human resources to adopt e-commerce makes ordering erratic and causes their living far from prosperity. Customers also feel some dilemma when buying clothing online, for example, the items purchased are not as good those at picture gallery. Another problem the customer is often confusion in determining the tailor or confection when making clothing directly. Doing it in the city is expensive, whereas doing it in the village leading to poor quality. To overcome this, the need to develop a system of e-marketplace specifically for SMEs of tailor and confection. The development of this system is based on the analysis of problems and needs. This analysis is obtained by directly interviewing the twenty-four SMEs tailors and confection. The developed system has been tested using functional testing and UAT (User Acceptance Test). \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The field of e-commerce is currently on the rise, but it has not been able to be enjoyed by the majority of SME tailors and confection in Indonesia. On the contrary, fashion is one of the most purchased items via e-commerce. Inability of SME human resources to adopt e-commerce makes ordering erratic and causes their living far from prosperity. Customers also feel some dilemma when buying clothing online, for example, the items purchased are not as good those at picture gallery. Another problem the customer is often confusion in determining the tailor or confection when making clothing directly. Doing it in the city is expensive, whereas doing it in the village leading to poor quality. To overcome this, the need to develop a system of e-marketplace specifically for SMEs of tailor and confection. The development of this system is based on the analysis of problems and needs. This analysis is obtained by directly interviewing the twenty-four SMEs tailors and confection. The developed system has been tested using functional testing and UAT (User Acceptance Test). \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Measuring software product quality using ISO 9126: A systematic review"
        ],
        "penulis":"Umar, Muhammad Aminu;Ghazali, Masitah;Saedudin, Rd. Rohmat;Ashraf, Mahmood;Kasim, Shahreen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "ISO 9126 software quality model of 2001 is the most comprehensive and widely accepted model. It is a generic quality model that is used in measuring quality of software across computing domains. This study seeks to access the level of application of ISO 9126 model in measuring software quality and its impact on different software domains. We employed a standard methodology for systematic literature review using automated search on four digital libraries for studies published between 2001 and 2016. The results of the systematic review reveal that the model as a whole has played a significant role in measuring software quality across different domains. Out of total 63 primary stud-ies, 30 applied the six characteristics, and 33 papers applied one or more characteristics for measuring software quality. Software component and database are the most evaluated domains, while usability characteristics are the most measured quality. This is the result of the fact that software vendors are moving towards quality user-centred design instead of technology driven designs. Ambiguity resulting from the lack of clear guideline and operational instrument for evaluation is the major shortcoming of this quality model, but were favored by many due to its flexibility to suit the growing software domains. \u00a9 2019, World Academy of Research in Science and Engineering. All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "ISO 9126 software quality model of 2001 is the most comprehensive and widely accepted model. It is a generic quality model that is used in measuring quality of software across computing domains. This study seeks to access the level of application of ISO 9126 model in measuring software quality and its impact on different software domains. We employed a standard methodology for systematic literature review using automated search on four digital libraries for studies published between 2001 and 2016. The results of the systematic review reveal that the model as a whole has played a significant role in measuring software quality across different domains. Out of total 63 primary stud-ies, 30 applied the six characteristics, and 33 papers applied one or more characteristics for measuring software quality. Software component and database are the most evaluated domains, while usability characteristics are the most measured quality. This is the result of the fact that software vendors are moving towards quality user-centred design instead of technology driven designs. Ambiguity resulting from the lack of clear guideline and operational instrument for evaluation is the major shortcoming of this quality model, but were favored by many due to its flexibility to suit the growing software domains. \u00a9 2019, World Academy of Research in Science and Engineering. All rights reserved."
        ]
    },
    {
        "judul":[
            "The comparative analysis of energy consumption between olsr and zrp routing protocols"
        ],
        "penulis":"Sudiharto, Dodi W.;Pradana, Nur R.;Prabowo, Sidik;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The Mobile Ad-hoc Network (MANET) routing protocol generates a different performance when it is implemented in a different network scenario. It is a challenge to find the suitable characteristic of MANET protocol which conforms to a certain network condition scenario. Generally, many studies have been done to analyze the performance of MANET protocol. However, those studies are related to the scope of topology-based protocol. Based on that scope, the easy way to explore the MANET protocol is to compare between the Proactive protocol and the Reactive protocol. Alternatively, there is a protocol which is a combination of both, namely the Hybrid protocol. Studies which are related to the comparison between the Proactive protocol and the Hybrid protocol, or reviews which are related to the comparison between the Reactive protocol and Hybrid protocol have been widely executed. Nonetheless, there are still little studies related to the MANET protocol which focus on the character of its energy usage. Based on this information, this study is going to analyze about the comparison of energy usage in the MANET network between the Proactive which is performed by OLSR (Optimized Link State Routing Protocol) and the Hybrid which is presented by ZRP (Zone Routing Protocol). This study gives a result that the ZRP total energy consumption is fewer than the OLSR total energy consumption, nevertheless when the destination nodes are located in the sender nodes radius area, the OLSR can maintain its energy use better than the ZRP. \u00a9 2019 Journal of Communications.",
            "OBrPBrClClOOOH3CH3CView detailsExpand Substance naled",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Mobile Ad-hoc Network (MANET) routing protocol generates a different performance when it is implemented in a different network scenario. It is a challenge to find the suitable characteristic of MANET protocol which conforms to a certain network condition scenario. Generally, many studies have been done to analyze the performance of MANET protocol. However, those studies are related to the scope of topology-based protocol. Based on that scope, the easy way to explore the MANET protocol is to compare between the Proactive protocol and the Reactive protocol. Alternatively, there is a protocol which is a combination of both, namely the Hybrid protocol. Studies which are related to the comparison between the Proactive protocol and the Hybrid protocol, or reviews which are related to the comparison between the Reactive protocol and Hybrid protocol have been widely executed. Nonetheless, there are still little studies related to the MANET protocol which focus on the character of its energy usage. Based on this information, this study is going to analyze about the comparison of energy usage in the MANET network between the Proactive which is performed by OLSR (Optimized Link State Routing Protocol) and the Hybrid which is presented by ZRP (Zone Routing Protocol). This study gives a result that the ZRP total energy consumption is fewer than the OLSR total energy consumption, nevertheless when the destination nodes are located in the sender nodes radius area, the OLSR can maintain its energy use better than the ZRP. \u00a9 2019 Journal of Communications."
        ]
    },
    {
        "judul":[
            "A mutual authentication scheme for secure fog computing service handover in vehicular network environment"
        ],
        "penulis":"Dewanta, Favian;Mambo, Masahiro;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Handover schemes play a vital role on fog computing service (FCS) provided through vehicular network. It not only determines the quality of services (QoSs) but also the security and safety of vehicular network system against adversaries. As a part of handover process, authentication between vehicles and a new fog node (FN) significantly contributes to protecting private information and infrastructure of vehicular network at once. In this paper, we propose a lightweight and secure mutual authentication scheme for handover process considering limited access FCS in the vehicular network environment and also service reservation scenario at login and service request phase. In the proposed scheme, mutual authentication process is assisted by a cloud server (CS) during login and service request phase in which CS distributes the credentials for on-the-road authentication between the vehicles and FN installed on road side unit (RSU). We demonstrate that our proposed scheme is lightweight due to employing one-way hash function and exclusive-or operation extensively. In addition, our scheme is efficient in terms of computational cost as well as computation cost. We show that our scheme achieves 1.1-56.67 times faster computation and also reduces the total message size by 30%-58.21% in comparison with the previous authentication schemes in the most relevant environment. The informal and formal security analyses show that this authentication scheme can protect the secrecy of transactions of all interacting entities against various known attacks. In addition, validation using SPAN software based on AVISPA also confirms that the proposed authentication scheme can satisfy mutual authentication goal and, at the same time, also protect against replay and man-in-the-middle attack. \u00a9 2020 Copyright",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Handover schemes play a vital role on fog computing service (FCS) provided through vehicular network. It not only determines the quality of services (QoSs) but also the security and safety of vehicular network system against adversaries. As a part of handover process, authentication between vehicles and a new fog node (FN) significantly contributes to protecting private information and infrastructure of vehicular network at once. In this paper, we propose a lightweight and secure mutual authentication scheme for handover process considering limited access FCS in the vehicular network environment and also service reservation scenario at login and service request phase. In the proposed scheme, mutual authentication process is assisted by a cloud server (CS) during login and service request phase in which CS distributes the credentials for on-the-road authentication between the vehicles and FN installed on road side unit (RSU). We demonstrate that our proposed scheme is lightweight due to employing one-way hash function and exclusive-or operation extensively. In addition, our scheme is efficient in terms of computational cost as well as computation cost. We show that our scheme achieves 1.1-56.67 times faster computation and also reduces the total message size by 30%-58.21% in comparison with the previous authentication schemes in the most relevant environment. The informal and formal security analyses show that this authentication scheme can protect the secrecy of transactions of all interacting entities against various known attacks. In addition, validation using SPAN software based on AVISPA also confirms that the proposed authentication scheme can satisfy mutual authentication goal and, at the same time, also protect against replay and man-in-the-middle attack. \u00a9 2020 Copyright"
        ]
    },
    {
        "judul":[
            "Modelling augmented congklak using cycle of digital augmentation method"
        ],
        "penulis":"Satrio, Irfananda Rafif;Effendy, Veronikha;Junaedi, Danang;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Traditional Congklak is considered capable for practicing psychomotor and cognitive abilities through their playing activities. Although Congklak is considered capable of exercising this ability, there are some difficulties that can interfere with the gameplay. Children need to be helped to overcome these difficulties, so they could play more effectively. In this study, the Cycle of Digital Augmentation is used to modeling the augmented Congklak by adding visual feedback technology to ease children's activities while playing Congklak, while keep maintaining their traditional ways of playing so that the benefits to practice psychomotor and cognitive abilities will be maintained. After that, the Relative Manipulation Time (RMT) method is used to measure the value of the interaction effectiveness. Compared to traditional Congklak the value of interaction effectiveness has increased by 21.81%. These results indicate that children are more effective interacting with game objects using augmented Congklak than using traditional Congklak. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Traditional Congklak is considered capable for practicing psychomotor and cognitive abilities through their playing activities. Although Congklak is considered capable of exercising this ability, there are some difficulties that can interfere with the gameplay. Children need to be helped to overcome these difficulties, so they could play more effectively. In this study, the Cycle of Digital Augmentation is used to modeling the augmented Congklak by adding visual feedback technology to ease children's activities while playing Congklak, while keep maintaining their traditional ways of playing so that the benefits to practice psychomotor and cognitive abilities will be maintained. After that, the Relative Manipulation Time (RMT) method is used to measure the value of the interaction effectiveness. Compared to traditional Congklak the value of interaction effectiveness has increased by 21.81%. These results indicate that children are more effective interacting with game objects using augmented Congklak than using traditional Congklak. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A survey of in-flight connectivity implementation in Indonesia"
        ],
        "penulis":"Marlasari, Rafidah;Nashiruddin, Muhammad Imam;Adriansyah, Nachwan Mufti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Inmarsat Global survey in 2016 already found that on any flight length, the majority of passengers around 54% prefer to have the option of in-flight Wi-Fi. Rest of it, over 16% choosing In-Flight Entertainment (IFE), 19% choosing meal, and 7% choosing duty-free. As time goes by, the procurement of In-Flight Connectivity (IFC) is increasingly becoming a focus for the aviation industry. So far, IFC services provide through satellite and direct Air-to-Ground (ATG) technology. High interest in onboard connectivity makes the procurement also expand from the international route flights to the domestic route flights. A large number of passengers makes Indonesia have a bright future to develop IFC. 2 Indonesian airlines already begin to provide IFC. Although not specific on IFC, Indonesia already has a precise regulation that allows foreign satellite as a provider of IFC. Involving related companies such as operator or tower provider company to build a new independent ATG network for Indonesia shows opportunity. By considering the current state, the author analyzes the opportunities and challenges of IFC development in Indonesia in terms of market, network, regulation, and related company as players. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentReduced inequalitiesGoal 10Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Inmarsat Global survey in 2016 already found that on any flight length, the majority of passengers around 54% prefer to have the option of in-flight Wi-Fi. Rest of it, over 16% choosing In-Flight Entertainment (IFE), 19% choosing meal, and 7% choosing duty-free. As time goes by, the procurement of In-Flight Connectivity (IFC) is increasingly becoming a focus for the aviation industry. So far, IFC services provide through satellite and direct Air-to-Ground (ATG) technology. High interest in onboard connectivity makes the procurement also expand from the international route flights to the domestic route flights. A large number of passengers makes Indonesia have a bright future to develop IFC. 2 Indonesian airlines already begin to provide IFC. Although not specific on IFC, Indonesia already has a precise regulation that allows foreign satellite as a provider of IFC. Involving related companies such as operator or tower provider company to build a new independent ATG network for Indonesia shows opportunity. By considering the current state, the author analyzes the opportunities and challenges of IFC development in Indonesia in terms of market, network, regulation, and related company as players. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Risk-return through financial ratios as determinants of stock price: A study from ASEAN region"
        ],
        "penulis":"Jermsittiparsert, Kittisak;Ambarita, Dedy E.;Mihardjo, Leonardus W.W.;Ghani, Erlane K.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The objective of this empirical research is to analyze the risk-return through financial ratios as determinants of stock price in ASEAN region. To address this purpose, business firms from Malaysia, Indonesia, Thailand and Singapore are selected with a sample of 10 firms in each state over 2012 to 2016. Multiple regression technique is applied to analyze the relationship between financial ratios and stock prices. It is observed that current ratio, quick ratio, assets growth, return on assets, return on equity, return on capital employed, and price to earning ratio are significant determinants of stock price. Although this study is a reasonable addition in existing literature of financial ratios as determinants of stock price. However, contribution of the study can be viewed through covering a gap from the context of ASEAN region, which is under reserachers attentions for stock price determinants. Core limitations of the study covers limited number of sample size and five years of time duration. Besides, some ratios are missing which can be reconsidered in upcoming studies. These ratios include debt ratios, interest payment ratios, and fixed cost covered ratios as well. \u00a9 2019, General Jonas Zemaitis Military Academy of Lithuania.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The objective of this empirical research is to analyze the risk-return through financial ratios as determinants of stock price in ASEAN region. To address this purpose, business firms from Malaysia, Indonesia, Thailand and Singapore are selected with a sample of 10 firms in each state over 2012 to 2016. Multiple regression technique is applied to analyze the relationship between financial ratios and stock prices. It is observed that current ratio, quick ratio, assets growth, return on assets, return on equity, return on capital employed, and price to earning ratio are significant determinants of stock price. Although this study is a reasonable addition in existing literature of financial ratios as determinants of stock price. However, contribution of the study can be viewed through covering a gap from the context of ASEAN region, which is under reserachers attentions for stock price determinants. Core limitations of the study covers limited number of sample size and five years of time duration. Besides, some ratios are missing which can be reconsidered in upcoming studies. These ratios include debt ratios, interest payment ratios, and fixed cost covered ratios as well. \u00a9 2019, General Jonas Zemaitis Military Academy of Lithuania."
        ]
    },
    {
        "judul":[
            "Monitoring and classification system of river water pollution conditions with fuzzy logic"
        ],
        "penulis":"Khalid Waleed A.S.;Kusuma, Purba Daru;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of the current era, and the rapid development of technology and the need for a significant increase in demand, as well as pollution, the water sector, especially the river has experienced a decline in water quality even to the occurrence of pollution, resulting in water can no longer be consumed either by human body also for other needs. Some of the systems that were developed began to be able to process existing data, be it conditions from water, chemical observations or physically. This is done because water is a necessity that cannot be tolerated, so this research is done to help fulfill or even provide a calm warning of water quality. With the development of Intemet of Things (IoT) the monitoring system will develop, because with the existence of technology such as low-power wide-area network (LPWAN) as specific as possible, short data can be sent using lower power. In this research, it was proven that the author could make a monitoring system and classification of river water pollution. By using an artificial intelligence, using the fuzzy logic method. The results of system testing show that the average accuracy of the monitoring system results is 99.7% and the results of the appropriate classification values are based on the results of system testing. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentClean water and sanitationGoal 6",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of the current era, and the rapid development of technology and the need for a significant increase in demand, as well as pollution, the water sector, especially the river has experienced a decline in water quality even to the occurrence of pollution, resulting in water can no longer be consumed either by human body also for other needs. Some of the systems that were developed began to be able to process existing data, be it conditions from water, chemical observations or physically. This is done because water is a necessity that cannot be tolerated, so this research is done to help fulfill or even provide a calm warning of water quality. With the development of Intemet of Things (IoT) the monitoring system will develop, because with the existence of technology such as low-power wide-area network (LPWAN) as specific as possible, short data can be sent using lower power. In this research, it was proven that the author could make a monitoring system and classification of river water pollution. By using an artificial intelligence, using the fuzzy logic method. The results of system testing show that the average accuracy of the monitoring system results is 99.7% and the results of the appropriate classification values are based on the results of system testing. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Hybrid Framework Parameterization Reduction Combination in Soft Set"
        ],
        "penulis":"Mohammed, Mohammed Adam Taheir;Mohd, Wan Maseri Wan;Arshah, Ruzaini Abdullah;Mungad M.;Sutoyo, Edi;Chiroma, Haruna;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Voluminous data are available in soft sets, which makes it difficult to recognize the soft set decisions of the data. The large increase in the volume of these soft set has made it necessary to enlarge the size of the storage media to store the data. Consequently, several researches have proposed oft set reduction of the data. This paper proposes uncertain soft set by hybridizing two soft set reduction techniques producing a significant result without affecting the decisive characteristics of the data. This proposed method utilizes advanced techniques to govern knowledge with proper reduction of related resources that can assist the decision-making process. \u00a9 Springer Nature Singapore Pte Ltd. 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Voluminous data are available in soft sets, which makes it difficult to recognize the soft set decisions of the data. The large increase in the volume of these soft set has made it necessary to enlarge the size of the storage media to store the data. Consequently, several researches have proposed oft set reduction of the data. This paper proposes uncertain soft set by hybridizing two soft set reduction techniques producing a significant result without affecting the decisive characteristics of the data. This proposed method utilizes advanced techniques to govern knowledge with proper reduction of related resources that can assist the decision-making process. \u00a9 Springer Nature Singapore Pte Ltd. 2019."
        ]
    },
    {
        "judul":[
            "Implementation of Enterprise Resource Planning (ERP) using Integrated Model of Extended Technology Acceptance Model (TAM) 2: Case Study of PT. Toyota Astra Motor"
        ],
        "penulis":"Ike Wahyuning W.;Lubis, Muharman;Witjaksono, Wahjoe;Azizah, Anik Hanifatul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "ERP (Enterprise Resource Planning) is an integrated information system that can accommodate information system needs specifically for different departments in a company. The use of ERP makes all systems within a company into a system that is integrated with one database so that some departments become easier in sharing data and communication. PT. Toyota Astra Motor is a company that has implemented an ERP system since 2000, but the success rate is still around 75% and 25% failure. Therefore, this study was designed to analyze what are the determinants of success that can be used as reference materials to make PT. Toyota Astra Motor is a better company and can improve the sales and customer service system. To analyze the determinants of the success of ERP implementation at PT. Toyota Astra Motor researchers used the Extended Technology Acceptance Model (TAM) 2 model to integrate the combined Technology Acceptance Model and the IS success model. This study uses quantitative design with hypotheses and analyzes using IBM AMOS software. Based on the results of the study using the Extended Technology Acceptance Model (TAM) 2 to find out success factors it is known that the influential variables are job relevance, compatibility, perceived ease of use, perceived usefulness, function, internal support and intention to use, which means if the variable can be used as a determining factor for the success of ERP implementation by PT. Toyota Astra Motor. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "ERP (Enterprise Resource Planning) is an integrated information system that can accommodate information system needs specifically for different departments in a company. The use of ERP makes all systems within a company into a system that is integrated with one database so that some departments become easier in sharing data and communication. PT. Toyota Astra Motor is a company that has implemented an ERP system since 2000, but the success rate is still around 75% and 25% failure. Therefore, this study was designed to analyze what are the determinants of success that can be used as reference materials to make PT. Toyota Astra Motor is a better company and can improve the sales and customer service system. To analyze the determinants of the success of ERP implementation at PT. Toyota Astra Motor researchers used the Extended Technology Acceptance Model (TAM) 2 model to integrate the combined Technology Acceptance Model and the IS success model. This study uses quantitative design with hypotheses and analyzes using IBM AMOS software. Based on the results of the study using the Extended Technology Acceptance Model (TAM) 2 to find out success factors it is known that the influential variables are job relevance, compatibility, perceived ease of use, perceived usefulness, function, internal support and intention to use, which means if the variable can be used as a determining factor for the success of ERP implementation by PT. Toyota Astra Motor. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A systematic literature review of security software defined network: Research trends, threat, attack, detect, mitigate, and countermeasure"
        ],
        "penulis":"Kurniawan, Mochamad Teguh;Yazid, Setiadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of internet technology in the current decade is growing very rapidly. This triggers a variety of innovations in the application layer. However, these developments cannot be followed by network layers that tend to be slow. The concept of Software Defined network is present to solve the problem. Various studies were conducted for SDN technology, one of them is security. The highlight in security is the security architecture. Many security systems that are created do not refer to the security architecture so it is difficult in its development. In addition, the current security architecture does not refer to the guidelines for the creation of security architectures according to [1] there are two parts of security zones and security layers so that only 8% of security architectures meet both sections. In this study, a survey was conducted to find out the development trend in SDN security and security architecture of SDN using systematic literature review (SLR) method, and SLR result stated that research in architecture of network security is still very relevant to be done. By knowing the guidelines for making security architecture, it is hoped that the security architecture that is designed can be the foundation of the development of security framework and security system that will be developed. \u00a9 2019 Association for Computing Machinery.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of internet technology in the current decade is growing very rapidly. This triggers a variety of innovations in the application layer. However, these developments cannot be followed by network layers that tend to be slow. The concept of Software Defined network is present to solve the problem. Various studies were conducted for SDN technology, one of them is security. The highlight in security is the security architecture. Many security systems that are created do not refer to the security architecture so it is difficult in its development. In addition, the current security architecture does not refer to the guidelines for the creation of security architectures according to [1] there are two parts of security zones and security layers so that only 8% of security architectures meet both sections. In this study, a survey was conducted to find out the development trend in SDN security and security architecture of SDN using systematic literature review (SLR) method, and SLR result stated that research in architecture of network security is still very relevant to be done. By knowing the guidelines for making security architecture, it is hoped that the security architecture that is designed can be the foundation of the development of security framework and security system that will be developed. \u00a9 2019 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Key factors supporting the benefit realization of erp system adoption: Empirical evidence from Indonesian companies"
        ],
        "penulis":"Mukti, Iqbal Yulizar;Govindaraju, Rajesri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "--To increase the business performance, many organizations decide to adopt ERP system as their supporting information system. However, despite the enormous money and time invested in adopting the ERP system, many organizations still failed to fully realize the benefits. Previous studies found that to realize the benefits from of ERP system adoption, organizations should give more attention on post-project phase, especially on activities to achieve institutionalized ERP system, which is a condition when the ERP system is used as an integral part of in the organization and used comfortably by the users. In this regard, this study explores key factors that can positively contribute to institutionalizing the ERP system. An empirical test was conducted to Indonesian companies which already stepped into the post-project phase. Research model consisting factors that hypothetically affect to the institutionalized ERP system was developed in this study. Hypotheses test using partial least square method (PLS) shows that help desk quality and IS-Business ownership do significantly contribute positively to the institutionalized ERP, whereas user knowledge sharing, formalization of work procedure, and control mechanism do not. Further, the result shows that control mechanism significantly gives a negative contribution to the institutionalized ERP system. The practical implicationsof the findings and the direction for future study are discussed. \u00a9 2019, Institute of Advanced Scientific Research, Inc.. All rights reserved.",
            "POOOH3CH3CNOOView detailsExpand Substance paraoxon",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "--To increase the business performance, many organizations decide to adopt ERP system as their supporting information system. However, despite the enormous money and time invested in adopting the ERP system, many organizations still failed to fully realize the benefits. Previous studies found that to realize the benefits from of ERP system adoption, organizations should give more attention on post-project phase, especially on activities to achieve institutionalized ERP system, which is a condition when the ERP system is used as an integral part of in the organization and used comfortably by the users. In this regard, this study explores key factors that can positively contribute to institutionalizing the ERP system. An empirical test was conducted to Indonesian companies which already stepped into the post-project phase. Research model consisting factors that hypothetically affect to the institutionalized ERP system was developed in this study. Hypotheses test using partial least square method (PLS) shows that help desk quality and IS-Business ownership do significantly contribute positively to the institutionalized ERP, whereas user knowledge sharing, formalization of work procedure, and control mechanism do not. Further, the result shows that control mechanism significantly gives a negative contribution to the institutionalized ERP system. The practical implicationsof the findings and the direction for future study are discussed. \u00a9 2019, Institute of Advanced Scientific Research, Inc.. All rights reserved."
        ]
    },
    {
        "judul":[
            "A Framework for Clustering of Web Users Transaction Based on Soft Set Theory"
        ],
        "penulis":"Sutoyo, Edi;Yanto, Iwan Tri Riyadi;Saadi, Younes;Chiroma, Haruna;Hamid, Suraya;Herawan, Tutut;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Clustering faces several additional challenges, compared to traditional applications. The clusters tend to have imprecise boundaries and uncertainty. As a consequence of this uncertainty, we can highlight some challenges for web mining related to many problems such as: Forming of clusters, the high computational complexity. Rough set theory has been used for clustering web user transactions, while managing uncertainty in clustering process. However, it suffers from high computational complexity. In this paper, we propose a framework for web clustering based on soft set theory with emphasis on reducing computational complexity. \u00a9 Springer Nature Singapore Pte Ltd. 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Clustering faces several additional challenges, compared to traditional applications. The clusters tend to have imprecise boundaries and uncertainty. As a consequence of this uncertainty, we can highlight some challenges for web mining related to many problems such as: Forming of clusters, the high computational complexity. Rough set theory has been used for clustering web user transactions, while managing uncertainty in clustering process. However, it suffers from high computational complexity. In this paper, we propose a framework for web clustering based on soft set theory with emphasis on reducing computational complexity. \u00a9 Springer Nature Singapore Pte Ltd. 2019."
        ]
    },
    {
        "judul":[
            "Analysis of Critical Success Factors from ERP System Implementation in Pharmaceutical Fields by Information System Success Model"
        ],
        "penulis":"Syafiraliany, Levie;Lubis, Muharman;Witjaksono, R. Wahjoe;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The implementation of ERP system in this era is important because it accelerates the achievement of company goals. The company in this study is engaged in pharmacy using the SAP system, but the implementation of the SAP system has not run optimally in the company, therefore it requires an analysis of the success factors of ERP in order to minimize the negative impact and failure of ERP implementation. The analysis critical success factors of the ERP system implementation in the pharmaceutical company is based on the success model of information systems by DeLone and Mclean. This type of research is explanatory research using a quantitative approach, the quantitative data obtained by using a survey in the form of a questionnaire. The results of the study indicate that the critical success factors of ERP implementation that has a significant effect is the use of net benefits, user satisfaction of net benefits, and system quality of use. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The implementation of ERP system in this era is important because it accelerates the achievement of company goals. The company in this study is engaged in pharmacy using the SAP system, but the implementation of the SAP system has not run optimally in the company, therefore it requires an analysis of the success factors of ERP in order to minimize the negative impact and failure of ERP implementation. The analysis critical success factors of the ERP system implementation in the pharmaceutical company is based on the success model of information systems by DeLone and Mclean. This type of research is explanatory research using a quantitative approach, the quantitative data obtained by using a survey in the form of a questionnaire. The results of the study indicate that the critical success factors of ERP implementation that has a significant effect is the use of net benefits, user satisfaction of net benefits, and system quality of use. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design of a Blockchain-based e-Tendering System: A Case Study in LPSE"
        ],
        "penulis":"Yutia, Syifa Nurgaida;Rahardjo, Budi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The tender process is a long and complex business process to produce a series of legal obligations related to business contracts. The purpose of conducting a tender in government is to support the work program by finding the right tender (provider of goods and services) in the government procurement program so that it can be the basis of their decision to choose the most suitable tender. At the government in Indonesia, the tender process has been carried out using an e-tendering system with the use of internet technology through LPSE. The purpose of e-tendering is to facilitate the procurement process with related parties to increase productivity, effectiveness, and transparency in the tender process. However, problems in the e-tendering system are currently centralized, so that the local LPSE organization has full control of the database and the system which can pose a threat of vulnerability to fraud, collusion, and manipulation practices. The tender selection process that is full of competition must be supported by effective and transparent technology so that it does not cause fraud and suspicion among bidders. Blockchain technology is one of the solutions that allow integrated systems without a third party because it adheres to the decentralized nature of distributed databases so that it has a copy of many users. By adopting blockchain e-tendering can reduce the source of fraud, namely database manipulation. This research will explore the process of developing a blockchain-based system with e-tendering case studies on LPSE. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The tender process is a long and complex business process to produce a series of legal obligations related to business contracts. The purpose of conducting a tender in government is to support the work program by finding the right tender (provider of goods and services) in the government procurement program so that it can be the basis of their decision to choose the most suitable tender. At the government in Indonesia, the tender process has been carried out using an e-tendering system with the use of internet technology through LPSE. The purpose of e-tendering is to facilitate the procurement process with related parties to increase productivity, effectiveness, and transparency in the tender process. However, problems in the e-tendering system are currently centralized, so that the local LPSE organization has full control of the database and the system which can pose a threat of vulnerability to fraud, collusion, and manipulation practices. The tender selection process that is full of competition must be supported by effective and transparent technology so that it does not cause fraud and suspicion among bidders. Blockchain technology is one of the solutions that allow integrated systems without a third party because it adheres to the decentralized nature of distributed databases so that it has a copy of many users. By adopting blockchain e-tendering can reduce the source of fraud, namely database manipulation. This research will explore the process of developing a blockchain-based system with e-tendering case studies on LPSE. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "RFID Characteristics Test as Business Needs at Logistic Companies in Indonesia"
        ],
        "penulis":"Irsan, Muhamad;Fitria Murad, Dina;Fernando, Erick;Touriano, Derist;Corradini, Andrea;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In embedded RFID chips for storing records or data, such as Electronic Product Code one of them using barcode, in tag. Tags have functions to be able to transmit data for readable readers or stationary readers. using radio transmission technology to read data in tags. Each computer in the same system network can share and track data, regardless of where the item is searched for within the scope of the marked or restricted area. Available information may include item code, item date, delivery date, and item price. This study presents a framework based on RFID Proxied Technology Characteristics Real Time Data Processing, Continuous Data Tracking and Discrete Data, and Reuse and explores its relationship with Business Needs. The observed populations are supervisors and managers working in logistic companies taken cross section obtained from a number of logistics companies incorporated in the Indonesian Logistics Association (ALI) in 2015. Sampling is done using convenience sampling method (convenience sampling method) because the population of respondents working in logistics companies in Indonesia is not known with certainty. This research can contribute to how users can select and measure RFID technology from their characteristics so that the application of RFID systems and technology becomes an added value for the company not just as a complementary technology only. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In embedded RFID chips for storing records or data, such as Electronic Product Code one of them using barcode, in tag. Tags have functions to be able to transmit data for readable readers or stationary readers. using radio transmission technology to read data in tags. Each computer in the same system network can share and track data, regardless of where the item is searched for within the scope of the marked or restricted area. Available information may include item code, item date, delivery date, and item price. This study presents a framework based on RFID Proxied Technology Characteristics Real Time Data Processing, Continuous Data Tracking and Discrete Data, and Reuse and explores its relationship with Business Needs. The observed populations are supervisors and managers working in logistic companies taken cross section obtained from a number of logistics companies incorporated in the Indonesian Logistics Association (ALI) in 2015. Sampling is done using convenience sampling method (convenience sampling method) because the population of respondents working in logistics companies in Indonesia is not known with certainty. This research can contribute to how users can select and measure RFID technology from their characteristics so that the application of RFID systems and technology becomes an added value for the company not just as a complementary technology only. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Classification of Japanese fagaceae wood based on microscopic image analysis"
        ],
        "penulis":"Salma;Gunawan P.H.;Prakasa, Esa;Damayanti, Ratih;Sugiyama, Junji;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents wood identification method on microscopic image of Japanese Fagaceae wood by applying Daubechies Wavelet (DW) and Local Binary Pattern (LBP) algorithms. The main idea for this identification is to extract as much as possible the characteristics of wood to improve accuracy. The color intensity of microscopic wood image can be one of the characteristics of wood. Therefore, before extracting features with DW and LBP, we add color extraction to separate the color intensity in the Red, Green, and Blue (RGB) channels from the image. In addition, we compared several values of the LBP parameter for kernel type original, var, uniform, and ror to find the optimal value. The results of this work performed the accuracy of wood identification on microscopic image of Japanese Fagaceae wood with the Support Vector Machine (SVM) classifier is obtained 95.2% by setting P and R parameters at 8 and 2. Moreover in this paper, the most optimal LBP parameter value occurs when P = 16 and R = 1 for the original kernel type, which reaches 100% accuracy. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents wood identification method on microscopic image of Japanese Fagaceae wood by applying Daubechies Wavelet (DW) and Local Binary Pattern (LBP) algorithms. The main idea for this identification is to extract as much as possible the characteristics of wood to improve accuracy. The color intensity of microscopic wood image can be one of the characteristics of wood. Therefore, before extracting features with DW and LBP, we add color extraction to separate the color intensity in the Red, Green, and Blue (RGB) channels from the image. In addition, we compared several values of the LBP parameter for kernel type original, var, uniform, and ror to find the optimal value. The results of this work performed the accuracy of wood identification on microscopic image of Japanese Fagaceae wood with the Support Vector Machine (SVM) classifier is obtained 95.2% by setting P and R parameters at 8 and 2. Moreover in this paper, the most optimal LBP parameter value occurs when P = 16 and R = 1 for the original kernel type, which reaches 100% accuracy. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Power Allocation for Group LDS-OFDM in Underlay Cognitive Radio"
        ],
        "penulis":"Meylani, Linda;Hidayat, Iswahyudi;Kurniawan, Adit;Arifianto, M. Sigit;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Low density signature orthogonal frequency division multiplexing (LDS-OFDM) is a promising multiple access that increases spectrum utilization. In LDS-OFDM, each subcarrier can be accessed by more than one user, however, it is limited to dcusers. Each user spreads its symbols in a number of dvsubcarriers. In this paper, we propose power allocation for LDS-OFDM in underlay cognitive radio to increase throughput for each secondary user (SU) by manage the power weighting of each user in every subcarrier. The simulation results confirm that our proposed algorithm can increase the throughput of SU compare to equal power weighting. Grouping on allocation resource will affect the outage probability and SU's throughput. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Low density signature orthogonal frequency division multiplexing (LDS-OFDM) is a promising multiple access that increases spectrum utilization. In LDS-OFDM, each subcarrier can be accessed by more than one user, however, it is limited to dcusers. Each user spreads its symbols in a number of dvsubcarriers. In this paper, we propose power allocation for LDS-OFDM in underlay cognitive radio to increase throughput for each secondary user (SU) by manage the power weighting of each user in every subcarrier. The simulation results confirm that our proposed algorithm can increase the throughput of SU compare to equal power weighting. Grouping on allocation resource will affect the outage probability and SU's throughput. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Improving the accuracy of fuzzy vault scheme in fingerprint biometric"
        ],
        "penulis":"Saputra, Joni;Sukarno, Parman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At present, authentication techniques using fingerprint biometrics have been widely used in various fields. This is because the authentication techniques using biometrics are safer and more comfortable than using traditional passwords. In order to realize this, a technique in the biometric cryptosystem is proposed in the research, called the fuzzy vault scheme. Although the fingerprint data in the form of minutiae can be protected with a fuzzy vault scheme compared to traditional authentication systems, it can reduce user convenience. Previous studies proposed a distance-based method in the fuzzy vault scheme. The distance-based method is proposed because it is no need to align and rotate the fingerprint image during registration or authentication. Then with the distance-based method also does not produce a helper data that can lead to information leakage that can be exploited by impostor. In the research, the distance-based method is proposed with several modifications, which are the minutiae filter and candidate points identification techniques. The previous method produces FRR 13.4375% and FAR 0.4515% and the proposed method produced FRR 8.9475% and FAR 0.3520%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At present, authentication techniques using fingerprint biometrics have been widely used in various fields. This is because the authentication techniques using biometrics are safer and more comfortable than using traditional passwords. In order to realize this, a technique in the biometric cryptosystem is proposed in the research, called the fuzzy vault scheme. Although the fingerprint data in the form of minutiae can be protected with a fuzzy vault scheme compared to traditional authentication systems, it can reduce user convenience. Previous studies proposed a distance-based method in the fuzzy vault scheme. The distance-based method is proposed because it is no need to align and rotate the fingerprint image during registration or authentication. Then with the distance-based method also does not produce a helper data that can lead to information leakage that can be exploited by impostor. In the research, the distance-based method is proposed with several modifications, which are the minutiae filter and candidate points identification techniques. The previous method produces FRR 13.4375% and FAR 0.4515% and the proposed method produced FRR 8.9475% and FAR 0.3520%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Case Study of Universities Dormitory Residence Management System (DRMS) in Indonesia"
        ],
        "penulis":"Lubis, Muharman;Fauzi, Rokhman;Lubis, Arif Ridho;Fauzi, Rahmat;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study explores the problems and challenges faced by several universities in Indonesia to allow, commonly, the first year students to enroll in dormitory either online or offline. It is reasonable for prospective students to have expectation that university provide suitable facilities in term of accommodation and logistics considering that a large number of student come from different cities in various provinces. The development of Dormitory Residential Management System (DRMS) should accommodate the process of enrollment, payment and booking from student online and support the staff to control and manage integrated program or activities based on determined schedule. Besides that, the system also allow monitoring process for reporting purpose and notify or confirm certain activities or allocation process. This study investigates several systems used by respected universities to identify the level of satisfaction of students. Interestingly, there are many evidences showed bottom level of satisfaction from student towards the services offered by university for DRMS. \u00a9 2018 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study explores the problems and challenges faced by several universities in Indonesia to allow, commonly, the first year students to enroll in dormitory either online or offline. It is reasonable for prospective students to have expectation that university provide suitable facilities in term of accommodation and logistics considering that a large number of student come from different cities in various provinces. The development of Dormitory Residential Management System (DRMS) should accommodate the process of enrollment, payment and booking from student online and support the staff to control and manage integrated program or activities based on determined schedule. Besides that, the system also allow monitoring process for reporting purpose and notify or confirm certain activities or allocation process. This study investigates several systems used by respected universities to identify the level of satisfaction of students. Interestingly, there are many evidences showed bottom level of satisfaction from student towards the services offered by university for DRMS. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Recent development in electronic nose data processing for beef quality assessment"
        ],
        "penulis":"Sarno, Riyanarto;Wijaya, Dedy Rahman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Beef is kind of perishable food that easily to decay. Hence, a rapid system for beef quality assessment is needed to guarantee the quality of beef. In the last few years, electronic nose (e-nose) is developed for beef spoilage detection. In this paper, we discuss the challenges of e-nose application to beef quality assessment, especially in e-nose data processing. We also provide a summary of our previous studies that explains several methods to deal with gas sensor noise, sensor array optimization problem, beef quality classification, and prediction of the microbial population in beef sample. This paper might be useful for researchers and practitioners to understand the challenges and methods of e-nose data processing for beef quality assessment. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Beef is kind of perishable food that easily to decay. Hence, a rapid system for beef quality assessment is needed to guarantee the quality of beef. In the last few years, electronic nose (e-nose) is developed for beef spoilage detection. In this paper, we discuss the challenges of e-nose application to beef quality assessment, especially in e-nose data processing. We also provide a summary of our previous studies that explains several methods to deal with gas sensor noise, sensor array optimization problem, beef quality classification, and prediction of the microbial population in beef sample. This paper might be useful for researchers and practitioners to understand the challenges and methods of e-nose data processing for beef quality assessment. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Key factors supporting the benefit realization of erp system adoption: Empirical evidence from Indonesian companies"
        ],
        "penulis":"Mukti, Iqbal Yulizar;Govindaraju, Rajesri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "--To increase the business performance, many organizations decide to adopt ERP system as their supporting information system. However, despite the enormous money and time invested in adopting the ERP system, many organizations still failed to fully realize the benefits. Previous studies found that to realize the benefits from of ERP system adoption, organizations should give more attention on post-project phase, especially on activities to achieve institutionalized ERP system, which is a condition when the ERP system is used as an integral part of in the organization and used comfortably by the users. In this regard, this study explores key factors that can positively contribute to institutionalizing the ERP system. An empirical test was conducted to Indonesian companies which already stepped into the post-project phase. Research model consisting factors that hypothetically affect to the institutionalized ERP system was developed in this study. Hypotheses test using partial least square method (PLS) shows that help desk quality and IS-Business ownership do significantly contribute positively to the institutionalized ERP, whereas user knowledge sharing, formalization of work procedure, and control mechanism do not. Further, the result shows that control mechanism significantly gives a negative contribution to the institutionalized ERP system. The practical implicationsof the findings and the direction for future study are discussed. \u00a9 2019, Institute of Advanced Scientific Research, Inc.. All rights reserved.",
            "POOOH3CH3CNOOView detailsExpand Substance paraoxon",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "--To increase the business performance, many organizations decide to adopt ERP system as their supporting information system. However, despite the enormous money and time invested in adopting the ERP system, many organizations still failed to fully realize the benefits. Previous studies found that to realize the benefits from of ERP system adoption, organizations should give more attention on post-project phase, especially on activities to achieve institutionalized ERP system, which is a condition when the ERP system is used as an integral part of in the organization and used comfortably by the users. In this regard, this study explores key factors that can positively contribute to institutionalizing the ERP system. An empirical test was conducted to Indonesian companies which already stepped into the post-project phase. Research model consisting factors that hypothetically affect to the institutionalized ERP system was developed in this study. Hypotheses test using partial least square method (PLS) shows that help desk quality and IS-Business ownership do significantly contribute positively to the institutionalized ERP, whereas user knowledge sharing, formalization of work procedure, and control mechanism do not. Further, the result shows that control mechanism significantly gives a negative contribution to the institutionalized ERP system. The practical implicationsof the findings and the direction for future study are discussed. \u00a9 2019, Institute of Advanced Scientific Research, Inc.. All rights reserved."
        ]
    },
    {
        "judul":[
            "A Framework for Clustering of Web Users Transaction Based on Soft Set Theory"
        ],
        "penulis":"Sutoyo, Edi;Yanto, Iwan Tri Riyadi;Saadi, Younes;Chiroma, Haruna;Hamid, Suraya;Herawan, Tutut;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Clustering faces several additional challenges, compared to traditional applications. The clusters tend to have imprecise boundaries and uncertainty. As a consequence of this uncertainty, we can highlight some challenges for web mining related to many problems such as: Forming of clusters, the high computational complexity. Rough set theory has been used for clustering web user transactions, while managing uncertainty in clustering process. However, it suffers from high computational complexity. In this paper, we propose a framework for web clustering based on soft set theory with emphasis on reducing computational complexity. \u00a9 Springer Nature Singapore Pte Ltd. 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Clustering faces several additional challenges, compared to traditional applications. The clusters tend to have imprecise boundaries and uncertainty. As a consequence of this uncertainty, we can highlight some challenges for web mining related to many problems such as: Forming of clusters, the high computational complexity. Rough set theory has been used for clustering web user transactions, while managing uncertainty in clustering process. However, it suffers from high computational complexity. In this paper, we propose a framework for web clustering based on soft set theory with emphasis on reducing computational complexity. \u00a9 Springer Nature Singapore Pte Ltd. 2019."
        ]
    },
    {
        "judul":[
            "Design and development of a monitoring and controlling system for multi-intravenous infusion"
        ],
        "penulis":"Cahyanurani, Antika;Hadiyoso, Sugondo;Aulia, Suci;Faqih, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Recently, many of conventional infusion control tools which has functions to control the drops of infusion fluid and to monitor the volume of infusion fluid. Because it work manually, it has low level of accuracy and low efficiency. So that, in this research has designed a device that could monitor and control the drops of infusion fluid for multipoint (multi intravenous) through online application. On hardware part, photodiode and LED was used to detect the drops of infusion fluid, a sliding potentiometer and simple modified spring was used to detect the volume of infusion fluid. In this research was also implemented a mechanical which use motor servo to set the speed of drops of infusion fluid. WEMOS and MCU node has been designed as main control to controlling the whole of system. The device was equipped with ESP8266 as interface to internet network. An administrator can monitoring and controlling the system through offline or real time through a website application that has been built. based on the testing result, as functionality the system was working well. The device could detect the drops of infusion fluid with 100 % of accuracy and could control the volume of infusion fluid with 99 % of accuracy. Total of maximum drops per minute that could detected by system was 135 DPMs with average of transferring delay was 1.95 second. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recently, many of conventional infusion control tools which has functions to control the drops of infusion fluid and to monitor the volume of infusion fluid. Because it work manually, it has low level of accuracy and low efficiency. So that, in this research has designed a device that could monitor and control the drops of infusion fluid for multipoint (multi intravenous) through online application. On hardware part, photodiode and LED was used to detect the drops of infusion fluid, a sliding potentiometer and simple modified spring was used to detect the volume of infusion fluid. In this research was also implemented a mechanical which use motor servo to set the speed of drops of infusion fluid. WEMOS and MCU node has been designed as main control to controlling the whole of system. The device was equipped with ESP8266 as interface to internet network. An administrator can monitoring and controlling the system through offline or real time through a website application that has been built. based on the testing result, as functionality the system was working well. The device could detect the drops of infusion fluid with 100 % of accuracy and could control the volume of infusion fluid with 99 % of accuracy. Total of maximum drops per minute that could detected by system was 135 DPMs with average of transferring delay was 1.95 second. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Design of a Blockchain-based e-Tendering System: A Case Study in LPSE"
        ],
        "penulis":"Yutia, Syifa Nurgaida;Rahardjo, Budi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The tender process is a long and complex business process to produce a series of legal obligations related to business contracts. The purpose of conducting a tender in government is to support the work program by finding the right tender (provider of goods and services) in the government procurement program so that it can be the basis of their decision to choose the most suitable tender. At the government in Indonesia, the tender process has been carried out using an e-tendering system with the use of internet technology through LPSE. The purpose of e-tendering is to facilitate the procurement process with related parties to increase productivity, effectiveness, and transparency in the tender process. However, problems in the e-tendering system are currently centralized, so that the local LPSE organization has full control of the database and the system which can pose a threat of vulnerability to fraud, collusion, and manipulation practices. The tender selection process that is full of competition must be supported by effective and transparent technology so that it does not cause fraud and suspicion among bidders. Blockchain technology is one of the solutions that allow integrated systems without a third party because it adheres to the decentralized nature of distributed databases so that it has a copy of many users. By adopting blockchain e-tendering can reduce the source of fraud, namely database manipulation. This research will explore the process of developing a blockchain-based system with e-tendering case studies on LPSE. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The tender process is a long and complex business process to produce a series of legal obligations related to business contracts. The purpose of conducting a tender in government is to support the work program by finding the right tender (provider of goods and services) in the government procurement program so that it can be the basis of their decision to choose the most suitable tender. At the government in Indonesia, the tender process has been carried out using an e-tendering system with the use of internet technology through LPSE. The purpose of e-tendering is to facilitate the procurement process with related parties to increase productivity, effectiveness, and transparency in the tender process. However, problems in the e-tendering system are currently centralized, so that the local LPSE organization has full control of the database and the system which can pose a threat of vulnerability to fraud, collusion, and manipulation practices. The tender selection process that is full of competition must be supported by effective and transparent technology so that it does not cause fraud and suspicion among bidders. Blockchain technology is one of the solutions that allow integrated systems without a third party because it adheres to the decentralized nature of distributed databases so that it has a copy of many users. By adopting blockchain e-tendering can reduce the source of fraud, namely database manipulation. This research will explore the process of developing a blockchain-based system with e-tendering case studies on LPSE. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "RFID Characteristics Test as Business Needs at Logistic Companies in Indonesia"
        ],
        "penulis":"Irsan, Muhamad;Fitria Murad, Dina;Fernando, Erick;Touriano, Derist;Corradini, Andrea;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In embedded RFID chips for storing records or data, such as Electronic Product Code one of them using barcode, in tag. Tags have functions to be able to transmit data for readable readers or stationary readers. using radio transmission technology to read data in tags. Each computer in the same system network can share and track data, regardless of where the item is searched for within the scope of the marked or restricted area. Available information may include item code, item date, delivery date, and item price. This study presents a framework based on RFID Proxied Technology Characteristics Real Time Data Processing, Continuous Data Tracking and Discrete Data, and Reuse and explores its relationship with Business Needs. The observed populations are supervisors and managers working in logistic companies taken cross section obtained from a number of logistics companies incorporated in the Indonesian Logistics Association (ALI) in 2015. Sampling is done using convenience sampling method (convenience sampling method) because the population of respondents working in logistics companies in Indonesia is not known with certainty. This research can contribute to how users can select and measure RFID technology from their characteristics so that the application of RFID systems and technology becomes an added value for the company not just as a complementary technology only. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In embedded RFID chips for storing records or data, such as Electronic Product Code one of them using barcode, in tag. Tags have functions to be able to transmit data for readable readers or stationary readers. using radio transmission technology to read data in tags. Each computer in the same system network can share and track data, regardless of where the item is searched for within the scope of the marked or restricted area. Available information may include item code, item date, delivery date, and item price. This study presents a framework based on RFID Proxied Technology Characteristics Real Time Data Processing, Continuous Data Tracking and Discrete Data, and Reuse and explores its relationship with Business Needs. The observed populations are supervisors and managers working in logistic companies taken cross section obtained from a number of logistics companies incorporated in the Indonesian Logistics Association (ALI) in 2015. Sampling is done using convenience sampling method (convenience sampling method) because the population of respondents working in logistics companies in Indonesia is not known with certainty. This research can contribute to how users can select and measure RFID technology from their characteristics so that the application of RFID systems and technology becomes an added value for the company not just as a complementary technology only. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Classification of Japanese fagaceae wood based on microscopic image analysis"
        ],
        "penulis":"Salma;Gunawan P.H.;Prakasa, Esa;Damayanti, Ratih;Sugiyama, Junji;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents wood identification method on microscopic image of Japanese Fagaceae wood by applying Daubechies Wavelet (DW) and Local Binary Pattern (LBP) algorithms. The main idea for this identification is to extract as much as possible the characteristics of wood to improve accuracy. The color intensity of microscopic wood image can be one of the characteristics of wood. Therefore, before extracting features with DW and LBP, we add color extraction to separate the color intensity in the Red, Green, and Blue (RGB) channels from the image. In addition, we compared several values of the LBP parameter for kernel type original, var, uniform, and ror to find the optimal value. The results of this work performed the accuracy of wood identification on microscopic image of Japanese Fagaceae wood with the Support Vector Machine (SVM) classifier is obtained 95.2% by setting P and R parameters at 8 and 2. Moreover in this paper, the most optimal LBP parameter value occurs when P = 16 and R = 1 for the original kernel type, which reaches 100% accuracy. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents wood identification method on microscopic image of Japanese Fagaceae wood by applying Daubechies Wavelet (DW) and Local Binary Pattern (LBP) algorithms. The main idea for this identification is to extract as much as possible the characteristics of wood to improve accuracy. The color intensity of microscopic wood image can be one of the characteristics of wood. Therefore, before extracting features with DW and LBP, we add color extraction to separate the color intensity in the Red, Green, and Blue (RGB) channels from the image. In addition, we compared several values of the LBP parameter for kernel type original, var, uniform, and ror to find the optimal value. The results of this work performed the accuracy of wood identification on microscopic image of Japanese Fagaceae wood with the Support Vector Machine (SVM) classifier is obtained 95.2% by setting P and R parameters at 8 and 2. Moreover in this paper, the most optimal LBP parameter value occurs when P = 16 and R = 1 for the original kernel type, which reaches 100% accuracy. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Prototype Design Mapping of kWh Meters Based on Internet of Things (IoT)"
        ],
        "penulis":"Ramdana, Fakhri;Nasrun, Muhammad;Setianingsih, Casi;Murti, Muhammad Ary;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At present electricity is one of the most widely used energy sources for humans to support their daily needs. The electricity consumption used by each customer also varies according to the power capacity obtained by each of the electricity customers. Problems with the use of electricity consumption also occur in the campus environment. in the campus environment, the use of electrical energy is included in the high usage due to the dense activity on campus. Generally, the use of high electricity consumption occurs during working hours during the day. but it does not rule out the possibility also occurs at night with additional activities such as research labs and non-academic student agendas.In the construction of the kWh meter in this study, an integration tool of digital power meter (kWh meter) was made with the internet network using a microcontroller and IoT module. By connecting the kWh meter device with IoT, the measurement data can be easily monitored remotely. To monitor the data, a web application was made to monitor the data on electricity consumption. It is expected that with this monitor system users can manage electricity consumption better in accordance with needs.In the measurement accuracy testing, the accuracy value obtained with a multimeter of 99.19% was obtained in the 1P Voltage parameter, and for the results of the throughput test the best value was obtained 100% with a delivery time span every 5 minutes.  \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At present electricity is one of the most widely used energy sources for humans to support their daily needs. The electricity consumption used by each customer also varies according to the power capacity obtained by each of the electricity customers. Problems with the use of electricity consumption also occur in the campus environment. in the campus environment, the use of electrical energy is included in the high usage due to the dense activity on campus. Generally, the use of high electricity consumption occurs during working hours during the day. but it does not rule out the possibility also occurs at night with additional activities such as research labs and non-academic student agendas.In the construction of the kWh meter in this study, an integration tool of digital power meter (kWh meter) was made with the internet network using a microcontroller and IoT module. By connecting the kWh meter device with IoT, the measurement data can be easily monitored remotely. To monitor the data, a web application was made to monitor the data on electricity consumption. It is expected that with this monitor system users can manage electricity consumption better in accordance with needs.In the measurement accuracy testing, the accuracy value obtained with a multimeter of 99.19% was obtained in the 1P Voltage parameter, and for the results of the throughput test the best value was obtained 100% with a delivery time span every 5 minutes.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Case Study of Universities Dormitory Residence Management System (DRMS) in Indonesia"
        ],
        "penulis":"Lubis, Muharman;Fauzi, Rokhman;Lubis, Arif Ridho;Fauzi, Rahmat;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study explores the problems and challenges faced by several universities in Indonesia to allow, commonly, the first year students to enroll in dormitory either online or offline. It is reasonable for prospective students to have expectation that university provide suitable facilities in term of accommodation and logistics considering that a large number of student come from different cities in various provinces. The development of Dormitory Residential Management System (DRMS) should accommodate the process of enrollment, payment and booking from student online and support the staff to control and manage integrated program or activities based on determined schedule. Besides that, the system also allow monitoring process for reporting purpose and notify or confirm certain activities or allocation process. This study investigates several systems used by respected universities to identify the level of satisfaction of students. Interestingly, there are many evidences showed bottom level of satisfaction from student towards the services offered by university for DRMS. \u00a9 2018 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study explores the problems and challenges faced by several universities in Indonesia to allow, commonly, the first year students to enroll in dormitory either online or offline. It is reasonable for prospective students to have expectation that university provide suitable facilities in term of accommodation and logistics considering that a large number of student come from different cities in various provinces. The development of Dormitory Residential Management System (DRMS) should accommodate the process of enrollment, payment and booking from student online and support the staff to control and manage integrated program or activities based on determined schedule. Besides that, the system also allow monitoring process for reporting purpose and notify or confirm certain activities or allocation process. This study investigates several systems used by respected universities to identify the level of satisfaction of students. Interestingly, there are many evidences showed bottom level of satisfaction from student towards the services offered by university for DRMS. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Classification of microarray data involves Na\u00efve Bayes and dimension reduction using haar wavelet"
        ],
        "penulis":"Rohmawati, Aniq A.;Adiwijaya;Sarmilah, Milah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A general problem solving for handling microarray data is classification process with added a selection process from huge attributes. In particular, the escalated of attributes dimensionality provides a challenge to microarray handling techniques, related to microarray represents the large amount of genes expression. The multi-dependency (multicollinearity) may affect the performance when determining the parameter of classification. Many ways of solving the multicollinearity problem exists, the variable selection technique has become particularly popular. This is the method which use wavelet transformation for a few carefully selected variable and the method which regress respond variable onto a few linier combinations (components) of the original attributes. Wavelet is commonly used in image processing, spectral data using wavelet transformation have proved very successful in capturing the distinction among hyperspectral data. This paper investigates a new method of transformation data using Haar wavelet for selection processes. Our extensive study compares the selection processes using Haar wavelet transformation and Genetic Algorithm considering the selection dataset that implemented to Na\u00efve Bayes classification. In addition, the selection-classification using Haar wavelet and Na\u00efve Bayes describes a classification cancer and non-cancer quite well related to the accuracy of confusion matrix. \u00a9 BEIESP.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A general problem solving for handling microarray data is classification process with added a selection process from huge attributes. In particular, the escalated of attributes dimensionality provides a challenge to microarray handling techniques, related to microarray represents the large amount of genes expression. The multi-dependency (multicollinearity) may affect the performance when determining the parameter of classification. Many ways of solving the multicollinearity problem exists, the variable selection technique has become particularly popular. This is the method which use wavelet transformation for a few carefully selected variable and the method which regress respond variable onto a few linier combinations (components) of the original attributes. Wavelet is commonly used in image processing, spectral data using wavelet transformation have proved very successful in capturing the distinction among hyperspectral data. This paper investigates a new method of transformation data using Haar wavelet for selection processes. Our extensive study compares the selection processes using Haar wavelet transformation and Genetic Algorithm considering the selection dataset that implemented to Na\u00efve Bayes classification. In addition, the selection-classification using Haar wavelet and Na\u00efve Bayes describes a classification cancer and non-cancer quite well related to the accuracy of confusion matrix. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Disaster victims detection system using convolutional neural network (CNN) method"
        ],
        "penulis":"Hartawan, Dean Rizki;Purboyo, Tito Waluyo;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Natural disasters are one of the things that cannot be predicted. Natural disasters can cause losses, both assets and objects can even take lives. To reduce the number of losses, rapid evacuation handling from the Search and Rescue (SAR) team is needed to help victims of natural disasters. But in fact, there are often obstacles in the evacuation process. Such obstacles are such as bad weather conditions, disconnection of telecommunications networks, difficulty access to the victims of natural disasters and the spread of SAR teams that are not evenly distributed throughout the disaster area. Convolutional Neural Network is one of the developments of Artificial Neural Networks for image classification, image segmentation, and object recognition with high accuracy and high performance. CNN can learn to detect various images according to images from the dataset studied. So, this paper designed a system for detecting victims of natural disasters using the CNN method and implemented it on a raspberry pi which can detect victims of natural disasters through streaming cameras placed on UAVs. In this paper, the Convolutional Neural Network (CNN) method with 100% accuracy with distance object 1-4 m uses the Mobile-net SSD model. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Natural disasters are one of the things that cannot be predicted. Natural disasters can cause losses, both assets and objects can even take lives. To reduce the number of losses, rapid evacuation handling from the Search and Rescue (SAR) team is needed to help victims of natural disasters. But in fact, there are often obstacles in the evacuation process. Such obstacles are such as bad weather conditions, disconnection of telecommunications networks, difficulty access to the victims of natural disasters and the spread of SAR teams that are not evenly distributed throughout the disaster area. Convolutional Neural Network is one of the developments of Artificial Neural Networks for image classification, image segmentation, and object recognition with high accuracy and high performance. CNN can learn to detect various images according to images from the dataset studied. So, this paper designed a system for detecting victims of natural disasters using the CNN method and implemented it on a raspberry pi which can detect victims of natural disasters through streaming cameras placed on UAVs. In this paper, the Convolutional Neural Network (CNN) method with 100% accuracy with distance object 1-4 m uses the Mobile-net SSD model. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Application of Distributed Databases for Information Systems Fertilizer Management"
        ],
        "penulis":"Ali A.H.;Nugraha R.A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of this study is to identify and build applications that will integrate two databases and testing system by using black-box. The stages of the research method were systematic observation, data collection, system design, manufacture, and final system testing. The results of this study are the implementation of distributed database-based fertilizer buying and selling transactions that are used as online fertilizer stock reporting from retailers to distributors. The conclusion of this study is by utilizing the Internet with the proposed system (distributed database application) than providing an alternative in the process of fertilizer transactions by distributor and fertilizer stores. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to identify and build applications that will integrate two databases and testing system by using black-box. The stages of the research method were systematic observation, data collection, system design, manufacture, and final system testing. The results of this study are the implementation of distributed database-based fertilizer buying and selling transactions that are used as online fertilizer stock reporting from retailers to distributors. The conclusion of this study is by utilizing the Internet with the proposed system (distributed database application) than providing an alternative in the process of fertilizer transactions by distributor and fertilizer stores. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Increasing accuracy of power consumption using artificial neural network"
        ],
        "penulis":"Syukur, Arry Muhammad;Putrada, Aji Gautama;Abdurohman, Maman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposed a smart lighting system using Artificial Neural Network (ANN) algorithm. Power saving is one of the concerns of researchers to continue to be improved. The addition of predictions will increase the ability to save power on the use of smart home devices in the future. Through prediction, the system can decide when the lights are used and when the lights are not used. Therefore, an IoT-based smart light system that can predict the state of the lamp based on sensor data is needed. In this paper ANN algorithm is used to predict the state of the lamp. The purpose of this paper is to analyze the performance of the ANN by entering data from the light system based on the presence of lecturers using magnetic door and infrared sensors. The accuracy of the ANN application is influenced by the lamp state pattern. The result shows that an accuracy of 58.17% for training data and 52.54% for test data in predicting the state of the lamp. The significant power saving is calculated using Wilcoxon Method. It shows that this system provides significance for power saving of 31.75%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposed a smart lighting system using Artificial Neural Network (ANN) algorithm. Power saving is one of the concerns of researchers to continue to be improved. The addition of predictions will increase the ability to save power on the use of smart home devices in the future. Through prediction, the system can decide when the lights are used and when the lights are not used. Therefore, an IoT-based smart light system that can predict the state of the lamp based on sensor data is needed. In this paper ANN algorithm is used to predict the state of the lamp. The purpose of this paper is to analyze the performance of the ANN by entering data from the light system based on the presence of lecturers using magnetic door and infrared sensors. The accuracy of the ANN application is influenced by the lamp state pattern. The result shows that an accuracy of 58.17% for training data and 52.54% for test data in predicting the state of the lamp. The significant power saving is calculated using Wilcoxon Method. It shows that this system provides significance for power saving of 31.75%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Shape Magnetic Anisotropy from Spin Density in Nanoscale Slab Systems"
        ],
        "penulis":"Oda, Tatsuki;Pardede, Indra;Kanagawa, Tomosato;Ikhsan, Nurul;Yoshikawa, Daiki;Obata, Masao;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We developed a computational method for estimating magnetic dipole energy of slab materials using spin density obtained through a density functional approach. The new method can accurately estimate magnetic anisotropy energy (MAE) for slabs from magnetic dipole interaction called shape MAE (SMAE). We investigated ferromagnetic and antiferromagnetic slabs and found that a quadrupole component of atomic spin density suppresses SMAE in ferromagnetic slabs with Fe\/MgO interface. In antiferromagnetic MnPt slabs, which have a perpendicular favor originating from the crystalline magnetic dipole interaction, a surface effect at the Mn edge appears as an enhancement of SMAE. \u00a9 1965-2012 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We developed a computational method for estimating magnetic dipole energy of slab materials using spin density obtained through a density functional approach. The new method can accurately estimate magnetic anisotropy energy (MAE) for slabs from magnetic dipole interaction called shape MAE (SMAE). We investigated ferromagnetic and antiferromagnetic slabs and found that a quadrupole component of atomic spin density suppresses SMAE in ferromagnetic slabs with Fe\/MgO interface. In antiferromagnetic MnPt slabs, which have a perpendicular favor originating from the crystalline magnetic dipole interaction, a surface effect at the Mn edge appears as an enhancement of SMAE. \u00a9 1965-2012 IEEE."
        ]
    },
    {
        "judul":[
            "SENTIMENT ANALYSIS of 'Indonesian NO DATING CAMPAIGNS' on TWITTER USING NA\u00cfVE BAYES ALGORITHM"
        ],
        "penulis":"Ardhianie, Nadia;Andreswari, Rachmadita;Hs, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The modern world has witnessed the widespread emergence of online social media. Many people use this kind of technology to share their view about anything. As consequence, it is easy to know public opinions on certain issue by utilizing social media data. One of trending issue in Indonesian Twitter user is about 'Indonesian No Dating Campaign. It is interesting to know effectiveness of that campaign by analyzing public sentiment. In order to analyze the campaign, this study employ sentiment analysis using Na\u00efve Bayes algorithm. This algorithm was chosen by considering its accuracy in several related studies. This research starts with data collection process, by crawling twitter's data that related to the campaign. The collected data will go through the data preprocessing, data classification based on its sentiment using Na\u00efve Bayes. As the result, Na\u00efve Bayes algorithm successfully classifies the twitter's data into 56% positive sentiment, negative sentiment 32% and neutral sentiment 12%. The accuracy of this classification is 74.77%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The modern world has witnessed the widespread emergence of online social media. Many people use this kind of technology to share their view about anything. As consequence, it is easy to know public opinions on certain issue by utilizing social media data. One of trending issue in Indonesian Twitter user is about 'Indonesian No Dating Campaign. It is interesting to know effectiveness of that campaign by analyzing public sentiment. In order to analyze the campaign, this study employ sentiment analysis using Na\u00efve Bayes algorithm. This algorithm was chosen by considering its accuracy in several related studies. This research starts with data collection process, by crawling twitter's data that related to the campaign. The collected data will go through the data preprocessing, data classification based on its sentiment using Na\u00efve Bayes. As the result, Na\u00efve Bayes algorithm successfully classifies the twitter's data into 56% positive sentiment, negative sentiment 32% and neutral sentiment 12%. The accuracy of this classification is 74.77%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Item Delivery Simulation Using Dijkstra Algorithm for Solving Traveling Salesman Problem"
        ],
        "penulis":"Ginting, Hagai Nuansa;Osmond, Andrew Brian;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Companies that contribute to travel have many problems in the process of item delivery. Distances and priorities are considered for a process of item delivery based on the highest priority. A delivery target that can be done one day evidently exceed the expected limit and that is the impact. This is an example of the waste time and operational costs that should be at the same time that two or more addresses can be sent. Traveling Salesman Problem (TSP) was define a classical problem to finding the shortest route that salesman can be passed when visiting several places without visit again in the same place more than once. In this study, TSP requires all calculations of possible routes to be obtained. Then choose one of the shortest routes by prioritizing the things considered, namely distance and priority. Delivery is done quickly through the shortest route according to priority using the Dijkstra algorithm. Simulation shows that the Dijkstra algorithm must be approved by use clustering data for Dijkstra's priorities and sub-routes to solve TSP problems. Simulation shows that the Dijkstra algorithm must be modified using Dijkstra's priority clustering and sub-routing to solve TSP problems. The resulting route has an influence between two graphs. Complete graph has a distance efficiency of 47.8% and execution time of 48.1% compared to non-complete graphs. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Companies that contribute to travel have many problems in the process of item delivery. Distances and priorities are considered for a process of item delivery based on the highest priority. A delivery target that can be done one day evidently exceed the expected limit and that is the impact. This is an example of the waste time and operational costs that should be at the same time that two or more addresses can be sent. Traveling Salesman Problem (TSP) was define a classical problem to finding the shortest route that salesman can be passed when visiting several places without visit again in the same place more than once. In this study, TSP requires all calculations of possible routes to be obtained. Then choose one of the shortest routes by prioritizing the things considered, namely distance and priority. Delivery is done quickly through the shortest route according to priority using the Dijkstra algorithm. Simulation shows that the Dijkstra algorithm must be approved by use clustering data for Dijkstra's priorities and sub-routes to solve TSP problems. Simulation shows that the Dijkstra algorithm must be modified using Dijkstra's priority clustering and sub-routing to solve TSP problems. The resulting route has an influence between two graphs. Complete graph has a distance efficiency of 47.8% and execution time of 48.1% compared to non-complete graphs. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Management maintenance system for remote control based on microcontroller and virtual private serve"
        ],
        "penulis":"Kamil, Idham;Julham;Lubis, Muharman;Lubis, Arif Ridho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Open loop shaped control system is a form of system control without any feedback from the system. One example is the on-off condition which functions to connect and disconnect electricity. The condition to be studied is a dc motor that can be set to live and die via internet server-based client service. The server in this system is a virtual private server (VPS) device that will provide a source of service to the client in the form of a collection of information on dc motor conditions. In addition, its function is also to record the working time of the dc motor. So that a schedule can be determined when the dc motor is maintained. While the client is a control unit consisting of a microcontroller device, an ethernet module enc28j60 and a dc motor. In general the working principle of the system is beginning with the user accessing the desired VPS IP address through a web browser application. From the web browser the user chooses a dc motor to be activated. But before the client has been connected to the VPS regularly (every second), the point is to always get the latest dc motor condition information. Then the microcontroller will set the dc motor in active or off condition. The research method used is research and development. The results obtained from this study are that the amount of bandwidth needed for communication between VPS and microcontrollers via the internet network, when the control unit works is 6.02 kbps, while the response time for dc motor is 3.16 seconds and the response time for dc motor 2 is 3.46 seconds. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "CH3OHH3CCH3OHHHView detailsExpand Substance 17-methyltestosterone",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Open loop shaped control system is a form of system control without any feedback from the system. One example is the on-off condition which functions to connect and disconnect electricity. The condition to be studied is a dc motor that can be set to live and die via internet server-based client service. The server in this system is a virtual private server (VPS) device that will provide a source of service to the client in the form of a collection of information on dc motor conditions. In addition, its function is also to record the working time of the dc motor. So that a schedule can be determined when the dc motor is maintained. While the client is a control unit consisting of a microcontroller device, an ethernet module enc28j60 and a dc motor. In general the working principle of the system is beginning with the user accessing the desired VPS IP address through a web browser application. From the web browser the user chooses a dc motor to be activated. But before the client has been connected to the VPS regularly (every second), the point is to always get the latest dc motor condition information. Then the microcontroller will set the dc motor in active or off condition. The research method used is research and development. The results obtained from this study are that the amount of bandwidth needed for communication between VPS and microcontrollers via the internet network, when the control unit works is 6.02 kbps, while the response time for dc motor is 3.16 seconds and the response time for dc motor 2 is 3.46 seconds. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Performance analysis of tunnel broker through open virtual private network"
        ],
        "penulis":"Munadi, Rendy;Sanjoyo, Danu Dwi;Perdana, Doan;Adjie, Fidar;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tunnel Broker uses automatic configuration tunneling mechanism for IPv6 clients connected to IPv4 internet. Connectivity between clients and service providers in IPv6 is urgently needed. Open VPN as a provider implemented configures it by a VPN network, so IPv6 and IPv4 public IP clients can easily connect to the server. In this research focused on the performance of tunnel broker mechanism by utilizing open VPN as access to the network. IPv6 tunnel broker is developed by installing Open VPN and providing IPv6 IPs. Implementation of public IP usage in observing the performance of tunnel broker development is done in BCN Telkom Laboratory Network. The measurement results show that TCP and UDP throughput of IPv6 is slightly higher than IPv4. The research using OpenVPN as a server Tunnel Broker for client access to the server is still rarely done, especially in the field of the network based on Internet Protocol. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tunnel Broker uses automatic configuration tunneling mechanism for IPv6 clients connected to IPv4 internet. Connectivity between clients and service providers in IPv6 is urgently needed. Open VPN as a provider implemented configures it by a VPN network, so IPv6 and IPv4 public IP clients can easily connect to the server. In this research focused on the performance of tunnel broker mechanism by utilizing open VPN as access to the network. IPv6 tunnel broker is developed by installing Open VPN and providing IPv6 IPs. Implementation of public IP usage in observing the performance of tunnel broker development is done in BCN Telkom Laboratory Network. The measurement results show that TCP and UDP throughput of IPv6 is slightly higher than IPv4. The research using OpenVPN as a server Tunnel Broker for client access to the server is still rarely done, especially in the field of the network based on Internet Protocol. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Labeling Analysis in the Classification of Product Review Sentiments by using Multinomial Naive Bayes Algorithm"
        ],
        "penulis":"Tama V.O.;Sibaroni Y.;Adiwijaya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Along with the development of technology, e-commerce also experienced a fairly rapid development. The existence of e-commerce becomes another consumer alternative to make it easier for them to fulfill their needs. After buying the goods, consumers are free to assess the products they buy. Product reviews and ratings provided by consumers are one means that can be used to increase sales and can also be used to determine the decision in purchasing a product by reading the product reviews. However, using ratings and reviews alone is not enough to summarize one's opinion. Therefore, in this Final Project built a system that can classify opinions on product reviews into positive and negative sentiments by utilizing the rating. The dataset used is Grocery and Gourmet Food from Amazon as much as 50,000 which will then be labeled using Labeling Methods Average and Binary. The classification of this opinion uses the approach of Supervised learning Algorithm Multinomial Na\u00efve Bayes. The result of this research shows that labeling using Method Average is suitable for processing Grocery and Gourmet Food Dataset and proves that the best ratio of feature selection usage is 20% succeed to produce 80.48% accuracy. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Along with the development of technology, e-commerce also experienced a fairly rapid development. The existence of e-commerce becomes another consumer alternative to make it easier for them to fulfill their needs. After buying the goods, consumers are free to assess the products they buy. Product reviews and ratings provided by consumers are one means that can be used to increase sales and can also be used to determine the decision in purchasing a product by reading the product reviews. However, using ratings and reviews alone is not enough to summarize one's opinion. Therefore, in this Final Project built a system that can classify opinions on product reviews into positive and negative sentiments by utilizing the rating. The dataset used is Grocery and Gourmet Food from Amazon as much as 50,000 which will then be labeled using Labeling Methods Average and Binary. The classification of this opinion uses the approach of Supervised learning Algorithm Multinomial Na\u00efve Bayes. The result of this research shows that labeling using Method Average is suitable for processing Grocery and Gourmet Food Dataset and proves that the best ratio of feature selection usage is 20% succeed to produce 80.48% accuracy. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Business process analysis of academic information system application using process mining (case study: Final project module)"
        ],
        "penulis":"Fitriansah, Ilham Akbar;Andreswari, Rachmadita;Hasibuan, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of information technology is currently influencing the organization; one of them is Telkom University. Online-Based information technology at Telkom University, namely the Integrated Academic Information System (I-Gracias). I-Gracias is an Academic Information System owned by Telkom University that provides services both academically and non-academically. One of the menus in i-Gracias is the TA \/ PA application; this menu intends for students who will take the bachelor degree final project and will carry out the bachelor degree final project. Based on the current procedure, the service standards for the TA \/ PA I-Gracias application provided do not have specific service time limits. There are differences in service for each user in the TA \/ PA application activity. Therefore, to find out the actual operations in this application, a modeling process is needed to find out the activities that have the longest time. Identification of the modeling process is made by using the process mining approach and utilizing the I-Gracias log event. The modeling process uses the Heuristic Miner modeling technique aimed at modeling the process and finding the best fitness value. The heuristic miner algorithm is chosen because of its ability to handle event logs with noise and can display primary behavior from existing business processes. After getting the modeling, then analyzing the bottleneck for the procedure. Based on the conformance checking results, the best fitness value is 0.98492914, the precision value is 0.7015873, and the structure value is 1. Modeling in performance analysis shows that there are bottlenecks in the activity of uploading proposals and completeness of print trial activities. Bottleneck shows the problem related to the bachelor degree final project guidance application. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of information technology is currently influencing the organization; one of them is Telkom University. Online-Based information technology at Telkom University, namely the Integrated Academic Information System (I-Gracias). I-Gracias is an Academic Information System owned by Telkom University that provides services both academically and non-academically. One of the menus in i-Gracias is the TA \/ PA application; this menu intends for students who will take the bachelor degree final project and will carry out the bachelor degree final project. Based on the current procedure, the service standards for the TA \/ PA I-Gracias application provided do not have specific service time limits. There are differences in service for each user in the TA \/ PA application activity. Therefore, to find out the actual operations in this application, a modeling process is needed to find out the activities that have the longest time. Identification of the modeling process is made by using the process mining approach and utilizing the I-Gracias log event. The modeling process uses the Heuristic Miner modeling technique aimed at modeling the process and finding the best fitness value. The heuristic miner algorithm is chosen because of its ability to handle event logs with noise and can display primary behavior from existing business processes. After getting the modeling, then analyzing the bottleneck for the procedure. Based on the conformance checking results, the best fitness value is 0.98492914, the precision value is 0.7015873, and the structure value is 1. Modeling in performance analysis shows that there are bottlenecks in the activity of uploading proposals and completeness of print trial activities. Bottleneck shows the problem related to the bachelor degree final project guidance application. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Enhancing the performance of smote algorithm by using attribute weighting scheme and new selective sampling method for imbalanced data set"
        ],
        "penulis":"Fahrudin, Tora;Buliali, Joko Lianto;Fatichah, Chastine;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "SMOTE is one of the well-known algorithms for balancing train data by adding synthetic data on minor class data. One of the stages in SMOTE is finding the nearest neighbors (kNN) as the basis for creating synthetic data using Euclidean dis- tance. In cases where a small number of attributes having high correlation value than others, finding kNN using Euclidean without considering this correlation may not find representative neighbors. This paper introduces AWH-SMOTE (Attribute Weighted and kNN Hub on SMOTE), which enhances SMOTE in improving neighbors and noise identification using attribute weighting and also improving selective sampling method using occurrence data in the kNN hub. Wojna and Information Gain methods are used for attribute weighting. A small number of occurrences in the kNN hub results in more syn- thetic data generated so that minority data in dangerous region are more represented. Nine public datasets from Keel repository are used to evaluate AWH-SMOTE. Evaluation shows AWH-SMOTE has better performance on minority precision and minority f-measure for both pruned and unpruned condition than other oversampling algorithms. Information Gain as attribute weighting method in AWH-SMOTE achieves best perfor- mance in unpruned condition when compared to other weighting methods for minority recall, minority precision and minority f-measure. \u00a9 2019 ICIC International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SMOTE is one of the well-known algorithms for balancing train data by adding synthetic data on minor class data. One of the stages in SMOTE is finding the nearest neighbors (kNN) as the basis for creating synthetic data using Euclidean dis- tance. In cases where a small number of attributes having high correlation value than others, finding kNN using Euclidean without considering this correlation may not find representative neighbors. This paper introduces AWH-SMOTE (Attribute Weighted and kNN Hub on SMOTE), which enhances SMOTE in improving neighbors and noise identification using attribute weighting and also improving selective sampling method using occurrence data in the kNN hub. Wojna and Information Gain methods are used for attribute weighting. A small number of occurrences in the kNN hub results in more syn- thetic data generated so that minority data in dangerous region are more represented. Nine public datasets from Keel repository are used to evaluate AWH-SMOTE. Evaluation shows AWH-SMOTE has better performance on minority precision and minority f-measure for both pruned and unpruned condition than other oversampling algorithms. Information Gain as attribute weighting method in AWH-SMOTE achieves best perfor- mance in unpruned condition when compared to other weighting methods for minority recall, minority precision and minority f-measure. \u00a9 2019 ICIC International."
        ]
    },
    {
        "judul":[
            "Study of squeezer machine performance of cooked soy porridge"
        ],
        "penulis":"Hadi R.M.E.;Chumaidiah E.;Wulandari S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Managers of tofu craftsmen complain a lot on the issue of soybean raw materials that the more days the price is increasing so high, so the benefits gained is decreasing significantly. To anticipate the continuous soybean price increase, the tofu craftsmen plan to make a squeezer machine of cooked soybean porridge which is useful to increase the juice, reduce the time of squeeze, and can ease the squeeze. The benefits of squeezer machine of cooked soybean porridge are that from the aspect of its output it will produce more, that in terms of time it can be faster, that the energy spent is very small because the squeeze utilizes the power of the driving motor, and the tofu dregs produced will be less. The performance study of hygienic tofu making by utilizing a squeezer machine of cooked soybean porridge will be done by comparing the measurement of squeeze time which is currently done by measuring the squeeze time by utilizing the squeezer machine of cooked soybean porridge and measuring the water content in the tofu dregs after the squeeze process. The results are by utilizing the squeezer machine of cooked soybean porridge meet the requirements in accordance with the wishes of the tofu craftsmen in which the water content in the tofu dregs is little, the tofu produced is more, and the process of squeeze is quicker. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Managers of tofu craftsmen complain a lot on the issue of soybean raw materials that the more days the price is increasing so high, so the benefits gained is decreasing significantly. To anticipate the continuous soybean price increase, the tofu craftsmen plan to make a squeezer machine of cooked soybean porridge which is useful to increase the juice, reduce the time of squeeze, and can ease the squeeze. The benefits of squeezer machine of cooked soybean porridge are that from the aspect of its output it will produce more, that in terms of time it can be faster, that the energy spent is very small because the squeeze utilizes the power of the driving motor, and the tofu dregs produced will be less. The performance study of hygienic tofu making by utilizing a squeezer machine of cooked soybean porridge will be done by comparing the measurement of squeeze time which is currently done by measuring the squeeze time by utilizing the squeezer machine of cooked soybean porridge and measuring the water content in the tofu dregs after the squeeze process. The results are by utilizing the squeezer machine of cooked soybean porridge meet the requirements in accordance with the wishes of the tofu craftsmen in which the water content in the tofu dregs is little, the tofu produced is more, and the process of squeeze is quicker. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Fire Detection Using Image Processing Techniques with Convolutional Neural Networks"
        ],
        "penulis":"Sadewa, Raam Pujangga;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Fire is a flame, whether it is small or large, an undesirable place, situation and time. In general, every place has the potential to experience a fire. But at this time, the smoke sensors are the most widely used devices to detect fires. Where the smoke sensors can only detect fires if the fire is large. So that a system is needed to detect early fires. In this paper, an image-based fire alarm system is designed, using a laptop and webcam as the main equipment. The method for using Convolutional Neural Networks (CNN) to identify fire. The system created has an accuracy rate of 92%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Fire is a flame, whether it is small or large, an undesirable place, situation and time. In general, every place has the potential to experience a fire. But at this time, the smoke sensors are the most widely used devices to detect fires. Where the smoke sensors can only detect fires if the fire is large. So that a system is needed to detect early fires. In this paper, an image-based fire alarm system is designed, using a laptop and webcam as the main equipment. The method for using Convolutional Neural Networks (CNN) to identify fire. The system created has an accuracy rate of 92%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis and Design of Data Synchronization Algorithm for Master Data Management Tools Based on Open Source Platform at PT. XYZ"
        ],
        "penulis":"Hanif, Amri;Kusumasari, Tien Fabrianti;Andreswari, Rachmadita;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Data is the source of any information. Quality of data will provide accurate information. There are still many companies, especially State-Owned Enterprises that have not been able to maintain the quality of data. There is still a lot of duplication and redundancy of data in each application. Actually, the data remains the same even when the app is different. This problem can be solved by applying Data Governance processes, that is Reference and Master Data. In this process requires a Master Data Management Tool to manage, so the data will no longer be duplication or redundancy of data. In this research focuses on the analysis and design of master data synchronization algorithms, update master data algorithms, saving master data algorithms and using open source application platform that is Pentaho Data Integration. The results of this research are the matching data algorithm, saving master data algorithms, change master data algorithm and synchronization and integration master data algorithm. Although use open source-based application, MDM algorithm in this research can be made of data on the PT. XYZ can be synchronized and integrated between applications and can help PT. XYZ to maintain the quality of their data. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data is the source of any information. Quality of data will provide accurate information. There are still many companies, especially State-Owned Enterprises that have not been able to maintain the quality of data. There is still a lot of duplication and redundancy of data in each application. Actually, the data remains the same even when the app is different. This problem can be solved by applying Data Governance processes, that is Reference and Master Data. In this process requires a Master Data Management Tool to manage, so the data will no longer be duplication or redundancy of data. In this research focuses on the analysis and design of master data synchronization algorithms, update master data algorithms, saving master data algorithms and using open source application platform that is Pentaho Data Integration. The results of this research are the matching data algorithm, saving master data algorithms, change master data algorithm and synchronization and integration master data algorithm. Although use open source-based application, MDM algorithm in this research can be made of data on the PT. XYZ can be synchronized and integrated between applications and can help PT. XYZ to maintain the quality of their data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Stream Control Transportation Protocol (SCTP) towards MANET Routing: Comparison of DSR and AODV"
        ],
        "penulis":"Lubis, Muharman;Lubis, Fahrurrozi;Lubis, Arif Ridho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research wants to compare the performance of Stream Control Transportation Protocol (SCTP) with two difference mechanism, which are Ad-hoc on Demand Distance Vector (AODV) and Dynamic Source Routing protocol (DSR) by using Network Simulator (NS-2). Specifically, it measures the behavior of SCTP in terms of throughput and smoothness by having assumption that routing protocol in MANET (Mobile Ad-hoc Network) can bring significant effect in SCTP in the overall performance. Actually, IETF (Internet Engineering Task Force), has issued a new protocol called SCTP, which in this study, the interaction of SCTP is investigated through the examination of traffic flows through a number of network topologies. This performance analysis is over MANET Routing Protocol that enables the process of analysis of several performance metrics. The simulation use topology with 16 nodes that is consisting of metric 4\u00d74 of SCTP transport layer for both routing protocol of AODV and DSR. At last, this research have been found that MANET impact less on the throughput of SCTP with only amounted to 0-2% within 5m\/s to 25 m\/s of simulation area. Furthermore, the speed of node movement does not significantly affect the smoothness as well. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research wants to compare the performance of Stream Control Transportation Protocol (SCTP) with two difference mechanism, which are Ad-hoc on Demand Distance Vector (AODV) and Dynamic Source Routing protocol (DSR) by using Network Simulator (NS-2). Specifically, it measures the behavior of SCTP in terms of throughput and smoothness by having assumption that routing protocol in MANET (Mobile Ad-hoc Network) can bring significant effect in SCTP in the overall performance. Actually, IETF (Internet Engineering Task Force), has issued a new protocol called SCTP, which in this study, the interaction of SCTP is investigated through the examination of traffic flows through a number of network topologies. This performance analysis is over MANET Routing Protocol that enables the process of analysis of several performance metrics. The simulation use topology with 16 nodes that is consisting of metric 4\u00d74 of SCTP transport layer for both routing protocol of AODV and DSR. At last, this research have been found that MANET impact less on the throughput of SCTP with only amounted to 0-2% within 5m\/s to 25 m\/s of simulation area. Furthermore, the speed of node movement does not significantly affect the smoothness as well. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Optimization of a photovoltaic hybrid energy storage system using energy storage peak shaving"
        ],
        "penulis":"Adam, Kharisma Bani;Miyauchi, Hajime;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electrical supply in rural areas, especially on small islands, commonly utilizes eco-unfriendly and costly diesel-based power plants. Renewable energy power plants can replace these diesel-based power plants. Thus, energy optimization is critical for the improvement of the energy efficiency of the renewable energy system. The optimization of a photovoltaic energy system through a hybrid energy storage system is analyzed for the off-grid island. The hybrid energy storage system involves the hybridization of two energy storage systems including a battery storage system and a hydrogen storage system. The management of a photovoltaic hybrid energy storage system requires a power management system. This paper proposes a power management system based on the peak shaving strategy in hydrogen energy storage to improve the efficiency of the hybrid energy storage system while considering the surplus energy forecasting. The hybrid energy storage system typically focuses on the efficiency of a closed system. In such a closed system, the optimization focuses on the life-saving of the battery. The energy storage peak shaving is used to improve the efficiency of the hybrid energy storage system, for the maximization of excess hydrogen to supply electricity to the islands. The result reveals that the average efficiency of the hybrid energy storage system based on the proposed power management system is 52.3%, which is 29.6% higher than the one obtained from traditional power management system strategy, whereas the battery depreciation is improved by 1.2%. \u00a9 2019 Praise Worthy Prize S.r.l.-All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electrical supply in rural areas, especially on small islands, commonly utilizes eco-unfriendly and costly diesel-based power plants. Renewable energy power plants can replace these diesel-based power plants. Thus, energy optimization is critical for the improvement of the energy efficiency of the renewable energy system. The optimization of a photovoltaic energy system through a hybrid energy storage system is analyzed for the off-grid island. The hybrid energy storage system involves the hybridization of two energy storage systems including a battery storage system and a hydrogen storage system. The management of a photovoltaic hybrid energy storage system requires a power management system. This paper proposes a power management system based on the peak shaving strategy in hydrogen energy storage to improve the efficiency of the hybrid energy storage system while considering the surplus energy forecasting. The hybrid energy storage system typically focuses on the efficiency of a closed system. In such a closed system, the optimization focuses on the life-saving of the battery. The energy storage peak shaving is used to improve the efficiency of the hybrid energy storage system, for the maximization of excess hydrogen to supply electricity to the islands. The result reveals that the average efficiency of the hybrid energy storage system based on the proposed power management system is 52.3%, which is 29.6% higher than the one obtained from traditional power management system strategy, whereas the battery depreciation is improved by 1.2%. \u00a9 2019 Praise Worthy Prize S.r.l.-All rights reserved."
        ]
    },
    {
        "judul":[
            "The undersampling effects on RANDSHUFF oversampling algorithms"
        ],
        "penulis":"Fahrudin, Tora;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Randshuff (Random Shuffle Oversampling Techniques for Qualitative Data) is one of an oversampling algorithm which appropriate for nominal attributes. Randshuff uses IVDM (Interpolated Value Difference Metric) distance calculation and crossover with random shuffle technique. Although Randshuff can overcome the problems on minority data, but the problems on majority data are ignored. The problem arises where majority data contain distribution complexity problems such as small disjuncts, overlap and noise. There are two kinds of undersampling concepts: informed undersampling and simple random undersampling. Tomeks links, Edited Nearest neighbors (ENN) and Near Miss are informed undersampling state of the art methods. Meanwhile, Random Undersampling (RUS) is simple random undersampling method. So, evaluations of both undersampling concepts on Randshuff are needed to be conducted. The experiments were evaluated on five public datasets. The results show that RUS as simple random undersampling and Near Miss as informed under sampling improve recall, f-measure and g-mean performance on Randshuff algorithm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Randshuff (Random Shuffle Oversampling Techniques for Qualitative Data) is one of an oversampling algorithm which appropriate for nominal attributes. Randshuff uses IVDM (Interpolated Value Difference Metric) distance calculation and crossover with random shuffle technique. Although Randshuff can overcome the problems on minority data, but the problems on majority data are ignored. The problem arises where majority data contain distribution complexity problems such as small disjuncts, overlap and noise. There are two kinds of undersampling concepts: informed undersampling and simple random undersampling. Tomeks links, Edited Nearest neighbors (ENN) and Near Miss are informed undersampling state of the art methods. Meanwhile, Random Undersampling (RUS) is simple random undersampling method. So, evaluations of both undersampling concepts on Randshuff are needed to be conducted. The experiments were evaluated on five public datasets. The results show that RUS as simple random undersampling and Near Miss as informed under sampling improve recall, f-measure and g-mean performance on Randshuff algorithm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Towards Successful Implementation of a Virtual Classroom for Vocational Higher Education in Indonesia"
        ],
        "penulis":"Aditya, Bayu Rima;Nurhas, Irawan;Pawlowski, Jan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The virtual classroom continues to grow, but it is becoming more and more the norm, and it is fundamentally different from the vocational students at the Indonesian university. With the promised benefits of the virtual classroom, many challenges and difficulties come in the implementation. Although there are already successful design principles for virtual classrooms that support organizations in overcoming the challenges, the approach to implementing the design principles of virtual classroom at the vocational higher education in Indonesia is still lacking. In this study, we aim to answer the research gap and used the design sciences research by interviewing the lecturers to design the solutions. The proposed design approaches were implemented in a course and evaluated with students from two different groups. Overall, the evaluation of the proposed approaches shows 1 significant results as an indicator of the benefits of the implementation of a virtual classroom for vocational students in Indonesia. \u00a9 2019, Springer Nature Switzerland AG.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The virtual classroom continues to grow, but it is becoming more and more the norm, and it is fundamentally different from the vocational students at the Indonesian university. With the promised benefits of the virtual classroom, many challenges and difficulties come in the implementation. Although there are already successful design principles for virtual classrooms that support organizations in overcoming the challenges, the approach to implementing the design principles of virtual classroom at the vocational higher education in Indonesia is still lacking. In this study, we aim to answer the research gap and used the design sciences research by interviewing the lecturers to design the solutions. The proposed design approaches were implemented in a course and evaluated with students from two different groups. Overall, the evaluation of the proposed approaches shows 1 significant results as an indicator of the benefits of the implementation of a virtual classroom for vocational students in Indonesia. \u00a9 2019, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Predicting staple food materials price using multivariables factors (regression and fourier models with ARIMA)"
        ],
        "penulis":"Asnhari, Said Fadlan;Gunawan P.H.;Rusmawati, Yanti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Staple food material prices can be a trending topic in the market. The fluctuation of the price is influenced by many factors. For instance, the weather, oil price, and etc are the external factors of the staple food price. Indeed, the prediction of staple food fluctuation price is important for the farmers, consumers, even government. In this paper, the Linear Regression and Fourier model with ARIMA (Autoregressive Integrated Moving Average) will be used to predict the staple food price which consider the external influences. Here, the results using those two methods are shown in a good agreement with the observation price at market. However, the highest accuracy in predicting price using Fourier regression with ARIMA is obtained for staple food onion which is 96.57%. Meanwhile, using multiple linear regression with ARIMA, the highest accuracy is obtained for staple food red chili with 99.84%. Overall, in this research, Fourier regression with ARIMA is observed better than multiple linear regression with ARIMA method, since the accuracy of Fourier regression with ARIMA is quite stable without disturbance of fluctuation existing data. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Staple food material prices can be a trending topic in the market. The fluctuation of the price is influenced by many factors. For instance, the weather, oil price, and etc are the external factors of the staple food price. Indeed, the prediction of staple food fluctuation price is important for the farmers, consumers, even government. In this paper, the Linear Regression and Fourier model with ARIMA (Autoregressive Integrated Moving Average) will be used to predict the staple food price which consider the external influences. Here, the results using those two methods are shown in a good agreement with the observation price at market. However, the highest accuracy in predicting price using Fourier regression with ARIMA is obtained for staple food onion which is 96.57%. Meanwhile, using multiple linear regression with ARIMA, the highest accuracy is obtained for staple food red chili with 99.84%. Overall, in this research, Fourier regression with ARIMA is observed better than multiple linear regression with ARIMA method, since the accuracy of Fourier regression with ARIMA is quite stable without disturbance of fluctuation existing data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2019,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "The effects of the quality of service and social media on the interests of Argo Parahyangan train passengers on Bandung-Jakarta"
        ],
        "penulis":"Hidayah, Riski Taufik;Yolinda, Syindria;Nugraha, Deden Novan Setiawan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Argo Parahyangan Railway Transports Passengers is currently one of the best choices in traveling the Bandung-Jakarta and Jakarta-Bandung route. The purpose of this study was to find out how much influence the quality of services provided to passengers in traveling, and promotional activities through social media are used to interest passengers to use the Argo Parahyangan Railway. This research involved descriptive verification with a total sample of 100 Bandung people who conduct activities in Jakarta. Results of the study indicated that 44.89% of Purchase interest is contributed by the quality of service and 51.84% is contributed by promotional activities through Social media. \u00a9 2019 Primrose Hall Publishing Group.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Argo Parahyangan Railway Transports Passengers is currently one of the best choices in traveling the Bandung-Jakarta and Jakarta-Bandung route. The purpose of this study was to find out how much influence the quality of services provided to passengers in traveling, and promotional activities through social media are used to interest passengers to use the Argo Parahyangan Railway. This research involved descriptive verification with a total sample of 100 Bandung people who conduct activities in Jakarta. Results of the study indicated that 44.89% of Purchase interest is contributed by the quality of service and 51.84% is contributed by promotional activities through Social media. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Water flow control system based on context aware algorithm and IoT for hydroponic"
        ],
        "penulis":"Gandhi, Otrinanda;Ramdhani, Mohamad;Murti, Muhammad Ary;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Farming with using a hydroponic technique became a solution for future farming technique. Hydroponic uses water to provide nutrient and oxygen for the plant. Water must be distributed equally in all part of hydroponic pipes, so that every plants get same amount of nutrient. In order to control the water flow to be distributed equally, this research used servo valve controlled by microcontroller based on Internet of Things (IoT). Lastly, this research also observe the plant grows in the hydroponic that using this system. The result shows that the system can make the plant growth, like plant length and leave width will be more equal between growing tube. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Smart Cane: Public Transportation Code Detection and Identification System for Visually Impaired"
        ],
        "penulis":"Suhandi, Kevin Manuel;Hapsari, Gita Indah;Mutiara, Giva Andriana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The visually impaired people are still having difficulties to be able to take advantage of public transportation in their daily activities. The lack of the facilities that provide convenience and comfort to use public transportation, makes a limitation of the movement of the visually impaired people. This research built an extend system for the blind cane which can determine the existence of the public transportation near the visually impaired. This system is constructed using [Arduino Uno, numeric button, buzzers, white cane and the Radio Frequency APC 220. This system consists of smart cane module and public transportation module. The testing was conducted to determine the RF module range between the smart cane and the detection Public Transportation vehicle with various scenarios. The result stated that public transportation can provide information on arrivals to the visually impaired people with a range of distances of 80-100 meters, depending on the air regulation. The system runs about 31-32 seconds to detect and identify the public transportation. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The visually impaired people are still having difficulties to be able to take advantage of public transportation in their daily activities. The lack of the facilities that provide convenience and comfort to use public transportation, makes a limitation of the movement of the visually impaired people. This research built an extend system for the blind cane which can determine the existence of the public transportation near the visually impaired. This system is constructed using [Arduino Uno, numeric button, buzzers, white cane and the Radio Frequency APC 220. This system consists of smart cane module and public transportation module. The testing was conducted to determine the RF module range between the smart cane and the detection Public Transportation vehicle with various scenarios. The result stated that public transportation can provide information on arrivals to the visually impaired people with a range of distances of 80-100 meters, depending on the air regulation. The system runs about 31-32 seconds to detect and identify the public transportation. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "An elliptical slot loaded planar monopole antenna with tapered feed line and spline cut ground plane for super-wideband applications"
        ],
        "penulis":"Prasetyo, Agus D.;Syihabuddin, Budi;Hanuranto, Ahmad T.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, a super-wideband (SWB) planar antenna that is using the elliptical shape as a patch is presented. The elliptical patch is loaded with an elliptical slot and fed by 50 tapered feed line. A spline cut ground plane is also implemented to get the SWB response. The proposed antenna has been studied and optimized at 1-50 GHz with return loss \u2264-10 dB. The optimized size of the antenna is 44.45 mm \u00d7 46.69 mm \u00d7 1.57 mm, and it can maintain the specified return loss starting from 1.576 GHz to above 50 GHz. The gains are simulated in 5 frequencies, i.e., 5 GHz, 16.25 GHz, 27.5 GHz, 38.75 GHz, and 50 GHz. In sequence, the gain of the antenna is 2.37 dBi, 4.72 dBi, 5.89 dBi, 7.68 dBi, and 7.94 dBi. Then, the observation of the bandwidth is extended up to 140 GHz. As the results, this antenna still works on the specified return loss, and it has a bandwidth ratio higher than 88.8:1, a bandwidth percentage greater than 195.6%, and the BDR index greater than 3566. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, a super-wideband (SWB) planar antenna that is using the elliptical shape as a patch is presented. The elliptical patch is loaded with an elliptical slot and fed by 50 tapered feed line. A spline cut ground plane is also implemented to get the SWB response. The proposed antenna has been studied and optimized at 1-50 GHz with return loss \u2264-10 dB. The optimized size of the antenna is 44.45 mm \u00d7 46.69 mm \u00d7 1.57 mm, and it can maintain the specified return loss starting from 1.576 GHz to above 50 GHz. The gains are simulated in 5 frequencies, i.e., 5 GHz, 16.25 GHz, 27.5 GHz, 38.75 GHz, and 50 GHz. In sequence, the gain of the antenna is 2.37 dBi, 4.72 dBi, 5.89 dBi, 7.68 dBi, and 7.94 dBi. Then, the observation of the bandwidth is extended up to 140 GHz. As the results, this antenna still works on the specified return loss, and it has a bandwidth ratio higher than 88.8:1, a bandwidth percentage greater than 195.6%, and the BDR index greater than 3566. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Designing a Data Logger Monitoring System Prototype on Automatic PlantSprinklers"
        ],
        "penulis":"Derisa, Muhamad;Mulyana, Edi;Sumaryo, Sony;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One of plant treatment methods is watering it regularry. There are lot of automatic watering device that sold. But sometimes, that device is not working at top performace caused by error and not monitored. For ease of monitoring to automatic watering system, a data logger built with four input sensors. Sensor that used are humidity sensor, soil moisture sensor, rain drop sensor, and voltage sensor. For ease of access to this data logger, it connected to internet. Source of data is come from environtment and device performance data can be accessed via Ubidots Web as cloud. Monitoring system data logger device divide into two main components, which are data logger components and automatic watering plant components. Data logger component is used for collecting data automatically, and automatic watering plant component as monitoring object. Automatic watering plant device work at value of 850. This value is taken by average test of varity soil humidity level. After all device working completely then it combined into a system. Output of this system can be identified as 3 condition, which are normal ON, normal OFF, and normal OFF in rain condition. Any other condition will identified as a problem. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of plant treatment methods is watering it regularry. There are lot of automatic watering device that sold. But sometimes, that device is not working at top performace caused by error and not monitored. For ease of monitoring to automatic watering system, a data logger built with four input sensors. Sensor that used are humidity sensor, soil moisture sensor, rain drop sensor, and voltage sensor. For ease of access to this data logger, it connected to internet. Source of data is come from environtment and device performance data can be accessed via Ubidots Web as cloud. Monitoring system data logger device divide into two main components, which are data logger components and automatic watering plant components. Data logger component is used for collecting data automatically, and automatic watering plant component as monitoring object. Automatic watering plant device work at value of 850. This value is taken by average test of varity soil humidity level. After all device working completely then it combined into a system. Output of this system can be identified as 3 condition, which are normal ON, normal OFF, and normal OFF in rain condition. Any other condition will identified as a problem. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Influence of annealing temperature on the morphology and crystal structure of Ga-doped ZnO thin films"
        ],
        "penulis":"Sulhadi;Usriyah F.;Wibowo E.;Astuti B.;Sugianto;Aryanto D.;Marwoto P.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Ga-doped ZnO (ZnO:Ga) thin films have been deposited on Corning glass substrates by handmade dc magnetron sputtering. The pressure and deposition time respectively were set on 500 mTorr and 60 minutes. The deposition temperature was fixed at 300\u00b0C with 30 watts of plasma power. The deposited ZnO:Ga thin films were heated at 300\u00b0C, 350\u00b0C, and 400\u00b0C, respectively. The morphology and crystallinity of ZnO:Ga thin films have been observed with SEM and XRD. The observation with SEM shows that the film morphology is denser and the grain size is smaller when the temperature is increased. The crystallinity of the film increases as the annealing temperature is enhanced from 300\u00b0C to 350\u00b0C. However, the crystallinity of the ZnO:Ga films decreased when the annealing temperature is 400\u00b0C. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ga-doped ZnO (ZnO:Ga) thin films have been deposited on Corning glass substrates by handmade dc magnetron sputtering. The pressure and deposition time respectively were set on 500 mTorr and 60 minutes. The deposition temperature was fixed at 300\u00b0C with 30 watts of plasma power. The deposited ZnO:Ga thin films were heated at 300\u00b0C, 350\u00b0C, and 400\u00b0C, respectively. The morphology and crystallinity of ZnO:Ga thin films have been observed with SEM and XRD. The observation with SEM shows that the film morphology is denser and the grain size is smaller when the temperature is increased. The crystallinity of the film increases as the annealing temperature is enhanced from 300\u00b0C to 350\u00b0C. However, the crystallinity of the ZnO:Ga films decreased when the annealing temperature is 400\u00b0C. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparison of feature selection techniques in classifying stroke documents"
        ],
        "penulis":"Rafei, Nur Syaza Izzati Mohd;Hassan, Rohayanti;Saedudin, R. D. Rohmat;Raffei, Anis Farihan Mat;Zakaria, Zalmiyah;Kasim, Shahreen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The amount of digital biomedical literature grows that make most of the researchers facing the difficulties to manage and retrieve the required information from the Internet because this task is very challenging. The application of text classification on biomedical literature is one of the solutions in order to solve problem that have been faced by researchers but managing the high dimensionality of data being a common issue on text classification. Therefore, the aim of this research is to compare the techniques that could be used to select the relevant features for classifying biomedical text abstracts. This research focus on Pearson\u201fs Correlation and Information Gain as feature selection techniques for reducing the high dimensionality of data. Towards this effort, we conduct and evaluate several experiments using 100 abstract of stroke documents that retrieved from PubMed database as datasets. This dataset underwent the text pre-processing that is crucial before proceed to feature selection phase. Features selection phase is involving Information Gain and Pearson Correlation technique. Support Vector Machine classifier is used in order to evaluate and compare the effectiveness of two feature selection techniques. For this dataset, Information Gain has outperformed Pearson\u201fs Correlation by 3.3%. This research tends to extract the meaningful features from a subset of stroke documents that can be used for various application especially in diagnose the stroke disease. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The amount of digital biomedical literature grows that make most of the researchers facing the difficulties to manage and retrieve the required information from the Internet because this task is very challenging. The application of text classification on biomedical literature is one of the solutions in order to solve problem that have been faced by researchers but managing the high dimensionality of data being a common issue on text classification. Therefore, the aim of this research is to compare the techniques that could be used to select the relevant features for classifying biomedical text abstracts. This research focus on Pearson\u201fs Correlation and Information Gain as feature selection techniques for reducing the high dimensionality of data. Towards this effort, we conduct and evaluate several experiments using 100 abstract of stroke documents that retrieved from PubMed database as datasets. This dataset underwent the text pre-processing that is crucial before proceed to feature selection phase. Features selection phase is involving Information Gain and Pearson Correlation technique. Support Vector Machine classifier is used in order to evaluate and compare the effectiveness of two feature selection techniques. For this dataset, Information Gain has outperformed Pearson\u201fs Correlation by 3.3%. This research tends to extract the meaningful features from a subset of stroke documents that can be used for various application especially in diagnose the stroke disease. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Object distance measurement system using monocular camera on vehicle"
        ],
        "penulis":"Dirgantara, Fussy Mentari;Rohman, Arief Syaichu;Yulianti, Lenni;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "To support autonomous vehicles that are currently often studied by various parties, the authors propose to make a system of predicting the distance of objects using monocular cameras on vehicles. Distance prediction uses four methods and the input parameter was obtained from images processed with MobileNets SSD. Calculations using linear regression are the simplest calculations among the four methods but have an error of 1% with a standard deviation of 1.65 meters. While using the first method, the average error value is 9% with a standard deviation of 0.43 meters. By using the second calculation, the average error resulted in 6% with a standard deviation of 0.35 meters. The experimental method had an average error of 1% with a standard deviation of 0.26 meters, so the experimental method was used. \u00a9 2019, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "To support autonomous vehicles that are currently often studied by various parties, the authors propose to make a system of predicting the distance of objects using monocular cameras on vehicles. Distance prediction uses four methods and the input parameter was obtained from images processed with MobileNets SSD. Calculations using linear regression are the simplest calculations among the four methods but have an error of 1% with a standard deviation of 1.65 meters. While using the first method, the average error value is 9% with a standard deviation of 0.43 meters. By using the second calculation, the average error resulted in 6% with a standard deviation of 0.35 meters. The experimental method had an average error of 1% with a standard deviation of 0.26 meters, so the experimental method was used. \u00a9 2019, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Design of Foreign Currency Recognition Application using Scale Invariant Feature Transform (SIFT) Method based on Android (Case Study: Singapore Dollar)"
        ],
        "penulis":"Adhiguna, Mohammad Rizky;Irawan, Budhi;Prasasti, Anggunmeka Luhur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Money is the most commonly used means of payment by the public. But without denying fake money is widely circulated and there are still many people who are less accurate in recognizing the authenticity of the money. This will be bad for social life as we known that money is main payment that can use by everyone. For people with disabilities that lack of visual itself will be hard to know the identity from the money. With this problem in this research will be designed and implemented an Android based mobile application that can recognize currency with image. Applications designed using the Scale Invariant Feature Transform (SIFT) method that can provide information to users about their nominal and authenticity of the money using Indonesian. This application can help people who are less aware of information about genuine money and people with disabilities to find informations about authenticity of Foreign currency. With this application people with disabilities, also can tell the identity of the money itself with more accurate considering this app has implemented by SIFT method on feature extrachon but the process time will be longer because the SIFT method itself has a fairly complicated calculation process. From these complex calculations will also produce better accuracy. \u00a9 Medwell Journals, 2019",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Money is the most commonly used means of payment by the public. But without denying fake money is widely circulated and there are still many people who are less accurate in recognizing the authenticity of the money. This will be bad for social life as we known that money is main payment that can use by everyone. For people with disabilities that lack of visual itself will be hard to know the identity from the money. With this problem in this research will be designed and implemented an Android based mobile application that can recognize currency with image. Applications designed using the Scale Invariant Feature Transform (SIFT) method that can provide information to users about their nominal and authenticity of the money using Indonesian. This application can help people who are less aware of information about genuine money and people with disabilities to find informations about authenticity of Foreign currency. With this application people with disabilities, also can tell the identity of the money itself with more accurate considering this app has implemented by SIFT method on feature extrachon but the process time will be longer because the SIFT method itself has a fairly complicated calculation process. From these complex calculations will also produce better accuracy. \u00a9 Medwell Journals, 2019"
        ]
    },
    {
        "judul":[
            "Metamaterial Antenna on Electro-Optic Modulator for Wireless Terra-Hertz Detection Through Radio-Over-Fibre Technology"
        ],
        "penulis":"Wijayanto, Yusuf Nur;Fathnan, Ashif Aminulloh;Kanno, Atsushi;Mahmudin, Dadin;Daud, Pamungkas;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We propose a new metamaterial antenna on electro-optic (EO) modulator for wireless terra-hertz detection through radio-over-fibre (ROF) technology. By wireless terra-hertz signal irradiation to the proposed device, strong terra-hertz electric field can be induced on the electric- LC metamaterial resonator. The induced terra-hertz electric field can be used for optical modulation through EO effects when a light-wave propagates into an optical waveguide located under the capacitive gap which the strongest induced terra-hertz electric field. Analysis of optical modulation is presented in details for operational frequency of 0.1 THz. The device fabrication process and the results of its measured characteristics are also reported. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We propose a new metamaterial antenna on electro-optic (EO) modulator for wireless terra-hertz detection through radio-over-fibre (ROF) technology. By wireless terra-hertz signal irradiation to the proposed device, strong terra-hertz electric field can be induced on the electric- LC metamaterial resonator. The induced terra-hertz electric field can be used for optical modulation through EO effects when a light-wave propagates into an optical waveguide located under the capacitive gap which the strongest induced terra-hertz electric field. Analysis of optical modulation is presented in details for operational frequency of 0.1 THz. The device fabrication process and the results of its measured characteristics are also reported. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Numerical Analysis of Discrete Lp-norm Error for Rayleigh-Ritz Variational Technique and Its Application to Groundwater Flows Model"
        ],
        "penulis":"Gunawan P.H.;Aditsania A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The investigation of computational finite element method based on variational technique for approximating groundwater flow model is elaborated in this paper. Here, the Rayleigh-Ritz scheme will be used in order to obtain the numerical solution for steady state form of groundwater flow model. The groundwater model is given in one-dimensional parabolic type partial differential equation (PDE). To obtain steady state form, the finite difference approach is used for discretizing time differential equation in PDE form. Two numerical tests are elaborated to see the robustness of the numerical scheme to approximate the continuous model. The convergence rates of discrete Lp-norm error with p = 1, p = 2 and  p = \u221e are shown satisfying for two numerical tests. The result of Rayleigh-Ritz scheme is obtained in second order approximation. Moreover, the comparison of current result and result from another literature for groundwater flow simulation is shown in a good agreement. \u00a9 2019, Springer Nature Switzerland AG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The investigation of computational finite element method based on variational technique for approximating groundwater flow model is elaborated in this paper. Here, the Rayleigh-Ritz scheme will be used in order to obtain the numerical solution for steady state form of groundwater flow model. The groundwater model is given in one-dimensional parabolic type partial differential equation (PDE). To obtain steady state form, the finite difference approach is used for discretizing time differential equation in PDE form. Two numerical tests are elaborated to see the robustness of the numerical scheme to approximate the continuous model. The convergence rates of discrete Lp-norm error with p = 1, p = 2 and  p = \u221e are shown satisfying for two numerical tests. The result of Rayleigh-Ritz scheme is obtained in second order approximation. Moreover, the comparison of current result and result from another literature for groundwater flow simulation is shown in a good agreement. \u00a9 2019, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Lean manufacturing performance and organizational culture: An exploratory study"
        ],
        "penulis":"Salma, Sheila Amalia;Gafigi, Mohammad Andi;Rahma, Karyma Talitha;Widyanti, Ari;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Lean manufacturing is an approach to enhancing productivity through lean thinking. The success of the lean manufacturing application is influenced by various factors, one of them is the organizational culture. This study aims to explore lean manufacturing and organizational culture in an Indonesian aircraft manufacturer. Ninety workers in three production divisions (i.e., Detailed Part Manufacturing\/DPM, Component Assembly\/CA, Final Assyline & Delivery Center\/FAL & DC) in the aircraft manufacture are involved in this study voluntarily by filling out a set of questionnaire. Lean manufacturing performance is observed using Lean Manufacturing Benchmark, whereas organizational culture is evaluated using the Organizational Culture Assessment Instrument. The result shows that lean performance for DPM is 57%, CA is 61%, FAL & DC is 59%. All divisions have no dominant culture. However, the increased of lean performance is along with the increased hierarchy and clan culture, and the decreased of market and adhocracy culture. Implications of the results are discussed. \u00a9 2019 Author(s).",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Lean manufacturing is an approach to enhancing productivity through lean thinking. The success of the lean manufacturing application is influenced by various factors, one of them is the organizational culture. This study aims to explore lean manufacturing and organizational culture in an Indonesian aircraft manufacturer. Ninety workers in three production divisions (i.e., Detailed Part Manufacturing\/DPM, Component Assembly\/CA, Final Assyline & Delivery Center\/FAL & DC) in the aircraft manufacture are involved in this study voluntarily by filling out a set of questionnaire. Lean manufacturing performance is observed using Lean Manufacturing Benchmark, whereas organizational culture is evaluated using the Organizational Culture Assessment Instrument. The result shows that lean performance for DPM is 57%, CA is 61%, FAL & DC is 59%. All divisions have no dominant culture. However, the increased of lean performance is along with the increased hierarchy and clan culture, and the decreased of market and adhocracy culture. Implications of the results are discussed. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Coverage and capacity analysis of LoRa WAN deployment for massive IoT in urban and suburban scenario"
        ],
        "penulis":"Nashiruddin, Muhammad Imam;Hidayati, Amriane;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Choosing connectivity technologies for the Internet of Things (IoT) is the most important aspect in the early stages of network planning. Long Range (LoRa) Wide Area Network (WAN) that categorized into Low Power Wide Area (LPWA) network is a potential connectivity technology for typical massive IoT applications like a smart meter, smart manufacturing, environmental monitoring, etc. This paper aims to provide coverage and capacity analysis of LoRa WAN for typical massive IoT application. The urban and suburban areas were chosen to observe the differences between those two scenarios. The results shown the capacity calculation in terms of the gateways needed is mainly influenced by the value of the bandwidth (BW), spreading factor (SF) and Coding Rate (CR). Coverage simulation is done by calculating the link budget, followed by a simulation using Forsk Atoll 3.3.2. It can be concluded that the whole determined areas can be served within acceptable levels with values > -137 dBm as the minimum sensitivity of the highest SF. While the mean of best signal level is -84.58 dBm and -90.9 dBm for the urban and suburban scenario, respectively.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Choosing connectivity technologies for the Internet of Things (IoT) is the most important aspect in the early stages of network planning. Long Range (LoRa) Wide Area Network (WAN) that categorized into Low Power Wide Area (LPWA) network is a potential connectivity technology for typical massive IoT applications like a smart meter, smart manufacturing, environmental monitoring, etc. This paper aims to provide coverage and capacity analysis of LoRa WAN for typical massive IoT application. The urban and suburban areas were chosen to observe the differences between those two scenarios. The results shown the capacity calculation in terms of the gateways needed is mainly influenced by the value of the bandwidth (BW), spreading factor (SF) and Coding Rate (CR). Coverage simulation is done by calculating the link budget, followed by a simulation using Forsk Atoll 3.3.2. It can be concluded that the whole determined areas can be served within acceptable levels with values > -137 dBm as the minimum sensitivity of the highest SF. While the mean of best signal level is -84.58 dBm and -90.9 dBm for the urban and suburban scenario, respectively.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Air quality monitoring system based internet of things (IoT) using LPWAN LoRa"
        ],
        "penulis":"Firdaus, Rizky;Murti, Muhammad Ary;Alinursafa, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Air has an important function and role in the lives of humans and other living beings. Every living things needs clean air to support its life optimally, its quality needs to be maintained. A good and healthy level of air quality is one of the main factors in creating a healthy and comfortable environment if the air quality is bad then there will be pollution that will interfere with the health of every population that inhaled. In this research, the author utilizes the Internet of Things (IoT) technology to monitor the condition of air quality levels such as temperature, air humidity, CO and CO2. The system uses ATmega328P-AU as a controller, DHT22 sensor for temperature and air humidity, MQ-7 sensor for CO gas, MQ-135 sensor for CO2 gas, LPWAN LoRa for data transmission communication and Antares as a cloud service for storing data to be displayed on Android. The test results obtained the average error value for temperatures \u00b1 0.8 \u00b0C, humidity \u00b1 3.1 % RH, CO \u00b1 10 ppm and CO2 \u00b1 16 ppm. The results of sensor data are stored in the Antares cloud and displayed on Android. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Air has an important function and role in the lives of humans and other living beings. Every living things needs clean air to support its life optimally, its quality needs to be maintained. A good and healthy level of air quality is one of the main factors in creating a healthy and comfortable environment if the air quality is bad then there will be pollution that will interfere with the health of every population that inhaled. In this research, the author utilizes the Internet of Things (IoT) technology to monitor the condition of air quality levels such as temperature, air humidity, CO and CO2. The system uses ATmega328P-AU as a controller, DHT22 sensor for temperature and air humidity, MQ-7 sensor for CO gas, MQ-135 sensor for CO2 gas, LPWAN LoRa for data transmission communication and Antares as a cloud service for storing data to be displayed on Android. The test results obtained the average error value for temperatures \u00b1 0.8 \u00b0C, humidity \u00b1 3.1 % RH, CO \u00b1 10 ppm and CO2 \u00b1 16 ppm. The results of sensor data are stored in the Antares cloud and displayed on Android. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Speed and steering control system for self-driving car prototype"
        ],
        "penulis":"Rafsanjani;Wibawa I.P.D.;Ekaputri C.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A self-driving car is a vehicle that can run autonomously using a control. There are two systems that are controlled in this research. The first-speed control functions to regulate the speed and movement of the self-driving car prototype by adjusting the PWM value on the DC motor and second, the steering control uses the Ackerman steering system with a servo motor as an actuator. Both are arranged using fuzzy logic control methods that adapt from the habits in driving a car. the goal self-driving car prototype can walk to follow the track, maintain the robot car in the middle of the lane, can adjust the speed when turning and can stop when there are obstacles or traffic lights. The results of the control design testing in this study are, the average error value in the simulation is 0.771008 for the servo angle and 0.392072 for the speed. The error value in the programming algorithm is 0.149712 for servo angles and 0.198168 for PWM DC motors. Robot cars in accordance with the logic of the fuzzy rules made. Self-driving car prototypes can run turns and follow trajectories with a success rate of 93.33%. The distance between the robot car and the track is 1.83 cm inside the track and 0.03 cm outside the track. The self-driving car prototype can adjust its speed and can stop when there are obstacles with an average distance of 29.89 cm. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A self-driving car is a vehicle that can run autonomously using a control. There are two systems that are controlled in this research. The first-speed control functions to regulate the speed and movement of the self-driving car prototype by adjusting the PWM value on the DC motor and second, the steering control uses the Ackerman steering system with a servo motor as an actuator. Both are arranged using fuzzy logic control methods that adapt from the habits in driving a car. the goal self-driving car prototype can walk to follow the track, maintain the robot car in the middle of the lane, can adjust the speed when turning and can stop when there are obstacles or traffic lights. The results of the control design testing in this study are, the average error value in the simulation is 0.771008 for the servo angle and 0.392072 for the speed. The error value in the programming algorithm is 0.149712 for servo angles and 0.198168 for PWM DC motors. Robot cars in accordance with the logic of the fuzzy rules made. Self-driving car prototypes can run turns and follow trajectories with a success rate of 93.33%. The distance between the robot car and the track is 1.83 cm inside the track and 0.03 cm outside the track. The self-driving car prototype can adjust its speed and can stop when there are obstacles with an average distance of 29.89 cm. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Face spoofing detection using color distortion features and principal component analysis"
        ],
        "penulis":"Simanjuntak, Graham Desmon;Ramadhani, Kurniawan Nur;Arifianto, Anditya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Face anti-spoofing is an important topic of face recognition system to protect against security breach. Previous approach for face spoofing detection based on distortion in images have achieved promising results. However, their generalization ability has not been sufficiently addressed. In this work, we propose a face spoofing detection based on color distortion analysis, which captures the chromatic aberration from a face image. Color distortion analysis extracts color moment and ranked histogram features, which generate 116 feature vector. The feature vector then forwarded to Principal Component Analysis (PCA) to perform dimensionality reduction. For classifying a live or spoof face image, a Na\u00efve Bayes classifier performed on the principal components obtained from PCA. From experiment, the proposed method achieves competitive performance compared to previous approach, with the highest TPR (True Positive Rate) is 97.4%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Face anti-spoofing is an important topic of face recognition system to protect against security breach. Previous approach for face spoofing detection based on distortion in images have achieved promising results. However, their generalization ability has not been sufficiently addressed. In this work, we propose a face spoofing detection based on color distortion analysis, which captures the chromatic aberration from a face image. Color distortion analysis extracts color moment and ranked histogram features, which generate 116 feature vector. The feature vector then forwarded to Principal Component Analysis (PCA) to perform dimensionality reduction. For classifying a live or spoof face image, a Na\u00efve Bayes classifier performed on the principal components obtained from PCA. From experiment, the proposed method achieves competitive performance compared to previous approach, with the highest TPR (True Positive Rate) is 97.4%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design of human behavior automatic lamp switch with blynk platform"
        ],
        "penulis":"Pasau, Adiatma Manglolo;Nasrun, Muhammad;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The use of Internet of Things (IoT) technology provides comfort and convenience for technology users. In this research, an automatic light switch device used the Light Dependent Resistor sensor as an automation for light intensity and AI server assistance for human habits. In this tool there are two rules that govern the automation of the Decision Rule and Priority Rule. From the testing of this tool, the two rules have shown an accuracy of 100%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of Internet of Things (IoT) technology provides comfort and convenience for technology users. In this research, an automatic light switch device used the Light Dependent Resistor sensor as an automation for light intensity and AI server assistance for human habits. In this tool there are two rules that govern the automation of the Decision Rule and Priority Rule. From the testing of this tool, the two rules have shown an accuracy of 100%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Evaluation study of unsupervised face-to-face translation using generative adversarial networks"
        ],
        "penulis":"Iqbal, Muhamad;Widyanto, M. Rahmat;Adnan, Risman;Basaruddin T.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cross-domain image-to-image translation provides mechanism to capture special characteristics of one image collection and convert into other image collection with different representations. Recent research on generative learning have produced powerful image-toimage translation methods in supervised setting, where paired training datasets are available. However, collecting paired training data is difficult, expensive and required manual authoring. We present an evaluation study of recent unsupervised Generative Adversarial Network (GAN) models that can learn to translate a facial image from a source domain X to a target domain Y without paired labeled training dataset. Each GAN model is trained on the same facial image dataset and comparable hyperparameters. We report a comparison result using same GAN model evaluation metrics. \u00a9 2019 Association for Computing Machinery.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cross-domain image-to-image translation provides mechanism to capture special characteristics of one image collection and convert into other image collection with different representations. Recent research on generative learning have produced powerful image-toimage translation methods in supervised setting, where paired training datasets are available. However, collecting paired training data is difficult, expensive and required manual authoring. We present an evaluation study of recent unsupervised Generative Adversarial Network (GAN) models that can learn to translate a facial image from a source domain X to a target domain Y without paired labeled training dataset. Each GAN model is trained on the same facial image dataset and comparable hyperparameters. We report a comparison result using same GAN model evaluation metrics. \u00a9 2019 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Design Autonomous Drone Control for Monitoring Tea Plantation Using Dynamic Programming and Kruskal Algorithm"
        ],
        "penulis":"Wirabudi, Andri Agustav;Munadi, Rendy;Rusdinar, Angga;Rohdiana, Dadan;Lee, Dong Ho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia is a country with the largest tea producers in the world, with a very large area needed tools to be able to help monitor the area of tea plantations as a whole. Unmanned Aerial Vehicle (UAV) wash chosen as a solution for the monitoring proses. Optimum flight path calculation is needed in order to produce good quality images, and also it influence to power consumption. The algorithm proposed in this study is Dynamic Programming and Kruskal Algorithm. Implementing these two network algorithms is expected to find the optimal path in aerial photography. The experimental results showed that the algorithm produced the optimum path, and more efficient power consumption than conventional lines. Image data obtained during tea plantation monitoring produced high-quality images, with the accuracy of each map above 90% and the assumption of errors below 5%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is a country with the largest tea producers in the world, with a very large area needed tools to be able to help monitor the area of tea plantations as a whole. Unmanned Aerial Vehicle (UAV) wash chosen as a solution for the monitoring proses. Optimum flight path calculation is needed in order to produce good quality images, and also it influence to power consumption. The algorithm proposed in this study is Dynamic Programming and Kruskal Algorithm. Implementing these two network algorithms is expected to find the optimal path in aerial photography. The experimental results showed that the algorithm produced the optimum path, and more efficient power consumption than conventional lines. Image data obtained during tea plantation monitoring produced high-quality images, with the accuracy of each map above 90% and the assumption of errors below 5%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Threshold based algorithms for the multi-product multi-period inventory routing problem"
        ],
        "penulis":"Ramadhan, Fadillah;Imran, Arif;Rizana, Afrin F.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Inventory management and transportation are important factors to enhance the organization competitive advantage in the area of supply chain management. The integration of these aspects is known as the Inventory Routing Problem (IRP). In this paper, we address the multi-product, multi-period IRP. Here, a depot houses homogenous vehicles that deliver multi-period of times to an assembly plant, from multi-supplier. The aim is to find the least total inventory and transportation cost. We develop Threshold Acceptance (TA) and Record to Record Travel (RTR) based algorithm to solve the IRP. The initial solution for both algorithms is obtained by using an adaptation of the least cost insertion procedure called the least cost insertion with vehicle capacity maximization (LCI-VCM). A number of local searches and LCI-VCM are applied when conducting downhill moves to search the lowest total cost. The proposed algorithms are then tested to solve the dataset from the literature and competitive results are obtained. \u00a9 2019 School of Engineering, Taylor's University.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Inventory management and transportation are important factors to enhance the organization competitive advantage in the area of supply chain management. The integration of these aspects is known as the Inventory Routing Problem (IRP). In this paper, we address the multi-product, multi-period IRP. Here, a depot houses homogenous vehicles that deliver multi-period of times to an assembly plant, from multi-supplier. The aim is to find the least total inventory and transportation cost. We develop Threshold Acceptance (TA) and Record to Record Travel (RTR) based algorithm to solve the IRP. The initial solution for both algorithms is obtained by using an adaptation of the least cost insertion procedure called the least cost insertion with vehicle capacity maximization (LCI-VCM). A number of local searches and LCI-VCM are applied when conducting downhill moves to search the lowest total cost. The proposed algorithms are then tested to solve the dataset from the literature and competitive results are obtained. \u00a9 2019 School of Engineering, Taylor's University."
        ]
    },
    {
        "judul":[
            "Implementation of Decision Tree C4.5 for Big Five Personality Predictions with TF-RF and TF-CHI2 on Social Media Twitter"
        ],
        "penulis":"Willy;Setiawan, Erwin B.;Nugraha, Fida N.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Every tweet can provide an information about someone's personality. The problem is how to classify an obtained information on Twitter social media into classes that will be created with good performance value. Personality classification through Twitter social media has been studied by several researchers. For instance, in Damanik Agnes and Khodra Masayu [3], Classification method using Support Vector Regression (SVR) and TF-IDF weighting method. The result shown good with Mean Absolute Error (MAE) 0.2739. In this paper, writer builds a system that classifies someone personality on Twitter social media using decision tree C4.5 classification method with TF-RF and TF-CHI2weighting method. The diffences on this paper is the weighting of each word using the weighting method TF-RF and TF-CHI2with the addition of new features for approaches based on user social behavior which will be explained in more detail in section II. From the results of the experiment on the 90% training data ratio and 10% test data (90:10) and the combination of personality features based on social behavior with a linguistic approach with TF-RF weighting obtained the accuracy results of 65.72%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Every tweet can provide an information about someone's personality. The problem is how to classify an obtained information on Twitter social media into classes that will be created with good performance value. Personality classification through Twitter social media has been studied by several researchers. For instance, in Damanik Agnes and Khodra Masayu [3], Classification method using Support Vector Regression (SVR) and TF-IDF weighting method. The result shown good with Mean Absolute Error (MAE) 0.2739. In this paper, writer builds a system that classifies someone personality on Twitter social media using decision tree C4.5 classification method with TF-RF and TF-CHI2weighting method. The diffences on this paper is the weighting of each word using the weighting method TF-RF and TF-CHI2with the addition of new features for approaches based on user social behavior which will be explained in more detail in section II. From the results of the experiment on the 90% training data ratio and 10% test data (90:10) and the combination of personality features based on social behavior with a linguistic approach with TF-RF weighting obtained the accuracy results of 65.72%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A mutual authentication scheme for secure fog computing service handover in vehicular network environment"
        ],
        "penulis":"Dewanta, Favian;Mambo, Masahiro;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Handover schemes play a vital role on fog computing service (FCS) provided through vehicular network. It not only determines the quality of services (QoSs) but also the security and safety of vehicular network system against adversaries. As a part of handover process, authentication between vehicles and a new fog node (FN) significantly contributes to protecting private information and infrastructure of vehicular network at once. In this paper, we propose a lightweight and secure mutual authentication scheme for handover process considering limited access FCS in the vehicular network environment and also service reservation scenario at login and service request phase. In the proposed scheme, mutual authentication process is assisted by a cloud server (CS) during login and service request phase in which CS distributes the credentials for on-the-road authentication between the vehicles and FN installed on road side unit (RSU). We demonstrate that our proposed scheme is lightweight due to employing one-way hash function and exclusive-or operation extensively. In addition, our scheme is efficient in terms of computational cost as well as computation cost. We show that our scheme achieves 1.1-56.67 times faster computation and also reduces the total message size by 30%-58.21% in comparison with the previous authentication schemes in the most relevant environment. The informal and formal security analyses show that this authentication scheme can protect the secrecy of transactions of all interacting entities against various known attacks. In addition, validation using SPAN software based on AVISPA also confirms that the proposed authentication scheme can satisfy mutual authentication goal and, at the same time, also protect against replay and man-in-the-middle attack. \u00a9 2020 Copyright",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Handover schemes play a vital role on fog computing service (FCS) provided through vehicular network. It not only determines the quality of services (QoSs) but also the security and safety of vehicular network system against adversaries. As a part of handover process, authentication between vehicles and a new fog node (FN) significantly contributes to protecting private information and infrastructure of vehicular network at once. In this paper, we propose a lightweight and secure mutual authentication scheme for handover process considering limited access FCS in the vehicular network environment and also service reservation scenario at login and service request phase. In the proposed scheme, mutual authentication process is assisted by a cloud server (CS) during login and service request phase in which CS distributes the credentials for on-the-road authentication between the vehicles and FN installed on road side unit (RSU). We demonstrate that our proposed scheme is lightweight due to employing one-way hash function and exclusive-or operation extensively. In addition, our scheme is efficient in terms of computational cost as well as computation cost. We show that our scheme achieves 1.1-56.67 times faster computation and also reduces the total message size by 30%-58.21% in comparison with the previous authentication schemes in the most relevant environment. The informal and formal security analyses show that this authentication scheme can protect the secrecy of transactions of all interacting entities against various known attacks. In addition, validation using SPAN software based on AVISPA also confirms that the proposed authentication scheme can satisfy mutual authentication goal and, at the same time, also protect against replay and man-in-the-middle attack. \u00a9 2020 Copyright"
        ]
    },
    {
        "judul":[
            "A survey of in-flight connectivity implementation in Indonesia"
        ],
        "penulis":"Marlasari, Rafidah;Nashiruddin, Muhammad Imam;Adriansyah, Nachwan Mufti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Inmarsat Global survey in 2016 already found that on any flight length, the majority of passengers around 54% prefer to have the option of in-flight Wi-Fi. Rest of it, over 16% choosing In-Flight Entertainment (IFE), 19% choosing meal, and 7% choosing duty-free. As time goes by, the procurement of In-Flight Connectivity (IFC) is increasingly becoming a focus for the aviation industry. So far, IFC services provide through satellite and direct Air-to-Ground (ATG) technology. High interest in onboard connectivity makes the procurement also expand from the international route flights to the domestic route flights. A large number of passengers makes Indonesia have a bright future to develop IFC. 2 Indonesian airlines already begin to provide IFC. Although not specific on IFC, Indonesia already has a precise regulation that allows foreign satellite as a provider of IFC. Involving related companies such as operator or tower provider company to build a new independent ATG network for Indonesia shows opportunity. By considering the current state, the author analyzes the opportunities and challenges of IFC development in Indonesia in terms of market, network, regulation, and related company as players. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentReduced inequalitiesGoal 10Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Inmarsat Global survey in 2016 already found that on any flight length, the majority of passengers around 54% prefer to have the option of in-flight Wi-Fi. Rest of it, over 16% choosing In-Flight Entertainment (IFE), 19% choosing meal, and 7% choosing duty-free. As time goes by, the procurement of In-Flight Connectivity (IFC) is increasingly becoming a focus for the aviation industry. So far, IFC services provide through satellite and direct Air-to-Ground (ATG) technology. High interest in onboard connectivity makes the procurement also expand from the international route flights to the domestic route flights. A large number of passengers makes Indonesia have a bright future to develop IFC. 2 Indonesian airlines already begin to provide IFC. Although not specific on IFC, Indonesia already has a precise regulation that allows foreign satellite as a provider of IFC. Involving related companies such as operator or tower provider company to build a new independent ATG network for Indonesia shows opportunity. By considering the current state, the author analyzes the opportunities and challenges of IFC development in Indonesia in terms of market, network, regulation, and related company as players. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Economic impact of artificial intelligence: New look for the macroeconomic assessment in Asia-pacific region"
        ],
        "penulis":"Haseeb, Muhammad;Sasmoko;Mihardjo, Leonardus W. W.;Gill, Abid Rashid;Jermsittiparsert, Kittisak;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Objective: To determine the impact of artificial intelligence (AI) on the selected economies in the Asia-Pacific region. Methods: This secondary research collected data from macroeconomic and AI-specific data sets. The sources of data from which insights were gained included digital technology sectors and corporations and their functions. The focus was on the need to assess the capability of AI on business operations The macroeconomic data was collected from data resources of international organizations\u2019 including the World Economic Forum, the Organization for Economic Co-operation and Development (OECD), the World Intellectual Property Organization (WIPO), and the International Telecommunication Union (ITU). In addition, this study has considered 19 economic indicators to analyze the economic outcome of AI in selected economies of Asia-Pacific. Results: From the results, the period between 2014 and 2016 witnessed China leading with over 25,000 citable documents on the AI topic. Regarding institutions that were observed to publish over 500 times on the AI topic, the countries in the ascending order include China (600), Hong Kong (1,100), and Singapore (2,000). As such, this study established that Asia-Pacific economies such as Hong Kong and Singapore though have smaller populations, but the majority of their higher education institutions have made a significant contribution to AI research; with the small economies also having a relatively higher number of computer scientists among the top 1,000 individuals. Additionally, through empirically analyses, during 1998\u20132016 with annual observations, it is found that various economic outcomes of AI were presented in 8 economies of targeted region. Limitations: At first, the future outlook of AI is just discussed in conceptual meaning while empirical context still needs to be examined in upcoming studies. At second, covering the overall South Asian region provides better findings with more generalization which is missing in current research. At third, other dimensions of AI and economy like implication of AI impact index and its relationship with macroeconomic variables is also missing in current research which could be reconsidered in coming studies. Conclusion: It is evident that AI exhibits the potential to be the main driver of Asia-Pacific\u2019s economic growth. Relative to the net and gross effect of AI on labor markets and the gross domestic product (GDP) of the top Asia-Pacific economies demonstrate that by 2030, AI might yield a 16-percent increase in output, translating into an estimated amount of $13 trillion. Overall, it is concluded that Asia-Pacific, when compared to developed regions such as North America, is lagging but the availability of a large pool of user data implies that the region can move ahead\u2014given better resource and talent allocation. \u00a9 2019 The Authors. Published by Atlantis Press SARL.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Objective: To determine the impact of artificial intelligence (AI) on the selected economies in the Asia-Pacific region. Methods: This secondary research collected data from macroeconomic and AI-specific data sets. The sources of data from which insights were gained included digital technology sectors and corporations and their functions. The focus was on the need to assess the capability of AI on business operations The macroeconomic data was collected from data resources of international organizations\u2019 including the World Economic Forum, the Organization for Economic Co-operation and Development (OECD), the World Intellectual Property Organization (WIPO), and the International Telecommunication Union (ITU). In addition, this study has considered 19 economic indicators to analyze the economic outcome of AI in selected economies of Asia-Pacific. Results: From the results, the period between 2014 and 2016 witnessed China leading with over 25,000 citable documents on the AI topic. Regarding institutions that were observed to publish over 500 times on the AI topic, the countries in the ascending order include China (600), Hong Kong (1,100), and Singapore (2,000). As such, this study established that Asia-Pacific economies such as Hong Kong and Singapore though have smaller populations, but the majority of their higher education institutions have made a significant contribution to AI research; with the small economies also having a relatively higher number of computer scientists among the top 1,000 individuals. Additionally, through empirically analyses, during 1998\u20132016 with annual observations, it is found that various economic outcomes of AI were presented in 8 economies of targeted region. Limitations: At first, the future outlook of AI is just discussed in conceptual meaning while empirical context still needs to be examined in upcoming studies. At second, covering the overall South Asian region provides better findings with more generalization which is missing in current research. At third, other dimensions of AI and economy like implication of AI impact index and its relationship with macroeconomic variables is also missing in current research which could be reconsidered in coming studies. Conclusion: It is evident that AI exhibits the potential to be the main driver of Asia-Pacific\u2019s economic growth. Relative to the net and gross effect of AI on labor markets and the gross domestic product (GDP) of the top Asia-Pacific economies demonstrate that by 2030, AI might yield a 16-percent increase in output, translating into an estimated amount of $13 trillion. Overall, it is concluded that Asia-Pacific, when compared to developed regions such as North America, is lagging but the availability of a large pool of user data implies that the region can move ahead\u2014given better resource and talent allocation. \u00a9 2019 The Authors. Published by Atlantis Press SARL."
        ]
    },
    {
        "judul":[
            "A Perspective of Home Security Using Wireless Communication"
        ],
        "penulis":"Purboyo, Tito Waluyo;Osmond, Andrew Brian;Aryani, Ressy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Home security is security system to applied at home or at one building. A function of home security is to provide comfort, some level of protection for the inhabitants of the house and can also be implemented into the system for crime prevention. The research will be conducted using wireless communication as the communication module used in security systems. The diversity of application, technology, methods, sensors that used and many more ways can increase the level of security at home. This study aims to review and compare some paper of home security likes methods, used tools, advantages and disadvantages of a security system. At the end, the final duty is to know which system is suitable for home by using the parameters to be compared. \u00a9 Medwell Journals, 2019"
        ],
        "abstrak":[
            "Home security is security system to applied at home or at one building. A function of home security is to provide comfort, some level of protection for the inhabitants of the house and can also be implemented into the system for crime prevention. The research will be conducted using wireless communication as the communication module used in security systems. The diversity of application, technology, methods, sensors that used and many more ways can increase the level of security at home. This study aims to review and compare some paper of home security likes methods, used tools, advantages and disadvantages of a security system. At the end, the final duty is to know which system is suitable for home by using the parameters to be compared. \u00a9 Medwell Journals, 2019"
        ]
    },
    {
        "judul":[
            "Automatic controlling system and IoT based monitoring for pH rate on the aquaponics system"
        ],
        "penulis":"Defa R.P.;Ramdhani M.;Priramadhi R.A.;Aprillia B.S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Aquaponics is an opportunity for cultivating plants and fish. Plants use nutrients from fish feces and the fishes use clean water after being filtered by plant roots. The results of fish metabolism, food residue, and temperature change will affect the pH rate. An automatic control system and monitoring pH rate on aquaponics system is designed to maintain the pH rate within a certain range. The method used is a literature study to find the basic theory in designing a control system and monitoring water pH levels. Afterward, it's necessary to find out the arising problems. The next step to do is designing the system, starting from flow diagrams to system design. The last step to do is simulating the tools that have been designed and then testing the system. Based on the results, it can be concluded that the system could maintain the water condition automatically in pH range from 6.3 to 7.7. The average error found in this sensor was 0.67%, the average decrease in water pH level was 0.023 per day, and the controlling interval was every 42 seconds, the success rate of sending monitoring data was 100% in which the data was sent every 1 minute in 1 hour. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Aquaponics is an opportunity for cultivating plants and fish. Plants use nutrients from fish feces and the fishes use clean water after being filtered by plant roots. The results of fish metabolism, food residue, and temperature change will affect the pH rate. An automatic control system and monitoring pH rate on aquaponics system is designed to maintain the pH rate within a certain range. The method used is a literature study to find the basic theory in designing a control system and monitoring water pH levels. Afterward, it's necessary to find out the arising problems. The next step to do is designing the system, starting from flow diagrams to system design. The last step to do is simulating the tools that have been designed and then testing the system. Based on the results, it can be concluded that the system could maintain the water condition automatically in pH range from 6.3 to 7.7. The average error found in this sensor was 0.67%, the average decrease in water pH level was 0.023 per day, and the controlling interval was every 42 seconds, the success rate of sending monitoring data was 100% in which the data was sent every 1 minute in 1 hour. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "A new method for congestion avoidance in wireless mesh networks"
        ],
        "penulis":"Pa, Son;Mandala, Satria;Adiwijaya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Wireless Mesh Networks (WMNs) will play an important role in next-generation wireless communications involving wireless networks. The traffic in this network (WMN) often saturates on certain paths, causing congestion problems to occur. Currently, many proposed protocols have been created based on Ant Colony Optimization (ACO) to contribute towards solving this particular problem. Unfortunately, most of these methods disregard the congestion problem after an optimal path is found. In this paper, a New Congestion Avoidance Method (NCAM) is proposed. NCAM is designed to improve load balancing by solving congestion problems after the optimal path is found. There are three mechanisms proposed in NCAM: detection of congestion in each optimal node to prepare a suboptimal path, updating of suboptimal pheromone value, and transferring data packets to the suboptimal path. We implemented our method in Network Simulator Version 2 and measured its effective performance compared to a family of existing ACO approaches in terms of packet throughput, end-to-end delay, and packet loss. The result demonstrates that NCAM provided better throughput, decreased end-to-end delay, and less packet loss compared to AntNet and CACO. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Wireless Mesh Networks (WMNs) will play an important role in next-generation wireless communications involving wireless networks. The traffic in this network (WMN) often saturates on certain paths, causing congestion problems to occur. Currently, many proposed protocols have been created based on Ant Colony Optimization (ACO) to contribute towards solving this particular problem. Unfortunately, most of these methods disregard the congestion problem after an optimal path is found. In this paper, a New Congestion Avoidance Method (NCAM) is proposed. NCAM is designed to improve load balancing by solving congestion problems after the optimal path is found. There are three mechanisms proposed in NCAM: detection of congestion in each optimal node to prepare a suboptimal path, updating of suboptimal pheromone value, and transferring data packets to the suboptimal path. We implemented our method in Network Simulator Version 2 and measured its effective performance compared to a family of existing ACO approaches in terms of packet throughput, end-to-end delay, and packet loss. The result demonstrates that NCAM provided better throughput, decreased end-to-end delay, and less packet loss compared to AntNet and CACO. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Incorporation of Spiral Shaped Defected Ground Structure for Improving Radiation Characteristic of Planar Array-Antenna"
        ],
        "penulis":"Yunus, Mochamad;Patriana, Zero Luthfi;Wismiana, Evyta;Firmasyah, Teguh;Syihabuddin, Budi;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper deals with the incorporation of spiral shaped defected ground structure (DGS) for improving radiation characteristic for planar array-antenna. The proposed planar array-antenna which is intended to operate at the frequency of 2.4GHz is designed on an FR4 epoxy dielectric substrate with the thickness of 1.6 mm and analyzed by use of a simulation software. It consists of 4\u00d7 4 elements where the microstrip line inset feeding method is employed to excite each antenna element. The characterization results show that the use of spiral shaped DGS yields the measured radiation characteristic to achieve the gain achievement of 10.47 dBi at the resonant frequency and the -10ddB bandwidth response of 140 MHz. These results are comparable to the simulated ones which are showing the potentiality of spiral shaped DGS incorporation for the radiation characteristics improvement. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper deals with the incorporation of spiral shaped defected ground structure (DGS) for improving radiation characteristic for planar array-antenna. The proposed planar array-antenna which is intended to operate at the frequency of 2.4GHz is designed on an FR4 epoxy dielectric substrate with the thickness of 1.6 mm and analyzed by use of a simulation software. It consists of 4\u00d7 4 elements where the microstrip line inset feeding method is employed to excite each antenna element. The characterization results show that the use of spiral shaped DGS yields the measured radiation characteristic to achieve the gain achievement of 10.47 dBi at the resonant frequency and the -10ddB bandwidth response of 140 MHz. These results are comparable to the simulated ones which are showing the potentiality of spiral shaped DGS incorporation for the radiation characteristics improvement. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Lamp Control System by Reccurent Neural Network and Long-Short Term Memory"
        ],
        "penulis":"Sasia, Priscilya Inri;Murti, Muhammad Ary;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Smart lamp is a technology that offers convenience for users in controlling the lamp. Previously, there had been research developing this system, but the controls offered were still based on Android that can't support a multiple platform. This system uses the Recurrent Neural Network (RNN) and Long-Short Term Memory (LSTM) algorithms. Besides that, this system also does a trial by using Internet of Things System for controlling and monitoring the lamps.From this research, the results of testing show that the average time required for the system to turn on and turn off Lamp I are 3.3 seconds and 3.28 seconds respectively with a minimum sound intensity of 60.6 dB. To turn on and turn off Lamp II in succession is 3.43 second and 3.61 second with a minimum sound intensity of 60.8 dB. Meanwhile, to turn on and turn off Lamp III in a row is 3.32 seconds and 3.39 seconds with a sound intensity of at least 61.32 dB. The three lamps can be controlled with the furthest distance is 1.2 meters. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Smart lamp is a technology that offers convenience for users in controlling the lamp. Previously, there had been research developing this system, but the controls offered were still based on Android that can't support a multiple platform. This system uses the Recurrent Neural Network (RNN) and Long-Short Term Memory (LSTM) algorithms. Besides that, this system also does a trial by using Internet of Things System for controlling and monitoring the lamps.From this research, the results of testing show that the average time required for the system to turn on and turn off Lamp I are 3.3 seconds and 3.28 seconds respectively with a minimum sound intensity of 60.6 dB. To turn on and turn off Lamp II in succession is 3.43 second and 3.61 second with a minimum sound intensity of 60.8 dB. Meanwhile, to turn on and turn off Lamp III in a row is 3.32 seconds and 3.39 seconds with a sound intensity of at least 61.32 dB. The three lamps can be controlled with the furthest distance is 1.2 meters. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Medium composition, coconut water, and chitosan effects on Phalaenopsis protocorm growth and development"
        ],
        "penulis":"Sukma D.;Aziz S.A.;Andini N.;Putri H.A.;Sudarsono S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Protocorm multiplication through the regeneration of protocorm-like bodies (PLBs) is used to obtain clonal progenies of hybrid orchids. The aim of the present study was to identify effective media for commercial orchid propagation through PLB proliferation. We evaluated the effects of basal media and either coconut water or chitosan supplementation on the growth of PLBs and the proliferation of Phalaenopsis hybrid PLBs, using two experiments, with random complete block designs (RBCD). The first experiment evaluated the progeny of white (V3) \u00d7 pink standard hybrid (KHM0421, population 1) and their reciprocal hybridization (population 2) and different medium compositions. The hybrid seeds germinated and developed into protocorms on a half-strength Murashige and Skoog (\u00bd MS) medium supplemented with 15% coconut water (CW). The protocorms were then transferred to four different media: 1) \u00bd MS; 2) \u00bd MS + 15% CW; 3) 2 g L-1complete fertilizer (CF); and 4) CF + 15% CW. Experiment two evaluated the effects of chitosan on the growth and proliferation of protocorms from population 1, using four different media: 1) \u00bd MS; 2) 2 g L-1CF; 3) \u00bd MS + 5 ppm chitosan; and 4) CF + 5 ppm chitosan, supplemented with 15% CW. The first experiment showed that the protocorm from population 1 generated more PLBs (5.4 PLBs in 16 weeks) than that of population 2 (2.2 PLBs in 16 weeks). The best media for protocorm proliferation and plantlet regeneration was CF and CF + 15% CW. The results of the second experiment revealed CF + 15% CW was the best medium for protocorm multiplication and plantlet regenerations. Chitosan tended to have a negative effect on protocorm growth and did not increase protocorm multiplication or plantlet regeneration. The use of CF medium could benefit orchid propagation, as it was cheaper than the MS medium. \u00a9 2019 International Society for Horticultural Science. All rights reserved.",
            "ChitinView detailsExpand Substance chitin",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Protocorm multiplication through the regeneration of protocorm-like bodies (PLBs) is used to obtain clonal progenies of hybrid orchids. The aim of the present study was to identify effective media for commercial orchid propagation through PLB proliferation. We evaluated the effects of basal media and either coconut water or chitosan supplementation on the growth of PLBs and the proliferation of Phalaenopsis hybrid PLBs, using two experiments, with random complete block designs (RBCD). The first experiment evaluated the progeny of white (V3) \u00d7 pink standard hybrid (KHM0421, population 1) and their reciprocal hybridization (population 2) and different medium compositions. The hybrid seeds germinated and developed into protocorms on a half-strength Murashige and Skoog (\u00bd MS) medium supplemented with 15% coconut water (CW). The protocorms were then transferred to four different media: 1) \u00bd MS; 2) \u00bd MS + 15% CW; 3) 2 g L-1complete fertilizer (CF); and 4) CF + 15% CW. Experiment two evaluated the effects of chitosan on the growth and proliferation of protocorms from population 1, using four different media: 1) \u00bd MS; 2) 2 g L-1CF; 3) \u00bd MS + 5 ppm chitosan; and 4) CF + 5 ppm chitosan, supplemented with 15% CW. The first experiment showed that the protocorm from population 1 generated more PLBs (5.4 PLBs in 16 weeks) than that of population 2 (2.2 PLBs in 16 weeks). The best media for protocorm proliferation and plantlet regeneration was CF and CF + 15% CW. The results of the second experiment revealed CF + 15% CW was the best medium for protocorm multiplication and plantlet regenerations. Chitosan tended to have a negative effect on protocorm growth and did not increase protocorm multiplication or plantlet regeneration. The use of CF medium could benefit orchid propagation, as it was cheaper than the MS medium. \u00a9 2019 International Society for Horticultural Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Enhanced OMP for Missing Traffic Reconstruction based on Sparse SVD"
        ],
        "penulis":"Irawati, Indrarini Dyah;Suksmono, Andriyan Bayu;Matheus Edward, Ian Joseph;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Missing large amount of internet data is a crucial issue to be addressed in network monitoring. The missing information should be restored using only a minimum knowledge of the data. Compressive Sampling (CS) algorithm provides a solution to complete data by utilizing the properties of randomness in the input data. Recently the reconstruction algorithm has developed in the base dictionary using orthogonal based operators. In this paper, we consider a CS approch to solve the missing problem using Singular Value Decomposition (SVD) sparsity, routing matrix for measurement matrix, and Orthogonal Matching Pursuit (OMP) as a recovery algorithm. To improve the accuracy, we also incorporating linear interpolation after OMP and Bilinear interpolation after SVD reconstruction. The missing scheme is randomized to simulate the actual behaviour of the network. Our experiments show that our proposed method is capable to fix large missing values with a high degree of accuracy for all missing type. This method is superior compared to the method in previous studies. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Missing large amount of internet data is a crucial issue to be addressed in network monitoring. The missing information should be restored using only a minimum knowledge of the data. Compressive Sampling (CS) algorithm provides a solution to complete data by utilizing the properties of randomness in the input data. Recently the reconstruction algorithm has developed in the base dictionary using orthogonal based operators. In this paper, we consider a CS approch to solve the missing problem using Singular Value Decomposition (SVD) sparsity, routing matrix for measurement matrix, and Orthogonal Matching Pursuit (OMP) as a recovery algorithm. To improve the accuracy, we also incorporating linear interpolation after OMP and Bilinear interpolation after SVD reconstruction. The missing scheme is randomized to simulate the actual behaviour of the network. Our experiments show that our proposed method is capable to fix large missing values with a high degree of accuracy for all missing type. This method is superior compared to the method in previous studies. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Detection of Gas Leaks Using the MQ-2 Gas Sensor on the Autonomous Mobile Sensor"
        ],
        "penulis":"Trisnawan, I. Kadek Nuary;Jati, Agung Nugroho;Istiqomah, Novera;Wasisto, Isro;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Gas leaks are one of the big problems in the industrial sector, even starting to spread to other sectors. One of the solutions to reduce losses due to gas leakage is to detect it early when there is a leak. There are already many technologies that help prevent gas leaks harm humans more, one of them is the mobile sensor. The development of mobile sensors is one way to overcome losses both from material and non-material. Using a gas sensor of type MQ-2 as a detector, it is expected that later it can be overcome before it has a wider impact. The gas sensor is connected to a mobile sensor and installed in four different directions. MQ-2 was chosen because it has a low price and good durability. Assisted by the SLAM method as navigation and a combination of source-seeking and active-sensing localization methods as identifiers of leak points, the mobile sensor identifies points of leakage which are on the abnormal boundary. MQ-2 is calibrated and configured using C language, which is implemented through Arduino IDE. After configuring the gas sensor, it is expected that the results of accuracy reach 80% with the distance from the gas sensor to the point of leakage about 0-10 cm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Gas leaks are one of the big problems in the industrial sector, even starting to spread to other sectors. One of the solutions to reduce losses due to gas leakage is to detect it early when there is a leak. There are already many technologies that help prevent gas leaks harm humans more, one of them is the mobile sensor. The development of mobile sensors is one way to overcome losses both from material and non-material. Using a gas sensor of type MQ-2 as a detector, it is expected that later it can be overcome before it has a wider impact. The gas sensor is connected to a mobile sensor and installed in four different directions. MQ-2 was chosen because it has a low price and good durability. Assisted by the SLAM method as navigation and a combination of source-seeking and active-sensing localization methods as identifiers of leak points, the mobile sensor identifies points of leakage which are on the abnormal boundary. MQ-2 is calibrated and configured using C language, which is implemented through Arduino IDE. After configuring the gas sensor, it is expected that the results of accuracy reach 80% with the distance from the gas sensor to the point of leakage about 0-10 cm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The mediation of intrinsic motivation and affective commitment in the relationship of transformational leadership and employee engagement in technology-based companies"
        ],
        "penulis":"Azis, Elvira;Prasetio, Arif Partono;Gustyana, Tieka Trikartika;Putril, Sofia Fauziana;Rakhmawati, Dheana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper aims to determine the relationship of transformational leadership and employee engagement of technology-based company in Indonesia. Employees who perceived their leader caring and inspiring will become more engaged to their job and organization. The study also aims to examine the mediation of intrinsic motivation and affective commitment in the relationship. Data collected from 300 participants of two technology-based companies in Indonesia in 2019. The mediation analysis was used for data analysis and determined the direct and indirect effect. The results suggest that the intrinsic motivation and affective commitment become mediation element in connecting the transformational leadership and employee engagement. Individually or simultaneously, both mediated the relationship. \u00a9 2019, Czestochowa University of Technology. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper aims to determine the relationship of transformational leadership and employee engagement of technology-based company in Indonesia. Employees who perceived their leader caring and inspiring will become more engaged to their job and organization. The study also aims to examine the mediation of intrinsic motivation and affective commitment in the relationship. Data collected from 300 participants of two technology-based companies in Indonesia in 2019. The mediation analysis was used for data analysis and determined the direct and indirect effect. The results suggest that the intrinsic motivation and affective commitment become mediation element in connecting the transformational leadership and employee engagement. Individually or simultaneously, both mediated the relationship. \u00a9 2019, Czestochowa University of Technology. All rights reserved."
        ]
    },
    {
        "judul":[
            "Welcome message from TPC chair of ICSigSys 2019"
        ],
        "penulis":"Murti, Muhammad Ary;Save all to author list",
        "tahun":2019,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Designing Green Procurement System Based on Enterprise Resources Planning for the Rubber Processing Industry"
        ],
        "penulis":"Karlina, Octa;Ridwan, Ari Yanuar;Fajrillah, Asti Amalia Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The rubber processing industry is one of the manufacturing industries that pay attention to every activity on its production process that occurs during rubber processing. The work done in the production process at manufacturing, such as the rubber processing industry, produces waste that harms the environment. Therefore, it is necessary to monitor business activities. In this study focuses on designing application based on Enterprise Resource Planning (ERP) by running a green procurement system therein. Green procurement provides solutions to the selection of materials and services that can minimize the impact on the environment and provide benefits for the company. In implementing of green procurement system, ISO 14000 standardization data to determine the green supplier and the green material attributes data are needed to use for the Key Performance Indicator (KPI) report. The ERP-based application can generate report Key Performance Indicator (KPI) for green materials and green suppliers to help the company to monitor business processes in green procurement. However, the process of measuring the percentage of green materials and green suppliers is out of the scope of the discussion in this study, because this study only provides designing an application to implement green procurement. The selection of application based on Enterprise Resources Planning (ERP) is due to an ERP system that can add and also update data and information without duplication so that it can improve employee efficiency in monitoring business process activities with data integration in application based on Enterprise Resources Planning (ERP). The design of this application is tailored to the user requirements for green procurement that focus on the ability of the application system to provide purchase requisition, request for quotation, supplier selection, purchase order and integrating data such as payment of materials with the finance division, integrating data material that enters warehouse with the warehouse division. In addition, the aim of this study is to have an information system in monitoring business process activities carried out during the procurement process in the rubber processing industry using the Key Performance Indicator report, to assist in the management of procurement business processes using Enterprise Resource Planning (ERP) system. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The rubber processing industry is one of the manufacturing industries that pay attention to every activity on its production process that occurs during rubber processing. The work done in the production process at manufacturing, such as the rubber processing industry, produces waste that harms the environment. Therefore, it is necessary to monitor business activities. In this study focuses on designing application based on Enterprise Resource Planning (ERP) by running a green procurement system therein. Green procurement provides solutions to the selection of materials and services that can minimize the impact on the environment and provide benefits for the company. In implementing of green procurement system, ISO 14000 standardization data to determine the green supplier and the green material attributes data are needed to use for the Key Performance Indicator (KPI) report. The ERP-based application can generate report Key Performance Indicator (KPI) for green materials and green suppliers to help the company to monitor business processes in green procurement. However, the process of measuring the percentage of green materials and green suppliers is out of the scope of the discussion in this study, because this study only provides designing an application to implement green procurement. The selection of application based on Enterprise Resources Planning (ERP) is due to an ERP system that can add and also update data and information without duplication so that it can improve employee efficiency in monitoring business process activities with data integration in application based on Enterprise Resources Planning (ERP). The design of this application is tailored to the user requirements for green procurement that focus on the ability of the application system to provide purchase requisition, request for quotation, supplier selection, purchase order and integrating data such as payment of materials with the finance division, integrating data material that enters warehouse with the warehouse division. In addition, the aim of this study is to have an information system in monitoring business process activities carried out during the procurement process in the rubber processing industry using the Key Performance Indicator report, to assist in the management of procurement business processes using Enterprise Resource Planning (ERP) system. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Smart light recommending system using artificial neural network algorithm"
        ],
        "penulis":"Akbar, Muchammad Ferdian;Putrada, Aji Gautama;Abdurohman, Maman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes smart light recommending system based on sleep monitoring data using Artificial Neural Network (ANN) algorithm. lights are one of the biggest contributors to the power consumption of electrical equipment. The effort to reduce the use of lights is related to not using them when they are not in use. One of the moments when the lights are not used is when we are sleeping but some user sleep styles keep the lights on even when they are sleeping so the idea is how to turn off the lights after the user sleeps. To realize this idea, it is necessary to detect sleep which can be derived from the detection of heart rate by certain sensors. The sensors that are needed are those already embedded in Fitbit, a bracelet-shaped device that can detect various kinds of conditions in the human body. However, Fitbit cannot directly provide the sleep condition to the user or the lamp, but it can provide information in the form of logs, so that the lamp settings cannot be instantaneous. To overcome this problem a learning method can be applied to know sleep patterns that appear in logs produced by Fitbit. This paper applies ANN back propagation to learn the sleep patterns of users, especially sleep start time and sleep end time. Nine ANN models made from user sleep data are applied to 60 days of testing. From these models, the best results were given by the model which gave 82.27% accuracy for sleep start time and 98.28% for sleep end time. Accuracy is largely determined by the user's sleep style. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes smart light recommending system based on sleep monitoring data using Artificial Neural Network (ANN) algorithm. lights are one of the biggest contributors to the power consumption of electrical equipment. The effort to reduce the use of lights is related to not using them when they are not in use. One of the moments when the lights are not used is when we are sleeping but some user sleep styles keep the lights on even when they are sleeping so the idea is how to turn off the lights after the user sleeps. To realize this idea, it is necessary to detect sleep which can be derived from the detection of heart rate by certain sensors. The sensors that are needed are those already embedded in Fitbit, a bracelet-shaped device that can detect various kinds of conditions in the human body. However, Fitbit cannot directly provide the sleep condition to the user or the lamp, but it can provide information in the form of logs, so that the lamp settings cannot be instantaneous. To overcome this problem a learning method can be applied to know sleep patterns that appear in logs produced by Fitbit. This paper applies ANN back propagation to learn the sleep patterns of users, especially sleep start time and sleep end time. Nine ANN models made from user sleep data are applied to 60 days of testing. From these models, the best results were given by the model which gave 82.27% accuracy for sleep start time and 98.28% for sleep end time. Accuracy is largely determined by the user's sleep style. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Increasing Received Modulation Signal for Integrated EOM Microwave Antenna by Using Paraboloid Reflector"
        ],
        "penulis":"Natali Y.;Priambodo P.S.;Rahardjo E.T.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Fifth generation mobile communication, 5G is a cellular networking architecture built based on the International Mobile Telecommunication (IMT) 2020 vision. As the vision to give better bit rate at the wireless user side, it requires fiber-optics transport or fronthaul to optimize the energy and decrease the delay in the process of transferring signals from wireless modes to fiber-optics and vice versa. One of it is a radio over fiber technology, which supplement the IMT 2020 standard. The radio over fiber communication consists of radio and optical link. Formerly, there are several techniques that have been proposed to reduce the network delay or latency in radio over fiber link. One of such techniques is to integrate a microwave receiving antenna with electro-optical modulator (EOM) plates in one device. However, there is a consequence that the RF modulating signals become very low. While an expectation that this integration can eliminate the requirement of the low noise amplifier (LNA) component in the RoF. Previously, the integrated antenna EOM arranged in a serial cascade or parallel, but it can cause disruption in electro-optic modulation. To keep maintain an adequate signal level without disturbing the modulation process, in this paper, we propose another method, whereas using an existing paraboloid dish to focus on the integrated microwave antenna EOM modulator. We examine the experiment in the radio link and comparing the surface area among the paraboloid and bowtie substrate to get the increasing RF modulation signal on the bowtie receiver. The experiments show 20 dB increasing of RF modulation signal. This method can be a solution for overcome the decreasing RF signal on the integrated EOM microwave antenna. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Fifth generation mobile communication, 5G is a cellular networking architecture built based on the International Mobile Telecommunication (IMT) 2020 vision. As the vision to give better bit rate at the wireless user side, it requires fiber-optics transport or fronthaul to optimize the energy and decrease the delay in the process of transferring signals from wireless modes to fiber-optics and vice versa. One of it is a radio over fiber technology, which supplement the IMT 2020 standard. The radio over fiber communication consists of radio and optical link. Formerly, there are several techniques that have been proposed to reduce the network delay or latency in radio over fiber link. One of such techniques is to integrate a microwave receiving antenna with electro-optical modulator (EOM) plates in one device. However, there is a consequence that the RF modulating signals become very low. While an expectation that this integration can eliminate the requirement of the low noise amplifier (LNA) component in the RoF. Previously, the integrated antenna EOM arranged in a serial cascade or parallel, but it can cause disruption in electro-optic modulation. To keep maintain an adequate signal level without disturbing the modulation process, in this paper, we propose another method, whereas using an existing paraboloid dish to focus on the integrated microwave antenna EOM modulator. We examine the experiment in the radio link and comparing the surface area among the paraboloid and bowtie substrate to get the increasing RF modulation signal on the bowtie receiver. The experiments show 20 dB increasing of RF modulation signal. This method can be a solution for overcome the decreasing RF signal on the integrated EOM microwave antenna. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Gap analysis of Indonesian state-owned bank internet banking website"
        ],
        "penulis":"Pradana, Mahir;Wahyuddin S.;Syarifuddin, Syarifuddin;Putra, Adrianza;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aimed to describe the level of quality perceived by internet banking customers of a state-owned bank in Indonesia. We use Website Quality (WebQual) theory for this research. By analyzing usability, information quality, and service interaction of the internet banking website, we then interpret the result with Gap Analysis method. With the participation of 100 respondents collected from all over Indonesia, we found that there are value gaps between the actual quality (performance) and ideal quality (importance). \u00a9 2019, IEOM Society International.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aimed to describe the level of quality perceived by internet banking customers of a state-owned bank in Indonesia. We use Website Quality (WebQual) theory for this research. By analyzing usability, information quality, and service interaction of the internet banking website, we then interpret the result with Gap Analysis method. With the participation of 100 respondents collected from all over Indonesia, we found that there are value gaps between the actual quality (performance) and ideal quality (importance). \u00a9 2019, IEOM Society International."
        ]
    },
    {
        "judul":[
            "Development of IoT server on electricity mapping system"
        ],
        "penulis":"Putra, Yuantoro K. S.;Nasrun, Muhammad;Setianingsih, Casi;Murti, Muhammad Ary;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electricity is the main need of society in everyday life. Each building has an electricity meter or kWh meter to calculate the electricity consumption of its consumers in kWh (kilowatt-hour) units. If electricity consumers have several buildings, it is very important to know the electricity usage of each building. One way is to make an Electricity Mapping System make it easier for consumers to know the use of electricity without having to manually check each kWh meter. This Monitoring System has 3 main parts, namely the Hardware System (client), System Server (server), and the Web Interface System (client). With the rapid development of IOT, many devices can communicate with each other through networks without human interaction. Data communication networks used are client-server based by publishing\/subscribing to Message Queuing Telemetry Transport (MQTT) Servers and requests for Web Servers that have their respective roles. Based on the test results show that the server can store sensor data sent via nodeMCU with the highest throghput value occurring in scenario 4 with 100% data reception while the lowest throughput value occurs in scenario 3 with 60%. And for receiving static data with the sending process every 15 seconds once in 1 hour, the server system can receive every 1 data for 15,126 seconds so there is a delay of 0.126 seconds. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electricity is the main need of society in everyday life. Each building has an electricity meter or kWh meter to calculate the electricity consumption of its consumers in kWh (kilowatt-hour) units. If electricity consumers have several buildings, it is very important to know the electricity usage of each building. One way is to make an Electricity Mapping System make it easier for consumers to know the use of electricity without having to manually check each kWh meter. This Monitoring System has 3 main parts, namely the Hardware System (client), System Server (server), and the Web Interface System (client). With the rapid development of IOT, many devices can communicate with each other through networks without human interaction. Data communication networks used are client-server based by publishing\/subscribing to Message Queuing Telemetry Transport (MQTT) Servers and requests for Web Servers that have their respective roles. Based on the test results show that the server can store sensor data sent via nodeMCU with the highest throghput value occurring in scenario 4 with 100% data reception while the lowest throughput value occurs in scenario 3 with 60%. And for receiving static data with the sending process every 15 seconds once in 1 hour, the server system can receive every 1 data for 15,126 seconds so there is a delay of 0.126 seconds. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A heuristic method for location-inventory-routing problem in a three-echelon supply chain system"
        ],
        "penulis":"Saragih, Nova Indah;Bahagia, Senator Nur;Suprayogi;Syabri, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Location-inventory-routing problem belongs to the class of NP-hard problems. It needs a heuristic method to solve the problem in large scales so it can be applied in a real system case. This paper develops a heuristic method for location-inventory-routing problem in a three-echelon supply chain system where inventory decisions are made in the three involved entities. The involved entities in the system are single supplier, multi depots, and multi retailers. The demand of the retailers is probabilistic, single product, and following a normal distribution. The heuristic method consists of two stages, which are constructive stage and improvement stage. At the improvement stage, there are three phases developed to improve solution iteratively. The phases are location phase, inventory phase, and routing phase. SA (simulated annealing) is used at the improvement stage to improve the solution. The heuristic method is evaluated using instances and the solutions are compared to the MINLP (mixed integer nonlinear programming) model. Average gap between the heuristic method and the MINLP model is 0.55% in terms of total cost. The proposed heuristic is applied in a real system case which is food supply chain system of DKI Jakarta to design a new supply chain system that can increase availability. The new design can increase the availability from 76% to 95%. \u00a9 2018 Elsevier Ltd",
            "SOHOOHONOView detailsExpand Substance 3-(N-morpholinyl)-2-hydroxypropanesulfonic acid",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Location-inventory-routing problem belongs to the class of NP-hard problems. It needs a heuristic method to solve the problem in large scales so it can be applied in a real system case. This paper develops a heuristic method for location-inventory-routing problem in a three-echelon supply chain system where inventory decisions are made in the three involved entities. The involved entities in the system are single supplier, multi depots, and multi retailers. The demand of the retailers is probabilistic, single product, and following a normal distribution. The heuristic method consists of two stages, which are constructive stage and improvement stage. At the improvement stage, there are three phases developed to improve solution iteratively. The phases are location phase, inventory phase, and routing phase. SA (simulated annealing) is used at the improvement stage to improve the solution. The heuristic method is evaluated using instances and the solutions are compared to the MINLP (mixed integer nonlinear programming) model. Average gap between the heuristic method and the MINLP model is 0.55% in terms of total cost. The proposed heuristic is applied in a real system case which is food supply chain system of DKI Jakarta to design a new supply chain system that can increase availability. The new design can increase the availability from 76% to 95%. \u00a9 2018 Elsevier Ltd"
        ]
    },
    {
        "judul":[
            "Name indexing in Indonesian translation of hadith using named entity recognition with na\u00efve bayes classifier"
        ],
        "penulis":"Azalia, Fadhila Yasmine;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hadith is believed to be the main source of Islam after Qur'an. The simplicity of obtaining hadith information is currently supported by global access using the internet. The abundance of hadith literature sometimes finds difficulties to obtain the information that needed. Therefore, information extraction is required to facilitate the searching of information in hadith. In this study, the name indexing in Indonesian translation of hadith from nine narrators was built. The model was built using Named Entity Recognition with Na\u00efve Bayes classifier. The features used in this study are title case, POS tag and unigram. This study experimented with individual features and features that were combined. Precision, recall, and F1-Score are employed as evaluation metrics. F1-Score is used in this study to measure the performance of named entity and features. The results of experiments extracted 258 people's names from 13870 token data from 100 Indonesian hadith texts and show that implementing the combination of all features can achieve 82.63% of F1-Score. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hadith is believed to be the main source of Islam after Qur'an. The simplicity of obtaining hadith information is currently supported by global access using the internet. The abundance of hadith literature sometimes finds difficulties to obtain the information that needed. Therefore, information extraction is required to facilitate the searching of information in hadith. In this study, the name indexing in Indonesian translation of hadith from nine narrators was built. The model was built using Named Entity Recognition with Na\u00efve Bayes classifier. The features used in this study are title case, POS tag and unigram. This study experimented with individual features and features that were combined. Precision, recall, and F1-Score are employed as evaluation metrics. F1-Score is used in this study to measure the performance of named entity and features. The results of experiments extracted 258 people's names from 13870 token data from 100 Indonesian hadith texts and show that implementing the combination of all features can achieve 82.63% of F1-Score. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "Automatic Risk Detection System for Farmer's Health Monitoring Based on Behavior of Pesticide Use"
        ],
        "penulis":"Silvi Lydia, Maya;Aulia, Indra;Lestari Mahyuni, Eka;Hizriadi, Ainul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The Indonesian farmers usually use the agrochemical technology (i.e. pesticide) to prevent or control not only pests but also weeds. Unfortunately, this technique is often applied without adhering to the Occupational Health and Safety (OHS) standards, so that the risks to the pesticide exposure cannot be avoided. Nowadays, the stakeholder has the difficulties for detecting the risks. The current detection system is still performed manually by involving the related experts to assess the farmers' behavior of pesticide use. This process often spends more times, so that it is impacted on late awareness of the pesticide exposure risk. Due to this, this paper proposed the automatic early detection (ArDeFarm) system with applying Certainty Factor method. This system uses the certainty values acquired from the related experts in order to generate the percentage of the pesticide exposure risk based on the farmers' behavior in the pesticide mixing, loading and application. It is tested by using farmers' behavior data collected from 100 orange farmers in Karo District. Based on the experiment, it is able to identify the pesticide exposure risk faced on farmers in the form of the risk percentage automatically, without relying on the experts. Besides, the result shows that it has been appropriate to the expert assessment. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Indonesian farmers usually use the agrochemical technology (i.e. pesticide) to prevent or control not only pests but also weeds. Unfortunately, this technique is often applied without adhering to the Occupational Health and Safety (OHS) standards, so that the risks to the pesticide exposure cannot be avoided. Nowadays, the stakeholder has the difficulties for detecting the risks. The current detection system is still performed manually by involving the related experts to assess the farmers' behavior of pesticide use. This process often spends more times, so that it is impacted on late awareness of the pesticide exposure risk. Due to this, this paper proposed the automatic early detection (ArDeFarm) system with applying Certainty Factor method. This system uses the certainty values acquired from the related experts in order to generate the percentage of the pesticide exposure risk based on the farmers' behavior in the pesticide mixing, loading and application. It is tested by using farmers' behavior data collected from 100 orange farmers in Karo District. Based on the experiment, it is able to identify the pesticide exposure risk faced on farmers in the form of the risk percentage automatically, without relying on the experts. Besides, the result shows that it has been appropriate to the expert assessment. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "WHY SHOULD THE Q-METHOD BE INTEGRATED INTO THE DESIGN SCIENCE RESEARCH? A SYSTEMATIC MAPPING STUDY"
        ],
        "penulis":"Nurhas, Irawan;Geisler, Stefan;Pawlowski, Jan M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The Q-method has been utilized over time in various areas, including information systems. In this study, we used a systematic mapping to illustrate how the Q-method was applied within Information Systems (IS) community and proposing towards integration of Q-method into the Design Sciences Research (DSR) process as a tool for future research DSR-based IS studies. In this mapping study, we collected peer-reviewed journals from Basket-of-Eight journals and the digital library of the Association for Information Systems (AIS). Then we grouped the publications according to the process of DSR, and different variables for preparing Q-method from IS publications. We found that the potential of the Q-methodology can be used to support each main research stage of DSR processes and can serve as the useful tool to evaluate a system in the IS topic of system analysis and design. \u00a9 2019, Association for Information Systems. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Q-method has been utilized over time in various areas, including information systems. In this study, we used a systematic mapping to illustrate how the Q-method was applied within Information Systems (IS) community and proposing towards integration of Q-method into the Design Sciences Research (DSR) process as a tool for future research DSR-based IS studies. In this mapping study, we collected peer-reviewed journals from Basket-of-Eight journals and the digital library of the Association for Information Systems (AIS). Then we grouped the publications according to the process of DSR, and different variables for preparing Q-method from IS publications. We found that the potential of the Q-methodology can be used to support each main research stage of DSR processes and can serve as the useful tool to evaluate a system in the IS topic of system analysis and design. \u00a9 2019, Association for Information Systems. All rights reserved."
        ]
    },
    {
        "judul":[
            "TLS-VaD: A new tool for developing centralized link-scheduling algorithms on the IEEE802.15.4e TSCH network"
        ],
        "penulis":"Santoso, Iman Hedi;Ramli, Kalamullah;Suryadi M.T.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A simulator plays an important role in network protocol research, as it enables researchers to develop protocols more flexibly. Many simulators have been developed to support research in this field, including NS-2, NS-3, OPNET, OMNeT, and Cooja. Although, as a research support tools, NS3 and Cooja have already been equipped with an Internet of things (IoT) module, their support for research on IoT centralized scheduling is still limited. Therefore, this study is aimed to develop a tool for IoT centralized scheduling research, where the IoT technology is based on the IEEE802.15.4e time synchronized channel hopping (TSCH) standard. The tool is called the TSCH Link-Scheduling visualization and data processing (TLS-VaD). The results of validity tests show that TLS-VaD works well; therefore, this tool can be used in the performance measurement of centralized scheduling algorithms on TSCH networks. As an example of the application, this research used TLS-VaD to test the performance of three scheduling algorithms: Iman Ramli Bursty Transmission Scheduling Algorithm (IRByTSA), first top scheduling algorithm (FTSA), and first leaf scheduling algorithm (FLSA). The test results using TLS-VaD shows that IRByTSA had better performance compared to FLSA and FTSA, because it saved more power and was able to generate scheduling decisions relatively quickly. \u00a9 2019 by the authors. Licensee MDPI, Basel, Switzerland.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A simulator plays an important role in network protocol research, as it enables researchers to develop protocols more flexibly. Many simulators have been developed to support research in this field, including NS-2, NS-3, OPNET, OMNeT, and Cooja. Although, as a research support tools, NS3 and Cooja have already been equipped with an Internet of things (IoT) module, their support for research on IoT centralized scheduling is still limited. Therefore, this study is aimed to develop a tool for IoT centralized scheduling research, where the IoT technology is based on the IEEE802.15.4e time synchronized channel hopping (TSCH) standard. The tool is called the TSCH Link-Scheduling visualization and data processing (TLS-VaD). The results of validity tests show that TLS-VaD works well; therefore, this tool can be used in the performance measurement of centralized scheduling algorithms on TSCH networks. As an example of the application, this research used TLS-VaD to test the performance of three scheduling algorithms: Iman Ramli Bursty Transmission Scheduling Algorithm (IRByTSA), first top scheduling algorithm (FTSA), and first leaf scheduling algorithm (FLSA). The test results using TLS-VaD shows that IRByTSA had better performance compared to FLSA and FTSA, because it saved more power and was able to generate scheduling decisions relatively quickly. \u00a9 2019 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Application of Transfer Learning Using Convolutional Neural Network Method for Early Detection of Terry's Nail"
        ],
        "penulis":"Yani, Muhamad;Irawan, Budhi;Setiningsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nails are one part of the fingers and toes, by observing the shape and the condition of the nails, health expert can find out information about a person's health. However, this sometimes not realized and ignored by society, even though many diseases that can be seen through the condition of the nails and the shape of the nails are one of the systemic diseases. This research was conducted to detect abnormalities in the nail based on digital images. The detected abnormalities are terry's nails in the hand which can represent systemic diseases, while the method used is the Convolutional Neural Network (CNN) method. This research uses Tensorflow Inception-V3 architecture model with the transfer learning method where the results of the experiments that have been done are obtained with 95.24% accuracy. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nails are one part of the fingers and toes, by observing the shape and the condition of the nails, health expert can find out information about a person's health. However, this sometimes not realized and ignored by society, even though many diseases that can be seen through the condition of the nails and the shape of the nails are one of the systemic diseases. This research was conducted to detect abnormalities in the nail based on digital images. The detected abnormalities are terry's nails in the hand which can represent systemic diseases, while the method used is the Convolutional Neural Network (CNN) method. This research uses Tensorflow Inception-V3 architecture model with the transfer learning method where the results of the experiments that have been done are obtained with 95.24% accuracy. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Purchase intention determinants of halal food in secular countries"
        ],
        "penulis":"Pradana, Mahir;Syarifuddin, Syarifuddin;Hafid, Haeruddin;Gilang, Alini;Diandri, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to determine the effect of subjective norm, halal awareness, and behavioural control on purchase intention in halal food products for Muslim students in non-Islamic countries. This research is a survey research using a questionnaire as an instrument, distributed to respondents all over Europe. The population used in this study were Muslim students. 215 respondents used the purposive sampling method, which is a sample selection technique in which an individual chooses a sample based on a personal assessment of some appropriate characteristics of the sample members. The analysis technique used is multiple regression analysis with the theory of planned behaviour. The results of the study found that perceived behavioural control is not an influential predictor on purchase intention. This finding is somewhat contrary to the existing findings which perceived behavioural control as an important factor in influencing consumer to purchase halal food. \u00a9 ExcelingTech Pub, UK.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to determine the effect of subjective norm, halal awareness, and behavioural control on purchase intention in halal food products for Muslim students in non-Islamic countries. This research is a survey research using a questionnaire as an instrument, distributed to respondents all over Europe. The population used in this study were Muslim students. 215 respondents used the purposive sampling method, which is a sample selection technique in which an individual chooses a sample based on a personal assessment of some appropriate characteristics of the sample members. The analysis technique used is multiple regression analysis with the theory of planned behaviour. The results of the study found that perceived behavioural control is not an influential predictor on purchase intention. This finding is somewhat contrary to the existing findings which perceived behavioural control as an important factor in influencing consumer to purchase halal food. \u00a9 ExcelingTech Pub, UK."
        ]
    },
    {
        "judul":[
            "Air pollution distribution in Telkom University: Spatial interpolation map"
        ],
        "penulis":"Oktaviani I.D.;Erfianto B.;Rakhmatsyah A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Currently, air quality information in a region becomes an important thing to know. Some efforts have been conducted to show air quality in certain region. One of the efforts that has been done is information regarding air quality in several big cities in Indonesia which can be seen in the official website of the Ministry of Environment and Forestry that have several weaknesses. One of the problems to be overcome in this research is visualization of air quality data that is monitored at one point only in which that point is the placement location of air quality monitoring station. Because of that, we need an application that can display a map of air pollution distribution using the spatial interpolation method. The solution offered is the depiction of air quality by using heatmap on the map. The method used to produce heatmap with smooth result is natural cubic spline interpolation method. The production of heatmap uses API which is provided by Google Maps. The final result obtained is the map view with the coloration in the form of color gradation in accordance with the air quality value that is obtained. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Currently, air quality information in a region becomes an important thing to know. Some efforts have been conducted to show air quality in certain region. One of the efforts that has been done is information regarding air quality in several big cities in Indonesia which can be seen in the official website of the Ministry of Environment and Forestry that have several weaknesses. One of the problems to be overcome in this research is visualization of air quality data that is monitored at one point only in which that point is the placement location of air quality monitoring station. Because of that, we need an application that can display a map of air pollution distribution using the spatial interpolation method. The solution offered is the depiction of air quality by using heatmap on the map. The method used to produce heatmap with smooth result is natural cubic spline interpolation method. The production of heatmap uses API which is provided by Google Maps. The final result obtained is the map view with the coloration in the form of color gradation in accordance with the air quality value that is obtained. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Performance evaluation of M-ary modulated DCO-OFDM in an indoor visible light communication system"
        ],
        "penulis":"Milia, Nurul Fatma;Sugesti, Erna Sri;Saputri, Desti Madya;Pamukti, Brian;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper reports the performance of an indoor Visible Light Communication (VLC) system using a Direct Current-biased Optical Orthogonal Frequency Division Multiplexing (DCO-OFDM) scheme with a single Light Emitting Diode (LED). The DCO-OFDM is assigned to alter the bipolar signals produced by ordinary OFDM into unipolar signals. We simulate some M-ary modulations and employ Line-of-Sight (LOS) propagation model. The results show that the Quadrature Phase Shift Keying (QPSK) modulation is the most extensive one, with BER \u2264 10-3with lower SNR. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper reports the performance of an indoor Visible Light Communication (VLC) system using a Direct Current-biased Optical Orthogonal Frequency Division Multiplexing (DCO-OFDM) scheme with a single Light Emitting Diode (LED). The DCO-OFDM is assigned to alter the bipolar signals produced by ordinary OFDM into unipolar signals. We simulate some M-ary modulations and employ Line-of-Sight (LOS) propagation model. The results show that the Quadrature Phase Shift Keying (QPSK) modulation is the most extensive one, with BER \u2264 10-3with lower SNR. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Self-complementary bow-tie antenna design for UWB respiration system"
        ],
        "penulis":"Jannah, Solihatul;Pramudita, Aloysius Adya;Wahyu, Yuyu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Ultra Wide Band (UWB) radars are widely studied to be implemented in the medical field for detecting vital signs in humans such as heartbeat and respiration. UWB antenna is an important issue in UWB radar system since the UWB characteristic isn't only determining form impedance bandwidth perspective, but the suitable UWB antenna design is also required for UWB respiration radar. In this paper, we propose a bow-tie antenna design for UWB respiration radar system with self-complementary structure. The simulation and measurement experiments were conducted to investigate the proposed antenna characteristic and its performance in supporting the radar system in respiration detection process. In the experiment, the Vector Network Analyzer (VNA) is used to modelled the UWB respiration radar. The antenna is realized using FR4 dielectric substrate with relative permittivity of 4.3 and thickness of 1.6 mm. The antenna was design to cover the UWB range from 4-10 GHz. Simulation and measurement results show that the proposed antenna has fulfill the bandwidth requirement. The proposed antenna has a bandwidth within range 2.8 GHz to 10 GHz. Due to the minimum distortion point of view, the S21 result from both simulation and measurement indicate that the antenna has linear phase response. The Respiration radar experiments using VNA shows that the reflected signal from chest wall at exhale and inhale can be identified well using the proposed antenna. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ultra Wide Band (UWB) radars are widely studied to be implemented in the medical field for detecting vital signs in humans such as heartbeat and respiration. UWB antenna is an important issue in UWB radar system since the UWB characteristic isn't only determining form impedance bandwidth perspective, but the suitable UWB antenna design is also required for UWB respiration radar. In this paper, we propose a bow-tie antenna design for UWB respiration radar system with self-complementary structure. The simulation and measurement experiments were conducted to investigate the proposed antenna characteristic and its performance in supporting the radar system in respiration detection process. In the experiment, the Vector Network Analyzer (VNA) is used to modelled the UWB respiration radar. The antenna is realized using FR4 dielectric substrate with relative permittivity of 4.3 and thickness of 1.6 mm. The antenna was design to cover the UWB range from 4-10 GHz. Simulation and measurement results show that the proposed antenna has fulfill the bandwidth requirement. The proposed antenna has a bandwidth within range 2.8 GHz to 10 GHz. Due to the minimum distortion point of view, the S21 result from both simulation and measurement indicate that the antenna has linear phase response. The Respiration radar experiments using VNA shows that the reflected signal from chest wall at exhale and inhale can be identified well using the proposed antenna. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Infrared Indoor Positioning Using Invisible Beacon"
        ],
        "penulis":"Cahyadi, Willy Anugrah;Chung, Yeon Ho;Adiono, Trio;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, we present an experimental demonstration of an infrared (IR) indoor positioning scheme (IPS). Unlike previous studies that employ light emitting diode (LED) and camera as the transmitter and the receiver, respectively, the proposed IPS is based on a widely available surveillance camera as the receiver and a single invisible IR LED beacon installed in smartphones as the transmitter in indoor environments. An intraframe algorithm is also proposed to provide accurate positioning on both static and moving beacon (smartphone) by minimizing the amount of ambient light interference. The proposed IPS is experimentally proven that it achieves centimeter accuracy with a mean positioning error of 6 cm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we present an experimental demonstration of an infrared (IR) indoor positioning scheme (IPS). Unlike previous studies that employ light emitting diode (LED) and camera as the transmitter and the receiver, respectively, the proposed IPS is based on a widely available surveillance camera as the receiver and a single invisible IR LED beacon installed in smartphones as the transmitter in indoor environments. An intraframe algorithm is also proposed to provide accurate positioning on both static and moving beacon (smartphone) by minimizing the amount of ambient light interference. The proposed IPS is experimentally proven that it achieves centimeter accuracy with a mean positioning error of 6 cm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "HERDING BEHAVIOR IN THE INDONESIAN ISLAMIC STOCK MARKET"
        ],
        "penulis":"Rizal, Nora Amelda;Damayanti, Mirta Kartika;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia Stock Exchange provides Islamic stocks for Muslim investors who want to invest, with the first Islamic stock index in Indonesia being Jakarta Islamic Index or JII that consists of thirty of the most liquid Islamic stocks. The market capitalization of JII tends to increase every year. This paper examines the presence of herding behavior in emerging Islamic stock market of Indonesia using daily return of Indonesia Composite Index and JII from October 6, 2000 to October 5, 2018. Herding behavior could generally trigger shifting market prices from equilibrium values. Herding behavior may be identified from the relation between stock return dispersion and market return. Stock return dispersion is measured using Cross Sectional Absolute Deviation or CSAD. Generalized Auto Regressive Conditional Heteroskedasticity or GARCH method is used to detect herding behavior. GARCH does not see heteroskedasticity as a problem, instead uses it to make a model. The result indicates that herding behavior exist in Islamic stock market of Indonesia. Asymmetric herding occurs in Indonesia Islamic stock market where herding behavior exists during falling market condition only. \u00a9 2019 Bank Indonesia Institute. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia Stock Exchange provides Islamic stocks for Muslim investors who want to invest, with the first Islamic stock index in Indonesia being Jakarta Islamic Index or JII that consists of thirty of the most liquid Islamic stocks. The market capitalization of JII tends to increase every year. This paper examines the presence of herding behavior in emerging Islamic stock market of Indonesia using daily return of Indonesia Composite Index and JII from October 6, 2000 to October 5, 2018. Herding behavior could generally trigger shifting market prices from equilibrium values. Herding behavior may be identified from the relation between stock return dispersion and market return. Stock return dispersion is measured using Cross Sectional Absolute Deviation or CSAD. Generalized Auto Regressive Conditional Heteroskedasticity or GARCH method is used to detect herding behavior. GARCH does not see heteroskedasticity as a problem, instead uses it to make a model. The result indicates that herding behavior exist in Islamic stock market of Indonesia. Asymmetric herding occurs in Indonesia Islamic stock market where herding behavior exists during falling market condition only. \u00a9 2019 Bank Indonesia Institute. All rights reserved."
        ]
    },
    {
        "judul":[
            "A Multi Tone Modeling for Seismic Data Compression"
        ],
        "penulis":"Liu, Bo;Mohandes M.;Nuha H.;Deriche M.;Iqbal, Naveed;Fekri, Faramarz;McClellan, James H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG"
        ]
    },
    {
        "judul":[
            "Optimal complex power production cost in the electric power market"
        ],
        "penulis":"Zein, Hermagasantos;Raharjo, Jangkung;Mulyadi, Ahmad Deni;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cost reduction issues have received serious attention from actors of power industries during the past decade in the power market mechanism. Appropriate management of reactive power is very essential for supporting power system security. Besides, it has also dominant effects on real energy losses. Furthermore, the reactive power can support the secure operation of the system as an ancillary service. However, most researches have focussed on a transaction of the reactive power in electricity markets. On the other hand, reactive power production of generating is highly dependent on the real power output and only absorbed by the local consumers. As a result, to accommodate a market and to maintain a secure operation of the system, a fair cost allocation method seems to be very essential. Appropriate pricing of reactive power as an ancillary service has been a challenging problem during the past decade. However, most methods proposed so far for reactive power pricing are essentially based on empirical approximations. In this paper, a new method for reducing active and reactive power cost allocations has been proposed. The method is based on optimal cost calculation, which will be imposed on generators producing reactive power. The proposed method is fair, accurate and realistic, simple and easy to be applicated in the power system. Application of the proposed method on IEEE 9-bus standard network confirms its validity and effectiveness. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cost reduction issues have received serious attention from actors of power industries during the past decade in the power market mechanism. Appropriate management of reactive power is very essential for supporting power system security. Besides, it has also dominant effects on real energy losses. Furthermore, the reactive power can support the secure operation of the system as an ancillary service. However, most researches have focussed on a transaction of the reactive power in electricity markets. On the other hand, reactive power production of generating is highly dependent on the real power output and only absorbed by the local consumers. As a result, to accommodate a market and to maintain a secure operation of the system, a fair cost allocation method seems to be very essential. Appropriate pricing of reactive power as an ancillary service has been a challenging problem during the past decade. However, most methods proposed so far for reactive power pricing are essentially based on empirical approximations. In this paper, a new method for reducing active and reactive power cost allocations has been proposed. The method is based on optimal cost calculation, which will be imposed on generators producing reactive power. The proposed method is fair, accurate and realistic, simple and easy to be applicated in the power system. Application of the proposed method on IEEE 9-bus standard network confirms its validity and effectiveness. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Students Graduation Target Based on Academic Data Record Using C4.5 Algorithm Case Study: Information Systems Students of Telkom University"
        ],
        "penulis":"Putri, Dela Youlina;Andreswari, Rachmadita;Hasibuan, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Study program of Information Systems is one of the existing study programs at Telkom University which has produced many graduates until 2017. However, not all graduates produced successfully completed the study period during four years of normal study period in which may cause the decrease of study programs quality and affect the assessment of study program if there is an audit or evaluation so it can affect the achievement level of the study program. To solve the problem can be by making a prediction model of student graduation that can be obtained from data classification process using decision tree with algorithm C4.5 and implement it to the academic data record of existing student so that got two group of student, that is student which predicted pass on time and student predicted to pass late. From the results of the classification of student data can be done an analysis of what factors that can affect the graduation of students who are predicted to pass on time and plan appropriate strategies for groups of students who may not pass on time. The data classification process is done with the help of open source based tools using RapidMiner application. The result of the classification is a prediction model that has an accuracy value of 82.24% and states that the most influential factor in predicting students' graduation is GPA in the second year. The result of the student's graduation classification is expected to be used as the reference base to support the academic planner in making the right decision to the student groups generated so that all students can graduate on time. \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Study program of Information Systems is one of the existing study programs at Telkom University which has produced many graduates until 2017. However, not all graduates produced successfully completed the study period during four years of normal study period in which may cause the decrease of study programs quality and affect the assessment of study program if there is an audit or evaluation so it can affect the achievement level of the study program. To solve the problem can be by making a prediction model of student graduation that can be obtained from data classification process using decision tree with algorithm C4.5 and implement it to the academic data record of existing student so that got two group of student, that is student which predicted pass on time and student predicted to pass late. From the results of the classification of student data can be done an analysis of what factors that can affect the graduation of students who are predicted to pass on time and plan appropriate strategies for groups of students who may not pass on time. The data classification process is done with the help of open source based tools using RapidMiner application. The result of the classification is a prediction model that has an accuracy value of 82.24% and states that the most influential factor in predicting students' graduation is GPA in the second year. The result of the student's graduation classification is expected to be used as the reference base to support the academic planner in making the right decision to the student groups generated so that all students can graduate on time. \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Information System Architecture Planning with the Open Group Architecture Framework"
        ],
        "penulis":"Nugraha R.A.;Handoko Y.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose if this research is to develop a blueprint that can be used to build Information System Architecture that can integrate business and information technology with the aim of increasing the effectiveness and business efficiency of the company. The method used is TOGAF-ADM so that it is more flexible in verifying various types of modelling techniques used in designing information systems. The results of this study in the form of preliminary data collection from the TOGAF framework stage which in the future can be used for information system development that can be used at PT. Corocot Digital Creative. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose if this research is to develop a blueprint that can be used to build Information System Architecture that can integrate business and information technology with the aim of increasing the effectiveness and business efficiency of the company. The method used is TOGAF-ADM so that it is more flexible in verifying various types of modelling techniques used in designing information systems. The results of this study in the form of preliminary data collection from the TOGAF framework stage which in the future can be used for information system development that can be used at PT. Corocot Digital Creative. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Indicator Warning Refined Fuel Oil in A Motorcycle with Fuzzy Logic and Sound Navigaiotn through Smart Helmet"
        ],
        "penulis":"Rahman, Arif;Abdurohman, Maman;Putrada, Aji Gautama;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Even though the motorbike has a fuelmeter on its dashboard, breakdown incident due to run out of gasoline is still often encountered. This is a sign that the warning system provided by the motorbike is still insufficient. On the other hand research in the field of smart helmets is growing and advancing. This research proposes a fuel indicator that is mounted on the smart helmet. The indicator is in forms of voice warning. Fuelmeters are connected to buoys that are in the fuel tank. The buoy serves to detect the remaining fuel oil in the tank. In this design a combination of helmets and fuel oil detectors is carried out in the tank. When the fuel oil on the tank will run out, the helmet will produce output in the form of sound notification of the remaining fuel oil in the tank. In the oil fuel tank there are buoys to measure fuel levels, measurements made in this study using a microcontroller that is connected to a buoy. The microcontroller reads the current in the buoy, where when the fuel is full the voltage will be above 7 volts, when the half voltage level is between 5 volts - 7 volts and when it is almost gone or close to the voltage below 5 volts. When the fuel is half and runs out, the microcontroller in the tank will send a signal to the helmet to notify the level of available fuel. Helmets will receive signals from tank microcontrollers and helmets will provide output in the form of sound. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Even though the motorbike has a fuelmeter on its dashboard, breakdown incident due to run out of gasoline is still often encountered. This is a sign that the warning system provided by the motorbike is still insufficient. On the other hand research in the field of smart helmets is growing and advancing. This research proposes a fuel indicator that is mounted on the smart helmet. The indicator is in forms of voice warning. Fuelmeters are connected to buoys that are in the fuel tank. The buoy serves to detect the remaining fuel oil in the tank. In this design a combination of helmets and fuel oil detectors is carried out in the tank. When the fuel oil on the tank will run out, the helmet will produce output in the form of sound notification of the remaining fuel oil in the tank. In the oil fuel tank there are buoys to measure fuel levels, measurements made in this study using a microcontroller that is connected to a buoy. The microcontroller reads the current in the buoy, where when the fuel is full the voltage will be above 7 volts, when the half voltage level is between 5 volts - 7 volts and when it is almost gone or close to the voltage below 5 volts. When the fuel is half and runs out, the microcontroller in the tank will send a signal to the helmet to notify the level of available fuel. Helmets will receive signals from tank microcontrollers and helmets will provide output in the form of sound. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Removing Unvoiced Segment to Improve Text Independent Speaker Recognition"
        ],
        "penulis":"Ridha, Dzufiqar;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Speaker recognition is one of the biometric technologies to recognize humans, such as identification of fingerprints, DNA, and iris because the characteristics of human speech are unique. The characteristics of speech are dominated by voiced segment. Meanwhile, the unvoiced segments those commonly have random waveform can be seen as noise for the speaker recognition. Therefore, in this paper, a simple procedure to remove unvoiced parts is proposed to improve the accuracy. This procedure is simply implemented using the short time zero-crossing rate (STZCR) to detect and remove the unvoiced parts. It is applied before the Mel Frequency Cepstral Coefficients (MFCC)-based feature extraction and the Gaussian Mixture Model (GMM)-based classification. Evaluation on VoxForge dataset using 4-fold cross-validation show that the proposed procedure is capable of improving the accuracy from 99.94% to 100%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Speaker recognition is one of the biometric technologies to recognize humans, such as identification of fingerprints, DNA, and iris because the characteristics of human speech are unique. The characteristics of speech are dominated by voiced segment. Meanwhile, the unvoiced segments those commonly have random waveform can be seen as noise for the speaker recognition. Therefore, in this paper, a simple procedure to remove unvoiced parts is proposed to improve the accuracy. This procedure is simply implemented using the short time zero-crossing rate (STZCR) to detect and remove the unvoiced parts. It is applied before the Mel Frequency Cepstral Coefficients (MFCC)-based feature extraction and the Gaussian Mixture Model (GMM)-based classification. Evaluation on VoxForge dataset using 4-fold cross-validation show that the proposed procedure is capable of improving the accuracy from 99.94% to 100%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Exploring entrepreneurial competencies in identifying ideas and opportunities, managing resources, and taking action: Evidence from small catering business owners in Bandung, Indonesia"
        ],
        "penulis":"Gustomo, Aurik;Ghina, Astri;Anggadwita, Grisna;Herliana, Sri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Entrepreneurial competencies are particularly important for catering business owners in order to maintain and develop their businesses. This article empirically investigates and identifies entrepreneurial competencies in catering business owners in Bandung, Indonesia. In-depth, semi-structured interviews and focus-group discussions were conducted with key informants from five catering business establishments in Bandung. With the use of the case study approach, the study found that the level of entrepreneurial competencies in catering business owners falls generally in the middle, with some at low levels. Three main competencies were identified in this study: ideas and opportunities, resources, and actions. The implications of these findings are explored. \u00a9 2019, \u00a9 2019 Taylor & Francis.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Entrepreneurial competencies are particularly important for catering business owners in order to maintain and develop their businesses. This article empirically investigates and identifies entrepreneurial competencies in catering business owners in Bandung, Indonesia. In-depth, semi-structured interviews and focus-group discussions were conducted with key informants from five catering business establishments in Bandung. With the use of the case study approach, the study found that the level of entrepreneurial competencies in catering business owners falls generally in the middle, with some at low levels. Three main competencies were identified in this study: ideas and opportunities, resources, and actions. The implications of these findings are explored. \u00a9 2019, \u00a9 2019 Taylor & Francis."
        ]
    },
    {
        "judul":[
            "Malmquist index productivity of Indonesian Bank: Based on commercial bank business group"
        ],
        "penulis":"Octrina, Fajra;Primiana, Ina;Anwar, Mokhamad;Herwany, Aldrin;Rusnoto Susanto, Moh.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to measure the level of productivity of conventional banks in Indonesia during the period of 2012 - 2016 using the method of Malmquist Productivity Index (MPI). Of the 50 bank samples, there are only five banks which have the composition of EFFCH, TECHCH, PECH, SECK and TFPCH \u2265 1, namely Anglomas Bank, Bank Fama, Lampung BPD, Bank of China Limited, JP Morgan Bank, and Bank of Tokyo Mitsubishi. It is because the changes in efficiency and technology are seen to less optimally contribute to enhance the productivity. Design: Malmquist Productivity Index (MPI) method using DEAP 2.1 software.Findings: It shows that banks in the category of BUKU 4 are not yet productive. Moreover, of the total, there are only five banks which indicate the composition of EFFCH, TECHCH, PECH, SECK and TFPCH \u2265 1, namely Anglomas Bank, Bank Fama, Lampung BPD, Bank of China Limited, JP Morgan Bank, and Bank of Tokyo Mitsubishi, all of which are classified into BUKU 1, 2 and 3.Originality and value: This research was conducted to analyze the extent to which the banking sector are productive when viewed based on the Commercial Bank Business Group (BUKU) classification which had not previously been carried out. \u00a9 BEIESP.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to measure the level of productivity of conventional banks in Indonesia during the period of 2012 - 2016 using the method of Malmquist Productivity Index (MPI). Of the 50 bank samples, there are only five banks which have the composition of EFFCH, TECHCH, PECH, SECK and TFPCH \u2265 1, namely Anglomas Bank, Bank Fama, Lampung BPD, Bank of China Limited, JP Morgan Bank, and Bank of Tokyo Mitsubishi. It is because the changes in efficiency and technology are seen to less optimally contribute to enhance the productivity. Design: Malmquist Productivity Index (MPI) method using DEAP 2.1 software.Findings: It shows that banks in the category of BUKU 4 are not yet productive. Moreover, of the total, there are only five banks which indicate the composition of EFFCH, TECHCH, PECH, SECK and TFPCH \u2265 1, namely Anglomas Bank, Bank Fama, Lampung BPD, Bank of China Limited, JP Morgan Bank, and Bank of Tokyo Mitsubishi, all of which are classified into BUKU 1, 2 and 3.Originality and value: This research was conducted to analyze the extent to which the banking sector are productive when viewed based on the Commercial Bank Business Group (BUKU) classification which had not previously been carried out. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Study of squeezer machine performance of cooked soy porridge"
        ],
        "penulis":"Hadi R.M.E.;Chumaidiah E.;Wulandari S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Managers of tofu craftsmen complain a lot on the issue of soybean raw materials that the more days the price is increasing so high, so the benefits gained is decreasing significantly. To anticipate the continuous soybean price increase, the tofu craftsmen plan to make a squeezer machine of cooked soybean porridge which is useful to increase the juice, reduce the time of squeeze, and can ease the squeeze. The benefits of squeezer machine of cooked soybean porridge are that from the aspect of its output it will produce more, that in terms of time it can be faster, that the energy spent is very small because the squeeze utilizes the power of the driving motor, and the tofu dregs produced will be less. The performance study of hygienic tofu making by utilizing a squeezer machine of cooked soybean porridge will be done by comparing the measurement of squeeze time which is currently done by measuring the squeeze time by utilizing the squeezer machine of cooked soybean porridge and measuring the water content in the tofu dregs after the squeeze process. The results are by utilizing the squeezer machine of cooked soybean porridge meet the requirements in accordance with the wishes of the tofu craftsmen in which the water content in the tofu dregs is little, the tofu produced is more, and the process of squeeze is quicker. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Managers of tofu craftsmen complain a lot on the issue of soybean raw materials that the more days the price is increasing so high, so the benefits gained is decreasing significantly. To anticipate the continuous soybean price increase, the tofu craftsmen plan to make a squeezer machine of cooked soybean porridge which is useful to increase the juice, reduce the time of squeeze, and can ease the squeeze. The benefits of squeezer machine of cooked soybean porridge are that from the aspect of its output it will produce more, that in terms of time it can be faster, that the energy spent is very small because the squeeze utilizes the power of the driving motor, and the tofu dregs produced will be less. The performance study of hygienic tofu making by utilizing a squeezer machine of cooked soybean porridge will be done by comparing the measurement of squeeze time which is currently done by measuring the squeeze time by utilizing the squeezer machine of cooked soybean porridge and measuring the water content in the tofu dregs after the squeeze process. The results are by utilizing the squeezer machine of cooked soybean porridge meet the requirements in accordance with the wishes of the tofu craftsmen in which the water content in the tofu dregs is little, the tofu produced is more, and the process of squeeze is quicker. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Fire Detection Using Image Processing Techniques with Convolutional Neural Networks"
        ],
        "penulis":"Sadewa, Raam Pujangga;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Fire is a flame, whether it is small or large, an undesirable place, situation and time. In general, every place has the potential to experience a fire. But at this time, the smoke sensors are the most widely used devices to detect fires. Where the smoke sensors can only detect fires if the fire is large. So that a system is needed to detect early fires. In this paper, an image-based fire alarm system is designed, using a laptop and webcam as the main equipment. The method for using Convolutional Neural Networks (CNN) to identify fire. The system created has an accuracy rate of 92%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Fire is a flame, whether it is small or large, an undesirable place, situation and time. In general, every place has the potential to experience a fire. But at this time, the smoke sensors are the most widely used devices to detect fires. Where the smoke sensors can only detect fires if the fire is large. So that a system is needed to detect early fires. In this paper, an image-based fire alarm system is designed, using a laptop and webcam as the main equipment. The method for using Convolutional Neural Networks (CNN) to identify fire. The system created has an accuracy rate of 92%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Sentiment Analysis of Social Media Users Using Na\u00efve Bayes, Decision Tree, Random Forest Algorithm: A Case Study of Draft Law on the Elimination of Sexual Violence (RUU PKS)"
        ],
        "penulis":"Virra, Khalisa;Andreswari, Rachmadita;Hasibuan, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this digitalization era, it made it easy for the people of Indonesia to deliver ideas, opinions to carry out campaigns. One real example is regarding the existence of Draft Law on the Elimination of Sexual Violence (RUU PKS) with the aim of creating a new paradigm that ensures the community is free from sexual violence. The draft initiated by the National Commission on Violence Against Women, known as KOMNAS Perempuan, succeeded in becoming a conversation with social media users. Twitter is one of the social media that is a means of delivering public opinion regarding the case. One of the uses of this research is to find out the tendency of Twitter users to comment on regarding the existence of Draft Law on the Elimination of Sexual Violence (RUU PKS) by conducting sentiment analysis. The stages of this research are carried out by collecting data. The data that has been collected will go through the pre-processing, processing stage which will produce data in the positive, negative and neutral categories then testing using confession matrix. From the results of accuracy in the order of naive bayes, decision tree and random forest, the accuracy is 83.94%, 75.31 and 75.72%. Based on this, it can be concluded that the sentiment analysis of this case gets the best results using the Naive Bayes algorithm. As well as based on the results obtained that campaigning through social media has an effect, in this case for the campaign to support the RUU PKS itself produces more positive sentiments. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGender equalityGoal 5Peace, justice and strong institutionsGoal 16",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this digitalization era, it made it easy for the people of Indonesia to deliver ideas, opinions to carry out campaigns. One real example is regarding the existence of Draft Law on the Elimination of Sexual Violence (RUU PKS) with the aim of creating a new paradigm that ensures the community is free from sexual violence. The draft initiated by the National Commission on Violence Against Women, known as KOMNAS Perempuan, succeeded in becoming a conversation with social media users. Twitter is one of the social media that is a means of delivering public opinion regarding the case. One of the uses of this research is to find out the tendency of Twitter users to comment on regarding the existence of Draft Law on the Elimination of Sexual Violence (RUU PKS) by conducting sentiment analysis. The stages of this research are carried out by collecting data. The data that has been collected will go through the pre-processing, processing stage which will produce data in the positive, negative and neutral categories then testing using confession matrix. From the results of accuracy in the order of naive bayes, decision tree and random forest, the accuracy is 83.94%, 75.31 and 75.72%. Based on this, it can be concluded that the sentiment analysis of this case gets the best results using the Naive Bayes algorithm. As well as based on the results obtained that campaigning through social media has an effect, in this case for the campaign to support the RUU PKS itself produces more positive sentiments. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Linear Congruential Method for Randomization of Test Item in Computer-Based Psychological Edwards Personal Preference Schedule (EPPS) Test"
        ],
        "penulis":"Sesari E.G.;Dirgantoro B.;Setianingsih C.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Psychological tests are used to determine human's attitude and behavior. In its application, psychological tests still use the old method. Objects are asked to answer questions and then the answers will be collected again to be calculated, and then conclusion will be drawn from the result. It will be time consuming and impractical. Computer-based psychological test have an answer to these deficiencies. By utilizing the ease of test item management in computer, this paper discusses the application of linear congruential method for randomization of test item in computer-based psychological edwards personal preference schedule (EPPS) test developed by web-based programming. According to expert, the difference in the number of respondents who have the largest and smallest raw score aspects that are the same and not the same is considered not too significant that in this case randomization of test item can be applied to the EPPS test because the change in test results is not too significant and the scoring process is still valid. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Psychological tests are used to determine human's attitude and behavior. In its application, psychological tests still use the old method. Objects are asked to answer questions and then the answers will be collected again to be calculated, and then conclusion will be drawn from the result. It will be time consuming and impractical. Computer-based psychological test have an answer to these deficiencies. By utilizing the ease of test item management in computer, this paper discusses the application of linear congruential method for randomization of test item in computer-based psychological edwards personal preference schedule (EPPS) test developed by web-based programming. According to expert, the difference in the number of respondents who have the largest and smallest raw score aspects that are the same and not the same is considered not too significant that in this case randomization of test item can be applied to the EPPS test because the change in test results is not too significant and the scoring process is still valid. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "What are the Indonesian Concerns about the Internet of Things (IoT)? Portraying the Profile of the Prospective Market"
        ],
        "penulis":"Suryanegara, Muhammad;Arifin, Ajib Setyo;Asvial, Muhamad;Ramli, Kalamullah;Nashiruddin, Muhammad Imam;Hayati, Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper aims to characterize the profile of the prospective IoT market in Indonesia. The primary data were collected in July 2018 through a comprehensive survey that sampled respondents representing the whole Indonesian population. The questionnaire was developed by extracting the 4 (four) main issues regarding which the potential users of the IoT technology may have concerns, i.e., willingness to use the IoT services, concerns related to rejection and worries about the IoT, the characteristics of the IoT hardware, and perceptions about the role of the IoT within the existing system. The results of the survey were analyzed to capture the profile of the prospective IoT market, and the strategic implications of the findings were considered. Several interesting results were found, ranging from answering the common question of what kinds of the IoT services are most anticipated to answering the delicate question of how the Indonesian people perceive the disruptive force that the IoT technology may exert. The contribution of this research is that it can be used as an initial guide or reference for regulators, the government and the IoT firms that will begin to deploy services in Indonesia. \u00a9 2013 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper aims to characterize the profile of the prospective IoT market in Indonesia. The primary data were collected in July 2018 through a comprehensive survey that sampled respondents representing the whole Indonesian population. The questionnaire was developed by extracting the 4 (four) main issues regarding which the potential users of the IoT technology may have concerns, i.e., willingness to use the IoT services, concerns related to rejection and worries about the IoT, the characteristics of the IoT hardware, and perceptions about the role of the IoT within the existing system. The results of the survey were analyzed to capture the profile of the prospective IoT market, and the strategic implications of the findings were considered. Several interesting results were found, ranging from answering the common question of what kinds of the IoT services are most anticipated to answering the delicate question of how the Indonesian people perceive the disruptive force that the IoT technology may exert. The contribution of this research is that it can be used as an initial guide or reference for regulators, the government and the IoT firms that will begin to deploy services in Indonesia. \u00a9 2013 IEEE."
        ]
    },
    {
        "judul":[
            "A multi-label classification on topics of Indonesian news using K-Nearest Neighbor"
        ],
        "penulis":"Isnaini, Nikmah;Adiwijaya;Mubarok, Mohamad Syahrul;Bakar, Muhammad Yuslan Abu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "News has become a basic human need along with technological and internet developments. This causes the process of disseminating information on the news that switched from print media to the digital era. Another problem that appears when classifying news is multi-label. Multi-label classification is different from single label classification. A single label classification will classify documents into one label only. While multi-label classification can group documents into more than one label. For example, news articles that discuss in detail the early detection of ovarian cancer with a bioinformatics approach may have more than one label such as health, bioinformatics, and women. In this paper, a classification model is developed that can identify classes in each multi-label news article using K-Nearest Neighbor. The advantages of K-Nearest Neighbor are algorithms that are very suitable for multi-label cases; even KNN can be superior to other classifiers. From the system created, the results of the value of system performance as measured by the size of the closeness are the comparison between Manhattan Distance, Euclidean Distance and Supremum Distance using the K = 11 parameters, resulting in a Hamming Loss value of 11.16.%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "News has become a basic human need along with technological and internet developments. This causes the process of disseminating information on the news that switched from print media to the digital era. Another problem that appears when classifying news is multi-label. Multi-label classification is different from single label classification. A single label classification will classify documents into one label only. While multi-label classification can group documents into more than one label. For example, news articles that discuss in detail the early detection of ovarian cancer with a bioinformatics approach may have more than one label such as health, bioinformatics, and women. In this paper, a classification model is developed that can identify classes in each multi-label news article using K-Nearest Neighbor. The advantages of K-Nearest Neighbor are algorithms that are very suitable for multi-label cases; even KNN can be superior to other classifiers. From the system created, the results of the value of system performance as measured by the size of the closeness are the comparison between Manhattan Distance, Euclidean Distance and Supremum Distance using the K = 11 parameters, resulting in a Hamming Loss value of 11.16.%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Towards co-creation strategy and organizational agility based on customer experience orientation to shape transformational performance"
        ],
        "penulis":"Mihardjo, Leonardus W. Wasono;Sasmoko, Firdaus Alamsyah;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 5.0 is a step after digitalization and digitation has been accomplished. The collaboration, service orientation, agility and customer experience become a critical in this dynamic environment. Hence, the firm strategy has shifted from a competition strategy to a col-laboration strategy. Collaboration with customers is effected through co-creation Strategy (CCS). It could enable the firms in accelerating digital transformation. This study of the development of co-creation strategy focuses on customer experience orientation (CXO) and organization agility (OA) to support transformational performance (TP) in terms of relationship among variables and an empirical study has been conducted. Hence, in this paper, we propose a model of digital transformation for ICT Industry based on co-creation of strategy focused on customer experience orientation and organization agility. The study is based on an empirical study of 195 Indonesian ICT firms. The findings from this analysis reveal the concept of Service Dominant logic (S-D Logic) where the Co-creation capability and organizational agilities can suffice. \u00a9 2019 Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 5.0 is a step after digitalization and digitation has been accomplished. The collaboration, service orientation, agility and customer experience become a critical in this dynamic environment. Hence, the firm strategy has shifted from a competition strategy to a col-laboration strategy. Collaboration with customers is effected through co-creation Strategy (CCS). It could enable the firms in accelerating digital transformation. This study of the development of co-creation strategy focuses on customer experience orientation (CXO) and organization agility (OA) to support transformational performance (TP) in terms of relationship among variables and an empirical study has been conducted. Hence, in this paper, we propose a model of digital transformation for ICT Industry based on co-creation of strategy focused on customer experience orientation and organization agility. The study is based on an empirical study of 195 Indonesian ICT firms. The findings from this analysis reveal the concept of Service Dominant logic (S-D Logic) where the Co-creation capability and organizational agilities can suffice. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Text mining approach using TF-IDF and naive bayes for classification of exam questions based on cognitive level of bloom's taxonomy"
        ],
        "penulis":"Aninditya, Annisa;Hasibuan, Muhammad Azani;Sutoyo, Edi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Bloom's Taxonomy is a unity of three domains, which are divided into lower orders and high orders based on the Bloom Taxonomic Cognitive Domain, the level is used to classify learning objectives and serve as benchmarks for evaluating student achievement. Basically, an evaluation of student achievement can be done by giving questions on exam activities. The questions given are then classified according to the level in the Cognitive Domain. However, because the number of questions is too many and the classification is still manual, it causes the classification results are not accurate and inconsistent. Therefore, the employing of the Naive Bayes Classifier in classifying exam questions based on levels in the Cognitive Domain can be a solution. This study uses real-world dataset collected from mid-terms and final exams questions taken from Department of Information Systems, Telkom University from the academic year 2012\/2013 to 2018\/2019. In particular, we examined Words, Characters, and N-gram as indexing terms. The results showed that the classification using Na\u00efve Bayes and TF-IDF with N-gram as indexing terms achieved precision of 85% and recall of 80%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Bloom's Taxonomy is a unity of three domains, which are divided into lower orders and high orders based on the Bloom Taxonomic Cognitive Domain, the level is used to classify learning objectives and serve as benchmarks for evaluating student achievement. Basically, an evaluation of student achievement can be done by giving questions on exam activities. The questions given are then classified according to the level in the Cognitive Domain. However, because the number of questions is too many and the classification is still manual, it causes the classification results are not accurate and inconsistent. Therefore, the employing of the Naive Bayes Classifier in classifying exam questions based on levels in the Cognitive Domain can be a solution. This study uses real-world dataset collected from mid-terms and final exams questions taken from Department of Information Systems, Telkom University from the academic year 2012\/2013 to 2018\/2019. In particular, we examined Words, Characters, and N-gram as indexing terms. The results showed that the classification using Na\u00efve Bayes and TF-IDF with N-gram as indexing terms achieved precision of 85% and recall of 80%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Coverage and capacity analysis of LoRa WAN deployment for massive IoT in urban and suburban scenario"
        ],
        "penulis":"Nashiruddin, Muhammad Imam;Hidayati, Amriane;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Choosing connectivity technologies for the Internet of Things (IoT) is the most important aspect in the early stages of network planning. Long Range (LoRa) Wide Area Network (WAN) that categorized into Low Power Wide Area (LPWA) network is a potential connectivity technology for typical massive IoT applications like a smart meter, smart manufacturing, environmental monitoring, etc. This paper aims to provide coverage and capacity analysis of LoRa WAN for typical massive IoT application. The urban and suburban areas were chosen to observe the differences between those two scenarios. The results shown the capacity calculation in terms of the gateways needed is mainly influenced by the value of the bandwidth (BW), spreading factor (SF) and Coding Rate (CR). Coverage simulation is done by calculating the link budget, followed by a simulation using Forsk Atoll 3.3.2. It can be concluded that the whole determined areas can be served within acceptable levels with values > -137 dBm as the minimum sensitivity of the highest SF. While the mean of best signal level is -84.58 dBm and -90.9 dBm for the urban and suburban scenario, respectively.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Choosing connectivity technologies for the Internet of Things (IoT) is the most important aspect in the early stages of network planning. Long Range (LoRa) Wide Area Network (WAN) that categorized into Low Power Wide Area (LPWA) network is a potential connectivity technology for typical massive IoT applications like a smart meter, smart manufacturing, environmental monitoring, etc. This paper aims to provide coverage and capacity analysis of LoRa WAN for typical massive IoT application. The urban and suburban areas were chosen to observe the differences between those two scenarios. The results shown the capacity calculation in terms of the gateways needed is mainly influenced by the value of the bandwidth (BW), spreading factor (SF) and Coding Rate (CR). Coverage simulation is done by calculating the link budget, followed by a simulation using Forsk Atoll 3.3.2. It can be concluded that the whole determined areas can be served within acceptable levels with values > -137 dBm as the minimum sensitivity of the highest SF. While the mean of best signal level is -84.58 dBm and -90.9 dBm for the urban and suburban scenario, respectively.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementing principal component analysis and multinomial logit for cancer detection based on microarray data classification"
        ],
        "penulis":"Khoirunnisa, Azka;Adiwijaya;Rohmawati, Aniq A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cancer is the second largest cause of death in the world; in 2018, a total of 9.6 million mortalities were recorder, due to cancer alone. It is important to detect this deadly disease early. In the medical field, there are many methods that can be used to detect cancer. One of these methods is microarray data technology. Microarray data reads thousands of gene expressions at the same time. However, this method has a major problem; data with high dimensions can affect classification performance and consume a lot of computational time. Therefore, this research used Principal Component Analysis as the dimensional reduction method. This method performed feature extraction based on a Principal Component (PC) obtained from the calculation of eigenvalues and eigenvectors. Moreover, the data reduction was implemented using a Multinomial Logit Classifier by modifying the parameters estimator using Maximum Likelihood Estimation. The cancer data used in this research consists of Colon Cancer, Leukemia, Lung Cancer, and Ovarian Cancer datasets. The test results for the Ovarian Cancer dataset gave an accuracy of 100% using a Proportion of Variance (PPV) of 90%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is the second largest cause of death in the world; in 2018, a total of 9.6 million mortalities were recorder, due to cancer alone. It is important to detect this deadly disease early. In the medical field, there are many methods that can be used to detect cancer. One of these methods is microarray data technology. Microarray data reads thousands of gene expressions at the same time. However, this method has a major problem; data with high dimensions can affect classification performance and consume a lot of computational time. Therefore, this research used Principal Component Analysis as the dimensional reduction method. This method performed feature extraction based on a Principal Component (PC) obtained from the calculation of eigenvalues and eigenvectors. Moreover, the data reduction was implemented using a Multinomial Logit Classifier by modifying the parameters estimator using Maximum Likelihood Estimation. The cancer data used in this research consists of Colon Cancer, Leukemia, Lung Cancer, and Ovarian Cancer datasets. The test results for the Ovarian Cancer dataset gave an accuracy of 100% using a Proportion of Variance (PPV) of 90%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Street lighting efficiency with particle swarm optimization algorithm following Indonesian standard"
        ],
        "penulis":"Eriyadi M.;Abdullah A.G.;Mulia S.B.;Hasbullah H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper aims the street lighting efficiency optimization of street lighting on Dr. Setiabudhi street, Bandung city. Particle Swarm Optimization (PSO) algorithm is used to get maximum lighting efficiency values with constraints in the form of lamp height, the distance between lights, lamp power, type\/width of the street, the average illuminance and minimum illuminance according to Indonesian national standards (SNI) standards. Parameter optimization to obtain optimal values based on global standards and Indonesian national standards (SNI) has been done. PSO using MATLAB\u00ae (R2017a, MathWorks Inc, USA) has produced a street lighting optimization model with the level of lighting efficiency twice higher than the evaluation of existing conditions. Testing the results of the PSO algorithm shows a difference of 9.7% higher than the DIALux evo (8.0, Ludenscheid, Germany) software design. The test results show that the PSO algorithm can be used to obtain optimum lighting efficiency from a public street lighting system following SNI. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper aims the street lighting efficiency optimization of street lighting on Dr. Setiabudhi street, Bandung city. Particle Swarm Optimization (PSO) algorithm is used to get maximum lighting efficiency values with constraints in the form of lamp height, the distance between lights, lamp power, type\/width of the street, the average illuminance and minimum illuminance according to Indonesian national standards (SNI) standards. Parameter optimization to obtain optimal values based on global standards and Indonesian national standards (SNI) has been done. PSO using MATLAB\u00ae (R2017a, MathWorks Inc, USA) has produced a street lighting optimization model with the level of lighting efficiency twice higher than the evaluation of existing conditions. Testing the results of the PSO algorithm shows a difference of 9.7% higher than the DIALux evo (8.0, Ludenscheid, Germany) software design. The test results show that the PSO algorithm can be used to obtain optimum lighting efficiency from a public street lighting system following SNI. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Quantization effect on 5G millimeter wave communication"
        ],
        "penulis":"Armi, Nasrullah;Wael, Chaeriah;Mitayani, Arumjeni;Arief Suryadi S.;Galih Nugraha N.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The era of millimeter wave (mmWave) spectrum with operating frequency range 30-300 GHz is coming. These frequencies are potentially used by 5G cellular communication since it has some benefits such as larger bandwidth and capacity. Energy efficiency is a crucial issue in 5G mmWave where it employs a large number of antenna array with power consumed ADCs (Analog to Digital Converters). This paper studies the efficiency of energy for mmWave communication through the optimization of ADC bits quantization. We use Channel Structure-based Scheduling (CSS) algorithm for evaluation with the total rate used as a performance parameter. The selection of quantization bit must consider the complexity of implementation. The simulation uses 2 bits quantization to explore the total rate performance. Then increasing bit number into 3 bits and 5 bits in the following simulation. The total rate increases as transmit power increases for the entire implemented quantization bit number. The random scheduling algorithm is used as a reference for comparison. The simulation shows that Channel structure-based scheduling algorithm outperforms random scheduling. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The era of millimeter wave (mmWave) spectrum with operating frequency range 30-300 GHz is coming. These frequencies are potentially used by 5G cellular communication since it has some benefits such as larger bandwidth and capacity. Energy efficiency is a crucial issue in 5G mmWave where it employs a large number of antenna array with power consumed ADCs (Analog to Digital Converters). This paper studies the efficiency of energy for mmWave communication through the optimization of ADC bits quantization. We use Channel Structure-based Scheduling (CSS) algorithm for evaluation with the total rate used as a performance parameter. The selection of quantization bit must consider the complexity of implementation. The simulation uses 2 bits quantization to explore the total rate performance. Then increasing bit number into 3 bits and 5 bits in the following simulation. The total rate increases as transmit power increases for the entire implemented quantization bit number. The random scheduling algorithm is used as a reference for comparison. The simulation shows that Channel structure-based scheduling algorithm outperforms random scheduling. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "An initial framework of fuzzy neural network approach for online learner verification process"
        ],
        "penulis":"Sadikan, Siti Fairuz Nurr;Ramli, Azizul Azhar;Kasim, Shahreen;Mahdin, Hairulnizam;Salamat, Mohamad Aizi;Wisesty, Untari Novia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Online learning is become more popular among university due to its flexibility and adaptability. The student authentication as online learner is widely seen as a major concern for online assessment. In most cases, there is absent of face-to-face supervision during online assessment, this situation leads the student to use or find help from others in order to get high scores in their result. This paper address the issue related to online assessment. The main objective of this work was to propose the use of online learner verification framework. This proposed solution utilizes the keystroke analysis and activity-based authentication for the online learner authentication. A fuzzy neural network is used to train and validate the online learner\u2019s identity. The proposed framework can be implementing in any online learning environment for verifying online learner identity. \u00a9 2019, World Academy of Research in Science and Engineering. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Online learning is become more popular among university due to its flexibility and adaptability. The student authentication as online learner is widely seen as a major concern for online assessment. In most cases, there is absent of face-to-face supervision during online assessment, this situation leads the student to use or find help from others in order to get high scores in their result. This paper address the issue related to online assessment. The main objective of this work was to propose the use of online learner verification framework. This proposed solution utilizes the keystroke analysis and activity-based authentication for the online learner authentication. A fuzzy neural network is used to train and validate the online learner\u2019s identity. The proposed framework can be implementing in any online learning environment for verifying online learner identity. \u00a9 2019, World Academy of Research in Science and Engineering. All rights reserved."
        ]
    },
    {
        "judul":[
            "Digital anemometer and solar power meter analysis measurements for installation of wind and solar hybrid power plants"
        ],
        "penulis":"Mulyana, Tatang;Ibrahim, Rasidi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents an analysis of the results of wind speed measurements using Digital Anemometer Model AM-4203 and solar power measurements using Digital Solar Power Meter Model SPM-1116SD from a location which will be used as a site to install a hybrid system of wind and solar power plants. The wind speed measurement data taken in 3421 seconds are recorded and displayed in graphical form between wind speed (m\/s) and time (s). Meanwhile, the solar power measurement data taken in 111 seconds are recorded and displayed in graphical form between solar powers (W\/m2) to seconds (s). The lowest wind speed measurement result is 0 m\/s for some time and the highest is 3 m\/s for 2880 seconds, while for the average measurement result is 1 m\/s. While the lowest solar power measurement results are 20 W\/m2 for some time and the highest is 770 W\/m2 at 14:14:43 (23 s), while for the average measurement is 360 W\/m2. Referring to such measurement data, the potential for wind power generation is weak, so it is almost impossible to produce energy efficiently using wind power, as the wind speed must be greater than 4 m\/s. While based on the measurement profile of solar power, from time to time can reach 770 W\/m2 which has the potential to generate electricity. In addition, based on these two measurement results, they show a nonlinear random profile. Thus the installation of hybrid wind and solar power plants must have a nonlinear control system design. \u00a9 2019 Penerbit Akademia Baru.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents an analysis of the results of wind speed measurements using Digital Anemometer Model AM-4203 and solar power measurements using Digital Solar Power Meter Model SPM-1116SD from a location which will be used as a site to install a hybrid system of wind and solar power plants. The wind speed measurement data taken in 3421 seconds are recorded and displayed in graphical form between wind speed (m\/s) and time (s). Meanwhile, the solar power measurement data taken in 111 seconds are recorded and displayed in graphical form between solar powers (W\/m2) to seconds (s). The lowest wind speed measurement result is 0 m\/s for some time and the highest is 3 m\/s for 2880 seconds, while for the average measurement result is 1 m\/s. While the lowest solar power measurement results are 20 W\/m2 for some time and the highest is 770 W\/m2 at 14:14:43 (23 s), while for the average measurement is 360 W\/m2. Referring to such measurement data, the potential for wind power generation is weak, so it is almost impossible to produce energy efficiently using wind power, as the wind speed must be greater than 4 m\/s. While based on the measurement profile of solar power, from time to time can reach 770 W\/m2 which has the potential to generate electricity. In addition, based on these two measurement results, they show a nonlinear random profile. Thus the installation of hybrid wind and solar power plants must have a nonlinear control system design. \u00a9 2019 Penerbit Akademia Baru."
        ]
    },
    {
        "judul":[
            "Chemical pretreatment of lignocellulosic wastes for cellulase production by Aspergillus niger FNU 6018"
        ],
        "penulis":"Gunam, Ida Bagus Wayan;Antara, Nyoman Semadi;Anggreni, Anak Agung Made Dewi;Setiyo, Yohanes;Wiguna, I. Putu Eka;Wijaya, I. Made Mahaputra;Putra, I. Wayan Wisma Pradnyana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The objective of the research was to find out a source of lignocelluloses that could be converted to simple sugars especially glucose as a raw material in bioethanol production. The bioethanol production is an inefficient process, particularly the delignification process. Some solid wastes such as bagasse, corn straw, paddy straw, and sawdust were used as raw materials of lignocelluloses resource. The raw material was dried, ground into small particles, and delignified by using sodium hydroxide (NaOH), ammonia (NH3), and Hydrogen Peroxide (H2O2) in different concentration and soaking time. Two kinds of cellulose resources were chosen based on the value of its potency with the best chemical treatment for delignification. These selected cellulose and chemical used for delignification process were then used as substrate of cellulase enzyme production by Aspergillus niger FNU 6018. Results of the research showed that NaOH was the most effective chemical substance used in delignification process. This solvent also could increase the water retention value (WRV) of the lignocelluloses. Bagasse and corn straw were the potential agriculture waste to be used as raw material in bioethanol production. After delignification process, this raw material contained cellulose, lignin, and WRV of 69.46%, 8.79%, and 8.42, respectively. The FP-ase activity (bagasse as substrate) and CMC-ase activity (corn straw as substrate) of the crude enzyme was 0.0226 U and was 0.0606 U, respectively. \u00a9 2019 Author(s).",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The objective of the research was to find out a source of lignocelluloses that could be converted to simple sugars especially glucose as a raw material in bioethanol production. The bioethanol production is an inefficient process, particularly the delignification process. Some solid wastes such as bagasse, corn straw, paddy straw, and sawdust were used as raw materials of lignocelluloses resource. The raw material was dried, ground into small particles, and delignified by using sodium hydroxide (NaOH), ammonia (NH3), and Hydrogen Peroxide (H2O2) in different concentration and soaking time. Two kinds of cellulose resources were chosen based on the value of its potency with the best chemical treatment for delignification. These selected cellulose and chemical used for delignification process were then used as substrate of cellulase enzyme production by Aspergillus niger FNU 6018. Results of the research showed that NaOH was the most effective chemical substance used in delignification process. This solvent also could increase the water retention value (WRV) of the lignocelluloses. Bagasse and corn straw were the potential agriculture waste to be used as raw material in bioethanol production. After delignification process, this raw material contained cellulose, lignin, and WRV of 69.46%, 8.79%, and 8.42, respectively. The FP-ase activity (bagasse as substrate) and CMC-ase activity (corn straw as substrate) of the crude enzyme was 0.0226 U and was 0.0606 U, respectively. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Analysis of Critical Success Factors from ERP System Implementation in Pharmaceutical Fields by Information System Success Model"
        ],
        "penulis":"Syafiraliany, Levie;Lubis, Muharman;Witjaksono, R. Wahjoe;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The implementation of ERP system in this era is important because it accelerates the achievement of company goals. The company in this study is engaged in pharmacy using the SAP system, but the implementation of the SAP system has not run optimally in the company, therefore it requires an analysis of the success factors of ERP in order to minimize the negative impact and failure of ERP implementation. The analysis critical success factors of the ERP system implementation in the pharmaceutical company is based on the success model of information systems by DeLone and Mclean. This type of research is explanatory research using a quantitative approach, the quantitative data obtained by using a survey in the form of a questionnaire. The results of the study indicate that the critical success factors of ERP implementation that has a significant effect is the use of net benefits, user satisfaction of net benefits, and system quality of use. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The implementation of ERP system in this era is important because it accelerates the achievement of company goals. The company in this study is engaged in pharmacy using the SAP system, but the implementation of the SAP system has not run optimally in the company, therefore it requires an analysis of the success factors of ERP in order to minimize the negative impact and failure of ERP implementation. The analysis critical success factors of the ERP system implementation in the pharmaceutical company is based on the success model of information systems by DeLone and Mclean. This type of research is explanatory research using a quantitative approach, the quantitative data obtained by using a survey in the form of a questionnaire. The results of the study indicate that the critical success factors of ERP implementation that has a significant effect is the use of net benefits, user satisfaction of net benefits, and system quality of use. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Item Delivery Simulation Using Dijkstra Algorithm for Solving Traveling Salesman Problem"
        ],
        "penulis":"Ginting, Hagai Nuansa;Osmond, Andrew Brian;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Companies that contribute to travel have many problems in the process of item delivery. Distances and priorities are considered for a process of item delivery based on the highest priority. A delivery target that can be done one day evidently exceed the expected limit and that is the impact. This is an example of the waste time and operational costs that should be at the same time that two or more addresses can be sent. Traveling Salesman Problem (TSP) was define a classical problem to finding the shortest route that salesman can be passed when visiting several places without visit again in the same place more than once. In this study, TSP requires all calculations of possible routes to be obtained. Then choose one of the shortest routes by prioritizing the things considered, namely distance and priority. Delivery is done quickly through the shortest route according to priority using the Dijkstra algorithm. Simulation shows that the Dijkstra algorithm must be approved by use clustering data for Dijkstra's priorities and sub-routes to solve TSP problems. Simulation shows that the Dijkstra algorithm must be modified using Dijkstra's priority clustering and sub-routing to solve TSP problems. The resulting route has an influence between two graphs. Complete graph has a distance efficiency of 47.8% and execution time of 48.1% compared to non-complete graphs. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Companies that contribute to travel have many problems in the process of item delivery. Distances and priorities are considered for a process of item delivery based on the highest priority. A delivery target that can be done one day evidently exceed the expected limit and that is the impact. This is an example of the waste time and operational costs that should be at the same time that two or more addresses can be sent. Traveling Salesman Problem (TSP) was define a classical problem to finding the shortest route that salesman can be passed when visiting several places without visit again in the same place more than once. In this study, TSP requires all calculations of possible routes to be obtained. Then choose one of the shortest routes by prioritizing the things considered, namely distance and priority. Delivery is done quickly through the shortest route according to priority using the Dijkstra algorithm. Simulation shows that the Dijkstra algorithm must be approved by use clustering data for Dijkstra's priorities and sub-routes to solve TSP problems. Simulation shows that the Dijkstra algorithm must be modified using Dijkstra's priority clustering and sub-routing to solve TSP problems. The resulting route has an influence between two graphs. Complete graph has a distance efficiency of 47.8% and execution time of 48.1% compared to non-complete graphs. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Labeling Analysis in the Classification of Product Review Sentiments by using Multinomial Naive Bayes Algorithm"
        ],
        "penulis":"Tama V.O.;Sibaroni Y.;Adiwijaya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Along with the development of technology, e-commerce also experienced a fairly rapid development. The existence of e-commerce becomes another consumer alternative to make it easier for them to fulfill their needs. After buying the goods, consumers are free to assess the products they buy. Product reviews and ratings provided by consumers are one means that can be used to increase sales and can also be used to determine the decision in purchasing a product by reading the product reviews. However, using ratings and reviews alone is not enough to summarize one's opinion. Therefore, in this Final Project built a system that can classify opinions on product reviews into positive and negative sentiments by utilizing the rating. The dataset used is Grocery and Gourmet Food from Amazon as much as 50,000 which will then be labeled using Labeling Methods Average and Binary. The classification of this opinion uses the approach of Supervised learning Algorithm Multinomial Na\u00efve Bayes. The result of this research shows that labeling using Method Average is suitable for processing Grocery and Gourmet Food Dataset and proves that the best ratio of feature selection usage is 20% succeed to produce 80.48% accuracy. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Along with the development of technology, e-commerce also experienced a fairly rapid development. The existence of e-commerce becomes another consumer alternative to make it easier for them to fulfill their needs. After buying the goods, consumers are free to assess the products they buy. Product reviews and ratings provided by consumers are one means that can be used to increase sales and can also be used to determine the decision in purchasing a product by reading the product reviews. However, using ratings and reviews alone is not enough to summarize one's opinion. Therefore, in this Final Project built a system that can classify opinions on product reviews into positive and negative sentiments by utilizing the rating. The dataset used is Grocery and Gourmet Food from Amazon as much as 50,000 which will then be labeled using Labeling Methods Average and Binary. The classification of this opinion uses the approach of Supervised learning Algorithm Multinomial Na\u00efve Bayes. The result of this research shows that labeling using Method Average is suitable for processing Grocery and Gourmet Food Dataset and proves that the best ratio of feature selection usage is 20% succeed to produce 80.48% accuracy. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Improving the accuracy of fuzzy vault scheme in fingerprint biometric"
        ],
        "penulis":"Saputra, Joni;Sukarno, Parman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At present, authentication techniques using fingerprint biometrics have been widely used in various fields. This is because the authentication techniques using biometrics are safer and more comfortable than using traditional passwords. In order to realize this, a technique in the biometric cryptosystem is proposed in the research, called the fuzzy vault scheme. Although the fingerprint data in the form of minutiae can be protected with a fuzzy vault scheme compared to traditional authentication systems, it can reduce user convenience. Previous studies proposed a distance-based method in the fuzzy vault scheme. The distance-based method is proposed because it is no need to align and rotate the fingerprint image during registration or authentication. Then with the distance-based method also does not produce a helper data that can lead to information leakage that can be exploited by impostor. In the research, the distance-based method is proposed with several modifications, which are the minutiae filter and candidate points identification techniques. The previous method produces FRR 13.4375% and FAR 0.4515% and the proposed method produced FRR 8.9475% and FAR 0.3520%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At present, authentication techniques using fingerprint biometrics have been widely used in various fields. This is because the authentication techniques using biometrics are safer and more comfortable than using traditional passwords. In order to realize this, a technique in the biometric cryptosystem is proposed in the research, called the fuzzy vault scheme. Although the fingerprint data in the form of minutiae can be protected with a fuzzy vault scheme compared to traditional authentication systems, it can reduce user convenience. Previous studies proposed a distance-based method in the fuzzy vault scheme. The distance-based method is proposed because it is no need to align and rotate the fingerprint image during registration or authentication. Then with the distance-based method also does not produce a helper data that can lead to information leakage that can be exploited by impostor. In the research, the distance-based method is proposed with several modifications, which are the minutiae filter and candidate points identification techniques. The previous method produces FRR 13.4375% and FAR 0.4515% and the proposed method produced FRR 8.9475% and FAR 0.3520%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Recent development in electronic nose data processing for beef quality assessment"
        ],
        "penulis":"Sarno, Riyanarto;Wijaya, Dedy Rahman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Beef is kind of perishable food that easily to decay. Hence, a rapid system for beef quality assessment is needed to guarantee the quality of beef. In the last few years, electronic nose (e-nose) is developed for beef spoilage detection. In this paper, we discuss the challenges of e-nose application to beef quality assessment, especially in e-nose data processing. We also provide a summary of our previous studies that explains several methods to deal with gas sensor noise, sensor array optimization problem, beef quality classification, and prediction of the microbial population in beef sample. This paper might be useful for researchers and practitioners to understand the challenges and methods of e-nose data processing for beef quality assessment. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Beef is kind of perishable food that easily to decay. Hence, a rapid system for beef quality assessment is needed to guarantee the quality of beef. In the last few years, electronic nose (e-nose) is developed for beef spoilage detection. In this paper, we discuss the challenges of e-nose application to beef quality assessment, especially in e-nose data processing. We also provide a summary of our previous studies that explains several methods to deal with gas sensor noise, sensor array optimization problem, beef quality classification, and prediction of the microbial population in beef sample. This paper might be useful for researchers and practitioners to understand the challenges and methods of e-nose data processing for beef quality assessment. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Bit-parallelism score computation with multi integer weight"
        ],
        "penulis":"Setyorini;Kuspriyanto;Widyantoro, Dwi Hendratmo;Pancoro, Adi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Dynamic Programming (DP) is still the core algorithm in many biological analysis tools, especially similarity analysis. DP always promises optimal solutions, but as the size and number of sequences increase, time performance decreases. This makes various researches related to the improvement of time performance offered. Performance improvement is offered by adding process units that work together in parallel environments or reducing the accuracy by only calculating the input part. Bit-parallelism offers an increase in speed by changing the score matrix process unit to a larger process unit, namely word. Then this word unit will be processed in parallel like word processing on a computer system. Bit-parallelism has been successfully applied to cases with simple weights such as LCS and Edit Distance. Applications in more complex cases, namely with integer weights also exist, but still assume an integer weight for match representation. In the case of protein alignment where there is more than one integer value to represent the match of the residual pair, this solution cannot be applied directly. This paper presents a preliminary research on how to formulate a computational algorithm score bitparallelism with multi-integer weights. The solution offered is the development of General Integer scoring, by applying functional multi tables. The results show that the algorithm is able to obtain the same score matrix as the DP score matrix, with computing O(m), m is size of the sequence, and O(b) space where b is the range of integer set weights. \u00a9 2019, School of Electrical Engineering and Informatics. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Dynamic Programming (DP) is still the core algorithm in many biological analysis tools, especially similarity analysis. DP always promises optimal solutions, but as the size and number of sequences increase, time performance decreases. This makes various researches related to the improvement of time performance offered. Performance improvement is offered by adding process units that work together in parallel environments or reducing the accuracy by only calculating the input part. Bit-parallelism offers an increase in speed by changing the score matrix process unit to a larger process unit, namely word. Then this word unit will be processed in parallel like word processing on a computer system. Bit-parallelism has been successfully applied to cases with simple weights such as LCS and Edit Distance. Applications in more complex cases, namely with integer weights also exist, but still assume an integer weight for match representation. In the case of protein alignment where there is more than one integer value to represent the match of the residual pair, this solution cannot be applied directly. This paper presents a preliminary research on how to formulate a computational algorithm score bitparallelism with multi-integer weights. The solution offered is the development of General Integer scoring, by applying functional multi tables. The results show that the algorithm is able to obtain the same score matrix as the DP score matrix, with computing O(m), m is size of the sequence, and O(b) space where b is the range of integer set weights. \u00a9 2019, School of Electrical Engineering and Informatics. All rights reserved."
        ]
    },
    {
        "judul":[
            "Study on Multilayer em Wave Absorber Composed of Metasurface for X-band Application"
        ],
        "penulis":"Syihabuddin, Budi;Gunawan, Arief Hamdani;Effendi, Mohammad Ridwan;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In recent years, researches on electromagnetics (EM) wave absorber have been intensively investigated for numerous applications. One of essential issues in the EM wave absorber is the deficiency in its performance particularly bandwidth and absorption characteristics. In this paper, a multilayer EM wave absorber composed of metasurface is studied for X-band application. The utilization of metasurface and multilayer structures is aimed to enhance the characteristics of absorber in bandwidth and absorption performances. The structure of metasurface is configured by combining split ring resonator (SRR) and narrow thin strip deployed on different layers of 0.8mm thick FR4 epoxy dielectric substrate. The proposed EM wave absorber is characterized through its unit cell with the dimension of 3.80mm \u00d7 3.80mm. Some attempts by inserting another layer with varied thickness between the SRR layer and the narrow thin strip layer is performed to investigate the absorber characteristics. The characterization result shows that the insertion of another layer could improve the characteristics of proposed EM wave absorber. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In recent years, researches on electromagnetics (EM) wave absorber have been intensively investigated for numerous applications. One of essential issues in the EM wave absorber is the deficiency in its performance particularly bandwidth and absorption characteristics. In this paper, a multilayer EM wave absorber composed of metasurface is studied for X-band application. The utilization of metasurface and multilayer structures is aimed to enhance the characteristics of absorber in bandwidth and absorption performances. The structure of metasurface is configured by combining split ring resonator (SRR) and narrow thin strip deployed on different layers of 0.8mm thick FR4 epoxy dielectric substrate. The proposed EM wave absorber is characterized through its unit cell with the dimension of 3.80mm \u00d7 3.80mm. Some attempts by inserting another layer with varied thickness between the SRR layer and the narrow thin strip layer is performed to investigate the absorber characteristics. The characterization result shows that the insertion of another layer could improve the characteristics of proposed EM wave absorber. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Experimental process of data laboratory recruitment using C4.5 algorithm"
        ],
        "penulis":"Aprilia, Yasella Dina;Latuconsina, Roswan;Purboyo, Tito Waluyo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Data processing use C4.5 algorithm with Excel is useful to speed up manual calculations. Use of MS. Excel to help users to learn in understanding data mining algorithms before using programming languages like Java, C ++, R programming, etc. Data train is the data recruitment assistant laboratory. This data has several stages: file collection interview, written test, coding test internship test, teaching test, a coding test for 12 h. Based on the phase stage will be done with the calculation C4.5 algorithm. Based on the results of this experiment will form a decision tree. \u00a9 Medwell Journals, 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data processing use C4.5 algorithm with Excel is useful to speed up manual calculations. Use of MS. Excel to help users to learn in understanding data mining algorithms before using programming languages like Java, C ++, R programming, etc. Data train is the data recruitment assistant laboratory. This data has several stages: file collection interview, written test, coding test internship test, teaching test, a coding test for 12 h. Based on the phase stage will be done with the calculation C4.5 algorithm. Based on the results of this experiment will form a decision tree. \u00a9 Medwell Journals, 2019."
        ]
    },
    {
        "judul":[
            "Lelang.in Website as Supply Chain Management and Scheduling Using Simulated Annealing for Fisheries Commodities Distribution"
        ],
        "penulis":"Pradipta, Sarah Tyas;Sari, Fourriska Mukti Nuryasinta;Program, Eva Wati Asri Mawaddah;Darnoto, Brian Rizqi Paradisiaca;Bukhori, Saiful;Dewi, Fitriyana;Putra, Januar Adi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The gap that occurs between fishermen and the last-hand customers causes a low level of economic Indonesian fishermen. Fish purchased from fishermen always get a low price while the selling price in shops, supermarkets or modern markets is higher or far from the price of fishermen. This is quite beneficial for the large fisheries industry sector but not for small industry sector fishermen. The use of the Lelang.in system is expected to provide a high purchase price to fishermen while the selling price to customers is based on market prices. By using the Simulated Annealing Algorithm, it is expected that it can also help in arranging scheduling that occurs in a particular fishery company or factory. So the possibility of not doing raw fish can be overcome quickly by processing. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The gap that occurs between fishermen and the last-hand customers causes a low level of economic Indonesian fishermen. Fish purchased from fishermen always get a low price while the selling price in shops, supermarkets or modern markets is higher or far from the price of fishermen. This is quite beneficial for the large fisheries industry sector but not for small industry sector fishermen. The use of the Lelang.in system is expected to provide a high purchase price to fishermen while the selling price to customers is based on market prices. By using the Simulated Annealing Algorithm, it is expected that it can also help in arranging scheduling that occurs in a particular fishery company or factory. So the possibility of not doing raw fish can be overcome quickly by processing. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Techno-economic analysis of narrowband IoT (NB-IoT) deployment for smart metering"
        ],
        "penulis":"Hidayati, Amriane;Reza, Muhamad;Adriansyah, Nachwan Mufti;Nashiruddin, Muhammad Imam;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The Internet of things (IoT) wireless network are evolving to help meet the needs of a wide variety of connected devices. 3GPP has introduced a narrowband system based on Long Term Evolution (LTE) named Narrowband IoT (NB-IoT). It provides low-cost, wide coverage, long battery life, and support massive devices. The smart meter has become one of the main element in smart grids that potential to use NB-IoT technology and categorized into massive IoT because of its characteristics requirements. This paper aims to provide a techno-economic analysis of NB-IoT deployment for smart metering. The analysis results show that smart metering deployment will be feasible if there are consumers involvement considered. In addition, based on sensitivity analysis results, material costs become the most critical element to bring successful deployment. Its variations and slight changes have a significant impact on the overall Net Present Value (NPV).  \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Internet of things (IoT) wireless network are evolving to help meet the needs of a wide variety of connected devices. 3GPP has introduced a narrowband system based on Long Term Evolution (LTE) named Narrowband IoT (NB-IoT). It provides low-cost, wide coverage, long battery life, and support massive devices. The smart meter has become one of the main element in smart grids that potential to use NB-IoT technology and categorized into massive IoT because of its characteristics requirements. This paper aims to provide a techno-economic analysis of NB-IoT deployment for smart metering. The analysis results show that smart metering deployment will be feasible if there are consumers involvement considered. In addition, based on sensitivity analysis results, material costs become the most critical element to bring successful deployment. Its variations and slight changes have a significant impact on the overall Net Present Value (NPV).  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Application of Taguchi Method for Optimization of Parameter in Improving Soybean Cracking Process on Dry Process of tempeh Production"
        ],
        "penulis":"Anugraha R.A.;Wiraditya M.Y.;Iqbal M.;Darmawan N.M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Taguchi method is a Design of Experiment approach for parameter optimization of a process. The purpose of this study is to determine the optimum parameters and the most influential parameters in the process of soybean cracking in the dry process of tempeh production. In the process of cracking the dry soybeans found a defect of 14.5%. after applying the Taguchi method and obtaining the optimum parameters, the defect on the dry process of cracking the dry soybeans is reduced to 6.6%. Determination of parameters and levels, objective functions, orthogonal array, signal-to-noise ratio, and analysis of variance (ANOVA) will be done in this study to improve the performance of the soy-cracking process. In this study there are three parameters used in conducting experiments with Taguchi method, three parameters namely distance between stones, hopper outlet diameter, and sun-drying duration. The results of this study are: distance between stones with setting optimum 1mm and percentage contribution 13%; hopper outlet diameter with setting optimum 25mm and percentage contribution 85%; and sun-drying duration with drying optimum 1 day and percentage contribution 2%. the most influential parameter is the hopper outlet diameter in the soybean cracking process, as it determines the soybean discharge that goes into the cracking phase. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Taguchi method is a Design of Experiment approach for parameter optimization of a process. The purpose of this study is to determine the optimum parameters and the most influential parameters in the process of soybean cracking in the dry process of tempeh production. In the process of cracking the dry soybeans found a defect of 14.5%. after applying the Taguchi method and obtaining the optimum parameters, the defect on the dry process of cracking the dry soybeans is reduced to 6.6%. Determination of parameters and levels, objective functions, orthogonal array, signal-to-noise ratio, and analysis of variance (ANOVA) will be done in this study to improve the performance of the soy-cracking process. In this study there are three parameters used in conducting experiments with Taguchi method, three parameters namely distance between stones, hopper outlet diameter, and sun-drying duration. The results of this study are: distance between stones with setting optimum 1mm and percentage contribution 13%; hopper outlet diameter with setting optimum 25mm and percentage contribution 85%; and sun-drying duration with drying optimum 1 day and percentage contribution 2%. the most influential parameter is the hopper outlet diameter in the soybean cracking process, as it determines the soybean discharge that goes into the cracking phase. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Higher Education Clustering in Indonesia by using k-means and Geographical Similarity Methods"
        ],
        "penulis":"Kusuma, Purba Daru;Rachmaningrum, Nilla;Save all to author list",
        "tahun":2019,
        "sdgs":[
            ": Diverse quality and equality in higher education has been concerned by government of Indonesia. It is because these aspects have positive correlation with the country development and competitiveness. Meanwhile, improvement policy should be supported by better perspective and mapping about the condition of the higher education in this country. Although, ministry of research and higher education of Indonesia has published statistical data, the analysis of it is veiy limited. Based on this problem, we use clustering method to analyze this higher education statistic data, so that, new perspective and understanding can be explored. In this research, we use two computational methods: k-means and geographical similarity, so that, the analysis can be enriched. In this research, we also compare the condition in private institution and public institution. Result shows that in some aspects, there is disparity between private institution and public institution. Meanwhile in some aspect, there is disparity between Java Region and other regions in Indonesia \u00a9 Medwell Journals, 2019",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            ": Diverse quality and equality in higher education has been concerned by government of Indonesia. It is because these aspects have positive correlation with the country development and competitiveness. Meanwhile, improvement policy should be supported by better perspective and mapping about the condition of the higher education in this country. Although, ministry of research and higher education of Indonesia has published statistical data, the analysis of it is veiy limited. Based on this problem, we use clustering method to analyze this higher education statistic data, so that, new perspective and understanding can be explored. In this research, we use two computational methods: k-means and geographical similarity, so that, the analysis can be enriched. In this research, we also compare the condition in private institution and public institution. Result shows that in some aspects, there is disparity between private institution and public institution. Meanwhile in some aspect, there is disparity between Java Region and other regions in Indonesia \u00a9 Medwell Journals, 2019"
        ]
    },
    {
        "judul":[
            "Image Processing Schemes for Improving Needle Visibility in USG Image Using Curve Transducer"
        ],
        "penulis":"Septyvergy, Arkanty;Susanti, Hesty;Suprijanto;Juliastuti, Endang;Nadhira, Vebi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In ultrasound (US)-guided needle insertion, the needle should be detected precisely to avoid damage to the tissue. Due to the inconsistent needle visibility, it is difficult to determine the needle position. In this work, a post-processing scheme is developed to improve needle visibility. The proposed scheme starts with raw US image rotation to transform the needle area in the US image on normalization position. Next, selecting nxm (ROI) of the square area that covers needle in normalization US image. Using line scanning, the ROI viewed as m column of a set of pixel value in each column ROI {Xnm}. A linear derivative in each {Xnm} applied to estimate points that estimate needle position in the ROI. Outlier points are removed by a specific threshold value. The remaining points of with m of vector set {Xnm} that related with needle position is converted to a line curve by linear interpolation. The developed scheme has a success rate by 92% to visualize by overlay a line curve to needle area in US image if no high speckle noise in the US image. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In ultrasound (US)-guided needle insertion, the needle should be detected precisely to avoid damage to the tissue. Due to the inconsistent needle visibility, it is difficult to determine the needle position. In this work, a post-processing scheme is developed to improve needle visibility. The proposed scheme starts with raw US image rotation to transform the needle area in the US image on normalization position. Next, selecting nxm (ROI) of the square area that covers needle in normalization US image. Using line scanning, the ROI viewed as m column of a set of pixel value in each column ROI {Xnm}. A linear derivative in each {Xnm} applied to estimate points that estimate needle position in the ROI. Outlier points are removed by a specific threshold value. The remaining points of with m of vector set {Xnm} that related with needle position is converted to a line curve by linear interpolation. The developed scheme has a success rate by 92% to visualize by overlay a line curve to needle area in US image if no high speckle noise in the US image. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Development of rule-based feature extraction in multi-label text classification"
        ],
        "penulis":"Mediamer, Gugun;Adiwijaya, adiwijaya@telkomuniversity.ac.id;Faraby, Said Al;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hadith is the second main guidelines after the Holy Quran in the Islamic religion, which was revealed through the Messenger of Allah. Today, Hadith can classified by more than one class such as advice class, prohibited, and information to facilitate readers of Hadith in filtering the appropriate classes for each Hadith of Rasulullah SAW. In the course of research, there are many kinds of data involved in a text classification study. Therefore, special handling that fit with the characteristics of certain data is required. This study investigates the handling of multi-label data-Hadith Bukhari in Indonesian translation-focusing on feature extraction, feature weighted, and preprocessing methods. This study uses a rule-based feature extraction combined with several types of preprocessing along with three types of feature-weighted methods: TF-IDF, Word2vec, and Word2vec weighted with TF-IDF, the five preprocessing stages in this research: Case Folding, Tokenization, Remove Punctuation, Stopword Removal, and Stemming. From the 13 experiments conducted in this study consist of 2000 hadiths, it was found that the best performance for multi-label classification of Hadith data produced by the combination of the proposed rule-based feature extraction, Word2vec feature weighted method, and without using Stemming and Stopword Removal in the preprocessing phase. The Hamming Loss value obtained from this combination was 0.0623. The results show that our rule-based feature extraction method better than baseline method. \u00a9 2019 Tech Science Press.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hadith is the second main guidelines after the Holy Quran in the Islamic religion, which was revealed through the Messenger of Allah. Today, Hadith can classified by more than one class such as advice class, prohibited, and information to facilitate readers of Hadith in filtering the appropriate classes for each Hadith of Rasulullah SAW. In the course of research, there are many kinds of data involved in a text classification study. Therefore, special handling that fit with the characteristics of certain data is required. This study investigates the handling of multi-label data-Hadith Bukhari in Indonesian translation-focusing on feature extraction, feature weighted, and preprocessing methods. This study uses a rule-based feature extraction combined with several types of preprocessing along with three types of feature-weighted methods: TF-IDF, Word2vec, and Word2vec weighted with TF-IDF, the five preprocessing stages in this research: Case Folding, Tokenization, Remove Punctuation, Stopword Removal, and Stemming. From the 13 experiments conducted in this study consist of 2000 hadiths, it was found that the best performance for multi-label classification of Hadith data produced by the combination of the proposed rule-based feature extraction, Word2vec feature weighted method, and without using Stemming and Stopword Removal in the preprocessing phase. The Hamming Loss value obtained from this combination was 0.0623. The results show that our rule-based feature extraction method better than baseline method. \u00a9 2019 Tech Science Press."
        ]
    },
    {
        "judul":[
            "Dual-polarized Wideband Horn Antenna with Lower Frequency Extension for Microwave Imaging Application"
        ],
        "penulis":"Oktafiarri, Falin;Syihabuddin, Budi;Hamid, Effrina Yanti;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Horn antenna is frequently used for microwave imaging since its characteristics satisfied the required specification. However, its dimension is too large for low frequency usage and commonly produces single polarization. In this paper, a dual-polarized wideband horn antenna with lower frequency extension is investigated for microwave imaging application. This design is supposed to accommodate the requirements of high resolution. The usage of ridges and dielectric inserted into the horn is proposed to produce dual polarization of the antenna and extend the bandwidth in low frequency. The characterization results show that the proposed antenna yields reflection coefficient less than -10 dB, isolation between ports below - 25 dB and sidelobe level better than -20dB at the frequency range of 2.5-14GHz for each polarization suitable for the desired application. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Horn antenna is frequently used for microwave imaging since its characteristics satisfied the required specification. However, its dimension is too large for low frequency usage and commonly produces single polarization. In this paper, a dual-polarized wideband horn antenna with lower frequency extension is investigated for microwave imaging application. This design is supposed to accommodate the requirements of high resolution. The usage of ridges and dielectric inserted into the horn is proposed to produce dual polarization of the antenna and extend the bandwidth in low frequency. The characterization results show that the proposed antenna yields reflection coefficient less than -10 dB, isolation between ports below - 25 dB and sidelobe level better than -20dB at the frequency range of 2.5-14GHz for each polarization suitable for the desired application. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Incorporating syllabification points into a model of grapheme-to-phoneme conversion"
        ],
        "penulis":"Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A model to convert a grapheme into a phoneme (G2P) is crucial in the natural language processing area. In general, it is developed using a probabilistic-based data-driven approach and directly applied to a sequence of graphemes with no other information. Important research shows that incorporating information of syllabification point is capable of improving a probabilistic-based English G2P. However, the information should be accurately provided by a perfect orthographic syllabification. Some noises or errors of syllabification significantly reduce the G2P performance. In this paper, incorporation of syllabification points into a probabilistic-based G2P model for Bahasa Indonesia is investigated. This information is important since Bahasa Indonesia is richer than English in terms of syllables. A 5-fold cross-validating on 50 k words shows that the incorporation of syllabification points significantly improves the performance of G2P model, where the phoneme error rate (PER) can be relatively reduced by 10.75%. This PER is much lower than the G2P model based on an inductive learning algorithm. An important contribution of this research is that the proposed G2P model is quite robust to syllabification errors. A syllable error rate (SER) of 2.5% that comes from an orthographic syllabification model just slightly increases the PER of the proposed G2P model from 0.83% to be 0.90%. A higher SER up to 10% just increase the PER to be 1.14%. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A model to convert a grapheme into a phoneme (G2P) is crucial in the natural language processing area. In general, it is developed using a probabilistic-based data-driven approach and directly applied to a sequence of graphemes with no other information. Important research shows that incorporating information of syllabification point is capable of improving a probabilistic-based English G2P. However, the information should be accurately provided by a perfect orthographic syllabification. Some noises or errors of syllabification significantly reduce the G2P performance. In this paper, incorporation of syllabification points into a probabilistic-based G2P model for Bahasa Indonesia is investigated. This information is important since Bahasa Indonesia is richer than English in terms of syllables. A 5-fold cross-validating on 50 k words shows that the incorporation of syllabification points significantly improves the performance of G2P model, where the phoneme error rate (PER) can be relatively reduced by 10.75%. This PER is much lower than the G2P model based on an inductive learning algorithm. An important contribution of this research is that the proposed G2P model is quite robust to syllabification errors. A syllable error rate (SER) of 2.5% that comes from an orthographic syllabification model just slightly increases the PER of the proposed G2P model from 0.83% to be 0.90%. A higher SER up to 10% just increase the PER to be 1.14%. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "Development of Test Environment Platform for IMA using COTS components"
        ],
        "penulis":"Wijiutomo, Catur Wirawan;Trilaksono, Bambang Riyanto;Kistijantoro, Achmad Imam;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Avionics software is playing a bigger role in future aircraft. The dilemma is to have the developer grasp the idea of modern avionics based on IMA (integrate Modular Avionics) to use software component re-use on shared resources. in this paper, we propose a test environment for IMA software development that resembles the nature of IMA using a combination of COTS (Commercial of the shelf) hardware and software. We develop AFDX switch with Linux-based router that can build custom ethernet packet that resembles AFDX. We also consider LXC, a Linux container, handled with custom algorithm scheme to control CPU and memory allocation for each container to resemble ARINC 653 standard. The test environment is built as similar as IMA as whole system, as this is not an ideal IMA there is drawback in data communication. That the average jitter for data communication still does not meet ARINC 664 requirement. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Avionics software is playing a bigger role in future aircraft. The dilemma is to have the developer grasp the idea of modern avionics based on IMA (integrate Modular Avionics) to use software component re-use on shared resources. in this paper, we propose a test environment for IMA software development that resembles the nature of IMA using a combination of COTS (Commercial of the shelf) hardware and software. We develop AFDX switch with Linux-based router that can build custom ethernet packet that resembles AFDX. We also consider LXC, a Linux container, handled with custom algorithm scheme to control CPU and memory allocation for each container to resemble ARINC 653 standard. The test environment is built as similar as IMA as whole system, as this is not an ideal IMA there is drawback in data communication. That the average jitter for data communication still does not meet ARINC 664 requirement. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The causality effect on vector autoregressive model: The case for rainfall forecasting"
        ],
        "penulis":"Rohmawati, Aniq A.;Gunawan P.H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In recent decades, a stochastics modeling of weather prediction is gaining popularity among government and researchers. A devastating weather may have profound environmental, human and\/or financial loss. It is a familiar fact that the series process over a fixed time horizon following historical time series model. A Vector Autoregressive (VAR) is one of time series models that explain current and past values of the multivariate variables as a linear model. Moreover, the instantaneous interaction between two or more variables deal with a causal relations between those variables. In particular application, observing the response of one variable to an impulse in the other is interesting, allowing a number of further variables as well. The explanation of impulse response is essential for a structural modeling, we explore a causality concept well known as Granger-Causality (G-causes) test. Thus, we shall examine the causal relations between rainfall and temperature, addressed by constructing and forecasting simultaneously bivariate VAR model. Henceforth, we consider the VAR(2) based on a parsimonious principle and Akaike Information Criteria (AIC). Evidently, the result present an exogenous shock of temperature has an effect for rainfall, we called temperature is \"G-causes\" for rainfall. Thus, we argue a temperature do Granger-cause for rainfall, and a vice versa is not properly true. A VAR model provide deeper and more accurate insight into rainfall prediction, shown by an RMSE 0.0021. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In recent decades, a stochastics modeling of weather prediction is gaining popularity among government and researchers. A devastating weather may have profound environmental, human and\/or financial loss. It is a familiar fact that the series process over a fixed time horizon following historical time series model. A Vector Autoregressive (VAR) is one of time series models that explain current and past values of the multivariate variables as a linear model. Moreover, the instantaneous interaction between two or more variables deal with a causal relations between those variables. In particular application, observing the response of one variable to an impulse in the other is interesting, allowing a number of further variables as well. The explanation of impulse response is essential for a structural modeling, we explore a causality concept well known as Granger-Causality (G-causes) test. Thus, we shall examine the causal relations between rainfall and temperature, addressed by constructing and forecasting simultaneously bivariate VAR model. Henceforth, we consider the VAR(2) based on a parsimonious principle and Akaike Information Criteria (AIC). Evidently, the result present an exogenous shock of temperature has an effect for rainfall, we called temperature is \"G-causes\" for rainfall. Thus, we argue a temperature do Granger-cause for rainfall, and a vice versa is not properly true. A VAR model provide deeper and more accurate insight into rainfall prediction, shown by an RMSE 0.0021. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Classification of premature ventricular contraction based on ECG signal using multiorder r\u00e9nyi entropy"
        ],
        "penulis":"Rizal, Achmad;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electrocardiogram (ECG) signals are commonly used to analyze the heart abnormalities. Many researchers used this method due to the simplicity, inexpensive, and the non-invasiveness of the devices. The basic concept of ECG is by measuring the electrical activity of the heart using non-invasive electrodes placed in the body. Premature ventricular contraction (PVC) is one of the abnormalities of the human heart which produce extra heartbeat that started in the two lower ventricles. This 'additional' heartbeat disrupts the regular heart rhythm. Early detection for PVC is essential, so in this research, we classify the PVC from ECG signal by using multi-order R\u00e9nyi entropy as the feature extraction, and SVM as the classifier. We search for the optimum feature number needed for the detection system. Our proposed method showed a promising result, because we only use one feature extraction parameter, that is R\u00e9nyi entropy, as the only feature which calculated in the different orders, and this made the computing complexity low. We got 95.8% of accuracy using six characteristics of entropy for PVC and normal ECG classification. Our proposed method was simple, low computation and need fewer number of features. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electrocardiogram (ECG) signals are commonly used to analyze the heart abnormalities. Many researchers used this method due to the simplicity, inexpensive, and the non-invasiveness of the devices. The basic concept of ECG is by measuring the electrical activity of the heart using non-invasive electrodes placed in the body. Premature ventricular contraction (PVC) is one of the abnormalities of the human heart which produce extra heartbeat that started in the two lower ventricles. This 'additional' heartbeat disrupts the regular heart rhythm. Early detection for PVC is essential, so in this research, we classify the PVC from ECG signal by using multi-order R\u00e9nyi entropy as the feature extraction, and SVM as the classifier. We search for the optimum feature number needed for the detection system. Our proposed method showed a promising result, because we only use one feature extraction parameter, that is R\u00e9nyi entropy, as the only feature which calculated in the different orders, and this made the computing complexity low. We got 95.8% of accuracy using six characteristics of entropy for PVC and normal ECG classification. Our proposed method was simple, low computation and need fewer number of features. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of transient signal using hilbert-huang transform for chatter monitoring in turning process"
        ],
        "penulis":"Susanto, Agus;Azka, Muizuddin;Yamada, Keiji;Sekiya, Katsuhiko;Novia, Putri;Tanaka, Ryutaro;Prasetio, Murman Dwi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Machining of railway components is necessary to be controlled because this process requires precise accuracy and high surface finish of the final product. However, chatter vibration can be an obstacle that leads to negative effects. One of the ways for chatter monitoring in machining is by vibration signal analysis. In this paper, transient vibration signals are analyzed using Hilbert-Huang (HHT) transform and compare to STFT. The results show the excellence of HHT for analysis transient signals for chatter vibration identification correctly in turning process. Frequency transition between frequency of rotational spindle and chatter frequency is well captured using HHT, but STFT is trouble for capturing that one. Besides, the EMD (empirical mode decomposition) process of HHT separated out non-chatter from chatter signals. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Machining of railway components is necessary to be controlled because this process requires precise accuracy and high surface finish of the final product. However, chatter vibration can be an obstacle that leads to negative effects. One of the ways for chatter monitoring in machining is by vibration signal analysis. In this paper, transient vibration signals are analyzed using Hilbert-Huang (HHT) transform and compare to STFT. The results show the excellence of HHT for analysis transient signals for chatter vibration identification correctly in turning process. Frequency transition between frequency of rotational spindle and chatter frequency is well captured using HHT, but STFT is trouble for capturing that one. Besides, the EMD (empirical mode decomposition) process of HHT separated out non-chatter from chatter signals. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Simple Rateless Codes Based on 5G New Radio QC-LDPC Codes for Dynamic Networks"
        ],
        "penulis":"Fitri, Arini;Anwar, Khoirul;Saputri, Desti Madya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The fifth telecommunications generation new radio (5G-NR) uses quasi-cyclic low density parity check (QC-LDPC) codes as the channel coding for data transmission, where the codes are based on Raptor coding principle. The advantages of QC-LDPC codes inspire this paper to propose simple and rateless QC-LDPC codes, called simple rateless QC-LDPC (SR-QCLDPC) codes, for dynamic networks communication systems, where simplicity is of importance to minimize the power consumption. Although the coding is simple, the codes should provide high performance coding schemes to support various channel conditions, where a rateless coding scheme is one of the solutions. We design the proposed SR-QC-LDPC codes by removing the high degrees of check nodes and variable nodes in 5G-NR QC-LDPC codes to make the codes are both reduced in size and simpler in computation. We also adjust the fraction of the degree distributions of SR-QC-LDPC codes, evaluate the gap using extrinsic information transfer (EXIT) chart, and investigate the bit-error-rate (BER) performances under additive white Gaussian noise (AWGN) and frequency-flat Rayleigh fading channels using a series of computer simulations. We found that the proposed codes are good and comparable to the performance of original 5G-NR QC-LDPC codes given the equal codes length and complexity. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The fifth telecommunications generation new radio (5G-NR) uses quasi-cyclic low density parity check (QC-LDPC) codes as the channel coding for data transmission, where the codes are based on Raptor coding principle. The advantages of QC-LDPC codes inspire this paper to propose simple and rateless QC-LDPC codes, called simple rateless QC-LDPC (SR-QCLDPC) codes, for dynamic networks communication systems, where simplicity is of importance to minimize the power consumption. Although the coding is simple, the codes should provide high performance coding schemes to support various channel conditions, where a rateless coding scheme is one of the solutions. We design the proposed SR-QC-LDPC codes by removing the high degrees of check nodes and variable nodes in 5G-NR QC-LDPC codes to make the codes are both reduced in size and simpler in computation. We also adjust the fraction of the degree distributions of SR-QC-LDPC codes, evaluate the gap using extrinsic information transfer (EXIT) chart, and investigate the bit-error-rate (BER) performances under additive white Gaussian noise (AWGN) and frequency-flat Rayleigh fading channels using a series of computer simulations. We found that the proposed codes are good and comparable to the performance of original 5G-NR QC-LDPC codes given the equal codes length and complexity. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Integrated Subsurface Temperature Modeling beneath Mt. Lawu and Mt. Muriah in the Northeast Java Basin, Indonesia"
        ],
        "penulis":"Nurhandoko, Bagus Endar B.;Kurniadi, Rizal;Susilowati S.;Triyoso, Kaswandhi;Widowati, Sri;Asmara Hadi, M. Rizka;Abda, M. Rizal;Martha, Rio K.;Fatiah, Elfa;Rizal Komara, Insan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The subsurface temperature has many impacts on geological phenomena such as hydrocarbon generation, geothermal energy, mineralization, and geological hazards. The Northeast Java Basin has various interesting phenomena, such as many oil fields, active faults, mud eruptions, and some active and dormant volcanoes. We measured temperature data from tens of wells along a 130 km survey line with an average spacing of 5 km. We also measured the thermal conductivity of rocks of various lithologies along the survey line to provide geothermal heat flow data. We propose integrated modeling for profiling the subsurface temperature beneath the survey line from Mt. Lawu to Mt. Muriah in the Northeast Java Basin. The modeling of subsurface temperature integrates various input data such as a thermal conductivity model, surface temperature, gradient temperature, a geological model, and geothermal heat flow. The thermal conductivity model considers the subsurface geological model. The temperature modeling uses the finite difference of Fourier's law, with an input subsurface thermal conductivity model, geothermal heat flow, and surface temperature. The subsurface temperature profile along with survey line shows some interesting anomalies which correlate with either subsurface volcanic activity or the impact of fault activity. \u00a9 2019 Bagus Endar B. Nurhandoko et al.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Sustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The subsurface temperature has many impacts on geological phenomena such as hydrocarbon generation, geothermal energy, mineralization, and geological hazards. The Northeast Java Basin has various interesting phenomena, such as many oil fields, active faults, mud eruptions, and some active and dormant volcanoes. We measured temperature data from tens of wells along a 130 km survey line with an average spacing of 5 km. We also measured the thermal conductivity of rocks of various lithologies along the survey line to provide geothermal heat flow data. We propose integrated modeling for profiling the subsurface temperature beneath the survey line from Mt. Lawu to Mt. Muriah in the Northeast Java Basin. The modeling of subsurface temperature integrates various input data such as a thermal conductivity model, surface temperature, gradient temperature, a geological model, and geothermal heat flow. The thermal conductivity model considers the subsurface geological model. The temperature modeling uses the finite difference of Fourier's law, with an input subsurface thermal conductivity model, geothermal heat flow, and surface temperature. The subsurface temperature profile along with survey line shows some interesting anomalies which correlate with either subsurface volcanic activity or the impact of fault activity. \u00a9 2019 Bagus Endar B. Nurhandoko et al."
        ]
    },
    {
        "judul":[
            "Smart parking area management system for the disabled using IoT and mobile application"
        ],
        "penulis":"Fikri, Rifqi Muhammad;Hwang, Mintae;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "There are a lot of cases of non-disabled drivers regularly using spaces for people with disability. They often get away with it too unless an authority happens to check while their vehicle is parked there. This project presents a reserve-based parking system in securing the parking spaces for the disabled. In this proposed system a special parking area for disabled will be introduced using current technology such as the internet of things (IoT), and mobile application as a Smart City concept initiatives. By using the reservation system and alarm system, violation of disabled parking system can be avoided. In order to separate normal people and disabled people, we use identification method by using NFC tag reader. After the successful identification process, the user can make a reservation and choose the disabled parking space with their mobile application. The system also uses an alarm system to warn the non-disabled person who wants to park in the disabled parking spot. The implementation of the system, expected to simplify the operations of parking systems, as well as improve the quality of life of the disabled person. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "There are a lot of cases of non-disabled drivers regularly using spaces for people with disability. They often get away with it too unless an authority happens to check while their vehicle is parked there. This project presents a reserve-based parking system in securing the parking spaces for the disabled. In this proposed system a special parking area for disabled will be introduced using current technology such as the internet of things (IoT), and mobile application as a Smart City concept initiatives. By using the reservation system and alarm system, violation of disabled parking system can be avoided. In order to separate normal people and disabled people, we use identification method by using NFC tag reader. After the successful identification process, the user can make a reservation and choose the disabled parking space with their mobile application. The system also uses an alarm system to warn the non-disabled person who wants to park in the disabled parking spot. The implementation of the system, expected to simplify the operations of parking systems, as well as improve the quality of life of the disabled person. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Narrator's name recognition with support vector machine for indexing Indonesian hadith translations"
        ],
        "penulis":"Yusup, Fajar Achmad;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The narrator's name in the Hadith is one of the most important components in determining the validity of a hadith, but with the large number of Hadiths that exist, causing the process of determining the validity of a Hadith manually becomes difficult, especially in the Indonesian Hadith translation. Named Entity Recognition (NER) is a method that aims to find entities in a text document, in this case the entity includes the name of the person, location, organization, etc. This study will discuss the implementation of the Named Entity Recognition to the Indonesian translation of the Hadith collection to find the names of narrators from each Hadith. In this study 200 Hadiths from 9 different books consisting of 31010 tokens and 2241 narrator name entities will be used as datasets. Because of the variety of entity forms and the amount of data used, this study will use a supervised-learning approach, and to maximize performance from the NER system, Support Vector Machine (SVM) is chosen as a classifier model that is known to have good generalization capabilities in classifying data and ability to deal with high-dimensional data. Some combinations of test scenarios on the NER model showed the highest F-1 results of 0.9 with training data totaling 140 Hadiths consisting of 1564 entities and testing 60 Hadiths consisting of 677 entities. The narrator name produced by the NER system will then be used as an index of the Hadiths that have been narrated by the narrator using the Inverted Index method. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The narrator's name in the Hadith is one of the most important components in determining the validity of a hadith, but with the large number of Hadiths that exist, causing the process of determining the validity of a Hadith manually becomes difficult, especially in the Indonesian Hadith translation. Named Entity Recognition (NER) is a method that aims to find entities in a text document, in this case the entity includes the name of the person, location, organization, etc. This study will discuss the implementation of the Named Entity Recognition to the Indonesian translation of the Hadith collection to find the names of narrators from each Hadith. In this study 200 Hadiths from 9 different books consisting of 31010 tokens and 2241 narrator name entities will be used as datasets. Because of the variety of entity forms and the amount of data used, this study will use a supervised-learning approach, and to maximize performance from the NER system, Support Vector Machine (SVM) is chosen as a classifier model that is known to have good generalization capabilities in classifying data and ability to deal with high-dimensional data. Some combinations of test scenarios on the NER model showed the highest F-1 results of 0.9 with training data totaling 140 Hadiths consisting of 1564 entities and testing 60 Hadiths consisting of 677 entities. The narrator name produced by the NER system will then be used as an index of the Hadiths that have been narrated by the narrator using the Inverted Index method. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "Degree Level of Publicness Through Meaning of Public Sphere in Bandung City, West Java, Indonesia"
        ],
        "penulis":"Friestya Asharsinyo, Doddy;Irma Maulina Hanafiah, Ully;Mustafa, Muhizam;Hafizal Mohd Isa, Mohd;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Bandung city public area at this time is experiencing a rapid growth due to economic growth and the influence of globalization. The development of public spaces that tend to be limited to the people who live in them, makes it difficult for the public to enter the area of its public sphere. Public sphere are formed based on the economic, political, cultural, developmental, and changes that occur in the area of today's public sphere, making it limited and inaccessible to the public at large. This is caused by the hierarchy of public space formed by the changes of the functions, forms, and meanings. This study focused on the relationship between form, function, and meaning of public sphere to the degree level of public spaces of the city of Bandung. The purpose of this study is to reveal all the relationships that exist between the concepts of public space and its influence on the degree level of publicness in the space of the city of Bandung in the context of its change. This research is descriptive-analytical and interpretive based on structuralist approach and empirical evidence obtained from study cases. This approach is used to read public sphere in Bandung's urban spaces to get a reference to the interpretation of relationships from an empirical condition. The degree level and its meaning in Alun-alun Bandung Square with surrounding buildings has been changed and has blocked the accessibility to some buildings and their facades. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Bandung city public area at this time is experiencing a rapid growth due to economic growth and the influence of globalization. The development of public spaces that tend to be limited to the people who live in them, makes it difficult for the public to enter the area of its public sphere. Public sphere are formed based on the economic, political, cultural, developmental, and changes that occur in the area of today's public sphere, making it limited and inaccessible to the public at large. This is caused by the hierarchy of public space formed by the changes of the functions, forms, and meanings. This study focused on the relationship between form, function, and meaning of public sphere to the degree level of public spaces of the city of Bandung. The purpose of this study is to reveal all the relationships that exist between the concepts of public space and its influence on the degree level of publicness in the space of the city of Bandung in the context of its change. This research is descriptive-analytical and interpretive based on structuralist approach and empirical evidence obtained from study cases. This approach is used to read public sphere in Bandung's urban spaces to get a reference to the interpretation of relationships from an empirical condition. The degree level and its meaning in Alun-alun Bandung Square with surrounding buildings has been changed and has blocked the accessibility to some buildings and their facades. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Analysis of Alpha and Beta EEG Signal Pattern in Trypophobia Condition with Wavelet Method"
        ],
        "penulis":"Herdaning, Jehan Pratama;Hadiyoso, Sugondo;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A phobia is a human fear of things that are sometimes very simple for some people. One of them is Trypophobia which is a fear of visualizing small holes. The effect of the trypophobia effect can we analyze his brain waves using an Electroencephalograph. In this study, a system was developed to classify a person's condition without Trypophobia (normal) and the condition of a person with Trypophobia based on analysis of alpha and beta EEG signals. In this study, the Artificial Neural Network (ANN) used for classifying conditions. Discrete Wavelet Transform (DWT) is used to reduce the raw dimensions of EEG signals and retrieve signal features. The test results show that the best performance obtained in beta signals which have the highest diagnostic parameter accuracy, namely Maximum, Standard Deviation and Variance with 100% accuracy, with computation time 0.027 and 0.037 seconds. While for alpha signals obtained with Variance and Interquartile Range parameters of 96.42% with a time of 0.03 and 0.032 seconds. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A phobia is a human fear of things that are sometimes very simple for some people. One of them is Trypophobia which is a fear of visualizing small holes. The effect of the trypophobia effect can we analyze his brain waves using an Electroencephalograph. In this study, a system was developed to classify a person's condition without Trypophobia (normal) and the condition of a person with Trypophobia based on analysis of alpha and beta EEG signals. In this study, the Artificial Neural Network (ANN) used for classifying conditions. Discrete Wavelet Transform (DWT) is used to reduce the raw dimensions of EEG signals and retrieve signal features. The test results show that the best performance obtained in beta signals which have the highest diagnostic parameter accuracy, namely Maximum, Standard Deviation and Variance with 100% accuracy, with computation time 0.027 and 0.037 seconds. While for alpha signals obtained with Variance and Interquartile Range parameters of 96.42% with a time of 0.03 and 0.032 seconds. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Logistic strategy to face disruption in freight multimodal transportation network"
        ],
        "penulis":"Rosyida, Erly Ekayanti;Santosa, Budi;Pujawan, I. Nyoman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper investigates distribution strategies when facing disruption. This strategy is based on the flexibility in transportation planning through the use of multimodal transportation. The flexibility mode of transportation mode will make it easier to re-plan routes when the system is affected by disruption but usually needs a higher total cost. The development of this model is based on the determining of the delivery route that results in the least total cost and time. The calculation result is intended to compare modes used in either single mode or modal combination in terms of cost and time used. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper investigates distribution strategies when facing disruption. This strategy is based on the flexibility in transportation planning through the use of multimodal transportation. The flexibility mode of transportation mode will make it easier to re-plan routes when the system is affected by disruption but usually needs a higher total cost. The development of this model is based on the determining of the delivery route that results in the least total cost and time. The calculation result is intended to compare modes used in either single mode or modal combination in terms of cost and time used. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "A new variant of Game Theory based Decision Making (GTDM) algorithm routing protocols to improve energy efficiency on vehicular delay tolerant network (VDTN)"
        ],
        "penulis":"Triadi, Muhammad Biben;Perdana, Doan;Munadi, Rendy;Wenzao, Li;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "These days, the application of Delay Tolerant Networks (DTN) have been expanded into various scenarios of communications field. Vehicular Ad hoc Networks (VANETs) as a communication scenario which treat its subject to disruption and disconnection with frequent partitioning and high latency. Therefore, Vehicular Delay Tolerant Network (VDTN) is introduced as a new research paradigm due to several characteristics match according to specific prerequisites. DTNs is proposed in Vehicular Network because its mechanisms which is using store-carry-forward, can be implemented to deliver the packets, without end-to-end connection, to the destination. One of challenging research of DTN in routing protocol is to meet prerequisites of many applications, especially in vehicular network (VDTN). This paper presents a new variant of Game Theory based on Decision Making (GTDM) that can deliver packet to static node due to improve the energy efficiency of DTNs in city environments. Hence, its destination node (Receiver Node) needs to go to the static node to take their packet under Working Day Movement (WDM), because relay node will be passing by the static node with continuously move to its track to deliver packet. In this paper author will analyze the new variant of GTDM (NVGTDM) which can be more useful than original GTDM for application in city environment with using transportation movement. We conclude that modification of GTDM routing algorithm (NVGTDM) improves energy efficiency as much as 10.38% than the original GTDM. Hence, it can be ensured to compare either to Epidemic or PRoPHET routing algorithm with 55.44% and 68.75% in rates of energy efficiency respectively. \u00a9 2019 Kohat University of Science and Technology.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document"
        ],
        "abstrak":[
            "These days, the application of Delay Tolerant Networks (DTN) have been expanded into various scenarios of communications field. Vehicular Ad hoc Networks (VANETs) as a communication scenario which treat its subject to disruption and disconnection with frequent partitioning and high latency. Therefore, Vehicular Delay Tolerant Network (VDTN) is introduced as a new research paradigm due to several characteristics match according to specific prerequisites. DTNs is proposed in Vehicular Network because its mechanisms which is using store-carry-forward, can be implemented to deliver the packets, without end-to-end connection, to the destination. One of challenging research of DTN in routing protocol is to meet prerequisites of many applications, especially in vehicular network (VDTN). This paper presents a new variant of Game Theory based on Decision Making (GTDM) that can deliver packet to static node due to improve the energy efficiency of DTNs in city environments. Hence, its destination node (Receiver Node) needs to go to the static node to take their packet under Working Day Movement (WDM), because relay node will be passing by the static node with continuously move to its track to deliver packet. In this paper author will analyze the new variant of GTDM (NVGTDM) which can be more useful than original GTDM for application in city environment with using transportation movement. We conclude that modification of GTDM routing algorithm (NVGTDM) improves energy efficiency as much as 10.38% than the original GTDM. Hence, it can be ensured to compare either to Epidemic or PRoPHET routing algorithm with 55.44% and 68.75% in rates of energy efficiency respectively. \u00a9 2019 Kohat University of Science and Technology."
        ]
    },
    {
        "judul":[
            "Analysis of Hubs and Authorities Centrality Using Probabilistic Affinity Index (PAI) on directed-weighted graph in Social Network Analysis"
        ],
        "penulis":"Farhan, Muhammad Thomy;Darwiyanto, Eko;Asror, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Social media is a place for interaction that is connected to the internet network, Twitter is one of the most popular social media. In Twitter sometimes someone does not want to be left behind information related to a particular topic, so it is necessary to follow the user related to the topic so that the information is conveyed quickly. In this study, an analysis was carried out that applied the Hubs and Authorities Centrality method to determine user rankings and the Probabilistic Affinity Index method for weighting values. The results of authority centrality ranking can be used as a list of recommendations of a user who plays a role or has information about a particular topic and the results of centrality hub ranking can be used as a list of recommendations of a user who has an interest in a particular topic. From the testing in this study, changes in the number of other users that are related to the user have the largest average change in centrality value of 0.01188. While the change in the number of relations has the largest average change in the centrality value of 1.44087\u00d710-9. Based on these tests, the number of other users that are related to the user has a large influence on the results of ranking compared to the number of relationships to other users. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Social media is a place for interaction that is connected to the internet network, Twitter is one of the most popular social media. In Twitter sometimes someone does not want to be left behind information related to a particular topic, so it is necessary to follow the user related to the topic so that the information is conveyed quickly. In this study, an analysis was carried out that applied the Hubs and Authorities Centrality method to determine user rankings and the Probabilistic Affinity Index method for weighting values. The results of authority centrality ranking can be used as a list of recommendations of a user who plays a role or has information about a particular topic and the results of centrality hub ranking can be used as a list of recommendations of a user who has an interest in a particular topic. From the testing in this study, changes in the number of other users that are related to the user have the largest average change in centrality value of 0.01188. While the change in the number of relations has the largest average change in the centrality value of 1.44087\u00d710-9. Based on these tests, the number of other users that are related to the user has a large influence on the results of ranking compared to the number of relationships to other users. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "We are \u201cnot\u201d too (young\/old) to collaborate: Prominent key Barriers to intergenerational innovation"
        ],
        "penulis":"Nurhas, Irawan;Aditya, Bayu R.;Geisler, Stefan;Ojala, Arto;Pawlowski, Jan M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this study, we analyzed the barriers to technology-supported intergenerational innovation to understand better how young and old can collaborate towards global innovations. Researchers in different disciplines have already identified various barriers to intergenerational collaboration. However, barriers are changing depending on the context of collaboration, and difficulties still exist to support intergenerational innovation in global settings. Therefore, we investigated the barriers that emerge when people work with someone decades older or younger. The results of our study have shown what barriers are influenced by age, what barriers exist only for senior and younger adults. The study theoretically contributes to deepening the Information Systems (IS) community's understanding of the barriers to intergenerational innovation that need to be considered when developing systems for global innovation. \u00a9 Proceedings of the 23rd Pacific Asia Conference on Information Systems: Secure ICT Platform for the 4th Industrial Revolution, PACIS 2019.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this study, we analyzed the barriers to technology-supported intergenerational innovation to understand better how young and old can collaborate towards global innovations. Researchers in different disciplines have already identified various barriers to intergenerational collaboration. However, barriers are changing depending on the context of collaboration, and difficulties still exist to support intergenerational innovation in global settings. Therefore, we investigated the barriers that emerge when people work with someone decades older or younger. The results of our study have shown what barriers are influenced by age, what barriers exist only for senior and younger adults. The study theoretically contributes to deepening the Information Systems (IS) community's understanding of the barriers to intergenerational innovation that need to be considered when developing systems for global innovation. \u00a9 Proceedings of the 23rd Pacific Asia Conference on Information Systems: Secure ICT Platform for the 4th Industrial Revolution, PACIS 2019."
        ]
    },
    {
        "judul":[
            "Star Schema Implementation For Monitoring in Data Quality Management Tool (A Case Study at A Government Agency)"
        ],
        "penulis":"Effendy, Mohammad Reza;Kusumasari, Tien Fabrianti;Hasibuan, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the past few decades, the quality of data has become something important for managing data in an organization. The primary objective of an organization to build data quality management includes improving the accuracy of the data, the completeness of the data, the age of the data, and the reliability of the data. In developing quality management data, several strong analysis steps are needed so that the tools can run well. Data taken from various applications in an organization is required to maintain its quality. In general, data quality management has needs between tables. Star Schema as a model for representing relationships between tables in the development of data monitoring, a star schema is needed to store the results of data that has been tested from quality tools data. In this paper, we propose a star schema that is used as a basis for developing monitoring data quality management tools that we have developed. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the past few decades, the quality of data has become something important for managing data in an organization. The primary objective of an organization to build data quality management includes improving the accuracy of the data, the completeness of the data, the age of the data, and the reliability of the data. In developing quality management data, several strong analysis steps are needed so that the tools can run well. Data taken from various applications in an organization is required to maintain its quality. In general, data quality management has needs between tables. Star Schema as a model for representing relationships between tables in the development of data monitoring, a star schema is needed to store the results of data that has been tested from quality tools data. In this paper, we propose a star schema that is used as a basis for developing monitoring data quality management tools that we have developed. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Answer selection using Word Alignment based on Part of Speech Tagging in community question answering"
        ],
        "penulis":"Sutedi, Ade;Bijaksana, Moch. Arif;Romadhony, Ade;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper explain about answer selection using word alignment based on POS tagging in Community Question-Answering (CQA). This online community allowed the user to ask and reply related to the question problems which has no restrictions. This causes inappropriate comments with the question problems proposed before. To solve these problems, combining lexical and semantic features has been developed with result conclude that the approach more adequate for similarity task rather than question answering. According to the previous research, there is several problems that can be enhanced. First, vector representation counts exactly matched words, so it does not effective to cover other words that have relatedness between two pairing words. Second, noun overlap for similarity measure in pairing words can't define that the two words are similar. So, it must be define that the pairing POS tag is the same meaning or relatedness. In this study, unsupervised lexical and semantic similarity method employed with different approach from previous method in verbatim and contextual similarities. The data was taken from SemEval 2017 competition which focus on Question-Answer Similarity task. The experiment result for precision (Mean Average Precision) score shows the improvement from 0.674 to 0.6845, 1.03 % higher than previous research in CQA. This improvement comes from lexical similarity, which is not just from noun pattern but also taken from verb pattern. Furthermore, semantic similarity has an important role in determining which words that have same pattern and meaning to define relevancy between them. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper explain about answer selection using word alignment based on POS tagging in Community Question-Answering (CQA). This online community allowed the user to ask and reply related to the question problems which has no restrictions. This causes inappropriate comments with the question problems proposed before. To solve these problems, combining lexical and semantic features has been developed with result conclude that the approach more adequate for similarity task rather than question answering. According to the previous research, there is several problems that can be enhanced. First, vector representation counts exactly matched words, so it does not effective to cover other words that have relatedness between two pairing words. Second, noun overlap for similarity measure in pairing words can't define that the two words are similar. So, it must be define that the pairing POS tag is the same meaning or relatedness. In this study, unsupervised lexical and semantic similarity method employed with different approach from previous method in verbatim and contextual similarities. The data was taken from SemEval 2017 competition which focus on Question-Answer Similarity task. The experiment result for precision (Mean Average Precision) score shows the improvement from 0.674 to 0.6845, 1.03 % higher than previous research in CQA. This improvement comes from lexical similarity, which is not just from noun pattern but also taken from verb pattern. Furthermore, semantic similarity has an important role in determining which words that have same pattern and meaning to define relevancy between them. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparison of discrete cosine transform and dual-tree complex wavelet transform based on arithmetic coding in medical image compression"
        ],
        "penulis":"Novamizanti, Ledya;Prasasti, Anggunmeka Luhur;Noor Kiranda, Ilham Faezar;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Medical image contains very important information in the medical world used to diagnose diseases by doctors. Storage for storing medical imagery requires large storage media. The difficulty of sending and storing files, hence the process of compression image that can shrink the size of medical image. This research uses the Discrete Cosine Transform and Dual-Tree Complex Wavelet Transform-based Arithmetic Coding. DCT is used in the process of compression of imagery files using the cosine value approach. In DCT, there is a quantization process that causes image quality to decline, as it eliminates some information on imagery. DTCWT uses 2 trees, where tree 1 is for real value and tree 2 for imaginary value. Arithmetic Coding is one of entropy encoding that uses the range and probability values in the calculation. The value of decoding results in Arithmetic Coding has the same value as the original image. DCT produce a higher compression ratio than DTCWT, while DTCWT get higher PSNR than DCT. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Medical image contains very important information in the medical world used to diagnose diseases by doctors. Storage for storing medical imagery requires large storage media. The difficulty of sending and storing files, hence the process of compression image that can shrink the size of medical image. This research uses the Discrete Cosine Transform and Dual-Tree Complex Wavelet Transform-based Arithmetic Coding. DCT is used in the process of compression of imagery files using the cosine value approach. In DCT, there is a quantization process that causes image quality to decline, as it eliminates some information on imagery. DTCWT uses 2 trees, where tree 1 is for real value and tree 2 for imaginary value. Arithmetic Coding is one of entropy encoding that uses the range and probability values in the calculation. The value of decoding results in Arithmetic Coding has the same value as the original image. DCT produce a higher compression ratio than DTCWT, while DTCWT get higher PSNR than DCT. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Project Evaluation for Business and IT Alignment with Enterprise Architecture for Water Distribution Company"
        ],
        "penulis":"Wardani, Anita Eka;Asti Amalia N.F.;Gumilang, Soni F.;Muharman, Lubis;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Actually, there are gaps exist in the development of many large companies, which related to the automation and integration between the business and technology information systems within the company. Enterprise Architecture (EA) helps in aligning the business functions of a company with existing applications tooptimizethe existing business processes for the purpose of growth, revenue and satisfaction. For the creation of a well-integrated system, EAprovide logical design to build the sequence of connecting each function either in the structure, task and technology to achieve company goals. A well-designed information system (IS) architecture can be one of the best solutions to enhance the ability and capability of the company in serving its customers especially with the sustainability, maintainability, extendibility and maintainability. Furthermore, good information system can accommodate the company's needs to improve the company's performance process where the useful information system have been generated through careful planning and preparation. EA is a solution that can be used in designing systems within the company by integrating 4 (four) domains namely Business, Data, Applications, and Technology. This study provide the evaluation within the company that is expected to give preliminary result of process to be dealt with in order to increase the performance and support the business processes in the company. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Actually, there are gaps exist in the development of many large companies, which related to the automation and integration between the business and technology information systems within the company. Enterprise Architecture (EA) helps in aligning the business functions of a company with existing applications tooptimizethe existing business processes for the purpose of growth, revenue and satisfaction. For the creation of a well-integrated system, EAprovide logical design to build the sequence of connecting each function either in the structure, task and technology to achieve company goals. A well-designed information system (IS) architecture can be one of the best solutions to enhance the ability and capability of the company in serving its customers especially with the sustainability, maintainability, extendibility and maintainability. Furthermore, good information system can accommodate the company's needs to improve the company's performance process where the useful information system have been generated through careful planning and preparation. EA is a solution that can be used in designing systems within the company by integrating 4 (four) domains namely Business, Data, Applications, and Technology. This study provide the evaluation within the company that is expected to give preliminary result of process to be dealt with in order to increase the performance and support the business processes in the company. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Downscaled LDPC Codes for Indonesia Digital Video Broadcasting Terrestrial 2nd Generation (DVB-T2)"
        ],
        "penulis":"Fadhlika, Citra Yasin Akbar;Anwar, Khoirul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper evaluates the performances of Low Density Parity Check (LDPC) codes standardized for the Digital Video Broadcasting Terrestrial 2nd Generation (DVB-T2) for further practical development and applications in Indonesia. We consider a multi carrier transmission scheme under Bandung channel model derived from Indonesia natural environments. To reduce the computational complexity of encoder and decoder, we use a downscaling technique for LDPC codes of DVB-T2 with a block length of 16200 bits to 270 bits. We perform a computer-based simulation to demonstrate the effectiveness of the downscaled LDPC codes. The simulation results show acceptable Bit Error Rate (BER) performances of downscaled LDPC codes DVB-T2 under Bandung channel model suitable for application in device consuming low power. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper evaluates the performances of Low Density Parity Check (LDPC) codes standardized for the Digital Video Broadcasting Terrestrial 2nd Generation (DVB-T2) for further practical development and applications in Indonesia. We consider a multi carrier transmission scheme under Bandung channel model derived from Indonesia natural environments. To reduce the computational complexity of encoder and decoder, we use a downscaling technique for LDPC codes of DVB-T2 with a block length of 16200 bits to 270 bits. We perform a computer-based simulation to demonstrate the effectiveness of the downscaled LDPC codes. The simulation results show acceptable Bit Error Rate (BER) performances of downscaled LDPC codes DVB-T2 under Bandung channel model suitable for application in device consuming low power. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Parameters Filtering in Soft Set Using AND and OR Operations"
        ],
        "penulis":"Mohammed, Mohammed Adam Taheir;Mohd, Wan Maseri Wan;Arshah, Ruzaini Abdullah;Mungad M.;Sutoyo, Edi;Chiroma, Haruna;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Parameter reduction has a significant role in making precision decisions. Several decisions making researches mine Boolean soft set with defined operations such as AND, OR, union and intersection to utilize their thinking in rough set theory for reducing parameters. Discovering false frequent sets in a soft set takes the right direction for parameter reduction. In this study, the false parameters of multi set are filtered for decision making based on decision partition order or the decision partition order can be configured predefined based on priority. The most important AND intersection results confirm the two sets relations that whether the extensions of original maps the original set characteristics. This contribution enhanced objects decision partition (Herawan et al. in Int J Database Theory Appl 3(2), 2010 [1]) from a multi set for constructing AND and OR filters with the help of decision partition order and then the decision partition order enhanced using user\u2019s priority, and it shows better results in terms of objects reduction. \u00a9 Springer Nature Singapore Pte Ltd. 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Parameter reduction has a significant role in making precision decisions. Several decisions making researches mine Boolean soft set with defined operations such as AND, OR, union and intersection to utilize their thinking in rough set theory for reducing parameters. Discovering false frequent sets in a soft set takes the right direction for parameter reduction. In this study, the false parameters of multi set are filtered for decision making based on decision partition order or the decision partition order can be configured predefined based on priority. The most important AND intersection results confirm the two sets relations that whether the extensions of original maps the original set characteristics. This contribution enhanced objects decision partition (Herawan et al. in Int J Database Theory Appl 3(2), 2010 [1]) from a multi set for constructing AND and OR filters with the help of decision partition order and then the decision partition order enhanced using user\u2019s priority, and it shows better results in terms of objects reduction. \u00a9 Springer Nature Singapore Pte Ltd. 2019."
        ]
    },
    {
        "judul":[
            "Seismic data compression using auto-associative neural network and restricted Boltzmann machine"
        ],
        "penulis":"Nuha, Hilal;Mohandes, Mohamed;Liu, Bo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In a geophysical exploration survey, thousands of geophones are deployed where each geophone must transmit hundreds of recording over a narrow band channel to a fusion center. A lightweight compression technique for geophones is required to reduce the data traffic to the center. We present an efficient implementation of neural network for real-time seismic data compression for geophones. We use an auto-associative neural network architecture with a single linear hidden layer. The neural network is trained in two stages. First, we apply unsupervised learning with restricted Boltzmann machine (RBM) to obtain good initial weights. Secondly, the neural network with the initial weights is further fine-tuned in a supervised fashion with scaled conjugate gradient (SCG). Experimental results with real data have shown that the trained neural network achieves a peak signal-to-noise ratio (PSNR) of more than 30dB with a compression ratio of 10:1. The RBM is also proven to speed up the training up to nine times than that of without RBM. The proposed method is also compared with the linear predictive coding (LPC) and shows significant superiority in terms of compression error and reconstruction quality. \u00a9 2018 SEG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a geophysical exploration survey, thousands of geophones are deployed where each geophone must transmit hundreds of recording over a narrow band channel to a fusion center. A lightweight compression technique for geophones is required to reduce the data traffic to the center. We present an efficient implementation of neural network for real-time seismic data compression for geophones. We use an auto-associative neural network architecture with a single linear hidden layer. The neural network is trained in two stages. First, we apply unsupervised learning with restricted Boltzmann machine (RBM) to obtain good initial weights. Secondly, the neural network with the initial weights is further fine-tuned in a supervised fashion with scaled conjugate gradient (SCG). Experimental results with real data have shown that the trained neural network achieves a peak signal-to-noise ratio (PSNR) of more than 30dB with a compression ratio of 10:1. The RBM is also proven to speed up the training up to nine times than that of without RBM. The proposed method is also compared with the linear predictive coding (LPC) and shows significant superiority in terms of compression error and reconstruction quality. \u00a9 2018 SEG."
        ]
    },
    {
        "judul":[
            "Determinant variables of enterprise risk management (ERM), audit opinions and company value on insurance emitents listed in Indonesia stock exchange"
        ],
        "penulis":"Farida, Ajeng Luthfiyatul;Roziq, Ahmad;Wardayati, Siti Maria;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Risk is inherent uncertainty and must be faced in working life both individually and in an organization. Risks in the form of uncertainty occur due to lack or unavailability of sufficient information about what will happen in the company in the future. This study aims to test and obtain empirical results about determinants of Enterprise Risk Management (ERM) disclosure, audit opinion, and company value by using independent commissioner variables, company size, Leverage, and Risk Management Committee (RMC). The population in this study were all insurance issuers listed on the Indonesia Stock Exchange in 2013-2017 the amount of 15 companies. The sampling technique was carried out using the Purposive Sampling method which produced 12 samples during from 2013-2017. The data used is secondary data with documentation techniques consisting of annual reports of insurance issuers in 2013-2017. The tool used to test hypotheses using path analysis with SPSS Version 22. The results show that company size, leverage, and RMC have a significant effect on ERM disclosure. However, independent commissioners have no significant effect on ERM. For further researchers can use objects such as mining companies that have a higher potential risk. \u00a9 2019, International Journal of Scientific and Technology Research. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Risk is inherent uncertainty and must be faced in working life both individually and in an organization. Risks in the form of uncertainty occur due to lack or unavailability of sufficient information about what will happen in the company in the future. This study aims to test and obtain empirical results about determinants of Enterprise Risk Management (ERM) disclosure, audit opinion, and company value by using independent commissioner variables, company size, Leverage, and Risk Management Committee (RMC). The population in this study were all insurance issuers listed on the Indonesia Stock Exchange in 2013-2017 the amount of 15 companies. The sampling technique was carried out using the Purposive Sampling method which produced 12 samples during from 2013-2017. The data used is secondary data with documentation techniques consisting of annual reports of insurance issuers in 2013-2017. The tool used to test hypotheses using path analysis with SPSS Version 22. The results show that company size, leverage, and RMC have a significant effect on ERM disclosure. However, independent commissioners have no significant effect on ERM. For further researchers can use objects such as mining companies that have a higher potential risk. \u00a9 2019, International Journal of Scientific and Technology Research. All rights reserved."
        ]
    },
    {
        "judul":[
            "Development of digital evidence collector and file classification system with K-Means algorithm"
        ],
        "penulis":"Ruriawan, Muhammad Faris;Anggono, Bintaran;Siahaan, Isaac Anugerah;Purwanto, Yudha;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Digital forensic is a branch of forensic science that focuses on research on the usual storage media that electronic users use such as hard disks, flash drives or other devices used on computers. The output is called digital evidence. The purpose of doing digital forensics is to find an evidence that can be used in the investigation of a case, until the evidence becomes valid and could be used as evidence in court. In this research, we implement a system of digital evidence collection, recovery, and file classification application. The classification was done by K-Means clustering algorithm. The system could detect the storage media, duplicate the content, and classify the output using K-Means algorithm. It can help a forensic examiner in the collection, examination, analysis, and reporting phase in accordance with NIST SP 800-86. The application also can assist investigators in managing files in the storage media as digital evidence so that outputs are obtained in accordance with applicable law. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Digital forensic is a branch of forensic science that focuses on research on the usual storage media that electronic users use such as hard disks, flash drives or other devices used on computers. The output is called digital evidence. The purpose of doing digital forensics is to find an evidence that can be used in the investigation of a case, until the evidence becomes valid and could be used as evidence in court. In this research, we implement a system of digital evidence collection, recovery, and file classification application. The classification was done by K-Means clustering algorithm. The system could detect the storage media, duplicate the content, and classify the output using K-Means algorithm. It can help a forensic examiner in the collection, examination, analysis, and reporting phase in accordance with NIST SP 800-86. The application also can assist investigators in managing files in the storage media as digital evidence so that outputs are obtained in accordance with applicable law. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Comparative Studies: The Effect of Service Quality System toward Customer Satisfaction on TIKI and JNE"
        ],
        "penulis":"Komariah, Nur;Achmad, Suryana H.;Hidayat, Rahmat;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cities and islands scattered in some parts of Indonesia make the distance for people in Indonesia feel difficulty to establish communication far from where they are. Indonesian society has a tendency of consumptive, especially the existence of e-commerce which gives society easiness in doing sale and purchase transaction. The increasing number of online transactions each year makes the delivery service more and more required, but there is a trustworthiness factor of the quality of the shipping service that must be taken seriously by the company so that its customers feel always satisfied and will reuse the service when needed. This study aims to find out some freight services are often used in Indonesia, especially in Bandung about the quality of service to the satisfaction of the delivery services based on customer experience and perception. Some of the most commonly used and trusted shipping companies are TIKI and JNE. The research method used is the quantitative method through linear regression analysis to know the effect of service quality on customer satisfaction and compare each variable of TIKI and JNE through differentiation test of Wilcoxon. The data used is questionnaires data distributed to 100 respondents di Bandung. The findings of this research are the influence of service quality and satisfaction of both service delivery have significant effect and there is big difference (TIKI 33.5% and JNE 44.3%), but if seen from different test result, service quality and satisfaction from JNE slightly larger than TIKI (difference in service quality 1.48 and Satisfaction 0.626) \u00a9 2018 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cities and islands scattered in some parts of Indonesia make the distance for people in Indonesia feel difficulty to establish communication far from where they are. Indonesian society has a tendency of consumptive, especially the existence of e-commerce which gives society easiness in doing sale and purchase transaction. The increasing number of online transactions each year makes the delivery service more and more required, but there is a trustworthiness factor of the quality of the shipping service that must be taken seriously by the company so that its customers feel always satisfied and will reuse the service when needed. This study aims to find out some freight services are often used in Indonesia, especially in Bandung about the quality of service to the satisfaction of the delivery services based on customer experience and perception. Some of the most commonly used and trusted shipping companies are TIKI and JNE. The research method used is the quantitative method through linear regression analysis to know the effect of service quality on customer satisfaction and compare each variable of TIKI and JNE through differentiation test of Wilcoxon. The data used is questionnaires data distributed to 100 respondents di Bandung. The findings of this research are the influence of service quality and satisfaction of both service delivery have significant effect and there is big difference (TIKI 33.5% and JNE 44.3%), but if seen from different test result, service quality and satisfaction from JNE slightly larger than TIKI (difference in service quality 1.48 and Satisfaction 0.626) \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "On the Uplink Throughput of Zero Forcing in Cell-Free Massive MIMO With Coarse Quantization"
        ],
        "penulis":"Maryopi, Dick;Bashar, Manijeh;Burr, Alister;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The recently proposed cell-free massive multiple input multiple output (MIMO) architecture is studied for the uplink. In contrast to most previous works, joint detection is performed using global channel state information (CSI). Therefore, we study strategies for transferring CSI to the central processing unit taking into account the fronthaul capacity which limits CSI quantization. Two strategies for pilot-based CSI acquisition are considered: estimate-and-quantize and quantize-and-estimate. These are analyzed using the Bussgang decomposition. For a given quantization constraint for the data and CSI the achievable rate per user with zero forcing is determined. Numerical results show that quantize-and-estimate (the simpler strategy) is similar to or better than estimate-and-quantize at low resolution, especially for 1-bit. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The recently proposed cell-free massive multiple input multiple output (MIMO) architecture is studied for the uplink. In contrast to most previous works, joint detection is performed using global channel state information (CSI). Therefore, we study strategies for transferring CSI to the central processing unit taking into account the fronthaul capacity which limits CSI quantization. Two strategies for pilot-based CSI acquisition are considered: estimate-and-quantize and quantize-and-estimate. These are analyzed using the Bussgang decomposition. For a given quantization constraint for the data and CSI the achievable rate per user with zero forcing is determined. Numerical results show that quantize-and-estimate (the simpler strategy) is similar to or better than estimate-and-quantize at low resolution, especially for 1-bit. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design of Dust Collector on Sorting Machine Vibro Mesh Type Using Design for Assembly (DFA) Approach with Boothroyd and Dewhurst Method in PT. Perkebunan Nusantara VIII Ciater"
        ],
        "penulis":"Gulo C.A.;Rahayu M.;Martini S.;Kurniawan M.I.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PT. Perkebunan Nusantara VIII is a company that produce orthodox black tea in Indonesia with a land area of less than 400 hectares. In the production section, especially the sorting room in sorting machine, which produces dust contaminants are very disturbing operators who are working. For the maintenance process is scheduled for 2 hours on working hours every 1 month, if maintenance takes more than 2 hours it will cause the production process is delayed. To support the maintenance process on dust collector, Design of dust collector using design for assembly (DFA) aproachp using Boothroyd and Dewhurst method. DFA approach is chosen to simplify the process of maintenance dust collector, which required unloading dust collector every maintenance. There are 2 dust collector designs proposed to get the best assembly design. The design of dust collector with optimal assembly time, with the application of Boothroyd and Dewhurst is design 2 with total component of 82 pieces with assembly time of 552.62 sec with assembling efficiency of 24.43%. It is hoped that by using design 2, the dust collector maintenance process does not interfere with the production process and the shorter time of assembly. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. Perkebunan Nusantara VIII is a company that produce orthodox black tea in Indonesia with a land area of less than 400 hectares. In the production section, especially the sorting room in sorting machine, which produces dust contaminants are very disturbing operators who are working. For the maintenance process is scheduled for 2 hours on working hours every 1 month, if maintenance takes more than 2 hours it will cause the production process is delayed. To support the maintenance process on dust collector, Design of dust collector using design for assembly (DFA) aproachp using Boothroyd and Dewhurst method. DFA approach is chosen to simplify the process of maintenance dust collector, which required unloading dust collector every maintenance. There are 2 dust collector designs proposed to get the best assembly design. The design of dust collector with optimal assembly time, with the application of Boothroyd and Dewhurst is design 2 with total component of 82 pieces with assembly time of 552.62 sec with assembling efficiency of 24.43%. It is hoped that by using design 2, the dust collector maintenance process does not interfere with the production process and the shorter time of assembly. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Implementation of the Certainty Factor Method for Early Detection of Cirrhosis Based on Android"
        ],
        "penulis":"Safira, Laura;Irawan, Budhi;Setiningsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the digital era, computers already have an important role in the medical world. One of the roles of the computer is to help diagnose a patient's disease. Cirrhosis is a disease that attacks all parts of the liver with the formation of connective tissue characterized by nodules. Cirrhosis is also a chronic liver disease in which the liver is slowly damaged which lasts for a long time. This damage can expand so that the liver can stop functioning. This condition is called liver failure. An application to detect an illness desperately needs an expert system that functions as the brain of a machine. Accurate and precise calculations are needed to diagnose symptoms so that they can infer output using the certainty Factor (CF). This paper describes a process to detect liver disease based on weighting combinations of symptoms. A Smartphone application is produced which requires patients to answer about ten questions. The final result of this application is a diagnosis of cirrhosis. From the results of the experiment, it can be concluded that the accuracy of this application is 100% \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the digital era, computers already have an important role in the medical world. One of the roles of the computer is to help diagnose a patient's disease. Cirrhosis is a disease that attacks all parts of the liver with the formation of connective tissue characterized by nodules. Cirrhosis is also a chronic liver disease in which the liver is slowly damaged which lasts for a long time. This damage can expand so that the liver can stop functioning. This condition is called liver failure. An application to detect an illness desperately needs an expert system that functions as the brain of a machine. Accurate and precise calculations are needed to diagnose symptoms so that they can infer output using the certainty Factor (CF). This paper describes a process to detect liver disease based on weighting combinations of symptoms. A Smartphone application is produced which requires patients to answer about ten questions. The final result of this application is a diagnosis of cirrhosis. From the results of the experiment, it can be concluded that the accuracy of this application is 100% \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Analyzing work satisfaction of employees at production department: Case study of indonesian state military equipment manufacturer"
        ],
        "penulis":"Fakhri, Mahendra;Pradana, Mahir;Syarifuddin, Syarifuddin;Hafid, Haeruddin;Mustika, Nurfalinda Permata;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research was conducted to determine the job satisfaction of employees at PT Pindad (Persero) Bandung. The research is used the importance performance analysis method. The purpose of this research is to knowing and analyzing how perceptions and expectations of employees about job satisfaction are important and need to be improved in job satisfaction at PT Pindad. The method used in this research is quantitative with descriptive type. The analysis technique used is importance performance analysis (IPA) summarized from 95 respondents. Based on the results of the study, the perception of employee job satisfaction at PT Pindad (Persero) Bandung is still below expectations, shown in the lowest perception indicator, namely salary size with a score of 49.47% and fair regulatory and policy indicators with a score of 56, 21%. Other results from this study indicate that employees have high expectations for the company. This is indicated by the total score of expectations of 87.34% which means very important. \u00a9 2019 SERSC.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research was conducted to determine the job satisfaction of employees at PT Pindad (Persero) Bandung. The research is used the importance performance analysis method. The purpose of this research is to knowing and analyzing how perceptions and expectations of employees about job satisfaction are important and need to be improved in job satisfaction at PT Pindad. The method used in this research is quantitative with descriptive type. The analysis technique used is importance performance analysis (IPA) summarized from 95 respondents. Based on the results of the study, the perception of employee job satisfaction at PT Pindad (Persero) Bandung is still below expectations, shown in the lowest perception indicator, namely salary size with a score of 49.47% and fair regulatory and policy indicators with a score of 56, 21%. Other results from this study indicate that employees have high expectations for the company. This is indicated by the total score of expectations of 87.34% which means very important. \u00a9 2019 SERSC."
        ]
    },
    {
        "judul":[
            "Competency Measurement Instrument Design for Maintenance Staff of Electronic Expertise with SECI Method"
        ],
        "penulis":"Agisni;Soesanto R.P.;Kurniawati A.;Ambarsari N.;Andrawina L.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "To gain competitive advantages, companies must combine and collaborate with the tangible and intangible assets. The most important intangible assets in companies are people because people have the knowledge to run the companies. Competencies of each individual in a company is a basic characteristic that must be taken into account. The purpose of this research is to improve the quality of human resources of maintenance staff in the manufacturing company by designing competency measurement instrument that aims to assess the competency of employees. The focus of this research is the mechanical expertise of maintenance staff. SECI method is used in this research for managing knowledge that is held by senior employees regarding employee competence in electronic expertise. The SECI method converts the knowledge of a person's tacit knowledge into an explicit knowledge so that the knowledge can be used by others. The knowledge that is gathered from SECI method is converted into a list of competence and break down into the detailed competency. The result of this paper is the competency measurement instrument that aims to assess the competency of employees. Future research can be done to test the instrument and add more specific criteria. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "To gain competitive advantages, companies must combine and collaborate with the tangible and intangible assets. The most important intangible assets in companies are people because people have the knowledge to run the companies. Competencies of each individual in a company is a basic characteristic that must be taken into account. The purpose of this research is to improve the quality of human resources of maintenance staff in the manufacturing company by designing competency measurement instrument that aims to assess the competency of employees. The focus of this research is the mechanical expertise of maintenance staff. SECI method is used in this research for managing knowledge that is held by senior employees regarding employee competence in electronic expertise. The SECI method converts the knowledge of a person's tacit knowledge into an explicit knowledge so that the knowledge can be used by others. The knowledge that is gathered from SECI method is converted into a list of competence and break down into the detailed competency. The result of this paper is the competency measurement instrument that aims to assess the competency of employees. Future research can be done to test the instrument and add more specific criteria. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Stability and vulnerability of bird flocking behaviour: A mathematical analysis"
        ],
        "penulis":"Erfianto, Bayu;Muchtadi-Alamsyah, Intan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Given a large number of birds in the flock, we mathematically investigate the mechanism the birds move in a collective behavior. We assume that each bird is able to know its position and velocity of other birds within a radius of communication. Thus, to be able to fly in the flock, a bird has to adjust its position and velocity according to his neighbors. For this purpose, first of all, we analyze how the connectedness of the bird interaction network affects the cohesion of the stable bird flock. We further analyze a condition when the flock is vulnerable, which is mathematically indicated by means of the presence of an articulation point in bird communication network. \u00a9 2019 Institut Pertanian Bogor.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Given a large number of birds in the flock, we mathematically investigate the mechanism the birds move in a collective behavior. We assume that each bird is able to know its position and velocity of other birds within a radius of communication. Thus, to be able to fly in the flock, a bird has to adjust its position and velocity according to his neighbors. For this purpose, first of all, we analyze how the connectedness of the bird interaction network affects the cohesion of the stable bird flock. We further analyze a condition when the flock is vulnerable, which is mathematically indicated by means of the presence of an articulation point in bird communication network. \u00a9 2019 Institut Pertanian Bogor."
        ]
    },
    {
        "judul":[
            "User Group Management and Smart Society: Readiness Assessment of UU Adminduk (National Administration)"
        ],
        "penulis":"Adam Prasetyo, Yuli;Lubis, Muharman;Azani Hasibuan, Muhammad;Wiyono;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The conceptual model of smart societies has been aligned with smart offices, building and cities concurrently, which should concern various aspects of the individual such as attitude, behaviour and cognitive. In short, it should start from the fundamental and basic characteristic of human or bottom up approach not the other way around. In these concept, the new generation engages with the combination of smart energies, smart devices and smart transportations as the inheritance part of the advancement of smart system in the technologies utilization. For example, ubiquitous apps that provide rapid information about the direction to specific destination, the available spot to park, the reminder of respected area to avoid traffic congestion regardless the location of users. However, somehow, the utilization process often meet with failed in term of matching the user expectation with the system needs or, the most important thing, the readiness of current regulation to accommodate the trend changes and implementation of technology system. Thus, this study assess the interpretation of legal expert towards UU Adminduk (National Administration) by using content analysis through 21 selected coders from diverse background to gain more understanding of the complexity and reliability of the regulation. This act extremely necessary to govern the recording, changes, management and publication process of the personal data the purpose of national identity. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The conceptual model of smart societies has been aligned with smart offices, building and cities concurrently, which should concern various aspects of the individual such as attitude, behaviour and cognitive. In short, it should start from the fundamental and basic characteristic of human or bottom up approach not the other way around. In these concept, the new generation engages with the combination of smart energies, smart devices and smart transportations as the inheritance part of the advancement of smart system in the technologies utilization. For example, ubiquitous apps that provide rapid information about the direction to specific destination, the available spot to park, the reminder of respected area to avoid traffic congestion regardless the location of users. However, somehow, the utilization process often meet with failed in term of matching the user expectation with the system needs or, the most important thing, the readiness of current regulation to accommodate the trend changes and implementation of technology system. Thus, this study assess the interpretation of legal expert towards UU Adminduk (National Administration) by using content analysis through 21 selected coders from diverse background to gain more understanding of the complexity and reliability of the regulation. This act extremely necessary to govern the recording, changes, management and publication process of the personal data the purpose of national identity. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Towards co-creation strategy and organizational agility based on customer experience orientation to shape transformational performance"
        ],
        "penulis":"Mihardjo, Leonardus W. Wasono;Sasmoko, Firdaus Alamsyah;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 5.0 is a step after digitalization and digitation has been accomplished. The collaboration, service orientation, agility and customer experience become a critical in this dynamic environment. Hence, the firm strategy has shifted from a competition strategy to a col-laboration strategy. Collaboration with customers is effected through co-creation Strategy (CCS). It could enable the firms in accelerating digital transformation. This study of the development of co-creation strategy focuses on customer experience orientation (CXO) and organization agility (OA) to support transformational performance (TP) in terms of relationship among variables and an empirical study has been conducted. Hence, in this paper, we propose a model of digital transformation for ICT Industry based on co-creation of strategy focused on customer experience orientation and organization agility. The study is based on an empirical study of 195 Indonesian ICT firms. The findings from this analysis reveal the concept of Service Dominant logic (S-D Logic) where the Co-creation capability and organizational agilities can suffice. \u00a9 2019 Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 5.0 is a step after digitalization and digitation has been accomplished. The collaboration, service orientation, agility and customer experience become a critical in this dynamic environment. Hence, the firm strategy has shifted from a competition strategy to a col-laboration strategy. Collaboration with customers is effected through co-creation Strategy (CCS). It could enable the firms in accelerating digital transformation. This study of the development of co-creation strategy focuses on customer experience orientation (CXO) and organization agility (OA) to support transformational performance (TP) in terms of relationship among variables and an empirical study has been conducted. Hence, in this paper, we propose a model of digital transformation for ICT Industry based on co-creation of strategy focused on customer experience orientation and organization agility. The study is based on an empirical study of 195 Indonesian ICT firms. The findings from this analysis reveal the concept of Service Dominant logic (S-D Logic) where the Co-creation capability and organizational agilities can suffice. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Image Processing of IoT Based Cherry Tomato Growth Monitoring System"
        ],
        "penulis":"Anugraheni, Nadya Ayu;Suhendi, Asep;Bethanigtyas, Hertiana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Monitoring the growth of fruit in a plant is one of several important parameters to determine the phase of a plant's growth. Monitoring fruit growth in Cherry tomatoes can be done with image processing. Image processing is used to detect the ripe cherry tomatoes. To mark off the ripe one, first define the range of YCbCr value for ripe cherry's tomatoes, afterthat color segmentation needs to be done to the picture. Usually, cherry tomatoes touch each other, so separating touching cherry's tomatoes using the watershed algorithm is the next step. Next, counting the ripe fruits automatically. The value of counting needs to be shown, it will be sent to the IoT platform, in this paper, thingspeak is used for IoT platform. From this paper, the algorithm can detect 72 pictures from 100 pictures correctly with 10% error for the whole images. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Monitoring the growth of fruit in a plant is one of several important parameters to determine the phase of a plant's growth. Monitoring fruit growth in Cherry tomatoes can be done with image processing. Image processing is used to detect the ripe cherry tomatoes. To mark off the ripe one, first define the range of YCbCr value for ripe cherry's tomatoes, afterthat color segmentation needs to be done to the picture. Usually, cherry tomatoes touch each other, so separating touching cherry's tomatoes using the watershed algorithm is the next step. Next, counting the ripe fruits automatically. The value of counting needs to be shown, it will be sent to the IoT platform, in this paper, thingspeak is used for IoT platform. From this paper, the algorithm can detect 72 pictures from 100 pictures correctly with 10% error for the whole images. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Ant Colony Optimization method analyzing for Sequential Pattern Mining (Case Study: IGracias Telkom University)"
        ],
        "penulis":"Liana, Isma Dewi;Asror, Ibnu;Sardi, Indra Lukmana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "With the development of internet technology, information becomes very easy to obtain. Especially the use of web-based information systems are very widely used to disseminate information to the world. Similarly, in the Eld of education that makes the website as a source of information for all students, lecturers, to employees. In general, each user access to the website can form the access pattern. Then, the accessing pattern can be used to do the development on the website to facilitate the user get the desired menu. By using Ant Colony Optimization (ACO), the system can output the pattern of access based on the interests of all users. The selection of the Ant Colony Optimization (ACO) method due to the ow when the user accesses the website has in common with the ants while building the road to the food. In this experiment, pheromone will be modification with interest time and interest visit user to release the result that can approach the pattern of user access when accessing the website. Also, after testing the threshold was obtained 0.02 for the student group, 0.05 for the lecturer group, and 0.025 for the employee group which can produce a pattern that represents the user's habit patterns. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "With the development of internet technology, information becomes very easy to obtain. Especially the use of web-based information systems are very widely used to disseminate information to the world. Similarly, in the Eld of education that makes the website as a source of information for all students, lecturers, to employees. In general, each user access to the website can form the access pattern. Then, the accessing pattern can be used to do the development on the website to facilitate the user get the desired menu. By using Ant Colony Optimization (ACO), the system can output the pattern of access based on the interests of all users. The selection of the Ant Colony Optimization (ACO) method due to the ow when the user accesses the website has in common with the ants while building the road to the food. In this experiment, pheromone will be modification with interest time and interest visit user to release the result that can approach the pattern of user access when accessing the website. Also, after testing the threshold was obtained 0.02 for the student group, 0.05 for the lecturer group, and 0.025 for the employee group which can produce a pattern that represents the user's habit patterns. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "User Experience in Mobile Application Design: Utility Defined Context of Use"
        ],
        "penulis":"Lubis, Muharman;Sutoyo, Edi;Azuddin, Muna;Handayani, Dini;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Mobile application has been offered tremendous benefit to the user in providing solution especially related to accessibility and availability. Product functions are important but with the better user experiences, it will have more advantages, which somehow increase its level adoption and retention within context. User experience (UX) is the outcome that this study want to achieve through implementing user centred design in the process by defining the set of methods and phases, which are loosely connected each other to solve the problem arisen. This study identified the lack of integration process within driving communities to have service in motorcycle driving practice, permission letter and rental. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mobile application has been offered tremendous benefit to the user in providing solution especially related to accessibility and availability. Product functions are important but with the better user experiences, it will have more advantages, which somehow increase its level adoption and retention within context. User experience (UX) is the outcome that this study want to achieve through implementing user centred design in the process by defining the set of methods and phases, which are loosely connected each other to solve the problem arisen. This study identified the lack of integration process within driving communities to have service in motorcycle driving practice, permission letter and rental. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Reading level system on fairy tale stories for children using dolch sight word vocabulary with majority voting algorithm"
        ],
        "penulis":"Azzami, Alifa Nur;Kusumo, Dana Sulistyo;Astuti, Widi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Children need appropriate reading contents to improve their imagination and power of thought. Fairy tales become one of reading contents that are good for children growth, because it can arise children imagination. However, there is no reading content categorization for Indonesian fairy tale stories. Therefore, in this research, a Reading Level System was proposed to rank reading contents for Indonesian children. Adopting Dolch Sight Word Vocabulary, it enabled to build text clustering using the occurrences of empirical probability of words for each Dolch Sight Word Vocabulary in a fairy tale. The values of empirical probability levels were calculated for each fairy tale and the results of calculating the highest probability value for each fairy tale using the Majority Voting Algorithm. The results found that the majority of Reading Level System using Dolch Sight Word Vocabulary were level 3 and level 4, where at these levels the words component of the Dolch Sight words were larger than the rest two levels. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Children need appropriate reading contents to improve their imagination and power of thought. Fairy tales become one of reading contents that are good for children growth, because it can arise children imagination. However, there is no reading content categorization for Indonesian fairy tale stories. Therefore, in this research, a Reading Level System was proposed to rank reading contents for Indonesian children. Adopting Dolch Sight Word Vocabulary, it enabled to build text clustering using the occurrences of empirical probability of words for each Dolch Sight Word Vocabulary in a fairy tale. The values of empirical probability levels were calculated for each fairy tale and the results of calculating the highest probability value for each fairy tale using the Majority Voting Algorithm. The results found that the majority of Reading Level System using Dolch Sight Word Vocabulary were level 3 and level 4, where at these levels the words component of the Dolch Sight words were larger than the rest two levels. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Comparison of Real Time Iterative Deepening Best First Search Algorithm and A\u2217 Algorithm on Maze Chase Game NPC"
        ],
        "penulis":"Nabil, Husein;Nasution, Surya Michrandi;Nugrahaeni, Ratna Astuti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Maze Chase is a game that has a maze background. In this game there are players who have the task, which is to take all the points in the labyrinth. In the Maze Chase game there is also an NPC (Non-Playable Character) that aims to chase players so that players cannot take all the points in the labyrinth. Players can be considered to have won the game is that all the points in the labyrinth have been taken by the player. The author implements the A\u2217 and RIBS path search algorithms for NPCs so that NPCs can chase players. That way we get the travel time comparison to the players on each path search algorithm. After testing the average travel time to NPC players with the A\u2217 algorithm faster 0.116196% than NPC with the RIBS algorithm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Maze Chase is a game that has a maze background. In this game there are players who have the task, which is to take all the points in the labyrinth. In the Maze Chase game there is also an NPC (Non-Playable Character) that aims to chase players so that players cannot take all the points in the labyrinth. Players can be considered to have won the game is that all the points in the labyrinth have been taken by the player. The author implements the A\u2217 and RIBS path search algorithms for NPCs so that NPCs can chase players. That way we get the travel time comparison to the players on each path search algorithm. After testing the average travel time to NPC players with the A\u2217 algorithm faster 0.116196% than NPC with the RIBS algorithm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Causative factor identification of N212-400 product project delay at PT. Dirgantara Indonesia"
        ],
        "penulis":"Pujiariadi A.S.;Widiyanesti S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PT. Dirgantara Indonesia had a delay project for five aircrafts of n212-400 ordered by the Phillipines and Vietnam. This is a qualitative research using a case study approach in the identification of the causative factor of project delay, with the purpose of study using descriptive research and the process data validity and reliability using triangulation method. The data analysis in this research was the productivity of project, potential failure mode of the project using FMEA (Failure Mode and Effect Analysis) and fishbone diagram to determine the cause and effect of the project delay. The result of the productivity during N212-400 project was 40%, and in aerospace industry, this is below its average of 70% - 80%. Using fishbone and FMEA, the cause of delay and the potential failure of delay project N212-400 was identified and the main factor of project delay based on fishbone and FMEA was machine and material process. Both of the key factors had a high score of RPN (Risk Priority Number) at 810 and should be given priority for improvement. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. Dirgantara Indonesia had a delay project for five aircrafts of n212-400 ordered by the Phillipines and Vietnam. This is a qualitative research using a case study approach in the identification of the causative factor of project delay, with the purpose of study using descriptive research and the process data validity and reliability using triangulation method. The data analysis in this research was the productivity of project, potential failure mode of the project using FMEA (Failure Mode and Effect Analysis) and fishbone diagram to determine the cause and effect of the project delay. The result of the productivity during N212-400 project was 40%, and in aerospace industry, this is below its average of 70% - 80%. Using fishbone and FMEA, the cause of delay and the potential failure of delay project N212-400 was identified and the main factor of project delay based on fishbone and FMEA was machine and material process. Both of the key factors had a high score of RPN (Risk Priority Number) at 810 and should be given priority for improvement. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Identification of baby cry with Discrete Wavelet Transform, Mel Frequency Cepstral Coefficient and Principal Component Analysis"
        ],
        "penulis":"Luhur Prasasti, Anggunmeka;Novamizanti, Ledya;Razik, Muhammad Ichwannul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A baby's cry is a sign of a baby that shows the feelings and desires of a baby. However, many people misinterpret the baby's cry so that less precise handling happens often. Based on the research from Dunstan Baby Language (DBL), there are 5 types of languages used by infants namely NEH (Hungry), HEH (Discomfort), EAIRH (Lower Wind\/Gas), EH (Burp), and OWH (Tired). This research designed the baby's voice-based speech processing sound identification system. The baby's cry is recorded by using the audio record feature on the smartphone then get the extraction feature by using Discrete Wavelet Transform (DWT). DC removal and pre-emphasis stages are needed as pre-process. The sound signal is performed extraction feature by Mel Frequency Cepstral Coefficient (MFCC) and Principal Component Analysis (PCA) methods. The result of the feature extraction will be classified with Euclidean distance to measure the resemblance of the extraction value of each cry by calculating the difference in distance 2 matrices of features. From 150 training data and 50 test data, this system can identify the sound of crying babies on 5 conditions of a baby crying, namely Neh (Hungry), Heh (Discomfort), Eairh (Lower Wind\/Gas), Eh (Burp), and Owh (Tired). The best parameter is obtained at a frame size of 1024 data per frame, MFCC feature coefficient of 32, DWT at level 1, and DB 2. This system can detect the baby crying sound with the best accuracy of 90% and computing time 0.5542 seconds. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A baby's cry is a sign of a baby that shows the feelings and desires of a baby. However, many people misinterpret the baby's cry so that less precise handling happens often. Based on the research from Dunstan Baby Language (DBL), there are 5 types of languages used by infants namely NEH (Hungry), HEH (Discomfort), EAIRH (Lower Wind\/Gas), EH (Burp), and OWH (Tired). This research designed the baby's voice-based speech processing sound identification system. The baby's cry is recorded by using the audio record feature on the smartphone then get the extraction feature by using Discrete Wavelet Transform (DWT). DC removal and pre-emphasis stages are needed as pre-process. The sound signal is performed extraction feature by Mel Frequency Cepstral Coefficient (MFCC) and Principal Component Analysis (PCA) methods. The result of the feature extraction will be classified with Euclidean distance to measure the resemblance of the extraction value of each cry by calculating the difference in distance 2 matrices of features. From 150 training data and 50 test data, this system can identify the sound of crying babies on 5 conditions of a baby crying, namely Neh (Hungry), Heh (Discomfort), Eairh (Lower Wind\/Gas), Eh (Burp), and Owh (Tired). The best parameter is obtained at a frame size of 1024 data per frame, MFCC feature coefficient of 32, DWT at level 1, and DB 2. This system can detect the baby crying sound with the best accuracy of 90% and computing time 0.5542 seconds. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "GNSS interference reduction method for CORS site planning"
        ],
        "penulis":"Septiawan, Reza;AgungSyetiawan;Rufiyanto, Arief;Taufik, Nashrullah;Sulistya, Budi;Putro, Erik Madyo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Precision, Navigation, and Timing (PNT) system based on Global Navigation Satellite System (GNSS) becomes significant in the air, land, and sea traffic management. Integrity of GNSS is significant to provide a reliable real time PNT system such as CORS (Continuously Operating Reference Stations). GNSS Interference due to intentional or unintentional surrounding signal source may decrease the integrity of GNSS signal. Monitoring and identification of potential GNSS interference sources in the surrounding environment of CORS is significant. This paper proposed a methodology to reduce potential GNSS interference in a planned CORS site by first simulating the radiation pattern of potential source of interference to GNSS signal in the planned CORS sites. Thereafter ambient noise levels in the location of CORS may be measured to provide a reference point for analyzing the other potential sources of interferences. Based on these results, optimal location of CORS is chosen with the lowest possible unintentional interference signal from their surrounding. Measurement has been conducted in the location of CORS owned by BIG (Indonesian Agency for Geospatial Information), which is located in the rooftop of a building neara telecommunication tower.This method is necessary for CORS site planning to reduce potential GNSS interference sources in the environment of alternative sites. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Precision, Navigation, and Timing (PNT) system based on Global Navigation Satellite System (GNSS) becomes significant in the air, land, and sea traffic management. Integrity of GNSS is significant to provide a reliable real time PNT system such as CORS (Continuously Operating Reference Stations). GNSS Interference due to intentional or unintentional surrounding signal source may decrease the integrity of GNSS signal. Monitoring and identification of potential GNSS interference sources in the surrounding environment of CORS is significant. This paper proposed a methodology to reduce potential GNSS interference in a planned CORS site by first simulating the radiation pattern of potential source of interference to GNSS signal in the planned CORS sites. Thereafter ambient noise levels in the location of CORS may be measured to provide a reference point for analyzing the other potential sources of interferences. Based on these results, optimal location of CORS is chosen with the lowest possible unintentional interference signal from their surrounding. Measurement has been conducted in the location of CORS owned by BIG (Indonesian Agency for Geospatial Information), which is located in the rooftop of a building neara telecommunication tower.This method is necessary for CORS site planning to reduce potential GNSS interference sources in the environment of alternative sites. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Design of Testing Results of Reduction and Migration of Write off Transaction Data in POTS Segment Using Integration Testing on SAP Application: Study Case : ia Tbk"
        ],
        "penulis":"Sianturi, Ronald Lois Septian;Hediyanto, Umar Yunan K.S.;Puspitasari, Warih;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PT Telkom Indonesia is the largest telecommunication provider in Indonesia. There are many transactions carried out to provide services, one of these transactions is Write Off and WS. The number of transactions carried out by Telkom Indonesia and interrelated, Telkom Indonesia requires an Enterprise Resource Planning application, namely SAP, which can help integrate all business processes with each transaction made by Telkom Indonesia. Telkom Indonesia has an increase in customers every year. Most customer increases occur in POTS segmentation, so the data stored on the database server is getting bigger. Larger data can cause performance degradation in the system to load data on the database server and also cause several problems such as the risk of failure when the data backup is getting bigger, the data restoration process is very long so it can affect operational activities. Therefore, data reduction is done on the server and replacing the server to the new device to get more optimal performance. Data on a new device that have been reduced and migrated must be tested against related transactions in SAP to see if the data is consistent. Testing is done using System Integration Testing to make sure data being migrated is consistent. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT Telkom Indonesia is the largest telecommunication provider in Indonesia. There are many transactions carried out to provide services, one of these transactions is Write Off and WS. The number of transactions carried out by Telkom Indonesia and interrelated, Telkom Indonesia requires an Enterprise Resource Planning application, namely SAP, which can help integrate all business processes with each transaction made by Telkom Indonesia. Telkom Indonesia has an increase in customers every year. Most customer increases occur in POTS segmentation, so the data stored on the database server is getting bigger. Larger data can cause performance degradation in the system to load data on the database server and also cause several problems such as the risk of failure when the data backup is getting bigger, the data restoration process is very long so it can affect operational activities. Therefore, data reduction is done on the server and replacing the server to the new device to get more optimal performance. Data on a new device that have been reduced and migrated must be tested against related transactions in SAP to see if the data is consistent. Testing is done using System Integration Testing to make sure data being migrated is consistent. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Stream Control Transportation Protocol (SCTP) towards MANET Routing: Comparison of DSR and AODV"
        ],
        "penulis":"Lubis, Muharman;Lubis, Fahrurrozi;Lubis, Arif Ridho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research wants to compare the performance of Stream Control Transportation Protocol (SCTP) with two difference mechanism, which are Ad-hoc on Demand Distance Vector (AODV) and Dynamic Source Routing protocol (DSR) by using Network Simulator (NS-2). Specifically, it measures the behavior of SCTP in terms of throughput and smoothness by having assumption that routing protocol in MANET (Mobile Ad-hoc Network) can bring significant effect in SCTP in the overall performance. Actually, IETF (Internet Engineering Task Force), has issued a new protocol called SCTP, which in this study, the interaction of SCTP is investigated through the examination of traffic flows through a number of network topologies. This performance analysis is over MANET Routing Protocol that enables the process of analysis of several performance metrics. The simulation use topology with 16 nodes that is consisting of metric 4\u00d74 of SCTP transport layer for both routing protocol of AODV and DSR. At last, this research have been found that MANET impact less on the throughput of SCTP with only amounted to 0-2% within 5m\/s to 25 m\/s of simulation area. Furthermore, the speed of node movement does not significantly affect the smoothness as well. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research wants to compare the performance of Stream Control Transportation Protocol (SCTP) with two difference mechanism, which are Ad-hoc on Demand Distance Vector (AODV) and Dynamic Source Routing protocol (DSR) by using Network Simulator (NS-2). Specifically, it measures the behavior of SCTP in terms of throughput and smoothness by having assumption that routing protocol in MANET (Mobile Ad-hoc Network) can bring significant effect in SCTP in the overall performance. Actually, IETF (Internet Engineering Task Force), has issued a new protocol called SCTP, which in this study, the interaction of SCTP is investigated through the examination of traffic flows through a number of network topologies. This performance analysis is over MANET Routing Protocol that enables the process of analysis of several performance metrics. The simulation use topology with 16 nodes that is consisting of metric 4\u00d74 of SCTP transport layer for both routing protocol of AODV and DSR. At last, this research have been found that MANET impact less on the throughput of SCTP with only amounted to 0-2% within 5m\/s to 25 m\/s of simulation area. Furthermore, the speed of node movement does not significantly affect the smoothness as well. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A Framework for Clustering of Web Users Transaction Based on Soft Set Theory"
        ],
        "penulis":"Sutoyo, Edi;Yanto, Iwan Tri Riyadi;Saadi, Younes;Chiroma, Haruna;Hamid, Suraya;Herawan, Tutut;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Clustering faces several additional challenges, compared to traditional applications. The clusters tend to have imprecise boundaries and uncertainty. As a consequence of this uncertainty, we can highlight some challenges for web mining related to many problems such as: Forming of clusters, the high computational complexity. Rough set theory has been used for clustering web user transactions, while managing uncertainty in clustering process. However, it suffers from high computational complexity. In this paper, we propose a framework for web clustering based on soft set theory with emphasis on reducing computational complexity. \u00a9 Springer Nature Singapore Pte Ltd. 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Clustering faces several additional challenges, compared to traditional applications. The clusters tend to have imprecise boundaries and uncertainty. As a consequence of this uncertainty, we can highlight some challenges for web mining related to many problems such as: Forming of clusters, the high computational complexity. Rough set theory has been used for clustering web user transactions, while managing uncertainty in clustering process. However, it suffers from high computational complexity. In this paper, we propose a framework for web clustering based on soft set theory with emphasis on reducing computational complexity. \u00a9 Springer Nature Singapore Pte Ltd. 2019."
        ]
    },
    {
        "judul":[
            "Hotspot asummption as a forest fire indicator in Kalimantan based on climate factor"
        ],
        "penulis":"Aflahah, Elania;Hidayati, Rini;Hidayat, Rahmat;Alfahmi, Furqon;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The occurance of forest fire indonesia especially in Kalimantan is a potential threat to sustainable development. The purpose of this research is a early warning system in forest fire in Kalimantan, by estimating the hotspot as indicators based on visibility and climate data. This research using F test, T test, Multiple Linear Regression analysis, Principle Component Analysis (PCA) and Principle Component Regression Analysis (PCR) Vvisibility, hotspot and temperature data have releated, meaning the very big effect with forest fire incident. Test result of T test and ANOVA P-Value less than 0.05, there is influence between independent variables in this visibility and climate factor against dependent variables in this is the number of hotspots. Relation of climate variables to 10 days forest fire in Central Kalimantan R2adjusted is 0.4699 with F calculate larger from F table is 160.0940. Relation of climate variables to dasarian forest fire in central kalimantan as early warning system has R2adjusted that is 0.4176 with f calculate larger from table F of 129.3551. Conclusion forest fires following monsoon character and being affected by el nino events, visibility has a closer and can be used as a indicator of forest fire and land intensity, hotspot in a relationship has a close connection with visibility and climate condition at the same decade period, used equations for early warning system for predicted fire genesis indicates with hotspot amount, compiled from climate condition 10 days. \u00a9 2019, Pusat Penelitian Lingkungan Hidup - Lembaga Penelitian dan Pengabdian Kepada Masyarakat Institut Pertanian Bogor (PPLH-LPPM IPB). All rights reserved.",
            "Sustainable Development Goals mapped to this documentLife on landGoal 15Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The occurance of forest fire indonesia especially in Kalimantan is a potential threat to sustainable development. The purpose of this research is a early warning system in forest fire in Kalimantan, by estimating the hotspot as indicators based on visibility and climate data. This research using F test, T test, Multiple Linear Regression analysis, Principle Component Analysis (PCA) and Principle Component Regression Analysis (PCR) Vvisibility, hotspot and temperature data have releated, meaning the very big effect with forest fire incident. Test result of T test and ANOVA P-Value less than 0.05, there is influence between independent variables in this visibility and climate factor against dependent variables in this is the number of hotspots. Relation of climate variables to 10 days forest fire in Central Kalimantan R2adjusted is 0.4699 with F calculate larger from F table is 160.0940. Relation of climate variables to dasarian forest fire in central kalimantan as early warning system has R2adjusted that is 0.4176 with f calculate larger from table F of 129.3551. Conclusion forest fires following monsoon character and being affected by el nino events, visibility has a closer and can be used as a indicator of forest fire and land intensity, hotspot in a relationship has a close connection with visibility and climate condition at the same decade period, used equations for early warning system for predicted fire genesis indicates with hotspot amount, compiled from climate condition 10 days. \u00a9 2019, Pusat Penelitian Lingkungan Hidup - Lembaga Penelitian dan Pengabdian Kepada Masyarakat Institut Pertanian Bogor (PPLH-LPPM IPB). All rights reserved."
        ]
    },
    {
        "judul":[
            "Disaster victims detection system using convolutional neural network (CNN) method"
        ],
        "penulis":"Hartawan, Dean Rizki;Purboyo, Tito Waluyo;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Natural disasters are one of the things that cannot be predicted. Natural disasters can cause losses, both assets and objects can even take lives. To reduce the number of losses, rapid evacuation handling from the Search and Rescue (SAR) team is needed to help victims of natural disasters. But in fact, there are often obstacles in the evacuation process. Such obstacles are such as bad weather conditions, disconnection of telecommunications networks, difficulty access to the victims of natural disasters and the spread of SAR teams that are not evenly distributed throughout the disaster area. Convolutional Neural Network is one of the developments of Artificial Neural Networks for image classification, image segmentation, and object recognition with high accuracy and high performance. CNN can learn to detect various images according to images from the dataset studied. So, this paper designed a system for detecting victims of natural disasters using the CNN method and implemented it on a raspberry pi which can detect victims of natural disasters through streaming cameras placed on UAVs. In this paper, the Convolutional Neural Network (CNN) method with 100% accuracy with distance object 1-4 m uses the Mobile-net SSD model. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Natural disasters are one of the things that cannot be predicted. Natural disasters can cause losses, both assets and objects can even take lives. To reduce the number of losses, rapid evacuation handling from the Search and Rescue (SAR) team is needed to help victims of natural disasters. But in fact, there are often obstacles in the evacuation process. Such obstacles are such as bad weather conditions, disconnection of telecommunications networks, difficulty access to the victims of natural disasters and the spread of SAR teams that are not evenly distributed throughout the disaster area. Convolutional Neural Network is one of the developments of Artificial Neural Networks for image classification, image segmentation, and object recognition with high accuracy and high performance. CNN can learn to detect various images according to images from the dataset studied. So, this paper designed a system for detecting victims of natural disasters using the CNN method and implemented it on a raspberry pi which can detect victims of natural disasters through streaming cameras placed on UAVs. In this paper, the Convolutional Neural Network (CNN) method with 100% accuracy with distance object 1-4 m uses the Mobile-net SSD model. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The Effect of Hydrophilic Coating on Concrete Pile Surface in Pile Driving: Field Test"
        ],
        "penulis":"Amalia, Nadya;Yuliza, Elfi;Rokhmat, Mamat;Wibowo, Edy;Viridi, Sparisoma;Abdullah, Mikrajuddin;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At laboratory scale, hydrophilic coating on the surface of precast concrete piles is capable of affecting the piles to be installed into a certain depth level with less number of hammer strokes than piles without coating. In this work, a preliminary study of pile driving tests in the field, the origin of the soil at laboratory scale, has been carried out. Based on our analysis result of the measurement data, it is found that the hydrophilic coating has different effects on pile driving at laboratory and field scales. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At laboratory scale, hydrophilic coating on the surface of precast concrete piles is capable of affecting the piles to be installed into a certain depth level with less number of hammer strokes than piles without coating. In this work, a preliminary study of pile driving tests in the field, the origin of the soil at laboratory scale, has been carried out. Based on our analysis result of the measurement data, it is found that the hydrophilic coating has different effects on pile driving at laboratory and field scales. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Answer selection using Word Alignment based on Part of Speech Tagging in community question answering"
        ],
        "penulis":"Sutedi, Ade;Bijaksana, Moch. Arif;Romadhony, Ade;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper explain about answer selection using word alignment based on POS tagging in Community Question-Answering (CQA). This online community allowed the user to ask and reply related to the question problems which has no restrictions. This causes inappropriate comments with the question problems proposed before. To solve these problems, combining lexical and semantic features has been developed with result conclude that the approach more adequate for similarity task rather than question answering. According to the previous research, there is several problems that can be enhanced. First, vector representation counts exactly matched words, so it does not effective to cover other words that have relatedness between two pairing words. Second, noun overlap for similarity measure in pairing words can't define that the two words are similar. So, it must be define that the pairing POS tag is the same meaning or relatedness. In this study, unsupervised lexical and semantic similarity method employed with different approach from previous method in verbatim and contextual similarities. The data was taken from SemEval 2017 competition which focus on Question-Answer Similarity task. The experiment result for precision (Mean Average Precision) score shows the improvement from 0.674 to 0.6845, 1.03 % higher than previous research in CQA. This improvement comes from lexical similarity, which is not just from noun pattern but also taken from verb pattern. Furthermore, semantic similarity has an important role in determining which words that have same pattern and meaning to define relevancy between them. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper explain about answer selection using word alignment based on POS tagging in Community Question-Answering (CQA). This online community allowed the user to ask and reply related to the question problems which has no restrictions. This causes inappropriate comments with the question problems proposed before. To solve these problems, combining lexical and semantic features has been developed with result conclude that the approach more adequate for similarity task rather than question answering. According to the previous research, there is several problems that can be enhanced. First, vector representation counts exactly matched words, so it does not effective to cover other words that have relatedness between two pairing words. Second, noun overlap for similarity measure in pairing words can't define that the two words are similar. So, it must be define that the pairing POS tag is the same meaning or relatedness. In this study, unsupervised lexical and semantic similarity method employed with different approach from previous method in verbatim and contextual similarities. The data was taken from SemEval 2017 competition which focus on Question-Answer Similarity task. The experiment result for precision (Mean Average Precision) score shows the improvement from 0.674 to 0.6845, 1.03 % higher than previous research in CQA. This improvement comes from lexical similarity, which is not just from noun pattern but also taken from verb pattern. Furthermore, semantic similarity has an important role in determining which words that have same pattern and meaning to define relevancy between them. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Developing the maturity model for gig economy business processes"
        ],
        "penulis":"Gandhi, Arfive;Budiardjo, Eko Kuswardono;Giri Sucahyo, Yudho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Actualizes the progressiveness of digital business, gig economy brings easiness for people to search and do project using platforms. This opportunity may affect many treats, such as inefficient business processes and lack of professionalism. Many operators of gig platform govern their business processes intuitively without clear method or roadmap so that their growth is not predictable. This study proposes maturity model for gig economy business process to standardize growth of gig economy by considering the differentiating factors. It encompasses five levels: Initial, Defined, Standardized, Measured, and Optimized. They are appraised using eight staged Business Process Areas, related Specific Goals, and detail Specific Practices. This model relies on the evidence as Work Product to decide the compliance on each level. This maturity model is developed through five phases with hierarchy from CMMI-Service. It produces guidance to evaluate current reflection and formulate necessary improvement towards mature and qualified business processes in gig economy. Therefore, gig economy can generate more benefits and contributions for society. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Actualizes the progressiveness of digital business, gig economy brings easiness for people to search and do project using platforms. This opportunity may affect many treats, such as inefficient business processes and lack of professionalism. Many operators of gig platform govern their business processes intuitively without clear method or roadmap so that their growth is not predictable. This study proposes maturity model for gig economy business process to standardize growth of gig economy by considering the differentiating factors. It encompasses five levels: Initial, Defined, Standardized, Measured, and Optimized. They are appraised using eight staged Business Process Areas, related Specific Goals, and detail Specific Practices. This model relies on the evidence as Work Product to decide the compliance on each level. This maturity model is developed through five phases with hierarchy from CMMI-Service. It produces guidance to evaluate current reflection and formulate necessary improvement towards mature and qualified business processes in gig economy. Therefore, gig economy can generate more benefits and contributions for society. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Comparison of heat transfer coefficient on single tube and multi tube heat exchanger"
        ],
        "penulis":"Permana, Ikhwan;Ajiwiguna, Tri Ayodha;Kirom, Mukhammad Ramdlan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Heat exchanger (HX) is a device that provides heat exchange between two fluids that have temperature difference. Heat exchanger is widely applied to industrial process, power plant, transportation, air conditioning and refrigeration. In this study, the heat transfer coefficient between single tube and multi tube with the same heat transfer surface area are compared. The dimension of single tube heat exchanger is 40 cm length with 9.5 cm diameters. On the other hand, the multi tubes heat exchanger consists of ten tubes with 0.95 diameters and 40 cm length. These heat exchangers are submerged in low temperature water and the ambient air is streamed by fan with 0.0032 kg\/s, 0.0026 kg\/s, and 0.002 kg\/s of mass flow rate. The experiment is performed for two hours. The temperature of ambient, outlet air, and water are recorded using T-type thermocouple. The heat transfer coefficient are then analyzed. The result shows that heat transfer coefficient of multi-tubes heat exchanger are 26.6% higher than single tube heat exchanger. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Heat exchanger (HX) is a device that provides heat exchange between two fluids that have temperature difference. Heat exchanger is widely applied to industrial process, power plant, transportation, air conditioning and refrigeration. In this study, the heat transfer coefficient between single tube and multi tube with the same heat transfer surface area are compared. The dimension of single tube heat exchanger is 40 cm length with 9.5 cm diameters. On the other hand, the multi tubes heat exchanger consists of ten tubes with 0.95 diameters and 40 cm length. These heat exchangers are submerged in low temperature water and the ambient air is streamed by fan with 0.0032 kg\/s, 0.0026 kg\/s, and 0.002 kg\/s of mass flow rate. The experiment is performed for two hours. The temperature of ambient, outlet air, and water are recorded using T-type thermocouple. The heat transfer coefficient are then analyzed. The result shows that heat transfer coefficient of multi-tubes heat exchanger are 26.6% higher than single tube heat exchanger. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Adaptive hierarchical formation control for uncertain Euler\u2013Lagrange systems using distributed inverse dynamics"
        ],
        "penulis":"Rosa, Muhammad Ridho;Baldi, Simone;Wang, Ximan;Lv, Maolong;Yu, Wenwu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper establishes a novel adaptive hierarchical formation control method for uncertain heterogeneous nonlinear agents described by Euler\u2013Lagrange (EL) dynamics. Formation control is framed as a synchronization problem where a distributed model reference adaptive control is used to synchronize the EL systems. The idea behind the proposed adaptive formation algorithm is that each agent must converge to the model defined by its hierarchically superior neighbors. Using a distributed inverse dynamics structure, we prove that distributed nonlinear matching conditions between connected agents hold, so that matching gains exist to make the entire formation converge to same homogeneous dynamics: to compensate for the presence of uncertainties, estimation laws are devised for such matching gains, leading to adaptive synchronization. An appropriately designed distributed Lyapunov function is used to derive asymptotic convergence of the synchronization error. The effectiveness of the proposed methodology is supported by simulations of a formation of Unmanned Aerial Vehicles (UAVs). \u00a9 2018 European Control Association",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper establishes a novel adaptive hierarchical formation control method for uncertain heterogeneous nonlinear agents described by Euler\u2013Lagrange (EL) dynamics. Formation control is framed as a synchronization problem where a distributed model reference adaptive control is used to synchronize the EL systems. The idea behind the proposed adaptive formation algorithm is that each agent must converge to the model defined by its hierarchically superior neighbors. Using a distributed inverse dynamics structure, we prove that distributed nonlinear matching conditions between connected agents hold, so that matching gains exist to make the entire formation converge to same homogeneous dynamics: to compensate for the presence of uncertainties, estimation laws are devised for such matching gains, leading to adaptive synchronization. An appropriately designed distributed Lyapunov function is used to derive asymptotic convergence of the synchronization error. The effectiveness of the proposed methodology is supported by simulations of a formation of Unmanned Aerial Vehicles (UAVs). \u00a9 2018 European Control Association"
        ]
    },
    {
        "judul":[
            "Discrete Wavelet Transform on static hand gesture recognition"
        ],
        "penulis":"Candrasari, Erizka Banuwati;Novamizanti, Ledya;Aulia, Suci;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The technology in present-day is very useful for human-physical recognition and the hand gesture recognition is one of them. Nevertheless, that technology still had various weakness, for example in the image brightness, contrast, recognition time, and accuracy rate. The objective of this paper was to construct hand gesture recognition system using RGB images. Pre-processing is wrought by resizing the image, separate the hand area, and pick the specific layer. This experiment used the YCbCr because its derived directly from RGB and had a higher contrast compared to other layers. The feature value was gathered from feature extraction on Discrete Wavelet Transform (DWT) using Low-Low sub-band and 2ndlevel decomposition. The current sub-band had smoothest contours in comparison with other sub-band. The final process was gesture classification using Hidden Markov Models (HMM) and K-Nearest Neighbor (KNN). The amount of training and testing data used were 150 and 100 images respectively, divided into five gestures with accuracy using HMM and KNN consecutively was 58% and 100%. The research novelty was that the classification impacted positively on accuracy level. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The technology in present-day is very useful for human-physical recognition and the hand gesture recognition is one of them. Nevertheless, that technology still had various weakness, for example in the image brightness, contrast, recognition time, and accuracy rate. The objective of this paper was to construct hand gesture recognition system using RGB images. Pre-processing is wrought by resizing the image, separate the hand area, and pick the specific layer. This experiment used the YCbCr because its derived directly from RGB and had a higher contrast compared to other layers. The feature value was gathered from feature extraction on Discrete Wavelet Transform (DWT) using Low-Low sub-band and 2ndlevel decomposition. The current sub-band had smoothest contours in comparison with other sub-band. The final process was gesture classification using Hidden Markov Models (HMM) and K-Nearest Neighbor (KNN). The amount of training and testing data used were 150 and 100 images respectively, divided into five gestures with accuracy using HMM and KNN consecutively was 58% and 100%. The research novelty was that the classification impacted positively on accuracy level. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Fire Detection Using Image Processing Techniques with Convolutional Neural Networks"
        ],
        "penulis":"Sadewa, Raam Pujangga;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Fire is a flame, whether it is small or large, an undesirable place, situation and time. In general, every place has the potential to experience a fire. But at this time, the smoke sensors are the most widely used devices to detect fires. Where the smoke sensors can only detect fires if the fire is large. So that a system is needed to detect early fires. In this paper, an image-based fire alarm system is designed, using a laptop and webcam as the main equipment. The method for using Convolutional Neural Networks (CNN) to identify fire. The system created has an accuracy rate of 92%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Fire is a flame, whether it is small or large, an undesirable place, situation and time. In general, every place has the potential to experience a fire. But at this time, the smoke sensors are the most widely used devices to detect fires. Where the smoke sensors can only detect fires if the fire is large. So that a system is needed to detect early fires. In this paper, an image-based fire alarm system is designed, using a laptop and webcam as the main equipment. The method for using Convolutional Neural Networks (CNN) to identify fire. The system created has an accuracy rate of 92%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Smart shopping prediction on smart shopping with linear regression method"
        ],
        "penulis":"Nastiti, Medina Diani;Abdurohman, Maman;Putrada, Aji Gautama;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "IoT-based shopping needs can provide convenience in shopping. But this experience can be improved by the ability to predict the needs of goods. Until now the solution to this problem is not available. This is the reason we offer a Smart Shopping System. This system will classify food ingredients based on the amount of food stock in which the amount of stock is the result of the estimated time series data. The system will forecast each food supply by studying patterns of food use in the past using Linear Regression techniques. The system is implemented using Raspberry Pi, webcams, and barcode image processing for stock counting at home and a smartphone for the application dashboard. From a limited period of research, forecasting performance results that show that linear regression provides good accuracy in predictions. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "IoT-based shopping needs can provide convenience in shopping. But this experience can be improved by the ability to predict the needs of goods. Until now the solution to this problem is not available. This is the reason we offer a Smart Shopping System. This system will classify food ingredients based on the amount of food stock in which the amount of stock is the result of the estimated time series data. The system will forecast each food supply by studying patterns of food use in the past using Linear Regression techniques. The system is implemented using Raspberry Pi, webcams, and barcode image processing for stock counting at home and a smartphone for the application dashboard. From a limited period of research, forecasting performance results that show that linear regression provides good accuracy in predictions. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The effect of product quality, price, and e-advertising on the production purchase in WITHI batik boutique"
        ],
        "penulis":"Rachmawati, Mariana;Sukandi, Pipin;Saefudin, Nugraha;Handayani, Rini;Taufik Hidayat, Riski;Kurniawan, Ryan;Sofyandi, Herman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The Object Of Research In The Preparation Of This Thesis Is Withi Batik Boutique In This Study The Authors Examined The Effect Of Product Quality, Price, Advertising, On The Process Of Purchasing Decisions. The Unit Of Analysis Of This Research Is Consumers Of Withi Batik Boutique. In This Study The Authors Set A Sample Of 200 Respondents. In This Study the Author Uses Descriptive-Verification Research Method. By Testing The Hypothesis Multiple Linear Regression. T Test For Partial Test And F Test For Model Test. From The Results Of This Study It Can Be Concluded: Overall Product Quality Is In Good Category. This Is Reflected In The Responses Of Respondents That Batik In Withi Batik Boutique Has A Variety Of Motifs, Several Diverse Samples Of De'cantikqu Muslim Clothing Products Show A Buyer 'S Desire To Be More Fashionable, The Overall Price Of Withi Batik Boutique Is In The Appropriate Category With The Quality Provided. The Overall E-Advertising Of Withi Batik Boutique Has Been Effectively Carried Out As Well As The Level Of Visual Uniqueness Of The Advertisement Used By Withi Batik Boutique, The Frequency Of Withi Batik Boutique Advertisements In Online Media (Facebook And Instagram). Based On The Testing Of Statistical Analysis The Results Of Product Quality Have A Strong Influence On The Process Of Purchasing Clothing Products. Price Policy Has A Strong Influence On The Process Of Purchasing Clothing Products. While E-Advertising Has A Strong Influence On The Process Of Purchasing Clothing Products. The Results Of The Coefficient Of Determination And Hypothesis Testing Partially Indicate That E-Advertising Has A Significant Effect On The Variables Of The Process Of Purchasing Clothing Products. Simultaneous Hypothesis Test Results Show That There Are Significant (Simultaneous) Effects Of Product Quality, Price, And E-Advertising On The Process Of Purchasing Clothing Products. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Object Of Research In The Preparation Of This Thesis Is Withi Batik Boutique In This Study The Authors Examined The Effect Of Product Quality, Price, Advertising, On The Process Of Purchasing Decisions. The Unit Of Analysis Of This Research Is Consumers Of Withi Batik Boutique. In This Study The Authors Set A Sample Of 200 Respondents. In This Study the Author Uses Descriptive-Verification Research Method. By Testing The Hypothesis Multiple Linear Regression. T Test For Partial Test And F Test For Model Test. From The Results Of This Study It Can Be Concluded: Overall Product Quality Is In Good Category. This Is Reflected In The Responses Of Respondents That Batik In Withi Batik Boutique Has A Variety Of Motifs, Several Diverse Samples Of De'cantikqu Muslim Clothing Products Show A Buyer 'S Desire To Be More Fashionable, The Overall Price Of Withi Batik Boutique Is In The Appropriate Category With The Quality Provided. The Overall E-Advertising Of Withi Batik Boutique Has Been Effectively Carried Out As Well As The Level Of Visual Uniqueness Of The Advertisement Used By Withi Batik Boutique, The Frequency Of Withi Batik Boutique Advertisements In Online Media (Facebook And Instagram). Based On The Testing Of Statistical Analysis The Results Of Product Quality Have A Strong Influence On The Process Of Purchasing Clothing Products. Price Policy Has A Strong Influence On The Process Of Purchasing Clothing Products. While E-Advertising Has A Strong Influence On The Process Of Purchasing Clothing Products. The Results Of The Coefficient Of Determination And Hypothesis Testing Partially Indicate That E-Advertising Has A Significant Effect On The Variables Of The Process Of Purchasing Clothing Products. Simultaneous Hypothesis Test Results Show That There Are Significant (Simultaneous) Effects Of Product Quality, Price, And E-Advertising On The Process Of Purchasing Clothing Products. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "Performance Evaluation of Soil Substance Measurement System in Garlic Plant based on Internet of Things with Mesh Topology Network Scenario"
        ],
        "penulis":"Perdana, Doan;Imadudin, Muhammad;Bisono, Gustommy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The high consumption followed by low production makes the government have to import garlic to meet domestic needs every year. To help increase garlic yields, a system designed to facilitate the process of measuring Nitrogen (N), Phosphorus (P), Potassium (K) content on plantation land in real-time using NPK sensor and nodemcu as microcontrollers and provide the connectivity of real-time information using mesh topology. This system is an Internet of Things (IoT) based network, where internet connectivity is used to exchange information with each other with the objects around it. The result of the design of this system is a device to measure each element of N, P, and K as well as fertility status based on NPK values that have been obtained. And, with the IoT feature and mesh topology built in this device, the measurement data and whether or not the device works can be monitored easily through an android application that has been made on a smartphone. The mesh topology that built in this device is using painlessmesh library where the network built on the system is a true ad-hoc network, meaning that no-planning or central controller is required. We conclude that the accuracy of the measurement data compared to the NPK meter analog (Doctor Plant) is above 90%. Based on the durability test of the device and the system using Xiaomi's power bank of 5000mAh, the device and the system work well for 30 hours without any problems. Moreover, the accuracy of the data measured and uploaded to the database is no error with a 100% compatibility rate. \u00a9 2019 Kohat University of Science and Technology. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The high consumption followed by low production makes the government have to import garlic to meet domestic needs every year. To help increase garlic yields, a system designed to facilitate the process of measuring Nitrogen (N), Phosphorus (P), Potassium (K) content on plantation land in real-time using NPK sensor and nodemcu as microcontrollers and provide the connectivity of real-time information using mesh topology. This system is an Internet of Things (IoT) based network, where internet connectivity is used to exchange information with each other with the objects around it. The result of the design of this system is a device to measure each element of N, P, and K as well as fertility status based on NPK values that have been obtained. And, with the IoT feature and mesh topology built in this device, the measurement data and whether or not the device works can be monitored easily through an android application that has been made on a smartphone. The mesh topology that built in this device is using painlessmesh library where the network built on the system is a true ad-hoc network, meaning that no-planning or central controller is required. We conclude that the accuracy of the measurement data compared to the NPK meter analog (Doctor Plant) is above 90%. Based on the durability test of the device and the system using Xiaomi's power bank of 5000mAh, the device and the system work well for 30 hours without any problems. Moreover, the accuracy of the data measured and uploaded to the database is no error with a 100% compatibility rate. \u00a9 2019 Kohat University of Science and Technology. All rights reserved."
        ]
    },
    {
        "judul":[
            "Aperture Antennas for 5G Mobile Base Stations"
        ],
        "penulis":"Yamada, Yoshihide;Quzwain, Kamelia;Ansarudin, Farizah;Kamardin, Kamilia;Abd Rahman, Nurul Huda;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The fifth-generation (5G) mobile communication system will require the multi beam base station antennas. By taking into account a small antenna size at millimeter wave, any antenna types such as array, reflector and dielectric lens antennas become possible candidate. In this paper, aperture type antennas of reflector and lens are selected because of excellent multi beam performances. Fundamental antenna design technologies by a MATLAB software and expected radiation patterns by an electromagnetic simulator are shown. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The fifth-generation (5G) mobile communication system will require the multi beam base station antennas. By taking into account a small antenna size at millimeter wave, any antenna types such as array, reflector and dielectric lens antennas become possible candidate. In this paper, aperture type antennas of reflector and lens are selected because of excellent multi beam performances. Fundamental antenna design technologies by a MATLAB software and expected radiation patterns by an electromagnetic simulator are shown. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Value Chain Model on Small and Medium Enterprises (SMEs): A Case Study of Coffee Shops in Bandung"
        ],
        "penulis":"Anggadwita G.;Profityo W.B.;Permatasari A.;Alamanda D.T.;Hasfie M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia is one of countries as the best quality coffee producers in the world. Indonesia's geographical location is ideal for coffee growth and production, resulting in the diversity of coffee products with distinctive tastes. This led to the development of coffee shop business in Indonesia, especially in Bandung. Coffee business thrives in Indonesia and develops into a business with a scale of SMEs. This study aims to analyze the value chain model in coffee shop business in Bandung by mapping the input-output relationship, and identifying strength factors along the value chain. The research method used qualitative method with case study approach. The informant was determined by purposive sampling technique. Triangulation analysis is conducted to get more accurate and deep of data analysis. The results showed that the main activities and supporters in the coffee shop value chain in Bandung involve four main actors, namely local coffee farmers, coffee traders, processing industries, and coffee shops. This study contributes a similar trend to be observed in other coffee shop business value chains. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is one of countries as the best quality coffee producers in the world. Indonesia's geographical location is ideal for coffee growth and production, resulting in the diversity of coffee products with distinctive tastes. This led to the development of coffee shop business in Indonesia, especially in Bandung. Coffee business thrives in Indonesia and develops into a business with a scale of SMEs. This study aims to analyze the value chain model in coffee shop business in Bandung by mapping the input-output relationship, and identifying strength factors along the value chain. The research method used qualitative method with case study approach. The informant was determined by purposive sampling technique. Triangulation analysis is conducted to get more accurate and deep of data analysis. The results showed that the main activities and supporters in the coffee shop value chain in Bandung involve four main actors, namely local coffee farmers, coffee traders, processing industries, and coffee shops. This study contributes a similar trend to be observed in other coffee shop business value chains. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Digital leadership role in developing business model innovation and customer experience orientation in industry 4.0"
        ],
        "penulis":"Mihardjo, Leonardus W. W.;Sasmoko, Sasmoko;Alamsjah, Firdaus;Elidjen, Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 4.0 brings a new challenge for incumbent firms to anticipate new business model offered by emerging entries. The digital transformation is required by incumbent to develop innovation on product and service business model based on customer experience orientation. To support this transformation, strong digital leader is important to assure the development of this transformation. The study on the role of digital leadership on business model innovation and customer experience has not been explored, significantly, Hence, this research aims at assessing the role of digital leadership, whether it directly or indirectly influences the customer experience orientation in developing business model innovation. This study was conducted through survey to 88 senior leader respondents from Indonesia telecommunication firms, in which Smart-PLS application was used to analyze the data. The result show that digital leadership had direct and indirect impacts on customer experience orientation in developing business model innovation. The practical implications of these findings are recommended for the senior leader of management of telecommunications industries in Indonesia to strengthen digital leadership capability in conjunction with the development of business model innovation and customer experience orientation. Further research can be explored by expanding the sample, industry, statistical application and longitudinal study. \u00a9 2019 by the authors; licensee Growing Science, Canada. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 4.0 brings a new challenge for incumbent firms to anticipate new business model offered by emerging entries. The digital transformation is required by incumbent to develop innovation on product and service business model based on customer experience orientation. To support this transformation, strong digital leader is important to assure the development of this transformation. The study on the role of digital leadership on business model innovation and customer experience has not been explored, significantly, Hence, this research aims at assessing the role of digital leadership, whether it directly or indirectly influences the customer experience orientation in developing business model innovation. This study was conducted through survey to 88 senior leader respondents from Indonesia telecommunication firms, in which Smart-PLS application was used to analyze the data. The result show that digital leadership had direct and indirect impacts on customer experience orientation in developing business model innovation. The practical implications of these findings are recommended for the senior leader of management of telecommunications industries in Indonesia to strengthen digital leadership capability in conjunction with the development of business model innovation and customer experience orientation. Further research can be explored by expanding the sample, industry, statistical application and longitudinal study. \u00a9 2019 by the authors; licensee Growing Science, Canada. All rights reserved."
        ]
    },
    {
        "judul":[
            "Answer selection using Word Alignment based on Part of Speech Tagging in community question answering"
        ],
        "penulis":"Sutedi, Ade;Bijaksana, Moch. Arif;Romadhony, Ade;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper explain about answer selection using word alignment based on POS tagging in Community Question-Answering (CQA). This online community allowed the user to ask and reply related to the question problems which has no restrictions. This causes inappropriate comments with the question problems proposed before. To solve these problems, combining lexical and semantic features has been developed with result conclude that the approach more adequate for similarity task rather than question answering. According to the previous research, there is several problems that can be enhanced. First, vector representation counts exactly matched words, so it does not effective to cover other words that have relatedness between two pairing words. Second, noun overlap for similarity measure in pairing words can't define that the two words are similar. So, it must be define that the pairing POS tag is the same meaning or relatedness. In this study, unsupervised lexical and semantic similarity method employed with different approach from previous method in verbatim and contextual similarities. The data was taken from SemEval 2017 competition which focus on Question-Answer Similarity task. The experiment result for precision (Mean Average Precision) score shows the improvement from 0.674 to 0.6845, 1.03 % higher than previous research in CQA. This improvement comes from lexical similarity, which is not just from noun pattern but also taken from verb pattern. Furthermore, semantic similarity has an important role in determining which words that have same pattern and meaning to define relevancy between them. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper explain about answer selection using word alignment based on POS tagging in Community Question-Answering (CQA). This online community allowed the user to ask and reply related to the question problems which has no restrictions. This causes inappropriate comments with the question problems proposed before. To solve these problems, combining lexical and semantic features has been developed with result conclude that the approach more adequate for similarity task rather than question answering. According to the previous research, there is several problems that can be enhanced. First, vector representation counts exactly matched words, so it does not effective to cover other words that have relatedness between two pairing words. Second, noun overlap for similarity measure in pairing words can't define that the two words are similar. So, it must be define that the pairing POS tag is the same meaning or relatedness. In this study, unsupervised lexical and semantic similarity method employed with different approach from previous method in verbatim and contextual similarities. The data was taken from SemEval 2017 competition which focus on Question-Answer Similarity task. The experiment result for precision (Mean Average Precision) score shows the improvement from 0.674 to 0.6845, 1.03 % higher than previous research in CQA. This improvement comes from lexical similarity, which is not just from noun pattern but also taken from verb pattern. Furthermore, semantic similarity has an important role in determining which words that have same pattern and meaning to define relevancy between them. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Lessons learned to increase the digital startupssuccess rate"
        ],
        "penulis":"Mukti, Iqbal Yulizar;Wibowo, Ari Purno Wahyu;Galih, Savitri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose:The purpose of this paper is to explore the lessons learned to increase the startups\u2019 success rate based on a case study in Selurup, a digital startup worked on food delivery services. Design\/methodology\/approach: To systematically identify the lessons learned, and this paper adopts the hypothesis-driven entrepreneurship framework. Guides by research questions described in the introduction section, the lessons learned are elaborated by using interviews with the co-founder. Findings: Research in this paper, ultimately suggest the emerging digital startups to follow the hypothesis-driven entrepreneurship framework as the structured approach to face the extreme uncertainty that typically faced by the startups. Research limitations\/implications: Research in this paper explores the lessons learned only from one startup. Consequently, the lesson learned might not represented all the startups in Indonesia. Practical implications: It is expected that the lessons learned from this research can give positive contribution to increase the emerging digital startups success rate. Originality\/value: This study academically explores the lesson learned especially from the emerging digital startups, following the hypothesis-driven entrepreneurship framework. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose:The purpose of this paper is to explore the lessons learned to increase the startups\u2019 success rate based on a case study in Selurup, a digital startup worked on food delivery services. Design\/methodology\/approach: To systematically identify the lessons learned, and this paper adopts the hypothesis-driven entrepreneurship framework. Guides by research questions described in the introduction section, the lessons learned are elaborated by using interviews with the co-founder. Findings: Research in this paper, ultimately suggest the emerging digital startups to follow the hypothesis-driven entrepreneurship framework as the structured approach to face the extreme uncertainty that typically faced by the startups. Research limitations\/implications: Research in this paper explores the lessons learned only from one startup. Consequently, the lesson learned might not represented all the startups in Indonesia. Practical implications: It is expected that the lessons learned from this research can give positive contribution to increase the emerging digital startups success rate. Originality\/value: This study academically explores the lesson learned especially from the emerging digital startups, following the hypothesis-driven entrepreneurship framework. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "Hybrid Filter for Attributes Reduction in Soft Set"
        ],
        "penulis":"Mohammed, Mohammed Adam Taheir;Mohd, Wan Maseri Wan;Arshah, Ruzaini Abdullah;Mungad M.;Sutoyo, Edi;Chiroma, Haruna;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of this research is to overcome parameterization reduction limitation that focuses only on individual parameter reduction, whereas in some cases the individual parameter reduction is not sufficient even implies reduction. It was found that the dimensions sometimes are not able to reduce the number of data in the case of big data; hence, for this reason it became necessary to look for an alternative technique that can significantly reduce the parameters. This paper proposed an alternative decision partition order method based on rough set indiscernibility to select attributes reductions in soft set using decompositions. For significant candidates, the method decomposition partition order used R supp checking to confirm the correctness of the reduction. Comparison of the reduction methods shows that the proposed method provides better result than the parameterization reduction in enhancing reduction. The false candidates were filtered in the huge candidate reduction by the Min supp. The proposed method can be used to maintain object before attribute reduction as well as to reduce parameter size drastically while maintaining consistency in decision making. \u00a9 Springer Nature Singapore Pte Ltd. 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this research is to overcome parameterization reduction limitation that focuses only on individual parameter reduction, whereas in some cases the individual parameter reduction is not sufficient even implies reduction. It was found that the dimensions sometimes are not able to reduce the number of data in the case of big data; hence, for this reason it became necessary to look for an alternative technique that can significantly reduce the parameters. This paper proposed an alternative decision partition order method based on rough set indiscernibility to select attributes reductions in soft set using decompositions. For significant candidates, the method decomposition partition order used R supp checking to confirm the correctness of the reduction. Comparison of the reduction methods shows that the proposed method provides better result than the parameterization reduction in enhancing reduction. The false candidates were filtered in the huge candidate reduction by the Min supp. The proposed method can be used to maintain object before attribute reduction as well as to reduce parameter size drastically while maintaining consistency in decision making. \u00a9 Springer Nature Singapore Pte Ltd. 2019."
        ]
    },
    {
        "judul":[
            "Hjorth descriptor as feature extraction for classification of familiarity in EEG signal"
        ],
        "penulis":"Sanggarini, Hannissa;Wijayanto, Inung;Hadiyoso, Sugondo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Deficiency in identifying human emotional stages occurs in most of the existing contemporary Human-Computer Interactions (HCI) systems. There are vast areas of the human stages that can be identified. One of them is the stage when a human feels familiar. Electroencephalogram (EEG) signal can be used to detect human affective stage in familiarity category. This research classifies familiarity in EEG signal using data from DEAP: A Database for Emotion Analysis Using Physiological Signals. The signal feature was extracted using Hjorth Descriptor producing three parameters. The parameters then fed to the Multilayer Perceptron as the classifier. The best accuracy achieved was 92.85% using three features combination, with 2.132 seconds of computation time. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Deficiency in identifying human emotional stages occurs in most of the existing contemporary Human-Computer Interactions (HCI) systems. There are vast areas of the human stages that can be identified. One of them is the stage when a human feels familiar. Electroencephalogram (EEG) signal can be used to detect human affective stage in familiarity category. This research classifies familiarity in EEG signal using data from DEAP: A Database for Emotion Analysis Using Physiological Signals. The signal feature was extracted using Hjorth Descriptor producing three parameters. The parameters then fed to the Multilayer Perceptron as the classifier. The best accuracy achieved was 92.85% using three features combination, with 2.132 seconds of computation time. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Face expression recognition using Local Gabor Binary Pattern Three Orthogonal Planes (LGBP-TOP) and Support Vector Machine (SVM) method"
        ],
        "penulis":"Dewi R.R.K.;Sthevanie F.;Arifianto A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The video expression recognition system has been created before using the Local Gabor Binary Pattern Three Orthogonal Planes (LGBP-TOP) extraction method and the Support Vector Machine (SVM) classifi-cation method. However, the recognizable facial expressions use the entire area of the face image, while the expression can be recognized from the change of face fiducial point on the eyes and lips only. In this study, the introduction of facial expressions was developed using LGBP-TOP and SVM methods by focusing on facial and lip images only. Therefore, an algorithm is needed to extract the eye and lip area of the face ima-ge using 3x3 blocks and 4x4 blocks, which will then be used as input on the LGBP-TOP method. After the image of the eyes and lips extracted its features, the extraction results are classified using the SVM method. The results obtained is the recognition of facial expressions using the eye and lip area get 80% accuracy and better than using the entire area of the face, eye area only, and lip area only. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The video expression recognition system has been created before using the Local Gabor Binary Pattern Three Orthogonal Planes (LGBP-TOP) extraction method and the Support Vector Machine (SVM) classifi-cation method. However, the recognizable facial expressions use the entire area of the face image, while the expression can be recognized from the change of face fiducial point on the eyes and lips only. In this study, the introduction of facial expressions was developed using LGBP-TOP and SVM methods by focusing on facial and lip images only. Therefore, an algorithm is needed to extract the eye and lip area of the face ima-ge using 3x3 blocks and 4x4 blocks, which will then be used as input on the LGBP-TOP method. After the image of the eyes and lips extracted its features, the extraction results are classified using the SVM method. The results obtained is the recognition of facial expressions using the eye and lip area get 80% accuracy and better than using the entire area of the face, eye area only, and lip area only. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Person entity recognition for the Indonesian Qur'an translation with the approach hidden Markov model-viterbi"
        ],
        "penulis":"Syachrul R.M.M.A.K.;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Qur'an contains teachings about life given by Allah to the Prophet Muhammad. In the Qur'an, there are a lot of verses. With a large number of verses, it will be very difficult and take a long time for us to find a name. Manually searching for entities will be very difficult and take a long time to be searched. With NER, which is one of the techniques of information extraction that aims to detect entity names, such as people's names, locations, events, and time expected search for entity names in the Qur'an will significantly simplify and shorten the time. Indonesian Qur'an translations will later be used as Inputs, and their names are entity names. The solution to the problem above is to use NER. The Named Entity (NE) Recognition (NER) system will look for name entities people from the corpus that have been created. In applying NER requires a model to detect name entities in a text. Hidden Markov Model-Viterbi is a machine learning algorithm type Supervised Learning which will be applied. In the development of a system for searching names entities for the Indonesian translation of the Qur'an dataset have best F1 results is 76%. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Qur'an contains teachings about life given by Allah to the Prophet Muhammad. In the Qur'an, there are a lot of verses. With a large number of verses, it will be very difficult and take a long time for us to find a name. Manually searching for entities will be very difficult and take a long time to be searched. With NER, which is one of the techniques of information extraction that aims to detect entity names, such as people's names, locations, events, and time expected search for entity names in the Qur'an will significantly simplify and shorten the time. Indonesian Qur'an translations will later be used as Inputs, and their names are entity names. The solution to the problem above is to use NER. The Named Entity (NE) Recognition (NER) system will look for name entities people from the corpus that have been created. In applying NER requires a model to detect name entities in a text. Hidden Markov Model-Viterbi is a machine learning algorithm type Supervised Learning which will be applied. In the development of a system for searching names entities for the Indonesian translation of the Qur'an dataset have best F1 results is 76%. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "Digital transformation: A transformational performance-based conceptual model through co-creation strategy and business model innovation in the Industry 4.0 in Indonesia"
        ],
        "penulis":"Wasono Mihardjo, Leonardus W.;Sasmoko;Alamsjah, Firdaus;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper seeks to portray the conceptual model of ICT companies in transforming their business and organisation capabilities to face Industry 4.0 through co-creation strategies and business model innovations in Indonesia markets. The Indonesian market is unique in terms of its ICT infrastructure, but still left behind compared to other countries. However, the market has tremendous opportunities in terms of digital capability innovations. The strategic management outline used as a framework for this paper. Mediating variables were co-creation strategies and business innovations with distinctive organisational capability as an internal factor and consumer orientation as the external independent factor. The construct of co-creation strategy and transformational performance were discussed. This model of digital transformation was a suitable model for senior leaders to transform digital business capability and academics. Moreover, the model and construct of variable can be used to further develop the theory of digital transformation. Copyright \u00a9 2019 Inderscience Enterprises Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper seeks to portray the conceptual model of ICT companies in transforming their business and organisation capabilities to face Industry 4.0 through co-creation strategies and business model innovations in Indonesia markets. The Indonesian market is unique in terms of its ICT infrastructure, but still left behind compared to other countries. However, the market has tremendous opportunities in terms of digital capability innovations. The strategic management outline used as a framework for this paper. Mediating variables were co-creation strategies and business innovations with distinctive organisational capability as an internal factor and consumer orientation as the external independent factor. The construct of co-creation strategy and transformational performance were discussed. This model of digital transformation was a suitable model for senior leaders to transform digital business capability and academics. Moreover, the model and construct of variable can be used to further develop the theory of digital transformation. Copyright \u00a9 2019 Inderscience Enterprises Ltd."
        ]
    },
    {
        "judul":[
            "Smart tracking and fall detection for golden age's citizen"
        ],
        "penulis":"Fauziah, Ratna Juwita;Mutiara, Giva Andriana;Periyadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Senior Citizen is an elderly human in a golden age who has many limitations. The number of older people is increasing in almost every country, including in Indonesia. One of the diseases that were suffered is senile or known as Dementia. Therefore, to protect the elderly, the special care is needed in order to be able to monitor the located and to see the condition of the elderly when they are travelling outside the home. Based on that condition, a prototype of the detector is proposed in this paper namely Smart tracking for the Golden Age's Citizen. This system consists of a GPS module, a vibration sensor, a GSM Module, and a voice recorder module. GPS module will detect the location, and the vibration sensor will detect the vibration if the elderly falls. The GSM module will send the information in the form of SMS to the family. The voice recorder module is used to record and play the recorded sound. Based on the results of the prototype test, the prototype is successfully detecting the location if the elderly is outside the range. The testing was concluding that the older people position can be tracked approximately around 2-5 meters from the determination in google map application and send an SMS in 3-5 seconds, if the user falls or lost. \u00a9 2019 The Authors.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Senior Citizen is an elderly human in a golden age who has many limitations. The number of older people is increasing in almost every country, including in Indonesia. One of the diseases that were suffered is senile or known as Dementia. Therefore, to protect the elderly, the special care is needed in order to be able to monitor the located and to see the condition of the elderly when they are travelling outside the home. Based on that condition, a prototype of the detector is proposed in this paper namely Smart tracking for the Golden Age's Citizen. This system consists of a GPS module, a vibration sensor, a GSM Module, and a voice recorder module. GPS module will detect the location, and the vibration sensor will detect the vibration if the elderly falls. The GSM module will send the information in the form of SMS to the family. The voice recorder module is used to record and play the recorded sound. Based on the results of the prototype test, the prototype is successfully detecting the location if the elderly is outside the range. The testing was concluding that the older people position can be tracked approximately around 2-5 meters from the determination in google map application and send an SMS in 3-5 seconds, if the user falls or lost. \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Influence of annealing temperature on the morphology and crystal structure of Ga-doped ZnO thin films"
        ],
        "penulis":"Sulhadi;Usriyah F.;Wibowo E.;Astuti B.;Sugianto;Aryanto D.;Marwoto P.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Ga-doped ZnO (ZnO:Ga) thin films have been deposited on Corning glass substrates by handmade dc magnetron sputtering. The pressure and deposition time respectively were set on 500 mTorr and 60 minutes. The deposition temperature was fixed at 300\u00b0C with 30 watts of plasma power. The deposited ZnO:Ga thin films were heated at 300\u00b0C, 350\u00b0C, and 400\u00b0C, respectively. The morphology and crystallinity of ZnO:Ga thin films have been observed with SEM and XRD. The observation with SEM shows that the film morphology is denser and the grain size is smaller when the temperature is increased. The crystallinity of the film increases as the annealing temperature is enhanced from 300\u00b0C to 350\u00b0C. However, the crystallinity of the ZnO:Ga films decreased when the annealing temperature is 400\u00b0C. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ga-doped ZnO (ZnO:Ga) thin films have been deposited on Corning glass substrates by handmade dc magnetron sputtering. The pressure and deposition time respectively were set on 500 mTorr and 60 minutes. The deposition temperature was fixed at 300\u00b0C with 30 watts of plasma power. The deposited ZnO:Ga thin films were heated at 300\u00b0C, 350\u00b0C, and 400\u00b0C, respectively. The morphology and crystallinity of ZnO:Ga thin films have been observed with SEM and XRD. The observation with SEM shows that the film morphology is denser and the grain size is smaller when the temperature is increased. The crystallinity of the film increases as the annealing temperature is enhanced from 300\u00b0C to 350\u00b0C. However, the crystallinity of the ZnO:Ga films decreased when the annealing temperature is 400\u00b0C. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "A new metaheuristics for solving traveling salesman problem: Partial comparison optimization"
        ],
        "penulis":"Adhi, Antono;Santosa, Budi;Siswanto, Nurhadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research article proposes new metaheuristics method to solve Traveling Salesman Problem (TSP). This method is called Partial Comparison Optimization (PCO). TSP is defined as a problem where a salesman must visit all cities where each city is only visited once, and must start from and return to the origin city. The goal of solving this problem is to determine the route with minimum total distance or cost. TSP was first formulated in 1930 and it is one of the most intensively studied problems in optimization. Variants and various application of TSP have been developed and solved to accomodate industrial problems. TSP is an NP-hard combinatorial optimization problem. It means TSP can be solved in polynomial time. Exact methods are hard to solve big size TSP problem. The process of the exact method needs longer computational time to solve the problem. The limitation of exact method in dealing with complex TSP only can be solved by metaheuristics. PCO is powerful metaheuristic to solve combinatorial problems such as TSP. To test the performance of PCO, it was used to solve some TSPLIB instances. In this research PCO gave good optimum solution that almost close to the optimal solution of every TSPLIB instance. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research article proposes new metaheuristics method to solve Traveling Salesman Problem (TSP). This method is called Partial Comparison Optimization (PCO). TSP is defined as a problem where a salesman must visit all cities where each city is only visited once, and must start from and return to the origin city. The goal of solving this problem is to determine the route with minimum total distance or cost. TSP was first formulated in 1930 and it is one of the most intensively studied problems in optimization. Variants and various application of TSP have been developed and solved to accomodate industrial problems. TSP is an NP-hard combinatorial optimization problem. It means TSP can be solved in polynomial time. Exact methods are hard to solve big size TSP problem. The process of the exact method needs longer computational time to solve the problem. The limitation of exact method in dealing with complex TSP only can be solved by metaheuristics. PCO is powerful metaheuristic to solve combinatorial problems such as TSP. To test the performance of PCO, it was used to solve some TSPLIB instances. In this research PCO gave good optimum solution that almost close to the optimal solution of every TSPLIB instance. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "40 Gb\/s balanced parallel scheme in dispersion compensating fiber performance for DWDM in the Long haul network"
        ],
        "penulis":"Pamukti, Brian;Hambali, Akhmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research contributes optimal dispersion compensating by adding a new scheme of parallel compensation with Dispersion Compensating Fiber (DCF). Using four wavelengths around 1550 nm, this research shows that scheme without DCF resulting in a very large dispersion with Q-factor value 6 at 150 km, post-compensation scheme produces a Q-factor with a value of 6.6 at a distance about 400 km and the pre-compensation scheme produces a Q-factor with a value of 7.4 at a distance of about 600 km. Merging post and pre-compensation in serial cable made length performance further than single scheme up to 50%. However, performance increase significantly is obtained with new parallel scheme around 85%. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research contributes optimal dispersion compensating by adding a new scheme of parallel compensation with Dispersion Compensating Fiber (DCF). Using four wavelengths around 1550 nm, this research shows that scheme without DCF resulting in a very large dispersion with Q-factor value 6 at 150 km, post-compensation scheme produces a Q-factor with a value of 6.6 at a distance about 400 km and the pre-compensation scheme produces a Q-factor with a value of 7.4 at a distance of about 600 km. Merging post and pre-compensation in serial cable made length performance further than single scheme up to 50%. However, performance increase significantly is obtained with new parallel scheme around 85%. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Method to estimate the temperature drop in hot fluid flow using empirical equation with experimental comparison: Case study of horizontal pipe"
        ],
        "penulis":"Rianti, Arinta;Ajiwiguna, Tri Ayodha;Ramdlan Kirom M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The piping system is used in the industry as a fluid distribution method. The temperature of hot fluid should be maintained with a certain tolerance. In the process of distribution, temperature decreasing occurs due heat loss. However, calculations of convection heat transfer by empirical equations can only be applied for constant temperature surface. In this study the calculation is performed by numerically making partitions along pipe to estimate the temperature profile along the pipe. To verify this estimation, piping configuration to stream the hot water on horizontal pipe is constructed. The dimension of pipe is 0.5 inch diameter and 1 m length. The experiment is carried out under the condition of the pipe with some various inlet temperature from 40oC to 60oC and thermal insulation thickness from 0 cm to 1.5 cm. The result shows that the calculation and experimental method have the same traits in which the temperature decreasing is minimum at the thickest insulation layer. The maximum temperature difference at the outlet pipe between the two methods is 3.2oC. The heat loss is also observed to be minimum in the lower water temperature inlet. Based on the experimental method, the maximum heat loss reduction is achieved at 63% between without insulation and 1.5 cm insulation thickness with 60oC inlet water temperature. However the change of heat loss reduction become more insignificant for thicker insulation layer.                          \u00a9 2019 American Institute of Physics Inc. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The piping system is used in the industry as a fluid distribution method. The temperature of hot fluid should be maintained with a certain tolerance. In the process of distribution, temperature decreasing occurs due heat loss. However, calculations of convection heat transfer by empirical equations can only be applied for constant temperature surface. In this study the calculation is performed by numerically making partitions along pipe to estimate the temperature profile along the pipe. To verify this estimation, piping configuration to stream the hot water on horizontal pipe is constructed. The dimension of pipe is 0.5 inch diameter and 1 m length. The experiment is carried out under the condition of the pipe with some various inlet temperature from 40oC to 60oC and thermal insulation thickness from 0 cm to 1.5 cm. The result shows that the calculation and experimental method have the same traits in which the temperature decreasing is minimum at the thickest insulation layer. The maximum temperature difference at the outlet pipe between the two methods is 3.2oC. The heat loss is also observed to be minimum in the lower water temperature inlet. Based on the experimental method, the maximum heat loss reduction is achieved at 63% between without insulation and 1.5 cm insulation thickness with 60oC inlet water temperature. However the change of heat loss reduction become more insignificant for thicker insulation layer.                          \u00a9 2019 American Institute of Physics Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "Synthesis of Spherical Nanostructured \u03b3-Al2O3 Particles using Cetyltrimethylammonium Bromide (CTAB) Reverse Micelle Templating"
        ],
        "penulis":"Benu, Didi P.;Suendo, Veinardi;Mukti, Rino R.;Febriyanti, Erna;Steky, Fry V.;Adhika, Damar R.;Tanuwijaya, Viny V.;Nugraha, Ashari B.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We demonstrated the synthesis of spherical nanostructured \u03b3-Al2O3 using reverse micelle templating to enhance the surface area and reactant accessibility. Three different surfactants were used in this study: benzalkonium chloride (BZK), sodium dodecyl sulfate (SDS) and cetyltrimethylammonium bromide (CTAB). We obtained spherical nanostructured particles only using CTAB that form a reverse micelle emulsion. The particles have wide size distribution with an average size of 2.54 \u03bcm. The spherical particles consist of nanoplate crystallites with size 20-40 nm randomly arranged forming intercrystallite spaces. The crystalline phase of as-synthesized and calcined particles was boehmite and \u03b3-Al2O3,respectively as determined by XRD analysis. Here, the preserved particle morphology during boehmite to \u03b3-Al2O3 transformation opens a facile route to synthesize \u03b3-Al2O3 particles with complex morphology. The specific surface area of synthesized particles is 201 m2\/g, which is around five times higher than the conventional \u03b3-Al2O3 (Aldrich 544833). Spherical nanostructured \u03b3-Al2O3 provides wide potential applications in catalysis due to its high density closed packed structure, large surface area, and high accessibility. Copyright \u00a9 2019 BCREC Group. All rights reserved.",
            "HNNNNHView detailsExpand Substance tetraphenylporphinAlOHOHHOView detailsExpand Substance aluminum hydroxideNH3CCH3H3CClView detailsExpand Substance zephirol",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We demonstrated the synthesis of spherical nanostructured \u03b3-Al2O3 using reverse micelle templating to enhance the surface area and reactant accessibility. Three different surfactants were used in this study: benzalkonium chloride (BZK), sodium dodecyl sulfate (SDS) and cetyltrimethylammonium bromide (CTAB). We obtained spherical nanostructured particles only using CTAB that form a reverse micelle emulsion. The particles have wide size distribution with an average size of 2.54 \u03bcm. The spherical particles consist of nanoplate crystallites with size 20-40 nm randomly arranged forming intercrystallite spaces. The crystalline phase of as-synthesized and calcined particles was boehmite and \u03b3-Al2O3,respectively as determined by XRD analysis. Here, the preserved particle morphology during boehmite to \u03b3-Al2O3 transformation opens a facile route to synthesize \u03b3-Al2O3 particles with complex morphology. The specific surface area of synthesized particles is 201 m2\/g, which is around five times higher than the conventional \u03b3-Al2O3 (Aldrich 544833). Spherical nanostructured \u03b3-Al2O3 provides wide potential applications in catalysis due to its high density closed packed structure, large surface area, and high accessibility. Copyright \u00a9 2019 BCREC Group. All rights reserved."
        ]
    },
    {
        "judul":[
            "The Haematological profiles of high fat diet mice model with moringa oleifera leaves ethanol extract treatment"
        ],
        "penulis":"Alia, Fenty;Syamsunarno, Mas Rizky A.A.;Sumirat, Vanessa Ayu;Ghozali, Mohammad;Atik, Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Characteristics of obesity as dysfunction of adipose tissue and chronic low-grade inflammation can have impacts to haematological parameters. The Moringa oleifera leaves have been used empirically to treat metabolic and blood related diseases. However, it is still unknown whether Moringa oleifera leaves can influence haematological parameters in high fat diet. The study aimed to investigate the haematological parameter of high fat diet mice in parallel with Moringa oleifera leaves ethanol extract (MOLE). Forty male DDY mice in 5 weeks of age were randomly divided into five groups as follows: The SD group was fed with a standard diet, the HFD group was fed with high fat diet, the HFD+S group was fed with high fat diet and simvastatin (0,8 mg\/20gBW\/day). The HFD+MOLE1 and the HFD+MOLE2 groups were fed with high fat diet and MOLE in a dose of 5,6 mg\/20gBW\/day and 11,2 mg\/20gBW\/day, respectively. The experiment was performed for 7 weeks. At the end of the experiment, blood was drawn for haematology analysis of blood parameters. We found that sub-chronic high fat diet might alter the haematological parameters. Two different doses of MOLE might have potencies to prevent the worsening caused by those alterations, by increased of haemoglobin[12,9(10,4-15,3) vs 13,9(12,9-18,2) and 14(10,2-14,8), p>0,05)], slight decreased of WBC [(3,59\u00b11,974) vs (3,433\u00b11,747) and (3,42\u00b11,014), p>0,05]. Additionally, the MOLE might have an effect to decreasing the granulocyte percentage [18,5(9,2-43,6) vs 11,5(7,6-18,2) and 8,05(3,2-25,1), p>0,05], and slight decreased of MPV [4,2(2,6-6,7) vs 3,6(3,2-4,1) and 3,55(2,6-6,8), p>0,05]. In summary, the study showed that MOLE might have potencies to prevent the worsening of hematological parameters in the sub-chronic high fat diet. Oriental Scientific Publishing Company \u00a9 2019",
            "NOOCH3CH3ClView detailsExpand Substance clomazoneOH3COCH3OH3CH3CCH3OHOHView detailsExpand Substance simvastatin",
            "Powered by",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Characteristics of obesity as dysfunction of adipose tissue and chronic low-grade inflammation can have impacts to haematological parameters. The Moringa oleifera leaves have been used empirically to treat metabolic and blood related diseases. However, it is still unknown whether Moringa oleifera leaves can influence haematological parameters in high fat diet. The study aimed to investigate the haematological parameter of high fat diet mice in parallel with Moringa oleifera leaves ethanol extract (MOLE). Forty male DDY mice in 5 weeks of age were randomly divided into five groups as follows: The SD group was fed with a standard diet, the HFD group was fed with high fat diet, the HFD+S group was fed with high fat diet and simvastatin (0,8 mg\/20gBW\/day). The HFD+MOLE1 and the HFD+MOLE2 groups were fed with high fat diet and MOLE in a dose of 5,6 mg\/20gBW\/day and 11,2 mg\/20gBW\/day, respectively. The experiment was performed for 7 weeks. At the end of the experiment, blood was drawn for haematology analysis of blood parameters. We found that sub-chronic high fat diet might alter the haematological parameters. Two different doses of MOLE might have potencies to prevent the worsening caused by those alterations, by increased of haemoglobin[12,9(10,4-15,3) vs 13,9(12,9-18,2) and 14(10,2-14,8), p>0,05)], slight decreased of WBC [(3,59\u00b11,974) vs (3,433\u00b11,747) and (3,42\u00b11,014), p>0,05]. Additionally, the MOLE might have an effect to decreasing the granulocyte percentage [18,5(9,2-43,6) vs 11,5(7,6-18,2) and 8,05(3,2-25,1), p>0,05], and slight decreased of MPV [4,2(2,6-6,7) vs 3,6(3,2-4,1) and 3,55(2,6-6,8), p>0,05]. In summary, the study showed that MOLE might have potencies to prevent the worsening of hematological parameters in the sub-chronic high fat diet. Oriental Scientific Publishing Company \u00a9 2019"
        ]
    },
    {
        "judul":[
            "Air pollution monitoring system using LoRa modul as transceiver system"
        ],
        "penulis":"Rosmiati, Mia;Rizal, Moch. Fachru;Susanti, Fitri;Alfisyahrin, Gilang Fahreza;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Air pollution is a disaster that can indirectly interfere with human health, Indonesia is the third highest country in the world that has pollution levels, one of the types of pollution that threatens public health is the increase of CO, NO2and SO2level in the air. With the increasing level of air pollution in the city, it requires a device that can monitor air pollution in a real time. By integrating air sensor and Raspberry Pi as data processor and using LoRa module as transceiver module, then the process of transmitting data from transmitter to receiver can be done directly without connected internet. In a test, the system can transmit intensity data information by wireless system on Line Of Sight (LOS) scemes at a maximum distance of 1.7 Km and Non Line Of Sight (NLOS) scheme at a distance of 400 meters with a average delay is 2 second. \u00a9 2019 Universitas Ahmad Dahlan.",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Sustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Air pollution is a disaster that can indirectly interfere with human health, Indonesia is the third highest country in the world that has pollution levels, one of the types of pollution that threatens public health is the increase of CO, NO2and SO2level in the air. With the increasing level of air pollution in the city, it requires a device that can monitor air pollution in a real time. By integrating air sensor and Raspberry Pi as data processor and using LoRa module as transceiver module, then the process of transmitting data from transmitter to receiver can be done directly without connected internet. In a test, the system can transmit intensity data information by wireless system on Line Of Sight (LOS) scemes at a maximum distance of 1.7 Km and Non Line Of Sight (NLOS) scheme at a distance of 400 meters with a average delay is 2 second. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Trade-off analysis for eco-tourism of the Tasik Kenyir protected area"
        ],
        "penulis":"Lola, Muhamad Safiih;Ramlee, Mohd Noor Afiq;Hussin, Mohd Fadli;Abdul Rahman, Muhamad Na'eim;Abdullah, Mohd Tajuddin;Kamil, Anton Abdulbasah;Mohamad Yusof, Izham;Ibrahim, Yahaya;Khadar, Nur Zafirah A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Continuous pandemic of sustainable development rise numerous concern, hence resulting towards integration of multidimensional principle as an underlay in order to form sound decision-making process especially in ecological-sensitive area such as Tasik Kenyir. This study develops the structural framework for decision-making inclusive of all variables in order to strive for sustainable development of Tasik Kenyir in order to promote responsible tourism practices. Several criteria are selected and analyzed using Multi-criteria Analysis (to show the corresponding trade-off); ranged from economic, ecological and social variables such as economic revenue, employment, conservation of flora and fauna and environmental quality. The results show that under different scenarios, the score of different type of variables will change accordingly. \u00a9 Springer Nature Switzerland AG 2019.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Continuous pandemic of sustainable development rise numerous concern, hence resulting towards integration of multidimensional principle as an underlay in order to form sound decision-making process especially in ecological-sensitive area such as Tasik Kenyir. This study develops the structural framework for decision-making inclusive of all variables in order to strive for sustainable development of Tasik Kenyir in order to promote responsible tourism practices. Several criteria are selected and analyzed using Multi-criteria Analysis (to show the corresponding trade-off); ranged from economic, ecological and social variables such as economic revenue, employment, conservation of flora and fauna and environmental quality. The results show that under different scenarios, the score of different type of variables will change accordingly. \u00a9 Springer Nature Switzerland AG 2019."
        ]
    },
    {
        "judul":[
            "The effect of organizational relationship and competitive strategy on the performance of wholesale network service business in Indonesia"
        ],
        "penulis":"Sutjipto, Moh. Riza;Sule, Ernie Tisnawati;Sucherly;Kaltum, Umi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to examine the influence of organizational relationship and competitive strategy on the performance of wholesale network services business in Indonesia partially and simultaneously. The research used is quantitative method. Observation using time horizon (time horizon) is cross section \/ one shot, meaning information or data obtained is the results of research conducted at one particular time in 2017. Unit analysis in this study is Wholesale Network service company in Indonesia, so the observations unitis the management of the Wholesale Network service company. Based on the result of documentation study, it is known that Wholesale Network service company in Indonesia amounts to \u00b1 29 companies, so that this research will be conducted by census to examine all members of the population. Causality analysis is used to analyze the causality relationship between research variables in accordance with the hypothesis that is compiled. This analysis uses Partial Least Square (PLS). The results showed that Organizational Relationship and Competitive Strategy significantly influenced Business Performance, where Organizational Relationship has greater influence than competitive strategy. The results of this study are expected to give implications to the management of wholesale network services company in Indonesia in an effort to improve business performance through organizational relationship development and competitive strategy. \u00a9 2019, Allied Business Academies. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to examine the influence of organizational relationship and competitive strategy on the performance of wholesale network services business in Indonesia partially and simultaneously. The research used is quantitative method. Observation using time horizon (time horizon) is cross section \/ one shot, meaning information or data obtained is the results of research conducted at one particular time in 2017. Unit analysis in this study is Wholesale Network service company in Indonesia, so the observations unitis the management of the Wholesale Network service company. Based on the result of documentation study, it is known that Wholesale Network service company in Indonesia amounts to \u00b1 29 companies, so that this research will be conducted by census to examine all members of the population. Causality analysis is used to analyze the causality relationship between research variables in accordance with the hypothesis that is compiled. This analysis uses Partial Least Square (PLS). The results showed that Organizational Relationship and Competitive Strategy significantly influenced Business Performance, where Organizational Relationship has greater influence than competitive strategy. The results of this study are expected to give implications to the management of wholesale network services company in Indonesia in an effort to improve business performance through organizational relationship development and competitive strategy. \u00a9 2019, Allied Business Academies. All rights reserved."
        ]
    },
    {
        "judul":[
            "Analysis of transient signal using hilbert-huang transform for chatter monitoring in turning process"
        ],
        "penulis":"Susanto, Agus;Azka, Muizuddin;Yamada, Keiji;Sekiya, Katsuhiko;Novia, Putri;Tanaka, Ryutaro;Prasetio, Murman Dwi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Machining of railway components is necessary to be controlled because this process requires precise accuracy and high surface finish of the final product. However, chatter vibration can be an obstacle that leads to negative effects. One of the ways for chatter monitoring in machining is by vibration signal analysis. In this paper, transient vibration signals are analyzed using Hilbert-Huang (HHT) transform and compare to STFT. The results show the excellence of HHT for analysis transient signals for chatter vibration identification correctly in turning process. Frequency transition between frequency of rotational spindle and chatter frequency is well captured using HHT, but STFT is trouble for capturing that one. Besides, the EMD (empirical mode decomposition) process of HHT separated out non-chatter from chatter signals. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Machining of railway components is necessary to be controlled because this process requires precise accuracy and high surface finish of the final product. However, chatter vibration can be an obstacle that leads to negative effects. One of the ways for chatter monitoring in machining is by vibration signal analysis. In this paper, transient vibration signals are analyzed using Hilbert-Huang (HHT) transform and compare to STFT. The results show the excellence of HHT for analysis transient signals for chatter vibration identification correctly in turning process. Frequency transition between frequency of rotational spindle and chatter frequency is well captured using HHT, but STFT is trouble for capturing that one. Besides, the EMD (empirical mode decomposition) process of HHT separated out non-chatter from chatter signals. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Performance of staggered grid implementation of 2d shallow water equations using CUDA architecture"
        ],
        "penulis":"Arnoldy, Adrian;Adytia, Didit;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In nature, there are many examples of shallow water flows, such as flooding in coastal cities, river flow, or tsunami propagation and runup. The favorite model that is chosen for simulating such phenomena is the Shallow Water Equations (SWE) or also called the Saint- Venant equation. To simulate various nonlinear phenomena such as wave breaking and wave runup, the model should be implemented numerically by using a numerical scheme that is robust, accurate, and yet efficient in computation. In this paper, we implemented the model by using Finite Volume method in a staggered grid scheme. To broaden the applicability of the model for simulating large domain of computation, the model is implemented in CUDA architecture in Graphical Processing Unit (GPU). The performance of the parallel architecture is tested by comparing the computation time between the CUDA implementation with the traditional CPU implementation. The comparison shows significant speed up in the CUDA implementation. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In nature, there are many examples of shallow water flows, such as flooding in coastal cities, river flow, or tsunami propagation and runup. The favorite model that is chosen for simulating such phenomena is the Shallow Water Equations (SWE) or also called the Saint- Venant equation. To simulate various nonlinear phenomena such as wave breaking and wave runup, the model should be implemented numerically by using a numerical scheme that is robust, accurate, and yet efficient in computation. In this paper, we implemented the model by using Finite Volume method in a staggered grid scheme. To broaden the applicability of the model for simulating large domain of computation, the model is implemented in CUDA architecture in Graphical Processing Unit (GPU). The performance of the parallel architecture is tested by comparing the computation time between the CUDA implementation with the traditional CPU implementation. The comparison shows significant speed up in the CUDA implementation. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Array Antenna for Doppler Spread Compensator on High Speed Railway"
        ],
        "penulis":"Anbela, Dano Seto;Anwar, Khoirul;Yunita, Trasma;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Train movements on the high speed railway causes signal damage due to the Doppler effect. In this situation, The Doppler Spread Compensator (DSC) technique plays an important role in the rapid train technology. This paper proposes an array antenna as DSC. The antenna is designed based on a rectangular patch microstrip array antenna for high speed railway. As a Doppler spread compensator, antennas is designed for the Future Railway for Mobile Communication System technology (FRMCS). The material used on the substrate is FR4 Epoxy and the ground plane and patch using copper. The antenna is designed to have a large dimension suitable for covering along the train. The realization of the antenna was good enough. The simulated and measured results of the antenna, such as magnitude of the reflection coefficient (S11), Gain, and Radiation Patterns are all presented in this paper. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Train movements on the high speed railway causes signal damage due to the Doppler effect. In this situation, The Doppler Spread Compensator (DSC) technique plays an important role in the rapid train technology. This paper proposes an array antenna as DSC. The antenna is designed based on a rectangular patch microstrip array antenna for high speed railway. As a Doppler spread compensator, antennas is designed for the Future Railway for Mobile Communication System technology (FRMCS). The material used on the substrate is FR4 Epoxy and the ground plane and patch using copper. The antenna is designed to have a large dimension suitable for covering along the train. The realization of the antenna was good enough. The simulated and measured results of the antenna, such as magnitude of the reflection coefficient (S11), Gain, and Radiation Patterns are all presented in this paper. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Ideation meaning in the opinion forum of the Jakarta post: A metafunctions analysis"
        ],
        "penulis":"Wijayanto, Pikir Wisnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research aims to identify the meaning of sentences, in detail, from a discourse semantics' perspectives, through metafunctions analysis of ideation systems introduced by James Martin and David Rose (Martin & Rose, 2003). This research makes use of qualitative and descriptive methods with data obtained from the \"Opinion Forum\" of the Jakarta Post published on February 18th, 2019, entitled \"Islam Nusantara: A Soft Power Diplomacy\" written by Arifi Saiman. According to a metafunctions analysis of the phase ideation sequence and 'circumstances' process, the sentences expressed the writer's opinion, expectation, and suggestions with regards to Islam Nusantara concepts. In the sequence of activities and descriptions, each clause mostly expressed what they act, speak, or feel. Some circumstantial processes that have been proven by a 'wh-items' in this article, such as 'doing,' 'saying,' and 'sensing.' These are used to express the writer opinion, suggestion, and 'high' expectation to the Islam Nusantara concepts as an extension of its now well-known soft power diplomacy of organizing interfaith dialogues. \u00a9 2019 Primrose Hall Publishing Group.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research aims to identify the meaning of sentences, in detail, from a discourse semantics' perspectives, through metafunctions analysis of ideation systems introduced by James Martin and David Rose (Martin & Rose, 2003). This research makes use of qualitative and descriptive methods with data obtained from the \"Opinion Forum\" of the Jakarta Post published on February 18th, 2019, entitled \"Islam Nusantara: A Soft Power Diplomacy\" written by Arifi Saiman. According to a metafunctions analysis of the phase ideation sequence and 'circumstances' process, the sentences expressed the writer's opinion, expectation, and suggestions with regards to Islam Nusantara concepts. In the sequence of activities and descriptions, each clause mostly expressed what they act, speak, or feel. Some circumstantial processes that have been proven by a 'wh-items' in this article, such as 'doing,' 'saying,' and 'sensing.' These are used to express the writer opinion, suggestion, and 'high' expectation to the Islam Nusantara concepts as an extension of its now well-known soft power diplomacy of organizing interfaith dialogues. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Decentralization of medical emergency service to minimize response time"
        ],
        "penulis":"Umam, Muhammad Isnaini Hadiyul;Kurnianingtyas, Diva;Santosa, Budi;Siswanto, Nurhadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Medical Emergency Service (MES) is an important element in modern healthcare system. MES becomes important issue because it plays an important role in saving lives and reducing mortality and mordibility. The ability of MES to save lives depends on the time it takes for an ambulance to arrive on the scene after an emergency call received. This research will focus on changing the MES system from initially centralized to decentralized by considering the determination of the allocation and redeployment of ambulance. We propose the Nearest Neighbourhood - Symbiotic Organisms Search algorithm (NN-SOS) to overcome the problems. This study is expected to be able to solve the problems in the limitation of the number of ambulance required and the minimization of response time. From this study, it can be concluded that a decentralized ambulance system is needed. The comparison of the response time generated from the two systems is a centralized system with the best time limit having an average response time of 10-13 minutes while the decentralized system is better which is 3-6 minutes. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Medical Emergency Service (MES) is an important element in modern healthcare system. MES becomes important issue because it plays an important role in saving lives and reducing mortality and mordibility. The ability of MES to save lives depends on the time it takes for an ambulance to arrive on the scene after an emergency call received. This research will focus on changing the MES system from initially centralized to decentralized by considering the determination of the allocation and redeployment of ambulance. We propose the Nearest Neighbourhood - Symbiotic Organisms Search algorithm (NN-SOS) to overcome the problems. This study is expected to be able to solve the problems in the limitation of the number of ambulance required and the minimization of response time. From this study, it can be concluded that a decentralized ambulance system is needed. The comparison of the response time generated from the two systems is a centralized system with the best time limit having an average response time of 10-13 minutes while the decentralized system is better which is 3-6 minutes. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "Hoax News Detection on Twitter using Term Frequency Inverse Document Frequency and Support Vector Machine Method"
        ],
        "penulis":"Fauzi A.;Setiawan E.B.;Baizal Z.K.A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Twitter is one of the social media that is currently popularly used around the world. It's just that twitter has some problems that adversely affect its users. Hoax is one of the negative things that often occur in social media, news in the hoax is still doubted the truth or the fact. In this final project, the authors built a system to detect hoax news on twitter. The purpose of the research is to minimize the hoax news spread on twitter. The use of the Term Frequency Inverse Document Frequency (TF-IDF) weighting system in the system gives a weighted value to a tweet taken from the occurrence of a hoax news sent by someone on Twitter. Data classification uses the Support Vector Machine (SVM) method of the system to predict the possibility of a twitter account user spreading a hoax news based on the user's behavior. Testing data is done based on the contents of content tweets. Datasets are arranged based on attributes used such as the number of retweets, URLs, number of hashtags, provocations, feuds, anxieties, and unbalanced news. Processed data is divided into training data and testing data. The result of data using all features get the highest accuracy is 78,33%. The contribution of this research is that it can detect news that has a tendency towards hoax and can filter which is classified as hoax or not hoax. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Twitter is one of the social media that is currently popularly used around the world. It's just that twitter has some problems that adversely affect its users. Hoax is one of the negative things that often occur in social media, news in the hoax is still doubted the truth or the fact. In this final project, the authors built a system to detect hoax news on twitter. The purpose of the research is to minimize the hoax news spread on twitter. The use of the Term Frequency Inverse Document Frequency (TF-IDF) weighting system in the system gives a weighted value to a tweet taken from the occurrence of a hoax news sent by someone on Twitter. Data classification uses the Support Vector Machine (SVM) method of the system to predict the possibility of a twitter account user spreading a hoax news based on the user's behavior. Testing data is done based on the contents of content tweets. Datasets are arranged based on attributes used such as the number of retweets, URLs, number of hashtags, provocations, feuds, anxieties, and unbalanced news. Processed data is divided into training data and testing data. The result of data using all features get the highest accuracy is 78,33%. The contribution of this research is that it can detect news that has a tendency towards hoax and can filter which is classified as hoax or not hoax. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "What we give, we get back: Investigating the dimensions that influence knowledge sharing on profit enterprise in Indonesia"
        ],
        "penulis":"Saide, Saide;Astuti, Endang Siti;Indrajit, Richardus Eko;Trialih, Rahmat;Diniaty, Amirah;Dewi, Fitriyana;Herzavina, Herzavina;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose: As prior study offered further general context of knowledge management approach while misplaced more personal behavior development in the context of knowledge sharing practices, this study examined whether and why personal factors predict knowledge sharing practices. This study aims to integrate and analyze indicators such as altruism, grant, interaction ability and knowledge sharing participation to develop a comprehensive behavioral model. Design\/methodology\/approach: Structural equation modeling was used to check the research hypotheses framework with 268 samples of eight profit companies in Indonesia, divided into broadcasting, banking and services company. Findings: The results showed that altruism and interaction ability factors are significantly correlated with knowledge sharing participation. The findings may help companies and workers to initiate knowledge sharing implementation and encourage knowledge sharing in the internal company. Research limitations\/implications: The research focused on profit company in a single province in Indonesia. Further research may extend the study with a focus on non-profit organizations (e.g. academic institutions) and different geographical areas. Practical implications: Managerial ideally creates standardization or regulation that to encourage participation of workers for transfer their knowledge. In this aspect, the company needs to organize, such as formal\/informal training and meeting to make their workers more confident to communicate with each other. Originality\/value: Prior studies explored knowledge sharing behavior in a general sense; this paper examined the phenomenon specifically within the context of broadcasting, banking and services company in Indonesia, then analyzed the potential for a company to enhance their knowledge sharing strategy. \u00a9 2019, Emerald Publishing Limited.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: As prior study offered further general context of knowledge management approach while misplaced more personal behavior development in the context of knowledge sharing practices, this study examined whether and why personal factors predict knowledge sharing practices. This study aims to integrate and analyze indicators such as altruism, grant, interaction ability and knowledge sharing participation to develop a comprehensive behavioral model. Design\/methodology\/approach: Structural equation modeling was used to check the research hypotheses framework with 268 samples of eight profit companies in Indonesia, divided into broadcasting, banking and services company. Findings: The results showed that altruism and interaction ability factors are significantly correlated with knowledge sharing participation. The findings may help companies and workers to initiate knowledge sharing implementation and encourage knowledge sharing in the internal company. Research limitations\/implications: The research focused on profit company in a single province in Indonesia. Further research may extend the study with a focus on non-profit organizations (e.g. academic institutions) and different geographical areas. Practical implications: Managerial ideally creates standardization or regulation that to encourage participation of workers for transfer their knowledge. In this aspect, the company needs to organize, such as formal\/informal training and meeting to make their workers more confident to communicate with each other. Originality\/value: Prior studies explored knowledge sharing behavior in a general sense; this paper examined the phenomenon specifically within the context of broadcasting, banking and services company in Indonesia, then analyzed the potential for a company to enhance their knowledge sharing strategy. \u00a9 2019, Emerald Publishing Limited."
        ]
    },
    {
        "judul":[
            "LoRa-based IoT Network Planning for Advanced Metering Infrastructure in Urban, Suburban and Rural Scenario"
        ],
        "penulis":"Bagariang, Yosia;Nashiruddin, Muhammad Imam;Adriansyah, Nachwan Mufti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Internet of Things is predicted to be the future of digital business in Indonesia. The trend of IoT implements on a large scale as more sensors and devices are connected. LoRa is one of the promising applications of the Internet of Things with long-range wireless communication in broad areas. LoRa network deployment in Advanced Metering Infrastructure (AMI) is one of the most significant components in smart metering which measure and collect data from smart meters to be analyzed utilities distribution and consumption. In the IoT, the scenario must achieve two main goals: efficient communication like massive connectivity and defense against environmental conditions. In this paper, we propose the LoRa for Advanced Metering Infrastructure in three utilities (electric, gas, and water meter) to implement in urban, suburban, and rural areas in case of Medan and surroundings by calculating capacity and coverage planning to find out the optimum number of LoRa gateways. Use the method of forecasting IoT connected devices then predict the amount of LoRa gateways need with two scenarios. The first scenario requires the capacity planning by volume demand of the customer's supply of the system. Meanwhile, the second scenario needs coverage planning mostly depends on the link budget and geographical. The simulation results in Forsk Atoll 3.3.2 indicate that the whole determined areas can serve by the number of gateways that have to obtain within acceptable the mean of best signal levels is-76,28 dBm,-75,7 dBm,-81,67 dBm for the urban, suburban and rural scenario, respectively. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentClean water and sanitationGoal 6",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet of Things is predicted to be the future of digital business in Indonesia. The trend of IoT implements on a large scale as more sensors and devices are connected. LoRa is one of the promising applications of the Internet of Things with long-range wireless communication in broad areas. LoRa network deployment in Advanced Metering Infrastructure (AMI) is one of the most significant components in smart metering which measure and collect data from smart meters to be analyzed utilities distribution and consumption. In the IoT, the scenario must achieve two main goals: efficient communication like massive connectivity and defense against environmental conditions. In this paper, we propose the LoRa for Advanced Metering Infrastructure in three utilities (electric, gas, and water meter) to implement in urban, suburban, and rural areas in case of Medan and surroundings by calculating capacity and coverage planning to find out the optimum number of LoRa gateways. Use the method of forecasting IoT connected devices then predict the amount of LoRa gateways need with two scenarios. The first scenario requires the capacity planning by volume demand of the customer's supply of the system. Meanwhile, the second scenario needs coverage planning mostly depends on the link budget and geographical. The simulation results in Forsk Atoll 3.3.2 indicate that the whole determined areas can serve by the number of gateways that have to obtain within acceptable the mean of best signal levels is-76,28 dBm,-75,7 dBm,-81,67 dBm for the urban, suburban and rural scenario, respectively. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A multi-label classification on topics of quranic verses (english translation) using backpropagation neural network with stochastic gradient descent and adam optimizer"
        ],
        "penulis":"Huda, Nanang Saiful;Mubarok, Mohamad Syahrul;Adiwijaya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The Quran is a guideline for all Muslims. In the Quran, many things are talked about. In Quranic studies, the Quran is first classified into several topics according to the discussions of the Quranic verses. In this research, a classification model using a Back Propagation Neural Network was built based on the verses of Al-Quran and its multi-labelled topics. This allows the Back Propagation algorithm architecture to issue labels for each class in the form of 'yes' or 'no' for each output neuron. When using the Back Propagation algorithm, a sentence input that has become a vector is taken. In this way, TF-IDF will be used for feature extraction. Then, the model was evaluated via calculation of Hamming Loss. To ensure an optimal Back Propagation process, a comparison was made between the Stochastic Gradient Descent (SGD) and Adam optimizers. Based on some experiments, the proposed scheme yielded the best performance with a Hamming Loss value of 0.129. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Quran is a guideline for all Muslims. In the Quran, many things are talked about. In Quranic studies, the Quran is first classified into several topics according to the discussions of the Quranic verses. In this research, a classification model using a Back Propagation Neural Network was built based on the verses of Al-Quran and its multi-labelled topics. This allows the Back Propagation algorithm architecture to issue labels for each class in the form of 'yes' or 'no' for each output neuron. When using the Back Propagation algorithm, a sentence input that has become a vector is taken. In this way, TF-IDF will be used for feature extraction. Then, the model was evaluated via calculation of Hamming Loss. To ensure an optimal Back Propagation process, a comparison was made between the Stochastic Gradient Descent (SGD) and Adam optimizers. Based on some experiments, the proposed scheme yielded the best performance with a Hamming Loss value of 0.129. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "High Gain 2-stage Class-E RF Power Amplifier for Wireless Power Transfer"
        ],
        "penulis":"Ridwan, Azwar Mudzakkir;Hamidi, Eki Ahmad Zaki;Syihabuddin, Budi;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "During the last decade, the implementation of wireless power transfer (WPT) technology has been penetrating in many applications. One of essential issues in wireless power transfer is how to acquire high efficiency of power transferred wirelessly. In this paper, a high gain E-class radio frequency (RF) power amplifier is designed in 2-stage using MOSFETs and characterized for wireless power transfer application. The use of class-E RF power amplifier driven by 2 cascaded MOSFETs of IRF510 and IRF620 types is aimed to attain high efficiency of RF power amplifier with high gain amplification. Some attempts to achieve high output power of the RF power amplifier are performed through a circuit EM simulator software. Based on the optimum design result, the proposed RF power amplifier is then realized and experimentally characterized. The result shows that the realized RF power amplifier has gain achievement more than 38 dB suitable for wireless power transfer application. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "During the last decade, the implementation of wireless power transfer (WPT) technology has been penetrating in many applications. One of essential issues in wireless power transfer is how to acquire high efficiency of power transferred wirelessly. In this paper, a high gain E-class radio frequency (RF) power amplifier is designed in 2-stage using MOSFETs and characterized for wireless power transfer application. The use of class-E RF power amplifier driven by 2 cascaded MOSFETs of IRF510 and IRF620 types is aimed to attain high efficiency of RF power amplifier with high gain amplification. Some attempts to achieve high output power of the RF power amplifier are performed through a circuit EM simulator software. Based on the optimum design result, the proposed RF power amplifier is then realized and experimentally characterized. The result shows that the realized RF power amplifier has gain achievement more than 38 dB suitable for wireless power transfer application. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Self-concept and self-care: Implications for adolescents' achievement"
        ],
        "penulis":"Puspitasari S.;Budiastuti E.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to shed light on: (1) self-concept, (2) self-care, (3) achievement, (4) the relationship between self-concept and self-care, (5) the relationship between self-care and achievement, (6) the relationship between self-concept and student achievement, and (7) the effect of self-concept and self-care on achievement. This study employed a quantitative approach. A sample of 95 students was selected as the research subjects using the probability random sampling technique. The instruments of this study were questionnaires and students' report cards. The data were analyzed using the descriptive analysis technique and correlation. The results show that: (1) the students' self-concept is in a high category (mean=137); (2) the students' self-care is in a high category (mean=111); (3) the students' achievement is good (mean=80); (4) there is a positive correlation between self-concept and self-care with a correlation coefficient of 0.578; (5) there is a positive correlation between self-care and student achievement with a correlation coefficient of 0.822; (6) there is a positive correlation between self-concept and students' achievement with a correlation coefficient of 0.536; and (7) there is a significant effect of self-concept and self-care on students' achievement. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to shed light on: (1) self-concept, (2) self-care, (3) achievement, (4) the relationship between self-concept and self-care, (5) the relationship between self-care and achievement, (6) the relationship between self-concept and student achievement, and (7) the effect of self-concept and self-care on achievement. This study employed a quantitative approach. A sample of 95 students was selected as the research subjects using the probability random sampling technique. The instruments of this study were questionnaires and students' report cards. The data were analyzed using the descriptive analysis technique and correlation. The results show that: (1) the students' self-concept is in a high category (mean=137); (2) the students' self-care is in a high category (mean=111); (3) the students' achievement is good (mean=80); (4) there is a positive correlation between self-concept and self-care with a correlation coefficient of 0.578; (5) there is a positive correlation between self-care and student achievement with a correlation coefficient of 0.822; (6) there is a positive correlation between self-concept and students' achievement with a correlation coefficient of 0.536; and (7) there is a significant effect of self-concept and self-care on students' achievement. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Developing an adaptive language model for Bahasa Indonesia"
        ],
        "penulis":"Hidayatullah, Satria Nur;Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A language model is one of the important components in a speech recognition system. It is commonly developed using a statistical method called n-gram. However, a standard n-gram cannot be used for general domains with so many ambiguous semantics of sentences. This paper focuses on developing an adaptive n-gram language model for Bahasa Indonesia. First, a text corpus of ten million distinct sentences is crawled from hundreds of websites of news, magazines, personal blogs, and writing forums. The text corpus is then used to construct an adaptive language model using Latent Dirichlet Allocation (LDA) with Collapsed Gibbs Sampling (CGS) training method. Compare to the standard n-gram, the adaptive language model gives a better performance in the word selection to produce the best sentence. \u00a9 2018 The Science and Information (SAI) Organization Limited.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A language model is one of the important components in a speech recognition system. It is commonly developed using a statistical method called n-gram. However, a standard n-gram cannot be used for general domains with so many ambiguous semantics of sentences. This paper focuses on developing an adaptive n-gram language model for Bahasa Indonesia. First, a text corpus of ten million distinct sentences is crawled from hundreds of websites of news, magazines, personal blogs, and writing forums. The text corpus is then used to construct an adaptive language model using Latent Dirichlet Allocation (LDA) with Collapsed Gibbs Sampling (CGS) training method. Compare to the standard n-gram, the adaptive language model gives a better performance in the word selection to produce the best sentence. \u00a9 2018 The Science and Information (SAI) Organization Limited."
        ]
    },
    {
        "judul":[
            "Comprehensive Framework of E-commerce Adoption in Indonesian SMEs"
        ],
        "penulis":"Hayati I.;Andrawina L.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The use of Internet has been growing rapidly in the last decade. One of the popular uses of Internet is e-commerce which gives changes in the market and forces companies to adapt to survive, including small-medium enterprises (SMEs). As one of developing country, e-commerce adoption among Indonesian SMEs is still low with only 8\\% of SMEs has adopted e-commerce. Despite many researches regarding e-commerce adoption, the topic still needs a comprehensive study on internal and external factors affecting e-commerce adoption. This study aims to fill these gaps by developing a comprehensive framework on e-commerce adoption among Indonesian SMEs. The originality of this study resides in managerial demography and company's knowledge management as additional factors to the model proposed by previous studies. This study concludes four external dimensions and five internal dimensions affecting e-commerce adoption. The external dimensions are institutional environment, economic environment, socio-cultural environment and technology environment. While the internal dimensions consist of managerial demography, company's size, company's capabilities, corporate strategy and company's knowledge management. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of Internet has been growing rapidly in the last decade. One of the popular uses of Internet is e-commerce which gives changes in the market and forces companies to adapt to survive, including small-medium enterprises (SMEs). As one of developing country, e-commerce adoption among Indonesian SMEs is still low with only 8\\% of SMEs has adopted e-commerce. Despite many researches regarding e-commerce adoption, the topic still needs a comprehensive study on internal and external factors affecting e-commerce adoption. This study aims to fill these gaps by developing a comprehensive framework on e-commerce adoption among Indonesian SMEs. The originality of this study resides in managerial demography and company's knowledge management as additional factors to the model proposed by previous studies. This study concludes four external dimensions and five internal dimensions affecting e-commerce adoption. The external dimensions are institutional environment, economic environment, socio-cultural environment and technology environment. While the internal dimensions consist of managerial demography, company's size, company's capabilities, corporate strategy and company's knowledge management. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Accuracy Enhancement of Feature Extraction Scheme in Detection of Chainsaw Sound to Prevent Illegal Logging"
        ],
        "penulis":"Ramadhan, Bayu Rizky;Abdurohman, Maman;Prabowo, Sidik;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes an alternative scheme for feature extraction method based on Mel-Frequency Cepstral Coefficients (MFCC) and Sinusoidal Lifter. MFCC method itself works by using a coefficient called mel coefficient to represent features from audio. However, MFCC has had a problem in that the MFCC was susceptible to disturbance of noise. In this proposed scheme, the mel coefficient produced by the MFCC will later be passed through a lifter to solve the noise problem. The result from the experiment conducted on the case of chainsaw sound detection shows the use of lifter has given a higher capability of learning on artificial neuron network, compared to MFCC without lifter as MFCC without lifter requires more than 20000 iterations to be able to minimize error rate to 0.005. The MFCC with lifter, however, has taken only 16 iterations. The MFCC with lifter is, therefore, shown to have produced higher accuracy than MFCC without lifter by 20%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes an alternative scheme for feature extraction method based on Mel-Frequency Cepstral Coefficients (MFCC) and Sinusoidal Lifter. MFCC method itself works by using a coefficient called mel coefficient to represent features from audio. However, MFCC has had a problem in that the MFCC was susceptible to disturbance of noise. In this proposed scheme, the mel coefficient produced by the MFCC will later be passed through a lifter to solve the noise problem. The result from the experiment conducted on the case of chainsaw sound detection shows the use of lifter has given a higher capability of learning on artificial neuron network, compared to MFCC without lifter as MFCC without lifter requires more than 20000 iterations to be able to minimize error rate to 0.005. The MFCC with lifter, however, has taken only 16 iterations. The MFCC with lifter is, therefore, shown to have produced higher accuracy than MFCC without lifter by 20%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Evaluation of Random Forest model for forest fire prediction based on climatology over Borneo"
        ],
        "penulis":"Latifah, Arnida L.;Shabrina, Ayu;Wahyuni, Intan N.;Sadikin, Rifki;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia has entered an alarming condition related to forest fires. It is becoming a seasonal hazardous phenomenon in tropics. As the largest tropical forest in Indonesia, Borneo is the most susceptible area to fire especially in dry condition. Forest fires are threatened by climate, human activities, and ecosystem processes, but only climate variable can be quantified well in Borneo. This research aims to evaluate random forest model in predicting forest fires based on the climate variables and satellite data of burned area. Prediction of forest fires is expected to reduce the impact of forest fires in the future. Based on analysis of spatial and annual variability, the random forest model with all selected climate variables can represent the forest fires event over Borneo. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia has entered an alarming condition related to forest fires. It is becoming a seasonal hazardous phenomenon in tropics. As the largest tropical forest in Indonesia, Borneo is the most susceptible area to fire especially in dry condition. Forest fires are threatened by climate, human activities, and ecosystem processes, but only climate variable can be quantified well in Borneo. This research aims to evaluate random forest model in predicting forest fires based on the climate variables and satellite data of burned area. Prediction of forest fires is expected to reduce the impact of forest fires in the future. Based on analysis of spatial and annual variability, the random forest model with all selected climate variables can represent the forest fires event over Borneo. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Flatbuffers implementation on MQTT publish\/subscribe communication as data delivery format"
        ],
        "penulis":"Pradana, Muhammad Adna;Rakhmatsyah, Andrian;Wardana, Aulia Arif;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Communication between devices can be done in various ways, one of them is the Publish\/Subscribe model that uses the MQTT protocol From the shortcomings that exist in JSON, such as long processing time, Google recently introduced a new data format called Flatbuffers. Flatbuffers has a better data format serialization process than other data formats. This paper will discuss the implementation and testing of the Flatbuffers data format performance compared to other data formats through the MQTT Publish\/Subscribe communication model. Testing is done by measuring the value of payload, latency, and throughput obtained from each data format. The test results show that the Flatbuffers data format is very well used as a data extraction format based on data processing latency of 0.5002 ms and throughput 518.4649 bytes\/ms with payload 0.996108949 character\/byte. \u00a9 2019, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Communication between devices can be done in various ways, one of them is the Publish\/Subscribe model that uses the MQTT protocol From the shortcomings that exist in JSON, such as long processing time, Google recently introduced a new data format called Flatbuffers. Flatbuffers has a better data format serialization process than other data formats. This paper will discuss the implementation and testing of the Flatbuffers data format performance compared to other data formats through the MQTT Publish\/Subscribe communication model. Testing is done by measuring the value of payload, latency, and throughput obtained from each data format. The test results show that the Flatbuffers data format is very well used as a data extraction format based on data processing latency of 0.5002 ms and throughput 518.4649 bytes\/ms with payload 0.996108949 character\/byte. \u00a9 2019, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Analysis and implementation of steganography on JPEG using LSB and spread spectrum method"
        ],
        "penulis":"Bagaskara, Jordy A.;Purboyo, Tito Waluyo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Information is a message in the form of a utterance or phrase that can consist of symbols, or meanings that can be interpreted from a message or a collection of messages. Steganography is a technique that can be used to hide information on a media. In the digital era, the media used can be audio, image, or video. In its use, the concealment of messages is done by making small changes to a digital medium so as not to attract the attention of other people or attackers. In general, the concealment of a data or message on the image media is a technique that is often used in the implementation of steganography. In the use of image media, steganography can be implemented with existing methods; in this journal will be implemented Least Significant Bit (LSB) and Spread Spectrum method, which will further determine the analysis of image quality and comparison of both methods. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information is a message in the form of a utterance or phrase that can consist of symbols, or meanings that can be interpreted from a message or a collection of messages. Steganography is a technique that can be used to hide information on a media. In the digital era, the media used can be audio, image, or video. In its use, the concealment of messages is done by making small changes to a digital medium so as not to attract the attention of other people or attackers. In general, the concealment of a data or message on the image media is a technique that is often used in the implementation of steganography. In the use of image media, steganography can be implemented with existing methods; in this journal will be implemented Least Significant Bit (LSB) and Spread Spectrum method, which will further determine the analysis of image quality and comparison of both methods. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Knowledge Sharing Model for Competitive Ecosystem on Gig Economy"
        ],
        "penulis":"Gandhi, Arfive;Sensuse, Dana Indra;Sucahyo, Yudho Giri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Digital business with gig economy scheme had no culture to share knowledge since strictly competition among gig workers. It affects gig workers' limited ability and knowledge to accomplish projects and reduce their performance. This study proposed a knowledgesharing model to articulate insightful knowledge from scattered tacit and explicit knowledge by keep personal data and copyright. It performed Soft System Methodology to facilitate conceptualization process from founded problem until strategies formulation. It generated artifacts to clarify problems and elaborates their solutions. By decomposing the problems into fishbone analysis, this study has identified who are the involved stakeholders and how the knowledge management should run. It became root cause as baseline to conceptualize a knowledge sharing model among gig workers. As the result, this study delivered a knowledge sharing model which relied on point system to engage gig workers' participation to externalize their knowledge in knowledge repository and expert should validate them before knowledge storing. To achieve more qualified model, this study relied on validation by representative gig workers and platform applications. This model contributes to mediate knowledge circulation among gig workers by encourage their extrinsic motivation. Hence, it can deliver innovative solution to enhance digital business on modern society through gig worker empowerment. \u00a9 2019 Copyright held by the owner\/author(s).",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Digital business with gig economy scheme had no culture to share knowledge since strictly competition among gig workers. It affects gig workers' limited ability and knowledge to accomplish projects and reduce their performance. This study proposed a knowledgesharing model to articulate insightful knowledge from scattered tacit and explicit knowledge by keep personal data and copyright. It performed Soft System Methodology to facilitate conceptualization process from founded problem until strategies formulation. It generated artifacts to clarify problems and elaborates their solutions. By decomposing the problems into fishbone analysis, this study has identified who are the involved stakeholders and how the knowledge management should run. It became root cause as baseline to conceptualize a knowledge sharing model among gig workers. As the result, this study delivered a knowledge sharing model which relied on point system to engage gig workers' participation to externalize their knowledge in knowledge repository and expert should validate them before knowledge storing. To achieve more qualified model, this study relied on validation by representative gig workers and platform applications. This model contributes to mediate knowledge circulation among gig workers by encourage their extrinsic motivation. Hence, it can deliver innovative solution to enhance digital business on modern society through gig worker empowerment. \u00a9 2019 Copyright held by the owner\/author(s)."
        ]
    },
    {
        "judul":[
            "Speed and steering control system for self-driving car prototype"
        ],
        "penulis":"Rafsanjani;Wibawa I.P.D.;Ekaputri C.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A self-driving car is a vehicle that can run autonomously using a control. There are two systems that are controlled in this research. The first-speed control functions to regulate the speed and movement of the self-driving car prototype by adjusting the PWM value on the DC motor and second, the steering control uses the Ackerman steering system with a servo motor as an actuator. Both are arranged using fuzzy logic control methods that adapt from the habits in driving a car. the goal self-driving car prototype can walk to follow the track, maintain the robot car in the middle of the lane, can adjust the speed when turning and can stop when there are obstacles or traffic lights. The results of the control design testing in this study are, the average error value in the simulation is 0.771008 for the servo angle and 0.392072 for the speed. The error value in the programming algorithm is 0.149712 for servo angles and 0.198168 for PWM DC motors. Robot cars in accordance with the logic of the fuzzy rules made. Self-driving car prototypes can run turns and follow trajectories with a success rate of 93.33%. The distance between the robot car and the track is 1.83 cm inside the track and 0.03 cm outside the track. The self-driving car prototype can adjust its speed and can stop when there are obstacles with an average distance of 29.89 cm. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A self-driving car is a vehicle that can run autonomously using a control. There are two systems that are controlled in this research. The first-speed control functions to regulate the speed and movement of the self-driving car prototype by adjusting the PWM value on the DC motor and second, the steering control uses the Ackerman steering system with a servo motor as an actuator. Both are arranged using fuzzy logic control methods that adapt from the habits in driving a car. the goal self-driving car prototype can walk to follow the track, maintain the robot car in the middle of the lane, can adjust the speed when turning and can stop when there are obstacles or traffic lights. The results of the control design testing in this study are, the average error value in the simulation is 0.771008 for the servo angle and 0.392072 for the speed. The error value in the programming algorithm is 0.149712 for servo angles and 0.198168 for PWM DC motors. Robot cars in accordance with the logic of the fuzzy rules made. Self-driving car prototypes can run turns and follow trajectories with a success rate of 93.33%. The distance between the robot car and the track is 1.83 cm inside the track and 0.03 cm outside the track. The self-driving car prototype can adjust its speed and can stop when there are obstacles with an average distance of 29.89 cm. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Impact of green IS, service innovation and customer experience in influencing customer satisfaction and environmental performance"
        ],
        "penulis":"Mihardjo, Leonardus W. W.;Sasmoko;Alamsjah, Firdaus;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The current study is focused to empirically identify the relationship between digitalization, customer experience, satisfaction, and performance in the hotel industry of Indonesia. In doing so, the authors seek to examine the technological antecedents of customer experience (CUE) by examining the role of green information systems (GIS) and service innovation (SEI). Moreover, the study also aims to investigate the association of SEI and GIS with customer satisfaction (CUS) and hotels environmental performance (ENP). The novelty of the present study lies in identifying and testing the joint effects of the studied variables in improving the understanding of CUS and ENP in an existing complex environment. The results of PLS-SEM confirm that customer experience and ENP have a positive and significantly influenced by the GIS. Moreover, the results further suggested that customer experience and CUS have significantly and positively impacted by SEI. Finally, the results of PLS-SEM confirm that ENP and CUS have significantly and positively impacted by customer experience in multinational firms in Indonesia. \u00a9 2019, Econjournals. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The current study is focused to empirically identify the relationship between digitalization, customer experience, satisfaction, and performance in the hotel industry of Indonesia. In doing so, the authors seek to examine the technological antecedents of customer experience (CUE) by examining the role of green information systems (GIS) and service innovation (SEI). Moreover, the study also aims to investigate the association of SEI and GIS with customer satisfaction (CUS) and hotels environmental performance (ENP). The novelty of the present study lies in identifying and testing the joint effects of the studied variables in improving the understanding of CUS and ENP in an existing complex environment. The results of PLS-SEM confirm that customer experience and ENP have a positive and significantly influenced by the GIS. Moreover, the results further suggested that customer experience and CUS have significantly and positively impacted by SEI. Finally, the results of PLS-SEM confirm that ENP and CUS have significantly and positively impacted by customer experience in multinational firms in Indonesia. \u00a9 2019, Econjournals. All rights reserved."
        ]
    },
    {
        "judul":[
            "The evaluation of finance module implementation of enterprise resource planning (ERP) for employee performance"
        ],
        "penulis":"Hafifah, Dayane Kamila;Witarsyah, Deden;Saputra, Muhardi;Azizah, Anik Hanifatul;Eka Saputri, Marhaeni;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Information technology can improve efficiency, effectiveness, and productivity that have an impact on individual performance. However, many companies don't have an integrated information system to support the activity. The process is only supported by individual activities on each site. This study aims to determine how the impact of the application and use of the System Applications and Product (SAP) on employee performance using Task Technology Fit (TTF) Model. Data collection methods used in this study are quantitative and qualitative methods. Data obtained based on the results of questionnaires involving 100 respondents and make some interviews with employee representatives in five divisions. Data is processed using Smart PLS and SPSS. The results of this study show a positive influence on the performance of employees who use the SAP system. The model developed by Goodhue and Thompson explains that the use and attitudes of users towards technology to support individual performance, the strengths of this model are emphasizing the importance of conformity between task and technology in its effect on performance. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information technology can improve efficiency, effectiveness, and productivity that have an impact on individual performance. However, many companies don't have an integrated information system to support the activity. The process is only supported by individual activities on each site. This study aims to determine how the impact of the application and use of the System Applications and Product (SAP) on employee performance using Task Technology Fit (TTF) Model. Data collection methods used in this study are quantitative and qualitative methods. Data obtained based on the results of questionnaires involving 100 respondents and make some interviews with employee representatives in five divisions. Data is processed using Smart PLS and SPSS. The results of this study show a positive influence on the performance of employees who use the SAP system. The model developed by Goodhue and Thompson explains that the use and attitudes of users towards technology to support individual performance, the strengths of this model are emphasizing the importance of conformity between task and technology in its effect on performance. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis on E-commerce Purchase Intention and Decision in Java and Sumatra"
        ],
        "penulis":"Alfanur, Farah;Kadono, Yasuo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The rapid development of internet in Indonesia as a developing country has increased consumer's intention to use internet for shopping online using e-commerce websites. This study aims at better understanding the factors affecting e-commerce intention and decision of consumers in Java and Sumatera island as the most dominant e-commerce consumers in this country. This paper modified constructs in UTAUT2 model based on literature studies and interview results with e-commerce experts, companies and consumers which are suitable with Indonesian actual condition. A model of consumers purchase intention and decision in e-commerce was developed which incorporates factors such as convenience, perceived website quality, social influence, facilitating condition, hedonic motivation, economic reason\/price, security, variety, and goods delivery. Surveys data from 340 ecommerce consumers in Java and Sumatera island used in this study and analysed using covariance based structural equational modelling (CB-SEM). The result from the survey shows that hedonic motivation, convenience, and economic reason are significant influence purchase intention while purchase intention and facilitating condition are significant influence the purchase decision for consumer in Java island. On the other hand, only social influence and facilitating condition which are significant influence purchase intention for consumer in Sumatera island. Overall, the results help to increase our understanding of purchase intention and decision using e-commerce websites based on consumers characteristic in Java and Sumatera as part of Indonesia. It also can be very useful to determine strategies to lead internet users to become online purchaser. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The rapid development of internet in Indonesia as a developing country has increased consumer's intention to use internet for shopping online using e-commerce websites. This study aims at better understanding the factors affecting e-commerce intention and decision of consumers in Java and Sumatera island as the most dominant e-commerce consumers in this country. This paper modified constructs in UTAUT2 model based on literature studies and interview results with e-commerce experts, companies and consumers which are suitable with Indonesian actual condition. A model of consumers purchase intention and decision in e-commerce was developed which incorporates factors such as convenience, perceived website quality, social influence, facilitating condition, hedonic motivation, economic reason\/price, security, variety, and goods delivery. Surveys data from 340 ecommerce consumers in Java and Sumatera island used in this study and analysed using covariance based structural equational modelling (CB-SEM). The result from the survey shows that hedonic motivation, convenience, and economic reason are significant influence purchase intention while purchase intention and facilitating condition are significant influence the purchase decision for consumer in Java island. On the other hand, only social influence and facilitating condition which are significant influence purchase intention for consumer in Sumatera island. Overall, the results help to increase our understanding of purchase intention and decision using e-commerce websites based on consumers characteristic in Java and Sumatera as part of Indonesia. It also can be very useful to determine strategies to lead internet users to become online purchaser. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Item delivery simulation using genetic algorithm"
        ],
        "penulis":"Switrayana, I Nyoman;Osmond, Andrew Brian;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In sending items, time and costs can be minimized by selecting the shortest path. The problem of choosing the shortest path is often known as Travelling Salesman Problem (TSP). TSP in this study was not only concerned with distance but also the priority of places to be visited. Priority parameters in this research are a sign that each place has a value to be visited first than another place. This priority can also be assumed as a type of delivery service that can be chosen by the customer. Priority is divided into three groups, but it can also be more than that according to the needs of a shipping service provider. Delivery of multiple destinations in one area can be delivered with a single trip based on their priority. Search optimization of the shortest path is modeled with genetic algorithms. Hamilton path is the output of the simulation. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In sending items, time and costs can be minimized by selecting the shortest path. The problem of choosing the shortest path is often known as Travelling Salesman Problem (TSP). TSP in this study was not only concerned with distance but also the priority of places to be visited. Priority parameters in this research are a sign that each place has a value to be visited first than another place. This priority can also be assumed as a type of delivery service that can be chosen by the customer. Priority is divided into three groups, but it can also be more than that according to the needs of a shipping service provider. Delivery of multiple destinations in one area can be delivered with a single trip based on their priority. Search optimization of the shortest path is modeled with genetic algorithms. Hamilton path is the output of the simulation. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparison of Classical Interpolation Methods and Compressive Sensing for Missing Data Reconstruction"
        ],
        "penulis":"Usman, Koredianto;Ramdhani, Mohammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The emerging of a new compression technique called compressive sensing (CS) has opened various research possibility in many fields. Practically, CS consists of two main steps, which are compression step and reconstruction step. In many cases, the compression step occurs naturally, for example when several data is missing from the complete set of data. Reconstructing for complete data from incomplete data is the original aims of CS reconstruction process. It is therefore also a logical implication of CS as data interpolation method. Given this situation, a research of CS capability for data interpolation is not yet available. In this paper we investigate the capability of CS for data interpolation. Two popular CS reconstruction tools are used: orthogonal matching pursuit (OMP) and convex programming (CVX). We compared these CS reconstruction performance to the standard interpolation methods which are the linear interpolation and spline interpolation. Simulation results show that classical interpolation methods have better performance in term of general accuracy, while CS reconstruction method has advantage on accuracy in reconstructing data that has sharp changes. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The emerging of a new compression technique called compressive sensing (CS) has opened various research possibility in many fields. Practically, CS consists of two main steps, which are compression step and reconstruction step. In many cases, the compression step occurs naturally, for example when several data is missing from the complete set of data. Reconstructing for complete data from incomplete data is the original aims of CS reconstruction process. It is therefore also a logical implication of CS as data interpolation method. Given this situation, a research of CS capability for data interpolation is not yet available. In this paper we investigate the capability of CS for data interpolation. Two popular CS reconstruction tools are used: orthogonal matching pursuit (OMP) and convex programming (CVX). We compared these CS reconstruction performance to the standard interpolation methods which are the linear interpolation and spline interpolation. Simulation results show that classical interpolation methods have better performance in term of general accuracy, while CS reconstruction method has advantage on accuracy in reconstructing data that has sharp changes. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "ELAMOS: Extended Tsunami Early Alert System for Indoor Public Buildings"
        ],
        "penulis":"Damayanti, Sito Dewi;Krisnadi, Iwan;Nashiruddin, Muhammad Imam;Enriko, I. Ketut Agung;Ramli, Kalamullah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tsunami is a catastrophic disaster which causes a huge number of victims and destruction of buildings in the affected area as the impact of massive high-speed sea wave sweeping the land. Indonesia is a country which is vulnerable to tsunami attack since it consists of thousands of islands surrounded by the seas and located in the area where active tectonic plates encounter. In the last 25 years, at least six tsunamis attacked Indonesia regions, where the last fatal one happened in Sulawesi island, September 2018. Indonesia government has been aware and prepared the tsunami alert system which sensors are placed on the sea to trigger an alarm if a tsunami happens. The alarm will be pronounced by loudspeakers at some open public areas so the residents can hear and be prepared with the disaster. However, the weakness of the existing system is it cannot be heard by people located far away from those loudspeakers, especially if they are in the buildings. This paper aims to create a system that can extend and deliver tsunami alarm to public buildings using the Internet connection. The system is successfully implemented and installed in the Disaster Management Bureau and some hotels in Bali, Indonesia. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tsunami is a catastrophic disaster which causes a huge number of victims and destruction of buildings in the affected area as the impact of massive high-speed sea wave sweeping the land. Indonesia is a country which is vulnerable to tsunami attack since it consists of thousands of islands surrounded by the seas and located in the area where active tectonic plates encounter. In the last 25 years, at least six tsunamis attacked Indonesia regions, where the last fatal one happened in Sulawesi island, September 2018. Indonesia government has been aware and prepared the tsunami alert system which sensors are placed on the sea to trigger an alarm if a tsunami happens. The alarm will be pronounced by loudspeakers at some open public areas so the residents can hear and be prepared with the disaster. However, the weakness of the existing system is it cannot be heard by people located far away from those loudspeakers, especially if they are in the buildings. This paper aims to create a system that can extend and deliver tsunami alarm to public buildings using the Internet connection. The system is successfully implemented and installed in the Disaster Management Bureau and some hotels in Bali, Indonesia. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Comparison of feature selection techniques in classifying stroke documents"
        ],
        "penulis":"Rafei, Nur Syaza Izzati Mohd;Hassan, Rohayanti;Saedudin, R. D. Rohmat;Raffei, Anis Farihan Mat;Zakaria, Zalmiyah;Kasim, Shahreen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The amount of digital biomedical literature grows that make most of the researchers facing the difficulties to manage and retrieve the required information from the Internet because this task is very challenging. The application of text classification on biomedical literature is one of the solutions in order to solve problem that have been faced by researchers but managing the high dimensionality of data being a common issue on text classification. Therefore, the aim of this research is to compare the techniques that could be used to select the relevant features for classifying biomedical text abstracts. This research focus on Pearson\u201fs Correlation and Information Gain as feature selection techniques for reducing the high dimensionality of data. Towards this effort, we conduct and evaluate several experiments using 100 abstract of stroke documents that retrieved from PubMed database as datasets. This dataset underwent the text pre-processing that is crucial before proceed to feature selection phase. Features selection phase is involving Information Gain and Pearson Correlation technique. Support Vector Machine classifier is used in order to evaluate and compare the effectiveness of two feature selection techniques. For this dataset, Information Gain has outperformed Pearson\u201fs Correlation by 3.3%. This research tends to extract the meaningful features from a subset of stroke documents that can be used for various application especially in diagnose the stroke disease. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The amount of digital biomedical literature grows that make most of the researchers facing the difficulties to manage and retrieve the required information from the Internet because this task is very challenging. The application of text classification on biomedical literature is one of the solutions in order to solve problem that have been faced by researchers but managing the high dimensionality of data being a common issue on text classification. Therefore, the aim of this research is to compare the techniques that could be used to select the relevant features for classifying biomedical text abstracts. This research focus on Pearson\u201fs Correlation and Information Gain as feature selection techniques for reducing the high dimensionality of data. Towards this effort, we conduct and evaluate several experiments using 100 abstract of stroke documents that retrieved from PubMed database as datasets. This dataset underwent the text pre-processing that is crucial before proceed to feature selection phase. Features selection phase is involving Information Gain and Pearson Correlation technique. Support Vector Machine classifier is used in order to evaluate and compare the effectiveness of two feature selection techniques. For this dataset, Information Gain has outperformed Pearson\u201fs Correlation by 3.3%. This research tends to extract the meaningful features from a subset of stroke documents that can be used for various application especially in diagnose the stroke disease. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Impact of device orientation for visible light communication in closed room"
        ],
        "penulis":"Wijayanto, Amirullah;Sujatmoko, Kris;Pamukti, Brian;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper evaluates the impact of device orientation in Visible Light Communication (VLC) with the Bit Error Rate (BER) as the main parameter of measurement. Most studies on optical wireless communications have neglected the effect of random orientation in their performance analysis. In this paper, we analyze the device orientation and assess its importance on system performance. The device orientation are we use equal to 0\u00b0, 15\u00b0, and 35\u00b0. To support the simulation, we use the OOKNRZ modulation techniques with the threshold Bit Error Rate (BER) around 10-5. Each of the device orientation has the value of a wide range of communication coverage. The smaller of device orientation, the coverage will be wider. With using the biggest device orientation, the communication coverage is decreased of 11,04% while the smallest device orientation is 98.08% coverage area. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper evaluates the impact of device orientation in Visible Light Communication (VLC) with the Bit Error Rate (BER) as the main parameter of measurement. Most studies on optical wireless communications have neglected the effect of random orientation in their performance analysis. In this paper, we analyze the device orientation and assess its importance on system performance. The device orientation are we use equal to 0\u00b0, 15\u00b0, and 35\u00b0. To support the simulation, we use the OOKNRZ modulation techniques with the threshold Bit Error Rate (BER) around 10-5. Each of the device orientation has the value of a wide range of communication coverage. The smaller of device orientation, the coverage will be wider. With using the biggest device orientation, the communication coverage is decreased of 11,04% while the smallest device orientation is 98.08% coverage area. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of steady river flow through a sluice gate with a case study of Ciliwung River"
        ],
        "penulis":"Alamsyah M.N.A.;Gunawan P.H.;Pudjaprasetya S.R.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "During wet seasons, tropical rain may cause high discharge on rivers. To prevent flooding in the watershed area, sluice gates can be installed to control the water surface level. However, operating a sluice gate is not a trivial task; we must be aware of the backwater effect. Backwater is an increase of the upstream water level resulting from an obstruction of the flow, here is caused by the installation of a sluice gate. In addition, characteristic of the upstream and downstream flow which depend on flow types (subcritical or supercritical) must also be examined. In this paper, we analyse the behaviour of steady river flow through a sluice gate. On a river flow, the presence of a sluice gate (with a fixed opening), will change the total energy of the flow. Then, using the specific energy curve we can determine water surface level behind the gate. Further, by implementing the standard step method, a steady water surface on the upstream part of the gate can be calculated. This surface forms a backwater flow that extends far enough behind the gate. Characteristic of this backwater flow depends crucially on the flow discharge and the opening of the sluice gate. For the case study, we took the Ciliwung River with the Manggarai sluice gate, located nearly in the middle of the river. With the aim of preventing flooding in the watershed area, we calculated several scenarios of sluice gate opening under various river discharge. Our results may help sluice gate operator in controlling the Manggarai sluice gate of the Ciliwung River. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "During wet seasons, tropical rain may cause high discharge on rivers. To prevent flooding in the watershed area, sluice gates can be installed to control the water surface level. However, operating a sluice gate is not a trivial task; we must be aware of the backwater effect. Backwater is an increase of the upstream water level resulting from an obstruction of the flow, here is caused by the installation of a sluice gate. In addition, characteristic of the upstream and downstream flow which depend on flow types (subcritical or supercritical) must also be examined. In this paper, we analyse the behaviour of steady river flow through a sluice gate. On a river flow, the presence of a sluice gate (with a fixed opening), will change the total energy of the flow. Then, using the specific energy curve we can determine water surface level behind the gate. Further, by implementing the standard step method, a steady water surface on the upstream part of the gate can be calculated. This surface forms a backwater flow that extends far enough behind the gate. Characteristic of this backwater flow depends crucially on the flow discharge and the opening of the sluice gate. For the case study, we took the Ciliwung River with the Manggarai sluice gate, located nearly in the middle of the river. With the aim of preventing flooding in the watershed area, we calculated several scenarios of sluice gate opening under various river discharge. Our results may help sluice gate operator in controlling the Manggarai sluice gate of the Ciliwung River. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Simulation of design and analysis massive MIMO array microstrip rectangular patch dualband 3.5 GHz and 26 GHz for 5G communications"
        ],
        "penulis":"Ramadhan, Luthfi Muhammad;Astuti, Rina Pudji;Nugroho, Bambang Setia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In accordance with the scenario of ITU-R,IMT-2020 or fifth generation (5G) will have 3 scenarios, one of which is Enhanced Mobile Broadband (eMBB). Multi antenna by applying massive MIMO is used on eMBB. Frequency candidates used in the fifth generation (5G) are sub-6 GHz and sub-28 GHz frequencies. This paper focuses on simulating massive MIMO antenna designs that work at 3.5 GHz and 26 GHz frequencies. The antenna is arranged by rectangular patch in the form of an array with 12 patches for the 3.5 GHz frequency and 96 patches for the 26 GHz frequency, so the number of patches on the antenna is 108 patches. The designed antenna will be used as an indoor transmitter antenna. The antenna uses a proximity coupled feed with connectors and dielectric constants 2.2. The designed antenna gets s-parameter result of less than-10.8199 dB, a gain greater than 7.3 dB, and a mutual coupling of less than-32,6201 dB. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In accordance with the scenario of ITU-R,IMT-2020 or fifth generation (5G) will have 3 scenarios, one of which is Enhanced Mobile Broadband (eMBB). Multi antenna by applying massive MIMO is used on eMBB. Frequency candidates used in the fifth generation (5G) are sub-6 GHz and sub-28 GHz frequencies. This paper focuses on simulating massive MIMO antenna designs that work at 3.5 GHz and 26 GHz frequencies. The antenna is arranged by rectangular patch in the form of an array with 12 patches for the 3.5 GHz frequency and 96 patches for the 26 GHz frequency, so the number of patches on the antenna is 108 patches. The designed antenna will be used as an indoor transmitter antenna. The antenna uses a proximity coupled feed with connectors and dielectric constants 2.2. The designed antenna gets s-parameter result of less than-10.8199 dB, a gain greater than 7.3 dB, and a mutual coupling of less than-32,6201 dB. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Practical Decoding Scheme for Doubly Irregular Sparse Code Multiple Access"
        ],
        "penulis":"Hidayat, Iswahyudi;Meylani, Linda;Kurniawan, Adit;Arifianto, M. Sigit;Anwar, Khoirul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Doubly irregular sparse code multiple access (DI-SCMA) is a type of sparse code multiple access (SCMA) with irregular degree distributions both in resource node (RN) and user node (UN) to increase the overloading factor. This paper proposes a practical decoding scheme for DI-SCMA having low computational complexity based on using peeling decoding algorithm. We also use mother constellation capable of detecting 4 users simultaneously based on binary shift keying (BPSK)-like mapping leading to a total constellation similar to the 8 phase shift keying (8-PSK). We evaluate the decoding behaviour of the proposed DI-SCMA using extrinsic information transfer (EXIT) chart and computer simulations. Our results confirm the validity of achievable overloading factor using the practical decoding technique with better bit error rate (BER) performances compared to performances of 8-PSK modulations. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Doubly irregular sparse code multiple access (DI-SCMA) is a type of sparse code multiple access (SCMA) with irregular degree distributions both in resource node (RN) and user node (UN) to increase the overloading factor. This paper proposes a practical decoding scheme for DI-SCMA having low computational complexity based on using peeling decoding algorithm. We also use mother constellation capable of detecting 4 users simultaneously based on binary shift keying (BPSK)-like mapping leading to a total constellation similar to the 8 phase shift keying (8-PSK). We evaluate the decoding behaviour of the proposed DI-SCMA using extrinsic information transfer (EXIT) chart and computer simulations. Our results confirm the validity of achievable overloading factor using the practical decoding technique with better bit error rate (BER) performances compared to performances of 8-PSK modulations. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis and implementation of steganography on JPEG using LSB and spread spectrum method"
        ],
        "penulis":"Bagaskara, Jordy A.;Purboyo, Tito Waluyo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Information is a message in the form of a utterance or phrase that can consist of symbols, or meanings that can be interpreted from a message or a collection of messages. Steganography is a technique that can be used to hide information on a media. In the digital era, the media used can be audio, image, or video. In its use, the concealment of messages is done by making small changes to a digital medium so as not to attract the attention of other people or attackers. In general, the concealment of a data or message on the image media is a technique that is often used in the implementation of steganography. In the use of image media, steganography can be implemented with existing methods; in this journal will be implemented Least Significant Bit (LSB) and Spread Spectrum method, which will further determine the analysis of image quality and comparison of both methods. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information is a message in the form of a utterance or phrase that can consist of symbols, or meanings that can be interpreted from a message or a collection of messages. Steganography is a technique that can be used to hide information on a media. In the digital era, the media used can be audio, image, or video. In its use, the concealment of messages is done by making small changes to a digital medium so as not to attract the attention of other people or attackers. In general, the concealment of a data or message on the image media is a technique that is often used in the implementation of steganography. In the use of image media, steganography can be implemented with existing methods; in this journal will be implemented Least Significant Bit (LSB) and Spread Spectrum method, which will further determine the analysis of image quality and comparison of both methods. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Energy extraction method for EEG channel selection"
        ],
        "penulis":"Fauzi, Hilman;Azzam, M. Abdullah;Shapiai, Mohd. Ibrahim;Kyoso, Masaki;Khairuddin, Uswah;Komura, Tadayasu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Channel selection is an improvement technique to optimize EEG-based BCI performance. In previous studies, many channel selection methods-mostly based on spatial information of signals-have been introduced. One of these channel selection techniques is the energy calculation method. In this paper, we introduce an energy optimization calculation method, called the energy extraction method. Energy extraction is an extension of the energy calculation method, and is divided into two steps. The first step is energy calculation and the second is energy selection. In the energy calculation step, l2-norm is used to calculate channel energy, while in the energy selection method we propose three techniques: \"high value\" (HV), \"close to mean\" (CM), and \"automatic\". All proposed framework schemes for energy extraction are applied in two types of datasets. Two classes of datasets i.e. motor movement (hand and foot movement) and motor imagery (imagination of left-and right-hand movement) were used. The system used a Common Spatial Pattern (CSP) method to extract EEG signal features and k-NN as a classification method to classify the signal features with k=3. Based on the test results, all schemes for the proposed energy extraction method yielded improved BCI performance of up to 58%. In summary, the energy extraction approach using the CM energy selection method was found to be the best channel selection technique. \u00a9 2020 by the authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Channel selection is an improvement technique to optimize EEG-based BCI performance. In previous studies, many channel selection methods-mostly based on spatial information of signals-have been introduced. One of these channel selection techniques is the energy calculation method. In this paper, we introduce an energy optimization calculation method, called the energy extraction method. Energy extraction is an extension of the energy calculation method, and is divided into two steps. The first step is energy calculation and the second is energy selection. In the energy calculation step, l2-norm is used to calculate channel energy, while in the energy selection method we propose three techniques: \"high value\" (HV), \"close to mean\" (CM), and \"automatic\". All proposed framework schemes for energy extraction are applied in two types of datasets. Two classes of datasets i.e. motor movement (hand and foot movement) and motor imagery (imagination of left-and right-hand movement) were used. The system used a Common Spatial Pattern (CSP) method to extract EEG signal features and k-NN as a classification method to classify the signal features with k=3. Based on the test results, all schemes for the proposed energy extraction method yielded improved BCI performance of up to 58%. In summary, the energy extraction approach using the CM energy selection method was found to be the best channel selection technique. \u00a9 2020 by the authors."
        ]
    },
    {
        "judul":[
            "Smart tracking and fall detection for golden age's citizen"
        ],
        "penulis":"Fauziah, Ratna Juwita;Mutiara, Giva Andriana;Periyadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Senior Citizen is an elderly human in a golden age who has many limitations. The number of older people is increasing in almost every country, including in Indonesia. One of the diseases that were suffered is senile or known as Dementia. Therefore, to protect the elderly, the special care is needed in order to be able to monitor the located and to see the condition of the elderly when they are travelling outside the home. Based on that condition, a prototype of the detector is proposed in this paper namely Smart tracking for the Golden Age's Citizen. This system consists of a GPS module, a vibration sensor, a GSM Module, and a voice recorder module. GPS module will detect the location, and the vibration sensor will detect the vibration if the elderly falls. The GSM module will send the information in the form of SMS to the family. The voice recorder module is used to record and play the recorded sound. Based on the results of the prototype test, the prototype is successfully detecting the location if the elderly is outside the range. The testing was concluding that the older people position can be tracked approximately around 2-5 meters from the determination in google map application and send an SMS in 3-5 seconds, if the user falls or lost. \u00a9 2019 The Authors.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Senior Citizen is an elderly human in a golden age who has many limitations. The number of older people is increasing in almost every country, including in Indonesia. One of the diseases that were suffered is senile or known as Dementia. Therefore, to protect the elderly, the special care is needed in order to be able to monitor the located and to see the condition of the elderly when they are travelling outside the home. Based on that condition, a prototype of the detector is proposed in this paper namely Smart tracking for the Golden Age's Citizen. This system consists of a GPS module, a vibration sensor, a GSM Module, and a voice recorder module. GPS module will detect the location, and the vibration sensor will detect the vibration if the elderly falls. The GSM module will send the information in the form of SMS to the family. The voice recorder module is used to record and play the recorded sound. Based on the results of the prototype test, the prototype is successfully detecting the location if the elderly is outside the range. The testing was concluding that the older people position can be tracked approximately around 2-5 meters from the determination in google map application and send an SMS in 3-5 seconds, if the user falls or lost. \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Knowledge Sharing Model for Competitive Ecosystem on Gig Economy"
        ],
        "penulis":"Gandhi, Arfive;Sensuse, Dana Indra;Sucahyo, Yudho Giri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Digital business with gig economy scheme had no culture to share knowledge since strictly competition among gig workers. It affects gig workers' limited ability and knowledge to accomplish projects and reduce their performance. This study proposed a knowledgesharing model to articulate insightful knowledge from scattered tacit and explicit knowledge by keep personal data and copyright. It performed Soft System Methodology to facilitate conceptualization process from founded problem until strategies formulation. It generated artifacts to clarify problems and elaborates their solutions. By decomposing the problems into fishbone analysis, this study has identified who are the involved stakeholders and how the knowledge management should run. It became root cause as baseline to conceptualize a knowledge sharing model among gig workers. As the result, this study delivered a knowledge sharing model which relied on point system to engage gig workers' participation to externalize their knowledge in knowledge repository and expert should validate them before knowledge storing. To achieve more qualified model, this study relied on validation by representative gig workers and platform applications. This model contributes to mediate knowledge circulation among gig workers by encourage their extrinsic motivation. Hence, it can deliver innovative solution to enhance digital business on modern society through gig worker empowerment. \u00a9 2019 Copyright held by the owner\/author(s).",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Digital business with gig economy scheme had no culture to share knowledge since strictly competition among gig workers. It affects gig workers' limited ability and knowledge to accomplish projects and reduce their performance. This study proposed a knowledgesharing model to articulate insightful knowledge from scattered tacit and explicit knowledge by keep personal data and copyright. It performed Soft System Methodology to facilitate conceptualization process from founded problem until strategies formulation. It generated artifacts to clarify problems and elaborates their solutions. By decomposing the problems into fishbone analysis, this study has identified who are the involved stakeholders and how the knowledge management should run. It became root cause as baseline to conceptualize a knowledge sharing model among gig workers. As the result, this study delivered a knowledge sharing model which relied on point system to engage gig workers' participation to externalize their knowledge in knowledge repository and expert should validate them before knowledge storing. To achieve more qualified model, this study relied on validation by representative gig workers and platform applications. This model contributes to mediate knowledge circulation among gig workers by encourage their extrinsic motivation. Hence, it can deliver innovative solution to enhance digital business on modern society through gig worker empowerment. \u00a9 2019 Copyright held by the owner\/author(s)."
        ]
    },
    {
        "judul":[
            "Dissipation of Solitary Wave Due To Mangrove Forest: A Numerical Study by Using Non-Dispersive Wave Model"
        ],
        "penulis":"Adytia, Didit;Husrin, Semeidi;Latifah, Arnida Lailatul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, we study a dissipation of solitary wave due to mangrove forest by using numerical simulation. Here, the solitary wave is chosen to represent tsunami wave form. To simulate the wave dynamic, we use the non-dispersive Nonlinear Shallow Water Equations (NSWE). The model is implemented numerically by using finite volume method in a momentum conservative staggered grid. By using the proposed numerical scheme, the numerical code is able to simulate solitary wave breaking phenomenon. Wave dissipation due to mangrove forest is modelled as bottom roughness with an approximate value of manning roughness, which is derived from the classical Morisson\u2019s formula. To test the modelled dissipation by mangrove forest, we reconstruct a physical experiment in hydrodynamic laboratory where a solitary wave propagates above a sloping bottom, which has a parameterized mangrove in the shallower part. Two cases are performed to test the performance of the numerical implementation, i.e. the non-breaking and breaking solitary waves. Results of simulation agree quite well with the measurement data. The results of simulation are also analyzed quantitatively by calculating errors as well as correlation with the measurement data. Moreover, to investigate effects of wave steepness on solitary wave, to the reduction of wave energy, we perform numerical investigation. Various solitary waves with different wave steepness are simulated to see their effects on amplitude and energy reduction due to mangrove forest. \u00a9 Ilmu Kelautan, UNDIP.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we study a dissipation of solitary wave due to mangrove forest by using numerical simulation. Here, the solitary wave is chosen to represent tsunami wave form. To simulate the wave dynamic, we use the non-dispersive Nonlinear Shallow Water Equations (NSWE). The model is implemented numerically by using finite volume method in a momentum conservative staggered grid. By using the proposed numerical scheme, the numerical code is able to simulate solitary wave breaking phenomenon. Wave dissipation due to mangrove forest is modelled as bottom roughness with an approximate value of manning roughness, which is derived from the classical Morisson\u2019s formula. To test the modelled dissipation by mangrove forest, we reconstruct a physical experiment in hydrodynamic laboratory where a solitary wave propagates above a sloping bottom, which has a parameterized mangrove in the shallower part. Two cases are performed to test the performance of the numerical implementation, i.e. the non-breaking and breaking solitary waves. Results of simulation agree quite well with the measurement data. The results of simulation are also analyzed quantitatively by calculating errors as well as correlation with the measurement data. Moreover, to investigate effects of wave steepness on solitary wave, to the reduction of wave energy, we perform numerical investigation. Various solitary waves with different wave steepness are simulated to see their effects on amplitude and energy reduction due to mangrove forest. \u00a9 Ilmu Kelautan, UNDIP."
        ]
    },
    {
        "judul":[
            "Seizure Type Classification on EEG Signal using Support Vector Machine"
        ],
        "penulis":"Dwi Saputro, Inggi Ramadhani;Maryati, Nita Dwi;Solihati, Siti Rizqia;Wijayanto, Inung;Hadiyoso, Sugondo;Patmasari, Raditiana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One instrument to record the activity of brainwave in a specific time is called Electroencephalography (EEG). EEG signal can be used to analyze the epilepsy disease. Brainwave of seizure patient has a low frequency with a tighter pattern than brainwave of normal people. We use data from Temple University Hospital Seizure Corpus (TUSZ) that represents an accurate clinical condition characterization. Based on neurologist report, several types of seizure can be found in the dataset. In this research, we classify three types of seizure, Generalized Non-Specific Seizure (GNSZ), Focal Non-Specific Seizure (FNSZ) and Tonic-Clonic Seizure (TCSZ). We added a normal EEG signal, so we have four classes to be classified using Support Vector Machine (SVM). The training dataset consists from 120 data (20 GNSZ, 50 FNSZ, 25 TCSZ and 25 Normal), while the evaluation dataset is 90 datasets (20 GNSZ, 50 FNSZ, 5 TCSZ and 15 Normal). We observe the combination of three feature extraction method, Mel Frequency Cepstral Coefficients (MFCC), Hjorth Descriptor and Independent Component Analysis (ICA). The best result obtained by combining MFCC and Hjorth descriptor that can detect seizure type with 90.25%, 97.83%, and 91.4% of average sensitivity, average specificity, and accuracy respectively. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One instrument to record the activity of brainwave in a specific time is called Electroencephalography (EEG). EEG signal can be used to analyze the epilepsy disease. Brainwave of seizure patient has a low frequency with a tighter pattern than brainwave of normal people. We use data from Temple University Hospital Seizure Corpus (TUSZ) that represents an accurate clinical condition characterization. Based on neurologist report, several types of seizure can be found in the dataset. In this research, we classify three types of seizure, Generalized Non-Specific Seizure (GNSZ), Focal Non-Specific Seizure (FNSZ) and Tonic-Clonic Seizure (TCSZ). We added a normal EEG signal, so we have four classes to be classified using Support Vector Machine (SVM). The training dataset consists from 120 data (20 GNSZ, 50 FNSZ, 25 TCSZ and 25 Normal), while the evaluation dataset is 90 datasets (20 GNSZ, 50 FNSZ, 5 TCSZ and 15 Normal). We observe the combination of three feature extraction method, Mel Frequency Cepstral Coefficients (MFCC), Hjorth Descriptor and Independent Component Analysis (ICA). The best result obtained by combining MFCC and Hjorth descriptor that can detect seizure type with 90.25%, 97.83%, and 91.4% of average sensitivity, average specificity, and accuracy respectively. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "An implementation of support vector machine on the multi-label classification of english-translated quranic verses"
        ],
        "penulis":"Prabowo, Satrio Adi;Adiwijaya;Mubarok, Mohamad Syahrul;Faraby, Said Al;Naf, Muhammad Zidny;Abu Bakar, Muhammad Yuslan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One of the attempts to understand the meaning and content of the Quran, the central religious text of Islam, is the topic classification of Quranic verses. Verse topic classification aims to help the reader, so he can easily and quickly find information or knowledge contained in the Quran. In this paper, we build a classification model for the topics of English-translated Quranic verses using Support Vector Machine (SVM). The problem of classification of topics of Quranic verses is categorized as a multi-label classification problem. Hence, we design an SVM-based classifier to solve the multi-label classification of topics of Quranic verses. We also implement several techniques such as preprocessing, feature extraction, and dimensionality reduction to solve this problem. Then, we use Hamming Loss as a performance measure to evaluate our proposed classifier model. We find that our proposed model yields outstanding results. \u00a9 2019 Satrio Adi Prabowo, Adiwijaya, Mohamad Syahrul Mubarok, Said Al Faraby, Muhammad Zidny Naf and Muhammad Yuslan Abu Bakar.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the attempts to understand the meaning and content of the Quran, the central religious text of Islam, is the topic classification of Quranic verses. Verse topic classification aims to help the reader, so he can easily and quickly find information or knowledge contained in the Quran. In this paper, we build a classification model for the topics of English-translated Quranic verses using Support Vector Machine (SVM). The problem of classification of topics of Quranic verses is categorized as a multi-label classification problem. Hence, we design an SVM-based classifier to solve the multi-label classification of topics of Quranic verses. We also implement several techniques such as preprocessing, feature extraction, and dimensionality reduction to solve this problem. Then, we use Hamming Loss as a performance measure to evaluate our proposed classifier model. We find that our proposed model yields outstanding results. \u00a9 2019 Satrio Adi Prabowo, Adiwijaya, Mohamad Syahrul Mubarok, Said Al Faraby, Muhammad Zidny Naf and Muhammad Yuslan Abu Bakar."
        ]
    },
    {
        "judul":[
            "Engagement Experiences on Using Gamified Platform in Pre-service Teacher Education"
        ],
        "penulis":"Slamet, Taufik Ikhsan;Setyosari, Punaji;Fawwaz Al Maki, Wikky;Varelo, Jonathan;Oktaviani, Herlina Ike;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, we reflected our experience on using gamification platform to facilitate pre-service teachers to engage in different approach for improving teaching knowledge and skills. The platform called 'Berguru' (http:\/\/berguru.net) was developed to build strong and meaningful connection between students in pre-service teacher education program with master or real teachers in school institution. 34 students were involved in this experiment and trained to use the platform in a very narrow time to understand how adaptive the platform was. These students came from cross different teaching subjects, i.e. economics, engineering, science, and literacy. We measured and examined their responses based on the interaction occurred naturally during the process. These responses are indicated through several aspects, such as layout design, color composition, accessibility, control, clarity of purpose, personalization, and gamification features. By using Likert scale on a single questionnaire and accompanied by short interview to some students, it revealed that the gamification platform was highly adaptive, helpful, and potential to offer students a new engaging way of learning experience. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we reflected our experience on using gamification platform to facilitate pre-service teachers to engage in different approach for improving teaching knowledge and skills. The platform called 'Berguru' (http:\/\/berguru.net) was developed to build strong and meaningful connection between students in pre-service teacher education program with master or real teachers in school institution. 34 students were involved in this experiment and trained to use the platform in a very narrow time to understand how adaptive the platform was. These students came from cross different teaching subjects, i.e. economics, engineering, science, and literacy. We measured and examined their responses based on the interaction occurred naturally during the process. These responses are indicated through several aspects, such as layout design, color composition, accessibility, control, clarity of purpose, personalization, and gamification features. By using Likert scale on a single questionnaire and accompanied by short interview to some students, it revealed that the gamification platform was highly adaptive, helpful, and potential to offer students a new engaging way of learning experience. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Data"
        ],
        "penulis":"Nasution, Mahyuddin K.M.;Aulia, Indra;Elveny, Marischa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Towards understanding the big data conceptually, it is necessary to understand data entirely. Understanding of data is not only directly related to the relationship between the sample and the population, but also to determine the form of approach and the process used. This is based on data dimensions that require in-depth consideration to be able to be the useful information in decision making, and become the helpful knowledge in the direction of policy in the Industry 4.0 era. Therefore this paper is built to briefly describe data. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Towards understanding the big data conceptually, it is necessary to understand data entirely. Understanding of data is not only directly related to the relationship between the sample and the population, but also to determine the form of approach and the process used. This is based on data dimensions that require in-depth consideration to be able to be the useful information in decision making, and become the helpful knowledge in the direction of policy in the Industry 4.0 era. Therefore this paper is built to briefly describe data. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Evaluation of DLX Microprocessor Instructions Efficiency for Image Compression"
        ],
        "penulis":"Karna, Nyoman;Fatihah, Nimas;Kim, Dong-Seong;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Internet of Things (IoT) implementation usually uses a generic microprocessor, especially when the implementation is for a specific functionality where ASIC (Application-specific Integrated Circuit) has not yet available. However, a generic microprocessor originally designed for general purpose application that uses many machine instructions, which in return causes an inefficient power consumption. Although ASIC is the best choice when comes to power efficiency, ASIC is hardcoded, meaning that it is not programmable or is not flexible for future enhancement or to accommodate intelligent properties like ability to learn and grow. This research tries to find the minimum instruction set to propose an ASIP (Application-specific Instruction Set Processor) for application in high quality image compression coming from CCTV. This research uses the DLX microprocessor instruction set as a reference on Huffman Coding as part of JPEG compression. The research shows that Huffman Coding needs only 9 type of machine instruction, they are ADD, ADDI, SUBI, LW, SW, BEQZ, BNEZ, SEQ, and SGT. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet of Things (IoT) implementation usually uses a generic microprocessor, especially when the implementation is for a specific functionality where ASIC (Application-specific Integrated Circuit) has not yet available. However, a generic microprocessor originally designed for general purpose application that uses many machine instructions, which in return causes an inefficient power consumption. Although ASIC is the best choice when comes to power efficiency, ASIC is hardcoded, meaning that it is not programmable or is not flexible for future enhancement or to accommodate intelligent properties like ability to learn and grow. This research tries to find the minimum instruction set to propose an ASIP (Application-specific Instruction Set Processor) for application in high quality image compression coming from CCTV. This research uses the DLX microprocessor instruction set as a reference on Huffman Coding as part of JPEG compression. The research shows that Huffman Coding needs only 9 type of machine instruction, they are ADD, ADDI, SUBI, LW, SW, BEQZ, BNEZ, SEQ, and SGT. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Deep-ACTINet: End-to-end deep learning architecture for automatic sleep-wake detection using wrist actigraphy"
        ],
        "penulis":"Cho, Taeheum;Sunarya, Unang;Yeo, Minsoo;Hwang, Bosun;Koo, Yong Seo;Park, Cheolsoo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Sleep scoring is the first step for diagnosing sleep disorders. A variety of chronic diseases related to sleep disorders could be identified using sleep-state estimation. This paper presents an end-to-end deep learning architecture using wrist actigraphy, called Deep-ACTINet, for automatic sleep-wake detection using only noise canceled raw activity signals recorded during sleep and without a feature engineering method. As a benchmark test, the proposed Deep-ACTINet is compared with two conventional fixed model based sleep-wake scoring algorithms and four feature engineering based machine learning algorithms. The datasets were recorded from 10 subjects using three-axis accelerometer wristband sensors for eight hours in bed. The sleep recordings were analyzed using Deep-ACTINet and conventional approaches, and the suggested end-to-end deep learning model gained the highest accuracy of 89.65%, recall of 92.99%, and precision of 92.09% on average. These values were approximately 4.74% and 4.05% higher than those for the traditional model based and feature based machine learning algorithms, respectively. In addition, the neuron outputs of Deep-ACTINet contained the most significant information for separating the asleep and awake states, which was demonstrated by their high correlations with conventional significant features. Deep-ACTINet was designed to be a general model and thus has the potential to replace current actigraphy algorithms equipped in wristband wearable devices. \u00a9 2019 by the authors. Licensee MDPI, Basel, Switzerland.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sleep scoring is the first step for diagnosing sleep disorders. A variety of chronic diseases related to sleep disorders could be identified using sleep-state estimation. This paper presents an end-to-end deep learning architecture using wrist actigraphy, called Deep-ACTINet, for automatic sleep-wake detection using only noise canceled raw activity signals recorded during sleep and without a feature engineering method. As a benchmark test, the proposed Deep-ACTINet is compared with two conventional fixed model based sleep-wake scoring algorithms and four feature engineering based machine learning algorithms. The datasets were recorded from 10 subjects using three-axis accelerometer wristband sensors for eight hours in bed. The sleep recordings were analyzed using Deep-ACTINet and conventional approaches, and the suggested end-to-end deep learning model gained the highest accuracy of 89.65%, recall of 92.99%, and precision of 92.09% on average. These values were approximately 4.74% and 4.05% higher than those for the traditional model based and feature based machine learning algorithms, respectively. In addition, the neuron outputs of Deep-ACTINet contained the most significant information for separating the asleep and awake states, which was demonstrated by their high correlations with conventional significant features. Deep-ACTINet was designed to be a general model and thus has the potential to replace current actigraphy algorithms equipped in wristband wearable devices. \u00a9 2019 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Development of high power class-E amplifier for radio communication of tsunami early warning system"
        ],
        "penulis":"Kusmadi, Kusmadi;Syihabuddin, Budi;Aji, Galih Mustiko;Fajar Pratiwi, Artdhita;Purwiyanto, Purwiyanto;Chairunnisa, Chairunnisa;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Utilization of radio communication is one of alternative methods which can be offered to the society in responding tsunami warning. In order to have large coverage, the used radio communication requires high power output of radio frequency (RF) amplifier. This paper deals with the development of high power class-E amplifier implemented for radio communication of tsunami early warning systems (TEWS). The proposed amplifier is developed using a power laterally-diffused metal-oxide semiconductor (LDMOS) transistor of BLF188XR type from Am-pleon as the main component. The frequency range of developed amplifier is 90MHz to 110 MHz which is suited for proposed radio communication of TEWS. Some attempts to attain high power amplification are performed through a circuit EM simulator software. Based on the optimum performance, the proposed amplifier is then deployed on a printed circuit board (PCB) for experimental measurement. The result shows that the realized amplifier has the gain achievement more than 21 dB at the frequency of 100 MHz suitable for the desired application. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Utilization of radio communication is one of alternative methods which can be offered to the society in responding tsunami warning. In order to have large coverage, the used radio communication requires high power output of radio frequency (RF) amplifier. This paper deals with the development of high power class-E amplifier implemented for radio communication of tsunami early warning systems (TEWS). The proposed amplifier is developed using a power laterally-diffused metal-oxide semiconductor (LDMOS) transistor of BLF188XR type from Am-pleon as the main component. The frequency range of developed amplifier is 90MHz to 110 MHz which is suited for proposed radio communication of TEWS. Some attempts to attain high power amplification are performed through a circuit EM simulator software. Based on the optimum performance, the proposed amplifier is then deployed on a printed circuit board (PCB) for experimental measurement. The result shows that the realized amplifier has the gain achievement more than 21 dB at the frequency of 100 MHz suitable for the desired application. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Spreading Factor Variations on LoRa in Rural Areas"
        ],
        "penulis":"Turmudzi, Muhammad;Rakhmatsyah, Andrian;Wardana, Aulia Arif;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study will analyze the use of spreading factor variations from Long Range (LoRa) as Wireless Sensor Network (WSN) in the rural area to support the Internet of Things (IoT) technology. IoT is a Machine-to-machine (M2M) technology that requires an internet connection to send data. Internet connections in each region (especially in rural areas) are certainly different, one of the problems is the coverage of the mobile network. Because coverage from the internet is limited, IoT must be supported by WSN networks to retrieve data from non-mobile and non-TCP networks. One of the most popular technologies in the WSN is LoRa, which is Low Power Wide Area Network (LPWAN) technology. The advantage is that it has a wide coverage area, is cheap and has low power. So it is necessary to do a LoRa coverage test to find out how far it can reach especially in rural areas. In this paper, the testing of LoRa coverage in rural areas is tested and has hilly characteristics which have quite many obstacles so that it can be the worst possibility in LoRa coverage. This research uses the entire configuration in the Spreading Factor to determine the effect on distance. The test results show that LoRa can send data up to 980 meters in SF12 with a PDR of 12% and PER 100%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study will analyze the use of spreading factor variations from Long Range (LoRa) as Wireless Sensor Network (WSN) in the rural area to support the Internet of Things (IoT) technology. IoT is a Machine-to-machine (M2M) technology that requires an internet connection to send data. Internet connections in each region (especially in rural areas) are certainly different, one of the problems is the coverage of the mobile network. Because coverage from the internet is limited, IoT must be supported by WSN networks to retrieve data from non-mobile and non-TCP networks. One of the most popular technologies in the WSN is LoRa, which is Low Power Wide Area Network (LPWAN) technology. The advantage is that it has a wide coverage area, is cheap and has low power. So it is necessary to do a LoRa coverage test to find out how far it can reach especially in rural areas. In this paper, the testing of LoRa coverage in rural areas is tested and has hilly characteristics which have quite many obstacles so that it can be the worst possibility in LoRa coverage. This research uses the entire configuration in the Spreading Factor to determine the effect on distance. The test results show that LoRa can send data up to 980 meters in SF12 with a PDR of 12% and PER 100%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A novel differential modulation scheme using full-rate STBC for 4\u00d74 MIMO OFDM"
        ],
        "penulis":"Setiawan, Dhoni Putra;Zhao, Hua-An;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Non-coherent communication which employs Differential Modulation (DM) technique is an interesting technique to combat the uncertainty of channel in the wireless communication system. This technique also provides a more spectral efficient system than coherent communication because it does not need the presence of signal overhead for channel estimation purpose which usually exists in the coherent transmission. To improve the performance of DM technique, differential unitary modulation technique which is combining DM and Space Time Block Code (STBC) is explored in this paper. In this paper, we modify a quasi-orthogonal STBC (QO-STBC) to be used as a unitary matrix generator, and then we introduce an element-wise calculation concept to minimize the system complexity. The experimental results show the proposed differential unitary modulation technique could be an excellent technique to overcome the uncertainty of channel in a wireless telecommunication system. \u00a9 2019 Int. J. Elec. & Elecn. Eng. & J. Telcomm.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Non-coherent communication which employs Differential Modulation (DM) technique is an interesting technique to combat the uncertainty of channel in the wireless communication system. This technique also provides a more spectral efficient system than coherent communication because it does not need the presence of signal overhead for channel estimation purpose which usually exists in the coherent transmission. To improve the performance of DM technique, differential unitary modulation technique which is combining DM and Space Time Block Code (STBC) is explored in this paper. In this paper, we modify a quasi-orthogonal STBC (QO-STBC) to be used as a unitary matrix generator, and then we introduce an element-wise calculation concept to minimize the system complexity. The experimental results show the proposed differential unitary modulation technique could be an excellent technique to overcome the uncertainty of channel in a wireless telecommunication system. \u00a9 2019 Int. J. Elec. & Elecn. Eng. & J. Telcomm."
        ]
    },
    {
        "judul":[
            "Segment repetition based on high amplitude to enhance a speech emotion recognition"
        ],
        "penulis":"Prayitno, Bagas Adi;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Speech Emotion Recognition (SER) is a technology developed on a computer to realize a Human-Computer Interaction (HCI). It is a challenging task since the lack of data. Some data augmentation methods have been created to increase the data variation, but they do not significantly improve accuracy. Therefore, a new additional data augmentation method called Segment Repetition based on High Amplitude (SRHA) is proposed to solve this problem. This method makes some repetitions on the segments that have the highest amplitude. An experiment of 10 times data augmentation, using five standard augmentations and the additional SRHA with a Long Short-Term Memory (LSTM) as the classifier, shows that the proposed SRHA significantly increases the SER accuracy from 95.88% to 98.16%. Other experiments for 20 and 40 times data augmentations also show that the SRHA outperforms the five standard augmentations. These indicate that the SRHA is a powerful data augmentation method for SER. \u00a9 2019 The Authors. Published by Elsevier B.V.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Speech Emotion Recognition (SER) is a technology developed on a computer to realize a Human-Computer Interaction (HCI). It is a challenging task since the lack of data. Some data augmentation methods have been created to increase the data variation, but they do not significantly improve accuracy. Therefore, a new additional data augmentation method called Segment Repetition based on High Amplitude (SRHA) is proposed to solve this problem. This method makes some repetitions on the segments that have the highest amplitude. An experiment of 10 times data augmentation, using five standard augmentations and the additional SRHA with a Long Short-Term Memory (LSTM) as the classifier, shows that the proposed SRHA significantly increases the SER accuracy from 95.88% to 98.16%. Other experiments for 20 and 40 times data augmentations also show that the SRHA outperforms the five standard augmentations. These indicate that the SRHA is a powerful data augmentation method for SER. \u00a9 2019 The Authors. Published by Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Self-healing corrosion protective coatings in transportation industries"
        ],
        "penulis":"Yabuki, Akihiro;Fathona, Indra W.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Self-healing is a natural ability to spontaneously cure injury or illness, and this concept is now being applied in anticorrosion coatings. Recently, the design of a self-healing coating that could provide repetitive protection was proposed. In this chapter, the types, synthesis, properties, and characteristics of smart coatings in transportation industries are described and discussed. Corrosion and protection against it in various metallic materials are briefly explained. A specific discussion in self-healing coating consisting microand nanocapsules, fibers networks are presented. The future trend of self-healing coatings for corrosion protection will be described. \u00a9 2020 Elsevier Inc. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Self-healing is a natural ability to spontaneously cure injury or illness, and this concept is now being applied in anticorrosion coatings. Recently, the design of a self-healing coating that could provide repetitive protection was proposed. In this chapter, the types, synthesis, properties, and characteristics of smart coatings in transportation industries are described and discussed. Corrosion and protection against it in various metallic materials are briefly explained. A specific discussion in self-healing coating consisting microand nanocapsules, fibers networks are presented. The future trend of self-healing coatings for corrosion protection will be described. \u00a9 2020 Elsevier Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "The influence of digital leadership on innovation management based on dynamic capability: Market orientation as a moderator"
        ],
        "penulis":"Mihardjo, Leonardus W. Wasono;Sasmoko;Alamsyah, Firdaus;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Due to market changes in the digital era, we argue that innovation based on dynamic capability is accelerated when aligned with market orientation. Digital leadership will significantly enable sensing market changes, seizing opportunities, and reconfiguring organizations. Previous studies on digital leadership, dynamic capability, and innovation management focus mainly on constructs, benefits, and implications. However, a study on the role of digital leadership based on dynamic capability in fostering innovation and the impact of market orientation have not been thoroughly explored, which is the aim of this study, taking market orientation as a moderating variable. Employing a quantitative methodology, data were collected through online questionnaires, distributed through email and messaging applications to a purposive sample of 88 senior managers of Indonesian telecommunication firms. The results reveal that digital leadership based on dynamic capability impacts directly and indirectly on developing innovation. Market orientation also plays an important role in accelerating innovation. Due to limitations in terms of research model, sample size, and time, further research using larger samples in other industries and countries should be undertaken. \u00a9 2019 by the authors; licensee Growing Science, Canada.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Due to market changes in the digital era, we argue that innovation based on dynamic capability is accelerated when aligned with market orientation. Digital leadership will significantly enable sensing market changes, seizing opportunities, and reconfiguring organizations. Previous studies on digital leadership, dynamic capability, and innovation management focus mainly on constructs, benefits, and implications. However, a study on the role of digital leadership based on dynamic capability in fostering innovation and the impact of market orientation have not been thoroughly explored, which is the aim of this study, taking market orientation as a moderating variable. Employing a quantitative methodology, data were collected through online questionnaires, distributed through email and messaging applications to a purposive sample of 88 senior managers of Indonesian telecommunication firms. The results reveal that digital leadership based on dynamic capability impacts directly and indirectly on developing innovation. Market orientation also plays an important role in accelerating innovation. Due to limitations in terms of research model, sample size, and time, further research using larger samples in other industries and countries should be undertaken. \u00a9 2019 by the authors; licensee Growing Science, Canada."
        ]
    },
    {
        "judul":[
            "A study on signal complexity measurement for epileptic seizure detection"
        ],
        "penulis":"Wijayanto, Inung;Hartanto, Rudy;Nugroho, Hanung Adi;Setiawan, Noor Akhmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Epilepsy is a sudden brain malfunction that represented by an exaggerated, high, and hypersynchronous neuron activity inside the brain. Electroencephalogram (EEG) is a tool that can be used to measure the electrical changes of the brain by using electrodes placed on the scalp. An ictal pattern in the EEG signal can be used to identify seizure condition. Neurologist search for the ictal state by determining slow, spike, and sharp wave in the EEG recording manually. However, the manual method is very vulnerable to human errors. That is why many research has been conducted to develop an automatic seizure detection system. Since the EEG signal is a nonlinear, nonstationary, and chaotic, it is considered as a complex signal. This paper discusses a brief study on signal complexity measurement in the EEG signal in the term of epileptic seizure detection. Complexity measurement based on statistic, entropy, and chaos analysis is explored in six processing domain. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Epilepsy is a sudden brain malfunction that represented by an exaggerated, high, and hypersynchronous neuron activity inside the brain. Electroencephalogram (EEG) is a tool that can be used to measure the electrical changes of the brain by using electrodes placed on the scalp. An ictal pattern in the EEG signal can be used to identify seizure condition. Neurologist search for the ictal state by determining slow, spike, and sharp wave in the EEG recording manually. However, the manual method is very vulnerable to human errors. That is why many research has been conducted to develop an automatic seizure detection system. Since the EEG signal is a nonlinear, nonstationary, and chaotic, it is considered as a complex signal. This paper discusses a brief study on signal complexity measurement in the EEG signal in the term of epileptic seizure detection. Complexity measurement based on statistic, entropy, and chaos analysis is explored in six processing domain. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Cultural and Environmental Conservation through Community Service Program in Girimekar Village"
        ],
        "penulis":"Trihanondo, Donny;Endriawan, Didit;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Girimekar village in the outskirt of Bandung was chosen as target for community service program conducted by Telkom University and PT. Telkom Indonesia. The program lasted for 6 months. This program consisted of workshops, mural making, environmental conservation and waste management. Research was also conducted during the program, to analyze the effectiveness of the program to increase the villager's knowledge in cultural and environmental conservation. The method used in the research is participatory approach which used qualitative data. The findings are that the program effectively increase the awareness of the participants in recognizing environmental issues and that the visualization used in the mural making attracts people to come to see the murals. This is not only providing economic opportunities for the villagers, but also give challenges to the environmental conservation. The program is still ongoing, and this papers provide preliminary findings and discussions. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentResponsible consumption and productionGoal 12Life on landGoal 15Peace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Girimekar village in the outskirt of Bandung was chosen as target for community service program conducted by Telkom University and PT. Telkom Indonesia. The program lasted for 6 months. This program consisted of workshops, mural making, environmental conservation and waste management. Research was also conducted during the program, to analyze the effectiveness of the program to increase the villager's knowledge in cultural and environmental conservation. The method used in the research is participatory approach which used qualitative data. The findings are that the program effectively increase the awareness of the participants in recognizing environmental issues and that the visualization used in the mural making attracts people to come to see the murals. This is not only providing economic opportunities for the villagers, but also give challenges to the environmental conservation. The program is still ongoing, and this papers provide preliminary findings and discussions. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Impact of device orientation for visible light communication in closed room"
        ],
        "penulis":"Wijayanto, Amirullah;Sujatmoko, Kris;Pamukti, Brian;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper evaluates the impact of device orientation in Visible Light Communication (VLC) with the Bit Error Rate (BER) as the main parameter of measurement. Most studies on optical wireless communications have neglected the effect of random orientation in their performance analysis. In this paper, we analyze the device orientation and assess its importance on system performance. The device orientation are we use equal to 0\u00b0, 15\u00b0, and 35\u00b0. To support the simulation, we use the OOKNRZ modulation techniques with the threshold Bit Error Rate (BER) around 10-5. Each of the device orientation has the value of a wide range of communication coverage. The smaller of device orientation, the coverage will be wider. With using the biggest device orientation, the communication coverage is decreased of 11,04% while the smallest device orientation is 98.08% coverage area. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper evaluates the impact of device orientation in Visible Light Communication (VLC) with the Bit Error Rate (BER) as the main parameter of measurement. Most studies on optical wireless communications have neglected the effect of random orientation in their performance analysis. In this paper, we analyze the device orientation and assess its importance on system performance. The device orientation are we use equal to 0\u00b0, 15\u00b0, and 35\u00b0. To support the simulation, we use the OOKNRZ modulation techniques with the threshold Bit Error Rate (BER) around 10-5. Each of the device orientation has the value of a wide range of communication coverage. The smaller of device orientation, the coverage will be wider. With using the biggest device orientation, the communication coverage is decreased of 11,04% while the smallest device orientation is 98.08% coverage area. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of steady river flow through a sluice gate with a case study of Ciliwung River"
        ],
        "penulis":"Alamsyah M.N.A.;Gunawan P.H.;Pudjaprasetya S.R.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "During wet seasons, tropical rain may cause high discharge on rivers. To prevent flooding in the watershed area, sluice gates can be installed to control the water surface level. However, operating a sluice gate is not a trivial task; we must be aware of the backwater effect. Backwater is an increase of the upstream water level resulting from an obstruction of the flow, here is caused by the installation of a sluice gate. In addition, characteristic of the upstream and downstream flow which depend on flow types (subcritical or supercritical) must also be examined. In this paper, we analyse the behaviour of steady river flow through a sluice gate. On a river flow, the presence of a sluice gate (with a fixed opening), will change the total energy of the flow. Then, using the specific energy curve we can determine water surface level behind the gate. Further, by implementing the standard step method, a steady water surface on the upstream part of the gate can be calculated. This surface forms a backwater flow that extends far enough behind the gate. Characteristic of this backwater flow depends crucially on the flow discharge and the opening of the sluice gate. For the case study, we took the Ciliwung River with the Manggarai sluice gate, located nearly in the middle of the river. With the aim of preventing flooding in the watershed area, we calculated several scenarios of sluice gate opening under various river discharge. Our results may help sluice gate operator in controlling the Manggarai sluice gate of the Ciliwung River. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "During wet seasons, tropical rain may cause high discharge on rivers. To prevent flooding in the watershed area, sluice gates can be installed to control the water surface level. However, operating a sluice gate is not a trivial task; we must be aware of the backwater effect. Backwater is an increase of the upstream water level resulting from an obstruction of the flow, here is caused by the installation of a sluice gate. In addition, characteristic of the upstream and downstream flow which depend on flow types (subcritical or supercritical) must also be examined. In this paper, we analyse the behaviour of steady river flow through a sluice gate. On a river flow, the presence of a sluice gate (with a fixed opening), will change the total energy of the flow. Then, using the specific energy curve we can determine water surface level behind the gate. Further, by implementing the standard step method, a steady water surface on the upstream part of the gate can be calculated. This surface forms a backwater flow that extends far enough behind the gate. Characteristic of this backwater flow depends crucially on the flow discharge and the opening of the sluice gate. For the case study, we took the Ciliwung River with the Manggarai sluice gate, located nearly in the middle of the river. With the aim of preventing flooding in the watershed area, we calculated several scenarios of sluice gate opening under various river discharge. Our results may help sluice gate operator in controlling the Manggarai sluice gate of the Ciliwung River. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Analysis and implementation of steganography on JPEG using LSB and spread spectrum method"
        ],
        "penulis":"Bagaskara, Jordy A.;Purboyo, Tito Waluyo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Information is a message in the form of a utterance or phrase that can consist of symbols, or meanings that can be interpreted from a message or a collection of messages. Steganography is a technique that can be used to hide information on a media. In the digital era, the media used can be audio, image, or video. In its use, the concealment of messages is done by making small changes to a digital medium so as not to attract the attention of other people or attackers. In general, the concealment of a data or message on the image media is a technique that is often used in the implementation of steganography. In the use of image media, steganography can be implemented with existing methods; in this journal will be implemented Least Significant Bit (LSB) and Spread Spectrum method, which will further determine the analysis of image quality and comparison of both methods. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information is a message in the form of a utterance or phrase that can consist of symbols, or meanings that can be interpreted from a message or a collection of messages. Steganography is a technique that can be used to hide information on a media. In the digital era, the media used can be audio, image, or video. In its use, the concealment of messages is done by making small changes to a digital medium so as not to attract the attention of other people or attackers. In general, the concealment of a data or message on the image media is a technique that is often used in the implementation of steganography. In the use of image media, steganography can be implemented with existing methods; in this journal will be implemented Least Significant Bit (LSB) and Spread Spectrum method, which will further determine the analysis of image quality and comparison of both methods. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Energy extraction method for EEG channel selection"
        ],
        "penulis":"Fauzi, Hilman;Azzam, M. Abdullah;Shapiai, Mohd. Ibrahim;Kyoso, Masaki;Khairuddin, Uswah;Komura, Tadayasu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Channel selection is an improvement technique to optimize EEG-based BCI performance. In previous studies, many channel selection methods-mostly based on spatial information of signals-have been introduced. One of these channel selection techniques is the energy calculation method. In this paper, we introduce an energy optimization calculation method, called the energy extraction method. Energy extraction is an extension of the energy calculation method, and is divided into two steps. The first step is energy calculation and the second is energy selection. In the energy calculation step, l2-norm is used to calculate channel energy, while in the energy selection method we propose three techniques: \"high value\" (HV), \"close to mean\" (CM), and \"automatic\". All proposed framework schemes for energy extraction are applied in two types of datasets. Two classes of datasets i.e. motor movement (hand and foot movement) and motor imagery (imagination of left-and right-hand movement) were used. The system used a Common Spatial Pattern (CSP) method to extract EEG signal features and k-NN as a classification method to classify the signal features with k=3. Based on the test results, all schemes for the proposed energy extraction method yielded improved BCI performance of up to 58%. In summary, the energy extraction approach using the CM energy selection method was found to be the best channel selection technique. \u00a9 2020 by the authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Channel selection is an improvement technique to optimize EEG-based BCI performance. In previous studies, many channel selection methods-mostly based on spatial information of signals-have been introduced. One of these channel selection techniques is the energy calculation method. In this paper, we introduce an energy optimization calculation method, called the energy extraction method. Energy extraction is an extension of the energy calculation method, and is divided into two steps. The first step is energy calculation and the second is energy selection. In the energy calculation step, l2-norm is used to calculate channel energy, while in the energy selection method we propose three techniques: \"high value\" (HV), \"close to mean\" (CM), and \"automatic\". All proposed framework schemes for energy extraction are applied in two types of datasets. Two classes of datasets i.e. motor movement (hand and foot movement) and motor imagery (imagination of left-and right-hand movement) were used. The system used a Common Spatial Pattern (CSP) method to extract EEG signal features and k-NN as a classification method to classify the signal features with k=3. Based on the test results, all schemes for the proposed energy extraction method yielded improved BCI performance of up to 58%. In summary, the energy extraction approach using the CM energy selection method was found to be the best channel selection technique. \u00a9 2020 by the authors."
        ]
    },
    {
        "judul":[
            "Knowledge Sharing Model for Competitive Ecosystem on Gig Economy"
        ],
        "penulis":"Gandhi, Arfive;Sensuse, Dana Indra;Sucahyo, Yudho Giri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Digital business with gig economy scheme had no culture to share knowledge since strictly competition among gig workers. It affects gig workers' limited ability and knowledge to accomplish projects and reduce their performance. This study proposed a knowledgesharing model to articulate insightful knowledge from scattered tacit and explicit knowledge by keep personal data and copyright. It performed Soft System Methodology to facilitate conceptualization process from founded problem until strategies formulation. It generated artifacts to clarify problems and elaborates their solutions. By decomposing the problems into fishbone analysis, this study has identified who are the involved stakeholders and how the knowledge management should run. It became root cause as baseline to conceptualize a knowledge sharing model among gig workers. As the result, this study delivered a knowledge sharing model which relied on point system to engage gig workers' participation to externalize their knowledge in knowledge repository and expert should validate them before knowledge storing. To achieve more qualified model, this study relied on validation by representative gig workers and platform applications. This model contributes to mediate knowledge circulation among gig workers by encourage their extrinsic motivation. Hence, it can deliver innovative solution to enhance digital business on modern society through gig worker empowerment. \u00a9 2019 Copyright held by the owner\/author(s).",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Digital business with gig economy scheme had no culture to share knowledge since strictly competition among gig workers. It affects gig workers' limited ability and knowledge to accomplish projects and reduce their performance. This study proposed a knowledgesharing model to articulate insightful knowledge from scattered tacit and explicit knowledge by keep personal data and copyright. It performed Soft System Methodology to facilitate conceptualization process from founded problem until strategies formulation. It generated artifacts to clarify problems and elaborates their solutions. By decomposing the problems into fishbone analysis, this study has identified who are the involved stakeholders and how the knowledge management should run. It became root cause as baseline to conceptualize a knowledge sharing model among gig workers. As the result, this study delivered a knowledge sharing model which relied on point system to engage gig workers' participation to externalize their knowledge in knowledge repository and expert should validate them before knowledge storing. To achieve more qualified model, this study relied on validation by representative gig workers and platform applications. This model contributes to mediate knowledge circulation among gig workers by encourage their extrinsic motivation. Hence, it can deliver innovative solution to enhance digital business on modern society through gig worker empowerment. \u00a9 2019 Copyright held by the owner\/author(s)."
        ]
    },
    {
        "judul":[
            "Dissipation of Solitary Wave Due To Mangrove Forest: A Numerical Study by Using Non-Dispersive Wave Model"
        ],
        "penulis":"Adytia, Didit;Husrin, Semeidi;Latifah, Arnida Lailatul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, we study a dissipation of solitary wave due to mangrove forest by using numerical simulation. Here, the solitary wave is chosen to represent tsunami wave form. To simulate the wave dynamic, we use the non-dispersive Nonlinear Shallow Water Equations (NSWE). The model is implemented numerically by using finite volume method in a momentum conservative staggered grid. By using the proposed numerical scheme, the numerical code is able to simulate solitary wave breaking phenomenon. Wave dissipation due to mangrove forest is modelled as bottom roughness with an approximate value of manning roughness, which is derived from the classical Morisson\u2019s formula. To test the modelled dissipation by mangrove forest, we reconstruct a physical experiment in hydrodynamic laboratory where a solitary wave propagates above a sloping bottom, which has a parameterized mangrove in the shallower part. Two cases are performed to test the performance of the numerical implementation, i.e. the non-breaking and breaking solitary waves. Results of simulation agree quite well with the measurement data. The results of simulation are also analyzed quantitatively by calculating errors as well as correlation with the measurement data. Moreover, to investigate effects of wave steepness on solitary wave, to the reduction of wave energy, we perform numerical investigation. Various solitary waves with different wave steepness are simulated to see their effects on amplitude and energy reduction due to mangrove forest. \u00a9 Ilmu Kelautan, UNDIP.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we study a dissipation of solitary wave due to mangrove forest by using numerical simulation. Here, the solitary wave is chosen to represent tsunami wave form. To simulate the wave dynamic, we use the non-dispersive Nonlinear Shallow Water Equations (NSWE). The model is implemented numerically by using finite volume method in a momentum conservative staggered grid. By using the proposed numerical scheme, the numerical code is able to simulate solitary wave breaking phenomenon. Wave dissipation due to mangrove forest is modelled as bottom roughness with an approximate value of manning roughness, which is derived from the classical Morisson\u2019s formula. To test the modelled dissipation by mangrove forest, we reconstruct a physical experiment in hydrodynamic laboratory where a solitary wave propagates above a sloping bottom, which has a parameterized mangrove in the shallower part. Two cases are performed to test the performance of the numerical implementation, i.e. the non-breaking and breaking solitary waves. Results of simulation agree quite well with the measurement data. The results of simulation are also analyzed quantitatively by calculating errors as well as correlation with the measurement data. Moreover, to investigate effects of wave steepness on solitary wave, to the reduction of wave energy, we perform numerical investigation. Various solitary waves with different wave steepness are simulated to see their effects on amplitude and energy reduction due to mangrove forest. \u00a9 Ilmu Kelautan, UNDIP."
        ]
    },
    {
        "judul":[
            "Seizure Type Classification on EEG Signal using Support Vector Machine"
        ],
        "penulis":"Dwi Saputro, Inggi Ramadhani;Maryati, Nita Dwi;Solihati, Siti Rizqia;Wijayanto, Inung;Hadiyoso, Sugondo;Patmasari, Raditiana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One instrument to record the activity of brainwave in a specific time is called Electroencephalography (EEG). EEG signal can be used to analyze the epilepsy disease. Brainwave of seizure patient has a low frequency with a tighter pattern than brainwave of normal people. We use data from Temple University Hospital Seizure Corpus (TUSZ) that represents an accurate clinical condition characterization. Based on neurologist report, several types of seizure can be found in the dataset. In this research, we classify three types of seizure, Generalized Non-Specific Seizure (GNSZ), Focal Non-Specific Seizure (FNSZ) and Tonic-Clonic Seizure (TCSZ). We added a normal EEG signal, so we have four classes to be classified using Support Vector Machine (SVM). The training dataset consists from 120 data (20 GNSZ, 50 FNSZ, 25 TCSZ and 25 Normal), while the evaluation dataset is 90 datasets (20 GNSZ, 50 FNSZ, 5 TCSZ and 15 Normal). We observe the combination of three feature extraction method, Mel Frequency Cepstral Coefficients (MFCC), Hjorth Descriptor and Independent Component Analysis (ICA). The best result obtained by combining MFCC and Hjorth descriptor that can detect seizure type with 90.25%, 97.83%, and 91.4% of average sensitivity, average specificity, and accuracy respectively. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One instrument to record the activity of brainwave in a specific time is called Electroencephalography (EEG). EEG signal can be used to analyze the epilepsy disease. Brainwave of seizure patient has a low frequency with a tighter pattern than brainwave of normal people. We use data from Temple University Hospital Seizure Corpus (TUSZ) that represents an accurate clinical condition characterization. Based on neurologist report, several types of seizure can be found in the dataset. In this research, we classify three types of seizure, Generalized Non-Specific Seizure (GNSZ), Focal Non-Specific Seizure (FNSZ) and Tonic-Clonic Seizure (TCSZ). We added a normal EEG signal, so we have four classes to be classified using Support Vector Machine (SVM). The training dataset consists from 120 data (20 GNSZ, 50 FNSZ, 25 TCSZ and 25 Normal), while the evaluation dataset is 90 datasets (20 GNSZ, 50 FNSZ, 5 TCSZ and 15 Normal). We observe the combination of three feature extraction method, Mel Frequency Cepstral Coefficients (MFCC), Hjorth Descriptor and Independent Component Analysis (ICA). The best result obtained by combining MFCC and Hjorth descriptor that can detect seizure type with 90.25%, 97.83%, and 91.4% of average sensitivity, average specificity, and accuracy respectively. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Recommendation of scheduling tourism routes using tabu search method (case study bandung)"
        ],
        "penulis":"Anranur Uwaisy M.;Baizal Z.K.A.;Yusza Reditya M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In 2019, the Indonesian Ministry of Tourism is in the process of improving the Go Digital program for the industrial era 4.0, where the internet has become one of the ways to determine travel destinations. However, currently, tourists still have difficulties obtaining detailed and complete information about tourist destinations, when visiting several destinations in one trip. Tourists are still having trouble estimating the distance and time needed for tourism independently, without having to depend on travel agents. These problems are often referred to as Traveling Salesman Problems (TSP). Therefore, we provide a solution to solve this TSP problem in the form of a system scheduling and searching route tourist using the tabu search method which enables tourists to find the optimal solution based on travel time, operational hours of tourist attraction, and the time limit of visits per day. Calculations in the tabu search method are combined with the concept of MAUT (Multi-Attribute Utility Theory) to determine the optimal tour based on several criteria: popularity, cost, and the number of attractions to be visited. Then, the test results of the tabu search method are compared with the firefly method. The result shows that the tabu search method is better than the firefly method, where there is an increase in accuracy of 48% in the calculation of fitness values, 47% in running time average, and 27% in the number of tours to be visited during 3 days of tour visits. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In 2019, the Indonesian Ministry of Tourism is in the process of improving the Go Digital program for the industrial era 4.0, where the internet has become one of the ways to determine travel destinations. However, currently, tourists still have difficulties obtaining detailed and complete information about tourist destinations, when visiting several destinations in one trip. Tourists are still having trouble estimating the distance and time needed for tourism independently, without having to depend on travel agents. These problems are often referred to as Traveling Salesman Problems (TSP). Therefore, we provide a solution to solve this TSP problem in the form of a system scheduling and searching route tourist using the tabu search method which enables tourists to find the optimal solution based on travel time, operational hours of tourist attraction, and the time limit of visits per day. Calculations in the tabu search method are combined with the concept of MAUT (Multi-Attribute Utility Theory) to determine the optimal tour based on several criteria: popularity, cost, and the number of attractions to be visited. Then, the test results of the tabu search method are compared with the firefly method. The result shows that the tabu search method is better than the firefly method, where there is an increase in accuracy of 48% in the calculation of fitness values, 47% in running time average, and 27% in the number of tours to be visited during 3 days of tour visits. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "New Reward-Based Movement to Improve Globally-Evolved BCO in Nurse Rostering Problem"
        ],
        "penulis":"Clarissa, Vebby;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nurse Rostering Problem (NRP) is a crucial problem in hospital industry with combinatorial complex problem. NRP is one of the NP-Hard problems, which means that today there is no definite algorithm that is capable of solving the problem. In this paper, a metaheuristic approach called Reward-Based Movement for Bee Colony Optimization (RBMBCO) is proposed to solve the NRP. It is evaluated using an NRP instance of 30 nurses for 4 weeks of assignment from The Second International Nurse Rostering Competition (INRC-II) dataset. The experimental results show that RBMBCO is capable of generating a better solution than the standard Globally-Evolved Bee Colony Optimization. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nurse Rostering Problem (NRP) is a crucial problem in hospital industry with combinatorial complex problem. NRP is one of the NP-Hard problems, which means that today there is no definite algorithm that is capable of solving the problem. In this paper, a metaheuristic approach called Reward-Based Movement for Bee Colony Optimization (RBMBCO) is proposed to solve the NRP. It is evaluated using an NRP instance of 30 nurses for 4 weeks of assignment from The Second International Nurse Rostering Competition (INRC-II) dataset. The experimental results show that RBMBCO is capable of generating a better solution than the standard Globally-Evolved Bee Colony Optimization. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Ina-BWR: Indonesian bigram word rule for multi-label student complaints"
        ],
        "penulis":"Fahrudin, Tora;Buliali, Joko Lianto;Fatichah, Chastine;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Handling multi-label student complaints is one of interesting research topics. One of techniques used for handling multi-label student complaints is Bag of Word (BoW) method. In this research bigram word rule and preprocess are proposed to increase the accuracy of multi-label classification results. To show the effectiveness of the proposed method, data from Telkom University student data and additional relevant data by using hashtag are used as testing data. We develop Indonesian Bigram Word Rule for Multi-label Student Complaints (Ina-BWR) to identify multi-label student problems based on Bigram Word Rule. Ina-BWR consists of three processes such as preprocessing informal text, identifying complaint and object from text. Additional preprocessing techniques are conducted to formalize the text such as parsing a hashtag, correcting affixes word, correcting a conjunction word, parsing suffix people pronoun and correcting typo words. Indonesian bigram word rule is adopted from opinion identification rules with 3 additional corpuses (-)NN, (-)JJ and (-)VB to identify student complaints. To identify complaints, four label corpuses have been created manually. The experimental results show that Ina-BWR can increase Personal, Subject and Relation label accuracies. The best accuracy for four labels is obtained when Ina-BWR is combined with BoW method. \u00a9 2019",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Handling multi-label student complaints is one of interesting research topics. One of techniques used for handling multi-label student complaints is Bag of Word (BoW) method. In this research bigram word rule and preprocess are proposed to increase the accuracy of multi-label classification results. To show the effectiveness of the proposed method, data from Telkom University student data and additional relevant data by using hashtag are used as testing data. We develop Indonesian Bigram Word Rule for Multi-label Student Complaints (Ina-BWR) to identify multi-label student problems based on Bigram Word Rule. Ina-BWR consists of three processes such as preprocessing informal text, identifying complaint and object from text. Additional preprocessing techniques are conducted to formalize the text such as parsing a hashtag, correcting affixes word, correcting a conjunction word, parsing suffix people pronoun and correcting typo words. Indonesian bigram word rule is adopted from opinion identification rules with 3 additional corpuses (-)NN, (-)JJ and (-)VB to identify student complaints. To identify complaints, four label corpuses have been created manually. The experimental results show that Ina-BWR can increase Personal, Subject and Relation label accuracies. The best accuracy for four labels is obtained when Ina-BWR is combined with BoW method. \u00a9 2019"
        ]
    },
    {
        "judul":[
            "Implementation of role-based access control on OAuth 2.0 as authentication and authorization system"
        ],
        "penulis":"Sussi;Negara, Ridha Muldina;Triartono, Zehan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "As today\u2019s technology transition from monolithic towards microservices architecture, the authentication and authorization system also becomes a new concern because of the difference between monolithic and microservices pattern. Monolithic mostly uses role-based access control while microservices uses scope with OAuth 2.0. With this in mind, there is a need for a model that can integrate OAuth 2.0 with role-based access control. With role-based access control implemented on OAuth 2.0, we expect a simpler authorization process and a more secure authentication and authorization system for microservices backend architecture. This paper proposes a model to implement role-based access control on OAuth 2.0 using Laravel framework, we also test the performance of the system following by response time, data transferred and throughput. From the performance test, this approach has a good performance and can handle certain requests with simulated users even with limited resources. \u00a9 2019, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "As today\u2019s technology transition from monolithic towards microservices architecture, the authentication and authorization system also becomes a new concern because of the difference between monolithic and microservices pattern. Monolithic mostly uses role-based access control while microservices uses scope with OAuth 2.0. With this in mind, there is a need for a model that can integrate OAuth 2.0 with role-based access control. With role-based access control implemented on OAuth 2.0, we expect a simpler authorization process and a more secure authentication and authorization system for microservices backend architecture. This paper proposes a model to implement role-based access control on OAuth 2.0 using Laravel framework, we also test the performance of the system following by response time, data transferred and throughput. From the performance test, this approach has a good performance and can handle certain requests with simulated users even with limited resources. \u00a9 2019, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Hotspot asummption as a forest fire indicator in Kalimantan based on climate factor"
        ],
        "penulis":"Aflahah, Elania;Hidayati, Rini;Hidayat, Rahmat;Alfahmi, Furqon;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The occurance of forest fire indonesia especially in Kalimantan is a potential threat to sustainable development. The purpose of this research is a early warning system in forest fire in Kalimantan, by estimating the hotspot as indicators based on visibility and climate data. This research using F test, T test, Multiple Linear Regression analysis, Principle Component Analysis (PCA) and Principle Component Regression Analysis (PCR) Vvisibility, hotspot and temperature data have releated, meaning the very big effect with forest fire incident. Test result of T test and ANOVA P-Value less than 0.05, there is influence between independent variables in this visibility and climate factor against dependent variables in this is the number of hotspots. Relation of climate variables to 10 days forest fire in Central Kalimantan R2adjusted is 0.4699 with F calculate larger from F table is 160.0940. Relation of climate variables to dasarian forest fire in central kalimantan as early warning system has R2adjusted that is 0.4176 with f calculate larger from table F of 129.3551. Conclusion forest fires following monsoon character and being affected by el nino events, visibility has a closer and can be used as a indicator of forest fire and land intensity, hotspot in a relationship has a close connection with visibility and climate condition at the same decade period, used equations for early warning system for predicted fire genesis indicates with hotspot amount, compiled from climate condition 10 days. \u00a9 2019, Pusat Penelitian Lingkungan Hidup - Lembaga Penelitian dan Pengabdian Kepada Masyarakat Institut Pertanian Bogor (PPLH-LPPM IPB). All rights reserved.",
            "Sustainable Development Goals mapped to this documentLife on landGoal 15Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The occurance of forest fire indonesia especially in Kalimantan is a potential threat to sustainable development. The purpose of this research is a early warning system in forest fire in Kalimantan, by estimating the hotspot as indicators based on visibility and climate data. This research using F test, T test, Multiple Linear Regression analysis, Principle Component Analysis (PCA) and Principle Component Regression Analysis (PCR) Vvisibility, hotspot and temperature data have releated, meaning the very big effect with forest fire incident. Test result of T test and ANOVA P-Value less than 0.05, there is influence between independent variables in this visibility and climate factor against dependent variables in this is the number of hotspots. Relation of climate variables to 10 days forest fire in Central Kalimantan R2adjusted is 0.4699 with F calculate larger from F table is 160.0940. Relation of climate variables to dasarian forest fire in central kalimantan as early warning system has R2adjusted that is 0.4176 with f calculate larger from table F of 129.3551. Conclusion forest fires following monsoon character and being affected by el nino events, visibility has a closer and can be used as a indicator of forest fire and land intensity, hotspot in a relationship has a close connection with visibility and climate condition at the same decade period, used equations for early warning system for predicted fire genesis indicates with hotspot amount, compiled from climate condition 10 days. \u00a9 2019, Pusat Penelitian Lingkungan Hidup - Lembaga Penelitian dan Pengabdian Kepada Masyarakat Institut Pertanian Bogor (PPLH-LPPM IPB). All rights reserved."
        ]
    },
    {
        "judul":[
            "We are \u201cnot\u201d too (young\/old) to collaborate: Prominent key Barriers to intergenerational innovation"
        ],
        "penulis":"Nurhas, Irawan;Aditya, Bayu R.;Geisler, Stefan;Ojala, Arto;Pawlowski, Jan M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this study, we analyzed the barriers to technology-supported intergenerational innovation to understand better how young and old can collaborate towards global innovations. Researchers in different disciplines have already identified various barriers to intergenerational collaboration. However, barriers are changing depending on the context of collaboration, and difficulties still exist to support intergenerational innovation in global settings. Therefore, we investigated the barriers that emerge when people work with someone decades older or younger. The results of our study have shown what barriers are influenced by age, what barriers exist only for senior and younger adults. The study theoretically contributes to deepening the Information Systems (IS) community's understanding of the barriers to intergenerational innovation that need to be considered when developing systems for global innovation. \u00a9 Proceedings of the 23rd Pacific Asia Conference on Information Systems: Secure ICT Platform for the 4th Industrial Revolution, PACIS 2019.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this study, we analyzed the barriers to technology-supported intergenerational innovation to understand better how young and old can collaborate towards global innovations. Researchers in different disciplines have already identified various barriers to intergenerational collaboration. However, barriers are changing depending on the context of collaboration, and difficulties still exist to support intergenerational innovation in global settings. Therefore, we investigated the barriers that emerge when people work with someone decades older or younger. The results of our study have shown what barriers are influenced by age, what barriers exist only for senior and younger adults. The study theoretically contributes to deepening the Information Systems (IS) community's understanding of the barriers to intergenerational innovation that need to be considered when developing systems for global innovation. \u00a9 Proceedings of the 23rd Pacific Asia Conference on Information Systems: Secure ICT Platform for the 4th Industrial Revolution, PACIS 2019."
        ]
    },
    {
        "judul":[
            "Answer selection using Word Alignment based on Part of Speech Tagging in community question answering"
        ],
        "penulis":"Sutedi, Ade;Bijaksana, Moch. Arif;Romadhony, Ade;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper explain about answer selection using word alignment based on POS tagging in Community Question-Answering (CQA). This online community allowed the user to ask and reply related to the question problems which has no restrictions. This causes inappropriate comments with the question problems proposed before. To solve these problems, combining lexical and semantic features has been developed with result conclude that the approach more adequate for similarity task rather than question answering. According to the previous research, there is several problems that can be enhanced. First, vector representation counts exactly matched words, so it does not effective to cover other words that have relatedness between two pairing words. Second, noun overlap for similarity measure in pairing words can't define that the two words are similar. So, it must be define that the pairing POS tag is the same meaning or relatedness. In this study, unsupervised lexical and semantic similarity method employed with different approach from previous method in verbatim and contextual similarities. The data was taken from SemEval 2017 competition which focus on Question-Answer Similarity task. The experiment result for precision (Mean Average Precision) score shows the improvement from 0.674 to 0.6845, 1.03 % higher than previous research in CQA. This improvement comes from lexical similarity, which is not just from noun pattern but also taken from verb pattern. Furthermore, semantic similarity has an important role in determining which words that have same pattern and meaning to define relevancy between them. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper explain about answer selection using word alignment based on POS tagging in Community Question-Answering (CQA). This online community allowed the user to ask and reply related to the question problems which has no restrictions. This causes inappropriate comments with the question problems proposed before. To solve these problems, combining lexical and semantic features has been developed with result conclude that the approach more adequate for similarity task rather than question answering. According to the previous research, there is several problems that can be enhanced. First, vector representation counts exactly matched words, so it does not effective to cover other words that have relatedness between two pairing words. Second, noun overlap for similarity measure in pairing words can't define that the two words are similar. So, it must be define that the pairing POS tag is the same meaning or relatedness. In this study, unsupervised lexical and semantic similarity method employed with different approach from previous method in verbatim and contextual similarities. The data was taken from SemEval 2017 competition which focus on Question-Answer Similarity task. The experiment result for precision (Mean Average Precision) score shows the improvement from 0.674 to 0.6845, 1.03 % higher than previous research in CQA. This improvement comes from lexical similarity, which is not just from noun pattern but also taken from verb pattern. Furthermore, semantic similarity has an important role in determining which words that have same pattern and meaning to define relevancy between them. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Design of Foreign Currency Recognition Application using Scale Invariant Feature Transform (SIFT) Method based on Android (Case Study: Singapore Dollar)"
        ],
        "penulis":"Adhiguna, Mohammad Rizky;Irawan, Budhi;Prasasti, Anggunmeka Luhur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Money is the most commonly used means of payment by the public. But without denying fake money is widely circulated and there are still many people who are less accurate in recognizing the authenticity of the money. This will be bad for social life as we known that money is main payment that can use by everyone. For people with disabilities that lack of visual itself will be hard to know the identity from the money. With this problem in this research will be designed and implemented an Android based mobile application that can recognize currency with image. Applications designed using the Scale Invariant Feature Transform (SIFT) method that can provide information to users about their nominal and authenticity of the money using Indonesian. This application can help people who are less aware of information about genuine money and people with disabilities to find informations about authenticity of Foreign currency. With this application people with disabilities, also can tell the identity of the money itself with more accurate considering this app has implemented by SIFT method on feature extrachon but the process time will be longer because the SIFT method itself has a fairly complicated calculation process. From these complex calculations will also produce better accuracy. \u00a9 Medwell Journals, 2019",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Money is the most commonly used means of payment by the public. But without denying fake money is widely circulated and there are still many people who are less accurate in recognizing the authenticity of the money. This will be bad for social life as we known that money is main payment that can use by everyone. For people with disabilities that lack of visual itself will be hard to know the identity from the money. With this problem in this research will be designed and implemented an Android based mobile application that can recognize currency with image. Applications designed using the Scale Invariant Feature Transform (SIFT) method that can provide information to users about their nominal and authenticity of the money using Indonesian. This application can help people who are less aware of information about genuine money and people with disabilities to find informations about authenticity of Foreign currency. With this application people with disabilities, also can tell the identity of the money itself with more accurate considering this app has implemented by SIFT method on feature extrachon but the process time will be longer because the SIFT method itself has a fairly complicated calculation process. From these complex calculations will also produce better accuracy. \u00a9 Medwell Journals, 2019"
        ]
    },
    {
        "judul":[
            "QIM-based audio watermarking using polar-based singular value in DCT domain"
        ],
        "penulis":"Allwinnaldo;Budiman, Gelar;Novamizanti, Ledya;Alief, Revin Naufal;Ansori, Muhammad Rasyid Redha;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents an audio watermarking scheme that ensures the efficient of robustness-distortion ratio and a pleasing amount of capacity. Quantization Index Modulation (QIM) method synergism along with Discrete Wavelet Transform (DWT), Discrete Cosine Transform (DCT), Singular Value Decomposition (SVD), and Cartesian to Polar Transformation (CPT) to emphasize copyright protection for harmonical work of art. DWT synergism along with DCT, SVD, and CPT to emphasize copyright protection for harmonical work of art. The system establishes with DWT that divides the signal within a specific range of frequency, alter it to the frequency domain by DCT, partite with mathematical processing SVD, and transform the peculiar value of matrix-S to polar value using CPT, furthermore, QIM embed the watermark into the angular value from the CPT. The system performance is astonishing, tested using 4 different audio host signal and evaluated considers to desirable Bit Error Rate (BER) <0.025, Signal-to-Noise Ratio (SNR)>21dB, a great amount of data payload that is 525 bit per second, and the noise caused by watermark is inaudible. All of the experiments, trials, and results show that the designed audio watermarking system is robust and imperceptible. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents an audio watermarking scheme that ensures the efficient of robustness-distortion ratio and a pleasing amount of capacity. Quantization Index Modulation (QIM) method synergism along with Discrete Wavelet Transform (DWT), Discrete Cosine Transform (DCT), Singular Value Decomposition (SVD), and Cartesian to Polar Transformation (CPT) to emphasize copyright protection for harmonical work of art. DWT synergism along with DCT, SVD, and CPT to emphasize copyright protection for harmonical work of art. The system establishes with DWT that divides the signal within a specific range of frequency, alter it to the frequency domain by DCT, partite with mathematical processing SVD, and transform the peculiar value of matrix-S to polar value using CPT, furthermore, QIM embed the watermark into the angular value from the CPT. The system performance is astonishing, tested using 4 different audio host signal and evaluated considers to desirable Bit Error Rate (BER) <0.025, Signal-to-Noise Ratio (SNR)>21dB, a great amount of data payload that is 525 bit per second, and the noise caused by watermark is inaudible. All of the experiments, trials, and results show that the designed audio watermarking system is robust and imperceptible. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The mediating role of business strategies between management control systems package and firms stability: Evidence from SMEs in Malaysia"
        ],
        "penulis":"Haseeb, Muhammad;Lis, Marcin;Haouas, Ilham;Mihardjo, Leonardus W.W.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The aim of the current study was to ascertain the influence of a management control systems (MCS) package on a firm's sustainability with the help of mediating variables such as differentiation and cost leadership strategy in Malaysian small and medium enterprises (SMEs). Data were collected from managers working in Malaysian SMEs. A total of 384 questionnaires was finally used for analysis using SmartPLS 3.8.2. Area cluster sampling was used for data collection, and seven out of sixteen clusters were selected randomly. These included Selangor, Johor, Kuala Lumpur, Sabah, Penang, Sarawak, and Perak because these seven states cover 73.9% of total SMEs. Structural equation modeling (SEM) was used to test the hypotheses. Confirmatory factor analysis (CFA) was also used to examine the reliability and validity, and structural model assessment was used to test the relationship between variables. Findings revealed that an MCS package had a positive influence on a firm's sustainability, cost leadership, and differentiation strategy. Moreover, cost leadership and differentiation strategy have a significant and positive influence on a firm's sustainability. In addition, cost leadership strategies and differentiation strategies significantly mediate between the MCS package and a firm's sustainability. This research assesses the influence of the MCS package through cost leadership and differentiation strategy on a firm's sustainability of Malaysian SMEs. It helps top management to focus on the MCS package and business strategies in attaining a firm's long-term sustainability. Finally, research recommendations discuss that the present study helps future researchers and academicians. \u00a9 2019 by the authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aim of the current study was to ascertain the influence of a management control systems (MCS) package on a firm's sustainability with the help of mediating variables such as differentiation and cost leadership strategy in Malaysian small and medium enterprises (SMEs). Data were collected from managers working in Malaysian SMEs. A total of 384 questionnaires was finally used for analysis using SmartPLS 3.8.2. Area cluster sampling was used for data collection, and seven out of sixteen clusters were selected randomly. These included Selangor, Johor, Kuala Lumpur, Sabah, Penang, Sarawak, and Perak because these seven states cover 73.9% of total SMEs. Structural equation modeling (SEM) was used to test the hypotheses. Confirmatory factor analysis (CFA) was also used to examine the reliability and validity, and structural model assessment was used to test the relationship between variables. Findings revealed that an MCS package had a positive influence on a firm's sustainability, cost leadership, and differentiation strategy. Moreover, cost leadership and differentiation strategy have a significant and positive influence on a firm's sustainability. In addition, cost leadership strategies and differentiation strategies significantly mediate between the MCS package and a firm's sustainability. This research assesses the influence of the MCS package through cost leadership and differentiation strategy on a firm's sustainability of Malaysian SMEs. It helps top management to focus on the MCS package and business strategies in attaining a firm's long-term sustainability. Finally, research recommendations discuss that the present study helps future researchers and academicians. \u00a9 2019 by the authors."
        ]
    },
    {
        "judul":[
            "Analysis of the Markov Chain Approach to Detect Blood Sugar Level"
        ],
        "penulis":"Lubis, Arif Ridho;Prayudani, Santi;Lubis, Muharman;Al-Khowarizmi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Diabetes mellitus is a health disorder in which the level of sugar in a person's blood is getting higher due to the lack of insulin or insulin receptors in the body do not properly function. Indonesia ranks the 4th largest in the number of Diabetes Mellitus sufferers in the world. Many people initially did not know that they had diabetes mellitus and only found out that they had had diabetes after experiencing some complications in some organs of the body. To predict blood sugar levels, this study tries to use one method of probability approach, i.e. Markov chain. It is a calculation technique that is commonly applied in modeling many conditions so that this technique is applied to help predict changes that might occur in the future. The results of the analysis applying this method could predict blood sugar levels, which then the results can be used as material or basis for creating a system that is able to help people affected by diabetes mellitus in predicting the high and the low of blood sugar levels. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Diabetes mellitus is a health disorder in which the level of sugar in a person's blood is getting higher due to the lack of insulin or insulin receptors in the body do not properly function. Indonesia ranks the 4th largest in the number of Diabetes Mellitus sufferers in the world. Many people initially did not know that they had diabetes mellitus and only found out that they had had diabetes after experiencing some complications in some organs of the body. To predict blood sugar levels, this study tries to use one method of probability approach, i.e. Markov chain. It is a calculation technique that is commonly applied in modeling many conditions so that this technique is applied to help predict changes that might occur in the future. The results of the analysis applying this method could predict blood sugar levels, which then the results can be used as material or basis for creating a system that is able to help people affected by diabetes mellitus in predicting the high and the low of blood sugar levels. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The ClearPath Method for Care Pathway Process Mining and Simulation"
        ],
        "penulis":"Johnson, Owen A.;Ba Dhafari, Thamer;Kurniati, Angelina;Fox, Frank;Rojas, Eric;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Process mining of routine electronic healthcare records can help inform the management of care pathways. Combining process mining with simulation creates a rich set of tools for care pathway improvement. Healthcare process mining creates insight into the reality of patients\u2019 journeys through care pathways while healthcare process simulation can help communicate those insights and explore \u201cwhat if\u201d options for improvement. In this paper, we outline the ClearPath method, which extends the PM2process mining method with a process simulation approach that address issues of poor quality and missing data and supports rich stakeholder engagement. We review the literature that informed the development of ClearPath and illustrate the method with case studies of pathways for alcohol-related illness, giant-cell arteritis and functional neurological symptoms. We designed an evidence template that we use to underpin the fidelity of our simulation models by tracing each model element back to literature sources, data and process mining outputs and insights from qualitative research. Our approach may be of benefit to others using process-oriented data science to improve healthcare.                          \u00a9 2019, Springer Nature Switzerland AG.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Process mining of routine electronic healthcare records can help inform the management of care pathways. Combining process mining with simulation creates a rich set of tools for care pathway improvement. Healthcare process mining creates insight into the reality of patients\u2019 journeys through care pathways while healthcare process simulation can help communicate those insights and explore \u201cwhat if\u201d options for improvement. In this paper, we outline the ClearPath method, which extends the PM2process mining method with a process simulation approach that address issues of poor quality and missing data and supports rich stakeholder engagement. We review the literature that informed the development of ClearPath and illustrate the method with case studies of pathways for alcohol-related illness, giant-cell arteritis and functional neurological symptoms. We designed an evidence template that we use to underpin the fidelity of our simulation models by tracing each model element back to literature sources, data and process mining outputs and insights from qualitative research. Our approach may be of benefit to others using process-oriented data science to improve healthcare.                          \u00a9 2019, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Description calculation of production costs and cost of good sold for the cattle ranchers in North Bandung regency, Indonesia"
        ],
        "penulis":"Barus, Irene Sukma Lestari;Arsalan, Syakieb;Edison, Acep;Sukmawati, Fitri;Silviana;Putri, Ratna Komala;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research was conducted based on the complaints from the cattle ranchers about the income from selling their livestock products. They often suffer livestock farming losses. The selling price they received from the parties of supplier of cow\u2019s milk where they distribute their products are various. The selling price for milk is around IDR 4,600 to IDR 5,000 per liter depending on the quality of milk. Likewise, for beef, the selling price is around IDR 80,000 to IDR 120,000 per kilogram depending on the period of selling. The selling price they received is considered unable to cover the costs for manufacturing process so that the cattle ranchers felt damaged. Therefore, this research gave a contribution in form of knowledge for the cattle ranchers about determining and calculating the cost of the product, and establishing the selling price by using traditional or conventional method and activity based costing method. In traditional method, all costs were charged against the product, including production costs that were not caused by the product. Meanwhile, the activity based costing method explained about the classification of costs, driver, and the cost driver of the product. Hence, this research suggested the cattle ranchers to adopt the activity based costing method since the ABC (activity-based costing) method is more accurate in determining the classification of costs. In addition, this research also gave a contribution for appropriate selling price for milk and beef. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research was conducted based on the complaints from the cattle ranchers about the income from selling their livestock products. They often suffer livestock farming losses. The selling price they received from the parties of supplier of cow\u2019s milk where they distribute their products are various. The selling price for milk is around IDR 4,600 to IDR 5,000 per liter depending on the quality of milk. Likewise, for beef, the selling price is around IDR 80,000 to IDR 120,000 per kilogram depending on the period of selling. The selling price they received is considered unable to cover the costs for manufacturing process so that the cattle ranchers felt damaged. Therefore, this research gave a contribution in form of knowledge for the cattle ranchers about determining and calculating the cost of the product, and establishing the selling price by using traditional or conventional method and activity based costing method. In traditional method, all costs were charged against the product, including production costs that were not caused by the product. Meanwhile, the activity based costing method explained about the classification of costs, driver, and the cost driver of the product. Hence, this research suggested the cattle ranchers to adopt the activity based costing method since the ABC (activity-based costing) method is more accurate in determining the classification of costs. In addition, this research also gave a contribution for appropriate selling price for milk and beef. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "DBMS-KU interpolation for WMT19 news translation task"
        ],
        "penulis":"Budiwati, Sari Dewi;Siagian, Al Hafiz Akbar Maulana;Fatyanosa, Tirana Noor;Aritsugi, Masayoshi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents the participation of DBMS-KU Interpolation system in WMT19 shared task, namely, Kazakh-English language pair. We examine the use of interpolation method using a different language model order. Our Interpolation system combines a direct translation with Russian as a pivot language. We use 3-gram and 5-gram language model orders to perform the language translation in this work. To reduce noise in the pivot translation process, we prune the phrase table of source-pivot and pivot-target. Our experimental results show that our Interpolation system outperforms the Baseline in terms of BLEU-cased score by +0.5 and +0.1 points in Kazakh-English and English-Kazakh, respectively. In particular, using the 5-gram language model order in our system could obtain better BLEU-cased score than utilizing the 3-gram one. Interestingly, we found that by employing the Interpolation system could reduce the perplexity score of English-Kazakh when using 3-gram language model order. \u00a9 2019 Association for Computational Linguistics"
        ],
        "abstrak":[
            "This paper presents the participation of DBMS-KU Interpolation system in WMT19 shared task, namely, Kazakh-English language pair. We examine the use of interpolation method using a different language model order. Our Interpolation system combines a direct translation with Russian as a pivot language. We use 3-gram and 5-gram language model orders to perform the language translation in this work. To reduce noise in the pivot translation process, we prune the phrase table of source-pivot and pivot-target. Our experimental results show that our Interpolation system outperforms the Baseline in terms of BLEU-cased score by +0.5 and +0.1 points in Kazakh-English and English-Kazakh, respectively. In particular, using the 5-gram language model order in our system could obtain better BLEU-cased score than utilizing the 3-gram one. Interestingly, we found that by employing the Interpolation system could reduce the perplexity score of English-Kazakh when using 3-gram language model order. \u00a9 2019 Association for Computational Linguistics"
        ]
    },
    {
        "judul":[
            "Financial network approach for modeling about company bankruptcy"
        ],
        "penulis":"Permana, Jorgie Bartelsi;Rusmawati, Yanti;Arzaki, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We construct a financial network that models the complex system representing the bankruptcy effect of a company. In particular, we study the influence of PT Sariwangi AEA and Indorub bankruptcy, which affects at least three banks and four other companies directly. We present the interconnectivity of the banks and other corporations regarding the ownerships and liabilities using graphs. From these resulting graphs, we use techniques in network science to provide several important measurements and statistics, such as the centrality of each network. We successfully constructed a financial network surrounding PT Sariwangi AEA and Indorub. Centrality measures obtained from the graph shows that Rabobank, BCA, Rabobank UA, ICBC, and Interbank are the most important and influential entities in the financial network. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We construct a financial network that models the complex system representing the bankruptcy effect of a company. In particular, we study the influence of PT Sariwangi AEA and Indorub bankruptcy, which affects at least three banks and four other companies directly. We present the interconnectivity of the banks and other corporations regarding the ownerships and liabilities using graphs. From these resulting graphs, we use techniques in network science to provide several important measurements and statistics, such as the centrality of each network. We successfully constructed a financial network surrounding PT Sariwangi AEA and Indorub. Centrality measures obtained from the graph shows that Rabobank, BCA, Rabobank UA, ICBC, and Interbank are the most important and influential entities in the financial network. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Cholesterol level measurement through Iris image using gray level co-occurrence matrix and linear regression"
        ],
        "penulis":"Raharjo, Jangkung;Novamizanti, Ledya;Ramatryana, I. Nyoman Apraz;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cholesterol is a waxy fat compound that is mostly produced by the liver and the other part is obtained from food. The ideal cholesterol level in the human body is <200. High cholesterol can increase the risk of getting serious diseases such as strokes and heart attacks. Checking cholesterol levels through checking blood sugar requires the patient to undergo fasting for 10-12 hours first and processing the results of the examination also requires not a short time. Because of the seriousness of the disease that can be caused, an early examination is needed and it is also practical to determine the level of excess cholesterol in the human body. Iris has specific advantages which can record all organ conditions, body construction and psychological conditions. Therefore, Iridology as a science based on the arrangement of the iris can be an alternative for medical analysis. In this study, the author designed a system in the matrix simulator which is expected to be able to detect excess cholesterol levels with input in the form of iris images and then through the pre-processing stage then extracted features with the Gray Level Co-Occurrence Matrix method and classified using the Linear Regression method. The result from the modeling process can inform about cholesterol level. These processes make early detection of human body cholesterol level becomes easier. The cholesterol data level is classified into: normal cholesterol, at risk of cholesterol and high cholesterol. Each class was represented by 30 images, and each of it divided into two data types, 20 images used as training data and the remaining as testing data. The optimum result can be obtained on 45 degree angle, two pixels gap and correlation feture, which give 88.52% accuracy with 6.9595 standard deviation and 0.0365 seconds computation time for each image. \u00a9 2006-2019 Asian Research Publishing Network (ARPN). All rights reserved.",
            "OHH2NView detailsExpand Substance hydroxylamineCH3CH3CH3HOCH3CH3HHHHHView detailsExpand Substance cholesterol",
            "Powered by",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cholesterol is a waxy fat compound that is mostly produced by the liver and the other part is obtained from food. The ideal cholesterol level in the human body is <200. High cholesterol can increase the risk of getting serious diseases such as strokes and heart attacks. Checking cholesterol levels through checking blood sugar requires the patient to undergo fasting for 10-12 hours first and processing the results of the examination also requires not a short time. Because of the seriousness of the disease that can be caused, an early examination is needed and it is also practical to determine the level of excess cholesterol in the human body. Iris has specific advantages which can record all organ conditions, body construction and psychological conditions. Therefore, Iridology as a science based on the arrangement of the iris can be an alternative for medical analysis. In this study, the author designed a system in the matrix simulator which is expected to be able to detect excess cholesterol levels with input in the form of iris images and then through the pre-processing stage then extracted features with the Gray Level Co-Occurrence Matrix method and classified using the Linear Regression method. The result from the modeling process can inform about cholesterol level. These processes make early detection of human body cholesterol level becomes easier. The cholesterol data level is classified into: normal cholesterol, at risk of cholesterol and high cholesterol. Each class was represented by 30 images, and each of it divided into two data types, 20 images used as training data and the remaining as testing data. The optimum result can be obtained on 45 degree angle, two pixels gap and correlation feture, which give 88.52% accuracy with 6.9595 standard deviation and 0.0365 seconds computation time for each image. \u00a9 2006-2019 Asian Research Publishing Network (ARPN). All rights reserved."
        ]
    },
    {
        "judul":[
            "Analyzing tourism mobile applications perceived quality using sentiment analysis and topic modeling"
        ],
        "penulis":"Masrury, Riefvan Achmad;Fannisa;Alamsyah, Andry;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Mobile application is one of the most important information platforms for international tourists. Millions of tourists use mobile applications to find information and make transactions. Two popular Online Travel Agent (OTA) mobile applications for travel-related activities providers are Traveloka and Tiket.com. These applications certainly must meet travelers' needs to achieve satisfaction. Such satisfaction related to application Mobile Application Service Quality (MappSql) dimensions can be traced from thousands of their comments on the Google Play Store. From a set of reviews, information about the perception of mobile application quality can be obtained. Knowledge on user perceptions is very useful for company's consideration in creating effective business and app features to increase users' satisfaction. We propose Text Mining models to bring up hidden information regarding users' verdict. The selected text analysis methods for this research are Sentiment Analysis and Topic Modeling. We find that positive or negative sentiments towards MappSql dimensions of online travel agent applications qualities can be revealed using sentiment analysis method. Topic Modeling method is used to bring up groups of important words of topics related to each mobile application service quality dimensions. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mobile application is one of the most important information platforms for international tourists. Millions of tourists use mobile applications to find information and make transactions. Two popular Online Travel Agent (OTA) mobile applications for travel-related activities providers are Traveloka and Tiket.com. These applications certainly must meet travelers' needs to achieve satisfaction. Such satisfaction related to application Mobile Application Service Quality (MappSql) dimensions can be traced from thousands of their comments on the Google Play Store. From a set of reviews, information about the perception of mobile application quality can be obtained. Knowledge on user perceptions is very useful for company's consideration in creating effective business and app features to increase users' satisfaction. We propose Text Mining models to bring up hidden information regarding users' verdict. The selected text analysis methods for this research are Sentiment Analysis and Topic Modeling. We find that positive or negative sentiments towards MappSql dimensions of online travel agent applications qualities can be revealed using sentiment analysis method. Topic Modeling method is used to bring up groups of important words of topics related to each mobile application service quality dimensions. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Generalized linear model multivariate poisson with artificial marginal (GLM-MPAM): Application of vehicle insurance"
        ],
        "penulis":"Jamilatuzzahro;Caraka, Rezzy Eko;Aprinaldy, Dedi;Mahadi, Asma;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "At vehicle insurance companies, the determination of the appropriate pure premium will make the business run well. In this study, we were modeling claims frequency data by considering the characteristics of policyholder such as policyholder's age, marital status, sex, car engine capacity, and age. The data used in this study is a non-motor vehicle and non-truck motor vehicle insurance data, which filed claims during 2013 in a general insurance company. Explaining the significance or value of the research. We are using Generalized Linear Model Multivariate Poisson with Artificial Marginal (GLM-MPAM) to estimate model parameters. The parameter values of this model are estimated using the Maximum Likelihood Estimation method. Furthermore, the estimation result of the parameter can be alternative in the calculation of the pure premium in the next period. \u00a9 2019 Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "At vehicle insurance companies, the determination of the appropriate pure premium will make the business run well. In this study, we were modeling claims frequency data by considering the characteristics of policyholder such as policyholder's age, marital status, sex, car engine capacity, and age. The data used in this study is a non-motor vehicle and non-truck motor vehicle insurance data, which filed claims during 2013 in a general insurance company. Explaining the significance or value of the research. We are using Generalized Linear Model Multivariate Poisson with Artificial Marginal (GLM-MPAM) to estimate model parameters. The parameter values of this model are estimated using the Maximum Likelihood Estimation method. Furthermore, the estimation result of the parameter can be alternative in the calculation of the pure premium in the next period. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Feasibility analysis of Rumah Tempe Zanada establishment in Bandung using net present value, internal rate of return, and payback period"
        ],
        "penulis":"Zativita F.I.;Chumaidiyah E.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Rumah Tempe Indonesia was established based on the desire of KOPTI committee (Indonesian Tempe Tofu Producers Cooperative), Indonesian Tempe Forum, and Mercy Corps that want some changes in production process that can be used as references of ideal production place of tempe producer which prioritizes hygienic production process. As a pioneer of the establishment of a tempe hygienic production house, Rumah Tempe Indonesia opened its new business into Rumah Tempe Zanada which was established in Bandung. In establishing this business, a research study was conducted to ensure the is feasible. Using literature study and interview as the data collecting method, a feasibility study is conducted on the market, technical, and financial aspects of the establishment of Rumah Tempe Zanada for 5 years as the calculating period. The business is concluded to be feasible as in the financial aspect with the total of project cost at value Rp 765,427,036 by calculating the IRR which is 19% using MARR is equal to 10.25%, and estimated Payback Period from Tempe Zanada Home is 4 years, 6 months and 17 days. Meanwhile, the result of the NPV amount of this investment is Rp 260,380,763. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rumah Tempe Indonesia was established based on the desire of KOPTI committee (Indonesian Tempe Tofu Producers Cooperative), Indonesian Tempe Forum, and Mercy Corps that want some changes in production process that can be used as references of ideal production place of tempe producer which prioritizes hygienic production process. As a pioneer of the establishment of a tempe hygienic production house, Rumah Tempe Indonesia opened its new business into Rumah Tempe Zanada which was established in Bandung. In establishing this business, a research study was conducted to ensure the is feasible. Using literature study and interview as the data collecting method, a feasibility study is conducted on the market, technical, and financial aspects of the establishment of Rumah Tempe Zanada for 5 years as the calculating period. The business is concluded to be feasible as in the financial aspect with the total of project cost at value Rp 765,427,036 by calculating the IRR which is 19% using MARR is equal to 10.25%, and estimated Payback Period from Tempe Zanada Home is 4 years, 6 months and 17 days. Meanwhile, the result of the NPV amount of this investment is Rp 260,380,763. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Missing data problem in predictive analytics"
        ],
        "penulis":"Nugroho, Heru;Surendro, Kridanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A revolution in computational methods and statistics to process and analyse data into insight and knowledge is along with the growth of data. The paradigm of data analytic is changed from explicit to implicit raises the way to extract knowledge from data through a prospective approach to determine the value of new observations based on the structure of the relationship between input and output (predictive analytics). In the cycle of predictive analytics, data preparation is a very important stage. The main challenge faced is that raw data cannot be directly used for analysis and related to the quality of the data. Completeness is arising related to data quality. Missing data is one that often causes data to become incomplete. As a result, predictive analytics generated from these data becomes inaccurate. In this paper, the issues related to the missing data in predictive analytics will be discussed through a literature study from related research. Also, the challenges and direction that might occur in the predictive analytics domain with problems related to missing data will be presented. \u00a9 2019 Association for Computing Machinery.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A revolution in computational methods and statistics to process and analyse data into insight and knowledge is along with the growth of data. The paradigm of data analytic is changed from explicit to implicit raises the way to extract knowledge from data through a prospective approach to determine the value of new observations based on the structure of the relationship between input and output (predictive analytics). In the cycle of predictive analytics, data preparation is a very important stage. The main challenge faced is that raw data cannot be directly used for analysis and related to the quality of the data. Completeness is arising related to data quality. Missing data is one that often causes data to become incomplete. As a result, predictive analytics generated from these data becomes inaccurate. In this paper, the issues related to the missing data in predictive analytics will be discussed through a literature study from related research. Also, the challenges and direction that might occur in the predictive analytics domain with problems related to missing data will be presented. \u00a9 2019 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Cluster model study of the Indonesian defense industry towards encouraging industry independence"
        ],
        "penulis":"Hartati, Sri;Muhamad, Ade;Firmialy, Sita Deliyana;Tasrif, Muhamad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of this research is to find out how the defense industry and stakeholders are involved in developing defense industry clusters via comparative qualitative research methods. The results of the research show that the defense industry sector has 4 cluster stages. In conclusion, in the medium term, increasing industrial competitiveness is carried out by building and developing priority industry clusters while in the long run, it is more focused on integrating cluster approaches with efforts to manage demand (management demand) and build core competencies in each cluster. \u00a9 2019, Universidad del Zulia. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this research is to find out how the defense industry and stakeholders are involved in developing defense industry clusters via comparative qualitative research methods. The results of the research show that the defense industry sector has 4 cluster stages. In conclusion, in the medium term, increasing industrial competitiveness is carried out by building and developing priority industry clusters while in the long run, it is more focused on integrating cluster approaches with efforts to manage demand (management demand) and build core competencies in each cluster. \u00a9 2019, Universidad del Zulia. All rights reserved."
        ]
    },
    {
        "judul":[
            "Purchase intention determinants of halal food in secular countries"
        ],
        "penulis":"Pradana, Mahir;Syarifuddin, Syarifuddin;Hafid, Haeruddin;Gilang, Alini;Diandri, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to determine the effect of subjective norm, halal awareness, and behavioural control on purchase intention in halal food products for Muslim students in non-Islamic countries. This research is a survey research using a questionnaire as an instrument, distributed to respondents all over Europe. The population used in this study were Muslim students. 215 respondents used the purposive sampling method, which is a sample selection technique in which an individual chooses a sample based on a personal assessment of some appropriate characteristics of the sample members. The analysis technique used is multiple regression analysis with the theory of planned behaviour. The results of the study found that perceived behavioural control is not an influential predictor on purchase intention. This finding is somewhat contrary to the existing findings which perceived behavioural control as an important factor in influencing consumer to purchase halal food. \u00a9 ExcelingTech Pub, UK.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to determine the effect of subjective norm, halal awareness, and behavioural control on purchase intention in halal food products for Muslim students in non-Islamic countries. This research is a survey research using a questionnaire as an instrument, distributed to respondents all over Europe. The population used in this study were Muslim students. 215 respondents used the purposive sampling method, which is a sample selection technique in which an individual chooses a sample based on a personal assessment of some appropriate characteristics of the sample members. The analysis technique used is multiple regression analysis with the theory of planned behaviour. The results of the study found that perceived behavioural control is not an influential predictor on purchase intention. This finding is somewhat contrary to the existing findings which perceived behavioural control as an important factor in influencing consumer to purchase halal food. \u00a9 ExcelingTech Pub, UK."
        ]
    },
    {
        "judul":[
            "The influence of digital leadership on innovation management based on dynamic capability: Market orientation as a moderator"
        ],
        "penulis":"Mihardjo, Leonardus W. Wasono;Sasmoko;Alamsyah, Firdaus;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Due to market changes in the digital era, we argue that innovation based on dynamic capability is accelerated when aligned with market orientation. Digital leadership will significantly enable sensing market changes, seizing opportunities, and reconfiguring organizations. Previous studies on digital leadership, dynamic capability, and innovation management focus mainly on constructs, benefits, and implications. However, a study on the role of digital leadership based on dynamic capability in fostering innovation and the impact of market orientation have not been thoroughly explored, which is the aim of this study, taking market orientation as a moderating variable. Employing a quantitative methodology, data were collected through online questionnaires, distributed through email and messaging applications to a purposive sample of 88 senior managers of Indonesian telecommunication firms. The results reveal that digital leadership based on dynamic capability impacts directly and indirectly on developing innovation. Market orientation also plays an important role in accelerating innovation. Due to limitations in terms of research model, sample size, and time, further research using larger samples in other industries and countries should be undertaken. \u00a9 2019 by the authors; licensee Growing Science, Canada.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Due to market changes in the digital era, we argue that innovation based on dynamic capability is accelerated when aligned with market orientation. Digital leadership will significantly enable sensing market changes, seizing opportunities, and reconfiguring organizations. Previous studies on digital leadership, dynamic capability, and innovation management focus mainly on constructs, benefits, and implications. However, a study on the role of digital leadership based on dynamic capability in fostering innovation and the impact of market orientation have not been thoroughly explored, which is the aim of this study, taking market orientation as a moderating variable. Employing a quantitative methodology, data were collected through online questionnaires, distributed through email and messaging applications to a purposive sample of 88 senior managers of Indonesian telecommunication firms. The results reveal that digital leadership based on dynamic capability impacts directly and indirectly on developing innovation. Market orientation also plays an important role in accelerating innovation. Due to limitations in terms of research model, sample size, and time, further research using larger samples in other industries and countries should be undertaken. \u00a9 2019 by the authors; licensee Growing Science, Canada."
        ]
    },
    {
        "judul":[
            "Air pollution distribution in Telkom University: Spatial interpolation map"
        ],
        "penulis":"Oktaviani I.D.;Erfianto B.;Rakhmatsyah A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Currently, air quality information in a region becomes an important thing to know. Some efforts have been conducted to show air quality in certain region. One of the efforts that has been done is information regarding air quality in several big cities in Indonesia which can be seen in the official website of the Ministry of Environment and Forestry that have several weaknesses. One of the problems to be overcome in this research is visualization of air quality data that is monitored at one point only in which that point is the placement location of air quality monitoring station. Because of that, we need an application that can display a map of air pollution distribution using the spatial interpolation method. The solution offered is the depiction of air quality by using heatmap on the map. The method used to produce heatmap with smooth result is natural cubic spline interpolation method. The production of heatmap uses API which is provided by Google Maps. The final result obtained is the map view with the coloration in the form of color gradation in accordance with the air quality value that is obtained. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Currently, air quality information in a region becomes an important thing to know. Some efforts have been conducted to show air quality in certain region. One of the efforts that has been done is information regarding air quality in several big cities in Indonesia which can be seen in the official website of the Ministry of Environment and Forestry that have several weaknesses. One of the problems to be overcome in this research is visualization of air quality data that is monitored at one point only in which that point is the placement location of air quality monitoring station. Because of that, we need an application that can display a map of air pollution distribution using the spatial interpolation method. The solution offered is the depiction of air quality by using heatmap on the map. The method used to produce heatmap with smooth result is natural cubic spline interpolation method. The production of heatmap uses API which is provided by Google Maps. The final result obtained is the map view with the coloration in the form of color gradation in accordance with the air quality value that is obtained. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Investigation Reinforcement Learning Method for R-Wave Detection on Electrocardiogram Signal"
        ],
        "penulis":"Insani, Asep;Jatmiko, Wisnu;Sugiarto, Anto Tri;Jati, Grafika;Wibowo, Suryo Adhi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One of the essential things in recording electrocardiography (ECG) signals is R-wave detection. R-wave is a main component in the QRS wave, where it used for the diagnosis of heart rhythm irregularities and to calculate heart rate variability. On the other hand, Reinforcement Learning (RL) method has been proved that gives an excellent performance for games, network and stock market prediction. Based on this fact, in this paper, we want to investigate the RL for R-wave detection on the ECG signal. For the detection, the lower frequency is removed then we calculate the candidate of the peak, initialize Q-State-Action (QSA) table, peak detection, calculate reward and update the QSA table, respectively. Based on the experiment using the MIT-BIH dataset, the best accuracy of the proposed method is 86.8%, which calculated from alpha and gamma parameters are 0.1 and 0.9, respectively. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the essential things in recording electrocardiography (ECG) signals is R-wave detection. R-wave is a main component in the QRS wave, where it used for the diagnosis of heart rhythm irregularities and to calculate heart rate variability. On the other hand, Reinforcement Learning (RL) method has been proved that gives an excellent performance for games, network and stock market prediction. Based on this fact, in this paper, we want to investigate the RL for R-wave detection on the ECG signal. For the detection, the lower frequency is removed then we calculate the candidate of the peak, initialize Q-State-Action (QSA) table, peak detection, calculate reward and update the QSA table, respectively. Based on the experiment using the MIT-BIH dataset, the best accuracy of the proposed method is 86.8%, which calculated from alpha and gamma parameters are 0.1 and 0.9, respectively. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Vocabulary Based Summarization of Graph (VoG) on the Web Graph"
        ],
        "penulis":"Sa'adah, Siti;Kemas, Rahmat S.W.;Hartomo, Satrio Adityo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Increasing data of the web graph make it difficult to identify the data structure and get the information from that large graph. To identify the structure and get the information, some method needed to summarize the large graph into smaller subgraphs, so data structure identification can be conducted on the subgraph. This will make structure identification easier. Vocabulary based Summarization of Graph (VoG) is a method that can be used to summarize the large graph and identify the subgraph structure. In the process of structure identification, a maximum number of node in GCC (k) affects the generated subgraph. More and more k generates less of subgraph with clique and star structures but generates more subgraphs with chain structures. The k also affects the execution time of VoG. More and more k make the execution time of VoG faster. From generated and identified subgraph structure, information that can be obtained is clique subgraph represent there is a user network that polls on a question link and star subgraph represent there is one user contribute an answer on some question link on quora.com. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Increasing data of the web graph make it difficult to identify the data structure and get the information from that large graph. To identify the structure and get the information, some method needed to summarize the large graph into smaller subgraphs, so data structure identification can be conducted on the subgraph. This will make structure identification easier. Vocabulary based Summarization of Graph (VoG) is a method that can be used to summarize the large graph and identify the subgraph structure. In the process of structure identification, a maximum number of node in GCC (k) affects the generated subgraph. More and more k generates less of subgraph with clique and star structures but generates more subgraphs with chain structures. The k also affects the execution time of VoG. More and more k make the execution time of VoG faster. From generated and identified subgraph structure, information that can be obtained is clique subgraph represent there is a user network that polls on a question link and star subgraph represent there is one user contribute an answer on some question link on quora.com. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Temporal learning analytics based on triple-factor approach using self-organizing map"
        ],
        "penulis":"Laksitowening, Kusuma Ayu;Denny;Hasibuan, Zainal A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "E-learning personalization aims to deliver learning activities and materials that suits to learners' needs. Therefore, the system must have the ability to analyze the profile and characteristics of each individual learner. Characteristics of learners, among others, can be identified from their behavior in using e-learning. Their most frequent learning resource accessed, their participation on discussions, and their assessment result are some of the variables from the activity logs that can describe their learning patterns. On the other side, learners' behavior may change over time. This research aims to capture and analyze the dynamic learning pattern throughout the semester. The learning analytics are conducted using temporal clustering approach to identify the learning style, motivation, and knowledge abilities. This research performs two-level clustering analysis to acquire learning patterns from activity logs from Moodle Learning Management System using Self-Organizing Map (SOM) and k-Means. SOM enables visualization high dimensional data by projection to lower dimensions. The proto-clusters of SOM are then clustered using k-Means. The temporal clustering results show that the learning patterns of learners are changing over time. \u00a9 2019 International Center for Scientific Research and Studies.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "E-learning personalization aims to deliver learning activities and materials that suits to learners' needs. Therefore, the system must have the ability to analyze the profile and characteristics of each individual learner. Characteristics of learners, among others, can be identified from their behavior in using e-learning. Their most frequent learning resource accessed, their participation on discussions, and their assessment result are some of the variables from the activity logs that can describe their learning patterns. On the other side, learners' behavior may change over time. This research aims to capture and analyze the dynamic learning pattern throughout the semester. The learning analytics are conducted using temporal clustering approach to identify the learning style, motivation, and knowledge abilities. This research performs two-level clustering analysis to acquire learning patterns from activity logs from Moodle Learning Management System using Self-Organizing Map (SOM) and k-Means. SOM enables visualization high dimensional data by projection to lower dimensions. The proto-clusters of SOM are then clustered using k-Means. The temporal clustering results show that the learning patterns of learners are changing over time. \u00a9 2019 International Center for Scientific Research and Studies."
        ]
    },
    {
        "judul":[
            "Ciselexia: Computer-based method for improving self-awareness in children with dyslexia"
        ],
        "penulis":"Rahmawati, Aulia;Kaburuan, Emil Robert;Arifianto, Anditya;Juniati, Nahda Kurnia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Dyslexia has a lack of ability which causes other disturbances to social-emotional development. Based on an interview with the Chair of the Indonesian Dyslexia Association, increasing self-awareness is one form of dyslexia therapy to reduce that problem. Therefore there is a need for increasing self-awareness to solve that problem, whereas such technology the closest has not been fit with dyslexic children need. Then this study tries to focus on designed and developed CISELexia (Computer-Based Method for Improving Self-Awareness in Children with Dyslexia) technology using a gamification approach. It aims to help dyslexic children improve their competencies by increasing their self-awareness. Based on the implementation results CISELexia can increase the child's self-awareness state according to the rubric questionnaire given for about 10%. \u00a9 2019 ASTES Publishers. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Dyslexia has a lack of ability which causes other disturbances to social-emotional development. Based on an interview with the Chair of the Indonesian Dyslexia Association, increasing self-awareness is one form of dyslexia therapy to reduce that problem. Therefore there is a need for increasing self-awareness to solve that problem, whereas such technology the closest has not been fit with dyslexic children need. Then this study tries to focus on designed and developed CISELexia (Computer-Based Method for Improving Self-Awareness in Children with Dyslexia) technology using a gamification approach. It aims to help dyslexic children improve their competencies by increasing their self-awareness. Based on the implementation results CISELexia can increase the child's self-awareness state according to the rubric questionnaire given for about 10%. \u00a9 2019 ASTES Publishers. All rights reserved."
        ]
    },
    {
        "judul":[
            "Implementation of Object Tracking Augmented Reality Markerless using FAST Corner Detection on User Defined-Extended Target Tracking in Multivarious Intensities"
        ],
        "penulis":"Nurhadi;Saparudin;Adam N.;Purnamasari D.;Fachruddin;Ibrahim, Ali;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents a FAST Corner Detection object scanning to improve SLAM technique, which is SLAM, has a weakness in extracting features in the real-world object. The use of User Defined Target and Extended Tracking are for making this work more convenient and reliable. We can trace the object even though the object does not exist, so this improves the function of markerless itself. The use of Raycast is for the make labeling the objects or features in the scanned object. In this research, we executed multivarious intensity to test the FAST Corner Detection to increase function in real world feature extraction and prove it better than SLAM. Then, we got the result where is a brighter condition will get faster recognition. The best environments for augmentation are in the range of 80-190, they took in less than 1 second. On the contrary, the intensity outside of the range such as \u226450 or \u2265200, has a deficiency of augmentation. The range of \u226450, there was no augmentation cause of low intensity. For the range of \u2265200, we haven't made measurements as we don't have the resources yet, but we hypothesize that the object would be corrupt or we may call it was overexposure cause of the intensity is too high. So, this could also lead to augmentation will not occur. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents a FAST Corner Detection object scanning to improve SLAM technique, which is SLAM, has a weakness in extracting features in the real-world object. The use of User Defined Target and Extended Tracking are for making this work more convenient and reliable. We can trace the object even though the object does not exist, so this improves the function of markerless itself. The use of Raycast is for the make labeling the objects or features in the scanned object. In this research, we executed multivarious intensity to test the FAST Corner Detection to increase function in real world feature extraction and prove it better than SLAM. Then, we got the result where is a brighter condition will get faster recognition. The best environments for augmentation are in the range of 80-190, they took in less than 1 second. On the contrary, the intensity outside of the range such as \u226450 or \u2265200, has a deficiency of augmentation. The range of \u226450, there was no augmentation cause of low intensity. For the range of \u2265200, we haven't made measurements as we don't have the resources yet, but we hypothesize that the object would be corrupt or we may call it was overexposure cause of the intensity is too high. So, this could also lead to augmentation will not occur. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparison of Classification Algorithm to Improve Smart Fire Alarm System Performance"
        ],
        "penulis":"Sulistian, Gumilar;Abdurohman, Maman;Putrada, Aji Gautama;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Fire is a threat that is dangerous for the safety of residents. This research designs a fire early warning system that can ignite alerts for human. Technological advancements in the digital era, specifically in machine learning, can make the smart fire alarm system more developed to maximize the performance of the detection, and minimize false alarms. This paper implements four machine learning classification methods to be compared, Decision Tree, Na\u00efve Bayes, Support Vector Machine (SVM), and K-Nearest Neighbor (KNN). To implement the training and testing of each model, an IoT system is created. The IoT system consists of an IoT End Device and an IoT Platform. The IoT End Device consists of several sensors, such as DHT11, BMP180, MQ7, and MQ135. The IoT Platform consists of Thingspeak as data collection database and Matlab that performs all the classifier methods. The result of the comparison shows that Na\u00efve Bayes achieves the best performance in predicting fire. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Fire is a threat that is dangerous for the safety of residents. This research designs a fire early warning system that can ignite alerts for human. Technological advancements in the digital era, specifically in machine learning, can make the smart fire alarm system more developed to maximize the performance of the detection, and minimize false alarms. This paper implements four machine learning classification methods to be compared, Decision Tree, Na\u00efve Bayes, Support Vector Machine (SVM), and K-Nearest Neighbor (KNN). To implement the training and testing of each model, an IoT system is created. The IoT system consists of an IoT End Device and an IoT Platform. The IoT End Device consists of several sensors, such as DHT11, BMP180, MQ7, and MQ135. The IoT Platform consists of Thingspeak as data collection database and Matlab that performs all the classifier methods. The result of the comparison shows that Na\u00efve Bayes achieves the best performance in predicting fire. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Exploring Academic Patenting in Indonesia (1990-2015)"
        ],
        "penulis":"Sjafrizal T.;Pratami D.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study reveals the performance of Indonesian universities and institutes in producing academic patent for the period of 1990 until 2015. The study focused on the top 10 Indonesian universities by research performance index in 2015. Bibliometric data of academic patents from the Indonesian Patent Database were gathered and analyzed. Qualitative and quantitative analysis were deployed to portray the recent condition of academic patenting. Several anomalies were identified at the end of this study. Firstly, correlation study shows that no effect of academic quantity and quality research to patent filling. Secondly, the potential of technological-based institutes is not well developed in producing patents. Lastly, invention count on engineering-related inventions are still behind the medical, veterinary and food ones. \u00a9 Published under licence by IOP Publishing Ltd.",
            "HNOOH3CCH3View detailsExpand Substance Propham",
            "Powered by",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study reveals the performance of Indonesian universities and institutes in producing academic patent for the period of 1990 until 2015. The study focused on the top 10 Indonesian universities by research performance index in 2015. Bibliometric data of academic patents from the Indonesian Patent Database were gathered and analyzed. Qualitative and quantitative analysis were deployed to portray the recent condition of academic patenting. Several anomalies were identified at the end of this study. Firstly, correlation study shows that no effect of academic quantity and quality research to patent filling. Secondly, the potential of technological-based institutes is not well developed in producing patents. Lastly, invention count on engineering-related inventions are still behind the medical, veterinary and food ones. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Beamwidth enhancement of array microstrip antenna for radio altimeter application"
        ],
        "penulis":"Beoang, Antonius Kota;Anwar, Radial;Wahyu, Yuyu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, an array microstrip antenna with 2x2 configuration has been simulated and measured for radio altimeter. The goal of this study is to achieve a proper beamwidth for this application with acceptable VSWR. Thus, the spacing between patches has been varied to obtain the beamwidth. The simulation shows the antenna has 50.2 x 60 degrees beamwidth with VSWR of 1.21, where after measurement the antenna has gained VSWR of 1.238, 250.04 MHz bandwidth and beamwidth of \u00b148 x \u00b165 degrees. \u00a9 BEIESP.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, an array microstrip antenna with 2x2 configuration has been simulated and measured for radio altimeter. The goal of this study is to achieve a proper beamwidth for this application with acceptable VSWR. Thus, the spacing between patches has been varied to obtain the beamwidth. The simulation shows the antenna has 50.2 x 60 degrees beamwidth with VSWR of 1.21, where after measurement the antenna has gained VSWR of 1.238, 250.04 MHz bandwidth and beamwidth of \u00b148 x \u00b165 degrees. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Implementing binary particle swarm optimization and C4.5 decision tree for cancer detection based on microarray data classification"
        ],
        "penulis":"Pradana A.C.;Adiwijaya;Aditsania A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cancer is one of deadly disease in the world and needed to detect the symptoms early. Cancer can be represented with microarray data with measuring the changes occured in gene expression level. Cancer detection can be done by doing classification technique for microarray data. One of most algorithm that applied for classification is C4.5 Decision Tree. It is a linier method which is easy to interpret and included into the algorithm which has given impact in classification but it is sensitive to noise data. Microarray data has a large features (high dimensional) which is not all the features has important information (high noise) and small samples which is causing the classification is difficult and affect the accuracy. Binary Particle Swarm Optimization (BPSO) is one of search optimization algorithm that could find the optimal feature. The purpose in this research consists of implementing and analysing the influence of feature selection and classification on microarray data using Binary Particle Swarm Optimization (BPSO) as feature selection and Decision Tree C4.5 as classifier. The discretization is needed for Decision Tree rule model and applied using K-Means. System is divided into two schemes such as Information Gain (IG) - C4.5 and BPSO - C4.5. The accuracy result based on IG - C4.5 and BPSO - C4.5 both are 54% and 99%. Applying feature selection before the classification could avoid the noise data in microarray data so it could form the rule accurately. With applying BPSO and Decision Tree is able to find the most significant feature and improve the accuracy. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is one of deadly disease in the world and needed to detect the symptoms early. Cancer can be represented with microarray data with measuring the changes occured in gene expression level. Cancer detection can be done by doing classification technique for microarray data. One of most algorithm that applied for classification is C4.5 Decision Tree. It is a linier method which is easy to interpret and included into the algorithm which has given impact in classification but it is sensitive to noise data. Microarray data has a large features (high dimensional) which is not all the features has important information (high noise) and small samples which is causing the classification is difficult and affect the accuracy. Binary Particle Swarm Optimization (BPSO) is one of search optimization algorithm that could find the optimal feature. The purpose in this research consists of implementing and analysing the influence of feature selection and classification on microarray data using Binary Particle Swarm Optimization (BPSO) as feature selection and Decision Tree C4.5 as classifier. The discretization is needed for Decision Tree rule model and applied using K-Means. System is divided into two schemes such as Information Gain (IG) - C4.5 and BPSO - C4.5. The accuracy result based on IG - C4.5 and BPSO - C4.5 both are 54% and 99%. Applying feature selection before the classification could avoid the noise data in microarray data so it could form the rule accurately. With applying BPSO and Decision Tree is able to find the most significant feature and improve the accuracy. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "On the Uplink Throughput of Zero Forcing in Cell-Free Massive MIMO With Coarse Quantization"
        ],
        "penulis":"Maryopi, Dick;Bashar, Manijeh;Burr, Alister;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The recently proposed cell-free massive multiple input multiple output (MIMO) architecture is studied for the uplink. In contrast to most previous works, joint detection is performed using global channel state information (CSI). Therefore, we study strategies for transferring CSI to the central processing unit taking into account the fronthaul capacity which limits CSI quantization. Two strategies for pilot-based CSI acquisition are considered: estimate-and-quantize and quantize-and-estimate. These are analyzed using the Bussgang decomposition. For a given quantization constraint for the data and CSI the achievable rate per user with zero forcing is determined. Numerical results show that quantize-and-estimate (the simpler strategy) is similar to or better than estimate-and-quantize at low resolution, especially for 1-bit. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The recently proposed cell-free massive multiple input multiple output (MIMO) architecture is studied for the uplink. In contrast to most previous works, joint detection is performed using global channel state information (CSI). Therefore, we study strategies for transferring CSI to the central processing unit taking into account the fronthaul capacity which limits CSI quantization. Two strategies for pilot-based CSI acquisition are considered: estimate-and-quantize and quantize-and-estimate. These are analyzed using the Bussgang decomposition. For a given quantization constraint for the data and CSI the achievable rate per user with zero forcing is determined. Numerical results show that quantize-and-estimate (the simpler strategy) is similar to or better than estimate-and-quantize at low resolution, especially for 1-bit. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "IoT: Smart garbage monitoring using android and real time database"
        ],
        "penulis":"Putra, Riyan Hadi;Kusuma, Feri Teja;Damayanti, Tri Nopiani;Ramadan, Dadan Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Every single day, garbage is always produced and sometimes, due to the unbalance between high volume produced and the garbage volume transported to the landfill; it then leads to the buildup. To prevent any negative impact on environment, a system is needed to support the waste management process. Smart Garbage Monitoring System consists of two parts: portable garbage can and monitoring application using android smartphone. The use of ultrasonic sensor, GPS and GSM Module on the garbage can aims to provide the data on the garbage and send it to the real time database, in which the data will be processed by the monitoring application on smartphone to determine the time of garbage transport purposely to prevent any buildup. The system doesn't need a server to process, because the entire process of will be run by android application on a smartphone. Test results showed the capability of the system in monitoring the garbage can with the minimum distance between the wastes by three meters. The information on the height level of garbage can be synchronized in real time to smartphone, with an average delay on the EDGE network of 4.57 seconds, HSPA+ of 4.52 seconds and LTE of 3.85 seconds. \u00a9 2019 Universitas Ahmad Dahlan.",
            "Sustainable Development Goals mapped to this documentResponsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Every single day, garbage is always produced and sometimes, due to the unbalance between high volume produced and the garbage volume transported to the landfill; it then leads to the buildup. To prevent any negative impact on environment, a system is needed to support the waste management process. Smart Garbage Monitoring System consists of two parts: portable garbage can and monitoring application using android smartphone. The use of ultrasonic sensor, GPS and GSM Module on the garbage can aims to provide the data on the garbage and send it to the real time database, in which the data will be processed by the monitoring application on smartphone to determine the time of garbage transport purposely to prevent any buildup. The system doesn't need a server to process, because the entire process of will be run by android application on a smartphone. Test results showed the capability of the system in monitoring the garbage can with the minimum distance between the wastes by three meters. The information on the height level of garbage can be synchronized in real time to smartphone, with an average delay on the EDGE network of 4.57 seconds, HSPA+ of 4.52 seconds and LTE of 3.85 seconds. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "The used of modified UTAUT 2 model to analyze the continuance intention of travel mobile application"
        ],
        "penulis":"Indrawati;Amalia, Firda;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "PT. ABC is a state-owned company that provides railroad transportation services in Indonesia. In order to fulfill the needs of millions of passenger, PT. ABC has to innovate their business strategy in boosting up their train ticket sales. Following the technologies nowadays, the availability of ICT-based infrastructure is one of the most useful indicators to build up smart mobility. Therefore, the company launched its official mobile application named ABC Access in 2016. It is an official mobile application from PT. ABC that helps customers to order, manage and assist themselves with the service from pre, on until post train trip. However, the usage of application is still below the expectation hence it is the challenge that the company should find out the factors to increase the adoption of ABC Access. This study intends to analyze factors influencing the continuance intention of using ABC Access. The study's framework used in this study is adapted from the Unified Theory of Acceptance and Use of Technology 2 which is added with a new factor, namely System Quality. The data were collected from 409 valid respondents through purposive sampling technique. The data were analyzed by using SmartPLS 3.0 software and the result revealed that the factors influence continuance intention of using ABC Access from the highest to the lowest respectively are Hedonic Motivation, System Quality, Habit, and Performance Expectancy. The model can strongly predict the Continuance Intention of consumer towards ABC Access since the R2is 72%. Therefore, this model can be used by the company to improve and develop customer continuance intention towards ABC Access by considering those factors. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. ABC is a state-owned company that provides railroad transportation services in Indonesia. In order to fulfill the needs of millions of passenger, PT. ABC has to innovate their business strategy in boosting up their train ticket sales. Following the technologies nowadays, the availability of ICT-based infrastructure is one of the most useful indicators to build up smart mobility. Therefore, the company launched its official mobile application named ABC Access in 2016. It is an official mobile application from PT. ABC that helps customers to order, manage and assist themselves with the service from pre, on until post train trip. However, the usage of application is still below the expectation hence it is the challenge that the company should find out the factors to increase the adoption of ABC Access. This study intends to analyze factors influencing the continuance intention of using ABC Access. The study's framework used in this study is adapted from the Unified Theory of Acceptance and Use of Technology 2 which is added with a new factor, namely System Quality. The data were collected from 409 valid respondents through purposive sampling technique. The data were analyzed by using SmartPLS 3.0 software and the result revealed that the factors influence continuance intention of using ABC Access from the highest to the lowest respectively are Hedonic Motivation, System Quality, Habit, and Performance Expectancy. The model can strongly predict the Continuance Intention of consumer towards ABC Access since the R2is 72%. Therefore, this model can be used by the company to improve and develop customer continuance intention towards ABC Access by considering those factors. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Search relevant retrieval on indonesian translation hadith document using query expansion and smoothing probabilistic model"
        ],
        "penulis":"Ponilan, Ika Rahayu;Adiwijaya;Bijaksana, Moch. Arif;Raharusun, Agus Suyadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Hadith are words, deeds, decrees and approvals of the Prophet Muhammad SAW which are used as the basis for Islamic Shari'a law after the Qur'an. Currently there are many websites that provide information about hadith to facilitate users in the process of hadith learning or what we usually know as Information Retrievel (IR), such as the Lidwa Pustaka website. Basically, IR provides a search box for users to enter queries that reflect the user's information needs. The hadith search process on Lidwa Pustaka uses exact string matching method, which in the process of searching the hadith to the user's query must be the same as the hadith document in order per word (term), so that for partial matching search (matching the query in each word without sequential) can't be done yet. In addition, the writing of synonyms or variant strings that differ in Indonesian hadith translations, such as (al-khomru) are written as \"khamar\", \"khamer\", \"khamr\" or \"minuman keras\", making the process of the hadith search less precise. Therefore, this study aims to improve the search system for the hadith, using the approach of query expansion and smoothing probability models, namely Jelinerk-Mercer Smoothing, Dirichlet Smoothing and Absolute Discounting Smoothing. The use of query expansion and smoothing probability models in this study resulted in Mean Average Precision ALL (MAP ALL) values in all hadith documents, Mean Average Precision at 30 and the highest recall value of 30 compared to other methods, such as exact matching method for Lidwa Pustaka, Latent Semantic Indexing, Probability Model and Cosine Similarity. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hadith are words, deeds, decrees and approvals of the Prophet Muhammad SAW which are used as the basis for Islamic Shari'a law after the Qur'an. Currently there are many websites that provide information about hadith to facilitate users in the process of hadith learning or what we usually know as Information Retrievel (IR), such as the Lidwa Pustaka website. Basically, IR provides a search box for users to enter queries that reflect the user's information needs. The hadith search process on Lidwa Pustaka uses exact string matching method, which in the process of searching the hadith to the user's query must be the same as the hadith document in order per word (term), so that for partial matching search (matching the query in each word without sequential) can't be done yet. In addition, the writing of synonyms or variant strings that differ in Indonesian hadith translations, such as (al-khomru) are written as \"khamar\", \"khamer\", \"khamr\" or \"minuman keras\", making the process of the hadith search less precise. Therefore, this study aims to improve the search system for the hadith, using the approach of query expansion and smoothing probability models, namely Jelinerk-Mercer Smoothing, Dirichlet Smoothing and Absolute Discounting Smoothing. The use of query expansion and smoothing probability models in this study resulted in Mean Average Precision ALL (MAP ALL) values in all hadith documents, Mean Average Precision at 30 and the highest recall value of 30 compared to other methods, such as exact matching method for Lidwa Pustaka, Latent Semantic Indexing, Probability Model and Cosine Similarity. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Performance evaluation and comparison of scheduling algorithms on 5G networks using network simulator"
        ],
        "penulis":"Perdana, Doan;Sanyoto, Aji Nur;Bisono, Yoseph Gustommy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this research, we compared the Round Robin (RR) and the Proportional Fair (PF) algorithms for different user equipment density scenarios using voice and video traffic, to evaluate the key impact on performance of 5G mmwave network. This research simulated on NS3.27 with an integrated mmwave module. Based on the result, we found that the RR is a good choice for voice traffic. It has a throughput of 3.65% better than PF with similar fairness index. On the other hand, we found that the PF is the right choice for video traffic due to has better result for throughput. It has a throughput of 1.24% better than RR. For fairness index round robin has better result for voice and video traffic. \u00a9 2019 CC BY-NC.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this research, we compared the Round Robin (RR) and the Proportional Fair (PF) algorithms for different user equipment density scenarios using voice and video traffic, to evaluate the key impact on performance of 5G mmwave network. This research simulated on NS3.27 with an integrated mmwave module. Based on the result, we found that the RR is a good choice for voice traffic. It has a throughput of 3.65% better than PF with similar fairness index. On the other hand, we found that the PF is the right choice for video traffic due to has better result for throughput. It has a throughput of 1.24% better than RR. For fairness index round robin has better result for voice and video traffic. \u00a9 2019 CC BY-NC."
        ]
    },
    {
        "judul":[
            "User Interface Design of Mobile-based Commerce"
        ],
        "penulis":"Supriadi O.A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Current research regarding user interface has shown that successful interaction between e-commerce component and the end-user is related to a readable, perceivable user interface (UI). The purpose of this paper analyzes the design principles of the user interface used in popular e-commerce by using guidelines derived from previous researches and field survey. By using the variables, this research evaluated mobile-based commerce user interface through a case study, and how it affected the end-user expectation and acceptance. The result shows that popular m-commerce is aware of effective user interface used in its mobile app and that it applies UI basic principles on designing the app. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Current research regarding user interface has shown that successful interaction between e-commerce component and the end-user is related to a readable, perceivable user interface (UI). The purpose of this paper analyzes the design principles of the user interface used in popular e-commerce by using guidelines derived from previous researches and field survey. By using the variables, this research evaluated mobile-based commerce user interface through a case study, and how it affected the end-user expectation and acceptance. The result shows that popular m-commerce is aware of effective user interface used in its mobile app and that it applies UI basic principles on designing the app. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "An LSTM-based Spell Checker for Indonesian Text"
        ],
        "penulis":"Zaky, Damar;Romadhony, Ade;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A spell checker is a tool for detecting and correcting various spelling errors. While it might be trivial for humans, spell detecting and correcting can be very useful for machines, because machines could not detect spelling errors and correct them automatically. In Natural Language Processing (NLP), detecting and correcting spelling errors is a task that has been widely performed to normalize data, since most raw texts are noisy and have many spelling errors. In recent years, Long Short-Term Memory (LSTM) has shown to give an extraordinary result in solving sequential problems, including spelling correction. In this paper, we propose an LSTM model that encodes input word at character level, that also uses word and POS tag contexts as features. We performed the experiment on an artificial dataset based on Indonesian Wikipedia articles that we made by simulating some artificial spelling errors at character level and tested it on real dataset, mostly are Indonesian online news articles. The evaluation on test dataset gives 83.76% accuracy. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A spell checker is a tool for detecting and correcting various spelling errors. While it might be trivial for humans, spell detecting and correcting can be very useful for machines, because machines could not detect spelling errors and correct them automatically. In Natural Language Processing (NLP), detecting and correcting spelling errors is a task that has been widely performed to normalize data, since most raw texts are noisy and have many spelling errors. In recent years, Long Short-Term Memory (LSTM) has shown to give an extraordinary result in solving sequential problems, including spelling correction. In this paper, we propose an LSTM model that encodes input word at character level, that also uses word and POS tag contexts as features. We performed the experiment on an artificial dataset based on Indonesian Wikipedia articles that we made by simulating some artificial spelling errors at character level and tested it on real dataset, mostly are Indonesian online news articles. The evaluation on test dataset gives 83.76% accuracy. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Prototype of automation of organic fertilizer manufacturing systems based on internet of things"
        ],
        "penulis":"Pratama, Yogie Fajar;Ariyanto, Endro;Karimah, Siti Amatullah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Compost is an organic fertilizer made from the remnants of plants, animals and decomposable domestic waste with help from decomposers. The process to make compost is still manually done. Organic remnants and waste are piled and buried to create heat during the composting process. Then, the pile is mixed with hand and shovel to control moisture and temperature. Since ideal temperature and humidity have to be estimated manually, it will affect the decomposing duration. Compost will take more time to make if the mixing process and heat are not distributed well. Based on those problems, this research devises an automatic compost maker prototype which can detect temperature and humidity in the composting process based on Internet of Things, so the data can be processed by fuzzy logic, which also acts as the main control to run the actuator (heater and water pump). Temperature and humidity data from the sensor will be sent to a database, then the fuzzy logic will determine the optimal temperature and humidity for the composting process by activating the actuator which consists of water sprinkler, heater and mixing motor. Based on experiment results, the prototype is able to create compost in 14 days or 2,35 times faster than using the traditional tools that require 33 days. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Compost is an organic fertilizer made from the remnants of plants, animals and decomposable domestic waste with help from decomposers. The process to make compost is still manually done. Organic remnants and waste are piled and buried to create heat during the composting process. Then, the pile is mixed with hand and shovel to control moisture and temperature. Since ideal temperature and humidity have to be estimated manually, it will affect the decomposing duration. Compost will take more time to make if the mixing process and heat are not distributed well. Based on those problems, this research devises an automatic compost maker prototype which can detect temperature and humidity in the composting process based on Internet of Things, so the data can be processed by fuzzy logic, which also acts as the main control to run the actuator (heater and water pump). Temperature and humidity data from the sensor will be sent to a database, then the fuzzy logic will determine the optimal temperature and humidity for the composting process by activating the actuator which consists of water sprinkler, heater and mixing motor. Based on experiment results, the prototype is able to create compost in 14 days or 2,35 times faster than using the traditional tools that require 33 days. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Utilizing structured knowledge bases in open IE based event template extraction"
        ],
        "penulis":"Romadhony, Ade;Widyantoro, Dwi H.;Purwarianti, Ayu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Automatic template extraction including event template has been studied intensively in recent years. Researchers study the topic in order to solve the problem of manually defining a template that is required in most information extraction systems. Several studies of event template extraction rely on the documents characteristics to discover the pattern. Although there exist some structured knowledge bases, such as: FrameNet, Predicate Matrix, ACE (Automatic Content Extraction) event type keywords seeds, and FrameNet-ACE event type mapping, no previous researchers have studied combining this information for event template extraction. This paper presents an event template extraction approach that incorporates structured knowledge bases. We propose event template extraction from Open Information Extraction (Open IE) results (relation tuples) in two stages: relation tuple clustering and relation tuple filtering. Both processes utilize structured knowledge bases, as constraint sources in the clustering process and as the basis for the filtering process. The filtering process employs the word embedding representation to capture the semantic relatedness between words. We argue that by involving structured knowledge bases, the relation tuple semantic information can be enriched. Therefore, we can get groups of relation tuples with a similar event sense that represent event templates. The empirical experiment was based on an event argument extraction task and showed that our proposed approach outperforms similar methods that do not use structured knowledge bases. We also compare our proposed system performance to the performance of state-of-the-art systems. The comparison result shows that our proposed system outperforms other state-of-the-art systems, in terms of precision. \u00a9 2018, Springer Science+Business Media, LLC, part of Springer Nature.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Automatic template extraction including event template has been studied intensively in recent years. Researchers study the topic in order to solve the problem of manually defining a template that is required in most information extraction systems. Several studies of event template extraction rely on the documents characteristics to discover the pattern. Although there exist some structured knowledge bases, such as: FrameNet, Predicate Matrix, ACE (Automatic Content Extraction) event type keywords seeds, and FrameNet-ACE event type mapping, no previous researchers have studied combining this information for event template extraction. This paper presents an event template extraction approach that incorporates structured knowledge bases. We propose event template extraction from Open Information Extraction (Open IE) results (relation tuples) in two stages: relation tuple clustering and relation tuple filtering. Both processes utilize structured knowledge bases, as constraint sources in the clustering process and as the basis for the filtering process. The filtering process employs the word embedding representation to capture the semantic relatedness between words. We argue that by involving structured knowledge bases, the relation tuple semantic information can be enriched. Therefore, we can get groups of relation tuples with a similar event sense that represent event templates. The empirical experiment was based on an event argument extraction task and showed that our proposed approach outperforms similar methods that do not use structured knowledge bases. We also compare our proposed system performance to the performance of state-of-the-art systems. The comparison result shows that our proposed system outperforms other state-of-the-art systems, in terms of precision. \u00a9 2018, Springer Science+Business Media, LLC, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "Nonlinear autoregressive neural network models for sea level prediction, study case: In Semarang, Indonesia"
        ],
        "penulis":"Rizkina, Miftahul Awali;Adytia, Didit;Subasita, Nugrahinggil;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Sea level prediction is highly needed for coastal communities. Mainly driven by tidal, the sea level predictions can be used for analyzing the disposal and movements of sediments, tracers and pollutants, off-shore engineering constructions, environmental observations, as well as for ship navigation. Prediction of tides usually use tidal harmonic analysis for long term tidal predictions. However, this tide harmonic analysis has several drawbacks i.e. the method can not be used for short-term and real-time forecasting or instant prediction. Moreover, the method requires a large number of tidal data measurements to obtain accurate prediction. In this paper, we propose a sea level prediction by using Artificial Neural Network (ANN) model approach, namely the Nonlinear Autoregressive Neural Network (NAR). The method is applied for predicting sea level in Tanjung Emas Harbor in Semarang, Indonesia. We compare results of the prediction by using NAR with prediction by using tidal harmonic analysis. The accuracy of the prediction is measured by calculating the RMSE value and R value. NAR produces R value 0.9566 for training data and 0.9567 for prediction data. The choice of number of hidden layers in the NAR can also affects the results of prediction, in term of RMSE value and R value. The results show that NAR method produces a better accuracy in predicting sea level than using the tidal harmonic analysis. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sea level prediction is highly needed for coastal communities. Mainly driven by tidal, the sea level predictions can be used for analyzing the disposal and movements of sediments, tracers and pollutants, off-shore engineering constructions, environmental observations, as well as for ship navigation. Prediction of tides usually use tidal harmonic analysis for long term tidal predictions. However, this tide harmonic analysis has several drawbacks i.e. the method can not be used for short-term and real-time forecasting or instant prediction. Moreover, the method requires a large number of tidal data measurements to obtain accurate prediction. In this paper, we propose a sea level prediction by using Artificial Neural Network (ANN) model approach, namely the Nonlinear Autoregressive Neural Network (NAR). The method is applied for predicting sea level in Tanjung Emas Harbor in Semarang, Indonesia. We compare results of the prediction by using NAR with prediction by using tidal harmonic analysis. The accuracy of the prediction is measured by calculating the RMSE value and R value. NAR produces R value 0.9566 for training data and 0.9567 for prediction data. The choice of number of hidden layers in the NAR can also affects the results of prediction, in term of RMSE value and R value. The results show that NAR method produces a better accuracy in predicting sea level than using the tidal harmonic analysis. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Aperture Antennas for 5G Mobile Base Stations"
        ],
        "penulis":"Yamada, Yoshihide;Quzwain, Kamelia;Ansarudin, Farizah;Kamardin, Kamilia;Abd Rahman, Nurul Huda;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The fifth-generation (5G) mobile communication system will require the multi beam base station antennas. By taking into account a small antenna size at millimeter wave, any antenna types such as array, reflector and dielectric lens antennas become possible candidate. In this paper, aperture type antennas of reflector and lens are selected because of excellent multi beam performances. Fundamental antenna design technologies by a MATLAB software and expected radiation patterns by an electromagnetic simulator are shown. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The fifth-generation (5G) mobile communication system will require the multi beam base station antennas. By taking into account a small antenna size at millimeter wave, any antenna types such as array, reflector and dielectric lens antennas become possible candidate. In this paper, aperture type antennas of reflector and lens are selected because of excellent multi beam performances. Fundamental antenna design technologies by a MATLAB software and expected radiation patterns by an electromagnetic simulator are shown. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Digital leadership role in developing business model innovation and customer experience orientation in industry 4.0"
        ],
        "penulis":"Mihardjo, Leonardus W. W.;Sasmoko, Sasmoko;Alamsjah, Firdaus;Elidjen, Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 4.0 brings a new challenge for incumbent firms to anticipate new business model offered by emerging entries. The digital transformation is required by incumbent to develop innovation on product and service business model based on customer experience orientation. To support this transformation, strong digital leader is important to assure the development of this transformation. The study on the role of digital leadership on business model innovation and customer experience has not been explored, significantly, Hence, this research aims at assessing the role of digital leadership, whether it directly or indirectly influences the customer experience orientation in developing business model innovation. This study was conducted through survey to 88 senior leader respondents from Indonesia telecommunication firms, in which Smart-PLS application was used to analyze the data. The result show that digital leadership had direct and indirect impacts on customer experience orientation in developing business model innovation. The practical implications of these findings are recommended for the senior leader of management of telecommunications industries in Indonesia to strengthen digital leadership capability in conjunction with the development of business model innovation and customer experience orientation. Further research can be explored by expanding the sample, industry, statistical application and longitudinal study. \u00a9 2019 by the authors; licensee Growing Science, Canada. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 4.0 brings a new challenge for incumbent firms to anticipate new business model offered by emerging entries. The digital transformation is required by incumbent to develop innovation on product and service business model based on customer experience orientation. To support this transformation, strong digital leader is important to assure the development of this transformation. The study on the role of digital leadership on business model innovation and customer experience has not been explored, significantly, Hence, this research aims at assessing the role of digital leadership, whether it directly or indirectly influences the customer experience orientation in developing business model innovation. This study was conducted through survey to 88 senior leader respondents from Indonesia telecommunication firms, in which Smart-PLS application was used to analyze the data. The result show that digital leadership had direct and indirect impacts on customer experience orientation in developing business model innovation. The practical implications of these findings are recommended for the senior leader of management of telecommunications industries in Indonesia to strengthen digital leadership capability in conjunction with the development of business model innovation and customer experience orientation. Further research can be explored by expanding the sample, industry, statistical application and longitudinal study. \u00a9 2019 by the authors; licensee Growing Science, Canada. All rights reserved."
        ]
    },
    {
        "judul":[
            "Lessons learned to increase the digital startupssuccess rate"
        ],
        "penulis":"Mukti, Iqbal Yulizar;Wibowo, Ari Purno Wahyu;Galih, Savitri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose:The purpose of this paper is to explore the lessons learned to increase the startups\u2019 success rate based on a case study in Selurup, a digital startup worked on food delivery services. Design\/methodology\/approach: To systematically identify the lessons learned, and this paper adopts the hypothesis-driven entrepreneurship framework. Guides by research questions described in the introduction section, the lessons learned are elaborated by using interviews with the co-founder. Findings: Research in this paper, ultimately suggest the emerging digital startups to follow the hypothesis-driven entrepreneurship framework as the structured approach to face the extreme uncertainty that typically faced by the startups. Research limitations\/implications: Research in this paper explores the lessons learned only from one startup. Consequently, the lesson learned might not represented all the startups in Indonesia. Practical implications: It is expected that the lessons learned from this research can give positive contribution to increase the emerging digital startups success rate. Originality\/value: This study academically explores the lesson learned especially from the emerging digital startups, following the hypothesis-driven entrepreneurship framework. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose:The purpose of this paper is to explore the lessons learned to increase the startups\u2019 success rate based on a case study in Selurup, a digital startup worked on food delivery services. Design\/methodology\/approach: To systematically identify the lessons learned, and this paper adopts the hypothesis-driven entrepreneurship framework. Guides by research questions described in the introduction section, the lessons learned are elaborated by using interviews with the co-founder. Findings: Research in this paper, ultimately suggest the emerging digital startups to follow the hypothesis-driven entrepreneurship framework as the structured approach to face the extreme uncertainty that typically faced by the startups. Research limitations\/implications: Research in this paper explores the lessons learned only from one startup. Consequently, the lesson learned might not represented all the startups in Indonesia. Practical implications: It is expected that the lessons learned from this research can give positive contribution to increase the emerging digital startups success rate. Originality\/value: This study academically explores the lesson learned especially from the emerging digital startups, following the hypothesis-driven entrepreneurship framework. \u00a9 2019, Institute of Advanced Scientific Research, Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "Chili commodity price forecasting in bandung regency using the adaptive synthetic sampling (ADASYN) and K-Nearest neighbor (KNN) algorithms"
        ],
        "penulis":"Hasmita S.;Nhita, Fhira;Saepudin, Deni;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Red chili is an important spice in Indonesia. The Ministry of Agriculture (MoA) reported the significant contribution of red chili to the Indonesian economy both locally and internationally. Chili plants experience price inflation from year to year. This price change is influenced by several factors such as the number of requests and changes in the weather, both of which can affect production. In this study, the prediction of chili prices was carried out using the K-Nearest Neighbor (KNN) algorithm based on chili price data and weather data. The data obtained had imbalanced classes, so the Adaptive Synthetic (ADASYN) algorithm was used to overcome this issue. From the results, the classification using KNN reached the highest accuracy of 93% but with an F1-Score of 0%. In contrast, classification using KNN and ADASYN obtained 100% accuracy and an F1-Score of 100%. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Red chili is an important spice in Indonesia. The Ministry of Agriculture (MoA) reported the significant contribution of red chili to the Indonesian economy both locally and internationally. Chili plants experience price inflation from year to year. This price change is influenced by several factors such as the number of requests and changes in the weather, both of which can affect production. In this study, the prediction of chili prices was carried out using the K-Nearest Neighbor (KNN) algorithm based on chili price data and weather data. The data obtained had imbalanced classes, so the Adaptive Synthetic (ADASYN) algorithm was used to overcome this issue. From the results, the classification using KNN reached the highest accuracy of 93% but with an F1-Score of 0%. In contrast, classification using KNN and ADASYN obtained 100% accuracy and an F1-Score of 100%. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Hybrid Filter for Attributes Reduction in Soft Set"
        ],
        "penulis":"Mohammed, Mohammed Adam Taheir;Mohd, Wan Maseri Wan;Arshah, Ruzaini Abdullah;Mungad M.;Sutoyo, Edi;Chiroma, Haruna;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of this research is to overcome parameterization reduction limitation that focuses only on individual parameter reduction, whereas in some cases the individual parameter reduction is not sufficient even implies reduction. It was found that the dimensions sometimes are not able to reduce the number of data in the case of big data; hence, for this reason it became necessary to look for an alternative technique that can significantly reduce the parameters. This paper proposed an alternative decision partition order method based on rough set indiscernibility to select attributes reductions in soft set using decompositions. For significant candidates, the method decomposition partition order used R supp checking to confirm the correctness of the reduction. Comparison of the reduction methods shows that the proposed method provides better result than the parameterization reduction in enhancing reduction. The false candidates were filtered in the huge candidate reduction by the Min supp. The proposed method can be used to maintain object before attribute reduction as well as to reduce parameter size drastically while maintaining consistency in decision making. \u00a9 Springer Nature Singapore Pte Ltd. 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this research is to overcome parameterization reduction limitation that focuses only on individual parameter reduction, whereas in some cases the individual parameter reduction is not sufficient even implies reduction. It was found that the dimensions sometimes are not able to reduce the number of data in the case of big data; hence, for this reason it became necessary to look for an alternative technique that can significantly reduce the parameters. This paper proposed an alternative decision partition order method based on rough set indiscernibility to select attributes reductions in soft set using decompositions. For significant candidates, the method decomposition partition order used R supp checking to confirm the correctness of the reduction. Comparison of the reduction methods shows that the proposed method provides better result than the parameterization reduction in enhancing reduction. The false candidates were filtered in the huge candidate reduction by the Min supp. The proposed method can be used to maintain object before attribute reduction as well as to reduce parameter size drastically while maintaining consistency in decision making. \u00a9 Springer Nature Singapore Pte Ltd. 2019."
        ]
    },
    {
        "judul":[
            "A contrastive analysis of imperative sentences in English and Javanese language"
        ],
        "penulis":"Wijayanto, Pikir Wisnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to identify the similarities and differences between the functions of imperative sentences of English and Javanese languages. The contrastive analysis used as the research method to compare the two different languages. Based on the analysis, in the English imperative sentence, there are seven functions which are a command, prohibition, invitation, request, advice, suggestion, and compulsion. While, in the Javanese imperative sentence, it has nine functions, which are a command, prohibition, invitation, request, advice, suggestion, compulsion, panantang, and pangece. \u00a9 Universiti Putra Malaysia Press"
        ],
        "abstrak":[
            "This study aims to identify the similarities and differences between the functions of imperative sentences of English and Javanese languages. The contrastive analysis used as the research method to compare the two different languages. Based on the analysis, in the English imperative sentence, there are seven functions which are a command, prohibition, invitation, request, advice, suggestion, and compulsion. While, in the Javanese imperative sentence, it has nine functions, which are a command, prohibition, invitation, request, advice, suggestion, compulsion, panantang, and pangece. \u00a9 Universiti Putra Malaysia Press"
        ]
    },
    {
        "judul":[
            "Assembly line design in final assembly excavator at XYZ Corp using genetic algorithm"
        ],
        "penulis":"Sari, Risty Mayang;Damayanti, Dida Diah;Juliani, Widia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Large scale manufacturing companies are growing along with ever-increasing demand from consumers, one of which is the heavy equipment industry. Excavators are the products of the heavy equipment division at XYZ Corp, where the Excavator assembly lines are single-model. Based on observations of existing conditions that occur at XYZ Corp, the production still cannot meet the demands of consumers. In the assembly process, the Excavator has a significant time difference from each work station, the distribution of work elements in the assembly process is uneven. In the Final assembly section (Zone C) there is a discrepancy between the takt time of Excavator products which is one reason for not achieving the demand. In resolving these problems, a line balancing process is needed, namely balancing workloads on each workstation. This study applies the Heuristic Priority Rules method as an initial solution and allocation constraint should be added as input from the Genetic Algorithms method to complete line balancing with a single-model system. Problems can be solved by increasing line efficiency from existing conditions by 60.4% to 91.74% and Smoothness index which decreases from 955.54 to 158.3977. The proposed result of balancing the final assembly of the excavator results in a better balance of assembly lines. \u00a9 2019 Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Large scale manufacturing companies are growing along with ever-increasing demand from consumers, one of which is the heavy equipment industry. Excavators are the products of the heavy equipment division at XYZ Corp, where the Excavator assembly lines are single-model. Based on observations of existing conditions that occur at XYZ Corp, the production still cannot meet the demands of consumers. In the assembly process, the Excavator has a significant time difference from each work station, the distribution of work elements in the assembly process is uneven. In the Final assembly section (Zone C) there is a discrepancy between the takt time of Excavator products which is one reason for not achieving the demand. In resolving these problems, a line balancing process is needed, namely balancing workloads on each workstation. This study applies the Heuristic Priority Rules method as an initial solution and allocation constraint should be added as input from the Genetic Algorithms method to complete line balancing with a single-model system. Problems can be solved by increasing line efficiency from existing conditions by 60.4% to 91.74% and Smoothness index which decreases from 955.54 to 158.3977. The proposed result of balancing the final assembly of the excavator results in a better balance of assembly lines. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Stream Control Transportation Protocol (SCTP) towards MANET Routing: Comparison of DSR and AODV"
        ],
        "penulis":"Lubis, Muharman;Lubis, Fahrurrozi;Lubis, Arif Ridho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research wants to compare the performance of Stream Control Transportation Protocol (SCTP) with two difference mechanism, which are Ad-hoc on Demand Distance Vector (AODV) and Dynamic Source Routing protocol (DSR) by using Network Simulator (NS-2). Specifically, it measures the behavior of SCTP in terms of throughput and smoothness by having assumption that routing protocol in MANET (Mobile Ad-hoc Network) can bring significant effect in SCTP in the overall performance. Actually, IETF (Internet Engineering Task Force), has issued a new protocol called SCTP, which in this study, the interaction of SCTP is investigated through the examination of traffic flows through a number of network topologies. This performance analysis is over MANET Routing Protocol that enables the process of analysis of several performance metrics. The simulation use topology with 16 nodes that is consisting of metric 4\u00d74 of SCTP transport layer for both routing protocol of AODV and DSR. At last, this research have been found that MANET impact less on the throughput of SCTP with only amounted to 0-2% within 5m\/s to 25 m\/s of simulation area. Furthermore, the speed of node movement does not significantly affect the smoothness as well. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research wants to compare the performance of Stream Control Transportation Protocol (SCTP) with two difference mechanism, which are Ad-hoc on Demand Distance Vector (AODV) and Dynamic Source Routing protocol (DSR) by using Network Simulator (NS-2). Specifically, it measures the behavior of SCTP in terms of throughput and smoothness by having assumption that routing protocol in MANET (Mobile Ad-hoc Network) can bring significant effect in SCTP in the overall performance. Actually, IETF (Internet Engineering Task Force), has issued a new protocol called SCTP, which in this study, the interaction of SCTP is investigated through the examination of traffic flows through a number of network topologies. This performance analysis is over MANET Routing Protocol that enables the process of analysis of several performance metrics. The simulation use topology with 16 nodes that is consisting of metric 4\u00d74 of SCTP transport layer for both routing protocol of AODV and DSR. At last, this research have been found that MANET impact less on the throughput of SCTP with only amounted to 0-2% within 5m\/s to 25 m\/s of simulation area. Furthermore, the speed of node movement does not significantly affect the smoothness as well. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Optimization of a photovoltaic hybrid energy storage system using energy storage peak shaving"
        ],
        "penulis":"Adam, Kharisma Bani;Miyauchi, Hajime;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electrical supply in rural areas, especially on small islands, commonly utilizes eco-unfriendly and costly diesel-based power plants. Renewable energy power plants can replace these diesel-based power plants. Thus, energy optimization is critical for the improvement of the energy efficiency of the renewable energy system. The optimization of a photovoltaic energy system through a hybrid energy storage system is analyzed for the off-grid island. The hybrid energy storage system involves the hybridization of two energy storage systems including a battery storage system and a hydrogen storage system. The management of a photovoltaic hybrid energy storage system requires a power management system. This paper proposes a power management system based on the peak shaving strategy in hydrogen energy storage to improve the efficiency of the hybrid energy storage system while considering the surplus energy forecasting. The hybrid energy storage system typically focuses on the efficiency of a closed system. In such a closed system, the optimization focuses on the life-saving of the battery. The energy storage peak shaving is used to improve the efficiency of the hybrid energy storage system, for the maximization of excess hydrogen to supply electricity to the islands. The result reveals that the average efficiency of the hybrid energy storage system based on the proposed power management system is 52.3%, which is 29.6% higher than the one obtained from traditional power management system strategy, whereas the battery depreciation is improved by 1.2%. \u00a9 2019 Praise Worthy Prize S.r.l.-All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electrical supply in rural areas, especially on small islands, commonly utilizes eco-unfriendly and costly diesel-based power plants. Renewable energy power plants can replace these diesel-based power plants. Thus, energy optimization is critical for the improvement of the energy efficiency of the renewable energy system. The optimization of a photovoltaic energy system through a hybrid energy storage system is analyzed for the off-grid island. The hybrid energy storage system involves the hybridization of two energy storage systems including a battery storage system and a hydrogen storage system. The management of a photovoltaic hybrid energy storage system requires a power management system. This paper proposes a power management system based on the peak shaving strategy in hydrogen energy storage to improve the efficiency of the hybrid energy storage system while considering the surplus energy forecasting. The hybrid energy storage system typically focuses on the efficiency of a closed system. In such a closed system, the optimization focuses on the life-saving of the battery. The energy storage peak shaving is used to improve the efficiency of the hybrid energy storage system, for the maximization of excess hydrogen to supply electricity to the islands. The result reveals that the average efficiency of the hybrid energy storage system based on the proposed power management system is 52.3%, which is 29.6% higher than the one obtained from traditional power management system strategy, whereas the battery depreciation is improved by 1.2%. \u00a9 2019 Praise Worthy Prize S.r.l.-All rights reserved."
        ]
    },
    {
        "judul":[
            "The undersampling effects on RANDSHUFF oversampling algorithms"
        ],
        "penulis":"Fahrudin, Tora;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Randshuff (Random Shuffle Oversampling Techniques for Qualitative Data) is one of an oversampling algorithm which appropriate for nominal attributes. Randshuff uses IVDM (Interpolated Value Difference Metric) distance calculation and crossover with random shuffle technique. Although Randshuff can overcome the problems on minority data, but the problems on majority data are ignored. The problem arises where majority data contain distribution complexity problems such as small disjuncts, overlap and noise. There are two kinds of undersampling concepts: informed undersampling and simple random undersampling. Tomeks links, Edited Nearest neighbors (ENN) and Near Miss are informed undersampling state of the art methods. Meanwhile, Random Undersampling (RUS) is simple random undersampling method. So, evaluations of both undersampling concepts on Randshuff are needed to be conducted. The experiments were evaluated on five public datasets. The results show that RUS as simple random undersampling and Near Miss as informed under sampling improve recall, f-measure and g-mean performance on Randshuff algorithm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Randshuff (Random Shuffle Oversampling Techniques for Qualitative Data) is one of an oversampling algorithm which appropriate for nominal attributes. Randshuff uses IVDM (Interpolated Value Difference Metric) distance calculation and crossover with random shuffle technique. Although Randshuff can overcome the problems on minority data, but the problems on majority data are ignored. The problem arises where majority data contain distribution complexity problems such as small disjuncts, overlap and noise. There are two kinds of undersampling concepts: informed undersampling and simple random undersampling. Tomeks links, Edited Nearest neighbors (ENN) and Near Miss are informed undersampling state of the art methods. Meanwhile, Random Undersampling (RUS) is simple random undersampling method. So, evaluations of both undersampling concepts on Randshuff are needed to be conducted. The experiments were evaluated on five public datasets. The results show that RUS as simple random undersampling and Near Miss as informed under sampling improve recall, f-measure and g-mean performance on Randshuff algorithm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Designing metacognitive and motivation tutor: A pedagogical agent to facilitate learning in blended-learning environment in a higher education context"
        ],
        "penulis":"Martha, Ati Suci Dian;Santoso, Harry Budi;Junus, Kasiyah;Suhartanto, Heru;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, we present the initial results of research that is still ongoing in building metacognitive and motivation tutor, a pedagogical agent used to facilitate students in blended learning in a higher education context. The MeMo Tutor, which stands for \u201cMetacognitive and Motivation Tutor\u201d, is a pedagogical agent in the form of a conversational agent that integrated into the Moodle Learning Management System. The metacognitive and motivation tutor aims to provide feedback to students using an integration of metacognitive scaffolding and motivation scaffolding. The main objective of the pedagogical agent is to maintain and enhance student engagement and motivation in blended-learning environment. This paper presents the first results in ongoing research efforts. In this work, we attempt to design the components of the proposed pedagogical agent, consisting of a learning environment, character design, and system architecture. \u00a9 ICCE 2019 - 27th International Conference on Computers in Education, Proceedings. All rights reserved.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we present the initial results of research that is still ongoing in building metacognitive and motivation tutor, a pedagogical agent used to facilitate students in blended learning in a higher education context. The MeMo Tutor, which stands for \u201cMetacognitive and Motivation Tutor\u201d, is a pedagogical agent in the form of a conversational agent that integrated into the Moodle Learning Management System. The metacognitive and motivation tutor aims to provide feedback to students using an integration of metacognitive scaffolding and motivation scaffolding. The main objective of the pedagogical agent is to maintain and enhance student engagement and motivation in blended-learning environment. This paper presents the first results in ongoing research efforts. In this work, we attempt to design the components of the proposed pedagogical agent, consisting of a learning environment, character design, and system architecture. \u00a9 ICCE 2019 - 27th International Conference on Computers in Education, Proceedings. All rights reserved."
        ]
    },
    {
        "judul":[
            "A Fuzzy Logic Based Internet of Things (IoT) for Smart Water Bottle"
        ],
        "penulis":"Wijanarko, Angga Edwin;Abdurohman, Maman;Putrada, Aji Gautama;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes the smart water bottle system based on Internet of Things (IoT) using Fuzzy Logic method. This system has input data from water level and temperature levels. Various water levels and room temperatures are used to calculate the level of water consumption. The Fuzzy Inference System provides three classes, i.e. Low, Medium and High, which indicates user drinking requirements. Fuzzy results are selected according to the input given by the sensor for predicting water consumption, after generating the output directly sent to the server to be converted into a drink reminder notification. By using the fuzzy logic method, the prediction of the consumption of drinking water needed for daily activity is quite accurate and it can also be observed that the prediction model by fuzzy produces the appropriate output. This model is tested with a 3-hour notification period for one day and is able to predict water consumption. The result shows the effectiveness of smart water bottle system on predicting water consumption.  \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes the smart water bottle system based on Internet of Things (IoT) using Fuzzy Logic method. This system has input data from water level and temperature levels. Various water levels and room temperatures are used to calculate the level of water consumption. The Fuzzy Inference System provides three classes, i.e. Low, Medium and High, which indicates user drinking requirements. Fuzzy results are selected according to the input given by the sensor for predicting water consumption, after generating the output directly sent to the server to be converted into a drink reminder notification. By using the fuzzy logic method, the prediction of the consumption of drinking water needed for daily activity is quite accurate and it can also be observed that the prediction model by fuzzy produces the appropriate output. This model is tested with a 3-hour notification period for one day and is able to predict water consumption. The result shows the effectiveness of smart water bottle system on predicting water consumption.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Asterisk and radio over ip integration at voice communication system air traffic control"
        ],
        "penulis":"Hendrawan, Hendrawan;Aditya, Bagus;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Asterisk, the most popular open source VoIP core software in telecommunications technology that is integrated with Radio Over IP (RoIP) and Voice over IP (VoIP) gateway devices can be cheap and powerful solution for small airports usually located in rural areas. This paper reports the configuration and implementation of Internet Protocol (IP)-based voice communication system (VCS) for air traffic control using Asterisk VoIP server integrated with MySQL database, Apache webserver and Transceiver Radio PTT devices. The radio gateway that was selected for the prototype did not fulfil several of the chosen requirements, since it was using a different frequency with airport radio frequency standard usage. The prototype is click to call and report via web interface application and allowing 2 way voice communication between Air Traffic Controller (ATC) with airport telecommunication device (PTT Radio Transceiver telephony). At this report, we will discuss about the prototype of VCS web interface at ATC and communication of Radio Transceiver Device with asterisk VoIP server. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Asterisk, the most popular open source VoIP core software in telecommunications technology that is integrated with Radio Over IP (RoIP) and Voice over IP (VoIP) gateway devices can be cheap and powerful solution for small airports usually located in rural areas. This paper reports the configuration and implementation of Internet Protocol (IP)-based voice communication system (VCS) for air traffic control using Asterisk VoIP server integrated with MySQL database, Apache webserver and Transceiver Radio PTT devices. The radio gateway that was selected for the prototype did not fulfil several of the chosen requirements, since it was using a different frequency with airport radio frequency standard usage. The prototype is click to call and report via web interface application and allowing 2 way voice communication between Air Traffic Controller (ATC) with airport telecommunication device (PTT Radio Transceiver telephony). At this report, we will discuss about the prototype of VCS web interface at ATC and communication of Radio Transceiver Device with asterisk VoIP server. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Evaluating services computing systems engineering framework using an acceptance model"
        ],
        "penulis":"Kurniawan, Novianto Budi;Suhardi;Bandung, Yoanes;Prasetyo, Yuli Adam;Yustianto, Purnomo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The gap between business services and IT services becomes a major concern in services computing. As an approach for service-based IT solution, services computing systems are promised to be able to bridge the gap between these services. The implementation will require an engineering framework as a guide to building the systems. The framework needs to be evaluated to provide important feedback to the framework development. This paper outlines the evaluation of SCSE framework through an acceptance model. The study develops an acceptance model based on the experiences of a group of engineers after using the framework to build smart campus services systems. A survey involving 54 systems engineers with various engineering backgrounds was conducted to assess the experiences of the engineers in using the framework. The results of the acceptance model show that both perceived ease of use, represented by the level of agreement (\u03bd1) and perceived usefulness, represented by the level of importance (\u03bd2) deliver good results almost for the entire stages of the proposed framework. In addition, the user experiences of using the proposed framework are in the acceptable levels. The contribution of this paper is an enrichment of the engineering methodologies for the service-oriented system from the perspective of services computing. \u00a9 2019 International Journal on Advanced Science Engineering Information Technology.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The gap between business services and IT services becomes a major concern in services computing. As an approach for service-based IT solution, services computing systems are promised to be able to bridge the gap between these services. The implementation will require an engineering framework as a guide to building the systems. The framework needs to be evaluated to provide important feedback to the framework development. This paper outlines the evaluation of SCSE framework through an acceptance model. The study develops an acceptance model based on the experiences of a group of engineers after using the framework to build smart campus services systems. A survey involving 54 systems engineers with various engineering backgrounds was conducted to assess the experiences of the engineers in using the framework. The results of the acceptance model show that both perceived ease of use, represented by the level of agreement (\u03bd1) and perceived usefulness, represented by the level of importance (\u03bd2) deliver good results almost for the entire stages of the proposed framework. In addition, the user experiences of using the proposed framework are in the acceptable levels. The contribution of this paper is an enrichment of the engineering methodologies for the service-oriented system from the perspective of services computing. \u00a9 2019 International Journal on Advanced Science Engineering Information Technology."
        ]
    },
    {
        "judul":[
            "Design Features for Gender-specific Differences in Blended Learning within Higher Education in Indonesia"
        ],
        "penulis":"Aditya, Bayu Rima;Permadi, Aditya;Nurhas, Irawan;Pawlowski, Jan M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Blended learning offers learning solutions for higher educational institutions facing the industrial revolution 4.0. In this study, we investigated the influence factors student perceptions of blended learning based on gender-specific differences in Indonesia. We applied a research model to systematically assess the effect of design features on the effectiveness of blended learning indicators (intrinsic motivation and student satisfaction). Moreover, we evaluated the research model for both genders separately. Based on the quantitative survey of 223 Indonesian students, our study confirms that the design features significantly influence the effectiveness of blended learning for male and female students. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Blended learning offers learning solutions for higher educational institutions facing the industrial revolution 4.0. In this study, we investigated the influence factors student perceptions of blended learning based on gender-specific differences in Indonesia. We applied a research model to systematically assess the effect of design features on the effectiveness of blended learning indicators (intrinsic motivation and student satisfaction). Moreover, we evaluated the research model for both genders separately. Based on the quantitative survey of 223 Indonesian students, our study confirms that the design features significantly influence the effectiveness of blended learning for male and female students. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Reasoning about the disruption patterns for train system using Bayesian Network and Prolog"
        ],
        "penulis":"Pradiawati, Yunita Rachma;Rusmawati, Yanti;Arzaki, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We construct a Prolog-based expert system to reason about the disruption patterns for train system using Bayesian network and Prolog. The disruptions dependencies are modeled using Bayesian network and the reasoning is carried on using Prolog. We choose Bayesian network because it is one of the most efficient and elegant framework to represent and reason probabilistic graphical model. The causative relationship among disruptions is represented using Directed Acyclic Graph (DAG). We use Prolog to improve the efficiency of the reasoning process by defining Bayesian network and its probabilistic information into a knowledge base. The causative relationships among disruptions are also modeled in terms of Prolog rules. Our Prolog-based expert system combines the statistical reasoning capability of Bayesian network and logic programming efficiency. The system provides comprehensive reasoning regarding the causative probability of events, the causative relationship among disruptions, as well as the most triggering and triggered disruptions in train system. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We construct a Prolog-based expert system to reason about the disruption patterns for train system using Bayesian network and Prolog. The disruptions dependencies are modeled using Bayesian network and the reasoning is carried on using Prolog. We choose Bayesian network because it is one of the most efficient and elegant framework to represent and reason probabilistic graphical model. The causative relationship among disruptions is represented using Directed Acyclic Graph (DAG). We use Prolog to improve the efficiency of the reasoning process by defining Bayesian network and its probabilistic information into a knowledge base. The causative relationships among disruptions are also modeled in terms of Prolog rules. Our Prolog-based expert system combines the statistical reasoning capability of Bayesian network and logic programming efficiency. The system provides comprehensive reasoning regarding the causative probability of events, the causative relationship among disruptions, as well as the most triggering and triggered disruptions in train system. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Livelihood resilience: The case of sungai Terengganu communities"
        ],
        "penulis":"Muhamad, Suriyani;Nawawi, Mohd Nasir;Kulub Abd Rashid, Noorhaslinda;Kusairi, Suhal;Nik Mohd Kamil, Nik Fuad;Samsudin, Hazman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Livelihood in river settings may appear simple, but upon closer examination, it is multifaceted and dynamic. The elements of uncertainty in sustaining a satisfactory livelihood are always present. The concept of resilience is about individuals, households or groups making a living and attempting to satisfy their consumption and economic necessities, surviving with uncertainties and responding to new opportunities. The earlier approaches in livelihood studies regarded poor people as inactive or passive victims. However, the trend has changed with greater interest to study on the survival strategies of the poor. In particular, consideration is given to the living experiences of households and the community. The objective of this study is to apply the concept of resilience as a diagnostic approach to the understanding of rural communities' livelihoods. The analysis highlights the resilience aspects of the rural community and their livelihood strategies for comfortable living. \u00a9 Springer Nature Switzerland AG 2019.",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Livelihood in river settings may appear simple, but upon closer examination, it is multifaceted and dynamic. The elements of uncertainty in sustaining a satisfactory livelihood are always present. The concept of resilience is about individuals, households or groups making a living and attempting to satisfy their consumption and economic necessities, surviving with uncertainties and responding to new opportunities. The earlier approaches in livelihood studies regarded poor people as inactive or passive victims. However, the trend has changed with greater interest to study on the survival strategies of the poor. In particular, consideration is given to the living experiences of households and the community. The objective of this study is to apply the concept of resilience as a diagnostic approach to the understanding of rural communities' livelihoods. The analysis highlights the resilience aspects of the rural community and their livelihood strategies for comfortable living. \u00a9 Springer Nature Switzerland AG 2019."
        ]
    },
    {
        "judul":[
            "Sensitivity analysis of thorax imaging using two-dimensional Electrical Impedance Tomography (EIT)"
        ],
        "penulis":"Andiani L.;Rubiyanto A.;Endarko;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Electrical Impedance Tomography (EIT) is a non-invasive medical imaging technique which estimates the electrical impedance distribution within some tissue. The study aimed to assess the performance of the EIT system in a thorax imaging by analysis of sensitivity distribution. Sensitivity distribution was visualized using COMSOL Multiphysics simulation in a human thorax represented as an elliptic cylinder phantom consisting of homogeneous and inhomogeneous medium with varying different dimensions of 16 electrode EIT system. Current density distribution was collected for sensitivity analysis using the neighboring method. The sensitivity distribution at each position in the phantom is different. It is caused by the interaction of current density from transmitter and receiver terminal. The different varying parameter of the system can also influence sensitivity distribution. The sensitivity of inhomogeneous phantom is very non-uniformly distributed. The performance of systems was assessed by analysis of the change of sensitivity with the change of electrode dimensions in the homogeneous and inhomogeneous medium. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electrical Impedance Tomography (EIT) is a non-invasive medical imaging technique which estimates the electrical impedance distribution within some tissue. The study aimed to assess the performance of the EIT system in a thorax imaging by analysis of sensitivity distribution. Sensitivity distribution was visualized using COMSOL Multiphysics simulation in a human thorax represented as an elliptic cylinder phantom consisting of homogeneous and inhomogeneous medium with varying different dimensions of 16 electrode EIT system. Current density distribution was collected for sensitivity analysis using the neighboring method. The sensitivity distribution at each position in the phantom is different. It is caused by the interaction of current density from transmitter and receiver terminal. The different varying parameter of the system can also influence sensitivity distribution. The sensitivity of inhomogeneous phantom is very non-uniformly distributed. The performance of systems was assessed by analysis of the change of sensitivity with the change of electrode dimensions in the homogeneous and inhomogeneous medium. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Few-Bit CSI Acquisition for Centralized Cell-Free Massive MIMO with Spatial Correlation"
        ],
        "penulis":"Maryopi, Dick;Burr, Alister;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The availability and accuracy of Channel State Information (CSI) play a crucial role for coherent detection in almost every communication system. Particularly in the recently proposed cell-free massive MIMO system, in which a large number of distributed Access Points (APs) is connected to a Central processing Unit (CPU) for joint decoding, acquiring CSI at the CPU may improve performance through the use of detection algorithms such as minimum mean square error (MMSE) or zero forcing (ZF). There are also significant challenges, especially the increase in fronthaul load arising from the transfer of high precision CSI, with the resulting complexity and scalability issues. In this paper, we address these CSI acquisition problems by utilizing vector quantization with precision of only a few bits and we show that the accuracy of the channel estimate at the CPU can be increased by exploiting the spatial correlation subject to this limited fronthaul load. Further, we derive an estimator for the simple Quantize-and-Estimate (QE) strategy based on the Bussgang theorem and compare its performance to Estimate-and-Quantize (EQ) in terms of Mean Squared Error (MSE). Our simulation results indicate that the QE with few-bit vector quantization can outperform EQ and individual scalar quantization at moderate SNR for small numbers of bits per dimension. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The availability and accuracy of Channel State Information (CSI) play a crucial role for coherent detection in almost every communication system. Particularly in the recently proposed cell-free massive MIMO system, in which a large number of distributed Access Points (APs) is connected to a Central processing Unit (CPU) for joint decoding, acquiring CSI at the CPU may improve performance through the use of detection algorithms such as minimum mean square error (MMSE) or zero forcing (ZF). There are also significant challenges, especially the increase in fronthaul load arising from the transfer of high precision CSI, with the resulting complexity and scalability issues. In this paper, we address these CSI acquisition problems by utilizing vector quantization with precision of only a few bits and we show that the accuracy of the channel estimate at the CPU can be increased by exploiting the spatial correlation subject to this limited fronthaul load. Further, we derive an estimator for the simple Quantize-and-Estimate (QE) strategy based on the Bussgang theorem and compare its performance to Estimate-and-Quantize (EQ) in terms of Mean Squared Error (MSE). Our simulation results indicate that the QE with few-bit vector quantization can outperform EQ and individual scalar quantization at moderate SNR for small numbers of bits per dimension. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design and Realization Step Frequency Continuous Wave Generator for Ground Penetrating Radar Using Phase-locked Loop"
        ],
        "penulis":"Fajar, Candra Nur;Arseno, Dharu;Edwar;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Ground Penetrating Radar (GPR) is a system that uses the radio wave to detect ground surface or buried object with a certain distance without ruin the soil. One of GPR applications uses the Step Frequency Continuous Waves (SFCW) signal which has a wide bandwidth that is needed to detect a high-resolution object or subsoil structure. Ideally, GPR has a working frequency that can be adjusted as needed by using a programmable signal generator. In this research, a SFCW signal generator was designed and realized using the implementation of Phase Locked-loop (PLL) ADF4351 which is controlled by the Arduino UNO micro controller. The signal generator in this research generates SFCW signals in the frequency range 500 MHz1500 MHz. Experiments were conducted with the number of steps frequency 8, 16 and 32 times. The measurement results for each step frequency show the power varies between-10.41 dBm up to-2.9 dBm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ground Penetrating Radar (GPR) is a system that uses the radio wave to detect ground surface or buried object with a certain distance without ruin the soil. One of GPR applications uses the Step Frequency Continuous Waves (SFCW) signal which has a wide bandwidth that is needed to detect a high-resolution object or subsoil structure. Ideally, GPR has a working frequency that can be adjusted as needed by using a programmable signal generator. In this research, a SFCW signal generator was designed and realized using the implementation of Phase Locked-loop (PLL) ADF4351 which is controlled by the Arduino UNO micro controller. The signal generator in this research generates SFCW signals in the frequency range 500 MHz1500 MHz. Experiments were conducted with the number of steps frequency 8, 16 and 32 times. The measurement results for each step frequency show the power varies between-10.41 dBm up to-2.9 dBm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Personality Classification based on Facebook status text using Multinomial Na\u00efve Bayes method"
        ],
        "penulis":"Artissa Y.B.N.D.;Asror I.;Faraby S.A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Psychological research shows that the way people write is influenced by their personalities. Words that are often used can describe someone's personality. Facebook is one of the social networking sites for users to express themselves. User status posts can be used to identify the user's personality. To find out the personality of a person based on the statuses they write on Facebook use text classification techniques using Multinomial Naive Bayes method. The language is English. The test result shows that accuracy increases after reducing the number of word variations and variations of prior probability values. The accuracy obtained by using stemming in the preprocessing process is 59.9% and using uniform prior increases 0.3%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Psychological research shows that the way people write is influenced by their personalities. Words that are often used can describe someone's personality. Facebook is one of the social networking sites for users to express themselves. User status posts can be used to identify the user's personality. To find out the personality of a person based on the statuses they write on Facebook use text classification techniques using Multinomial Naive Bayes method. The language is English. The test result shows that accuracy increases after reducing the number of word variations and variations of prior probability values. The accuracy obtained by using stemming in the preprocessing process is 59.9% and using uniform prior increases 0.3%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Prototype of automation of organic fertilizer manufacturing systems based on internet of things"
        ],
        "penulis":"Pratama, Yogie Fajar;Ariyanto, Endro;Karimah, Siti Amatullah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Compost is an organic fertilizer made from the remnants of plants, animals and decomposable domestic waste with help from decomposers. The process to make compost is still manually done. Organic remnants and waste are piled and buried to create heat during the composting process. Then, the pile is mixed with hand and shovel to control moisture and temperature. Since ideal temperature and humidity have to be estimated manually, it will affect the decomposing duration. Compost will take more time to make if the mixing process and heat are not distributed well. Based on those problems, this research devises an automatic compost maker prototype which can detect temperature and humidity in the composting process based on Internet of Things, so the data can be processed by fuzzy logic, which also acts as the main control to run the actuator (heater and water pump). Temperature and humidity data from the sensor will be sent to a database, then the fuzzy logic will determine the optimal temperature and humidity for the composting process by activating the actuator which consists of water sprinkler, heater and mixing motor. Based on experiment results, the prototype is able to create compost in 14 days or 2,35 times faster than using the traditional tools that require 33 days. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Compost is an organic fertilizer made from the remnants of plants, animals and decomposable domestic waste with help from decomposers. The process to make compost is still manually done. Organic remnants and waste are piled and buried to create heat during the composting process. Then, the pile is mixed with hand and shovel to control moisture and temperature. Since ideal temperature and humidity have to be estimated manually, it will affect the decomposing duration. Compost will take more time to make if the mixing process and heat are not distributed well. Based on those problems, this research devises an automatic compost maker prototype which can detect temperature and humidity in the composting process based on Internet of Things, so the data can be processed by fuzzy logic, which also acts as the main control to run the actuator (heater and water pump). Temperature and humidity data from the sensor will be sent to a database, then the fuzzy logic will determine the optimal temperature and humidity for the composting process by activating the actuator which consists of water sprinkler, heater and mixing motor. Based on experiment results, the prototype is able to create compost in 14 days or 2,35 times faster than using the traditional tools that require 33 days. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A survey on location-routing-inventory problem"
        ],
        "penulis":"Saragih N.I.;Bahagia S.N.;Suprayogi;Syabri I.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents an overview of location-routing-inventory problem which is a branch of location analysis that takes into account vehicle routing and inventory policy aspects. The aim of this paper is to survey the state of the art in this area based on the model components. Some suggestions for future research are also presented in this paper. \u00a9 2019, Institute of Advanced Scientific Research, Inc.. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents an overview of location-routing-inventory problem which is a branch of location analysis that takes into account vehicle routing and inventory policy aspects. The aim of this paper is to survey the state of the art in this area based on the model components. Some suggestions for future research are also presented in this paper. \u00a9 2019, Institute of Advanced Scientific Research, Inc.. All rights reserved."
        ]
    },
    {
        "judul":[
            "Architecture model of information technology infrastructure based on service quality at government institution"
        ],
        "penulis":"Widjajarto, Adityas;Lubis, Muharman;Yunan, Umar;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Public service activities in several government institutions are currently using information technology services so that information technology services must also have criteria in accordance with the government's vision and mission. One fundamental problem is providing quality and reliable information services that provide infrastructure support that has the capability and capacity. The provision of this infrastructure can be approached with accurate and complete planning and design. The purpose of this research is to produce infrastructure architecture planning and design that forms infrastructure services. As a service, infrastructure architecture has the duty to provide quality and reliable services for end users. Applications and data which are business processes of government institutions require infrastructure parameters that are presented from the service side perception. One way to present infrastructure services for information services in business processes is by planning right before the implementation and deployment phase. At present, the discussion of infrastructure architecture that is widely used is based on the core functions of infrastructure architecture which are limited to the main development and use. These core functions usually focus on availability and modularity (scalability). Availability is usually discussed in the criticality of services that require infrastructure backup. Whereas modularity is related to an increase in the number of users or services. In this study a collaborative role was added, namely an open contribution to the service delivery cycle from the infrastructure section. This open collaborative method is a strategy to \"develop synergies\" between infrastructure service providers and service users (end-users). \u00a9 2019 The Authors.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Public service activities in several government institutions are currently using information technology services so that information technology services must also have criteria in accordance with the government's vision and mission. One fundamental problem is providing quality and reliable information services that provide infrastructure support that has the capability and capacity. The provision of this infrastructure can be approached with accurate and complete planning and design. The purpose of this research is to produce infrastructure architecture planning and design that forms infrastructure services. As a service, infrastructure architecture has the duty to provide quality and reliable services for end users. Applications and data which are business processes of government institutions require infrastructure parameters that are presented from the service side perception. One way to present infrastructure services for information services in business processes is by planning right before the implementation and deployment phase. At present, the discussion of infrastructure architecture that is widely used is based on the core functions of infrastructure architecture which are limited to the main development and use. These core functions usually focus on availability and modularity (scalability). Availability is usually discussed in the criticality of services that require infrastructure backup. Whereas modularity is related to an increase in the number of users or services. In this study a collaborative role was added, namely an open contribution to the service delivery cycle from the infrastructure section. This open collaborative method is a strategy to \"develop synergies\" between infrastructure service providers and service users (end-users). \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Utilizing structured knowledge bases in open IE based event template extraction"
        ],
        "penulis":"Romadhony, Ade;Widyantoro, Dwi H.;Purwarianti, Ayu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Automatic template extraction including event template has been studied intensively in recent years. Researchers study the topic in order to solve the problem of manually defining a template that is required in most information extraction systems. Several studies of event template extraction rely on the documents characteristics to discover the pattern. Although there exist some structured knowledge bases, such as: FrameNet, Predicate Matrix, ACE (Automatic Content Extraction) event type keywords seeds, and FrameNet-ACE event type mapping, no previous researchers have studied combining this information for event template extraction. This paper presents an event template extraction approach that incorporates structured knowledge bases. We propose event template extraction from Open Information Extraction (Open IE) results (relation tuples) in two stages: relation tuple clustering and relation tuple filtering. Both processes utilize structured knowledge bases, as constraint sources in the clustering process and as the basis for the filtering process. The filtering process employs the word embedding representation to capture the semantic relatedness between words. We argue that by involving structured knowledge bases, the relation tuple semantic information can be enriched. Therefore, we can get groups of relation tuples with a similar event sense that represent event templates. The empirical experiment was based on an event argument extraction task and showed that our proposed approach outperforms similar methods that do not use structured knowledge bases. We also compare our proposed system performance to the performance of state-of-the-art systems. The comparison result shows that our proposed system outperforms other state-of-the-art systems, in terms of precision. \u00a9 2018, Springer Science+Business Media, LLC, part of Springer Nature.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Automatic template extraction including event template has been studied intensively in recent years. Researchers study the topic in order to solve the problem of manually defining a template that is required in most information extraction systems. Several studies of event template extraction rely on the documents characteristics to discover the pattern. Although there exist some structured knowledge bases, such as: FrameNet, Predicate Matrix, ACE (Automatic Content Extraction) event type keywords seeds, and FrameNet-ACE event type mapping, no previous researchers have studied combining this information for event template extraction. This paper presents an event template extraction approach that incorporates structured knowledge bases. We propose event template extraction from Open Information Extraction (Open IE) results (relation tuples) in two stages: relation tuple clustering and relation tuple filtering. Both processes utilize structured knowledge bases, as constraint sources in the clustering process and as the basis for the filtering process. The filtering process employs the word embedding representation to capture the semantic relatedness between words. We argue that by involving structured knowledge bases, the relation tuple semantic information can be enriched. Therefore, we can get groups of relation tuples with a similar event sense that represent event templates. The empirical experiment was based on an event argument extraction task and showed that our proposed approach outperforms similar methods that do not use structured knowledge bases. We also compare our proposed system performance to the performance of state-of-the-art systems. The comparison result shows that our proposed system outperforms other state-of-the-art systems, in terms of precision. \u00a9 2018, Springer Science+Business Media, LLC, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "Dynamic Message Puzzle as pre-authentication scheme in wireless sensor networks"
        ],
        "penulis":"Afianti, Farah;Wirawan;Suryani, Titiek;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Denial of Service (DoS) is a type of attack that has a huge impact on a computer system. This can deplete and shorten the lifetime of wireless sensor networks (WSNs). Signature-based DoS is a kind of DoS attack that exploits the high computation of a public key cryptography based authentication. The adversaries have the opportunity to send a large number of a fake signature to the WSNs. Message Specific Puzzle (MSP) was developed to defend against this type of attack. This scheme utilizes a hash function as an irreversible method to create a puzzle and produce a session key. Furthermore, this has low complexity in the sender and receiver for construction and verification process. However, the sender-side delay occurred. The higher the security expected for the system leads to the more time is needed for the user to send messages. The number of hash iteration in the puzzle construction cannot be controlled. This paper proposes the Dynamic Message Puzzle scheme that uses the power of first quartile (Q1power1) and the exponential of second quartile (Q2exp) threshold functions. These limit the maximum number of hash iterations for each puzzle construction. Consequently, this mechanism can decrease sender-side delay by at least 60%. Besides avoiding zero solution and has a high value of mean absolute deviation, this scheme also increases the adversaries' complexity in attacking the system. The proposed scheme transmits index implicitly. This obscures the portion of each parameter in the transmitted packet. \u00a9 2019, Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Denial of Service (DoS) is a type of attack that has a huge impact on a computer system. This can deplete and shorten the lifetime of wireless sensor networks (WSNs). Signature-based DoS is a kind of DoS attack that exploits the high computation of a public key cryptography based authentication. The adversaries have the opportunity to send a large number of a fake signature to the WSNs. Message Specific Puzzle (MSP) was developed to defend against this type of attack. This scheme utilizes a hash function as an irreversible method to create a puzzle and produce a session key. Furthermore, this has low complexity in the sender and receiver for construction and verification process. However, the sender-side delay occurred. The higher the security expected for the system leads to the more time is needed for the user to send messages. The number of hash iteration in the puzzle construction cannot be controlled. This paper proposes the Dynamic Message Puzzle scheme that uses the power of first quartile (Q1power1) and the exponential of second quartile (Q2exp) threshold functions. These limit the maximum number of hash iterations for each puzzle construction. Consequently, this mechanism can decrease sender-side delay by at least 60%. Besides avoiding zero solution and has a high value of mean absolute deviation, this scheme also increases the adversaries' complexity in attacking the system. The proposed scheme transmits index implicitly. This obscures the portion of each parameter in the transmitted packet. \u00a9 2019, Insight Society."
        ]
    },
    {
        "judul":[
            "Automated social media account identification using Simplified Brute Force"
        ],
        "penulis":"Harianto G.;Setiawan E.B.;Murti Y.R.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Social media is a media where millions of people can connect and obtain information through the Internet network. The features provided by social media has made it easier to exchange data on the internet. Social media has covered so many people who have more than one social media account. Day by day the number of social media users has increased and has reached a huge number plus everyone can have more than one account. This huge amount makes social media into a data warehouse that can be used to obtain information. By crawling data on multiple social media at once, the search process will be faster so that we can identify accounts on more than one social media at once. In this research, we will crawl to some social media at once using DOM Parser. After the data collected, we performed the matching using the simplified Brute Force algorithm with a time efficiency of 78,16% where Facebook received the highest 90% accuracy on unverified account identification and Instagram received the highest 80% accuracy for verified account identification. We apply crawling to obtain account information from several social media as well as directly. The crawling process uses the DOM structure to parse the content on the site and SQL to insert data into the database. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Social media is a media where millions of people can connect and obtain information through the Internet network. The features provided by social media has made it easier to exchange data on the internet. Social media has covered so many people who have more than one social media account. Day by day the number of social media users has increased and has reached a huge number plus everyone can have more than one account. This huge amount makes social media into a data warehouse that can be used to obtain information. By crawling data on multiple social media at once, the search process will be faster so that we can identify accounts on more than one social media at once. In this research, we will crawl to some social media at once using DOM Parser. After the data collected, we performed the matching using the simplified Brute Force algorithm with a time efficiency of 78,16% where Facebook received the highest 90% accuracy on unverified account identification and Instagram received the highest 80% accuracy for verified account identification. We apply crawling to obtain account information from several social media as well as directly. The crawling process uses the DOM structure to parse the content on the site and SQL to insert data into the database. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Empirical testing of the implementation of supply chain management and successful supporting factors of management accounting information systems"
        ],
        "penulis":"Suzan, Leny;Mulyani, Sri;Sukmadilaga, Citra;Farida, Ida;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study aims to measure empirically tested conceptual models regarding the magnitude of intellectual capital influence, operational risk management, and business strategy on the effectiveness of management accounting information systems and their implications on the performance of a balanced scorecard based company. This research used sensus as sampling technique, it used all existing population. This research was conducted using a survey method in Banking Sectors in Indonesia based on the supply chain management. Data analysis was performed using Structural Equation Model (SEM) approach alongside a Linear Structural Relationship (LISREL) analysis tool. The results of the study found that intellectual capital, operational risk management, and business strategy have a significant positive effect on the effectiveness of accounting information system; while its significance on the performance of balanced scorecard based company, operational risk management and business strategy alone has a significant positive effect. While the effectiveness of accounting information systems are known to have significant implications on the company's performance-based balanced scorecard. \u00a9 ExcelingTech Pub, UK.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to measure empirically tested conceptual models regarding the magnitude of intellectual capital influence, operational risk management, and business strategy on the effectiveness of management accounting information systems and their implications on the performance of a balanced scorecard based company. This research used sensus as sampling technique, it used all existing population. This research was conducted using a survey method in Banking Sectors in Indonesia based on the supply chain management. Data analysis was performed using Structural Equation Model (SEM) approach alongside a Linear Structural Relationship (LISREL) analysis tool. The results of the study found that intellectual capital, operational risk management, and business strategy have a significant positive effect on the effectiveness of accounting information system; while its significance on the performance of balanced scorecard based company, operational risk management and business strategy alone has a significant positive effect. While the effectiveness of accounting information systems are known to have significant implications on the company's performance-based balanced scorecard. \u00a9 ExcelingTech Pub, UK."
        ]
    },
    {
        "judul":[
            "Discrete Wavelet Transform on static hand gesture recognition"
        ],
        "penulis":"Candrasari, Erizka Banuwati;Novamizanti, Ledya;Aulia, Suci;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The technology in present-day is very useful for human-physical recognition and the hand gesture recognition is one of them. Nevertheless, that technology still had various weakness, for example in the image brightness, contrast, recognition time, and accuracy rate. The objective of this paper was to construct hand gesture recognition system using RGB images. Pre-processing is wrought by resizing the image, separate the hand area, and pick the specific layer. This experiment used the YCbCr because its derived directly from RGB and had a higher contrast compared to other layers. The feature value was gathered from feature extraction on Discrete Wavelet Transform (DWT) using Low-Low sub-band and 2ndlevel decomposition. The current sub-band had smoothest contours in comparison with other sub-band. The final process was gesture classification using Hidden Markov Models (HMM) and K-Nearest Neighbor (KNN). The amount of training and testing data used were 150 and 100 images respectively, divided into five gestures with accuracy using HMM and KNN consecutively was 58% and 100%. The research novelty was that the classification impacted positively on accuracy level. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The technology in present-day is very useful for human-physical recognition and the hand gesture recognition is one of them. Nevertheless, that technology still had various weakness, for example in the image brightness, contrast, recognition time, and accuracy rate. The objective of this paper was to construct hand gesture recognition system using RGB images. Pre-processing is wrought by resizing the image, separate the hand area, and pick the specific layer. This experiment used the YCbCr because its derived directly from RGB and had a higher contrast compared to other layers. The feature value was gathered from feature extraction on Discrete Wavelet Transform (DWT) using Low-Low sub-band and 2ndlevel decomposition. The current sub-band had smoothest contours in comparison with other sub-band. The final process was gesture classification using Hidden Markov Models (HMM) and K-Nearest Neighbor (KNN). The amount of training and testing data used were 150 and 100 images respectively, divided into five gestures with accuracy using HMM and KNN consecutively was 58% and 100%. The research novelty was that the classification impacted positively on accuracy level. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Development of Flexible Production Scheduling by Applying Gantt Charts in Manufacturing Module Open Source ERP (Case Study CV. XYZ)"
        ],
        "penulis":"Nafianto, Chandratya;Puspitasari, Warih;Saputra, Muhardi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "CV. XYZ is a manufacturing company engaged in the textile industry producing t-shirts, cotton fabrics, and various other textile products. One of the business processes in the CV. XYZ is the production section. The main problems in the production section are the absence of a system that relates between production department and warehouse department in carrying out business processes and does not have any reports. Development of Enterprise Resource Planning (ERP) can be a solution for CV. XYZ. Odoo is one of open source ERP software that is widely used by various types of companies. The development of CV. XYZ uses the Odoo Quickstart Methodology. This methodology can implement the completion process on time and the costs needed can be adjusted to the project. The purpose of the development of CV. XYZ is to make their business processes can be accessed effectively and efficiently with the flexible production scheduling system. Once the ERP implementation is finished the system is measured using System Usability Scale (SUS) to measure the system usefulness based on the SUS result, the ERP implementation has succeed and acceptable. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "CV. XYZ is a manufacturing company engaged in the textile industry producing t-shirts, cotton fabrics, and various other textile products. One of the business processes in the CV. XYZ is the production section. The main problems in the production section are the absence of a system that relates between production department and warehouse department in carrying out business processes and does not have any reports. Development of Enterprise Resource Planning (ERP) can be a solution for CV. XYZ. Odoo is one of open source ERP software that is widely used by various types of companies. The development of CV. XYZ uses the Odoo Quickstart Methodology. This methodology can implement the completion process on time and the costs needed can be adjusted to the project. The purpose of the development of CV. XYZ is to make their business processes can be accessed effectively and efficiently with the flexible production scheduling system. Once the ERP implementation is finished the system is measured using System Usability Scale (SUS) to measure the system usefulness based on the SUS result, the ERP implementation has succeed and acceptable. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "IT Roadmap to Improve Business Strategy using TOGAF ADM: A Case Study of Government-Owned Electricity Company"
        ],
        "penulis":"Thea Nisaa'Andi S.;Asti Amalia N.F.;Lubis, Muharman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Service industry in Indonesua has applied IT to conduct and establish their business process through automation and integration in order to achieve effectiveness and efficiency, especially in the industry of electricity. However, there is still no alignment between business strategy and IT assets. Thus, it is necessary to implement Enterprise Architecture to have appropriateness between the organizational's goal and the strategy's execution in the field. This research identifies various components in the respected industry by implement TOGAF ADM as the framework through observation and interview, with begin with preliminary phase until migration planning. The purpose is to create IT Roadmap in the form of recommendation for the electricity company in order to achieve their short and long term objectives. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Service industry in Indonesua has applied IT to conduct and establish their business process through automation and integration in order to achieve effectiveness and efficiency, especially in the industry of electricity. However, there is still no alignment between business strategy and IT assets. Thus, it is necessary to implement Enterprise Architecture to have appropriateness between the organizational's goal and the strategy's execution in the field. This research identifies various components in the respected industry by implement TOGAF ADM as the framework through observation and interview, with begin with preliminary phase until migration planning. The purpose is to create IT Roadmap in the form of recommendation for the electricity company in order to achieve their short and long term objectives. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Exploring the User Engagement Factors in Computer Mediated Communication"
        ],
        "penulis":"Lubis, Muharman;Khairiansyah, Alfi;Jafar Adrian, Qadhli;Almaarif, Ahmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "User engagement can be defined as the perception of the user to qualify the experience towards certain application, which focus on the positive aspects of the interaction through Internet in the context of the desire to use it continuously and for longer time. It is fundamental concept in the design of online applications regardless of the platform, driven by the observation that successful applications are not only used but those that work. However, user engagement in the technology advancement is a paradox phenomenon, as they recognize the potentiality but reluctant to adopt or they realize its use to solve problem but prefer the other solution for longer of time. The usual ways to evaluate them can be through self-report measures, observational methods, speech analysis or web analytics. These methods represent different compensations in term of configuration, the size of object and the scale of data to be collected. For example, some study might find detail and deep analysis but they are limited in term of generalizability, while the other might found out resourceful but denies the user reasoning and the context. During this millennial, the diffusion of innovation became the acceptable theory that majority academician and practical expert use to explain the phenomenon of the reason and factor to adopt certain product. Therefore, due to the assumption of several factors such as technology advancement and paradigm shift, this study want to explore current situation in the user engagement factors, which focused to computer mediated communication. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "User engagement can be defined as the perception of the user to qualify the experience towards certain application, which focus on the positive aspects of the interaction through Internet in the context of the desire to use it continuously and for longer time. It is fundamental concept in the design of online applications regardless of the platform, driven by the observation that successful applications are not only used but those that work. However, user engagement in the technology advancement is a paradox phenomenon, as they recognize the potentiality but reluctant to adopt or they realize its use to solve problem but prefer the other solution for longer of time. The usual ways to evaluate them can be through self-report measures, observational methods, speech analysis or web analytics. These methods represent different compensations in term of configuration, the size of object and the scale of data to be collected. For example, some study might find detail and deep analysis but they are limited in term of generalizability, while the other might found out resourceful but denies the user reasoning and the context. During this millennial, the diffusion of innovation became the acceptable theory that majority academician and practical expert use to explain the phenomenon of the reason and factor to adopt certain product. Therefore, due to the assumption of several factors such as technology advancement and paradigm shift, this study want to explore current situation in the user engagement factors, which focused to computer mediated communication. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Array Antenna for Doppler Spread Compensator on High Speed Railway"
        ],
        "penulis":"Anbela, Dano Seto;Anwar, Khoirul;Yunita, Trasma;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Train movements on the high speed railway causes signal damage due to the Doppler effect. In this situation, The Doppler Spread Compensator (DSC) technique plays an important role in the rapid train technology. This paper proposes an array antenna as DSC. The antenna is designed based on a rectangular patch microstrip array antenna for high speed railway. As a Doppler spread compensator, antennas is designed for the Future Railway for Mobile Communication System technology (FRMCS). The material used on the substrate is FR4 Epoxy and the ground plane and patch using copper. The antenna is designed to have a large dimension suitable for covering along the train. The realization of the antenna was good enough. The simulated and measured results of the antenna, such as magnitude of the reflection coefficient (S11), Gain, and Radiation Patterns are all presented in this paper. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Train movements on the high speed railway causes signal damage due to the Doppler effect. In this situation, The Doppler Spread Compensator (DSC) technique plays an important role in the rapid train technology. This paper proposes an array antenna as DSC. The antenna is designed based on a rectangular patch microstrip array antenna for high speed railway. As a Doppler spread compensator, antennas is designed for the Future Railway for Mobile Communication System technology (FRMCS). The material used on the substrate is FR4 Epoxy and the ground plane and patch using copper. The antenna is designed to have a large dimension suitable for covering along the train. The realization of the antenna was good enough. The simulated and measured results of the antenna, such as magnitude of the reflection coefficient (S11), Gain, and Radiation Patterns are all presented in this paper. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Competencies for effective public middle managers"
        ],
        "penulis":"Sudirman, Iman;Siswanto, Joko;Monang, Joe;Aisha, Atya Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose: The purpose of this paper is to investigate a set of competencies that characterizes effective public middle managers. Design\/methodology\/approach: A total of 20 middle managers from several public agencies were interviewed in person using the behavioral event interview technique. In all, 80 stories were deductively coded based on the existing National Civil Service Agency\u2019s managerial competency dictionary and inductively examined through a thematic analysis to discover new themes. Findings: This study\u2019s findings suggest that communication, organizing, information seeking, analytical thinking and planning competencies are common competencies, but essential for effective public middle managers. Conversely, achievement orientation, leadership, directiveness, persuasiveness and innovation are competencies that characterize effective public middle managers and distinguish them from average performers. In addition, some other new competencies inductively obtained using a thematic analysis are also important for effective public managers: adherence to laws and regulations, multi-stakeholder collaboration, and technical competencies (technology management, human resource management and financial management). Research limitations\/implications: The research was undertaken using 20 samples divided into superior and average performers; thus, it is limited to developing competency levels to new competencies. Originality\/value: This study identifies the competencies necessary for effective middle managers within the public sector context. Conducting behavioral event interviews with two distinct groups provides empirically unique behavioral evidence of competencies that characterize effective public middle managers and enables to discover new competencies. \u00a9 2019, Emerald Publishing Limited.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: The purpose of this paper is to investigate a set of competencies that characterizes effective public middle managers. Design\/methodology\/approach: A total of 20 middle managers from several public agencies were interviewed in person using the behavioral event interview technique. In all, 80 stories were deductively coded based on the existing National Civil Service Agency\u2019s managerial competency dictionary and inductively examined through a thematic analysis to discover new themes. Findings: This study\u2019s findings suggest that communication, organizing, information seeking, analytical thinking and planning competencies are common competencies, but essential for effective public middle managers. Conversely, achievement orientation, leadership, directiveness, persuasiveness and innovation are competencies that characterize effective public middle managers and distinguish them from average performers. In addition, some other new competencies inductively obtained using a thematic analysis are also important for effective public managers: adherence to laws and regulations, multi-stakeholder collaboration, and technical competencies (technology management, human resource management and financial management). Research limitations\/implications: The research was undertaken using 20 samples divided into superior and average performers; thus, it is limited to developing competency levels to new competencies. Originality\/value: This study identifies the competencies necessary for effective middle managers within the public sector context. Conducting behavioral event interviews with two distinct groups provides empirically unique behavioral evidence of competencies that characterize effective public middle managers and enables to discover new competencies. \u00a9 2019, Emerald Publishing Limited."
        ]
    },
    {
        "judul":[
            "Comparison of Machine Learning Classification Method on Text-based Case in Twitter"
        ],
        "penulis":"Telnoni, Patrick Adolf;Budiawan, Reza;Qana'a, Mutia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "As Artificial Intelligence (AI) and Machine Learning (ML) gaining momentum on industry and academic field, a deeper understanding for AI and ML are highly required. One of the most popular sub-field in this field is text analysis. This paper will discuss the performance of classification methods for text-based data and give the best choices of classification method in term of accuracy and training time, so that will help ML enthusiast to build ML project that does not require high computational cost. This paper aimed to give recommendation to practitioner and academic about which classifier best for text classification. This paper will limit its study in supervised learning only. The tested algorithm will be Support Vector Machine, Logistic Regression, Naive Bayes, Random Forest, and K-Nearest Neighbor. To simplify the project, text will be labelled into single-label data, not multi-label. The test shows that SVM gives best result, in term of accuracy and training time among other methods. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "As Artificial Intelligence (AI) and Machine Learning (ML) gaining momentum on industry and academic field, a deeper understanding for AI and ML are highly required. One of the most popular sub-field in this field is text analysis. This paper will discuss the performance of classification methods for text-based data and give the best choices of classification method in term of accuracy and training time, so that will help ML enthusiast to build ML project that does not require high computational cost. This paper aimed to give recommendation to practitioner and academic about which classifier best for text classification. This paper will limit its study in supervised learning only. The tested algorithm will be Support Vector Machine, Logistic Regression, Naive Bayes, Random Forest, and K-Nearest Neighbor. To simplify the project, text will be labelled into single-label data, not multi-label. The test shows that SVM gives best result, in term of accuracy and training time among other methods. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Study on C-band electromagnetic wave absorber made of S-ring resonator"
        ],
        "penulis":"Lanang, Farhan Fathir;Nur, Levy Olivia;Syihabuddin, Budi;Nugroho, Bambang Setia;Prasetyo, Agus D.;Wijanto, Heroe;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents the characterization of rectangular s-ring resonator as an electromagnetic wave absorber for C band. The structure consists of copper s-ring patch in the top layer, FR-4 dielectric substrate, and the back is fully copper laminated. The initial dimension has 7 mm \u00d7 7 mm with the thickness of FR4 is 1 mm. The characterization observes the changes of each variable from the initial design that affect the shift in resonant frequency and bandwidth. Maximum bandwidth can be achieved at S-Ring length 4.4 mm for 0.0941 GHz. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents the characterization of rectangular s-ring resonator as an electromagnetic wave absorber for C band. The structure consists of copper s-ring patch in the top layer, FR-4 dielectric substrate, and the back is fully copper laminated. The initial dimension has 7 mm \u00d7 7 mm with the thickness of FR4 is 1 mm. The characterization observes the changes of each variable from the initial design that affect the shift in resonant frequency and bandwidth. Maximum bandwidth can be achieved at S-Ring length 4.4 mm for 0.0941 GHz. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Smart Bus Arrival Notification for Visually Impaired"
        ],
        "penulis":"Herdiansyah, Puri;Hapsari, Gita Indah;Mutiara, Giva Andriana;Meisaroh, Lisda;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Public transportation such as a bus is often used to travel to various places in Indonesia. Each bus will only stop at each bus stop transit. However, the bus stop transit in Indonesia, especially at Bandung city, is not friendly to disable person like visually impaired people. In this research, a smart public transportation bus stop transit is designed and implemented, which can inform the identities of the next arrival bus through sound and text display. This research purposed to provide a device which gives a natural movement for the visually impaired in using public transportation and reducing the dependence on other people in doing daily activities in their lives. This system is using NRF24L01 as a sender and receiver the data between bus and the bus stop transit. According to the testing result, this system can transmit the information about 30 meters from the bus stop transit. The delay occurs around 2-3 seconds for a single coming bus, and 5-6 seconds to the bus which arrived into the bus stop platform at the same time. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Sustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Public transportation such as a bus is often used to travel to various places in Indonesia. Each bus will only stop at each bus stop transit. However, the bus stop transit in Indonesia, especially at Bandung city, is not friendly to disable person like visually impaired people. In this research, a smart public transportation bus stop transit is designed and implemented, which can inform the identities of the next arrival bus through sound and text display. This research purposed to provide a device which gives a natural movement for the visually impaired in using public transportation and reducing the dependence on other people in doing daily activities in their lives. This system is using NRF24L01 as a sender and receiver the data between bus and the bus stop transit. According to the testing result, this system can transmit the information about 30 meters from the bus stop transit. The delay occurs around 2-3 seconds for a single coming bus, and 5-6 seconds to the bus which arrived into the bus stop platform at the same time. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Comparison of Real Time Iterative Deepening Best First Search Algorithm and A\u2217 Algorithm on Maze Chase Game NPC"
        ],
        "penulis":"Nabil, Husein;Nasution, Surya Michrandi;Nugrahaeni, Ratna Astuti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Maze Chase is a game that has a maze background. In this game there are players who have the task, which is to take all the points in the labyrinth. In the Maze Chase game there is also an NPC (Non-Playable Character) that aims to chase players so that players cannot take all the points in the labyrinth. Players can be considered to have won the game is that all the points in the labyrinth have been taken by the player. The author implements the A\u2217 and RIBS path search algorithms for NPCs so that NPCs can chase players. That way we get the travel time comparison to the players on each path search algorithm. After testing the average travel time to NPC players with the A\u2217 algorithm faster 0.116196% than NPC with the RIBS algorithm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Maze Chase is a game that has a maze background. In this game there are players who have the task, which is to take all the points in the labyrinth. In the Maze Chase game there is also an NPC (Non-Playable Character) that aims to chase players so that players cannot take all the points in the labyrinth. Players can be considered to have won the game is that all the points in the labyrinth have been taken by the player. The author implements the A\u2217 and RIBS path search algorithms for NPCs so that NPCs can chase players. That way we get the travel time comparison to the players on each path search algorithm. After testing the average travel time to NPC players with the A\u2217 algorithm faster 0.116196% than NPC with the RIBS algorithm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Labor Market and Household Debt in Asia Pacific Countries: Dynamic Heterogeneous Panel Data Analysis"
        ],
        "penulis":"Kusairi, Suhal;Muhamad, Suriyani;Musdholifah, M;Chang, Shu-Chen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "An overwhelming increase in household debt in the last decade has stirred researchers to explore the determinants of this phenomena, especially the role of the labor market. This paper comes to identify these determinants using the macro panel data from Asia Pacific countries for 1994-2016 and dynamic heterogeneous panel data analysis. The empirical results found that household consumption, housing price index, and labor force have a long-run positive relationship with household debt. In contrast, the unemployment rate and dependency ratio have a long-run negative relationship with household debt. This implies that when consumption, housing price, and labor force increase, then the household debt will increase, and when the unemployment rate and dependency ratio increase, the household debt will decrease. Also, in the short-run, public debt does affect private consumption, and it is not different among countries. The labor market, as represented by the unemployment rate, dependency ratio, and labor force, has a strong effect on the household debt in the long-run. Based on these findings, the government should pay more attention to the household debt related to property and commodity markets because they expose the short-run volatility and create problems for the long-term. \u00a9 2019 World Scientific Publishing Company.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An overwhelming increase in household debt in the last decade has stirred researchers to explore the determinants of this phenomena, especially the role of the labor market. This paper comes to identify these determinants using the macro panel data from Asia Pacific countries for 1994-2016 and dynamic heterogeneous panel data analysis. The empirical results found that household consumption, housing price index, and labor force have a long-run positive relationship with household debt. In contrast, the unemployment rate and dependency ratio have a long-run negative relationship with household debt. This implies that when consumption, housing price, and labor force increase, then the household debt will increase, and when the unemployment rate and dependency ratio increase, the household debt will decrease. Also, in the short-run, public debt does affect private consumption, and it is not different among countries. The labor market, as represented by the unemployment rate, dependency ratio, and labor force, has a strong effect on the household debt in the long-run. Based on these findings, the government should pay more attention to the household debt related to property and commodity markets because they expose the short-run volatility and create problems for the long-term. \u00a9 2019 World Scientific Publishing Company."
        ]
    },
    {
        "judul":[
            "A comparison of Neural Network and SVM on the multi-label classification of Quran verses topic in English translation"
        ],
        "penulis":"Nurfikri, Fahmi Salman;Adiwijaya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indeed the Quran is the main guideline for Muslims. The enticing thing in the Quran is one verse of the Quran can be classified into more than one topic of discussion in the Quran, for example one verse discusses about prayer and faith or arkanul Islam and religions, thus this called multilabel case. In this study, we compared the multi-label Quran verse topic classification techniques using Naive bayes, ANN and SVM. Based on the experiment conducted, combination Naive Bayes algorithm with Mutual Information or Information Gain gives the best performance when it applied to construct the model with Hamming Loss of 0.0938. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indeed the Quran is the main guideline for Muslims. The enticing thing in the Quran is one verse of the Quran can be classified into more than one topic of discussion in the Quran, for example one verse discusses about prayer and faith or arkanul Islam and religions, thus this called multilabel case. In this study, we compared the multi-label Quran verse topic classification techniques using Naive bayes, ANN and SVM. Based on the experiment conducted, combination Naive Bayes algorithm with Mutual Information or Information Gain gives the best performance when it applied to construct the model with Hamming Loss of 0.0938. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Effectiveness of Digital Marketing for Show Up Company: Issues and Challenges"
        ],
        "penulis":"Kusumawati, Niken Febriani;Kusumasari, Tien Fabrianti;Lubis, Muharman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this decade, start-up companies have played an essential role in the global economy and their existences have grown significantly to maintain the rise of economy domestically and internationally. Therefore, this kind of companies have struggle to gain foothold in the competitive market because some of them produce kind of complex products or weird service that find difficulty in term of engagement with market entrance and targeted customer due to several reasons. One of primary reason is that most of them cannot establish proper marketing strategy and maintain the channel for communication in order to raise attractiveness to the potential customers. The purpose of this study is aiming to investigate the effectiveness of digital marketing in a start-up company, which in this case focus on social media platform of influencers and promoters. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this decade, start-up companies have played an essential role in the global economy and their existences have grown significantly to maintain the rise of economy domestically and internationally. Therefore, this kind of companies have struggle to gain foothold in the competitive market because some of them produce kind of complex products or weird service that find difficulty in term of engagement with market entrance and targeted customer due to several reasons. One of primary reason is that most of them cannot establish proper marketing strategy and maintain the channel for communication in order to raise attractiveness to the potential customers. The purpose of this study is aiming to investigate the effectiveness of digital marketing in a start-up company, which in this case focus on social media platform of influencers and promoters. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Towards co-creation strategy and organizational agility based on customer experience orientation to shape transformational performance"
        ],
        "penulis":"Mihardjo, Leonardus W. Wasono;Sasmoko, Firdaus Alamsyah;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 5.0 is a step after digitalization and digitation has been accomplished. The collaboration, service orientation, agility and customer experience become a critical in this dynamic environment. Hence, the firm strategy has shifted from a competition strategy to a col-laboration strategy. Collaboration with customers is effected through co-creation Strategy (CCS). It could enable the firms in accelerating digital transformation. This study of the development of co-creation strategy focuses on customer experience orientation (CXO) and organization agility (OA) to support transformational performance (TP) in terms of relationship among variables and an empirical study has been conducted. Hence, in this paper, we propose a model of digital transformation for ICT Industry based on co-creation of strategy focused on customer experience orientation and organization agility. The study is based on an empirical study of 195 Indonesian ICT firms. The findings from this analysis reveal the concept of Service Dominant logic (S-D Logic) where the Co-creation capability and organizational agilities can suffice. \u00a9 2019 Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 5.0 is a step after digitalization and digitation has been accomplished. The collaboration, service orientation, agility and customer experience become a critical in this dynamic environment. Hence, the firm strategy has shifted from a competition strategy to a col-laboration strategy. Collaboration with customers is effected through co-creation Strategy (CCS). It could enable the firms in accelerating digital transformation. This study of the development of co-creation strategy focuses on customer experience orientation (CXO) and organization agility (OA) to support transformational performance (TP) in terms of relationship among variables and an empirical study has been conducted. Hence, in this paper, we propose a model of digital transformation for ICT Industry based on co-creation of strategy focused on customer experience orientation and organization agility. The study is based on an empirical study of 195 Indonesian ICT firms. The findings from this analysis reveal the concept of Service Dominant logic (S-D Logic) where the Co-creation capability and organizational agilities can suffice. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Face image super-resolution using inception residual network and GAN framework"
        ],
        "penulis":"Indradi, Septian Dwi;Arifianto, Anditya;Ramadhani, Kurniawan Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Single Image Super-Resolution (SISR) is an image reconstruction technique that aims to generate a high-resolution image from a low-resolution image. One of the SISR implementations is to reconstruct face images in order to gain more facial information from a low-resolution face images. In this paper, we propose a method to reconstruct face images using a Generative Adversarial Network (GAN) framework that able to generate plausible high-resolution images. Inside the GAN framework, we use inception residual network to improve the generated image quality and stabilize the training. Experimental results demonstrated that our proposed method was able to generate visually pleasant face images with the highest PSNR score of 26.615 and SSIM score of 0.8461. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Single Image Super-Resolution (SISR) is an image reconstruction technique that aims to generate a high-resolution image from a low-resolution image. One of the SISR implementations is to reconstruct face images in order to gain more facial information from a low-resolution face images. In this paper, we propose a method to reconstruct face images using a Generative Adversarial Network (GAN) framework that able to generate plausible high-resolution images. Inside the GAN framework, we use inception residual network to improve the generated image quality and stabilize the training. Experimental results demonstrated that our proposed method was able to generate visually pleasant face images with the highest PSNR score of 26.615 and SSIM score of 0.8461. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Named-entity recognition on Indonesian tweets using bidirectional LSTM-CRF"
        ],
        "penulis":"Wintaka, Deni Cahya;Bijaksana, Moch Arif;Asror, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The massive amount of Twitter data allow it to be analyzed using Named-Entity Recognition. Named-Entity Recognition (NER) is a sub-task of Information Extraction that can recognize entities in a text. Most NERs are trained to handle formal text such as news articles, but when applied to informal texts such as tweets, it provides poor performance. The limited number of words, informal and messy grammar on tweets makes it difficult to classify the entities needed. In this study, it was built the model using a combination of deep learning and machine learning approaches, Bidirectional Long Short-Term Memory (BLSTM) and Conditional Random Field (CRF) as the solutions. Entities identified in the form of Person, Location and Organization. The corpus tested included 600 Indonesian tweets comprising 250 formal tweets and 350 informal tweets. The model got the best F1score results by adding the word embedding type FastText, which are 86,13% for formal tweets, 81,17% for informal tweets, and 84,11% for combined tweets. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The massive amount of Twitter data allow it to be analyzed using Named-Entity Recognition. Named-Entity Recognition (NER) is a sub-task of Information Extraction that can recognize entities in a text. Most NERs are trained to handle formal text such as news articles, but when applied to informal texts such as tweets, it provides poor performance. The limited number of words, informal and messy grammar on tweets makes it difficult to classify the entities needed. In this study, it was built the model using a combination of deep learning and machine learning approaches, Bidirectional Long Short-Term Memory (BLSTM) and Conditional Random Field (CRF) as the solutions. Entities identified in the form of Person, Location and Organization. The corpus tested included 600 Indonesian tweets comprising 250 formal tweets and 350 informal tweets. The model got the best F1score results by adding the word embedding type FastText, which are 86,13% for formal tweets, 81,17% for informal tweets, and 84,11% for combined tweets. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "Analysis of Double indian Ballbreaker Net Sorter Machine Based on Overall Equipment Effectiveness Method Cases in Tea Plantation Plants"
        ],
        "penulis":"Alhilman J.;Abdillah A.F.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In a factory, the position of the production machine plays an important role because if the engine is damaged it will disrupt the production target. This study analyzes the performance of Double Indian Ballbreaker Net Sorter (DIBN) machines, one of the machines used to produce orthodox tea which in the fact, this machine often damaged and has high downtime. This leads to a low level of machine availability in the Production Department. For that, we need an Overall Equipment Effectiveness (OEE) method to measure the performance and the level of effectiveness of the machine and six big losses factor analysis to find out what factors cause low of OEE value. Based on the OEE calculation results, the value of OEE DIBN machine is 53.98%. The result is still far from the standard set by the Japanese Institute of Plant Maintenance of 85%. From six big losses, it is known that the most influencing factors to decrease the effectiveness of DIBN machines are rework losses (23.33%), reduced yield losses (20.17%) and reduced speed of 19.49%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a factory, the position of the production machine plays an important role because if the engine is damaged it will disrupt the production target. This study analyzes the performance of Double Indian Ballbreaker Net Sorter (DIBN) machines, one of the machines used to produce orthodox tea which in the fact, this machine often damaged and has high downtime. This leads to a low level of machine availability in the Production Department. For that, we need an Overall Equipment Effectiveness (OEE) method to measure the performance and the level of effectiveness of the machine and six big losses factor analysis to find out what factors cause low of OEE value. Based on the OEE calculation results, the value of OEE DIBN machine is 53.98%. The result is still far from the standard set by the Japanese Institute of Plant Maintenance of 85%. From six big losses, it is known that the most influencing factors to decrease the effectiveness of DIBN machines are rework losses (23.33%), reduced yield losses (20.17%) and reduced speed of 19.49%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "GNSS interference reduction method for CORS site planning"
        ],
        "penulis":"Septiawan, Reza;AgungSyetiawan;Rufiyanto, Arief;Taufik, Nashrullah;Sulistya, Budi;Putro, Erik Madyo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Precision, Navigation, and Timing (PNT) system based on Global Navigation Satellite System (GNSS) becomes significant in the air, land, and sea traffic management. Integrity of GNSS is significant to provide a reliable real time PNT system such as CORS (Continuously Operating Reference Stations). GNSS Interference due to intentional or unintentional surrounding signal source may decrease the integrity of GNSS signal. Monitoring and identification of potential GNSS interference sources in the surrounding environment of CORS is significant. This paper proposed a methodology to reduce potential GNSS interference in a planned CORS site by first simulating the radiation pattern of potential source of interference to GNSS signal in the planned CORS sites. Thereafter ambient noise levels in the location of CORS may be measured to provide a reference point for analyzing the other potential sources of interferences. Based on these results, optimal location of CORS is chosen with the lowest possible unintentional interference signal from their surrounding. Measurement has been conducted in the location of CORS owned by BIG (Indonesian Agency for Geospatial Information), which is located in the rooftop of a building neara telecommunication tower.This method is necessary for CORS site planning to reduce potential GNSS interference sources in the environment of alternative sites. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Precision, Navigation, and Timing (PNT) system based on Global Navigation Satellite System (GNSS) becomes significant in the air, land, and sea traffic management. Integrity of GNSS is significant to provide a reliable real time PNT system such as CORS (Continuously Operating Reference Stations). GNSS Interference due to intentional or unintentional surrounding signal source may decrease the integrity of GNSS signal. Monitoring and identification of potential GNSS interference sources in the surrounding environment of CORS is significant. This paper proposed a methodology to reduce potential GNSS interference in a planned CORS site by first simulating the radiation pattern of potential source of interference to GNSS signal in the planned CORS sites. Thereafter ambient noise levels in the location of CORS may be measured to provide a reference point for analyzing the other potential sources of interferences. Based on these results, optimal location of CORS is chosen with the lowest possible unintentional interference signal from their surrounding. Measurement has been conducted in the location of CORS owned by BIG (Indonesian Agency for Geospatial Information), which is located in the rooftop of a building neara telecommunication tower.This method is necessary for CORS site planning to reduce potential GNSS interference sources in the environment of alternative sites. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "An LSTM-based Spell Checker for Indonesian Text"
        ],
        "penulis":"Zaky, Damar;Romadhony, Ade;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A spell checker is a tool for detecting and correcting various spelling errors. While it might be trivial for humans, spell detecting and correcting can be very useful for machines, because machines could not detect spelling errors and correct them automatically. In Natural Language Processing (NLP), detecting and correcting spelling errors is a task that has been widely performed to normalize data, since most raw texts are noisy and have many spelling errors. In recent years, Long Short-Term Memory (LSTM) has shown to give an extraordinary result in solving sequential problems, including spelling correction. In this paper, we propose an LSTM model that encodes input word at character level, that also uses word and POS tag contexts as features. We performed the experiment on an artificial dataset based on Indonesian Wikipedia articles that we made by simulating some artificial spelling errors at character level and tested it on real dataset, mostly are Indonesian online news articles. The evaluation on test dataset gives 83.76% accuracy. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A spell checker is a tool for detecting and correcting various spelling errors. While it might be trivial for humans, spell detecting and correcting can be very useful for machines, because machines could not detect spelling errors and correct them automatically. In Natural Language Processing (NLP), detecting and correcting spelling errors is a task that has been widely performed to normalize data, since most raw texts are noisy and have many spelling errors. In recent years, Long Short-Term Memory (LSTM) has shown to give an extraordinary result in solving sequential problems, including spelling correction. In this paper, we propose an LSTM model that encodes input word at character level, that also uses word and POS tag contexts as features. We performed the experiment on an artificial dataset based on Indonesian Wikipedia articles that we made by simulating some artificial spelling errors at character level and tested it on real dataset, mostly are Indonesian online news articles. The evaluation on test dataset gives 83.76% accuracy. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Predictive analytics for predicting customer behavior"
        ],
        "penulis":"Asniar;Surendro, Kridanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of the internet has caused digitalization of data which opens up big data opportunities. Digital data in large numbers leaves traces of what customers see, what they read, their involvement and behavior, judgment, about their interests and preferences so as to provide a large amount of data that can be mined for learning experiences. The big data value lies in the results of analysis and predictions or actions taken from the results of the analysis and prediction. Predictive analytics is data utilization, statistical algorithms, and machine-learning techniques to identify possible trends, events, and behaviors in the future based on historical data. This paper tries to propose predictive analytics to predict customer behavior by using behavior informatics and analytics approach so that deeper insight into customer behavior can be obtained to support predictive analysis in order to improve business decision making. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of the internet has caused digitalization of data which opens up big data opportunities. Digital data in large numbers leaves traces of what customers see, what they read, their involvement and behavior, judgment, about their interests and preferences so as to provide a large amount of data that can be mined for learning experiences. The big data value lies in the results of analysis and predictions or actions taken from the results of the analysis and prediction. Predictive analytics is data utilization, statistical algorithms, and machine-learning techniques to identify possible trends, events, and behaviors in the future based on historical data. This paper tries to propose predictive analytics to predict customer behavior by using behavior informatics and analytics approach so that deeper insight into customer behavior can be obtained to support predictive analysis in order to improve business decision making. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The policy implementation impact on region management"
        ],
        "penulis":"Sarihati, Tati;Rachaju, Rannie Dyah K.;Mukhlisiana, Lusy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The land function alteration happens massively at Kecamatan Cimenyan, an area in North Bandung Region or known as Kawasan Bandung Utara (KBU). KBU areas are important because it is located traverse 4 different regions, such as Bandung, Kabupaten Bandung, Kabupaten Bandung Barat, and Cimahi. The main function KBU areas to the cities and districts are very important, especially for water infiltration. It means that these areas are become the main water conservation land and also a flooding prevention area, not only for Bandung Raya region, but also for West Java Region. Land function alteration that happen in Kecamatan Cimenyan are encompass forest, plantation, dry land agricultural plant or known as TPLK conversion and water conservation land alteration into housing development, hotel chain business, and even change into mining area. That leads to environmental changes, such as soil erosion and sedimentation, overflowing river that leads to floods. It\u2019s all because the water conservation areas are getting smaller and smaller each day. Thus, this research aimed to analyse the policy implementation factors that affect the region management effectiveness, hindrance factor, and also the administration efforts at Kecamatan Cimenyan Kabupaten Bandung. An explanative method was used to analyse this research, and used cluster sampling to select the sample from 9 village and kelurahan in KBU region, Kecamatan Cimenyan Kabupaten Bandung in particular. And on every stage sampling are taken by simple random sampling method. The data of this research are examine using structure equation modelling (SEM), a procedure based on methods of successive interval. This research disclosed that the policy implementation that based on communication dimension, resources, disposition\/support attitude and bureaucratic structure have a significant impact on the region management effectiveness. And the most significant dimension to determine the effectiveness of the region management was support\/disposition dimension then followed by others dimension. \u00a9 BEIESP.",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Life on landGoal 15",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The land function alteration happens massively at Kecamatan Cimenyan, an area in North Bandung Region or known as Kawasan Bandung Utara (KBU). KBU areas are important because it is located traverse 4 different regions, such as Bandung, Kabupaten Bandung, Kabupaten Bandung Barat, and Cimahi. The main function KBU areas to the cities and districts are very important, especially for water infiltration. It means that these areas are become the main water conservation land and also a flooding prevention area, not only for Bandung Raya region, but also for West Java Region. Land function alteration that happen in Kecamatan Cimenyan are encompass forest, plantation, dry land agricultural plant or known as TPLK conversion and water conservation land alteration into housing development, hotel chain business, and even change into mining area. That leads to environmental changes, such as soil erosion and sedimentation, overflowing river that leads to floods. It\u2019s all because the water conservation areas are getting smaller and smaller each day. Thus, this research aimed to analyse the policy implementation factors that affect the region management effectiveness, hindrance factor, and also the administration efforts at Kecamatan Cimenyan Kabupaten Bandung. An explanative method was used to analyse this research, and used cluster sampling to select the sample from 9 village and kelurahan in KBU region, Kecamatan Cimenyan Kabupaten Bandung in particular. And on every stage sampling are taken by simple random sampling method. The data of this research are examine using structure equation modelling (SEM), a procedure based on methods of successive interval. This research disclosed that the policy implementation that based on communication dimension, resources, disposition\/support attitude and bureaucratic structure have a significant impact on the region management effectiveness. And the most significant dimension to determine the effectiveness of the region management was support\/disposition dimension then followed by others dimension. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Web Recommended System Library Book Selection Using Item Based Collaborative Filtering Method"
        ],
        "penulis":"Kusumawardhani, Nida Khairunnisa;Nasrun, Muhammad;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The recommendation system is one feature that is widely used by software today. The recommendation system is Beneficial for users to make it easier for users to make a book selection by providing book recommendations that may be following the desired book preferences. The recommendation system in this research uses the Item Based Collaborative Filtering method, where this method is the result of combining Collaborative Filtering and Item Based. Collaborative Filtering uses the rating matrix to calculate ratings, and Item Based uses book attributes to calculate similarity attributes between books.The collaborative filtering method has been used successfully in several applications. The Collaborative Filtering method predicts user preferences for items in a word-of-month manner, i.e. user preferences are determined by considering opinions in the form of preference ratings.Based on the results of tests conducted, the minimum MAE generated by the system is 0.018 with a maximum accuracy of 99.63% contained in the first test, meaning that the more variable data rating data, the higher the MAE value generated. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The recommendation system is one feature that is widely used by software today. The recommendation system is Beneficial for users to make it easier for users to make a book selection by providing book recommendations that may be following the desired book preferences. The recommendation system in this research uses the Item Based Collaborative Filtering method, where this method is the result of combining Collaborative Filtering and Item Based. Collaborative Filtering uses the rating matrix to calculate ratings, and Item Based uses book attributes to calculate similarity attributes between books.The collaborative filtering method has been used successfully in several applications. The Collaborative Filtering method predicts user preferences for items in a word-of-month manner, i.e. user preferences are determined by considering opinions in the form of preference ratings.Based on the results of tests conducted, the minimum MAE generated by the system is 0.018 with a maximum accuracy of 99.63% contained in the first test, meaning that the more variable data rating data, the higher the MAE value generated. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Study of PWM regulation effect using boost converter on electrolysis injection system based on Fuzzy Logic Controller"
        ],
        "penulis":"Iskandar, Reza Fauzi;Firdaus, Yandi;Rizki, Yasir;Deardo, Erik;Tasmara, Fahmi;Sigit, Zuhal;Vonia, Eka;Adetia, Mirval;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The aim of this paper is study the effect of PWM regulation on electric boost converter. The converter was used for electric driver in electrolysis injection system in order to modified the gas flow production. Electric driver will result the modified gas flow that injected into the combustion engine. The proposed scheme was expected to rose the combustion process and reduce the CO emission. The PMW regulation on this paper was developed using fuzzy logic controller that obtained feedback signal from CO gas sensor measurement. The experimental result showed that CO concentration measured about 330 PPM and its reduced until 253 PPM after the implementation of PWM variation. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aim of this paper is study the effect of PWM regulation on electric boost converter. The converter was used for electric driver in electrolysis injection system in order to modified the gas flow production. Electric driver will result the modified gas flow that injected into the combustion engine. The proposed scheme was expected to rose the combustion process and reduce the CO emission. The PMW regulation on this paper was developed using fuzzy logic controller that obtained feedback signal from CO gas sensor measurement. The experimental result showed that CO concentration measured about 330 PPM and its reduced until 253 PPM after the implementation of PWM variation. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Self service system for library automation: Case study at Telkom university open Library"
        ],
        "penulis":"Karna, Nyoman;Pratama, Donny;Ramzani, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "With an increasing number of the student body at Telkom University, office automation is one of many possible solutions to provide better and personalized service to students. This automation also includes library services, covering self loan, self-return, and self-pickup, which commonly use RFID (Radio Frequency Identification). The problem arises in RFID-based self-service system for library automation, which is how to ensure that the ID card of the patron truly belongs to the person using the service. This problem follows the self-loan service since the ID card of the patron is used only when borrowing the collection. Another problem is how to ensure that the borrowed collection is the actual collection registered in the LMS (Library Management System). This research proposes a business process of a self loan system design that minimizes fraudulent practice in borrowing collections by merging image capture of the patron and the borrowed collection where the librarian is not necessarily present for circulation. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "With an increasing number of the student body at Telkom University, office automation is one of many possible solutions to provide better and personalized service to students. This automation also includes library services, covering self loan, self-return, and self-pickup, which commonly use RFID (Radio Frequency Identification). The problem arises in RFID-based self-service system for library automation, which is how to ensure that the ID card of the patron truly belongs to the person using the service. This problem follows the self-loan service since the ID card of the patron is used only when borrowing the collection. Another problem is how to ensure that the borrowed collection is the actual collection registered in the LMS (Library Management System). This research proposes a business process of a self loan system design that minimizes fraudulent practice in borrowing collections by merging image capture of the patron and the borrowed collection where the librarian is not necessarily present for circulation. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Experimental characterization of SRR-based multilayer X-band wave absorber"
        ],
        "penulis":"Syihabuddin, Budi;Effendi, Mohammad Ridwan;Munir, Achmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In last two decades, researches on electromagnetics (EM) materials particularly which have unique properties have grown tremendously. The structure of ring resonator such as split ring resonator (SRR) as well as its complementary could sometimes implemented for fulfilling specification of EM wave absorber requirement. In this paper, the experimental characterization of SRR-based multilayer X-band wave absorber is presented. The working frequency of wave absorber is focused on 9.5 GHz intended for X-band radar application. The proposed X-band wave absorber which is developed on multilayer of 1.6mm thick FR4 epoxy dielectric substrates is designed using a unit cell composed of SRR and thin strip with the dimension of 3.5mm \u00d7 3.5 mm. Some attempts to enhance the characteristics of X-band wave absorber are carried out by inserting an air gap between the SRR structure on the top of first layer and the thin strip on the top of third layer. The characterization result shows that realized X-band wave absorber could achieve the reflection coefficient value up to -42.5dB which is similar to the performance of commercialized absorbent material with the reflection coefficient of -42.9 dB. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In last two decades, researches on electromagnetics (EM) materials particularly which have unique properties have grown tremendously. The structure of ring resonator such as split ring resonator (SRR) as well as its complementary could sometimes implemented for fulfilling specification of EM wave absorber requirement. In this paper, the experimental characterization of SRR-based multilayer X-band wave absorber is presented. The working frequency of wave absorber is focused on 9.5 GHz intended for X-band radar application. The proposed X-band wave absorber which is developed on multilayer of 1.6mm thick FR4 epoxy dielectric substrates is designed using a unit cell composed of SRR and thin strip with the dimension of 3.5mm \u00d7 3.5 mm. Some attempts to enhance the characteristics of X-band wave absorber are carried out by inserting an air gap between the SRR structure on the top of first layer and the thin strip on the top of third layer. The characterization result shows that realized X-band wave absorber could achieve the reflection coefficient value up to -42.5dB which is similar to the performance of commercialized absorbent material with the reflection coefficient of -42.9 dB. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Indonesian chatbot of university admission using a question answering system based on sequence-to-sequence model"
        ],
        "penulis":"Chandra, Yogi Wisesa;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Question and Answering (QA) system is a problem in natural language processing that can be used as the system of dialogs and chatbots. It can be used as a customer service that can provide a response to the customer quickly. A QA system receives an input in the form of sentences and produces the predictive sentences that are responses to the input. Therefore, a model that can learn such conversations is needed. This research focuses on developing a chatbot based on a sequence-to-sequence model. It is trained using a data set of conversation from a university admission. Evaluation on a small dataset obtained from the Telkom University admission on Whatsapp instant messaging application shows that the model produces a quite high BLEU score of 41.04. An attention mechanism technique using the reversed sentences improves the model to gives a higher BLEU up to 44.68. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Question and Answering (QA) system is a problem in natural language processing that can be used as the system of dialogs and chatbots. It can be used as a customer service that can provide a response to the customer quickly. A QA system receives an input in the form of sentences and produces the predictive sentences that are responses to the input. Therefore, a model that can learn such conversations is needed. This research focuses on developing a chatbot based on a sequence-to-sequence model. It is trained using a data set of conversation from a university admission. Evaluation on a small dataset obtained from the Telkom University admission on Whatsapp instant messaging application shows that the model produces a quite high BLEU score of 41.04. An attention mechanism technique using the reversed sentences improves the model to gives a higher BLEU up to 44.68. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "Management maintenance system for remote control based on microcontroller and virtual private serve"
        ],
        "penulis":"Kamil, Idham;Julham;Lubis, Muharman;Lubis, Arif Ridho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Open loop shaped control system is a form of system control without any feedback from the system. One example is the on-off condition which functions to connect and disconnect electricity. The condition to be studied is a dc motor that can be set to live and die via internet server-based client service. The server in this system is a virtual private server (VPS) device that will provide a source of service to the client in the form of a collection of information on dc motor conditions. In addition, its function is also to record the working time of the dc motor. So that a schedule can be determined when the dc motor is maintained. While the client is a control unit consisting of a microcontroller device, an ethernet module enc28j60 and a dc motor. In general the working principle of the system is beginning with the user accessing the desired VPS IP address through a web browser application. From the web browser the user chooses a dc motor to be activated. But before the client has been connected to the VPS regularly (every second), the point is to always get the latest dc motor condition information. Then the microcontroller will set the dc motor in active or off condition. The research method used is research and development. The results obtained from this study are that the amount of bandwidth needed for communication between VPS and microcontrollers via the internet network, when the control unit works is 6.02 kbps, while the response time for dc motor is 3.16 seconds and the response time for dc motor 2 is 3.46 seconds. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "CH3OHH3CCH3OHHHView detailsExpand Substance 17-methyltestosterone",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Open loop shaped control system is a form of system control without any feedback from the system. One example is the on-off condition which functions to connect and disconnect electricity. The condition to be studied is a dc motor that can be set to live and die via internet server-based client service. The server in this system is a virtual private server (VPS) device that will provide a source of service to the client in the form of a collection of information on dc motor conditions. In addition, its function is also to record the working time of the dc motor. So that a schedule can be determined when the dc motor is maintained. While the client is a control unit consisting of a microcontroller device, an ethernet module enc28j60 and a dc motor. In general the working principle of the system is beginning with the user accessing the desired VPS IP address through a web browser application. From the web browser the user chooses a dc motor to be activated. But before the client has been connected to the VPS regularly (every second), the point is to always get the latest dc motor condition information. Then the microcontroller will set the dc motor in active or off condition. The research method used is research and development. The results obtained from this study are that the amount of bandwidth needed for communication between VPS and microcontrollers via the internet network, when the control unit works is 6.02 kbps, while the response time for dc motor is 3.16 seconds and the response time for dc motor 2 is 3.46 seconds. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Optimal Planning of Solar PV Using Simple Model for New Feed-in Tariff in Indonesia"
        ],
        "penulis":"Adam, Kharisma Bani;Miyauchi, Hajime;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia is still struggling to attract the investor to involve in solar photovoltaic (PV) project. There is a rapid transformation in PV regulation by the government. Four regulation related to solar PV is delivered from 2016 until 2018. In 2018, the feed-in tariff regulation was established. The feed-in tariff aims the electricity customer to install the PV system and inject the excess energy to the grid. However, this rapid regulation changing is not yet attracting developer nor customer to invest in the solar PV. This paper proposes a simple model to calculate the optimal size of PV for new feed-in tariff regulation in Indonesia. Feed-in tariff regulation allows the customer to inject the energy produced by PV to the grid. The regulation provides 65% compensation of electricity price from energy sent to the grid with several limitations. There is difficulty to estimate daily energy data. Then, a technical calculation is proposed by using a simple model so that it can help the customer in sizing the solar PV system. Adding to the proposal of the methodology, this research also develops an application to help customers in calculating the optimal size of solar PV and its profitability. The new feed-in tariff rule will be an attraction for the customer. However, it needs a comprehensive calculation so that solar PV can be profitable. Oversized PV systems can cause financial losses with the large investment and limitation on the calculation of energy injected into the grid. The result shows that the PV simple model is successfully developed to help the consumer obtain the optimal PV size. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Climate actionGoal 13Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is still struggling to attract the investor to involve in solar photovoltaic (PV) project. There is a rapid transformation in PV regulation by the government. Four regulation related to solar PV is delivered from 2016 until 2018. In 2018, the feed-in tariff regulation was established. The feed-in tariff aims the electricity customer to install the PV system and inject the excess energy to the grid. However, this rapid regulation changing is not yet attracting developer nor customer to invest in the solar PV. This paper proposes a simple model to calculate the optimal size of PV for new feed-in tariff regulation in Indonesia. Feed-in tariff regulation allows the customer to inject the energy produced by PV to the grid. The regulation provides 65% compensation of electricity price from energy sent to the grid with several limitations. There is difficulty to estimate daily energy data. Then, a technical calculation is proposed by using a simple model so that it can help the customer in sizing the solar PV system. Adding to the proposal of the methodology, this research also develops an application to help customers in calculating the optimal size of solar PV and its profitability. The new feed-in tariff rule will be an attraction for the customer. However, it needs a comprehensive calculation so that solar PV can be profitable. Oversized PV systems can cause financial losses with the large investment and limitation on the calculation of energy injected into the grid. The result shows that the PV simple model is successfully developed to help the consumer obtain the optimal PV size. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Effect of lactic acid bacteria and yeasts towards chemical, physical and organoleptic qualities of mutton salami"
        ],
        "penulis":"Suryaningsih, Lilis;Hidayat, Rahmat;Utama, Gemilang Lara;Pratama, Andry;Balia, Roostita L.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Mutton has exceptional qualities such as smell, high consistency, and huge muscle fat, which makes mutton are restricted to consume. To expand mutton utilization, diversification with proper innovation is important. Salami is one of the proper mutton products that required starter such LAB that can deliver metabolites to change the texture, taste, and odor of meat. Other than LAB, yeasts additionally show up in meat processing, particularly in salami fermentation, which can build the meat taste and odor. The study aimed to identify the chemical, physical (water holding capacity, tenderness, and pH) and organoleptic (odor, color, texture, and taste) quality of mutton salami. Completely Randomized Design (CRD) was used as an experimental design with starters of Lactobacillus Plantarum as lactic acid bacteria (LAB) and yeasts, i.e. Cryptococcus humicolous and Trichosporon beigelii. The treatments were divided into 5 levels, i.e. R1 (0.5% LAB: Yeast 0.5%), R2 (1% LAB: Yeast 1 %), R3 (1.5% LAB: Yeast 1.5%), R4 (2% LAB: Yeast 2%), and R5 (2.5% LAB: Yeast 2.5%), with four replications. Analysis of variance was used to find out the treatment effect, and the Duncan Multiple Range Test was used to find out the difference between any treatments. The results show that the addition of Lactobacillus Plantarum from 0.5% to 2.5% and yeast Cryptococcus humicolous, Trichosporon beigelii from 0.5% to 2.5%, did not significantly affect chemical and physical quality, while water holding capacity and organoleptic test, i.e., color, odor, and texture showed significant effects except taste. \u00a9 2019 International Journal on Advanced Science Engineering Information Technology.",
            "HOH3COHOView detailsExpand Substance LACTIC ACID",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mutton has exceptional qualities such as smell, high consistency, and huge muscle fat, which makes mutton are restricted to consume. To expand mutton utilization, diversification with proper innovation is important. Salami is one of the proper mutton products that required starter such LAB that can deliver metabolites to change the texture, taste, and odor of meat. Other than LAB, yeasts additionally show up in meat processing, particularly in salami fermentation, which can build the meat taste and odor. The study aimed to identify the chemical, physical (water holding capacity, tenderness, and pH) and organoleptic (odor, color, texture, and taste) quality of mutton salami. Completely Randomized Design (CRD) was used as an experimental design with starters of Lactobacillus Plantarum as lactic acid bacteria (LAB) and yeasts, i.e. Cryptococcus humicolous and Trichosporon beigelii. The treatments were divided into 5 levels, i.e. R1 (0.5% LAB: Yeast 0.5%), R2 (1% LAB: Yeast 1 %), R3 (1.5% LAB: Yeast 1.5%), R4 (2% LAB: Yeast 2%), and R5 (2.5% LAB: Yeast 2.5%), with four replications. Analysis of variance was used to find out the treatment effect, and the Duncan Multiple Range Test was used to find out the difference between any treatments. The results show that the addition of Lactobacillus Plantarum from 0.5% to 2.5% and yeast Cryptococcus humicolous, Trichosporon beigelii from 0.5% to 2.5%, did not significantly affect chemical and physical quality, while water holding capacity and organoleptic test, i.e., color, odor, and texture showed significant effects except taste. \u00a9 2019 International Journal on Advanced Science Engineering Information Technology."
        ]
    },
    {
        "judul":[
            "The effect of social media to the sustainability of short message service (SMS) and phone call"
        ],
        "penulis":"Lubis, Arif Ridho;Lubis, Muharman;Azhar, Citra Dewi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the development of increasingly advanced technology, the use of SMS and telephone has been replaced by smartphone users who are more intended to use social media, especially among students. Social media are online media where users can communicate and interact one another for social interactions conducted online through the internet such as WhatsApp, Line, Instagram, Facebook, Twitter, Skype and Telegram. The existence of social media makes SMS and telephone user switch to social media which has more features, capacities and functions. Therefore, it is interesting to investigate the effect of social media to influence the sustainability of SMS and telephone which is seen from the effectiveness of social media in terms of time, quality and quantity, cost, distance, and energy in related to the utilization of SMS and telephone among users. To determine the effect of respected social media, this study use multiple regression, which is analysed using SPSS 17.0 and has passed the validity and reliability test up to 32.7% the influence of all variants. The most dominant influence on Usage and Function variables is Quality and Quantity which has 18% with significant value of test 0,000 smaller than the value set (0.05), the cost of which has 4.7% with significant value of T test at around 0.003 smaller than the value determined (0.05), and Energy which has 2.1% with significant value of T test about 0.013 smaller than the value set (0.05). \u00a9 2019 The Authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the development of increasingly advanced technology, the use of SMS and telephone has been replaced by smartphone users who are more intended to use social media, especially among students. Social media are online media where users can communicate and interact one another for social interactions conducted online through the internet such as WhatsApp, Line, Instagram, Facebook, Twitter, Skype and Telegram. The existence of social media makes SMS and telephone user switch to social media which has more features, capacities and functions. Therefore, it is interesting to investigate the effect of social media to influence the sustainability of SMS and telephone which is seen from the effectiveness of social media in terms of time, quality and quantity, cost, distance, and energy in related to the utilization of SMS and telephone among users. To determine the effect of respected social media, this study use multiple regression, which is analysed using SPSS 17.0 and has passed the validity and reliability test up to 32.7% the influence of all variants. The most dominant influence on Usage and Function variables is Quality and Quantity which has 18% with significant value of test 0,000 smaller than the value set (0.05), the cost of which has 4.7% with significant value of T test at around 0.003 smaller than the value determined (0.05), and Energy which has 2.1% with significant value of T test about 0.013 smaller than the value set (0.05). \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Towards Successful Implementation of a Virtual Classroom for Vocational Higher Education in Indonesia"
        ],
        "penulis":"Aditya, Bayu Rima;Nurhas, Irawan;Pawlowski, Jan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The virtual classroom continues to grow, but it is becoming more and more the norm, and it is fundamentally different from the vocational students at the Indonesian university. With the promised benefits of the virtual classroom, many challenges and difficulties come in the implementation. Although there are already successful design principles for virtual classrooms that support organizations in overcoming the challenges, the approach to implementing the design principles of virtual classroom at the vocational higher education in Indonesia is still lacking. In this study, we aim to answer the research gap and used the design sciences research by interviewing the lecturers to design the solutions. The proposed design approaches were implemented in a course and evaluated with students from two different groups. Overall, the evaluation of the proposed approaches shows 1 significant results as an indicator of the benefits of the implementation of a virtual classroom for vocational students in Indonesia. \u00a9 2019, Springer Nature Switzerland AG.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The virtual classroom continues to grow, but it is becoming more and more the norm, and it is fundamentally different from the vocational students at the Indonesian university. With the promised benefits of the virtual classroom, many challenges and difficulties come in the implementation. Although there are already successful design principles for virtual classrooms that support organizations in overcoming the challenges, the approach to implementing the design principles of virtual classroom at the vocational higher education in Indonesia is still lacking. In this study, we aim to answer the research gap and used the design sciences research by interviewing the lecturers to design the solutions. The proposed design approaches were implemented in a course and evaluated with students from two different groups. Overall, the evaluation of the proposed approaches shows 1 significant results as an indicator of the benefits of the implementation of a virtual classroom for vocational students in Indonesia. \u00a9 2019, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Predicting staple food materials price using multivariables factors (regression and fourier models with ARIMA)"
        ],
        "penulis":"Asnhari, Said Fadlan;Gunawan P.H.;Rusmawati, Yanti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Staple food material prices can be a trending topic in the market. The fluctuation of the price is influenced by many factors. For instance, the weather, oil price, and etc are the external factors of the staple food price. Indeed, the prediction of staple food fluctuation price is important for the farmers, consumers, even government. In this paper, the Linear Regression and Fourier model with ARIMA (Autoregressive Integrated Moving Average) will be used to predict the staple food price which consider the external influences. Here, the results using those two methods are shown in a good agreement with the observation price at market. However, the highest accuracy in predicting price using Fourier regression with ARIMA is obtained for staple food onion which is 96.57%. Meanwhile, using multiple linear regression with ARIMA, the highest accuracy is obtained for staple food red chili with 99.84%. Overall, in this research, Fourier regression with ARIMA is observed better than multiple linear regression with ARIMA method, since the accuracy of Fourier regression with ARIMA is quite stable without disturbance of fluctuation existing data. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Staple food material prices can be a trending topic in the market. The fluctuation of the price is influenced by many factors. For instance, the weather, oil price, and etc are the external factors of the staple food price. Indeed, the prediction of staple food fluctuation price is important for the farmers, consumers, even government. In this paper, the Linear Regression and Fourier model with ARIMA (Autoregressive Integrated Moving Average) will be used to predict the staple food price which consider the external influences. Here, the results using those two methods are shown in a good agreement with the observation price at market. However, the highest accuracy in predicting price using Fourier regression with ARIMA is obtained for staple food onion which is 96.57%. Meanwhile, using multiple linear regression with ARIMA, the highest accuracy is obtained for staple food red chili with 99.84%. Overall, in this research, Fourier regression with ARIMA is observed better than multiple linear regression with ARIMA method, since the accuracy of Fourier regression with ARIMA is quite stable without disturbance of fluctuation existing data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2019,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "The effects of the quality of service and social media on the interests of Argo Parahyangan train passengers on Bandung-Jakarta"
        ],
        "penulis":"Hidayah, Riski Taufik;Yolinda, Syindria;Nugraha, Deden Novan Setiawan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Argo Parahyangan Railway Transports Passengers is currently one of the best choices in traveling the Bandung-Jakarta and Jakarta-Bandung route. The purpose of this study was to find out how much influence the quality of services provided to passengers in traveling, and promotional activities through social media are used to interest passengers to use the Argo Parahyangan Railway. This research involved descriptive verification with a total sample of 100 Bandung people who conduct activities in Jakarta. Results of the study indicated that 44.89% of Purchase interest is contributed by the quality of service and 51.84% is contributed by promotional activities through Social media. \u00a9 2019 Primrose Hall Publishing Group.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Argo Parahyangan Railway Transports Passengers is currently one of the best choices in traveling the Bandung-Jakarta and Jakarta-Bandung route. The purpose of this study was to find out how much influence the quality of services provided to passengers in traveling, and promotional activities through social media are used to interest passengers to use the Argo Parahyangan Railway. This research involved descriptive verification with a total sample of 100 Bandung people who conduct activities in Jakarta. Results of the study indicated that 44.89% of Purchase interest is contributed by the quality of service and 51.84% is contributed by promotional activities through Social media. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Classification of gene expressions of lung cancer and colon tumor using Adaptive-Network-Based Fuzzy Inference System (ANFIS) with Ant Colony Optimization (ACO) as the feature selection"
        ],
        "penulis":"Zainuddin S.;Nhita F.;Wisesty U.N.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cancer is one of the death causes in most countries. In 2015 the death count caused by cancer is reaching 8,8 million and in 2030 it is estimated that the death count reaches 13 million. Therefore, in this research conducted an expression classification of gene using Adaptive-Network-based Fuzzy Inference System (ANFIS) with Ant Colony Optimization (ACO) as the feature selection can help the process of early diagnosis to reduce mortality. The data used are colon tumor and lung cancer obtained from Kent Ridge Biomedical Data Set Repository. Accuracy results obtained are influenced by several factors such as data partition method, the number of ants, and the number of gene attributes. The best accuracy results obtained for colon tumor is 94,73% and lung data cancer is 100%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is one of the death causes in most countries. In 2015 the death count caused by cancer is reaching 8,8 million and in 2030 it is estimated that the death count reaches 13 million. Therefore, in this research conducted an expression classification of gene using Adaptive-Network-based Fuzzy Inference System (ANFIS) with Ant Colony Optimization (ACO) as the feature selection can help the process of early diagnosis to reduce mortality. The data used are colon tumor and lung cancer obtained from Kent Ridge Biomedical Data Set Repository. Accuracy results obtained are influenced by several factors such as data partition method, the number of ants, and the number of gene attributes. The best accuracy results obtained for colon tumor is 94,73% and lung data cancer is 100%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Approximating earthquake source of Italy using Steepest Descent method"
        ],
        "penulis":"Aziz F.A.;Gunawan P.H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper describes the comparison of Newton's method and Steepest Descent method for determining the coordinates of earthquake source. Here, the Steepest Descent method is used because it is a Newton-based method. The earthquake case used in this research is Italian earthquake August 24, 2016, which has a seismic phase of Pg. The calculation was supported by Azimuth Coordinate equations to find the coordinates and Haversine formula to find the distance between five earthquake stations to the earthquake source. The final result of calculations was path's graph from the iteration of Steepest Descent method. Moreover, the results will be compared with the results of Newton's method that has been successfully approaching the point of earthquake source in the same case study of previous research. The result shows the number of final iterations of two methods using tolerance number 0.01, minimum velocity number 3093 m\/s and three cases of initial guess in the form of city coordinate of Rome, Milan, and Palermo. Newton's method generates 12 iterations in every case, Steepest Descent method generate 7, 6, 5 iteration respectively. However, the final numerical errors for Rome, Milan and Palermo initial guess are 0.1598 by Newton's method, while Steepest Descent method are 0.1566, 0.1567 and 0.1567. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper describes the comparison of Newton's method and Steepest Descent method for determining the coordinates of earthquake source. Here, the Steepest Descent method is used because it is a Newton-based method. The earthquake case used in this research is Italian earthquake August 24, 2016, which has a seismic phase of Pg. The calculation was supported by Azimuth Coordinate equations to find the coordinates and Haversine formula to find the distance between five earthquake stations to the earthquake source. The final result of calculations was path's graph from the iteration of Steepest Descent method. Moreover, the results will be compared with the results of Newton's method that has been successfully approaching the point of earthquake source in the same case study of previous research. The result shows the number of final iterations of two methods using tolerance number 0.01, minimum velocity number 3093 m\/s and three cases of initial guess in the form of city coordinate of Rome, Milan, and Palermo. Newton's method generates 12 iterations in every case, Steepest Descent method generate 7, 6, 5 iteration respectively. However, the final numerical errors for Rome, Milan and Palermo initial guess are 0.1598 by Newton's method, while Steepest Descent method are 0.1566, 0.1567 and 0.1567. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Indoor Visible Light Communication System with Diversity Combining and Repetition Code"
        ],
        "penulis":"Alhadiid, Gogi Gautama;Astuti, Rina Pudji;Hidayat, Bambang;Darlis, Denny;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Concurrent illumination and communication using LED for Visible Light Communication (VLC) system has been the focus of some researches in the past years. Giving a new purpose of old technology, without addition of a new infrastructure becoming a strong point for VLC system. In this research we used diversity technique to perform a data communication using visible light medium. With diversity order of 3 with red Light Emitting Diode (LED), Green LED, and Blue LED. Each carry a redundant data. We encode the data and its redundant in a repetition code. Simulation results shows system performance with BER of 2.41x10-4at SNR of 1 dB compared to the proposed system with shadowing effect with BER of -2.47x10-4at SNR of 1 dB. This show that the system is robust against shadowing in an indoor VLC environment. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Concurrent illumination and communication using LED for Visible Light Communication (VLC) system has been the focus of some researches in the past years. Giving a new purpose of old technology, without addition of a new infrastructure becoming a strong point for VLC system. In this research we used diversity technique to perform a data communication using visible light medium. With diversity order of 3 with red Light Emitting Diode (LED), Green LED, and Blue LED. Each carry a redundant data. We encode the data and its redundant in a repetition code. Simulation results shows system performance with BER of 2.41x10-4at SNR of 1 dB compared to the proposed system with shadowing effect with BER of -2.47x10-4at SNR of 1 dB. This show that the system is robust against shadowing in an indoor VLC environment. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Knowledge Representation of Political Parties' Ideological Characteristics Using Formal Concept Analysis"
        ],
        "penulis":"Hanum, Savira Latifah;Arzaki, Muhammad;Rusmawati, Yanti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "We build a knowledge representation of ideological characteristics of political parties. In particular, we propose a knowledge representation regarding the ideological characteristics of Indonesia's political parties in the 2019 general election. Our proposed knowledge base is constructed using the rigorous approach of Formal Concept Analysis (FCA). We first define several formal contexts specifying the ideological characteristics satisfied by the associated political parties. These formal contexts are then used to construct the pictorial relationship among political parties' ideologies in the form of concept lattice. From this lattice, we also derived implications and association rules pertaining to the relationship between two or more ideological characteristics. These implications and association rules are useful for building the ontology of Indonesia's Political Parties ideological characteristics. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We build a knowledge representation of ideological characteristics of political parties. In particular, we propose a knowledge representation regarding the ideological characteristics of Indonesia's political parties in the 2019 general election. Our proposed knowledge base is constructed using the rigorous approach of Formal Concept Analysis (FCA). We first define several formal contexts specifying the ideological characteristics satisfied by the associated political parties. These formal contexts are then used to construct the pictorial relationship among political parties' ideologies in the form of concept lattice. From this lattice, we also derived implications and association rules pertaining to the relationship between two or more ideological characteristics. These implications and association rules are useful for building the ontology of Indonesia's Political Parties ideological characteristics. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Discovering the influencing factors of physical gig economy usage: Quantitative approach on clients9 perception"
        ],
        "penulis":"Auditianto, Ari;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Physical Gig Economy (PGE) in Indonesia has rapid growth in the last few years. Unfortunately, a large gap among PGE services occurred. Compared with ride-hailing services with highly frequent transactions, cleaning and mechanical services have had few transactions. This study aims to identify and analyze the factors that influence clients to use PGE services. Previous studies about users' intention were synthesized to develop the research model and hypothesis. Factors that are thought to have an influence on client behavior and intention are platform quality, trust, social influence, perceived risk, hedonic motivation, and economic benefits. Furthermore, a quantitative approach with Partial Least Squares Structural Equation Modeling (PLS-SEM) and 318 valid respondents is demonstrated. The results show that hedonic motivation is the most influencing factor followed by economic benefits, trust, and perceived platform quality. This study also informs that social influence only affects client on the early usage of PGE. Having the knowledge of these factors, PGE operators could develop the right strategies to further expand their business and attract new clients. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Physical Gig Economy (PGE) in Indonesia has rapid growth in the last few years. Unfortunately, a large gap among PGE services occurred. Compared with ride-hailing services with highly frequent transactions, cleaning and mechanical services have had few transactions. This study aims to identify and analyze the factors that influence clients to use PGE services. Previous studies about users' intention were synthesized to develop the research model and hypothesis. Factors that are thought to have an influence on client behavior and intention are platform quality, trust, social influence, perceived risk, hedonic motivation, and economic benefits. Furthermore, a quantitative approach with Partial Least Squares Structural Equation Modeling (PLS-SEM) and 318 valid respondents is demonstrated. The results show that hedonic motivation is the most influencing factor followed by economic benefits, trust, and perceived platform quality. This study also informs that social influence only affects client on the early usage of PGE. Having the knowledge of these factors, PGE operators could develop the right strategies to further expand their business and attract new clients. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Solving multi-objective vehicle routing problem using hyper-heuristic method by considering balance of route distances"
        ],
        "penulis":"Sasmi Hidayatul Y.T.;Djunaidy, Arif;Muklason, Ahmad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Vehicle Routing Problem (VRP) is one of the combinatoric problems that is difficult to solve, so it is incorporated into an NP-hard problem. VRP aims to produce a set of shortest routes from several of the same capacity vehicles to visit several customers at a certain time limit. Depot is the starting and ending point of the route. Due to the complexity of industry needs, the VRP problem needs to be improved into a multi-objective. Most of VRP prior researches only minimize total distance as a single objective. Therefore, in this study added an objective related to the balance of distances between routes. In prior researches, multi-objective VRP was solved using metaheuristic. It requires the determination of parameters and specific algorithm design to solve each problem domain. To overcome these shortcomings, this study uses a hyper-heuristic method to complete multi-objective VRP. Given that the use of hyper-heuristics in previous studies is for single objective VRP, so this study also proposes hyper-heuristic for multi-objective VRP. Gehring and Homberger dataset is used for the experiment. Based on the experiments in this study, The Hill Climbing algorithm gives better results than The Great Deluge algorithm for completing multi-objective VRP. \u00a9 2019 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Vehicle Routing Problem (VRP) is one of the combinatoric problems that is difficult to solve, so it is incorporated into an NP-hard problem. VRP aims to produce a set of shortest routes from several of the same capacity vehicles to visit several customers at a certain time limit. Depot is the starting and ending point of the route. Due to the complexity of industry needs, the VRP problem needs to be improved into a multi-objective. Most of VRP prior researches only minimize total distance as a single objective. Therefore, in this study added an objective related to the balance of distances between routes. In prior researches, multi-objective VRP was solved using metaheuristic. It requires the determination of parameters and specific algorithm design to solve each problem domain. To overcome these shortcomings, this study uses a hyper-heuristic method to complete multi-objective VRP. Given that the use of hyper-heuristics in previous studies is for single objective VRP, so this study also proposes hyper-heuristic for multi-objective VRP. Gehring and Homberger dataset is used for the experiment. Based on the experiments in this study, The Hill Climbing algorithm gives better results than The Great Deluge algorithm for completing multi-objective VRP. \u00a9 2019 IEEE"
        ]
    },
    {
        "judul":[
            "Vowel Sound Analysis in the Indonesian Language using Multilevel Wavelet Entropy"
        ],
        "penulis":"Hidayat, Risanuri;Rizal, Achmad;Bejo, Agus;Sumaryono, Sujoko;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "vowel is an integral part of speech signal processing. It can stand alone or be combined with a consonant to form specific sound. Previous studies have used wavelet transformation as sound vowel analysis method; however, these studies generally only used one level of wavelet decomposition in analyzing lung sound. This study, in turn, proposed entropy wavelet method with various levels of decomposition to obtain more comprehensive results of vowel sounds in various resolutions. It used the methods of multilevel wavelet entropy (MWE) and multilevel wavelet packet entropy (MWPE) in which the results showed 100% accuracy of MWE in the seventh level of Bior2.4 wavelet. Meanwhile, Haar wavelet and seventh level of Bior1.5 wavelet had 93.33% accuracy in MPWE. The combination of MWE and MWPE had 100% accuracy in the seventh level of Bior2.4 wavelet. Proposed method in this study can be used in a more extensive speech analysis. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "vowel is an integral part of speech signal processing. It can stand alone or be combined with a consonant to form specific sound. Previous studies have used wavelet transformation as sound vowel analysis method; however, these studies generally only used one level of wavelet decomposition in analyzing lung sound. This study, in turn, proposed entropy wavelet method with various levels of decomposition to obtain more comprehensive results of vowel sounds in various resolutions. It used the methods of multilevel wavelet entropy (MWE) and multilevel wavelet packet entropy (MWPE) in which the results showed 100% accuracy of MWE in the seventh level of Bior2.4 wavelet. Meanwhile, Haar wavelet and seventh level of Bior1.5 wavelet had 93.33% accuracy in MPWE. The combination of MWE and MWPE had 100% accuracy in the seventh level of Bior2.4 wavelet. Proposed method in this study can be used in a more extensive speech analysis. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The effectiveness of short message service advertising using EPIC model on consumer perception and purchase intention"
        ],
        "penulis":"Oktafani F.;Suryawardani B.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study was aimed to find out the effectiveness of Telkomsel SMS advertising using EPIC Model, and to find out the influence of SMS advertising to perception and purchasing interest partially and simultaneously. The method used was descriptive verification with purposive sampling technique. Then the data was analyzed using path analysis. The results showed that the effectiveness of Telkomsel SMS advertising using EPIC model has 3.58 EPIC rate. Meanwhile, the influence of SMS advertising to customer perception was 40.6%, customer perception to purchasing interest was 25.6%, and SMS advertising to purchasing interest of Telkomsel sim card users was 19.4%. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study was aimed to find out the effectiveness of Telkomsel SMS advertising using EPIC Model, and to find out the influence of SMS advertising to perception and purchasing interest partially and simultaneously. The method used was descriptive verification with purposive sampling technique. Then the data was analyzed using path analysis. The results showed that the effectiveness of Telkomsel SMS advertising using EPIC model has 3.58 EPIC rate. Meanwhile, the influence of SMS advertising to customer perception was 40.6%, customer perception to purchasing interest was 25.6%, and SMS advertising to purchasing interest of Telkomsel sim card users was 19.4%. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Multiple Face Image Feature Extraction Using Geometric Moment Invariants Method"
        ],
        "penulis":"Fachrurrozi, Muhammad;Saparudin;Lestari, Ayu;Arsalan, Osvari;Samsuryadi;Ermatita;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Research on human facial expression recognition has become a growing field. One important step in the recognition of facial expressions is feature extraction. This research uses Geometric Moment Invariants (GMI) as a feature extraction method. Research on facial expression recognition using either the GMI method or another method use single face image as the dataset. Therefore, in this study uses GMI feature extraction to classify facial expressions on multiple face images. Face detection process uses Viola-Jones method on OpenCV and classification process uses Multi Class SVM method. The results are features for each expression and a small average accuracy of 5 times. Therefore, the classification is also done with the k-fold cross validation technique with another classification method. The average accuracy results are still small. It caused by the training image also using outer area of face in the image, so the background included as the image features. It is tested from k value 2 to10, and produce Multi Class SVM 10.2%, Decision Tree Classifier 14.73%, Random Forest Classifier 14.78%, Gaussian Naive Bayes 14.73%, Nearest Centroid 14.66%, MLP Classifier 11.09%, and Stochastic Gradient Descent Classifier 14.19%. The highest accuracy result is Random Forest Classifier method 14.78%. In Random Forest method, the best k value obtained is 4 with an average accuracy 16.18%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Research on human facial expression recognition has become a growing field. One important step in the recognition of facial expressions is feature extraction. This research uses Geometric Moment Invariants (GMI) as a feature extraction method. Research on facial expression recognition using either the GMI method or another method use single face image as the dataset. Therefore, in this study uses GMI feature extraction to classify facial expressions on multiple face images. Face detection process uses Viola-Jones method on OpenCV and classification process uses Multi Class SVM method. The results are features for each expression and a small average accuracy of 5 times. Therefore, the classification is also done with the k-fold cross validation technique with another classification method. The average accuracy results are still small. It caused by the training image also using outer area of face in the image, so the background included as the image features. It is tested from k value 2 to10, and produce Multi Class SVM 10.2%, Decision Tree Classifier 14.73%, Random Forest Classifier 14.78%, Gaussian Naive Bayes 14.73%, Nearest Centroid 14.66%, MLP Classifier 11.09%, and Stochastic Gradient Descent Classifier 14.19%. The highest accuracy result is Random Forest Classifier method 14.78%. In Random Forest method, the best k value obtained is 4 with an average accuracy 16.18%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Competitive Advantage Analysis of Small Medium Industries in Indonesia: An Approach of Management Technology and Strategic Management"
        ],
        "penulis":"Rumanti A.A.;Muhammad F.;Rizana A.F.;Wiratmadja I.I.;Adelia C.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research discusses the achievement of competitive advantage through the perspective of management technology and strategic management. The object of the research is the Small Medium Industry (SMI) of leather and puppet in Yogyakarta. Based on the result of data processing through the technometric concept of technology management, it was found that TCC value of 0.0073 which classified the technology used by the SMI of Maju Karya as traditional technology. Although relatively low, the current technology condition of the SMI of Maju Karya has reached ideal condition. It shows the SMI has utilized its capabilities optimally. The further step is to test the hypotheses for the variables constructed in the research model using SmartPLS software. The result of data processing concluded that hypotheses of H11 and H21 are accepted. It means both the technology component and strategic management have a positive influence on competitive advantage. The last phase is to analyze the strategic position of the business portfolio by using the BCG Growth-share matrix. The result of data processing categorized the SMI of Maju Karya as Cash Cows. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research discusses the achievement of competitive advantage through the perspective of management technology and strategic management. The object of the research is the Small Medium Industry (SMI) of leather and puppet in Yogyakarta. Based on the result of data processing through the technometric concept of technology management, it was found that TCC value of 0.0073 which classified the technology used by the SMI of Maju Karya as traditional technology. Although relatively low, the current technology condition of the SMI of Maju Karya has reached ideal condition. It shows the SMI has utilized its capabilities optimally. The further step is to test the hypotheses for the variables constructed in the research model using SmartPLS software. The result of data processing concluded that hypotheses of H11 and H21 are accepted. It means both the technology component and strategic management have a positive influence on competitive advantage. The last phase is to analyze the strategic position of the business portfolio by using the BCG Growth-share matrix. The result of data processing categorized the SMI of Maju Karya as Cash Cows. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Robustness analysis of systems' safety through a new notion of input-to-state safety"
        ],
        "penulis":"Romdlony, Muhammad Zakiyullah;Jayawardhana, Bayu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, we propose a new robustness notion that is applicable for certifying systems' safety with respect to external disturbance signals. The proposed input-to-state safety notion allows us to certify systems' safety in the presence of the disturbances, which is analogous to the notion of input-to-state stability for analyzing systems' stability. \u00a9 2019 John Wiley & Sons, Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we propose a new robustness notion that is applicable for certifying systems' safety with respect to external disturbance signals. The proposed input-to-state safety notion allows us to certify systems' safety in the presence of the disturbances, which is analogous to the notion of input-to-state stability for analyzing systems' stability. \u00a9 2019 John Wiley & Sons, Ltd."
        ]
    },
    {
        "judul":[
            "Assessment of Team Based Learning: The Use of Student Centred Learning for Interaction Design Class"
        ],
        "penulis":"Lubis, Muharman;Azizah, Anik Hanifatul;Fauzi, Rahmat;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Student-centred learning has been defined as small approach to improve learning objective through variety of process where students not only choose what to learn, but how and why. Moreover, the essence of the learning environment is the responsibility and activities of students, in contrast to the focus on coach control and the scope of academic content in the teaching with the traditional teaching. In this case, the use of Team based learning can take into account the aspects of the time of tasks termination and student activities to learn the subject content in the maximum way to enrich the other concepts outside the learning module. This study investigate the utilization of Team Based Learning in the subject of Interaction Design to improve the understanding from the student towards the curriculum objective and target. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Student-centred learning has been defined as small approach to improve learning objective through variety of process where students not only choose what to learn, but how and why. Moreover, the essence of the learning environment is the responsibility and activities of students, in contrast to the focus on coach control and the scope of academic content in the teaching with the traditional teaching. In this case, the use of Team based learning can take into account the aspects of the time of tasks termination and student activities to learn the subject content in the maximum way to enrich the other concepts outside the learning module. This study investigate the utilization of Team Based Learning in the subject of Interaction Design to improve the understanding from the student towards the curriculum objective and target. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Combinational disruptions impact analysis in road freight transportation network"
        ],
        "penulis":"Rosyida, Erly Ekayanti;Santosa, Budi;Pujawan, I. Nyoman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The impacts of disruption caused by transportation breakdown cannot be underestimated as this condition often hinders the actual logistic delivery. Thus, a contingency plan is absolutely necessary. In doing so, some managers propose a strategy to minimize time loss and cost inefficiency. This paper investigates the impacts of combinational disruption in a road freight transportation network. This paper uses the VRPTW model that describes the road freight transportation network. Two kinds of disruption scenario were observed in this model; a single disruption and a combinational disruption. The disruption impact analysis aims to uncover the effects of disruption on transportation cost. The results show that an optimal route strategy that provides minimal cost, which is computed by a numerical experiment, results in route effectiveness under each disruption scenario. \u00a9 2019 Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The impacts of disruption caused by transportation breakdown cannot be underestimated as this condition often hinders the actual logistic delivery. Thus, a contingency plan is absolutely necessary. In doing so, some managers propose a strategy to minimize time loss and cost inefficiency. This paper investigates the impacts of combinational disruption in a road freight transportation network. This paper uses the VRPTW model that describes the road freight transportation network. Two kinds of disruption scenario were observed in this model; a single disruption and a combinational disruption. The disruption impact analysis aims to uncover the effects of disruption on transportation cost. The results show that an optimal route strategy that provides minimal cost, which is computed by a numerical experiment, results in route effectiveness under each disruption scenario. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Truncated query of phonetic search for al qur'an"
        ],
        "penulis":"Zafran, Aidil;Bijaksana, Moch Arif;Lhaksmana, Kemas M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This study examines how to look for a verse of the Quran or a clipped verse in the Qur'an and ranks search results correctly. Because the Qur'an consists of 30 juz, 114 letters and 6236 verses, then if you search for a particular verse then a Quranic verse search system is needed. At present, there is already a verse search system for the Quran, but the search results ranking process still has a number of errors in highlighting the verses that are searched for, the similarity scores that are less precise and have not been good at handling clipped or incomplete verses. When conducting a search that needs to remember a verse from the Koran, one can remember the whole verse of the Quran but there are also some cases that cannot remember a verse completely or cut off. For example, a complete verse search query zalikal kitabu la raiba fihi the result will be different from the clipped verse query like this zalikal kitabu fihi. Because some truncated characters will be ignored by the system and can reduce the value of similarity. This shows that the existing system does not provide good accuracy in string matching. With this research, it will overcome the LCS search problem which ignores previously unreadable characters. Using the LCS method of query search for all data so as to produce candidate results, then research the neglected character of the candidate results to find similarities between neglected characters and one of the candidates previously obtained. So, improve ranking in the lafzi and increase the ability of the lafzi to search for clauses that are clipped or incomplete. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study examines how to look for a verse of the Quran or a clipped verse in the Qur'an and ranks search results correctly. Because the Qur'an consists of 30 juz, 114 letters and 6236 verses, then if you search for a particular verse then a Quranic verse search system is needed. At present, there is already a verse search system for the Quran, but the search results ranking process still has a number of errors in highlighting the verses that are searched for, the similarity scores that are less precise and have not been good at handling clipped or incomplete verses. When conducting a search that needs to remember a verse from the Koran, one can remember the whole verse of the Quran but there are also some cases that cannot remember a verse completely or cut off. For example, a complete verse search query zalikal kitabu la raiba fihi the result will be different from the clipped verse query like this zalikal kitabu fihi. Because some truncated characters will be ignored by the system and can reduce the value of similarity. This shows that the existing system does not provide good accuracy in string matching. With this research, it will overcome the LCS search problem which ignores previously unreadable characters. Using the LCS method of query search for all data so as to produce candidate results, then research the neglected character of the candidate results to find similarities between neglected characters and one of the candidates previously obtained. So, improve ranking in the lafzi and increase the ability of the lafzi to search for clauses that are clipped or incomplete. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Sequential Pattern Mining Suggests Wellbeing Supportive Behaviors"
        ],
        "penulis":"Alibasa, Muhammad J.;Calvo, Rafael A.;Yacef, Kalina;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Amidst the headlines about the attention economy and the possible impacts of screen time, research investigating the complex relationship between digital technology usage and wellbeing has gained urgency. Researchers generally use a combination of surveys and automatic tracking tools to gather time and frequency of technology use. However, the focus of data analysis has been on measuring duration and frequency of usage rather than exploring behavioral patterns, possibly better indicators of mood states or stress levels. We propose a methodology for detecting behavioural patterns from digital footprints using a sequence pattern mining algorithm, and using these as features for predicting mood. Results show that our method can be used to analyze the relationship between digital usage and mood, and predict the latter with an accuracy of 80%, significantly above the baseline (71.1%). This method provides another angle to investigate digital technology usage in wellbeing-related research. \u00a9 2013 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Amidst the headlines about the attention economy and the possible impacts of screen time, research investigating the complex relationship between digital technology usage and wellbeing has gained urgency. Researchers generally use a combination of surveys and automatic tracking tools to gather time and frequency of technology use. However, the focus of data analysis has been on measuring duration and frequency of usage rather than exploring behavioral patterns, possibly better indicators of mood states or stress levels. We propose a methodology for detecting behavioural patterns from digital footprints using a sequence pattern mining algorithm, and using these as features for predicting mood. Results show that our method can be used to analyze the relationship between digital usage and mood, and predict the latter with an accuracy of 80%, significantly above the baseline (71.1%). This method provides another angle to investigate digital technology usage in wellbeing-related research. \u00a9 2013 IEEE."
        ]
    },
    {
        "judul":[
            "Radio Cellular Forensics Analysis: Where is the Adversary?"
        ],
        "penulis":"Falih, Muhammad Dzakwan;Satrya, Gandeva Bayu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The evolution of mobile cellular communication has been growing rapidly from 1G to 4G. Unfortunately, with this technology comes an increasing risk of cellular cybercrime. This research proposed a novel methodology to reveal the cybercrime adversary's location by using radio cellular forensics. Several tests were conducted to validate the proposed methodology. This research also presented the digital evidence in a forensically sound manner to support the forensics investigators. Finally, it is concluded that the proposed methodology can be used as a reference for investigators, analysts, and police in cybercrime cases. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The evolution of mobile cellular communication has been growing rapidly from 1G to 4G. Unfortunately, with this technology comes an increasing risk of cellular cybercrime. This research proposed a novel methodology to reveal the cybercrime adversary's location by using radio cellular forensics. Several tests were conducted to validate the proposed methodology. This research also presented the digital evidence in a forensically sound manner to support the forensics investigators. Finally, it is concluded that the proposed methodology can be used as a reference for investigators, analysts, and police in cybercrime cases. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Numerical simulation of solitary wave attenuation by vegetation with non-hydrostatic model"
        ],
        "penulis":"Adytia D.;Fadhilah M.A.;Pudjaprasetya S.R.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper solitary wave attenuation by vegetation is investigated by using numerical simulation. To take into account effects of dispersion, we use a dispersive and nonlinear wave mode; the non-hydrostatic with 1 vertical layer. The damping by vegetation is modelled by using mean drag force using Morison's formula. The dissipative term is added in the momentum equation. The wave model is implemented numerically using finite volume with momentum conservative staggered grid scheme. To test the numerical scheme implementation, we simulate a physical experiment of solitary wave attenuation by vegetation of Huang et al. 2011. Comparison with experimental data shows that the results of simulation agree quite well. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper solitary wave attenuation by vegetation is investigated by using numerical simulation. To take into account effects of dispersion, we use a dispersive and nonlinear wave mode; the non-hydrostatic with 1 vertical layer. The damping by vegetation is modelled by using mean drag force using Morison's formula. The dissipative term is added in the momentum equation. The wave model is implemented numerically using finite volume with momentum conservative staggered grid scheme. To test the numerical scheme implementation, we simulate a physical experiment of solitary wave attenuation by vegetation of Huang et al. 2011. Comparison with experimental data shows that the results of simulation agree quite well. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Perceptions, knowledge and adaptation about climate change: A study on farmers of haor areas after a flash flood in Bangladesh"
        ],
        "penulis":"Ferdushi, Kanis Fatama;Ismail, Mohd. Tahir;Kamil, Anton Abdulbasah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Bangladesh remains one of the most vulnerable countries in the world to the effects of climate change. Given the reliance of a large segment of the population on the agricultural sector for both their livelihoods as well as national food security, climate change adaptation in the agricultural sector is crucial for continued national food security and economic growth. Using household data from lowland rice farmers of selected haor areas in Sylhet, the current work presents an analysis of the determinants behind the implementation of different climate change adaptation strategies by lowland rice farmers. The first objective of this study was to explore the extent of awareness of climate change within this population as well as the type of opinions held by lowland rice farmers with respect to climate change. To serve this purpose, a severity index (SI) was developed and subsequently employed to evaluate the perceptions and attitudes of 378 farmers with respect to climate change vulnerability. Respondents were interviewed with respect to climate change related circumstances they faced in their daily lives. Attained SI index values ranged from 69.18% to 93.52%. The SI for the perception \"Climate change affects rice production\" was measured as 93.52%. Using data collected from the same 378 farmers, a logistic regression was carried out to investigate the impact of socio-economic and institutional factors on adaptation. The results show that credit from non-government organizations is highly statistically significant for adaptation, and that rural market structure also has a positive effect on adaptation. Among the studied factors, credit from non-governmental organizations (NGOs) was found to be the most important factor for adaptation. The results of this work further indicate that marginal farmers would benefit from government (GoB) funded seasonal training activities that cover pertinent information regarding adaptation after flash floods. Additionally, the authors of this piece recommend timely issuance of government-assisted credit during early flash floods to afflicted farmers, as such an initiative can aid farmers in adapting different strategies to mitigate losses and enhance their productivity as well as livelihood. \u00a9 2019 by the authors.",
            "Sustainable Development Goals mapped to this documentZero hungerGoal 2Decent work and economic growthGoal 8Sustainable cities and communitiesGoal 11Climate actionGoal 13Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Bangladesh remains one of the most vulnerable countries in the world to the effects of climate change. Given the reliance of a large segment of the population on the agricultural sector for both their livelihoods as well as national food security, climate change adaptation in the agricultural sector is crucial for continued national food security and economic growth. Using household data from lowland rice farmers of selected haor areas in Sylhet, the current work presents an analysis of the determinants behind the implementation of different climate change adaptation strategies by lowland rice farmers. The first objective of this study was to explore the extent of awareness of climate change within this population as well as the type of opinions held by lowland rice farmers with respect to climate change. To serve this purpose, a severity index (SI) was developed and subsequently employed to evaluate the perceptions and attitudes of 378 farmers with respect to climate change vulnerability. Respondents were interviewed with respect to climate change related circumstances they faced in their daily lives. Attained SI index values ranged from 69.18% to 93.52%. The SI for the perception \"Climate change affects rice production\" was measured as 93.52%. Using data collected from the same 378 farmers, a logistic regression was carried out to investigate the impact of socio-economic and institutional factors on adaptation. The results show that credit from non-government organizations is highly statistically significant for adaptation, and that rural market structure also has a positive effect on adaptation. Among the studied factors, credit from non-governmental organizations (NGOs) was found to be the most important factor for adaptation. The results of this work further indicate that marginal farmers would benefit from government (GoB) funded seasonal training activities that cover pertinent information regarding adaptation after flash floods. Additionally, the authors of this piece recommend timely issuance of government-assisted credit during early flash floods to afflicted farmers, as such an initiative can aid farmers in adapting different strategies to mitigate losses and enhance their productivity as well as livelihood. \u00a9 2019 by the authors."
        ]
    },
    {
        "judul":[
            "Analysis of attribute selection and classification algorithm applied to hepatitis patients"
        ],
        "penulis":"Samsuddin, Sherylaidah;Shah, Zuraini Ali;Rohmat Saedudin R.D.;Kasim, Shahreen;Seah, Choon Sen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Data mining techniques are widely used in classification, attribute selection and prediction in the field of bioinformatics because it helps to discover meaningful new correlations, patterns and trends by sifting through large volume of data, using pattern recognition technologies as well as statistical and mathematical techniques. Hepatitis is one of the most important health problem in the world. Many studies have been performed in the diagnosis of hepatitis disease but medical diagnosis is quite difficult and visual task which is mostly done by doctors. Therefore, this research is conducted to analyse the attribute selection and classification algorithm that applied to hepatitis patients. In order to achieve goals, WEKA tool is used to conduct the experiment with different attribute selector and classification algorithm . Hepatitis dataset that are used is taken from UC Irvine repository. This research deals with various attribute selector namely CfsSubsetEval, WrapperSubsetEval, GainRatioSubsetEval and CorrelationAttributeEval. The classification algorithm that used in this research are NaiveBayesUpdatable, SMO, KStar, RandomTree and SimpleLogistic. The results of the classification model are time and accuracy. Finally, it concludes that the best attribute selector is CfsSubsetEval while the best classifier is given to SMO because SMO performance is better than other classification techniques for hepatitis patients. \u00a9 2019 International Journal on Advanced Science Engineering Information Technology.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Affordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data mining techniques are widely used in classification, attribute selection and prediction in the field of bioinformatics because it helps to discover meaningful new correlations, patterns and trends by sifting through large volume of data, using pattern recognition technologies as well as statistical and mathematical techniques. Hepatitis is one of the most important health problem in the world. Many studies have been performed in the diagnosis of hepatitis disease but medical diagnosis is quite difficult and visual task which is mostly done by doctors. Therefore, this research is conducted to analyse the attribute selection and classification algorithm that applied to hepatitis patients. In order to achieve goals, WEKA tool is used to conduct the experiment with different attribute selector and classification algorithm . Hepatitis dataset that are used is taken from UC Irvine repository. This research deals with various attribute selector namely CfsSubsetEval, WrapperSubsetEval, GainRatioSubsetEval and CorrelationAttributeEval. The classification algorithm that used in this research are NaiveBayesUpdatable, SMO, KStar, RandomTree and SimpleLogistic. The results of the classification model are time and accuracy. Finally, it concludes that the best attribute selector is CfsSubsetEval while the best classifier is given to SMO because SMO performance is better than other classification techniques for hepatitis patients. \u00a9 2019 International Journal on Advanced Science Engineering Information Technology."
        ]
    },
    {
        "judul":[
            "Digital leadership role in developing business model innovation and customer experience orientation in industry 4.0"
        ],
        "penulis":"Mihardjo, Leonardus W. W.;Sasmoko, Sasmoko;Alamsjah, Firdaus;Elidjen, Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 4.0 brings a new challenge for incumbent firms to anticipate new business model offered by emerging entries. The digital transformation is required by incumbent to develop innovation on product and service business model based on customer experience orientation. To support this transformation, strong digital leader is important to assure the development of this transformation. The study on the role of digital leadership on business model innovation and customer experience has not been explored, significantly, Hence, this research aims at assessing the role of digital leadership, whether it directly or indirectly influences the customer experience orientation in developing business model innovation. This study was conducted through survey to 88 senior leader respondents from Indonesia telecommunication firms, in which Smart-PLS application was used to analyze the data. The result show that digital leadership had direct and indirect impacts on customer experience orientation in developing business model innovation. The practical implications of these findings are recommended for the senior leader of management of telecommunications industries in Indonesia to strengthen digital leadership capability in conjunction with the development of business model innovation and customer experience orientation. Further research can be explored by expanding the sample, industry, statistical application and longitudinal study. \u00a9 2019 by the authors; licensee Growing Science, Canada. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 4.0 brings a new challenge for incumbent firms to anticipate new business model offered by emerging entries. The digital transformation is required by incumbent to develop innovation on product and service business model based on customer experience orientation. To support this transformation, strong digital leader is important to assure the development of this transformation. The study on the role of digital leadership on business model innovation and customer experience has not been explored, significantly, Hence, this research aims at assessing the role of digital leadership, whether it directly or indirectly influences the customer experience orientation in developing business model innovation. This study was conducted through survey to 88 senior leader respondents from Indonesia telecommunication firms, in which Smart-PLS application was used to analyze the data. The result show that digital leadership had direct and indirect impacts on customer experience orientation in developing business model innovation. The practical implications of these findings are recommended for the senior leader of management of telecommunications industries in Indonesia to strengthen digital leadership capability in conjunction with the development of business model innovation and customer experience orientation. Further research can be explored by expanding the sample, industry, statistical application and longitudinal study. \u00a9 2019 by the authors; licensee Growing Science, Canada. All rights reserved."
        ]
    },
    {
        "judul":[
            "Optimal Planning of Solar PV Using Simple Model for New Feed-in Tariff in Indonesia"
        ],
        "penulis":"Adam, Kharisma Bani;Miyauchi, Hajime;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia is still struggling to attract the investor to involve in solar photovoltaic (PV) project. There is a rapid transformation in PV regulation by the government. Four regulation related to solar PV is delivered from 2016 until 2018. In 2018, the feed-in tariff regulation was established. The feed-in tariff aims the electricity customer to install the PV system and inject the excess energy to the grid. However, this rapid regulation changing is not yet attracting developer nor customer to invest in the solar PV. This paper proposes a simple model to calculate the optimal size of PV for new feed-in tariff regulation in Indonesia. Feed-in tariff regulation allows the customer to inject the energy produced by PV to the grid. The regulation provides 65% compensation of electricity price from energy sent to the grid with several limitations. There is difficulty to estimate daily energy data. Then, a technical calculation is proposed by using a simple model so that it can help the customer in sizing the solar PV system. Adding to the proposal of the methodology, this research also develops an application to help customers in calculating the optimal size of solar PV and its profitability. The new feed-in tariff rule will be an attraction for the customer. However, it needs a comprehensive calculation so that solar PV can be profitable. Oversized PV systems can cause financial losses with the large investment and limitation on the calculation of energy injected into the grid. The result shows that the PV simple model is successfully developed to help the consumer obtain the optimal PV size. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Climate actionGoal 13Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is still struggling to attract the investor to involve in solar photovoltaic (PV) project. There is a rapid transformation in PV regulation by the government. Four regulation related to solar PV is delivered from 2016 until 2018. In 2018, the feed-in tariff regulation was established. The feed-in tariff aims the electricity customer to install the PV system and inject the excess energy to the grid. However, this rapid regulation changing is not yet attracting developer nor customer to invest in the solar PV. This paper proposes a simple model to calculate the optimal size of PV for new feed-in tariff regulation in Indonesia. Feed-in tariff regulation allows the customer to inject the energy produced by PV to the grid. The regulation provides 65% compensation of electricity price from energy sent to the grid with several limitations. There is difficulty to estimate daily energy data. Then, a technical calculation is proposed by using a simple model so that it can help the customer in sizing the solar PV system. Adding to the proposal of the methodology, this research also develops an application to help customers in calculating the optimal size of solar PV and its profitability. The new feed-in tariff rule will be an attraction for the customer. However, it needs a comprehensive calculation so that solar PV can be profitable. Oversized PV systems can cause financial losses with the large investment and limitation on the calculation of energy injected into the grid. The result shows that the PV simple model is successfully developed to help the consumer obtain the optimal PV size. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Realization of achromatic microwave metasurface lenses"
        ],
        "penulis":"Fathnan, Ashif A.;Powell, David A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Achromatic metasurfaces have shown promising features whereby a constant wave-manipulation function can be implemented in a wide bandwidth of operation. Despite ample works on achieving achromatism using metasurfaces, there is a question of how far a metasurface can maintain broadband constant operation. Based on common three metallic layers of a transmission-type metasurface, we previously derived a physical limit, showing that there is a trade-off relation between metasurface aperture size and bandwidth. Here, we verify these findings, using an analytical study of two different metasurface lenses. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Achromatic metasurfaces have shown promising features whereby a constant wave-manipulation function can be implemented in a wide bandwidth of operation. Despite ample works on achieving achromatism using metasurfaces, there is a question of how far a metasurface can maintain broadband constant operation. Based on common three metallic layers of a transmission-type metasurface, we previously derived a physical limit, showing that there is a trade-off relation between metasurface aperture size and bandwidth. Here, we verify these findings, using an analytical study of two different metasurface lenses. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A regression approach for prediction of Youtube views"
        ],
        "penulis":"Rui, Lau Tian;Afif, Zehan Afizah;Saedudin, R. D. Rohmat;Mustapha, Aida;Razali, Nazim;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "YouTube has grown to be the number one video streaming platform on Internet and home to millions of content creator around the globe. Predicting the potential amount of YouTube views has proven to be extremely important for helping content creator to understand what type of videos the audience prefers to watch. In this paper, we will be introducing two types of regression models for predicting the total number of views a YouTube video can get based on the statistic that are available to our disposal. The dataset we will be using are released by YouTube to the public. The accuracy of both models are then compared by evaluating the mean absolute error and relative absolute error taken from the result of our experiment. The results showed that Ordinary Least Square method is more capable as compared to the Online Gradient Descent Method in providing a more accurate output because the algorithm allows us to find a gradient that is close as possible to the dependent variables despite having an only above average prediction. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "YouTube has grown to be the number one video streaming platform on Internet and home to millions of content creator around the globe. Predicting the potential amount of YouTube views has proven to be extremely important for helping content creator to understand what type of videos the audience prefers to watch. In this paper, we will be introducing two types of regression models for predicting the total number of views a YouTube video can get based on the statistic that are available to our disposal. The dataset we will be using are released by YouTube to the public. The accuracy of both models are then compared by evaluating the mean absolute error and relative absolute error taken from the result of our experiment. The results showed that Ordinary Least Square method is more capable as compared to the Online Gradient Descent Method in providing a more accurate output because the algorithm allows us to find a gradient that is close as possible to the dependent variables despite having an only above average prediction. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Radio resource allocation with the fairness metric for low density signature OFDM in underlay cognitive radio networks"
        ],
        "penulis":"Meylani, Linda;Kurniawan, Adit;Arifianto, M. Sigit;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Low density signature orthogonal frequency division multiplexing (LDS-OFDM), one type of non-orthogonal multiple access (NOMA), is a special case of multi-carrier code division multiple access (MC-CDMA). In LDS-OFDM, each user is allowed to spread its symbols in a small set of subcarriers, and there is only a small group of users that are permitted to share the same subcarrier. In this paper, we study the resource allocation for LDS-OFDM as the multiple access model in cognitive radio networks. In our scheme, SUs are allocated to certain subcarriers based on minimum interference or higher SINR in each subcarrier. To overcome the problem where SUs were allocated less than the subcarriers, we propose interference limit-based resource allocation with the fairness metric (ILRA-FM). Simulation results show that, compared to the ILRA algorithm, the ILRA-FM algorithm has a lower outage probability and higher fairness metric value and also a higher throughput fairness index. \u00a9 2019 by the authors. Licensee MDPI, Basel, Switzerland.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Low density signature orthogonal frequency division multiplexing (LDS-OFDM), one type of non-orthogonal multiple access (NOMA), is a special case of multi-carrier code division multiple access (MC-CDMA). In LDS-OFDM, each user is allowed to spread its symbols in a small set of subcarriers, and there is only a small group of users that are permitted to share the same subcarrier. In this paper, we study the resource allocation for LDS-OFDM as the multiple access model in cognitive radio networks. In our scheme, SUs are allocated to certain subcarriers based on minimum interference or higher SINR in each subcarrier. To overcome the problem where SUs were allocated less than the subcarriers, we propose interference limit-based resource allocation with the fairness metric (ILRA-FM). Simulation results show that, compared to the ILRA algorithm, the ILRA-FM algorithm has a lower outage probability and higher fairness metric value and also a higher throughput fairness index. \u00a9 2019 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Knowledge sharing and transformational leadership"
        ],
        "penulis":"Mihardjo, Leonardus W.W.;Sasmoko;Alamsjah, Firdaus;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The principal objective of the current study is to explore the link between knowledge sharing transformational leadership style, team performance, and mutual trust. In addition to that moderating role of mutual trust is also examined. The study has broached the argument that knowledge sharing and transformational leadership style improves team performance. Findings of the current study suggest creativity is a process that starts in the team through the sharing of knowledge. The currents study is also of the view that the that the process of creativity starts in the situation when the team members share knowledge through coordination and it is also argued that the much of the knowledge is shared when team members meet to share knowledge in a given area, much of which is tacit. Sharing such tacit knowledge creates a flow of novel ideas that contribute to successful outcomes, such as new products, processes and patents. The findings of the study have shown agreement with the proposed or hypothesize results. The study has used PLS-SEM to analyses the data. The study will be helpful for policy makers in the researcher in understanding the issues related to supply chain, its integration, flexibility, and internal performance. \u00a9 2019, General Jonas Zemaitis Military Academy of Lithuania.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The principal objective of the current study is to explore the link between knowledge sharing transformational leadership style, team performance, and mutual trust. In addition to that moderating role of mutual trust is also examined. The study has broached the argument that knowledge sharing and transformational leadership style improves team performance. Findings of the current study suggest creativity is a process that starts in the team through the sharing of knowledge. The currents study is also of the view that the that the process of creativity starts in the situation when the team members share knowledge through coordination and it is also argued that the much of the knowledge is shared when team members meet to share knowledge in a given area, much of which is tacit. Sharing such tacit knowledge creates a flow of novel ideas that contribute to successful outcomes, such as new products, processes and patents. The findings of the study have shown agreement with the proposed or hypothesize results. The study has used PLS-SEM to analyses the data. The study will be helpful for policy makers in the researcher in understanding the issues related to supply chain, its integration, flexibility, and internal performance. \u00a9 2019, General Jonas Zemaitis Military Academy of Lithuania."
        ]
    },
    {
        "judul":[
            "Complexity Analysis of EEG Signal in Patients with Cognitive Impairment Using the Hjorth Descriptor"
        ],
        "penulis":"Hadiyoso, Sugondo;Mengko, Tati Latifah E. R.;Zakaria, Hasballah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Elderly people with mild cognitive impairment earlier, have a higher potential to develop Alzheimer's. This degenerative process that tends to be progressive can be avoided by proper treatment at the initial onset. One of the low cost medical modalities for this symptom analysis is electroencephalogram (EEG). Spectral analysis is considered capable of describing pathological conditions and is normally characterized by the slowing of the EEG signal. However, bias can occur because noise artifacts have a dominant power at low frequencies. Therefore, this research proposes an approach based on complexity analysis for the differentiation of subjects with cognitive impairment and normal subjects as an attempt to early detection of Alzheimer's. This analysis can be used as a support for traditional spectral analysis so that it increases accuracy. The study was conducted on 27 subjects consisting of 16 normal and 11 MCI patients who were recorded using 19 channel EEG. The Hjorth descriptor was applied to calculate complexity parameters in both EEG wave groups. Statistical analysis was applied to find significant differences. Results showed that MCI groups have lower complexity values than normal in almost all channels. Significant differences was found in F3 and Fz channels (p <0.05) compared with averages of all channels. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Elderly people with mild cognitive impairment earlier, have a higher potential to develop Alzheimer's. This degenerative process that tends to be progressive can be avoided by proper treatment at the initial onset. One of the low cost medical modalities for this symptom analysis is electroencephalogram (EEG). Spectral analysis is considered capable of describing pathological conditions and is normally characterized by the slowing of the EEG signal. However, bias can occur because noise artifacts have a dominant power at low frequencies. Therefore, this research proposes an approach based on complexity analysis for the differentiation of subjects with cognitive impairment and normal subjects as an attempt to early detection of Alzheimer's. This analysis can be used as a support for traditional spectral analysis so that it increases accuracy. The study was conducted on 27 subjects consisting of 16 normal and 11 MCI patients who were recorded using 19 channel EEG. The Hjorth descriptor was applied to calculate complexity parameters in both EEG wave groups. Statistical analysis was applied to find significant differences. Results showed that MCI groups have lower complexity values than normal in almost all channels. Significant differences was found in F3 and Fz channels (p <0.05) compared with averages of all channels. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Performance of Outdoor Lamp Implementation for Visible Light Communication under Ambient Environment"
        ],
        "penulis":"Sitanggang, Ronaldo Soritua;Darlis, Denny;Noviyanti, Karina Wahyu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Visible Light Communication is an optical wireless communication technology that convey information by modulating visible light over some standard illumination. Interest in the field of VLC has grown rapidly along with the development of LEDs as a source of lighting. The motivation is clear: If the room is lit by an LED, why not use it further for the communication provider, along with the lighting facilities at the same time? At the sending side, VLC technology uses LED lighting lamps which are currently very popular to replace incandescent lamps and TL (Fluorescent Lamp) lamps. Visible light communication has many advantages, including security, speed, and convenience to be applied to users to send various types of information including digital data such as text and images. Several studies have been conducted previously regarding the application of information delivery systems using VLC such as sending voice, digital data, images, and video. However, it has not been clearly stated the influence of various lighting lamps used on the system mentioned above such as electrical and optical power used, the angle of transmission and optimal distance with the influence of environmental conditions that cause information transmission losses. Data that can be sent well use yard lighting with a maximum distance of 130cm with 15lx light intensity, street lighting with a maximum distance of 400cm with 6lx light intensity, and vehicle lights with a maximum distance of 270cm with 12lx light intensity. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Visible Light Communication is an optical wireless communication technology that convey information by modulating visible light over some standard illumination. Interest in the field of VLC has grown rapidly along with the development of LEDs as a source of lighting. The motivation is clear: If the room is lit by an LED, why not use it further for the communication provider, along with the lighting facilities at the same time? At the sending side, VLC technology uses LED lighting lamps which are currently very popular to replace incandescent lamps and TL (Fluorescent Lamp) lamps. Visible light communication has many advantages, including security, speed, and convenience to be applied to users to send various types of information including digital data such as text and images. Several studies have been conducted previously regarding the application of information delivery systems using VLC such as sending voice, digital data, images, and video. However, it has not been clearly stated the influence of various lighting lamps used on the system mentioned above such as electrical and optical power used, the angle of transmission and optimal distance with the influence of environmental conditions that cause information transmission losses. Data that can be sent well use yard lighting with a maximum distance of 130cm with 15lx light intensity, street lighting with a maximum distance of 400cm with 6lx light intensity, and vehicle lights with a maximum distance of 270cm with 12lx light intensity. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Supply Chain Performance Measurement System Development for Shoes SME using Subcontract Production Strategy Based on Integrated SCOR-BSC Model"
        ],
        "penulis":"Fauzi A.R.;Ridwan A.Y.;Juliani W.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Textile and apparel companies are a company that is widely available in Indonesia. Small and Medium Enterprise is a business that is growing rapidly and has many competitors in Indonesia, one of which is engaged in the textile sector. SME proves as one of the businesses that can survive when the economic crisis hit the world in 1997-1998 and had an impact on the Indonesian economy [1]. Even so, SME has several problems, one of which is to develop its business. Performance measurement system required to develop its business. With a performance measurement system, SME can monitor business performance that can help companies in making future decisions to improve the performance of the company. This paper focuses on SME engaged in the shoe industry and using subcontract as its production strategy. This paper also using integrated SCOR-BSC model as the baseline to determine the KPI needed by the Shoe SME. The result of this research is integrated SCOR-BSC KPI which can be used as the basis on performance measurement system making. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Textile and apparel companies are a company that is widely available in Indonesia. Small and Medium Enterprise is a business that is growing rapidly and has many competitors in Indonesia, one of which is engaged in the textile sector. SME proves as one of the businesses that can survive when the economic crisis hit the world in 1997-1998 and had an impact on the Indonesian economy [1]. Even so, SME has several problems, one of which is to develop its business. Performance measurement system required to develop its business. With a performance measurement system, SME can monitor business performance that can help companies in making future decisions to improve the performance of the company. This paper focuses on SME engaged in the shoe industry and using subcontract as its production strategy. This paper also using integrated SCOR-BSC model as the baseline to determine the KPI needed by the Shoe SME. The result of this research is integrated SCOR-BSC KPI which can be used as the basis on performance measurement system making. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Development of Web Stock Opname Application with SAP Business One Using Scrum Method"
        ],
        "penulis":"Ramadhan, Aulia;Lubis, Muharman;Puspitasari, Warih;Lubis, Arif Ridho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "SME Company (Small and Medium Enterprises) is a small-scale business unit, which require to have inventory function as an important asset in the company to ensure the availability of goods and stock within the warehouse process. Thus, an inventory management process calls Stock opname that is carried out to conduct calculation and computation have been established. Previously, majority activity process have been carried out manually in which the employees check and record the available items through reporting them to the managers without using any kind of software whatsoever, only a piece of document that have no integration with other business processes. Therefore, the data that is not processed in the real-time might be different at certain period and unmatched with the real situation can lead to the wrong decision making. Thus, the application should be developed, which in this case utilizing the web application to be integrated with SAP Business One to solve existing problems within the company to provide accurate and real-time inventory information management. It also has objective to maintain updated information with other department, unit or even business modules within the SME companies. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SME Company (Small and Medium Enterprises) is a small-scale business unit, which require to have inventory function as an important asset in the company to ensure the availability of goods and stock within the warehouse process. Thus, an inventory management process calls Stock opname that is carried out to conduct calculation and computation have been established. Previously, majority activity process have been carried out manually in which the employees check and record the available items through reporting them to the managers without using any kind of software whatsoever, only a piece of document that have no integration with other business processes. Therefore, the data that is not processed in the real-time might be different at certain period and unmatched with the real situation can lead to the wrong decision making. Thus, the application should be developed, which in this case utilizing the web application to be integrated with SAP Business One to solve existing problems within the company to provide accurate and real-time inventory information management. It also has objective to maintain updated information with other department, unit or even business modules within the SME companies. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Study of External Force and Impedance Scheme on Stroke Rehabilitation Robot Manipulator"
        ],
        "penulis":"Sumarso, Ade Hasan;Widyotriatmo, Augie;Purnama, Irwan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents rehabilitation robot with torque control with impedance scheme for post-stroke patients in the upper limb of the shoulder. This impedance scheme consists of external force input and impedance value. The external force input comes from the load cell at the end of the robot (the end effector), which is generated by the patient's force. The input force consists of two Cartesian directions, which will affect the robot dynamic torque for the X-axis and Y-axis. Meanwhile, the value of the impedance in the robotic system is provided by the therapist who handles the stroke patients. The amount of impedance in the robotic system can be adjusted according to the patient's condition. In this paper, we used 3 DOF (Degree of Freedom) self-produced robots. The rehabilitation trajectory consists of two parameters, the position parameter, and the torque control parameter in the impedance system. The impedance scheme in the robotic system use impedance characteristics and Proportional Integral (PI) controller. Proportional Integral (PI) controller is used as a simulation control in tracking errors of position and the torque impedance of the robot. With a simple controller, the characteristics relationship between the changes in the magnitude of the external force produced by the patient and the change in impedance values given to the robot system are obtained. By knowing these characteristics, robots can interact with various types of stroke patients. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents rehabilitation robot with torque control with impedance scheme for post-stroke patients in the upper limb of the shoulder. This impedance scheme consists of external force input and impedance value. The external force input comes from the load cell at the end of the robot (the end effector), which is generated by the patient's force. The input force consists of two Cartesian directions, which will affect the robot dynamic torque for the X-axis and Y-axis. Meanwhile, the value of the impedance in the robotic system is provided by the therapist who handles the stroke patients. The amount of impedance in the robotic system can be adjusted according to the patient's condition. In this paper, we used 3 DOF (Degree of Freedom) self-produced robots. The rehabilitation trajectory consists of two parameters, the position parameter, and the torque control parameter in the impedance system. The impedance scheme in the robotic system use impedance characteristics and Proportional Integral (PI) controller. Proportional Integral (PI) controller is used as a simulation control in tracking errors of position and the torque impedance of the robot. With a simple controller, the characteristics relationship between the changes in the magnitude of the external force produced by the patient and the change in impedance values given to the robot system are obtained. By knowing these characteristics, robots can interact with various types of stroke patients. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Evaluation of optimum golomb ruler performance for NG-PON2 networks"
        ],
        "penulis":"Priambodo, Satrio;Hambali, Akhmad;Pamukti, Brian;Melati, Putri Puspita;Putra, Raga Filydevilia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, we evaluate Optimum Golomb Ruler (OGR) for Next Generation Passive Optical Network Stage2 (NG-PON2) to overcome natural disaster namely non-linear effect. Non-Linear effect is the unavoidable tragedy from natural fiber effect, and biggest issue is Four Wave Mixing (FWM). To expand the capacity, NG-PON2 uses four wavelengths, where each wavelength transmit up to 10 Gbps for downstream. The impact of FWM decrease performance in NG-PON2, significantly, without exploit any mitigations. In addition, this paper focuses on the effect of the Optimum Unequal Channel Separation (OUCS) method with Golomb Ruler for the FWM effect on NG-PON2. Our simulation shows that after employee OGR, performance increase effectively at a distance of 25-31 km. The result shows that Q-Factor values, Signal to Noise Ratio (SNR), and received power improve around 14.27%, 40.26%, and 0.34%, respectively. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we evaluate Optimum Golomb Ruler (OGR) for Next Generation Passive Optical Network Stage2 (NG-PON2) to overcome natural disaster namely non-linear effect. Non-Linear effect is the unavoidable tragedy from natural fiber effect, and biggest issue is Four Wave Mixing (FWM). To expand the capacity, NG-PON2 uses four wavelengths, where each wavelength transmit up to 10 Gbps for downstream. The impact of FWM decrease performance in NG-PON2, significantly, without exploit any mitigations. In addition, this paper focuses on the effect of the Optimum Unequal Channel Separation (OUCS) method with Golomb Ruler for the FWM effect on NG-PON2. Our simulation shows that after employee OGR, performance increase effectively at a distance of 25-31 km. The result shows that Q-Factor values, Signal to Noise Ratio (SNR), and received power improve around 14.27%, 40.26%, and 0.34%, respectively. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Grazing enhances species diversity in grassland communities"
        ],
        "penulis":"Pulungan, Muhammad Almaududi;Suzuki, Shota;Gavina, Maica Krizna Areja;Tubay, Jerrold M.;Ito, Hiromu;Nii, Momoka;Ichinose, Genki;Okabe, Takuya;Ishida, Atsushi;Shiyomi, Masae;Togashi, Tatsuya;Yoshimura, Jin;Morita, Satoru;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In grassland studies, an intermediate level of grazing often results in the highest species diversity. Although a few hypotheses have been proposed to explain this unimodal response of species diversity to grazing intensity, no convincing explanation has been provided. Here, we build a lattice model of a grassland community comprising multiple species with various levels of grazing. We analyze the relationship between grazing and plant diversity in grasslands under variable intensities of grazing pressure. The highest species diversity is observed at an intermediate grazing intensity. Grazers suppress domination by the most superior species in birth rate, resulting in the coexistence of inferior species. This unimodal grazing effect disappears with the introduction of a small amount of nongrazing natural mortality. Unimodal patterns of species diversity may be limited to the case where grazers are the principal source of natural mortality. \u00a9 2019, The Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In grassland studies, an intermediate level of grazing often results in the highest species diversity. Although a few hypotheses have been proposed to explain this unimodal response of species diversity to grazing intensity, no convincing explanation has been provided. Here, we build a lattice model of a grassland community comprising multiple species with various levels of grazing. We analyze the relationship between grazing and plant diversity in grasslands under variable intensities of grazing pressure. The highest species diversity is observed at an intermediate grazing intensity. Grazers suppress domination by the most superior species in birth rate, resulting in the coexistence of inferior species. This unimodal grazing effect disappears with the introduction of a small amount of nongrazing natural mortality. Unimodal patterns of species diversity may be limited to the case where grazers are the principal source of natural mortality. \u00a9 2019, The Author(s)."
        ]
    },
    {
        "judul":[
            "Smart pot implementation using fuzzy logic"
        ],
        "penulis":"Karimah, Siti Amatullah;Rakhmatsyah, Andrian;Suwastika, Novian Anggis;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The paper present automated plant watering system based on Internet of Things. This system is expected to replace conventional system where the plant watering is done manually by humans. The system will also be the sole problem of land constraints, especially in densely populated urban areas. The system uses Soil Moisture, DHT11 and also pH Meter sensors to obtain soil moisture, humidity and acidity (pH) soil data. Next will be done data acquisition by XBee which will be forwarded to gateway where filtering data be done. After that the gateway will send data to the hosting server that will run the fuzzy algorithm to govern the actuator to be able to do watering automatically. The result shows the success of the system of plant watering, where the plants treated with Smart Pot have a plant height of 23 cm and a leaf width of 6 cm, while the manually treated plant has a height of 19 cm and a leaf width of 4.5cm. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The paper present automated plant watering system based on Internet of Things. This system is expected to replace conventional system where the plant watering is done manually by humans. The system will also be the sole problem of land constraints, especially in densely populated urban areas. The system uses Soil Moisture, DHT11 and also pH Meter sensors to obtain soil moisture, humidity and acidity (pH) soil data. Next will be done data acquisition by XBee which will be forwarded to gateway where filtering data be done. After that the gateway will send data to the hosting server that will run the fuzzy algorithm to govern the actuator to be able to do watering automatically. The result shows the success of the system of plant watering, where the plants treated with Smart Pot have a plant height of 23 cm and a leaf width of 6 cm, while the manually treated plant has a height of 19 cm and a leaf width of 4.5cm. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "My locker: Loaning locker system based on QR code"
        ],
        "penulis":"Negara, Ridha Muldina;Tulloh, Rohmat;Nandy Hadiansyah P.N.;Zahra, Rizka Triani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Locker is a place that people usually use to keep things. Commonly, lockers are found in campus hall, tourist site, or other public places. Lockers that we face in a daily activities usually still using a conventional keys that we can\u2019t guarantee the security of it. The focus of this research is on online locker rental system that can be accessed through android smartphone and MyLocker application by scanning the QR code. Within this system, occurred website that can be used to see the filled locker or the unfilled locker and there\u2019s admin page, to see the summary of data user and the agreement of top up request. The devices component that we used are NodeMCU, Relay, solenoid door lock and magnetic door switch. From the result of the test that done by system worked so well and delayed that we achieved while we did the QR code reading experiment with of lux, gap, and gradient slope with optimal condition is 1.45 seconds. \u00a9 BEIESP.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Locker is a place that people usually use to keep things. Commonly, lockers are found in campus hall, tourist site, or other public places. Lockers that we face in a daily activities usually still using a conventional keys that we can\u2019t guarantee the security of it. The focus of this research is on online locker rental system that can be accessed through android smartphone and MyLocker application by scanning the QR code. Within this system, occurred website that can be used to see the filled locker or the unfilled locker and there\u2019s admin page, to see the summary of data user and the agreement of top up request. The devices component that we used are NodeMCU, Relay, solenoid door lock and magnetic door switch. From the result of the test that done by system worked so well and delayed that we achieved while we did the QR code reading experiment with of lux, gap, and gradient slope with optimal condition is 1.45 seconds. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Analysis of Hubs and Authorities Centrality Using Probabilistic Affinity Index (PAI) on directed-weighted graph in Social Network Analysis"
        ],
        "penulis":"Farhan, Muhammad Thomy;Darwiyanto, Eko;Asror, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Social media is a place for interaction that is connected to the internet network, Twitter is one of the most popular social media. In Twitter sometimes someone does not want to be left behind information related to a particular topic, so it is necessary to follow the user related to the topic so that the information is conveyed quickly. In this study, an analysis was carried out that applied the Hubs and Authorities Centrality method to determine user rankings and the Probabilistic Affinity Index method for weighting values. The results of authority centrality ranking can be used as a list of recommendations of a user who plays a role or has information about a particular topic and the results of centrality hub ranking can be used as a list of recommendations of a user who has an interest in a particular topic. From the testing in this study, changes in the number of other users that are related to the user have the largest average change in centrality value of 0.01188. While the change in the number of relations has the largest average change in the centrality value of 1.44087\u00d710-9. Based on these tests, the number of other users that are related to the user has a large influence on the results of ranking compared to the number of relationships to other users. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Social media is a place for interaction that is connected to the internet network, Twitter is one of the most popular social media. In Twitter sometimes someone does not want to be left behind information related to a particular topic, so it is necessary to follow the user related to the topic so that the information is conveyed quickly. In this study, an analysis was carried out that applied the Hubs and Authorities Centrality method to determine user rankings and the Probabilistic Affinity Index method for weighting values. The results of authority centrality ranking can be used as a list of recommendations of a user who plays a role or has information about a particular topic and the results of centrality hub ranking can be used as a list of recommendations of a user who has an interest in a particular topic. From the testing in this study, changes in the number of other users that are related to the user have the largest average change in centrality value of 0.01188. While the change in the number of relations has the largest average change in the centrality value of 1.44087\u00d710-9. Based on these tests, the number of other users that are related to the user has a large influence on the results of ranking compared to the number of relationships to other users. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Assembly line design in final assembly excavator at XYZ Corp using genetic algorithm"
        ],
        "penulis":"Sari, Risty Mayang;Damayanti, Dida Diah;Juliani, Widia;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Large scale manufacturing companies are growing along with ever-increasing demand from consumers, one of which is the heavy equipment industry. Excavators are the products of the heavy equipment division at XYZ Corp, where the Excavator assembly lines are single-model. Based on observations of existing conditions that occur at XYZ Corp, the production still cannot meet the demands of consumers. In the assembly process, the Excavator has a significant time difference from each work station, the distribution of work elements in the assembly process is uneven. In the Final assembly section (Zone C) there is a discrepancy between the takt time of Excavator products which is one reason for not achieving the demand. In resolving these problems, a line balancing process is needed, namely balancing workloads on each workstation. This study applies the Heuristic Priority Rules method as an initial solution and allocation constraint should be added as input from the Genetic Algorithms method to complete line balancing with a single-model system. Problems can be solved by increasing line efficiency from existing conditions by 60.4% to 91.74% and Smoothness index which decreases from 955.54 to 158.3977. The proposed result of balancing the final assembly of the excavator results in a better balance of assembly lines. \u00a9 2019 Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Large scale manufacturing companies are growing along with ever-increasing demand from consumers, one of which is the heavy equipment industry. Excavators are the products of the heavy equipment division at XYZ Corp, where the Excavator assembly lines are single-model. Based on observations of existing conditions that occur at XYZ Corp, the production still cannot meet the demands of consumers. In the assembly process, the Excavator has a significant time difference from each work station, the distribution of work elements in the assembly process is uneven. In the Final assembly section (Zone C) there is a discrepancy between the takt time of Excavator products which is one reason for not achieving the demand. In resolving these problems, a line balancing process is needed, namely balancing workloads on each workstation. This study applies the Heuristic Priority Rules method as an initial solution and allocation constraint should be added as input from the Genetic Algorithms method to complete line balancing with a single-model system. Problems can be solved by increasing line efficiency from existing conditions by 60.4% to 91.74% and Smoothness index which decreases from 955.54 to 158.3977. The proposed result of balancing the final assembly of the excavator results in a better balance of assembly lines. \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Simulating water and sediment flow using SWE-convection diffusion model on OpenMP platform"
        ],
        "penulis":"Fakhrusy, Quedi Z.;Anggraeni, Cynthia P.;Gunawan P.H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, 1D SWE-convection reaction diffusion using semi implicit staggered scheme for approximating underwater landslide has been done. The numerical results is shown close enough to the experiment data by Centre National du Machinisme Agricole du G\u00e9nie Rural des Eaux et des For\u00eats (CEMEGREF) laboratory, on December 1994. Here, two scenarios using different parameters in convection diffusion equation are elaborated. Using sediment speed 0.25 and diffusion coefficient of sediment 0.005, the water and sediment error are observed 0.49 and 0.507 respectively at time t = 0.4. Moreover, in this paper, the parallel computing using OpenMP platform is elaborated in the simulation. As the result, computer I with AMD Rayzen(TM) 2400 has the best result for speedup and efficiency with 3.602396 times and 90.0599 % when the final time at t = 0.8s and Nx= 6400 points. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, 1D SWE-convection reaction diffusion using semi implicit staggered scheme for approximating underwater landslide has been done. The numerical results is shown close enough to the experiment data by Centre National du Machinisme Agricole du G\u00e9nie Rural des Eaux et des For\u00eats (CEMEGREF) laboratory, on December 1994. Here, two scenarios using different parameters in convection diffusion equation are elaborated. Using sediment speed 0.25 and diffusion coefficient of sediment 0.005, the water and sediment error are observed 0.49 and 0.507 respectively at time t = 0.4. Moreover, in this paper, the parallel computing using OpenMP platform is elaborated in the simulation. As the result, computer I with AMD Rayzen(TM) 2400 has the best result for speedup and efficiency with 3.602396 times and 90.0599 % when the final time at t = 0.8s and Nx= 6400 points. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Uncoordinated transmissions in multi-way relaying systems"
        ],
        "penulis":"Anwar, Khoirul;Hasan, Mohammad Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper we propose an uncoordinated transmissions scheme in multi-way relaying systems and define its capacity at relatively low signal-to-noise power ratio (SNR) region. We adopt the concept of coded slotted ALOHA (CSA) to overcome the interference problem. To improve the threshold of the offered traffic, we employ iterative demapping algorithm that can decode multi-packet simultaneously. From the capacity bound of the proposed networks which is higher than CSA, we conjecture that the proposed system can achieve a reliable communication with throughput more than 1 packet\/slot. Extrinsic information transfer (EXIT) chart analysis is shown to confirm the conjecture. \u00a9 VDE VERLAG GMBH \u00b7 Berlin \u00b7 Offenbach.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper we propose an uncoordinated transmissions scheme in multi-way relaying systems and define its capacity at relatively low signal-to-noise power ratio (SNR) region. We adopt the concept of coded slotted ALOHA (CSA) to overcome the interference problem. To improve the threshold of the offered traffic, we employ iterative demapping algorithm that can decode multi-packet simultaneously. From the capacity bound of the proposed networks which is higher than CSA, we conjecture that the proposed system can achieve a reliable communication with throughput more than 1 packet\/slot. Extrinsic information transfer (EXIT) chart analysis is shown to confirm the conjecture. \u00a9 VDE VERLAG GMBH \u00b7 Berlin \u00b7 Offenbach."
        ]
    },
    {
        "judul":[
            "Paraphrasing method based on contextual synonym substitution"
        ],
        "penulis":"Barmawi, Ari Moesriami;Muhammad, Ali;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Generating paraphrases is an important component of natural language processing and generation. There are several applications that use paraphrasing, for example linguistic steganography, recommender systems, machine translation, etc. One method for paraphrasing sentences is by using synonym substitution, such as the NGM-based paraphrasing method proposed by Gadag et al. The weakness of this method is that ambiguous meanings frequently occur because the paraphrasing process is based solely on n-gram. This negatively affects the naturalness of the paraphrased sentences. For overcoming this problem, a contextual synonym substitution method is proposed, which aims to increase the naturalness of the paraphrased sentences. Using the proposed method, the paraphrasing process is not only based on n-gram but also on the context of the sentence such that the naturalness is increased. Based on the experimental result, the sentences generated using the proposed method had higher naturalness than the sentences generated using the original method. \u00a9 2019 Published by ITB Journal Publisher,.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Generating paraphrases is an important component of natural language processing and generation. There are several applications that use paraphrasing, for example linguistic steganography, recommender systems, machine translation, etc. One method for paraphrasing sentences is by using synonym substitution, such as the NGM-based paraphrasing method proposed by Gadag et al. The weakness of this method is that ambiguous meanings frequently occur because the paraphrasing process is based solely on n-gram. This negatively affects the naturalness of the paraphrased sentences. For overcoming this problem, a contextual synonym substitution method is proposed, which aims to increase the naturalness of the paraphrased sentences. Using the proposed method, the paraphrasing process is not only based on n-gram but also on the context of the sentence such that the naturalness is increased. Based on the experimental result, the sentences generated using the proposed method had higher naturalness than the sentences generated using the original method. \u00a9 2019 Published by ITB Journal Publisher,."
        ]
    },
    {
        "judul":[
            "The development of archery games using motion capture and VR devices on archery virtual reality"
        ],
        "penulis":"Aprial, Riki Prasetia;Purboyo, Tito Waluyo;Ansori, Anton Raharjo Siswo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Motion capture is the process of capturing motion information, and the location of the subject over time. Animation production is the largest user of the Motion Capture system, examples of applications like movies, broadcasts, games, production stages, demonstration, and more. Motion capture is an attractive method for making movements in computer animation. Motion capture techniques rely on recording and retrieval of movements of humans, animals and inanimate objects as 3-dimensional data. This motion capture technique has various ways of applying it. With the development of technology as it is today, a new technology has been created, namely virtual reality. Virtual reality is a technology that allows us to interact with objects of imagination by using computers and displaying a 3-dimensional atmosphere that seems real. Virtual reality technology has also been widely used in the game world. Game is one of the entertainment media that is the choice of the community to eliminate boredom or just to fill their spare time. In addition to being an entertainment medium, games can also be a learning media to improve one's brain development. In this study, we will discuss archery games using motion capture and virtual reality (VR) devices on archery virtual reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Motion capture is the process of capturing motion information, and the location of the subject over time. Animation production is the largest user of the Motion Capture system, examples of applications like movies, broadcasts, games, production stages, demonstration, and more. Motion capture is an attractive method for making movements in computer animation. Motion capture techniques rely on recording and retrieval of movements of humans, animals and inanimate objects as 3-dimensional data. This motion capture technique has various ways of applying it. With the development of technology as it is today, a new technology has been created, namely virtual reality. Virtual reality is a technology that allows us to interact with objects of imagination by using computers and displaying a 3-dimensional atmosphere that seems real. Virtual reality technology has also been widely used in the game world. Game is one of the entertainment media that is the choice of the community to eliminate boredom or just to fill their spare time. In addition to being an entertainment medium, games can also be a learning media to improve one's brain development. In this study, we will discuss archery games using motion capture and virtual reality (VR) devices on archery virtual reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Adaptation of indigenous community agricultural systems on climate change (case study of Kasepuhan Ciptagelar, Sukabumi Regency, West Java)"
        ],
        "penulis":"Hapsari H.;Hapsari D.;Karyani T.;Fatimah S.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Climate change is a threat to indigenous farming systems that rely on nature. Indigenous society has idiosyncrasies in managing agricultural systems that relate to nature. This study aims to examine the adaptation mechanism of indigenous farming systems to climate change in terms of social, economic, and technological aspects. The study was conducted in Indigenous Village of Kasepuhan Ciptagelar of Sukabumi Regency West Java. The research method is case study. The technique of collecting data through in-depth interviews with selected informants, participant observation, and focus group discussion (FGD). The results showed that the indigenous society of Kasepuhan Ciptagelar experienced the changes that occur in the environment as a result of climate change. Strategies to adapt to these changes, among others: (1) use natural resources in a sustainable manner, (2) preserve the customary positive impact on the environment, (3) do a crop rotation system, (4) managing the communal granary community food security system, (5) maintaining social values in the society, (6) establish cooperation with the agricultural institutions; (7) utilizing communication networks and information systems; (8) with some help from external parties in the repair of facilities and infrastructure, such as transportation and irrigation; (9) perform the processing of non-rice farming profit-oriented, and (10) instilling the values of local wisdom to the younger generation from an early age. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentZero hungerGoal 2Decent work and economic growthGoal 8Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Climate change is a threat to indigenous farming systems that rely on nature. Indigenous society has idiosyncrasies in managing agricultural systems that relate to nature. This study aims to examine the adaptation mechanism of indigenous farming systems to climate change in terms of social, economic, and technological aspects. The study was conducted in Indigenous Village of Kasepuhan Ciptagelar of Sukabumi Regency West Java. The research method is case study. The technique of collecting data through in-depth interviews with selected informants, participant observation, and focus group discussion (FGD). The results showed that the indigenous society of Kasepuhan Ciptagelar experienced the changes that occur in the environment as a result of climate change. Strategies to adapt to these changes, among others: (1) use natural resources in a sustainable manner, (2) preserve the customary positive impact on the environment, (3) do a crop rotation system, (4) managing the communal granary community food security system, (5) maintaining social values in the society, (6) establish cooperation with the agricultural institutions; (7) utilizing communication networks and information systems; (8) with some help from external parties in the repair of facilities and infrastructure, such as transportation and irrigation; (9) perform the processing of non-rice farming profit-oriented, and (10) instilling the values of local wisdom to the younger generation from an early age. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "A review of edge image detection for marker-based augmented reality"
        ],
        "penulis":"Pandiangan, Samuel P.A.H.;Purboyo, Tito Waluyo;Saputra, Randy Erfa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The earlier way to do an image detecting is to use edge image detection. Edge image detection is using some kind of mathematical expression to detect the boundaries between objects between images in real world, with media like camera phone. Many aspects have used edge image detection, one of them is Augmented Reality, especially marker-based Augmented Reality. Augmented reality used edge image detection for reading and detecting the marker in real world and transfer the data to the database in application. This paper will review how the edge detection works and how it works in Augmented Reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN).",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The earlier way to do an image detecting is to use edge image detection. Edge image detection is using some kind of mathematical expression to detect the boundaries between objects between images in real world, with media like camera phone. Many aspects have used edge image detection, one of them is Augmented Reality, especially marker-based Augmented Reality. Augmented reality used edge image detection for reading and detecting the marker in real world and transfer the data to the database in application. This paper will review how the edge detection works and how it works in Augmented Reality. \u00a9 2006-2019 Asian Research Publishing Network (ARPN)."
        ]
    },
    {
        "judul":[
            "Implementation of python source code comparison results with Java using bubble sort method"
        ],
        "penulis":"Insanudin E.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the implementation of Python and Java source code comparison results are more focused on the scale of the ratio of the number of lines of code, file capacity, and access speed. As for the background of this writing because there are so many programming languages that can be used with the same results but overall we do not know which programming language is more optimal and efficient in terms of the number of lines of code better known in the programming language is LOC (Line of Code) capacity of file access speed. In this study, the authors focus only on Java programming language and python course as a first step to know the ratio of the number of lines of code, file capacity, and access density. To determine the comparison there is a method used is bubble short. The results of the implementation of the comparison of these programming languages for Python programming language to produce the number of LOC (line of code) or the number of lines of code as much as 10, the capacity of the file extension.py by 506 bytes and txt extension of 397 bytes and access speed approximately for less more 4 seconds. While Java produces the number of LOC (line of code) or the number of lines of code as much as 11, the capacity of the file extension. Java of 86.2 Kbytes and extension txt of 477 bytes and access speed for 7 seconds. So do not close the possibility to make other applications python programming language will be more optimal and efficient. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the implementation of Python and Java source code comparison results are more focused on the scale of the ratio of the number of lines of code, file capacity, and access speed. As for the background of this writing because there are so many programming languages that can be used with the same results but overall we do not know which programming language is more optimal and efficient in terms of the number of lines of code better known in the programming language is LOC (Line of Code) capacity of file access speed. In this study, the authors focus only on Java programming language and python course as a first step to know the ratio of the number of lines of code, file capacity, and access density. To determine the comparison there is a method used is bubble short. The results of the implementation of the comparison of these programming languages for Python programming language to produce the number of LOC (line of code) or the number of lines of code as much as 10, the capacity of the file extension.py by 506 bytes and txt extension of 397 bytes and access speed approximately for less more 4 seconds. While Java produces the number of LOC (line of code) or the number of lines of code as much as 11, the capacity of the file extension. Java of 86.2 Kbytes and extension txt of 477 bytes and access speed for 7 seconds. So do not close the possibility to make other applications python programming language will be more optimal and efficient. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "First evidence of the presence of genotype-1 of Japanese encephalitis virus in Culex gelidus in Indonesia"
        ],
        "penulis":"Garjito, Triwibowo Ambar;Prihatin, Mega Tyas;Susanti, Lulus;Prastowo, Dhian;Sa'Adah, Siti Rofiatus;Taviv, Yulian;Satoto, Tri Baskoro Tunggul;Waluyo, Joko;Manguin, Sylvie;Frutos, Roger;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Background: Japanese encephalitis has become a public health threat in Indonesia. Three genotypes have been recorded in Indonesia, i.e. genotype II (GII), genotype III (GIII) and genotype IV (GIV). Genotype I (GI) and genotype V (GV) have never been reported in Indonesia. Results: A Japanese encephalitis virus (JEV) belonging to the genotype I-a (GI-a) has been isolated for the first time from a Culex gelidus mosquito in the Province of Jambi, Indonesia. This virus is related to a 1983 isolate from Thailand whereas the infected Cx. gelidus mosquito belonged to a Chinese haplotype. Conclusions: Surveillance of JEV and mosquito dissemination is recommended. \u00a9 2019 The Author(s).",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Background: Japanese encephalitis has become a public health threat in Indonesia. Three genotypes have been recorded in Indonesia, i.e. genotype II (GII), genotype III (GIII) and genotype IV (GIV). Genotype I (GI) and genotype V (GV) have never been reported in Indonesia. Results: A Japanese encephalitis virus (JEV) belonging to the genotype I-a (GI-a) has been isolated for the first time from a Culex gelidus mosquito in the Province of Jambi, Indonesia. This virus is related to a 1983 isolate from Thailand whereas the infected Cx. gelidus mosquito belonged to a Chinese haplotype. Conclusions: Surveillance of JEV and mosquito dissemination is recommended. \u00a9 2019 The Author(s)."
        ]
    },
    {
        "judul":[
            "Noise Removal in Mild Cognitive Impairment EEG Recording using Empirical Mode Decomposition"
        ],
        "penulis":"Hadiyoso, Sugondo;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "EEG signals contain large amounts of random noise, such as artifacts and baseline changes. These noises appear at low frequencies, which may disturb the real activity of the EEG signal. Visual observation method often used to mark then removing the noise. However, this conventional method takes much time, requires experts to do the annotation, and has a huge possibility of error. One method that can be used to remove this interference is Empirical Mode Decomposition (EMD). EMD produces two essential parts of the signal, namely intrinsic mode function (IMF) and residue. This study applies EMD to remove artifacts that are present in EEG signals. The performance measured by calculating the RMSE and spectral power. From the test, obtained the average value of RMSE 0.0295 and signal power at frequencies below 1 Hz is 0.004 dB. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "EEG signals contain large amounts of random noise, such as artifacts and baseline changes. These noises appear at low frequencies, which may disturb the real activity of the EEG signal. Visual observation method often used to mark then removing the noise. However, this conventional method takes much time, requires experts to do the annotation, and has a huge possibility of error. One method that can be used to remove this interference is Empirical Mode Decomposition (EMD). EMD produces two essential parts of the signal, namely intrinsic mode function (IMF) and residue. This study applies EMD to remove artifacts that are present in EEG signals. The performance measured by calculating the RMSE and spectral power. From the test, obtained the average value of RMSE 0.0295 and signal power at frequencies below 1 Hz is 0.004 dB. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Dissipation of Solitary Wave Due To Mangrove Forest: A Numerical Study by Using Non-Dispersive Wave Model"
        ],
        "penulis":"Adytia, Didit;Husrin, Semeidi;Latifah, Arnida Lailatul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, we study a dissipation of solitary wave due to mangrove forest by using numerical simulation. Here, the solitary wave is chosen to represent tsunami wave form. To simulate the wave dynamic, we use the non-dispersive Nonlinear Shallow Water Equations (NSWE). The model is implemented numerically by using finite volume method in a momentum conservative staggered grid. By using the proposed numerical scheme, the numerical code is able to simulate solitary wave breaking phenomenon. Wave dissipation due to mangrove forest is modelled as bottom roughness with an approximate value of manning roughness, which is derived from the classical Morisson\u2019s formula. To test the modelled dissipation by mangrove forest, we reconstruct a physical experiment in hydrodynamic laboratory where a solitary wave propagates above a sloping bottom, which has a parameterized mangrove in the shallower part. Two cases are performed to test the performance of the numerical implementation, i.e. the non-breaking and breaking solitary waves. Results of simulation agree quite well with the measurement data. The results of simulation are also analyzed quantitatively by calculating errors as well as correlation with the measurement data. Moreover, to investigate effects of wave steepness on solitary wave, to the reduction of wave energy, we perform numerical investigation. Various solitary waves with different wave steepness are simulated to see their effects on amplitude and energy reduction due to mangrove forest. \u00a9 Ilmu Kelautan, UNDIP.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we study a dissipation of solitary wave due to mangrove forest by using numerical simulation. Here, the solitary wave is chosen to represent tsunami wave form. To simulate the wave dynamic, we use the non-dispersive Nonlinear Shallow Water Equations (NSWE). The model is implemented numerically by using finite volume method in a momentum conservative staggered grid. By using the proposed numerical scheme, the numerical code is able to simulate solitary wave breaking phenomenon. Wave dissipation due to mangrove forest is modelled as bottom roughness with an approximate value of manning roughness, which is derived from the classical Morisson\u2019s formula. To test the modelled dissipation by mangrove forest, we reconstruct a physical experiment in hydrodynamic laboratory where a solitary wave propagates above a sloping bottom, which has a parameterized mangrove in the shallower part. Two cases are performed to test the performance of the numerical implementation, i.e. the non-breaking and breaking solitary waves. Results of simulation agree quite well with the measurement data. The results of simulation are also analyzed quantitatively by calculating errors as well as correlation with the measurement data. Moreover, to investigate effects of wave steepness on solitary wave, to the reduction of wave energy, we perform numerical investigation. Various solitary waves with different wave steepness are simulated to see their effects on amplitude and energy reduction due to mangrove forest. \u00a9 Ilmu Kelautan, UNDIP."
        ]
    },
    {
        "judul":[
            "Seizure Type Classification on EEG Signal using Support Vector Machine"
        ],
        "penulis":"Dwi Saputro, Inggi Ramadhani;Maryati, Nita Dwi;Solihati, Siti Rizqia;Wijayanto, Inung;Hadiyoso, Sugondo;Patmasari, Raditiana;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "One instrument to record the activity of brainwave in a specific time is called Electroencephalography (EEG). EEG signal can be used to analyze the epilepsy disease. Brainwave of seizure patient has a low frequency with a tighter pattern than brainwave of normal people. We use data from Temple University Hospital Seizure Corpus (TUSZ) that represents an accurate clinical condition characterization. Based on neurologist report, several types of seizure can be found in the dataset. In this research, we classify three types of seizure, Generalized Non-Specific Seizure (GNSZ), Focal Non-Specific Seizure (FNSZ) and Tonic-Clonic Seizure (TCSZ). We added a normal EEG signal, so we have four classes to be classified using Support Vector Machine (SVM). The training dataset consists from 120 data (20 GNSZ, 50 FNSZ, 25 TCSZ and 25 Normal), while the evaluation dataset is 90 datasets (20 GNSZ, 50 FNSZ, 5 TCSZ and 15 Normal). We observe the combination of three feature extraction method, Mel Frequency Cepstral Coefficients (MFCC), Hjorth Descriptor and Independent Component Analysis (ICA). The best result obtained by combining MFCC and Hjorth descriptor that can detect seizure type with 90.25%, 97.83%, and 91.4% of average sensitivity, average specificity, and accuracy respectively. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One instrument to record the activity of brainwave in a specific time is called Electroencephalography (EEG). EEG signal can be used to analyze the epilepsy disease. Brainwave of seizure patient has a low frequency with a tighter pattern than brainwave of normal people. We use data from Temple University Hospital Seizure Corpus (TUSZ) that represents an accurate clinical condition characterization. Based on neurologist report, several types of seizure can be found in the dataset. In this research, we classify three types of seizure, Generalized Non-Specific Seizure (GNSZ), Focal Non-Specific Seizure (FNSZ) and Tonic-Clonic Seizure (TCSZ). We added a normal EEG signal, so we have four classes to be classified using Support Vector Machine (SVM). The training dataset consists from 120 data (20 GNSZ, 50 FNSZ, 25 TCSZ and 25 Normal), while the evaluation dataset is 90 datasets (20 GNSZ, 50 FNSZ, 5 TCSZ and 15 Normal). We observe the combination of three feature extraction method, Mel Frequency Cepstral Coefficients (MFCC), Hjorth Descriptor and Independent Component Analysis (ICA). The best result obtained by combining MFCC and Hjorth descriptor that can detect seizure type with 90.25%, 97.83%, and 91.4% of average sensitivity, average specificity, and accuracy respectively. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Mac-Cormack\u2019s Scheme for Shock Filtering Equation in Image Enhancement"
        ],
        "penulis":"Gunawan P.H.;Gumilar, Agung F.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Mac-Cormack\u2019s scheme is elaborated to approximate the solution of shock filtering equation in image enhancement. This scheme is in second order approximation of spatial and time variables. Here, the comparison results of upwind and Mac-Cormack\u2019s scheme are given. The results show that Mac-Cormack\u2019s scheme is able to preserve the edge discontinuity. For evaluating the performance of numerical results, the discrete L2norm error for both numerical schemes is given. From several experiments, along the increasing of image sizes, the error of Mac-Cormack\u2019s scheme is observed getting smaller. For instance, using image sizes (64,64) the error is obtained 0.13762, meanwhile using (512,512) the error is observed 0.06640. \u00a9 2019, Springer Nature Switzerland AG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mac-Cormack\u2019s scheme is elaborated to approximate the solution of shock filtering equation in image enhancement. This scheme is in second order approximation of spatial and time variables. Here, the comparison results of upwind and Mac-Cormack\u2019s scheme are given. The results show that Mac-Cormack\u2019s scheme is able to preserve the edge discontinuity. For evaluating the performance of numerical results, the discrete L2norm error for both numerical schemes is given. From several experiments, along the increasing of image sizes, the error of Mac-Cormack\u2019s scheme is observed getting smaller. For instance, using image sizes (64,64) the error is obtained 0.13762, meanwhile using (512,512) the error is observed 0.06640. \u00a9 2019, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Face spoofing detection using color distortion features and principal component analysis"
        ],
        "penulis":"Simanjuntak, Graham Desmon;Ramadhani, Kurniawan Nur;Arifianto, Anditya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Face anti-spoofing is an important topic of face recognition system to protect against security breach. Previous approach for face spoofing detection based on distortion in images have achieved promising results. However, their generalization ability has not been sufficiently addressed. In this work, we propose a face spoofing detection based on color distortion analysis, which captures the chromatic aberration from a face image. Color distortion analysis extracts color moment and ranked histogram features, which generate 116 feature vector. The feature vector then forwarded to Principal Component Analysis (PCA) to perform dimensionality reduction. For classifying a live or spoof face image, a Na\u00efve Bayes classifier performed on the principal components obtained from PCA. From experiment, the proposed method achieves competitive performance compared to previous approach, with the highest TPR (True Positive Rate) is 97.4%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Face anti-spoofing is an important topic of face recognition system to protect against security breach. Previous approach for face spoofing detection based on distortion in images have achieved promising results. However, their generalization ability has not been sufficiently addressed. In this work, we propose a face spoofing detection based on color distortion analysis, which captures the chromatic aberration from a face image. Color distortion analysis extracts color moment and ranked histogram features, which generate 116 feature vector. The feature vector then forwarded to Principal Component Analysis (PCA) to perform dimensionality reduction. For classifying a live or spoof face image, a Na\u00efve Bayes classifier performed on the principal components obtained from PCA. From experiment, the proposed method achieves competitive performance compared to previous approach, with the highest TPR (True Positive Rate) is 97.4%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design of human behavior automatic lamp switch with blynk platform"
        ],
        "penulis":"Pasau, Adiatma Manglolo;Nasrun, Muhammad;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The use of Internet of Things (IoT) technology provides comfort and convenience for technology users. In this research, an automatic light switch device used the Light Dependent Resistor sensor as an automation for light intensity and AI server assistance for human habits. In this tool there are two rules that govern the automation of the Decision Rule and Priority Rule. From the testing of this tool, the two rules have shown an accuracy of 100%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of Internet of Things (IoT) technology provides comfort and convenience for technology users. In this research, an automatic light switch device used the Light Dependent Resistor sensor as an automation for light intensity and AI server assistance for human habits. In this tool there are two rules that govern the automation of the Decision Rule and Priority Rule. From the testing of this tool, the two rules have shown an accuracy of 100%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The spillover effects of University to Business Growth: Evidence from Malaysia"
        ],
        "penulis":"Muhamad, Suriyani;Kusairi, Suhal;Ab Manah, Siti Khatijah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Higher education institutions (HEI) or universities are known as knowledge and learning centres that produce skilled human capital, educate productive workers and entrepreneurs. Their functions have changed with current demands of society, making significant their role in stimulating and sustaining economic growth. However, there are few studies that investigate the effects of the establishment of universities to cater for and address local economic development. This study aims to examine the spill over effects of universities in nurturing local business activities. With regards to universities, the study explores the (i) stakeholders' spending impact; faculty, staff, student and visitors; (ii) human capital impact and; (iii) knowledge and exploration impact of business growth. Using a Structural Equation Model (SEM), the research applies multistage sampling to survey 445 university stakeholders involving alumni, community and industry from three universities; (i) University of Technology Malaysia (UTM); (ii) Universiti Utara Malaysia (UUM) and; (iii) Universiti Malaysia Terengganu (UMT). The findings show that university expenditure, human capital and knowledge exploration positively influence local business growth. This affirms a positive spill-over effects of universities to regional business growth. Hence, the findings of the research suggest that the positive roles of universities to the local economic development need to be given a priority by related stakeholders. \u00a9 2019, Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Higher education institutions (HEI) or universities are known as knowledge and learning centres that produce skilled human capital, educate productive workers and entrepreneurs. Their functions have changed with current demands of society, making significant their role in stimulating and sustaining economic growth. However, there are few studies that investigate the effects of the establishment of universities to cater for and address local economic development. This study aims to examine the spill over effects of universities in nurturing local business activities. With regards to universities, the study explores the (i) stakeholders' spending impact; faculty, staff, student and visitors; (ii) human capital impact and; (iii) knowledge and exploration impact of business growth. Using a Structural Equation Model (SEM), the research applies multistage sampling to survey 445 university stakeholders involving alumni, community and industry from three universities; (i) University of Technology Malaysia (UTM); (ii) Universiti Utara Malaysia (UUM) and; (iii) Universiti Malaysia Terengganu (UMT). The findings show that university expenditure, human capital and knowledge exploration positively influence local business growth. This affirms a positive spill-over effects of universities to regional business growth. Hence, the findings of the research suggest that the positive roles of universities to the local economic development need to be given a priority by related stakeholders. \u00a9 2019, Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Inhibiting motivating factors on online gig economy client in Indonesia"
        ],
        "penulis":"Asih, Sinta Nur;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Online Gig Economy (OGE) as a result of digitalization results in a group of freelancers called gig workers. The rapid growth of the OGE platform and the high number of internet users in Indonesia has the potential to open up online job market opportunities and can lead to an excess supply of online gig workers. The growth of OGE in Indonesia needs to be balanced with the existence of research to find solutions to factors that influence people's interest in using online gig worker services. Data collection is done by distributing online questionnaires. Based on the results of the study, the factors that are motivating the interest of the public to use the gig worker online services are the Perceived Usefulness, and Social Influence while the inhibiting factor is the Perceived of Risk. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Online Gig Economy (OGE) as a result of digitalization results in a group of freelancers called gig workers. The rapid growth of the OGE platform and the high number of internet users in Indonesia has the potential to open up online job market opportunities and can lead to an excess supply of online gig workers. The growth of OGE in Indonesia needs to be balanced with the existence of research to find solutions to factors that influence people's interest in using online gig worker services. Data collection is done by distributing online questionnaires. Based on the results of the study, the factors that are motivating the interest of the public to use the gig worker online services are the Perceived Usefulness, and Social Influence while the inhibiting factor is the Perceived of Risk. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design Autonomous Drone Control for Monitoring Tea Plantation Using Dynamic Programming and Kruskal Algorithm"
        ],
        "penulis":"Wirabudi, Andri Agustav;Munadi, Rendy;Rusdinar, Angga;Rohdiana, Dadan;Lee, Dong Ho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia is a country with the largest tea producers in the world, with a very large area needed tools to be able to help monitor the area of tea plantations as a whole. Unmanned Aerial Vehicle (UAV) wash chosen as a solution for the monitoring proses. Optimum flight path calculation is needed in order to produce good quality images, and also it influence to power consumption. The algorithm proposed in this study is Dynamic Programming and Kruskal Algorithm. Implementing these two network algorithms is expected to find the optimal path in aerial photography. The experimental results showed that the algorithm produced the optimum path, and more efficient power consumption than conventional lines. Image data obtained during tea plantation monitoring produced high-quality images, with the accuracy of each map above 90% and the assumption of errors below 5%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is a country with the largest tea producers in the world, with a very large area needed tools to be able to help monitor the area of tea plantations as a whole. Unmanned Aerial Vehicle (UAV) wash chosen as a solution for the monitoring proses. Optimum flight path calculation is needed in order to produce good quality images, and also it influence to power consumption. The algorithm proposed in this study is Dynamic Programming and Kruskal Algorithm. Implementing these two network algorithms is expected to find the optimal path in aerial photography. The experimental results showed that the algorithm produced the optimum path, and more efficient power consumption than conventional lines. Image data obtained during tea plantation monitoring produced high-quality images, with the accuracy of each map above 90% and the assumption of errors below 5%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Decision Tree C4.5 for Big Five Personality Predictions with TF-RF and TF-CHI2 on Social Media Twitter"
        ],
        "penulis":"Willy;Setiawan, Erwin B.;Nugraha, Fida N.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Every tweet can provide an information about someone's personality. The problem is how to classify an obtained information on Twitter social media into classes that will be created with good performance value. Personality classification through Twitter social media has been studied by several researchers. For instance, in Damanik Agnes and Khodra Masayu [3], Classification method using Support Vector Regression (SVR) and TF-IDF weighting method. The result shown good with Mean Absolute Error (MAE) 0.2739. In this paper, writer builds a system that classifies someone personality on Twitter social media using decision tree C4.5 classification method with TF-RF and TF-CHI2weighting method. The diffences on this paper is the weighting of each word using the weighting method TF-RF and TF-CHI2with the addition of new features for approaches based on user social behavior which will be explained in more detail in section II. From the results of the experiment on the 90% training data ratio and 10% test data (90:10) and the combination of personality features based on social behavior with a linguistic approach with TF-RF weighting obtained the accuracy results of 65.72%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Every tweet can provide an information about someone's personality. The problem is how to classify an obtained information on Twitter social media into classes that will be created with good performance value. Personality classification through Twitter social media has been studied by several researchers. For instance, in Damanik Agnes and Khodra Masayu [3], Classification method using Support Vector Regression (SVR) and TF-IDF weighting method. The result shown good with Mean Absolute Error (MAE) 0.2739. In this paper, writer builds a system that classifies someone personality on Twitter social media using decision tree C4.5 classification method with TF-RF and TF-CHI2weighting method. The diffences on this paper is the weighting of each word using the weighting method TF-RF and TF-CHI2with the addition of new features for approaches based on user social behavior which will be explained in more detail in section II. From the results of the experiment on the 90% training data ratio and 10% test data (90:10) and the combination of personality features based on social behavior with a linguistic approach with TF-RF weighting obtained the accuracy results of 65.72%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "An efficient technique for cluster number prediction in graph clustering using nullity of laplacian matrix"
        ],
        "penulis":"Atastina, Imelda;Sitohang, Benhard;Saptawati, G.A.Putri;Moertini, Veronica S;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Clustering graph dataset representing users\u2019 interactions can be used to detect groups or communities. Many existing graph clustering algorithms require an initial cluster number. The closer the initial cluster numbers to the real or final ones, the faster the algorithm will converge. Hence, finding the right initial cluster number is important for increasing the efficiency of the algorithms. This research proposes a novel technique for computing the initial cluster number using the nullity of the Laplacian Matrix of Adjacency Matrix. The fact that nullity relates to the properties of the eigenvalues in the Laplacian matrix of a connected component is used to predict the best cluster numbers. By using this technique, trial and error experiments for finding the right clusters is no longer needed. The experiment results using artificial and real dataset and modularity values (for measuring the clusters quality) showed that our proposed technique is efficient in finding initial cluster numbers, which is also the real best cluster numbers. \u00a9 2005 \u2013 ongoing JATIT & LLS.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Clustering graph dataset representing users\u2019 interactions can be used to detect groups or communities. Many existing graph clustering algorithms require an initial cluster number. The closer the initial cluster numbers to the real or final ones, the faster the algorithm will converge. Hence, finding the right initial cluster number is important for increasing the efficiency of the algorithms. This research proposes a novel technique for computing the initial cluster number using the nullity of the Laplacian Matrix of Adjacency Matrix. The fact that nullity relates to the properties of the eigenvalues in the Laplacian matrix of a connected component is used to predict the best cluster numbers. By using this technique, trial and error experiments for finding the right clusters is no longer needed. The experiment results using artificial and real dataset and modularity values (for measuring the clusters quality) showed that our proposed technique is efficient in finding initial cluster numbers, which is also the real best cluster numbers. \u00a9 2005 \u2013 ongoing JATIT & LLS."
        ]
    },
    {
        "judul":[
            "Throughput improvement of an autocorrelation block for time synchronization in OFDM-based LiFi"
        ],
        "penulis":"Setiawan, Erwin;Adiono, Trio;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, the throughput improvement of an autocorrelation block is presented. The improvement is carried out by employing pipeline architecture. The autocorrelation block is used for time synchronization in OFDM-based Visible Light Communication (VLC) system. The autocorrelation block estimates the coarse time offset of the received OFDM data symbol. By adding pipeline registers, we can reduce the critical path of the combinational circuits by dividing it into smaller critical path, therefore the clock frequency can be increased. We show three times throughput improvement by using four stages pipeline architecture. The maximum clock frequency of the block is 188 MHz. The block has been implemented and verified on Xilinx Zynq-7000 FPGA. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, the throughput improvement of an autocorrelation block is presented. The improvement is carried out by employing pipeline architecture. The autocorrelation block is used for time synchronization in OFDM-based Visible Light Communication (VLC) system. The autocorrelation block estimates the coarse time offset of the received OFDM data symbol. By adding pipeline registers, we can reduce the critical path of the combinational circuits by dividing it into smaller critical path, therefore the clock frequency can be increased. We show three times throughput improvement by using four stages pipeline architecture. The maximum clock frequency of the block is 188 MHz. The block has been implemented and verified on Xilinx Zynq-7000 FPGA. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Real-time communication measurement on web services in the fingerprint machine"
        ],
        "penulis":"Darmawan, Irfan;Rahmatulloh, Alam;Mubarok, Husni;Gunawan, Rohmat;Syahriszani, Rezi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The problem of fingerprint-based attendance management has been overcome in previous studies. Web Service Implementation (WS) has successfully handled fingerprint machine communication with a web-based monitoring system with a different platform. However, it is not yet known the size of the data transfer rate between the fingerprint machine and the monitoring system. The primary purpose of this research is to test and measure data transfer speed and memory usage. Experiments in this study were carried out by connecting five fingerprint machines with a web-based monitoring system. Node.js is installed on the server-side that is connected to the web service and database. The experiment is repeated; the data transfer speed and memory usage are recorded in the table and averages are calculated. The experimental results in the study showed that after 50 trials it was known that the average time of data transfer was 14.53 ms and the average memory usage was 17.42 Mb. So that communication between fingerprint machines and web-based monitoring systems can be categorized as real-time communication. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The problem of fingerprint-based attendance management has been overcome in previous studies. Web Service Implementation (WS) has successfully handled fingerprint machine communication with a web-based monitoring system with a different platform. However, it is not yet known the size of the data transfer rate between the fingerprint machine and the monitoring system. The primary purpose of this research is to test and measure data transfer speed and memory usage. Experiments in this study were carried out by connecting five fingerprint machines with a web-based monitoring system. Node.js is installed on the server-side that is connected to the web service and database. The experiment is repeated; the data transfer speed and memory usage are recorded in the table and averages are calculated. The experimental results in the study showed that after 50 trials it was known that the average time of data transfer was 14.53 ms and the average memory usage was 17.42 Mb. So that communication between fingerprint machines and web-based monitoring systems can be categorized as real-time communication. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design and implementation program identification of traffic form in self driving car robot"
        ],
        "penulis":"Yudokusumo, Lukman;Dwi Wibawa, I.G. Prasetya;Ekaputri, Cahyantari;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of technology is growing more rapidly, one of them is a car robot without a driver who can help navigate the car to drive. The navigation is designed to determine the direction of the steering wheel to walk along the track properly. An image processing algorithm is designed to help navigate miniature cars. The design of this algorithm uses the Python programming language and has the OpenCV library. An image as an input while for the output is to have a miderror value to find out the position of the car in the middle of the track or not. The results in the miderror that are read in the python and the ruler on the straight track has an average of 5.485647966%, and identification of the track shape can distinguish between the straight track, turn right, and turn left. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of technology is growing more rapidly, one of them is a car robot without a driver who can help navigate the car to drive. The navigation is designed to determine the direction of the steering wheel to walk along the track properly. An image processing algorithm is designed to help navigate miniature cars. The design of this algorithm uses the Python programming language and has the OpenCV library. An image as an input while for the output is to have a miderror value to find out the position of the car in the middle of the track or not. The results in the miderror that are read in the python and the ruler on the straight track has an average of 5.485647966%, and identification of the track shape can distinguish between the straight track, turn right, and turn left. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Multicast routing protocol for advanced vehicular ad hoc networks"
        ],
        "penulis":"Al Mushayt, Omar Saeed;Gharibi, Wajeb;Armi, Nasrullah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Transport sector has great impact on our daily life. Despite the huge number of vehicular models, driving process still faces many challenges due to the lack information about the roads and the surrounding sudden events, which can result in high number of accidents globally and especially in Saudi Arabia. A new technology, vehicular ad hoc networks (VANETs), has emerged to support Intelligent Transport System (ITS) and to offer advanced solutions for drivers to avoid different hazard events that occur on the road. In this paper, we discuss the multicast and broadcast communications in VANETs, Quality of Sevice (QoS) awaregroup addressing\/managing solutions to VANETs which help inclassifying different application that explore and design a new cross-layer framework, aware of high mobility and efficiency. \u00a9 2019 Universitas Ahmad Dahlan.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Transport sector has great impact on our daily life. Despite the huge number of vehicular models, driving process still faces many challenges due to the lack information about the roads and the surrounding sudden events, which can result in high number of accidents globally and especially in Saudi Arabia. A new technology, vehicular ad hoc networks (VANETs), has emerged to support Intelligent Transport System (ITS) and to offer advanced solutions for drivers to avoid different hazard events that occur on the road. In this paper, we discuss the multicast and broadcast communications in VANETs, Quality of Sevice (QoS) awaregroup addressing\/managing solutions to VANETs which help inclassifying different application that explore and design a new cross-layer framework, aware of high mobility and efficiency. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Boosting the firm transformation in industry 5.0: Experience-agility innovation model"
        ],
        "penulis":"Mihardjo, Leonardus W Wasono;Sasmoko;Alamsyah, Firdaus;Elidjen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Industry 5.0 brings collaborative and automatic environment, thus creating a new paradigm for companies in doing business. The way organizations manage resources and capability, especially in relationship with people, culture and process in creating new business models have changed. Previous studies on developing innovation based on customer experience and agility of organization focus on the concept, relationship among variables and the implication. However, in the context of industry 5.0, the study on those topics has not been revealing. Hence, this study aims to assess the concept of experience-agility innovation model to support transformation in the context of digital transformation to face Industry 5.0. The proposed model was assessed with 195 Indonesia ICT firms using SEM-PLS statistical tools. The findings demonstrate that the firm that offers compelling value proposition from customer experience while concurrently developing agility in the organization to create business model innovation could boost the transformational performance. For further researches, the study can be enhanced through expanding the model, sample, and time. \u00a9 BEIESP.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry 5.0 brings collaborative and automatic environment, thus creating a new paradigm for companies in doing business. The way organizations manage resources and capability, especially in relationship with people, culture and process in creating new business models have changed. Previous studies on developing innovation based on customer experience and agility of organization focus on the concept, relationship among variables and the implication. However, in the context of industry 5.0, the study on those topics has not been revealing. Hence, this study aims to assess the concept of experience-agility innovation model to support transformation in the context of digital transformation to face Industry 5.0. The proposed model was assessed with 195 Indonesia ICT firms using SEM-PLS statistical tools. The findings demonstrate that the firm that offers compelling value proposition from customer experience while concurrently developing agility in the organization to create business model innovation could boost the transformational performance. For further researches, the study can be enhanced through expanding the model, sample, and time. \u00a9 BEIESP."
        ]
    },
    {
        "judul":[
            "Implementation of GPRS Service on Mobile Network Based OSMOCOM"
        ],
        "penulis":"Falih, Muhammad Dzakwan;Hafidudin;Ramadan, Dadan Nur;Hadiyoso, Sugondo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia has a large land area with varying earth contours, in some areas it is not covered by the General Packet Radio Service (GPRS) network because of the limited installation. Therefore, a mini repeater design is needed to reach these areas. This research was implemented a GPRS service using Open Source Mobile Communication (OSMOCOM) for areas where the signal was not covered. In this study, a method was developed to build a GPRS service infrastructure network, so that areas that are not covered by signals can still utilize internet services through cellular networks and GPRS services. This system employed Osmo Base Transceiver Station (OsmoBTS), Osmo Network in the Box (OsmoNITB), Osmo Packet Control Unit (OsmoPCU), Osmo Serving GPRS Support Node (OsmoSGSN) and Osmo Gateway GPRS Support Node (OsmoGGSN) as virtual system. From the performance testing on the system that was implemented, the GPRS service was successfully run via a smartphone. Users can access cellular and GPRS networks through networks which are transmitted by Universal Software Radio Peripheral (USRP) devices. The smartphone was connected to the internet through the Access Point Name (APN). The implemented system was able to provide quality warranty services such as throughput of 1070.1 bytes, delay of 1.1 seconds and packet loss of 4.3%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia has a large land area with varying earth contours, in some areas it is not covered by the General Packet Radio Service (GPRS) network because of the limited installation. Therefore, a mini repeater design is needed to reach these areas. This research was implemented a GPRS service using Open Source Mobile Communication (OSMOCOM) for areas where the signal was not covered. In this study, a method was developed to build a GPRS service infrastructure network, so that areas that are not covered by signals can still utilize internet services through cellular networks and GPRS services. This system employed Osmo Base Transceiver Station (OsmoBTS), Osmo Network in the Box (OsmoNITB), Osmo Packet Control Unit (OsmoPCU), Osmo Serving GPRS Support Node (OsmoSGSN) and Osmo Gateway GPRS Support Node (OsmoGGSN) as virtual system. From the performance testing on the system that was implemented, the GPRS service was successfully run via a smartphone. Users can access cellular and GPRS networks through networks which are transmitted by Universal Software Radio Peripheral (USRP) devices. The smartphone was connected to the internet through the Access Point Name (APN). The implemented system was able to provide quality warranty services such as throughput of 1070.1 bytes, delay of 1.1 seconds and packet loss of 4.3%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Item Delivery Simulation Using Dijkstra Algorithm for Solving Traveling Salesman Problem"
        ],
        "penulis":"Ginting, Hagai Nuansa;Osmond, Andrew Brian;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Companies that contribute to travel have many problems in the process of item delivery. Distances and priorities are considered for a process of item delivery based on the highest priority. A delivery target that can be done one day evidently exceed the expected limit and that is the impact. This is an example of the waste time and operational costs that should be at the same time that two or more addresses can be sent. Traveling Salesman Problem (TSP) was define a classical problem to finding the shortest route that salesman can be passed when visiting several places without visit again in the same place more than once. In this study, TSP requires all calculations of possible routes to be obtained. Then choose one of the shortest routes by prioritizing the things considered, namely distance and priority. Delivery is done quickly through the shortest route according to priority using the Dijkstra algorithm. Simulation shows that the Dijkstra algorithm must be approved by use clustering data for Dijkstra's priorities and sub-routes to solve TSP problems. Simulation shows that the Dijkstra algorithm must be modified using Dijkstra's priority clustering and sub-routing to solve TSP problems. The resulting route has an influence between two graphs. Complete graph has a distance efficiency of 47.8% and execution time of 48.1% compared to non-complete graphs. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Companies that contribute to travel have many problems in the process of item delivery. Distances and priorities are considered for a process of item delivery based on the highest priority. A delivery target that can be done one day evidently exceed the expected limit and that is the impact. This is an example of the waste time and operational costs that should be at the same time that two or more addresses can be sent. Traveling Salesman Problem (TSP) was define a classical problem to finding the shortest route that salesman can be passed when visiting several places without visit again in the same place more than once. In this study, TSP requires all calculations of possible routes to be obtained. Then choose one of the shortest routes by prioritizing the things considered, namely distance and priority. Delivery is done quickly through the shortest route according to priority using the Dijkstra algorithm. Simulation shows that the Dijkstra algorithm must be approved by use clustering data for Dijkstra's priorities and sub-routes to solve TSP problems. Simulation shows that the Dijkstra algorithm must be modified using Dijkstra's priority clustering and sub-routing to solve TSP problems. The resulting route has an influence between two graphs. Complete graph has a distance efficiency of 47.8% and execution time of 48.1% compared to non-complete graphs. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "What are the Indonesian Concerns about the Internet of Things (IoT)? Portraying the Profile of the Prospective Market"
        ],
        "penulis":"Suryanegara, Muhammad;Arifin, Ajib Setyo;Asvial, Muhamad;Ramli, Kalamullah;Nashiruddin, Muhammad Imam;Hayati, Nur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper aims to characterize the profile of the prospective IoT market in Indonesia. The primary data were collected in July 2018 through a comprehensive survey that sampled respondents representing the whole Indonesian population. The questionnaire was developed by extracting the 4 (four) main issues regarding which the potential users of the IoT technology may have concerns, i.e., willingness to use the IoT services, concerns related to rejection and worries about the IoT, the characteristics of the IoT hardware, and perceptions about the role of the IoT within the existing system. The results of the survey were analyzed to capture the profile of the prospective IoT market, and the strategic implications of the findings were considered. Several interesting results were found, ranging from answering the common question of what kinds of the IoT services are most anticipated to answering the delicate question of how the Indonesian people perceive the disruptive force that the IoT technology may exert. The contribution of this research is that it can be used as an initial guide or reference for regulators, the government and the IoT firms that will begin to deploy services in Indonesia. \u00a9 2013 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper aims to characterize the profile of the prospective IoT market in Indonesia. The primary data were collected in July 2018 through a comprehensive survey that sampled respondents representing the whole Indonesian population. The questionnaire was developed by extracting the 4 (four) main issues regarding which the potential users of the IoT technology may have concerns, i.e., willingness to use the IoT services, concerns related to rejection and worries about the IoT, the characteristics of the IoT hardware, and perceptions about the role of the IoT within the existing system. The results of the survey were analyzed to capture the profile of the prospective IoT market, and the strategic implications of the findings were considered. Several interesting results were found, ranging from answering the common question of what kinds of the IoT services are most anticipated to answering the delicate question of how the Indonesian people perceive the disruptive force that the IoT technology may exert. The contribution of this research is that it can be used as an initial guide or reference for regulators, the government and the IoT firms that will begin to deploy services in Indonesia. \u00a9 2013 IEEE."
        ]
    },
    {
        "judul":[
            "Imbalance class problems in data mining: A review"
        ],
        "penulis":"Ali, Haseeb;Salleh, Mohd Najib Mohd;Saedudin, Rohmat;Hussain, Kashif;Mushtaq, Muhammad Faheem;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The imbalanced data problems in data mining are common nowadays, which occur due to skewed nature of data. These problems impact the classification process negatively in machine learning process. In such problems, classes have different ratios of specimens in which a large number of specimens belong to one class and the other class has fewer specimens that is usually an essential class, but unfortunately misclassified by many classifiers. So far, significant research is performed to address the imbalanced data problems by implementing different techniques and approaches. In this research, a comprehensive survey is performed to identify the challenges of handling imbalanced class problems during classification process using machine learning algorithms. We discuss the issues of classifiers which endorse bias for majority class and ignore the minority class. Furthermore, the viable solutions and potential future directions are provided to handle the problems. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The imbalanced data problems in data mining are common nowadays, which occur due to skewed nature of data. These problems impact the classification process negatively in machine learning process. In such problems, classes have different ratios of specimens in which a large number of specimens belong to one class and the other class has fewer specimens that is usually an essential class, but unfortunately misclassified by many classifiers. So far, significant research is performed to address the imbalanced data problems by implementing different techniques and approaches. In this research, a comprehensive survey is performed to identify the challenges of handling imbalanced class problems during classification process using machine learning algorithms. We discuss the issues of classifiers which endorse bias for majority class and ignore the minority class. Furthermore, the viable solutions and potential future directions are provided to handle the problems. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Labeling Analysis in the Classification of Product Review Sentiments by using Multinomial Naive Bayes Algorithm"
        ],
        "penulis":"Tama V.O.;Sibaroni Y.;Adiwijaya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Along with the development of technology, e-commerce also experienced a fairly rapid development. The existence of e-commerce becomes another consumer alternative to make it easier for them to fulfill their needs. After buying the goods, consumers are free to assess the products they buy. Product reviews and ratings provided by consumers are one means that can be used to increase sales and can also be used to determine the decision in purchasing a product by reading the product reviews. However, using ratings and reviews alone is not enough to summarize one's opinion. Therefore, in this Final Project built a system that can classify opinions on product reviews into positive and negative sentiments by utilizing the rating. The dataset used is Grocery and Gourmet Food from Amazon as much as 50,000 which will then be labeled using Labeling Methods Average and Binary. The classification of this opinion uses the approach of Supervised learning Algorithm Multinomial Na\u00efve Bayes. The result of this research shows that labeling using Method Average is suitable for processing Grocery and Gourmet Food Dataset and proves that the best ratio of feature selection usage is 20% succeed to produce 80.48% accuracy. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Along with the development of technology, e-commerce also experienced a fairly rapid development. The existence of e-commerce becomes another consumer alternative to make it easier for them to fulfill their needs. After buying the goods, consumers are free to assess the products they buy. Product reviews and ratings provided by consumers are one means that can be used to increase sales and can also be used to determine the decision in purchasing a product by reading the product reviews. However, using ratings and reviews alone is not enough to summarize one's opinion. Therefore, in this Final Project built a system that can classify opinions on product reviews into positive and negative sentiments by utilizing the rating. The dataset used is Grocery and Gourmet Food from Amazon as much as 50,000 which will then be labeled using Labeling Methods Average and Binary. The classification of this opinion uses the approach of Supervised learning Algorithm Multinomial Na\u00efve Bayes. The result of this research shows that labeling using Method Average is suitable for processing Grocery and Gourmet Food Dataset and proves that the best ratio of feature selection usage is 20% succeed to produce 80.48% accuracy. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "System dynamics simulation to determine financial strategy for social health insurance in Indonesia"
        ],
        "penulis":"Kurnianingtyas, Diva;Santosa, Budi;Siswanto, Nurhadi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Social Health Insurance (SHI) in Indonesia is still experiencing financial constraints because the financial condition of the SHI has continued to be a loss since it was established in 2014 until present so it becomes special attention needed to get achieving the Universal Health Coverage (UHC) target by the government. Therefore, this study intends to provide an appropriate SHI financial strategy recommendation by considering the stability of the balance of income and expense. In addition, a system dynamics simulation approach is needed to find optimal SHI financial strategies with variables including participant premium rates, average cost of benefits, number of health cases, and number of insurance participants. The data used came from BPJS Health data for 2016 and 2017. Afterwards, the equation used was Income \u2265 Expenditures. In addition, there are several scenarios designed to reduce the level of financial losses that occur at SHI. The scenario of reducing the number of health cases is the best strategy recommendation decision. The results show that reducing average benefit costs and increasing premium rates also gets it can reduce financial problems. From the results that have been obtained, this study can contribute to the resolution of SHI Health financial problems in Indonesia. \u00a9 2019 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Reduced inequalitiesGoal 10Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Social Health Insurance (SHI) in Indonesia is still experiencing financial constraints because the financial condition of the SHI has continued to be a loss since it was established in 2014 until present so it becomes special attention needed to get achieving the Universal Health Coverage (UHC) target by the government. Therefore, this study intends to provide an appropriate SHI financial strategy recommendation by considering the stability of the balance of income and expense. In addition, a system dynamics simulation approach is needed to find optimal SHI financial strategies with variables including participant premium rates, average cost of benefits, number of health cases, and number of insurance participants. The data used came from BPJS Health data for 2016 and 2017. Afterwards, the equation used was Income \u2265 Expenditures. In addition, there are several scenarios designed to reduce the level of financial losses that occur at SHI. The scenario of reducing the number of health cases is the best strategy recommendation decision. The results show that reducing average benefit costs and increasing premium rates also gets it can reduce financial problems. From the results that have been obtained, this study can contribute to the resolution of SHI Health financial problems in Indonesia. \u00a9 2019 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "An Investigation of Aircraft Tracking through Space-based ADS-B Receiver"
        ],
        "penulis":"Caya T.V.;Hafizh M.;Benyamin S.O.;Edwar;Putra Y.D.;Widiawan A.K.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Nowadays space-based Automatic Dependent Surveillance-Broadcast (ADS-B) is widely developed with various methods to improve the quality of ADS-B. The method that can be used to design a space-based ADS-B receiver is creating a system-level simulator. The system-level simulator can be used to investigate performance of the system with scenarios that have been made. This paper presents a modeling of the ADS-B signal receiver system from an aircraft with a Low Earth Orbit (LEO) Satellite. In this model, the position of the aircraft is randomly scattered within the range of the satellite's coverage at an altitude of 5 km-15 km above the ground level. The satellite's antenna used in this simulation has a 90-degree beamwidth with 5 dBi of maximum gain on the main lobe. The lowest BER value obtained from the aircraft is 1x10-8, located at the satellite nadir and the highest value obtained from the aircraft is 1x10-6, located at the farthest distance from the satellite. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays space-based Automatic Dependent Surveillance-Broadcast (ADS-B) is widely developed with various methods to improve the quality of ADS-B. The method that can be used to design a space-based ADS-B receiver is creating a system-level simulator. The system-level simulator can be used to investigate performance of the system with scenarios that have been made. This paper presents a modeling of the ADS-B signal receiver system from an aircraft with a Low Earth Orbit (LEO) Satellite. In this model, the position of the aircraft is randomly scattered within the range of the satellite's coverage at an altitude of 5 km-15 km above the ground level. The satellite's antenna used in this simulation has a 90-degree beamwidth with 5 dBi of maximum gain on the main lobe. The lowest BER value obtained from the aircraft is 1x10-8, located at the satellite nadir and the highest value obtained from the aircraft is 1x10-6, located at the farthest distance from the satellite. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of the maintainability and portability of ERP host to host system using ISO 9126 model"
        ],
        "penulis":"Syamranata, Tommy;Witjaksono, R Wahjoe;Suputra, Muhardi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Telecommunication industry in Indonesia that have a complex system and interconnected for the payment transaction to each vendor. the quality of the system is very influential on each division in the company and the goals are to analyzed host to host quality system. The implementation process of the new system in terms of internal portability and also in terms of the quality system if changes are made, according to the requirements of certain conditions in this case including in terms of internal maintainability, in this case, to be in line with the company that is helping companies in managing business processes according to with company goals and able to carry out operational activities more efficient and more effective. In the process, the analysis of system quality this time was carried out in the system. To analyze the quality system, it was carried out with the ISO 9126 standard as a model and to analyze the internal variables are using Maintainability and Portability. In the analysis, the process is using SPSS 25 and SMARTPLS 3 as processing tools. The results of this analysis process are in the form of recommendations in terms of stability contained in internal maintainability and portability testing, which is taken from the results of the hypothesis and also measurement testing for each related variable. The recommendations proposed are the Improvement System, from the existing SAP ECC 6.0 to SAP S \/ 4 HANA which has advantages in system stability. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Telecommunication industry in Indonesia that have a complex system and interconnected for the payment transaction to each vendor. the quality of the system is very influential on each division in the company and the goals are to analyzed host to host quality system. The implementation process of the new system in terms of internal portability and also in terms of the quality system if changes are made, according to the requirements of certain conditions in this case including in terms of internal maintainability, in this case, to be in line with the company that is helping companies in managing business processes according to with company goals and able to carry out operational activities more efficient and more effective. In the process, the analysis of system quality this time was carried out in the system. To analyze the quality system, it was carried out with the ISO 9126 standard as a model and to analyze the internal variables are using Maintainability and Portability. In the analysis, the process is using SPSS 25 and SMARTPLS 3 as processing tools. The results of this analysis process are in the form of recommendations in terms of stability contained in internal maintainability and portability testing, which is taken from the results of the hypothesis and also measurement testing for each related variable. The recommendations proposed are the Improvement System, from the existing SAP ECC 6.0 to SAP S \/ 4 HANA which has advantages in system stability. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Low-cost communication system for explorer-class underwater remotely operated vehicle"
        ],
        "penulis":"Siregar, Simon;Sani, Muhammad Ikhsan;Kurnia, Muhammad Muchlis;Hasbialloh, Dzikri;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Disaster recovery from underwater earthquake, plane crashes into the sea, and monitoring underwater cables or piping for energy purpose are underwater missions for Remotely Operated Underwater Vehicle (ROV) in ASEAN MATE 2018 Competition. Two essentials factor to perform successfully in this ROV competition are design of an efficient communication protocol system and a low-cost communication hardware. In this research, an optimal communication system between RS-232 serial communication transmission and RS-485 serial communication transmission is developed to obtain the optimal solution. Both communication system is tested in Tech_SAS ROV-Telkom University Indonesia, a microcontroller underwater ROV based which used single microcontroller to control actuator, sensor and communication, and measured the Quality of Services (QoS) for end-to-end delay and packets loss. From the the experiment and evaluation for the two schemes, shows 12.57 ms end-to-end delay, 0% data packet error and $6 RS-485 communication system are the optimal solution for Tech_SAS ROV. \u00a9 2019 Universitas Ahmad Dahlan.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Disaster recovery from underwater earthquake, plane crashes into the sea, and monitoring underwater cables or piping for energy purpose are underwater missions for Remotely Operated Underwater Vehicle (ROV) in ASEAN MATE 2018 Competition. Two essentials factor to perform successfully in this ROV competition are design of an efficient communication protocol system and a low-cost communication hardware. In this research, an optimal communication system between RS-232 serial communication transmission and RS-485 serial communication transmission is developed to obtain the optimal solution. Both communication system is tested in Tech_SAS ROV-Telkom University Indonesia, a microcontroller underwater ROV based which used single microcontroller to control actuator, sensor and communication, and measured the Quality of Services (QoS) for end-to-end delay and packets loss. From the the experiment and evaluation for the two schemes, shows 12.57 ms end-to-end delay, 0% data packet error and $6 RS-485 communication system are the optimal solution for Tech_SAS ROV. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Adopting Tiny Encryption Algorithm for Patient Healthcare Record on Smart Card"
        ],
        "penulis":"Adiwiganda, Muhammad Rizki;Ariyanto, Endro;Yasirandi, Rahmat;Suwastika, Novian Anggis;Setyoko, Yoso Adi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Smart Card is something that is used for data transactions quickly and practically. The definition of 'smart' is when a card has a chip implanted. The card is very helpful in the authentication and administration process even during emergencies, such as a patient healthcare record at the hospital. In this case study, patient data should only be accessed and known by people who have rights. So it is necessary for the security of data storage such as cryptography algorithms. The algorithm needed for patient cards is an algorithm that has fast processing capability and a high level of security. So the aim of this study is to implement the Tiny Encryption Algorithm on Smart Cards. Based on the results of testing in this study the time of encrypting patient data with a total of 600 lines of patient history measuring 30.6 Kb produces an average encryption time of 20.17 ms. While the decryption for the same data takes 17.21 ms which shows very little processing time and the tolerance for waiting time for accessing data. Furthermore, the Avalanche Effect test carried out in the TEA encryption process results 77%, where these results indicate that encrypted data has very random cipher-text results so that the data contents are kept confidential with a high level of security. The results of testing the processing time and AE can be concluded that TEA is an algorithm that has a fast data security process with high security and time that can be tolerated by users. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Smart Card is something that is used for data transactions quickly and practically. The definition of 'smart' is when a card has a chip implanted. The card is very helpful in the authentication and administration process even during emergencies, such as a patient healthcare record at the hospital. In this case study, patient data should only be accessed and known by people who have rights. So it is necessary for the security of data storage such as cryptography algorithms. The algorithm needed for patient cards is an algorithm that has fast processing capability and a high level of security. So the aim of this study is to implement the Tiny Encryption Algorithm on Smart Cards. Based on the results of testing in this study the time of encrypting patient data with a total of 600 lines of patient history measuring 30.6 Kb produces an average encryption time of 20.17 ms. While the decryption for the same data takes 17.21 ms which shows very little processing time and the tolerance for waiting time for accessing data. Furthermore, the Avalanche Effect test carried out in the TEA encryption process results 77%, where these results indicate that encrypted data has very random cipher-text results so that the data contents are kept confidential with a high level of security. The results of testing the processing time and AE can be concluded that TEA is an algorithm that has a fast data security process with high security and time that can be tolerated by users. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "A perspective of home security using wireless communication"
        ],
        "penulis":"Purboyo, Tito Waluyo;Osmond, Andrew Brian;Aryani, Ressy;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Home security is security system to applied at home or at one building. A function of home security is to provide comfort, some level of protection for the inhabitants of the house and can also be implemented into the system for crime prevention. The research will be conducted using wireless communication as the communication module used in security systems. The diversity of application, technology, methods, sensors that used and many more ways can increase the level of security at home. This study aims to review and compare some paper of home security likes methods, used tools, advantages and disadvantages of a security system. At the end, the final duty is to know which system is suitable for home by using the parameters to be compared. \u00a9 2019, Medwell Journals.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Home security is security system to applied at home or at one building. A function of home security is to provide comfort, some level of protection for the inhabitants of the house and can also be implemented into the system for crime prevention. The research will be conducted using wireless communication as the communication module used in security systems. The diversity of application, technology, methods, sensors that used and many more ways can increase the level of security at home. This study aims to review and compare some paper of home security likes methods, used tools, advantages and disadvantages of a security system. At the end, the final duty is to know which system is suitable for home by using the parameters to be compared. \u00a9 2019, Medwell Journals."
        ]
    },
    {
        "judul":[
            "Text classification of british english and American english using support vector machine"
        ],
        "penulis":"Utomo, Muhammad Romi Ario;Sibaroni, Yuliant;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "English is a language commonly used in the international world. Meanwhile, English that is often used in society is British English and American English. Beyond of the similarities, they all have fundamental differences, starting from the vocabulary to the grammar used. In learning English, people must ensure the type of English that they will learn. Therefore, this study is created a text classification system that can classify sentences according to the type of English used in the text. By that, it is expected to facilitate the language learning process in English. The dataset is divided into two classes namely British English and American English. The data will be divided by 10-fold-cross-validation. In this study, a combination of N-gram features, Term Frequency-Inverse Document Frequency (TF-IDF) weighting, and additional word dictionary as features were used. In the TF-IDF weighting process, a threshold of 2,0 in the Document-Frequency (DF) is given. The classification process is carried out using Support Vector Machine (SVM) algorithm with a linear kernel and the best accuracy obtained is 96.53%. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "English is a language commonly used in the international world. Meanwhile, English that is often used in society is British English and American English. Beyond of the similarities, they all have fundamental differences, starting from the vocabulary to the grammar used. In learning English, people must ensure the type of English that they will learn. Therefore, this study is created a text classification system that can classify sentences according to the type of English used in the text. By that, it is expected to facilitate the language learning process in English. The dataset is divided into two classes namely British English and American English. The data will be divided by 10-fold-cross-validation. In this study, a combination of N-gram features, Term Frequency-Inverse Document Frequency (TF-IDF) weighting, and additional word dictionary as features were used. In the TF-IDF weighting process, a threshold of 2,0 in the Document-Frequency (DF) is given. The classification process is carried out using Support Vector Machine (SVM) algorithm with a linear kernel and the best accuracy obtained is 96.53%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The Means of Engagement (MOE) Model of the Agreement towards the Enterprise Resource Planning (ERP) Implementation"
        ],
        "penulis":"Syafiera, Tsara;Lubis, Muharman;Witjaksono, R. Wahjoe;Anggana, Hilman Dwi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Faster economic development led to increasingly tight business competition. With the development of increasingly sophisticated technology, these companies compete in leveraging technology to enhance competitive advantage and efficiency of their company's performance compared to its competitors. ERP systems are already commonly used in large companies and companies that develop because it is considered can improve performance and can help the process efficiency of data each process in system performance for flow can be connected. ERP system implementation is not always running smoothly. When the company failed to perform some of the success factors of ERP implementation, then these companies will experience failure in implementation. Companies must have a good strategy to achieve the desired success. Business strategy is done by optimizing the company's internal resources and innovate to face competition with other companies. By applying an ERP system can help companies to keep up with changes in the business that would later show up to the new business requirements. By using the Means of Engagement (MOE) model concept, the company can know the things to be aware of and consider implementing ERP software, so that it can minimize the failures that will occur. There are three levels in the MOE model, namely Adoption, Approval, Acceptance, and Agreement. At the level of Agreement that can be used by the analysis of clustering. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Faster economic development led to increasingly tight business competition. With the development of increasingly sophisticated technology, these companies compete in leveraging technology to enhance competitive advantage and efficiency of their company's performance compared to its competitors. ERP systems are already commonly used in large companies and companies that develop because it is considered can improve performance and can help the process efficiency of data each process in system performance for flow can be connected. ERP system implementation is not always running smoothly. When the company failed to perform some of the success factors of ERP implementation, then these companies will experience failure in implementation. Companies must have a good strategy to achieve the desired success. Business strategy is done by optimizing the company's internal resources and innovate to face competition with other companies. By applying an ERP system can help companies to keep up with changes in the business that would later show up to the new business requirements. By using the Means of Engagement (MOE) model concept, the company can know the things to be aware of and consider implementing ERP software, so that it can minimize the failures that will occur. There are three levels in the MOE model, namely Adoption, Approval, Acceptance, and Agreement. At the level of Agreement that can be used by the analysis of clustering. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Prototype of Micro Reaction Wheel for Cubesat"
        ],
        "penulis":"Manggala F.H.;Ramadhan R.P.;Wijanto H.;Mayditia H.;Edwar, Edwar;Vidyaningtyas H.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tel-USat is a Cubesat 1U which is designed to capture the Earth surface photograph using serial camera. To support the mission, an attitude control is needed such as Attitude and Determination Control Subsystem (ADCS). This spacecraft is designed with a Micro Reaction Wheel (MRW). This is a type of reaction wheel that has a small size which fit with cubesat dimension. It consists of flywheel attached to BLDC motor and Electronic Wheel Drive (WDE). The Micro Reaction Wheel has been designed to have a minimum speed of 64021rpm with a voltage of 8V and a duty cycle of 9.95% or 4.47% and the maximum speed with a rigid of 1, 9V and a 7.55% duty cycle or 6.69%. With these results, the Micro Reaction Wheel can generate a torque of 0.74 mNm. Consume battery energy at a maximum speed of 16,67 mAh\/minute. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tel-USat is a Cubesat 1U which is designed to capture the Earth surface photograph using serial camera. To support the mission, an attitude control is needed such as Attitude and Determination Control Subsystem (ADCS). This spacecraft is designed with a Micro Reaction Wheel (MRW). This is a type of reaction wheel that has a small size which fit with cubesat dimension. It consists of flywheel attached to BLDC motor and Electronic Wheel Drive (WDE). The Micro Reaction Wheel has been designed to have a minimum speed of 64021rpm with a voltage of 8V and a duty cycle of 9.95% or 4.47% and the maximum speed with a rigid of 1, 9V and a 7.55% duty cycle or 6.69%. With these results, the Micro Reaction Wheel can generate a torque of 0.74 mNm. Consume battery energy at a maximum speed of 16,67 mAh\/minute. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Item delivery simulation using genetic algorithm"
        ],
        "penulis":"Switrayana, I Nyoman;Osmond, Andrew Brian;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In sending items, time and costs can be minimized by selecting the shortest path. The problem of choosing the shortest path is often known as Travelling Salesman Problem (TSP). TSP in this study was not only concerned with distance but also the priority of places to be visited. Priority parameters in this research are a sign that each place has a value to be visited first than another place. This priority can also be assumed as a type of delivery service that can be chosen by the customer. Priority is divided into three groups, but it can also be more than that according to the needs of a shipping service provider. Delivery of multiple destinations in one area can be delivered with a single trip based on their priority. Search optimization of the shortest path is modeled with genetic algorithms. Hamilton path is the output of the simulation. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In sending items, time and costs can be minimized by selecting the shortest path. The problem of choosing the shortest path is often known as Travelling Salesman Problem (TSP). TSP in this study was not only concerned with distance but also the priority of places to be visited. Priority parameters in this research are a sign that each place has a value to be visited first than another place. This priority can also be assumed as a type of delivery service that can be chosen by the customer. Priority is divided into three groups, but it can also be more than that according to the needs of a shipping service provider. Delivery of multiple destinations in one area can be delivered with a single trip based on their priority. Search optimization of the shortest path is modeled with genetic algorithms. Hamilton path is the output of the simulation. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Implementation of Object Tracking Augmented Reality Markerless using FAST Corner Detection on User Defined-Extended Target Tracking in Multivarious Intensities"
        ],
        "penulis":"Nurhadi;Saparudin;Adam N.;Purnamasari D.;Fachruddin;Ibrahim, Ali;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents a FAST Corner Detection object scanning to improve SLAM technique, which is SLAM, has a weakness in extracting features in the real-world object. The use of User Defined Target and Extended Tracking are for making this work more convenient and reliable. We can trace the object even though the object does not exist, so this improves the function of markerless itself. The use of Raycast is for the make labeling the objects or features in the scanned object. In this research, we executed multivarious intensity to test the FAST Corner Detection to increase function in real world feature extraction and prove it better than SLAM. Then, we got the result where is a brighter condition will get faster recognition. The best environments for augmentation are in the range of 80-190, they took in less than 1 second. On the contrary, the intensity outside of the range such as \u226450 or \u2265200, has a deficiency of augmentation. The range of \u226450, there was no augmentation cause of low intensity. For the range of \u2265200, we haven't made measurements as we don't have the resources yet, but we hypothesize that the object would be corrupt or we may call it was overexposure cause of the intensity is too high. So, this could also lead to augmentation will not occur. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents a FAST Corner Detection object scanning to improve SLAM technique, which is SLAM, has a weakness in extracting features in the real-world object. The use of User Defined Target and Extended Tracking are for making this work more convenient and reliable. We can trace the object even though the object does not exist, so this improves the function of markerless itself. The use of Raycast is for the make labeling the objects or features in the scanned object. In this research, we executed multivarious intensity to test the FAST Corner Detection to increase function in real world feature extraction and prove it better than SLAM. Then, we got the result where is a brighter condition will get faster recognition. The best environments for augmentation are in the range of 80-190, they took in less than 1 second. On the contrary, the intensity outside of the range such as \u226450 or \u2265200, has a deficiency of augmentation. The range of \u226450, there was no augmentation cause of low intensity. For the range of \u2265200, we haven't made measurements as we don't have the resources yet, but we hypothesize that the object would be corrupt or we may call it was overexposure cause of the intensity is too high. So, this could also lead to augmentation will not occur. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Implementation of power inverter on grid connected photovoltaic generator system"
        ],
        "penulis":"Prastyo, Argo;Ekaputri, Cahyantarie;Reza, Muhamad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The issuance of ESDM (ministry of energy and mineral resources) regulation number 49 of 2018 concerning the use of a rooftop solar power generation system by consumers of PT PLN (Persero). It is encouraging to conduct research on one method of generating electricity using solar panels. The voltage generated in the generation process using solar panels is a direct voltage (DC) and requires an inverter as a voltage converter to be an alternating voltage (AC) which is the daily consumption of Indonesian people. This research aims to develop the use of renewable energy using an inverter. This inverter uses batteries as a source of voltage, Arduino as a source of SPWM waves, and MOSFETs are arranged in a full-bridge configuration to convert 12V DC electricity into 12VAC which will then be filtered using a low-pass filter to pass a 50 Hz frequency and then increase the voltage using a transformer to 220Vmax \/ 155 Vrms. The result of designing this research is that the inverter is able to produce a sinusoidal wave output 220 Vmax with a frequency of 50 Hz. With the output signal approaching the sinusoidal signal purely from the filter output, the power loss from the use of the transformer causes the power output from the inverter to be not optimal. \u00a9 2019 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The issuance of ESDM (ministry of energy and mineral resources) regulation number 49 of 2018 concerning the use of a rooftop solar power generation system by consumers of PT PLN (Persero). It is encouraging to conduct research on one method of generating electricity using solar panels. The voltage generated in the generation process using solar panels is a direct voltage (DC) and requires an inverter as a voltage converter to be an alternating voltage (AC) which is the daily consumption of Indonesian people. This research aims to develop the use of renewable energy using an inverter. This inverter uses batteries as a source of voltage, Arduino as a source of SPWM waves, and MOSFETs are arranged in a full-bridge configuration to convert 12V DC electricity into 12VAC which will then be filtered using a low-pass filter to pass a 50 Hz frequency and then increase the voltage using a transformer to 220Vmax \/ 155 Vrms. The result of designing this research is that the inverter is able to produce a sinusoidal wave output 220 Vmax with a frequency of 50 Hz. With the output signal approaching the sinusoidal signal purely from the filter output, the power loss from the use of the transformer causes the power output from the inverter to be not optimal. \u00a9 2019 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Item delivery simulation using genetic algorithm"
        ],
        "penulis":"Switrayana, I Nyoman;Osmond, Andrew Brian;Aditsania, Annisa;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In sending items, time and costs can be minimized by selecting the shortest path. The problem of choosing the shortest path is often known as Travelling Salesman Problem (TSP). TSP in this study was not only concerned with distance but also the priority of places to be visited. Priority parameters in this research are a sign that each place has a value to be visited first than another place. This priority can also be assumed as a type of delivery service that can be chosen by the customer. Priority is divided into three groups, but it can also be more than that according to the needs of a shipping service provider. Delivery of multiple destinations in one area can be delivered with a single trip based on their priority. Search optimization of the shortest path is modeled with genetic algorithms. Hamilton path is the output of the simulation. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In sending items, time and costs can be minimized by selecting the shortest path. The problem of choosing the shortest path is often known as Travelling Salesman Problem (TSP). TSP in this study was not only concerned with distance but also the priority of places to be visited. Priority parameters in this research are a sign that each place has a value to be visited first than another place. This priority can also be assumed as a type of delivery service that can be chosen by the customer. Priority is divided into three groups, but it can also be more than that according to the needs of a shipping service provider. Delivery of multiple destinations in one area can be delivered with a single trip based on their priority. Search optimization of the shortest path is modeled with genetic algorithms. Hamilton path is the output of the simulation. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparison of Classical Interpolation Methods and Compressive Sensing for Missing Data Reconstruction"
        ],
        "penulis":"Usman, Koredianto;Ramdhani, Mohammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The emerging of a new compression technique called compressive sensing (CS) has opened various research possibility in many fields. Practically, CS consists of two main steps, which are compression step and reconstruction step. In many cases, the compression step occurs naturally, for example when several data is missing from the complete set of data. Reconstructing for complete data from incomplete data is the original aims of CS reconstruction process. It is therefore also a logical implication of CS as data interpolation method. Given this situation, a research of CS capability for data interpolation is not yet available. In this paper we investigate the capability of CS for data interpolation. Two popular CS reconstruction tools are used: orthogonal matching pursuit (OMP) and convex programming (CVX). We compared these CS reconstruction performance to the standard interpolation methods which are the linear interpolation and spline interpolation. Simulation results show that classical interpolation methods have better performance in term of general accuracy, while CS reconstruction method has advantage on accuracy in reconstructing data that has sharp changes. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The emerging of a new compression technique called compressive sensing (CS) has opened various research possibility in many fields. Practically, CS consists of two main steps, which are compression step and reconstruction step. In many cases, the compression step occurs naturally, for example when several data is missing from the complete set of data. Reconstructing for complete data from incomplete data is the original aims of CS reconstruction process. It is therefore also a logical implication of CS as data interpolation method. Given this situation, a research of CS capability for data interpolation is not yet available. In this paper we investigate the capability of CS for data interpolation. Two popular CS reconstruction tools are used: orthogonal matching pursuit (OMP) and convex programming (CVX). We compared these CS reconstruction performance to the standard interpolation methods which are the linear interpolation and spline interpolation. Simulation results show that classical interpolation methods have better performance in term of general accuracy, while CS reconstruction method has advantage on accuracy in reconstructing data that has sharp changes. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Comparison of feature selection techniques in classifying stroke documents"
        ],
        "penulis":"Rafei, Nur Syaza Izzati Mohd;Hassan, Rohayanti;Saedudin, R. D. Rohmat;Raffei, Anis Farihan Mat;Zakaria, Zalmiyah;Kasim, Shahreen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The amount of digital biomedical literature grows that make most of the researchers facing the difficulties to manage and retrieve the required information from the Internet because this task is very challenging. The application of text classification on biomedical literature is one of the solutions in order to solve problem that have been faced by researchers but managing the high dimensionality of data being a common issue on text classification. Therefore, the aim of this research is to compare the techniques that could be used to select the relevant features for classifying biomedical text abstracts. This research focus on Pearson\u201fs Correlation and Information Gain as feature selection techniques for reducing the high dimensionality of data. Towards this effort, we conduct and evaluate several experiments using 100 abstract of stroke documents that retrieved from PubMed database as datasets. This dataset underwent the text pre-processing that is crucial before proceed to feature selection phase. Features selection phase is involving Information Gain and Pearson Correlation technique. Support Vector Machine classifier is used in order to evaluate and compare the effectiveness of two feature selection techniques. For this dataset, Information Gain has outperformed Pearson\u201fs Correlation by 3.3%. This research tends to extract the meaningful features from a subset of stroke documents that can be used for various application especially in diagnose the stroke disease. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The amount of digital biomedical literature grows that make most of the researchers facing the difficulties to manage and retrieve the required information from the Internet because this task is very challenging. The application of text classification on biomedical literature is one of the solutions in order to solve problem that have been faced by researchers but managing the high dimensionality of data being a common issue on text classification. Therefore, the aim of this research is to compare the techniques that could be used to select the relevant features for classifying biomedical text abstracts. This research focus on Pearson\u201fs Correlation and Information Gain as feature selection techniques for reducing the high dimensionality of data. Towards this effort, we conduct and evaluate several experiments using 100 abstract of stroke documents that retrieved from PubMed database as datasets. This dataset underwent the text pre-processing that is crucial before proceed to feature selection phase. Features selection phase is involving Information Gain and Pearson Correlation technique. Support Vector Machine classifier is used in order to evaluate and compare the effectiveness of two feature selection techniques. For this dataset, Information Gain has outperformed Pearson\u201fs Correlation by 3.3%. This research tends to extract the meaningful features from a subset of stroke documents that can be used for various application especially in diagnose the stroke disease. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "A multi-label classification on topics of Indonesian news using K-Nearest Neighbor"
        ],
        "penulis":"Isnaini, Nikmah;Adiwijaya;Mubarok, Mohamad Syahrul;Bakar, Muhammad Yuslan Abu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "News has become a basic human need along with technological and internet developments. This causes the process of disseminating information on the news that switched from print media to the digital era. Another problem that appears when classifying news is multi-label. Multi-label classification is different from single label classification. A single label classification will classify documents into one label only. While multi-label classification can group documents into more than one label. For example, news articles that discuss in detail the early detection of ovarian cancer with a bioinformatics approach may have more than one label such as health, bioinformatics, and women. In this paper, a classification model is developed that can identify classes in each multi-label news article using K-Nearest Neighbor. The advantages of K-Nearest Neighbor are algorithms that are very suitable for multi-label cases; even KNN can be superior to other classifiers. From the system created, the results of the value of system performance as measured by the size of the closeness are the comparison between Manhattan Distance, Euclidean Distance and Supremum Distance using the K = 11 parameters, resulting in a Hamming Loss value of 11.16.%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "News has become a basic human need along with technological and internet developments. This causes the process of disseminating information on the news that switched from print media to the digital era. Another problem that appears when classifying news is multi-label. Multi-label classification is different from single label classification. A single label classification will classify documents into one label only. While multi-label classification can group documents into more than one label. For example, news articles that discuss in detail the early detection of ovarian cancer with a bioinformatics approach may have more than one label such as health, bioinformatics, and women. In this paper, a classification model is developed that can identify classes in each multi-label news article using K-Nearest Neighbor. The advantages of K-Nearest Neighbor are algorithms that are very suitable for multi-label cases; even KNN can be superior to other classifiers. From the system created, the results of the value of system performance as measured by the size of the closeness are the comparison between Manhattan Distance, Euclidean Distance and Supremum Distance using the K = 11 parameters, resulting in a Hamming Loss value of 11.16.%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Coverage and capacity analysis of LoRa WAN deployment for massive IoT in urban and suburban scenario"
        ],
        "penulis":"Nashiruddin, Muhammad Imam;Hidayati, Amriane;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Choosing connectivity technologies for the Internet of Things (IoT) is the most important aspect in the early stages of network planning. Long Range (LoRa) Wide Area Network (WAN) that categorized into Low Power Wide Area (LPWA) network is a potential connectivity technology for typical massive IoT applications like a smart meter, smart manufacturing, environmental monitoring, etc. This paper aims to provide coverage and capacity analysis of LoRa WAN for typical massive IoT application. The urban and suburban areas were chosen to observe the differences between those two scenarios. The results shown the capacity calculation in terms of the gateways needed is mainly influenced by the value of the bandwidth (BW), spreading factor (SF) and Coding Rate (CR). Coverage simulation is done by calculating the link budget, followed by a simulation using Forsk Atoll 3.3.2. It can be concluded that the whole determined areas can be served within acceptable levels with values > -137 dBm as the minimum sensitivity of the highest SF. While the mean of best signal level is -84.58 dBm and -90.9 dBm for the urban and suburban scenario, respectively.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Choosing connectivity technologies for the Internet of Things (IoT) is the most important aspect in the early stages of network planning. Long Range (LoRa) Wide Area Network (WAN) that categorized into Low Power Wide Area (LPWA) network is a potential connectivity technology for typical massive IoT applications like a smart meter, smart manufacturing, environmental monitoring, etc. This paper aims to provide coverage and capacity analysis of LoRa WAN for typical massive IoT application. The urban and suburban areas were chosen to observe the differences between those two scenarios. The results shown the capacity calculation in terms of the gateways needed is mainly influenced by the value of the bandwidth (BW), spreading factor (SF) and Coding Rate (CR). Coverage simulation is done by calculating the link budget, followed by a simulation using Forsk Atoll 3.3.2. It can be concluded that the whole determined areas can be served within acceptable levels with values > -137 dBm as the minimum sensitivity of the highest SF. While the mean of best signal level is -84.58 dBm and -90.9 dBm for the urban and suburban scenario, respectively.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Tracking telemetry and command using software defined radio with nano-satellite parameters"
        ],
        "penulis":"Wangsa, Damas Wicaksi;Syihabuddin, Budi;Edwar;Wijanto, Heroe;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Ground station is satellite sub-system for satellite communication. It has several functions such as master station and Telemetry, Tracking, and Command (TT&C). Developing a ground station is expensive but it can be reduced by using Software Defined Radio (SDR). We use SDR because it is easily to reconfigure based on system requirement. Simulation process using GNU radio and implementation using HackRF. In this paper use two scenario for design and testing. First scenario for validating the simulation process and second scenario for testing TT&C performance using SDR. The scenarios use text and image file as basic data. It transmit 2.7 kB text file and 11.5kB image file and received respectively 2.23 kB and 11.15 kB. In first scenario, there are 1.2 errors for text file and 2.3 errors for image file and in second scenario there are 5.2 errors for text file and 25.9 errors. \u00a9 2019 IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ground station is satellite sub-system for satellite communication. It has several functions such as master station and Telemetry, Tracking, and Command (TT&C). Developing a ground station is expensive but it can be reduced by using Software Defined Radio (SDR). We use SDR because it is easily to reconfigure based on system requirement. Simulation process using GNU radio and implementation using HackRF. In this paper use two scenario for design and testing. First scenario for validating the simulation process and second scenario for testing TT&C performance using SDR. The scenarios use text and image file as basic data. It transmit 2.7 kB text file and 11.5kB image file and received respectively 2.23 kB and 11.15 kB. In first scenario, there are 1.2 errors for text file and 2.3 errors for image file and in second scenario there are 5.2 errors for text file and 25.9 errors. \u00a9 2019 IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Air quality monitoring system based internet of things (IoT) using LPWAN LoRa"
        ],
        "penulis":"Firdaus, Rizky;Murti, Muhammad Ary;Alinursafa, Ibnu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Air has an important function and role in the lives of humans and other living beings. Every living things needs clean air to support its life optimally, its quality needs to be maintained. A good and healthy level of air quality is one of the main factors in creating a healthy and comfortable environment if the air quality is bad then there will be pollution that will interfere with the health of every population that inhaled. In this research, the author utilizes the Internet of Things (IoT) technology to monitor the condition of air quality levels such as temperature, air humidity, CO and CO2. The system uses ATmega328P-AU as a controller, DHT22 sensor for temperature and air humidity, MQ-7 sensor for CO gas, MQ-135 sensor for CO2 gas, LPWAN LoRa for data transmission communication and Antares as a cloud service for storing data to be displayed on Android. The test results obtained the average error value for temperatures \u00b1 0.8 \u00b0C, humidity \u00b1 3.1 % RH, CO \u00b1 10 ppm and CO2 \u00b1 16 ppm. The results of sensor data are stored in the Antares cloud and displayed on Android. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Air has an important function and role in the lives of humans and other living beings. Every living things needs clean air to support its life optimally, its quality needs to be maintained. A good and healthy level of air quality is one of the main factors in creating a healthy and comfortable environment if the air quality is bad then there will be pollution that will interfere with the health of every population that inhaled. In this research, the author utilizes the Internet of Things (IoT) technology to monitor the condition of air quality levels such as temperature, air humidity, CO and CO2. The system uses ATmega328P-AU as a controller, DHT22 sensor for temperature and air humidity, MQ-7 sensor for CO gas, MQ-135 sensor for CO2 gas, LPWAN LoRa for data transmission communication and Antares as a cloud service for storing data to be displayed on Android. The test results obtained the average error value for temperatures \u00b1 0.8 \u00b0C, humidity \u00b1 3.1 % RH, CO \u00b1 10 ppm and CO2 \u00b1 16 ppm. The results of sensor data are stored in the Antares cloud and displayed on Android. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Modified K-Means clustering model in multi store delivery service"
        ],
        "penulis":"Kusuma, Purba Daru;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "There are several delivery service problems in companies that have multiple stores in one city. These problems occur especially for companies that offer products that these products must be delivered to the customers\u2019 location by using their own delivery service. For several companies, they distribute their stock in a single main warehouse and in their stores. In the other side, their delivery service fleet is also distributed in their main warehouse and in every store. This condition triggers inefficiency in stock and the delivery fleet. In this work, we propose the centralized shared delivery service model. As a centralized model, the delivery service is handled by the central management so that coordination in delivery process among vehicles can be more efficient. As a shared system, the vehicle is not dedicated for single store only so that the vehicle can deliver products that come from more than one store in a single trip. In warehouse management, we use single warehouse concept so that all purchased products from all stores will be delivered from the main warehouse. In this work, we propose modified k-means clustering model in managing the delivery process. By using clustering mechanism, each vehicle will deliver products that their destination location is near to each other. In this work, we propose two variants of the k-means clustering model. In the first variant, we combine the k-means clustering method with the round robin method. In the second variant, we combine the k-means clustering method with sequential vehicle creation method. There are research findings after we have done tests. The increasing of the city size makes all observed variables increase. This condition occurs in all models. The increasing of the maximum delivery distance does not affect the total delivery distance but makes the number of vehicles decrease and in the other side makes the delivery distance per vehicle increase. The increasing of the number of stores does not affect the total delivery distance. In the first model, the increasing of the number of stores makes the number of vehicles increase and the delivery distance per vehicle decrease. In the other models, the increasing of the number of stores does not affect the number of vehicles and the delivery distance per vehicle. The increasing of the number of destinations makes all observed variables increase. \u00a9 2005 \u2013 ongoing JATIT & LLS.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "There are several delivery service problems in companies that have multiple stores in one city. These problems occur especially for companies that offer products that these products must be delivered to the customers\u2019 location by using their own delivery service. For several companies, they distribute their stock in a single main warehouse and in their stores. In the other side, their delivery service fleet is also distributed in their main warehouse and in every store. This condition triggers inefficiency in stock and the delivery fleet. In this work, we propose the centralized shared delivery service model. As a centralized model, the delivery service is handled by the central management so that coordination in delivery process among vehicles can be more efficient. As a shared system, the vehicle is not dedicated for single store only so that the vehicle can deliver products that come from more than one store in a single trip. In warehouse management, we use single warehouse concept so that all purchased products from all stores will be delivered from the main warehouse. In this work, we propose modified k-means clustering model in managing the delivery process. By using clustering mechanism, each vehicle will deliver products that their destination location is near to each other. In this work, we propose two variants of the k-means clustering model. In the first variant, we combine the k-means clustering method with the round robin method. In the second variant, we combine the k-means clustering method with sequential vehicle creation method. There are research findings after we have done tests. The increasing of the city size makes all observed variables increase. This condition occurs in all models. The increasing of the maximum delivery distance does not affect the total delivery distance but makes the number of vehicles decrease and in the other side makes the delivery distance per vehicle increase. The increasing of the number of stores does not affect the total delivery distance. In the first model, the increasing of the number of stores makes the number of vehicles increase and the delivery distance per vehicle decrease. In the other models, the increasing of the number of stores does not affect the number of vehicles and the delivery distance per vehicle. The increasing of the number of destinations makes all observed variables increase. \u00a9 2005 \u2013 ongoing JATIT & LLS."
        ]
    },
    {
        "judul":[
            "A Progress on the Personality Measurement Model using Ontology based on Social Media Text"
        ],
        "penulis":"Alamsyah, Andry;Rachman, Muhammad Fadhli;Hudaya, Cindy Septiani;Putra, Rimba Pratama;Rifkyano, Aulia Ichsan;Nurwianti, Fivi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Personality measurement (PM) has evolved from taking a personality test or expert assessment into utilizing user generated content to measure personality. Several attempts to create a model for PM has been done by the various researcher using English as the main language. While the PM model in Bahasa Indonesia is limited. Further research is required due to the unavailability of PM model in Bahasa Indonesia, lack of corpus to gain high accuracy, and the urgency of automating the measurement process. The progress of PM Ontology model is 1) we are enriching the corpus in Bahasa Indonesia in the ontology model 2) design and prototyping the PM ontology platform using Ruby programming language 3) evaluate the PM ontology model. Our proposed platform offers a fast and affordable tool to analyze large textual data to measures human personality based on big five personality traits. Extensively, the platform is beneficial to have express analysis process and utilized the insight into various areas such as human resources, CRM, marketing or another process that requires personality measurement. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Personality measurement (PM) has evolved from taking a personality test or expert assessment into utilizing user generated content to measure personality. Several attempts to create a model for PM has been done by the various researcher using English as the main language. While the PM model in Bahasa Indonesia is limited. Further research is required due to the unavailability of PM model in Bahasa Indonesia, lack of corpus to gain high accuracy, and the urgency of automating the measurement process. The progress of PM Ontology model is 1) we are enriching the corpus in Bahasa Indonesia in the ontology model 2) design and prototyping the PM ontology platform using Ruby programming language 3) evaluate the PM ontology model. Our proposed platform offers a fast and affordable tool to analyze large textual data to measures human personality based on big five personality traits. Extensively, the platform is beneficial to have express analysis process and utilized the insight into various areas such as human resources, CRM, marketing or another process that requires personality measurement. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Mapping technological trajectories of Crystalline Silicon (c-Si) PV using patent analysis"
        ],
        "penulis":"Mubarok, Muhammad Husni;Nafizah, Ully Yunita;Permana, Muhammad Yorga;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper is the first to identify the technological development of crystalline silicon (c-Si) PV technology by analyzing network patent and main trajectory. The data used is the US granted patent from 1976 until 2010, thus resulted of 1,100 patents data. The network of patent citation data is analysed based on the key network measure (i.e., number of nodes, density, in-degree centrality, and out-degree centrality) and followed by developing the network trajectory. The main path analysis is obtained by using both SPLC method (Search Path Link Count) and the SPNP method (Search Path Nodes Pair). The main path further is analyzed along with its sub-path to understand the evolution of c-Si PV technology. The results indicate that: 1) the c-Si Solar cells technology has very low network density which means the patents are sparsely connected with each other, 2) The connected patents are the representative of the 'new' thin-film solar technology, 3) The most cited patent is not a part the main trajectory, meaning that there is a low correlation between patent and technology development, 4) The US, Japan, and Germany are the main actors in c-Si solar cells technology. US and Germany are identified as key pioneers during the early stage of this technology, while Japan appears at later stages, 5) Siemens is the main actor in the initial c-Si PV technology. \u00a9 2019, International Journal of Renewable Energy Research.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document"
        ],
        "abstrak":[
            "This paper is the first to identify the technological development of crystalline silicon (c-Si) PV technology by analyzing network patent and main trajectory. The data used is the US granted patent from 1976 until 2010, thus resulted of 1,100 patents data. The network of patent citation data is analysed based on the key network measure (i.e., number of nodes, density, in-degree centrality, and out-degree centrality) and followed by developing the network trajectory. The main path analysis is obtained by using both SPLC method (Search Path Link Count) and the SPNP method (Search Path Nodes Pair). The main path further is analyzed along with its sub-path to understand the evolution of c-Si PV technology. The results indicate that: 1) the c-Si Solar cells technology has very low network density which means the patents are sparsely connected with each other, 2) The connected patents are the representative of the 'new' thin-film solar technology, 3) The most cited patent is not a part the main trajectory, meaning that there is a low correlation between patent and technology development, 4) The US, Japan, and Germany are the main actors in c-Si solar cells technology. US and Germany are identified as key pioneers during the early stage of this technology, while Japan appears at later stages, 5) Siemens is the main actor in the initial c-Si PV technology. \u00a9 2019, International Journal of Renewable Energy Research."
        ]
    },
    {
        "judul":[
            "Rainfall forecasting multi kernel support vector regression seasonal autoregressive integrated moving average (MKSVR-SARIMA)"
        ],
        "penulis":"Caraka, Rezzy Eko;Bakar, Sakhinah Abu;Tahmid, Muhammad;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Rainfall variation in the tropics is caused by several factors, such as: geographic, topographical, and orographic. Therefore, the importance of rainfall analysis is needed to know the factors also local characteristics that affect fluctuations in daily rainfall \/ monthly in each particular area. Rainfall is one element of weather that has a vital role in various sectors in Indonesia. In the agriculture sector, rainfall prediction is used to know the schedule prediction of cropping pattern to optimize food crop production result. In the land, sea and air transport sector, the weather factor that rainfall has a role in the level of safety. In this paper, we used daily rainfall data in Manado, North Sulawesi province in January 2017-December 2017. In short, we combined of SARIMA, and Localized Multi Kernel Support Vector Regression (LMKL SVR) with linear kernel and polynomial kernel reached accuracy model R298.76%. On the one hand, after obtained rainfall prediction, we compared with actual rainfall data in January 2018 -February 2018 (59 data). Mainly, Rainfall is difficult to predict even though the model obtained has good accuracy. Still, after validation data forecast and actual data, there is a very far different with RMSE amount 24.43 because the data climate is very dynamic also there are variables that need to be analyzed in building prediction model of rainfall \u00a9 2019 Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rainfall variation in the tropics is caused by several factors, such as: geographic, topographical, and orographic. Therefore, the importance of rainfall analysis is needed to know the factors also local characteristics that affect fluctuations in daily rainfall \/ monthly in each particular area. Rainfall is one element of weather that has a vital role in various sectors in Indonesia. In the agriculture sector, rainfall prediction is used to know the schedule prediction of cropping pattern to optimize food crop production result. In the land, sea and air transport sector, the weather factor that rainfall has a role in the level of safety. In this paper, we used daily rainfall data in Manado, North Sulawesi province in January 2017-December 2017. In short, we combined of SARIMA, and Localized Multi Kernel Support Vector Regression (LMKL SVR) with linear kernel and polynomial kernel reached accuracy model R298.76%. On the one hand, after obtained rainfall prediction, we compared with actual rainfall data in January 2018 -February 2018 (59 data). Mainly, Rainfall is difficult to predict even though the model obtained has good accuracy. Still, after validation data forecast and actual data, there is a very far different with RMSE amount 24.43 because the data climate is very dynamic also there are variables that need to be analyzed in building prediction model of rainfall \u00a9 2019 Author(s)."
        ]
    },
    {
        "judul":[
            "Data processing of laboratory recruitment using K-nearest neighbor algorithm"
        ],
        "penulis":"Mustabshiroh;Latuconsina, Roswan;Purboyo, Tito Waluyo;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of science and technology increasingly popular in the society. Computer technology is growing very rapidly according to the level of human needs to solve various of problems. One of the rapid development of computer science is the field of data processing that is capable of processing data and provide information to support decision, one of which is data mining. Data mining helps to extract patterns from large data to be interpreted as human-readable information. A simple example of the use of data mining is the recommendation system used in the recruitment of laboratory assistants by using the k-nearest neighbor method. The training data is in the form of the grade from previous recruitment which will be used as a reference in determining whether the candidate is declared accepted or not. \u00a9 Medwell Journals, 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of science and technology increasingly popular in the society. Computer technology is growing very rapidly according to the level of human needs to solve various of problems. One of the rapid development of computer science is the field of data processing that is capable of processing data and provide information to support decision, one of which is data mining. Data mining helps to extract patterns from large data to be interpreted as human-readable information. A simple example of the use of data mining is the recommendation system used in the recruitment of laboratory assistants by using the k-nearest neighbor method. The training data is in the form of the grade from previous recruitment which will be used as a reference in determining whether the candidate is declared accepted or not. \u00a9 Medwell Journals, 2019."
        ]
    },
    {
        "judul":[
            "Business process maturity level of MSMEs in East Java, Indonesia"
        ],
        "penulis":"Dewi, Fitriyana;Mahendrawathi E.R.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The purpose of this research is to evaluate the degree of Micro, Small and Medium Enterprises (MSMEs)'s in East Java using business process maturity model. McCormack model is fine to use for assessing the MSME's business process that brings out the business process maturity level of MSMEs. On the ninth element of information systems support on BPOM model, we try to adjust the questionnaire items based on the condition of MSMEs in Indonesia which still lagging in the implementation of IT, so it is directing to the concept of IT readiness model by combining the state of IT infrastructure and application of MSMEs. This research also assessing the IT readiness of MSMEs and analyze the result by comparing with the level of maturity. The findings result from this research shows that the maturity of MSMEs in East Java are varying. Yet, the IT readiness of these MSMEs presents high score that indicates there seems to be a strong connection between IT usage, leadership and the maturity level of business process within the organization and explained how business process maturity is relevant to MSMEs. \u00a9 2019 The Authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this research is to evaluate the degree of Micro, Small and Medium Enterprises (MSMEs)'s in East Java using business process maturity model. McCormack model is fine to use for assessing the MSME's business process that brings out the business process maturity level of MSMEs. On the ninth element of information systems support on BPOM model, we try to adjust the questionnaire items based on the condition of MSMEs in Indonesia which still lagging in the implementation of IT, so it is directing to the concept of IT readiness model by combining the state of IT infrastructure and application of MSMEs. This research also assessing the IT readiness of MSMEs and analyze the result by comparing with the level of maturity. The findings result from this research shows that the maturity of MSMEs in East Java are varying. Yet, the IT readiness of these MSMEs presents high score that indicates there seems to be a strong connection between IT usage, leadership and the maturity level of business process within the organization and explained how business process maturity is relevant to MSMEs. \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Best Concept Selection for Dry-Soybean Cracking Machine Process Optimization using TOPSIS method"
        ],
        "penulis":"Anugraha R.A.;Darmawan N.M.;Iqbal M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tempe is a traditional Indonesian food with processed soybean as the main ingredients. Indonesia is the largest tempe producer in the world with hundreds of thousands of traditional tempe maker. Currently the traditional production process is wasteful that requires the amount of water as much as 1321 liters\/production of 37,5 kg tempe. Innovative dry production process is still less desirable because the dry soybean cracker machine is not optimal with a defect of 14,4% per production. In addition, the machine is unable to separate the husk and soybeans from the outlet. There are 12 alternative production concepts to produce highest quality tempe. TOPSIS method was used for selecting best production concept which reduces defect to 6,5% while manual separation process is eliminated. Water consumption is reduced to 800 liters\/production of 35,125 kg tempe. \u00a9 Published under licence by IOP Publishing Ltd.",
            "NIOOView detailsExpand Substance N-iodo-succinimide",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tempe is a traditional Indonesian food with processed soybean as the main ingredients. Indonesia is the largest tempe producer in the world with hundreds of thousands of traditional tempe maker. Currently the traditional production process is wasteful that requires the amount of water as much as 1321 liters\/production of 37,5 kg tempe. Innovative dry production process is still less desirable because the dry soybean cracker machine is not optimal with a defect of 14,4% per production. In addition, the machine is unable to separate the husk and soybeans from the outlet. There are 12 alternative production concepts to produce highest quality tempe. TOPSIS method was used for selecting best production concept which reduces defect to 6,5% while manual separation process is eliminated. Water consumption is reduced to 800 liters\/production of 35,125 kg tempe. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Clustering and classification of breathing activities by depth image from kinect"
        ],
        "penulis":"Delimayanti, Mera Kartika;Purnama, Bedy;Nguyen, Ngoc Giang;Mahmudah, Kunti Robiatul;Kubo, Mamoru;Kakikawa, Makiko;Yamada, Yoichi;Satou, Kenji;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper describes a new approach of the non-contact capturing method of breathing activities using the Kinect depth sensor. To process the data, we utilized feature extraction on time series of mean depth value and optional feature reduction step. The next process implemented a machine learning algorithm to execute clustering on the resulted data. The classification had been realized on four different subjects and then, continued to use 10-fold cross-validation and Support Vector Machine (SVM) classifier. The most efficient classifier is SVM radial with the grid reached the best accuracy for all of the subjects. \u00a9 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper describes a new approach of the non-contact capturing method of breathing activities using the Kinect depth sensor. To process the data, we utilized feature extraction on time series of mean depth value and optional feature reduction step. The next process implemented a machine learning algorithm to execute clustering on the resulted data. The classification had been realized on four different subjects and then, continued to use 10-fold cross-validation and Support Vector Machine (SVM) classifier. The most efficient classifier is SVM radial with the grid reached the best accuracy for all of the subjects. \u00a9 2019 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved."
        ]
    },
    {
        "judul":[
            "Flipping onsets to enhance syllabification"
        ],
        "penulis":"Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Two-year-old children who start learning to speak generally spell a polysyllabic word by flipping onsets of consecutive syllables. Sometimes they speak unclearly, hard to understand since the flipped onsets produce another word that has a much different meaning. For instance, two onsets in an English word \u201cme.lon\u201d (large round fruit of a plant of the gourd family) are flipped to produce another word \u201cle.mon\u201d (an acid fruit). In Bahasa Indonesia, such cases are quite common. For examples, two onsets in word \u201cba.tu\u201d (stone) are swapped to be \u201cta.bu\u201d (taboo), two onsets in \u201cbe.sar\u201d (big) are flipped to be \u201cse.bar\u201d (spread), two onsets in \u201cru.mah\u201d (house) are swapped to be \u201cmu.rah\u201d (cheap), etc. A preliminary study on 50k Indonesian formal words shows that the ratio between frequencies of the flipped-onset-bigrams and the 50 most frequent original syllable-bigrams is quite high, up to 13.09%. This research investigates the adoption of such phenomenon to enhances a bigram orthographic syllabification model that is commonly poor for out-of-vocabulary words. A five-fold cross-validation on 50k Indonesian formal words proves that the flipping onsets enhances the bigram orthographic syllabification, where the syllable error rate (SER) is relatively reduced by 18.02%. The method is also capable of producing quite low SER for a tiny trainset of 1k words to generalize 10k unseen words. Besides, it can be simply generalized to be applied to other languages as well as named-entities using a few specific knowledge related to the sets of vowels, diphthongs, and consonants. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Two-year-old children who start learning to speak generally spell a polysyllabic word by flipping onsets of consecutive syllables. Sometimes they speak unclearly, hard to understand since the flipped onsets produce another word that has a much different meaning. For instance, two onsets in an English word \u201cme.lon\u201d (large round fruit of a plant of the gourd family) are flipped to produce another word \u201cle.mon\u201d (an acid fruit). In Bahasa Indonesia, such cases are quite common. For examples, two onsets in word \u201cba.tu\u201d (stone) are swapped to be \u201cta.bu\u201d (taboo), two onsets in \u201cbe.sar\u201d (big) are flipped to be \u201cse.bar\u201d (spread), two onsets in \u201cru.mah\u201d (house) are swapped to be \u201cmu.rah\u201d (cheap), etc. A preliminary study on 50k Indonesian formal words shows that the ratio between frequencies of the flipped-onset-bigrams and the 50 most frequent original syllable-bigrams is quite high, up to 13.09%. This research investigates the adoption of such phenomenon to enhances a bigram orthographic syllabification model that is commonly poor for out-of-vocabulary words. A five-fold cross-validation on 50k Indonesian formal words proves that the flipping onsets enhances the bigram orthographic syllabification, where the syllable error rate (SER) is relatively reduced by 18.02%. The method is also capable of producing quite low SER for a tiny trainset of 1k words to generalize 10k unseen words. Besides, it can be simply generalized to be applied to other languages as well as named-entities using a few specific knowledge related to the sets of vowels, diphthongs, and consonants. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "Zone Based School Enrollment System by Using Modified k-Means Clustering Method"
        ],
        "penulis":"Kusuma, Purba Darn;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The main goal of zone based school enrollment method is reducing the student\u2019s home to school distance. So, among its variants, student will be allocated to the school that its location is near the student\u2019s home location. Meanwhile, one biggest problem in this method is the number of out of zone students which means of the student that is accepted in school that its location is outside his own zone. This situation occurs, especially when the zoning is determined statically. In this research, we propose dynamic zone based school enrollment model to meet the variations in school location distribution, student location distribution and school capacity. This model is developed based on k-means clustering method with several modifications. This proposed model then is implemented into zone based school enrollment simulation to measure its performance. In this simulation, the performance of this proposed model is also compared with the existing static one. In this simulation, adjusted parameters are school location distribution, student location distribution, school capacity, number of schools and number of students. Meanwhile, the observed parameters are average student\u2019s home to school distance and the success ratio. Based on the test result, there are several findings. The proposed model produces higher success ratio rather than the existing static method does. In the other side, the existing static method produces lower average student\u2019s home to school distance rather than the proposed model does. The number of schools and the average school capacity has positive correlation with the success ratio. The number of students has negative correlation with the success ratio. These adjusted variables do not affect the average student\u2019s home to school distance. \u00a9 Medwell Journals, 2019",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The main goal of zone based school enrollment method is reducing the student\u2019s home to school distance. So, among its variants, student will be allocated to the school that its location is near the student\u2019s home location. Meanwhile, one biggest problem in this method is the number of out of zone students which means of the student that is accepted in school that its location is outside his own zone. This situation occurs, especially when the zoning is determined statically. In this research, we propose dynamic zone based school enrollment model to meet the variations in school location distribution, student location distribution and school capacity. This model is developed based on k-means clustering method with several modifications. This proposed model then is implemented into zone based school enrollment simulation to measure its performance. In this simulation, the performance of this proposed model is also compared with the existing static one. In this simulation, adjusted parameters are school location distribution, student location distribution, school capacity, number of schools and number of students. Meanwhile, the observed parameters are average student\u2019s home to school distance and the success ratio. Based on the test result, there are several findings. The proposed model produces higher success ratio rather than the existing static method does. In the other side, the existing static method produces lower average student\u2019s home to school distance rather than the proposed model does. The number of schools and the average school capacity has positive correlation with the success ratio. The number of students has negative correlation with the success ratio. These adjusted variables do not affect the average student\u2019s home to school distance. \u00a9 Medwell Journals, 2019"
        ]
    },
    {
        "judul":[
            "The relationship of financial factors in asset pricing: The case of Indonesian market"
        ],
        "penulis":"Aryani, Sinta;Wiryono, Sudarso Kaderi;Koesrindartoto, Deddy P.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose of the study: The study shows how the financial factor of Leverage affects the empirical model of asset pricing together with other financial factors, i.e. Size, Book to Market, Operating Profit, and Investment. The contribution of Leverage in asset pricing will be tested, and its effect will be shown in the excess return of the asset. Methodology: The methodology used in this paper is based on the Fama and French model of asset pricing with additional factors added in the model. Data processing follows the Fama-Mc Beth procedure. Data comes from the Indonesian Stock Market, which consists of more than 500 stocks for ten years period of observation. Main Findings: The financial factor of Leverage affects the empirical model of asset pricing together with, i.e. Size, Book to Market, Operating Profit, and Investment. All the financial factors in the model are stationary around their mean, or they are non-stationary due to unit-roots. All the independents' variables have P-Value less than 10%. Implications: This study will be useful for financial investors in building an effective portfolio stock investment. By applying this model to their portfolio investment, the investors could effectively manage their portfolio return. On the management side, managing their financing structure, e.g. Leverage is the objective of the firm to maximize returns of the firms. Novelty\/Originality of this study: The empirical research with the involvement of the financial factor of Leverage has not been performed in Indonesia. The Leverage as the single factor of asset pricing has been considered as a significant financial factor for asset pricing, however, how the Leverage contributes to asset pricing compares to other financial factors has not examined yet. \u00a9 Aryani et al.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose of the study: The study shows how the financial factor of Leverage affects the empirical model of asset pricing together with other financial factors, i.e. Size, Book to Market, Operating Profit, and Investment. The contribution of Leverage in asset pricing will be tested, and its effect will be shown in the excess return of the asset. Methodology: The methodology used in this paper is based on the Fama and French model of asset pricing with additional factors added in the model. Data processing follows the Fama-Mc Beth procedure. Data comes from the Indonesian Stock Market, which consists of more than 500 stocks for ten years period of observation. Main Findings: The financial factor of Leverage affects the empirical model of asset pricing together with, i.e. Size, Book to Market, Operating Profit, and Investment. All the financial factors in the model are stationary around their mean, or they are non-stationary due to unit-roots. All the independents' variables have P-Value less than 10%. Implications: This study will be useful for financial investors in building an effective portfolio stock investment. By applying this model to their portfolio investment, the investors could effectively manage their portfolio return. On the management side, managing their financing structure, e.g. Leverage is the objective of the firm to maximize returns of the firms. Novelty\/Originality of this study: The empirical research with the involvement of the financial factor of Leverage has not been performed in Indonesia. The Leverage as the single factor of asset pricing has been considered as a significant financial factor for asset pricing, however, how the Leverage contributes to asset pricing compares to other financial factors has not examined yet. \u00a9 Aryani et al."
        ]
    },
    {
        "judul":[
            "Adaptive hierarchical formation control for uncertain Euler\u2013Lagrange systems using distributed inverse dynamics"
        ],
        "penulis":"Rosa, Muhammad Ridho;Baldi, Simone;Wang, Ximan;Lv, Maolong;Yu, Wenwu;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper establishes a novel adaptive hierarchical formation control method for uncertain heterogeneous nonlinear agents described by Euler\u2013Lagrange (EL) dynamics. Formation control is framed as a synchronization problem where a distributed model reference adaptive control is used to synchronize the EL systems. The idea behind the proposed adaptive formation algorithm is that each agent must converge to the model defined by its hierarchically superior neighbors. Using a distributed inverse dynamics structure, we prove that distributed nonlinear matching conditions between connected agents hold, so that matching gains exist to make the entire formation converge to same homogeneous dynamics: to compensate for the presence of uncertainties, estimation laws are devised for such matching gains, leading to adaptive synchronization. An appropriately designed distributed Lyapunov function is used to derive asymptotic convergence of the synchronization error. The effectiveness of the proposed methodology is supported by simulations of a formation of Unmanned Aerial Vehicles (UAVs). \u00a9 2018 European Control Association",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper establishes a novel adaptive hierarchical formation control method for uncertain heterogeneous nonlinear agents described by Euler\u2013Lagrange (EL) dynamics. Formation control is framed as a synchronization problem where a distributed model reference adaptive control is used to synchronize the EL systems. The idea behind the proposed adaptive formation algorithm is that each agent must converge to the model defined by its hierarchically superior neighbors. Using a distributed inverse dynamics structure, we prove that distributed nonlinear matching conditions between connected agents hold, so that matching gains exist to make the entire formation converge to same homogeneous dynamics: to compensate for the presence of uncertainties, estimation laws are devised for such matching gains, leading to adaptive synchronization. An appropriately designed distributed Lyapunov function is used to derive asymptotic convergence of the synchronization error. The effectiveness of the proposed methodology is supported by simulations of a formation of Unmanned Aerial Vehicles (UAVs). \u00a9 2018 European Control Association"
        ]
    },
    {
        "judul":[
            "Experimental Demonstration of OFDM Visible Light Communications based on System-on-Chip"
        ],
        "penulis":"Setiawan, Erwin;Fuada, Syifaul;Adiono, Trio;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In this paper, a System-on-Chip (SoC) architecture for OFDM-based Visible Light Communication (VLC) is demonstrated. The VLC system is used only for downlink (one way communication). We developed the SoC on the Xilinx ZYNQ-7000 All Programmable SoC. In this research, we integrated the system by connecting IP cores to the ARM Cortex-A9 processor; hence the IP cores can be accessed from software running on the Linux operating system (Ubuntu 16.04 version). To evaluate our SoC architecture, we integrated the FPGA into the Analog Front-End (AFE) module. The results show that the average Bit Error Rate (BER) are as follows: 7.693 \u00d7 10-5, 1.495\u00d710-3, and 6.578\u00d710-3for BPSK, QPSK, and QAM-16 modulations respectively.                          \u00a9 2018 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, a System-on-Chip (SoC) architecture for OFDM-based Visible Light Communication (VLC) is demonstrated. The VLC system is used only for downlink (one way communication). We developed the SoC on the Xilinx ZYNQ-7000 All Programmable SoC. In this research, we integrated the system by connecting IP cores to the ARM Cortex-A9 processor; hence the IP cores can be accessed from software running on the Linux operating system (Ubuntu 16.04 version). To evaluate our SoC architecture, we integrated the FPGA into the Analog Front-End (AFE) module. The results show that the average Bit Error Rate (BER) are as follows: 7.693 \u00d7 10-5, 1.495\u00d710-3, and 6.578\u00d710-3for BPSK, QPSK, and QAM-16 modulations respectively.                          \u00a9 2018 IEEE."
        ]
    },
    {
        "judul":[
            "Firm Innovation Capability through Knowledge Sharing at Indonesian Small and Medium Industries: Impact of Tacit and Explicit Knowledge Perspective"
        ],
        "penulis":"Rumanti, Augustina Asih;Wiratmadja, Iwan Inrawan;Sunaryo, Indryati;Ajidarma, Praditya;Ari Samadhi T.M.A.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Tacit knowledge is an asset that is embedded in an individual, while explicit knowledge is a type of knowledge that can be readily documented in an organization. Both types of knowledge are crucial for knowledge sharing within any organization as both are primary factors to boost innovation capability. Knowledge sharing process requires an enabler in its process. This research studies Small and Medium Industries (SMI), where knowledge sharing between one SMI to another is necessary, which enables a group of SMIs within a certain area to grow altogether. This research aims to analyze how the innovation capability of a company is influenced by knowledge sharing with the perspective of both tacit and explicit knowledge. The result shows that each indicator in every construct has a good validity, reliability, and significance level, which evidently suggests that a company's capacity to share knowledge, both tacitly and explicitly, is indeed significant and influential towards the innovation capability of such company in this case, SMI. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tacit knowledge is an asset that is embedded in an individual, while explicit knowledge is a type of knowledge that can be readily documented in an organization. Both types of knowledge are crucial for knowledge sharing within any organization as both are primary factors to boost innovation capability. Knowledge sharing process requires an enabler in its process. This research studies Small and Medium Industries (SMI), where knowledge sharing between one SMI to another is necessary, which enables a group of SMIs within a certain area to grow altogether. This research aims to analyze how the innovation capability of a company is influenced by knowledge sharing with the perspective of both tacit and explicit knowledge. The result shows that each indicator in every construct has a good validity, reliability, and significance level, which evidently suggests that a company's capacity to share knowledge, both tacitly and explicitly, is indeed significant and influential towards the innovation capability of such company in this case, SMI. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Defense behavior of real time strategy games: Comparison between HFSM and FSM"
        ],
        "penulis":"Fauzi, Rahmat;Hariadi, Mochamad;Nugroho, Supeno Mardi Susiki;Lubis, Muharman;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "RTS Game is one of the popular genre in PC gaming, which has been played by various type of players frequently. In RTS game, NPC Defense Building (Tower) has attacking behavior to the closest enemy without considering certain enemy parameters. This causes the NPC Tower to be more predictable by the opponent and easily defeated if NPC attacked by enemies in the group. Thus, this research simulates NPC Tower using Hierarchical Finite State Machine (HFSM) method compared with Finite State Machine (FSM). In this study, NPC Tower detects enemies by seeing at four parameters namely NPC Tower Health, Enemy's Health, Enemy Type, and Tower Distance to enemies. NPC Tower will attack the most dangerous enemy according to the \u2018Degree of Danger\u2019 parameter. Then use the decision-making logic of the rule-based system. The output of NPC Tower are three type of behaviors namely Aggressive Attacking, Regular Attacking, and Attack with Special Skill. From the test results of 3 NPC Tower, Kamandaka NPC Tower with HFSM method is winning 8.92% compare to Kamandaka Tower with FSM method. For Gayatri Tower NPC obtained equal results using both HFSM and FSM. Meanwhile, Adikara NPC with HFSM method is 4.62% superior to Adikara Tower with FSM method. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "RTS Game is one of the popular genre in PC gaming, which has been played by various type of players frequently. In RTS game, NPC Defense Building (Tower) has attacking behavior to the closest enemy without considering certain enemy parameters. This causes the NPC Tower to be more predictable by the opponent and easily defeated if NPC attacked by enemies in the group. Thus, this research simulates NPC Tower using Hierarchical Finite State Machine (HFSM) method compared with Finite State Machine (FSM). In this study, NPC Tower detects enemies by seeing at four parameters namely NPC Tower Health, Enemy's Health, Enemy Type, and Tower Distance to enemies. NPC Tower will attack the most dangerous enemy according to the \u2018Degree of Danger\u2019 parameter. Then use the decision-making logic of the rule-based system. The output of NPC Tower are three type of behaviors namely Aggressive Attacking, Regular Attacking, and Attack with Special Skill. From the test results of 3 NPC Tower, Kamandaka NPC Tower with HFSM method is winning 8.92% compare to Kamandaka Tower with FSM method. For Gayatri Tower NPC obtained equal results using both HFSM and FSM. Meanwhile, Adikara NPC with HFSM method is 4.62% superior to Adikara Tower with FSM method. \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Potential detection of lentigo maligna melanoma on solar lentigines image based on android"
        ],
        "penulis":"Bimastro, Kurnia Zikir;Purboyo, Tito Waluyo;Setianingsih, Casi;Murti, Muhammad Ary;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Solar Lentigines is a skin disease caused by frequent exposure to direct sunlight. Appearance in solar lentigines can resemble Lentigo Malignant Melanoma cancer at an early stage. solar lentigines a disease that is not dangerous and does not require special treatment, but if there are significant changes such as asymmetrical wounds, obscure borders, non-homogeneous colors, diameters exceeding 6 millimeters, solar lentigines are suspected as lentigo malignant early stage melanoma. lentigo malignant melanoma is a rare but dangerous type of skin cancer if it is not treated immediately with asymmetrical, unclear boundaries, non-homogeneous colors, diameters exceeding 6 millimeters. This research aims to help detect the potential of lentigo malignant melanoma disease by using the image of solar lentigines. This application uses the ABCD method for feature extraction to scratch the input image and decision tree for classification. ABCD method is a medical method used to detect cancer in terms of asymmetry, obscure borders, color, diameter. The data of this research were obtained from one hospital in Bandung and the data was presented in table form and explained informally. The result of the application is a diagnosis of the potential for disease. The accuracy value of this application is 97.5% from 60 training data. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Solar Lentigines is a skin disease caused by frequent exposure to direct sunlight. Appearance in solar lentigines can resemble Lentigo Malignant Melanoma cancer at an early stage. solar lentigines a disease that is not dangerous and does not require special treatment, but if there are significant changes such as asymmetrical wounds, obscure borders, non-homogeneous colors, diameters exceeding 6 millimeters, solar lentigines are suspected as lentigo malignant early stage melanoma. lentigo malignant melanoma is a rare but dangerous type of skin cancer if it is not treated immediately with asymmetrical, unclear boundaries, non-homogeneous colors, diameters exceeding 6 millimeters. This research aims to help detect the potential of lentigo malignant melanoma disease by using the image of solar lentigines. This application uses the ABCD method for feature extraction to scratch the input image and decision tree for classification. ABCD method is a medical method used to detect cancer in terms of asymmetry, obscure borders, color, diameter. The data of this research were obtained from one hospital in Bandung and the data was presented in table form and explained informally. The result of the application is a diagnosis of the potential for disease. The accuracy value of this application is 97.5% from 60 training data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Quranic Latin query correction as a search suggestion"
        ],
        "penulis":"Satriady, Wildhan;Bijaksana, Moch Arif;Lhaksmana, Kemas M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research proposes a method to help correct typo errors, such as wrong letters, missing letters, and additional letters. To date, the Lafzi search system is an example of an effective application for searching Arabic queries based on sound similarity. The Lafzi application helps correct typos due to the sound of Arabic letters that are almost the same as the pronunciation but not correct errors due to typos. Typos could prevent the search system not to display the desired results. This research proposes a solution by employing auto-complete to equipped missing trigram and the edit distance metric to calculate the differentiation value between the corrected query with the initial query. The way the system works is by separating and sorting trigram tokens from queries (user inputs) based on the verse. Each verse that has a missing trigram token will be equipped and re-transformed into a corrected query. Each corrected query will be compared to the edit distance value against the initial query (input from the user), then a corrected query will be taken which has the smallest edit distance value and will be made as a suggested query. The evaluation shows that the proposed method produces the highest recall value at 93.40% and the highest MAP value at 86%. This outperforms the previous Lafzi system approach which achieves recall at 85.23% and MAP at 79.83%. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research proposes a method to help correct typo errors, such as wrong letters, missing letters, and additional letters. To date, the Lafzi search system is an example of an effective application for searching Arabic queries based on sound similarity. The Lafzi application helps correct typos due to the sound of Arabic letters that are almost the same as the pronunciation but not correct errors due to typos. Typos could prevent the search system not to display the desired results. This research proposes a solution by employing auto-complete to equipped missing trigram and the edit distance metric to calculate the differentiation value between the corrected query with the initial query. The way the system works is by separating and sorting trigram tokens from queries (user inputs) based on the verse. Each verse that has a missing trigram token will be equipped and re-transformed into a corrected query. Each corrected query will be compared to the edit distance value against the initial query (input from the user), then a corrected query will be taken which has the smallest edit distance value and will be made as a suggested query. The evaluation shows that the proposed method produces the highest recall value at 93.40% and the highest MAP value at 86%. This outperforms the previous Lafzi system approach which achieves recall at 85.23% and MAP at 79.83%. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "The implication of business partnership, company asset and strategic innovation to business valuation of digital industry in Indonesia"
        ],
        "penulis":"Witjara, Edi;Nidar, Sulaeman R.;Herwany, Aldrin;Santosa, Setyanto P.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "It was predicted that between 2013-2020 the revenue growth of global operator especially voice and data services would be decline. However, there will be an increase in automated (Non-Human intervention) data services and digital service (content, video, ecommerce, etc.). It also predicted that the presence of digital product in Telco will be able to recover negative revenue growth become positive one. Nevertheless, the business valuation of the digital companies is fluctuating within the last nine years due to the volatility caused by several factors. The poor valuation of digital industry is allegedly due to the implementation of strategic innovation has not been completely implemented. It is associated with problems in the development of the company's assets and business partnership that has been initiated. This study aims to assess the influence of company assets and business partnership on strategic innovation and its implications on the business valuation of digital industry in Indonesia. The study uses a quantitative approach with the analysis unit is digital companies in Indonesia. We are using 200 respondents that comprise of various strategic position personal of digital companies and processed the analysis by using simple random sampling technique. The results of the study has pointed out that strategic innovation has a greatest effect on business valuation. Strategic Innovation is mostly affected by company asset rather than business partnership. Company asset and business partnership effect on business valuation both directly and indirectly through Strategic Innovation. \u00a9 2019 Allied Academies.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "It was predicted that between 2013-2020 the revenue growth of global operator especially voice and data services would be decline. However, there will be an increase in automated (Non-Human intervention) data services and digital service (content, video, ecommerce, etc.). It also predicted that the presence of digital product in Telco will be able to recover negative revenue growth become positive one. Nevertheless, the business valuation of the digital companies is fluctuating within the last nine years due to the volatility caused by several factors. The poor valuation of digital industry is allegedly due to the implementation of strategic innovation has not been completely implemented. It is associated with problems in the development of the company's assets and business partnership that has been initiated. This study aims to assess the influence of company assets and business partnership on strategic innovation and its implications on the business valuation of digital industry in Indonesia. The study uses a quantitative approach with the analysis unit is digital companies in Indonesia. We are using 200 respondents that comprise of various strategic position personal of digital companies and processed the analysis by using simple random sampling technique. The results of the study has pointed out that strategic innovation has a greatest effect on business valuation. Strategic Innovation is mostly affected by company asset rather than business partnership. Company asset and business partnership effect on business valuation both directly and indirectly through Strategic Innovation. \u00a9 2019 Allied Academies."
        ]
    },
    {
        "judul":[
            "Smart Lamp Control Based on User Behavior for Two Lamps Using K-Nearest Neighbour"
        ],
        "penulis":"Nugroho, Triono;Nasrun, Muhammad;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The number of housing needs each year increases. And these problems have an impact on the use of electricity every year. This condition results in the expense of excess electricity. To anticipate electricity energy savings, management of electronic devices is needed. With the existence of modern technology, the concept of home itself is starting to be integrated with the automation system, one of which is a smart home. In this study an automation system will be created to record user behavior in using electronic devices. By using the K-Nearest Neighbor classification method, data on user behavior recorded will be used as a set of information processed by the system to make predictions on a device. So that the automation system can work according to user behavior. The results of system performance testing in classifying data produce an average accuracy of 97.62% for lamp one, and 98.36% for lamp two. These results are predictive results that are not necessarily accurate according to the actual conditions, due to different user behavior.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The number of housing needs each year increases. And these problems have an impact on the use of electricity every year. This condition results in the expense of excess electricity. To anticipate electricity energy savings, management of electronic devices is needed. With the existence of modern technology, the concept of home itself is starting to be integrated with the automation system, one of which is a smart home. In this study an automation system will be created to record user behavior in using electronic devices. By using the K-Nearest Neighbor classification method, data on user behavior recorded will be used as a set of information processed by the system to make predictions on a device. So that the automation system can work according to user behavior. The results of system performance testing in classifying data produce an average accuracy of 97.62% for lamp one, and 98.36% for lamp two. These results are predictive results that are not necessarily accurate according to the actual conditions, due to different user behavior.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Optimized bio-inspired kernels with twin support vector machine using low identity sequences to solve imbalance multiclass classification"
        ],
        "penulis":"Guramand S.K.;Saedudin R.D.R.;Hassan R.;Kasim S.;Ramlan R.;Salim B.W.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The function of enzymes is performed differently depending on their bio-chemical mechanisms and important to the prediction of protein structure and function. In order to overcome the weaknesses of imbalance data distribution in subclasses prediction we proposed Bio-Twin Support Vector Machine (Bio-TWSVM). The TWSVM approach as also allow for kernel optimization where in this study we have introduced the bio-inspired kernels such as the Fisher, spectrum and mismatch kernels which at the same time incorporate the biological information regarding the protein evolution in the classification process. \u00a9 2019 Triveni Enterprises.",
            "OView detailsExpand Substance diphenylcyclopropenone",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The function of enzymes is performed differently depending on their bio-chemical mechanisms and important to the prediction of protein structure and function. In order to overcome the weaknesses of imbalance data distribution in subclasses prediction we proposed Bio-Twin Support Vector Machine (Bio-TWSVM). The TWSVM approach as also allow for kernel optimization where in this study we have introduced the bio-inspired kernels such as the Fisher, spectrum and mismatch kernels which at the same time incorporate the biological information regarding the protein evolution in the classification process. \u00a9 2019 Triveni Enterprises."
        ]
    },
    {
        "judul":[
            "People entity recognition in Indonesian quran translation with conditional random field approach"
        ],
        "penulis":"Arvianto, Farhan Dzaky;Bijaksana, Moch Arif;Huda, Arief Fatchul;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The Quran is the primary source of law for Muslims. Quran has a total of 30 juzs, divided into 144 surahs and arranged of 6,236 verses and in the Quran discuss different topics and have many entities too, so someone sometimes has difficulty understanding the Quran. To make it easier to understand the Quran, we can get identification of essential entities in the Quran such as names of the people in the Quran. One way to do it is by extracting information on essential entities in Quran is with Named Entity Recognition (NER). NER automatically recognizes essential entities such as the people's names at the Quran. This paper builds a system for identifying the entity of the people in the Quran using CRF techniques with a multiple choice approach where the system will be introduced with a range of possibilities from the entity and adjusted to an input given to be able to detect entities. On system developing for identifying the entity of the people in Quran with Indonesian Quran translation dataset shows, this test produces an average performance of using the F1 generated at 0.77 for the use of training data as many as 36814 data from 954 verses in the Quran. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Quran is the primary source of law for Muslims. Quran has a total of 30 juzs, divided into 144 surahs and arranged of 6,236 verses and in the Quran discuss different topics and have many entities too, so someone sometimes has difficulty understanding the Quran. To make it easier to understand the Quran, we can get identification of essential entities in the Quran such as names of the people in the Quran. One way to do it is by extracting information on essential entities in Quran is with Named Entity Recognition (NER). NER automatically recognizes essential entities such as the people's names at the Quran. This paper builds a system for identifying the entity of the people in the Quran using CRF techniques with a multiple choice approach where the system will be introduced with a range of possibilities from the entity and adjusted to an input given to be able to detect entities. On system developing for identifying the entity of the people in Quran with Indonesian Quran translation dataset shows, this test produces an average performance of using the F1 generated at 0.77 for the use of training data as many as 36814 data from 954 verses in the Quran. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Model for accelerating discharge of lane traffic to facilitate intersection access by EVs"
        ],
        "penulis":"Sumaryo, Sony;Halim, Abdul;Ramli, Kalamullah;Joelianto, Endra;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Intelligent Transportation System (ITS) is the synergy of information technology, real-time control, and communication networks. The system is expected to perform more complex traffic arrangements, in particular, traffic management of Emergency Vehicles (EV) such as fire trucks, ambulances, and so forth. Implementation of traffic management using only Traffic Signal Pre-emption does not give enough space for an EV to cross an intersection safely, especially on streets where there is only one lane. This paper proposes a model of accelerated emptying of traffic in front of EVs. Accelerated emptying model uses historical approach, based on current characteristics of traffic. For example, if the normal vehicle speed is equal to the EV speed before accelerated emptying, the system indicator will be 0%, thereby indicating no need for accelerated emptying. Similarly, a negative system indicator result means an accelerated emptying process is not necessary. However, if the system indicator is close to 100%, this result indicates accelerated emptying is necessary. \u00a9 IJTech 2019.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Intelligent Transportation System (ITS) is the synergy of information technology, real-time control, and communication networks. The system is expected to perform more complex traffic arrangements, in particular, traffic management of Emergency Vehicles (EV) such as fire trucks, ambulances, and so forth. Implementation of traffic management using only Traffic Signal Pre-emption does not give enough space for an EV to cross an intersection safely, especially on streets where there is only one lane. This paper proposes a model of accelerated emptying of traffic in front of EVs. Accelerated emptying model uses historical approach, based on current characteristics of traffic. For example, if the normal vehicle speed is equal to the EV speed before accelerated emptying, the system indicator will be 0%, thereby indicating no need for accelerated emptying. Similarly, a negative system indicator result means an accelerated emptying process is not necessary. However, if the system indicator is close to 100%, this result indicates accelerated emptying is necessary. \u00a9 IJTech 2019."
        ]
    },
    {
        "judul":[
            "Constructing the ideal SRI (sustainability reporting index) framework for Indonesian market: combined perspectives from rating agencies, academics, and practitioners"
        ],
        "penulis":"Firmialy, Sita deliyana;Nainggolan, Yunieta Anny;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Purpose: This study aims to focus on developing the sustainability reporting index (SRI) with combined perspectives from varied social rating agencies, along with integrated combined perspectives from academics experts and Indonesian companies. Design\/methodology\/approach: The first section discusses the theoretical framework along with the sustainability challenges faced by companies in Indonesia. The second section develops the methodology of the study to measure the SRI by considering practical and theoretical perspectives, starting from the identification of initial disclosure, selecting the final disclosure and developing the hierarchical framework. Lastly, the third section confirms the validity of the study\u2019s framework by the exploratory factor analysis method and its comparability by comparing the content analysis result of the study with the Kinder\u2013Lydenberg\u2013Domini (KLD) method. The content analysis was used to analyze annual reports, sustainability reports and companies\u2019 websites based on indicators found in the resulted model. Findings: The main finding is the SRI framework (SRIF) of the study, which is built on the basis of the stakeholder relationship theory and is focused on three main dimensions (social, economic and environmental). Specifically, the framework consists of 17 indicators and 93 sub-indicators. On the basis of factor analysis method, it can be safely said that the study\u2019s SRIF is quite valid. The high score of correlations between the SRIF and KLD results at the composite and dimension levels, along with the statistically significant results show that the study\u2019s SRIF results and KLD results are fairly similar. Research limitations\/implications: The present study has its limitation as it only gathers data from publicly available reports issued by the firms (secondary data). Owing to time limitation, primary data are not collected. However, this is also the strength of this research as it will allow investors to replicate the study\u2019s methodology to measure companies\u2019 sustainability. Practical implications: The study is useful to organizations and statutory bodies toward finding a replicable method to measure the Indonesian companies\u2019 social performance. In addition, the study also introduced the usefulness of the qualitative program Atlas TI to perform content analysis, the exploratory factor analysis method to ensure validity and comparability by comparing it to the KLD methodology, which is known globally as the most widely accepted methodology to measures social performance. Lastly, this study will provide implications to the Government to ascertain the level of SRI reporting among the Indonesian public-listed companies. Originality\/value: The resulted framework in this study simultaneously considers social, environmental and economic factors in the context of companies in Indonesia, while previous researchers have constructed reporting index separately (i.e. Sumiani et al., 2007; Zhao et al., 2012). Especially in the context of Indonesia, there is no such index simultaneously focused on the three main dimensions, namely, social, environmental and economics. The current study tries to fill the gap by using the constructed SRI index based on three perspectives combined, namely, social rating agencies, academic theorist and Indonesian companies. \u00a9 2018, Emerald Publishing Limited.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: This study aims to focus on developing the sustainability reporting index (SRI) with combined perspectives from varied social rating agencies, along with integrated combined perspectives from academics experts and Indonesian companies. Design\/methodology\/approach: The first section discusses the theoretical framework along with the sustainability challenges faced by companies in Indonesia. The second section develops the methodology of the study to measure the SRI by considering practical and theoretical perspectives, starting from the identification of initial disclosure, selecting the final disclosure and developing the hierarchical framework. Lastly, the third section confirms the validity of the study\u2019s framework by the exploratory factor analysis method and its comparability by comparing the content analysis result of the study with the Kinder\u2013Lydenberg\u2013Domini (KLD) method. The content analysis was used to analyze annual reports, sustainability reports and companies\u2019 websites based on indicators found in the resulted model. Findings: The main finding is the SRI framework (SRIF) of the study, which is built on the basis of the stakeholder relationship theory and is focused on three main dimensions (social, economic and environmental). Specifically, the framework consists of 17 indicators and 93 sub-indicators. On the basis of factor analysis method, it can be safely said that the study\u2019s SRIF is quite valid. The high score of correlations between the SRIF and KLD results at the composite and dimension levels, along with the statistically significant results show that the study\u2019s SRIF results and KLD results are fairly similar. Research limitations\/implications: The present study has its limitation as it only gathers data from publicly available reports issued by the firms (secondary data). Owing to time limitation, primary data are not collected. However, this is also the strength of this research as it will allow investors to replicate the study\u2019s methodology to measure companies\u2019 sustainability. Practical implications: The study is useful to organizations and statutory bodies toward finding a replicable method to measure the Indonesian companies\u2019 social performance. In addition, the study also introduced the usefulness of the qualitative program Atlas TI to perform content analysis, the exploratory factor analysis method to ensure validity and comparability by comparing it to the KLD methodology, which is known globally as the most widely accepted methodology to measures social performance. Lastly, this study will provide implications to the Government to ascertain the level of SRI reporting among the Indonesian public-listed companies. Originality\/value: The resulted framework in this study simultaneously considers social, environmental and economic factors in the context of companies in Indonesia, while previous researchers have constructed reporting index separately (i.e. Sumiani et al., 2007; Zhao et al., 2012). Especially in the context of Indonesia, there is no such index simultaneously focused on the three main dimensions, namely, social, environmental and economics. The current study tries to fill the gap by using the constructed SRI index based on three perspectives combined, namely, social rating agencies, academic theorist and Indonesian companies. \u00a9 2018, Emerald Publishing Limited."
        ]
    },
    {
        "judul":[
            "Implementation of python source code comparison results with Java using bubble sort method"
        ],
        "penulis":"Insanudin E.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the implementation of Python and Java source code comparison results are more focused on the scale of the ratio of the number of lines of code, file capacity, and access speed. As for the background of this writing because there are so many programming languages that can be used with the same results but overall we do not know which programming language is more optimal and efficient in terms of the number of lines of code better known in the programming language is LOC (Line of Code) capacity of file access speed. In this study, the authors focus only on Java programming language and python course as a first step to know the ratio of the number of lines of code, file capacity, and access density. To determine the comparison there is a method used is bubble short. The results of the implementation of the comparison of these programming languages for Python programming language to produce the number of LOC (line of code) or the number of lines of code as much as 10, the capacity of the file extension.py by 506 bytes and txt extension of 397 bytes and access speed approximately for less more 4 seconds. While Java produces the number of LOC (line of code) or the number of lines of code as much as 11, the capacity of the file extension. Java of 86.2 Kbytes and extension txt of 477 bytes and access speed for 7 seconds. So do not close the possibility to make other applications python programming language will be more optimal and efficient. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the implementation of Python and Java source code comparison results are more focused on the scale of the ratio of the number of lines of code, file capacity, and access speed. As for the background of this writing because there are so many programming languages that can be used with the same results but overall we do not know which programming language is more optimal and efficient in terms of the number of lines of code better known in the programming language is LOC (Line of Code) capacity of file access speed. In this study, the authors focus only on Java programming language and python course as a first step to know the ratio of the number of lines of code, file capacity, and access density. To determine the comparison there is a method used is bubble short. The results of the implementation of the comparison of these programming languages for Python programming language to produce the number of LOC (line of code) or the number of lines of code as much as 10, the capacity of the file extension.py by 506 bytes and txt extension of 397 bytes and access speed approximately for less more 4 seconds. While Java produces the number of LOC (line of code) or the number of lines of code as much as 11, the capacity of the file extension. Java of 86.2 Kbytes and extension txt of 477 bytes and access speed for 7 seconds. So do not close the possibility to make other applications python programming language will be more optimal and efficient. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Evaluate number of LED on reflector room for optical wireless communication"
        ],
        "penulis":"Ramadhanti, Dyndra Anindita;Sujatmoko, Kris;Pamukti, Brian;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Optical fiber communication system is the most implemented technology for backbone and access network telecommunication. However, the mobility of users has forced technology wired to wireless technology and one of the newest research is Optical Wireless Communication (OWC). The OWC has no longer using fiber optic as propagation media and using air for its transmission. In this paper, we evaluate number of Light Emitting Diode (LED) with comparison for one and two transmitters towards light communication distribution in a 5 m \u00d7 5 m \u00d7 4 m on closed room with reflector. We also use reflector mirror in the wall and using On Off Keying-Non Return to Zero (OOK-NRZ) as a modulation system. In addition, we evaluate wall reflector for impact of communication coverage area. From computer simulation, the results show that two LEDs used with reflector has 29.9 % larger coverage area than one LED. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Optical fiber communication system is the most implemented technology for backbone and access network telecommunication. However, the mobility of users has forced technology wired to wireless technology and one of the newest research is Optical Wireless Communication (OWC). The OWC has no longer using fiber optic as propagation media and using air for its transmission. In this paper, we evaluate number of Light Emitting Diode (LED) with comparison for one and two transmitters towards light communication distribution in a 5 m \u00d7 5 m \u00d7 4 m on closed room with reflector. We also use reflector mirror in the wall and using On Off Keying-Non Return to Zero (OOK-NRZ) as a modulation system. In addition, we evaluate wall reflector for impact of communication coverage area. From computer simulation, the results show that two LEDs used with reflector has 29.9 % larger coverage area than one LED. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Noise Removal in Mild Cognitive Impairment EEG Recording using Empirical Mode Decomposition"
        ],
        "penulis":"Hadiyoso, Sugondo;Wijayanto, Inung;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "EEG signals contain large amounts of random noise, such as artifacts and baseline changes. These noises appear at low frequencies, which may disturb the real activity of the EEG signal. Visual observation method often used to mark then removing the noise. However, this conventional method takes much time, requires experts to do the annotation, and has a huge possibility of error. One method that can be used to remove this interference is Empirical Mode Decomposition (EMD). EMD produces two essential parts of the signal, namely intrinsic mode function (IMF) and residue. This study applies EMD to remove artifacts that are present in EEG signals. The performance measured by calculating the RMSE and spectral power. From the test, obtained the average value of RMSE 0.0295 and signal power at frequencies below 1 Hz is 0.004 dB. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "EEG signals contain large amounts of random noise, such as artifacts and baseline changes. These noises appear at low frequencies, which may disturb the real activity of the EEG signal. Visual observation method often used to mark then removing the noise. However, this conventional method takes much time, requires experts to do the annotation, and has a huge possibility of error. One method that can be used to remove this interference is Empirical Mode Decomposition (EMD). EMD produces two essential parts of the signal, namely intrinsic mode function (IMF) and residue. This study applies EMD to remove artifacts that are present in EEG signals. The performance measured by calculating the RMSE and spectral power. From the test, obtained the average value of RMSE 0.0295 and signal power at frequencies below 1 Hz is 0.004 dB. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Developing Wood Identification System by Local Binary Pattern and Hough Transform Method"
        ],
        "penulis":"Hadiwidjaja, M. Luthfi;Gunawan P.H.;Prakasa, Esa;Rianto, Yan;Sugiarto, Bambang;Wardoyo, Riyo;Damayanti, Ratih;Sugiyanto, Krisdianto;Dewi, L. Mustika;Astutiputri, Vidya Fatimah;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The aim of this paper is to develop the wood identification system using two methods, called, Local Binary Pattern (LBP) and Hough Transform (HT). Here, 12 (twelve) varies of wood species form Indonesia will be used as the data sets. The wood species are taken from wood anatomy laboratory, Puslitbang Hasil Hutan (P3HH). Here, the classification method of this research uses Euclidean Distance (ED) to determine the distance of two images of wood. From the classification results, using LBP method is shown better than HT. The weakness of HT method in this paper is HT method can only detecting the circle shape rather than arbitrary shape. By using LBP method, 6 of 12 species are 100% accurate detected. Beside, using HT method, only one species (Cratoxylon formosum) has accuracy 90%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aim of this paper is to develop the wood identification system using two methods, called, Local Binary Pattern (LBP) and Hough Transform (HT). Here, 12 (twelve) varies of wood species form Indonesia will be used as the data sets. The wood species are taken from wood anatomy laboratory, Puslitbang Hasil Hutan (P3HH). Here, the classification method of this research uses Euclidean Distance (ED) to determine the distance of two images of wood. From the classification results, using LBP method is shown better than HT. The weakness of HT method in this paper is HT method can only detecting the circle shape rather than arbitrary shape. By using LBP method, 6 of 12 species are 100% accurate detected. Beside, using HT method, only one species (Cratoxylon formosum) has accuracy 90%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The hard c-means algorithm for clustering Indonesian plantation commodity based on metabolites composition"
        ],
        "penulis":"Rustam;Gunawan A.Y.;Kresnowati M.T.A.P.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Indonesia is the second largest biodiversity country in the world. Indonesia has a variety of top agricultural and plantation commodities, whereas each commodity has premium products which are normally related to its specific character\/flavour and are generally associated with the producing origins. Specific character\/flavour is represented by composition of metabolites each origin. To find out the specific character\/flavour in various Indonesian plantation commodities, clustering is needed. In this paper, we perform clustering on an Indonesian plantation commodity based on their metabolites composition. Metabolite compositions of samples of some origins of the commodity are clustered using the Hard C-Means algorithm with the Xie-Beni index as the cluster validity. Our present results confirm that each origin has a unique characteristic and belongs to a separate cluster. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is the second largest biodiversity country in the world. Indonesia has a variety of top agricultural and plantation commodities, whereas each commodity has premium products which are normally related to its specific character\/flavour and are generally associated with the producing origins. Specific character\/flavour is represented by composition of metabolites each origin. To find out the specific character\/flavour in various Indonesian plantation commodities, clustering is needed. In this paper, we perform clustering on an Indonesian plantation commodity based on their metabolites composition. Metabolite compositions of samples of some origins of the commodity are clustered using the Hard C-Means algorithm with the Xie-Beni index as the cluster validity. Our present results confirm that each origin has a unique characteristic and belongs to a separate cluster. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Design of IoT-based river water monitoring robot data transmission model using low power wide area network (LPWAN) communication technology"
        ],
        "penulis":"Lestari, Rahayu Dwi;Rusdinar, Angga;Murti, Muhammad Ary;Tawaqal, Gilang;Lee, Dongho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "River water monitoring system is one of the efforts as a contribution to control the pollution and\/or damage of the Citarum watershed in Indonesia based on Presidential Decree Number 15 of 2018. Monitoring of Citarum River water quality is essential because it is to know its condition. Despite that, regular monitoring requires water samples to be taken to the laboratory to be tested. Therefore it is not real-time and wasteful of energy. In this paper, a design of IoT-based river water quality monitoring-system using LPWAN communication technology will be proposed so that monitoring points on the Citarum watershed can be monitored in real-time and the results of monitoring data will be stored in the server for data logging. A test about communication range is performed with four nodes and one gateway with LoRa transceiver paired with Arduino boards, as LPWAN communication method, to be able to exchange information in terms of hardware and implement network mesh topologies to widen monitoring points in terms of software. It is shown from the test result that the communication range for the transmission between node to node or node to gateway reaches a maximum of 500 m close on the surface of the water. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentClean water and sanitationGoal 6Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "River water monitoring system is one of the efforts as a contribution to control the pollution and\/or damage of the Citarum watershed in Indonesia based on Presidential Decree Number 15 of 2018. Monitoring of Citarum River water quality is essential because it is to know its condition. Despite that, regular monitoring requires water samples to be taken to the laboratory to be tested. Therefore it is not real-time and wasteful of energy. In this paper, a design of IoT-based river water quality monitoring-system using LPWAN communication technology will be proposed so that monitoring points on the Citarum watershed can be monitored in real-time and the results of monitoring data will be stored in the server for data logging. A test about communication range is performed with four nodes and one gateway with LoRa transceiver paired with Arduino boards, as LPWAN communication method, to be able to exchange information in terms of hardware and implement network mesh topologies to widen monitoring points in terms of software. It is shown from the test result that the communication range for the transmission between node to node or node to gateway reaches a maximum of 500 m close on the surface of the water. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis LTE Picocell Design in Tamansari Parama Office Building PT Wika Realty"
        ],
        "penulis":"Hidayat, Aulia;Sujatmoko, Kris;Usman, Uke Kurniawan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Internet services with realtime Broadband Wireless Access technology such as freecall, instant messages, social media, video calls and so on nowadays are a common thing. But sometimes the signal is weak or the receiving power level is lacking which causes the maximum use of services. Tamansari Parama is an office building from PT WIKA which also serves for leasing other company offices. Employees and guests in the area complained about the problem of poor signal quality because the structure of the building dampened the signal from the outdoor site. So it is necessary to plan a picocell network in the Tamansari Parama building. Lack of signal strength in a place can be overcome by capacity planning and coverage planning as appropriate, such as using a picocell antenna. Planning results obtained RSRP value for basement floor which is equal to -74,67 dBm, 1st and mezzanine floors amounting to -73,12 dBm, 2nd to 5th floor of -73,70 dBm, and 6th to 16th floor which is equal to - 70,91 dBm. For SIR values on the basement floor are 8,90 dB, 1st floor and mezzanine is 10,88 dB, floors 2 to 5 are 38.96 dB, and floors 6 to 16 are 12.70 dB. From the simulation results, it meets the Key Performance Indicator (KPI). (Abstract) \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet services with realtime Broadband Wireless Access technology such as freecall, instant messages, social media, video calls and so on nowadays are a common thing. But sometimes the signal is weak or the receiving power level is lacking which causes the maximum use of services. Tamansari Parama is an office building from PT WIKA which also serves for leasing other company offices. Employees and guests in the area complained about the problem of poor signal quality because the structure of the building dampened the signal from the outdoor site. So it is necessary to plan a picocell network in the Tamansari Parama building. Lack of signal strength in a place can be overcome by capacity planning and coverage planning as appropriate, such as using a picocell antenna. Planning results obtained RSRP value for basement floor which is equal to -74,67 dBm, 1st and mezzanine floors amounting to -73,12 dBm, 2nd to 5th floor of -73,70 dBm, and 6th to 16th floor which is equal to - 70,91 dBm. For SIR values on the basement floor are 8,90 dB, 1st floor and mezzanine is 10,88 dB, floors 2 to 5 are 38.96 dB, and floors 6 to 16 are 12.70 dB. From the simulation results, it meets the Key Performance Indicator (KPI). (Abstract) \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Why do enterprises adopt natural language processing services? startups' landscape and opportunities in artificial intelligence"
        ],
        "penulis":"Ruliputra, Ricky Nauvaldy;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The large number of internet users in Indonesia contributes to Indonesia's growth potential in general in the digital economy. This rapid growth urged the government to plan for the industrial 4.0 revolution with artificial intelligence (AI) technology as its basis. Innovations in the field of AI come from many startup companies. Despite many benefits, only 40 percent companies in Asia-Pacific utilized the AI technology in functional areas, such as chatbot services and customer service robots. This gap needs to be addressed considering that more than 87 percent of internet users in Indonesia utilize chat services and social media. AI utilization can be implemented by using the services of companies engaged in AI, including startups. However, AI-based startups in Indonesia are not yet mapped. Furthermore, practical impact of AI implementation needs to be surveyed as knowledge to implement AI in business. This research mapped 68 Indonesian startups of AI service providers. In addition, this study evaluates the implementation of AI in the Natural Language Processing (NLP) category for companies from the perspective of the service provider. Of all 8 mapped NLP service providers, 4 of them are chosen as the research objects. The impacts of its implementation are categorized into eight categories: motivation, profit, interest, change in strategy, competition, satisfaction, trust, and ethics. Recommendations are given to companies related to NLP with the most important things which are defining purposes and dare to try. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The large number of internet users in Indonesia contributes to Indonesia's growth potential in general in the digital economy. This rapid growth urged the government to plan for the industrial 4.0 revolution with artificial intelligence (AI) technology as its basis. Innovations in the field of AI come from many startup companies. Despite many benefits, only 40 percent companies in Asia-Pacific utilized the AI technology in functional areas, such as chatbot services and customer service robots. This gap needs to be addressed considering that more than 87 percent of internet users in Indonesia utilize chat services and social media. AI utilization can be implemented by using the services of companies engaged in AI, including startups. However, AI-based startups in Indonesia are not yet mapped. Furthermore, practical impact of AI implementation needs to be surveyed as knowledge to implement AI in business. This research mapped 68 Indonesian startups of AI service providers. In addition, this study evaluates the implementation of AI in the Natural Language Processing (NLP) category for companies from the perspective of the service provider. Of all 8 mapped NLP service providers, 4 of them are chosen as the research objects. The impacts of its implementation are categorized into eight categories: motivation, profit, interest, change in strategy, competition, satisfaction, trust, and ethics. Recommendations are given to companies related to NLP with the most important things which are defining purposes and dare to try. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Developing a Complete Dialogue System Using Long Short-Term Memory"
        ],
        "penulis":"Bunga, Muhammad Husain Toding;Suyanto, Suyanto;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "As technologies of natural language understanding and generation improve, the human interest towards human-computer interaction increases. The technologies can be applied for various applications of customer services. Most works related to this field are emphasizing on single sentence and speaker turn. Meanwhile, a conversation sometimes has its own context according to the previous one. Designing this kind of conversational system is challenging. Most conversational agents are built based on knowledge-based and rule based systems. This paper discusses a development of a complete dialogue system to understand the intent of a text and give response based on the dialogue state. The dialogue model is implemented using the combination of rule-based and data-driven approach by utilizing a long short-Term memory (LSTM). Some experiments show that the developed system give a high performance. A detail observation informs that some errors come from the intent classifier that fails to classify some sentences not in the corpus. This system can be improved by increasing the performance of the intent classifier and incorporating an additional named entity recognition module. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "As technologies of natural language understanding and generation improve, the human interest towards human-computer interaction increases. The technologies can be applied for various applications of customer services. Most works related to this field are emphasizing on single sentence and speaker turn. Meanwhile, a conversation sometimes has its own context according to the previous one. Designing this kind of conversational system is challenging. Most conversational agents are built based on knowledge-based and rule based systems. This paper discusses a development of a complete dialogue system to understand the intent of a text and give response based on the dialogue state. The dialogue model is implemented using the combination of rule-based and data-driven approach by utilizing a long short-Term memory (LSTM). Some experiments show that the developed system give a high performance. A detail observation informs that some errors come from the intent classifier that fails to classify some sentences not in the corpus. This system can be improved by increasing the performance of the intent classifier and incorporating an additional named entity recognition module. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Sense of presence and learning satisfaction among students of different age groups in a 3-D virtual world"
        ],
        "penulis":"Rahman, Mohd Hishamuddin Abdul;Phon, Danakorn Nincarean Eh;Utama, Nur Ichsan;Yahaya, Noraffandy;Halim, Noor Dayana Abd;Kasim, Shahreen;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Virtual worlds are growing in popularity very quickly. This growing popularity of 3-dimensional (3-D) virtual worlds has drawn attention from educationists. Today, 3-dimensional (3-D) virtual worlds are exploited for online and virtual learning. Unlike the common online learning platforms, a virtual world environment closely resembles a 3-D video games environment. Thus the age of students might affect their sense of presence, interaction, and satisfaction in the said environment. Hence this study was conducted to investigate whether there are differences between students of different age groups on their sense of presence (place presence, social presence, and co-presence) and their learning satisfaction. The study was carried out for six weeks and involved 33 part-time diploma students with the use of interview and questionnaires as instruments. In this study, the researcher developed our own 3-D virtual world, known as ViEW, by using the Open Wonderland open source virtual world program. A nonparametric Mann-Whitney U analysis was applied to explore the differences between young and senior participants in terms of their sense of place presence, social presence, co-presence, and learning satisfaction. The results indicated significant differences between young and senior students in terms of place presence, co-presence, and learning satisfaction, but no differences were identified for social presence. These results might be in regard with the means of conducted the learning, which were in the forms of cooperative and synchronous learning by utilizing audio communication most of the time. Several recommendations for future research related to the study were also provided. \u00a9 2019 Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Virtual worlds are growing in popularity very quickly. This growing popularity of 3-dimensional (3-D) virtual worlds has drawn attention from educationists. Today, 3-dimensional (3-D) virtual worlds are exploited for online and virtual learning. Unlike the common online learning platforms, a virtual world environment closely resembles a 3-D video games environment. Thus the age of students might affect their sense of presence, interaction, and satisfaction in the said environment. Hence this study was conducted to investigate whether there are differences between students of different age groups on their sense of presence (place presence, social presence, and co-presence) and their learning satisfaction. The study was carried out for six weeks and involved 33 part-time diploma students with the use of interview and questionnaires as instruments. In this study, the researcher developed our own 3-D virtual world, known as ViEW, by using the Open Wonderland open source virtual world program. A nonparametric Mann-Whitney U analysis was applied to explore the differences between young and senior participants in terms of their sense of place presence, social presence, co-presence, and learning satisfaction. The results indicated significant differences between young and senior students in terms of place presence, co-presence, and learning satisfaction, but no differences were identified for social presence. These results might be in regard with the means of conducted the learning, which were in the forms of cooperative and synchronous learning by utilizing audio communication most of the time. Several recommendations for future research related to the study were also provided. \u00a9 2019 Insight Society."
        ]
    },
    {
        "judul":[
            "The Role Of Stakeholder Relations In Building Brand Awareness Study On Consumed Media Feedme Id"
        ],
        "penulis":"Damayasih, Nadiya;Mahes, Gayes;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research aimed to know the role of stakeholder relations in building brand awareness (study on consumed media feedme.id). The research method used for this study was qualitative and the methods of collecting data obtained by observation and structured interview as primary data and secondary data from literature study and company document. Analysis of data used coding data. The validity of data used t riangulation of data source. This research shows that the role of stakeholder relations in building brand awareness is to maintaining relations with consumed media relations feedme.id, otherwise stakeholder relations is doing consumer, client, and media relations on Consumed Media Feedme.id. \u00a9 2019 International Journal of Scientific and Technology Research. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research aimed to know the role of stakeholder relations in building brand awareness (study on consumed media feedme.id). The research method used for this study was qualitative and the methods of collecting data obtained by observation and structured interview as primary data and secondary data from literature study and company document. Analysis of data used coding data. The validity of data used t riangulation of data source. This research shows that the role of stakeholder relations in building brand awareness is to maintaining relations with consumed media relations feedme.id, otherwise stakeholder relations is doing consumer, client, and media relations on Consumed Media Feedme.id. \u00a9 2019 International Journal of Scientific and Technology Research. All rights reserved."
        ]
    },
    {
        "judul":[
            "Early Detection of Skin Basal Cell Carcinoma Nodular Using Extraction Methods ABCD Feature Comparison with Dermatofibroma Data"
        ],
        "penulis":"Irsyad, Firdaus;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Cancer is one of the biggest causes of death now, cancer is also a disease that is very difficult to cure and still relatively difficult to treat, the skin can also be a medium that can cause cancer. Prevention and detection of skin cancer early is one of the best ways to reduce the greater risk that can be caused by the disease, in this paper will explain the making of applications to detection cancer skin Carcinoma Basal Cell type nodular using Image Processing with tested by comparing the feature dermatofibroma and Basal Cell Carcinoma features. In this paper the system is made based on Android to support input features by comparing the 4 criteria of the feature, that is Asymmetry, Border, Color, and Diameter. The extraction method used in the feature xtraction is the ABCD feature with classification using K-Nearest Neighbor.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is one of the biggest causes of death now, cancer is also a disease that is very difficult to cure and still relatively difficult to treat, the skin can also be a medium that can cause cancer. Prevention and detection of skin cancer early is one of the best ways to reduce the greater risk that can be caused by the disease, in this paper will explain the making of applications to detection cancer skin Carcinoma Basal Cell type nodular using Image Processing with tested by comparing the feature dermatofibroma and Basal Cell Carcinoma features. In this paper the system is made based on Android to support input features by comparing the 4 criteria of the feature, that is Asymmetry, Border, Color, and Diameter. The extraction method used in the feature xtraction is the ABCD feature with classification using K-Nearest Neighbor.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Detection of Gas Leaks Using the MQ-2 Gas Sensor on the Autonomous Mobile Sensor"
        ],
        "penulis":"Trisnawan, I. Kadek Nuary;Jati, Agung Nugroho;Istiqomah, Novera;Wasisto, Isro;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Gas leaks are one of the big problems in the industrial sector, even starting to spread to other sectors. One of the solutions to reduce losses due to gas leakage is to detect it early when there is a leak. There are already many technologies that help prevent gas leaks harm humans more, one of them is the mobile sensor. The development of mobile sensors is one way to overcome losses both from material and non-material. Using a gas sensor of type MQ-2 as a detector, it is expected that later it can be overcome before it has a wider impact. The gas sensor is connected to a mobile sensor and installed in four different directions. MQ-2 was chosen because it has a low price and good durability. Assisted by the SLAM method as navigation and a combination of source-seeking and active-sensing localization methods as identifiers of leak points, the mobile sensor identifies points of leakage which are on the abnormal boundary. MQ-2 is calibrated and configured using C language, which is implemented through Arduino IDE. After configuring the gas sensor, it is expected that the results of accuracy reach 80% with the distance from the gas sensor to the point of leakage about 0-10 cm. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Gas leaks are one of the big problems in the industrial sector, even starting to spread to other sectors. One of the solutions to reduce losses due to gas leakage is to detect it early when there is a leak. There are already many technologies that help prevent gas leaks harm humans more, one of them is the mobile sensor. The development of mobile sensors is one way to overcome losses both from material and non-material. Using a gas sensor of type MQ-2 as a detector, it is expected that later it can be overcome before it has a wider impact. The gas sensor is connected to a mobile sensor and installed in four different directions. MQ-2 was chosen because it has a low price and good durability. Assisted by the SLAM method as navigation and a combination of source-seeking and active-sensing localization methods as identifiers of leak points, the mobile sensor identifies points of leakage which are on the abnormal boundary. MQ-2 is calibrated and configured using C language, which is implemented through Arduino IDE. After configuring the gas sensor, it is expected that the results of accuracy reach 80% with the distance from the gas sensor to the point of leakage about 0-10 cm. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "The effect of social media to the sustainability of short message service (SMS) and phone call"
        ],
        "penulis":"Lubis, Arif Ridho;Lubis, Muharman;Azhar, Citra Dewi;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "In the development of increasingly advanced technology, the use of SMS and telephone has been replaced by smartphone users who are more intended to use social media, especially among students. Social media are online media where users can communicate and interact one another for social interactions conducted online through the internet such as WhatsApp, Line, Instagram, Facebook, Twitter, Skype and Telegram. The existence of social media makes SMS and telephone user switch to social media which has more features, capacities and functions. Therefore, it is interesting to investigate the effect of social media to influence the sustainability of SMS and telephone which is seen from the effectiveness of social media in terms of time, quality and quantity, cost, distance, and energy in related to the utilization of SMS and telephone among users. To determine the effect of respected social media, this study use multiple regression, which is analysed using SPSS 17.0 and has passed the validity and reliability test up to 32.7% the influence of all variants. The most dominant influence on Usage and Function variables is Quality and Quantity which has 18% with significant value of test 0,000 smaller than the value set (0.05), the cost of which has 4.7% with significant value of T test at around 0.003 smaller than the value determined (0.05), and Energy which has 2.1% with significant value of T test about 0.013 smaller than the value set (0.05). \u00a9 2019 The Authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the development of increasingly advanced technology, the use of SMS and telephone has been replaced by smartphone users who are more intended to use social media, especially among students. Social media are online media where users can communicate and interact one another for social interactions conducted online through the internet such as WhatsApp, Line, Instagram, Facebook, Twitter, Skype and Telegram. The existence of social media makes SMS and telephone user switch to social media which has more features, capacities and functions. Therefore, it is interesting to investigate the effect of social media to influence the sustainability of SMS and telephone which is seen from the effectiveness of social media in terms of time, quality and quantity, cost, distance, and energy in related to the utilization of SMS and telephone among users. To determine the effect of respected social media, this study use multiple regression, which is analysed using SPSS 17.0 and has passed the validity and reliability test up to 32.7% the influence of all variants. The most dominant influence on Usage and Function variables is Quality and Quantity which has 18% with significant value of test 0,000 smaller than the value set (0.05), the cost of which has 4.7% with significant value of T test at around 0.003 smaller than the value determined (0.05), and Energy which has 2.1% with significant value of T test about 0.013 smaller than the value set (0.05). \u00a9 2019 The Authors."
        ]
    },
    {
        "judul":[
            "Towards Successful Implementation of a Virtual Classroom for Vocational Higher Education in Indonesia"
        ],
        "penulis":"Aditya, Bayu Rima;Nurhas, Irawan;Pawlowski, Jan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The virtual classroom continues to grow, but it is becoming more and more the norm, and it is fundamentally different from the vocational students at the Indonesian university. With the promised benefits of the virtual classroom, many challenges and difficulties come in the implementation. Although there are already successful design principles for virtual classrooms that support organizations in overcoming the challenges, the approach to implementing the design principles of virtual classroom at the vocational higher education in Indonesia is still lacking. In this study, we aim to answer the research gap and used the design sciences research by interviewing the lecturers to design the solutions. The proposed design approaches were implemented in a course and evaluated with students from two different groups. Overall, the evaluation of the proposed approaches shows 1 significant results as an indicator of the benefits of the implementation of a virtual classroom for vocational students in Indonesia. \u00a9 2019, Springer Nature Switzerland AG.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The virtual classroom continues to grow, but it is becoming more and more the norm, and it is fundamentally different from the vocational students at the Indonesian university. With the promised benefits of the virtual classroom, many challenges and difficulties come in the implementation. Although there are already successful design principles for virtual classrooms that support organizations in overcoming the challenges, the approach to implementing the design principles of virtual classroom at the vocational higher education in Indonesia is still lacking. In this study, we aim to answer the research gap and used the design sciences research by interviewing the lecturers to design the solutions. The proposed design approaches were implemented in a course and evaluated with students from two different groups. Overall, the evaluation of the proposed approaches shows 1 significant results as an indicator of the benefits of the implementation of a virtual classroom for vocational students in Indonesia. \u00a9 2019, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Predicting staple food materials price using multivariables factors (regression and fourier models with ARIMA)"
        ],
        "penulis":"Asnhari, Said Fadlan;Gunawan P.H.;Rusmawati, Yanti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Staple food material prices can be a trending topic in the market. The fluctuation of the price is influenced by many factors. For instance, the weather, oil price, and etc are the external factors of the staple food price. Indeed, the prediction of staple food fluctuation price is important for the farmers, consumers, even government. In this paper, the Linear Regression and Fourier model with ARIMA (Autoregressive Integrated Moving Average) will be used to predict the staple food price which consider the external influences. Here, the results using those two methods are shown in a good agreement with the observation price at market. However, the highest accuracy in predicting price using Fourier regression with ARIMA is obtained for staple food onion which is 96.57%. Meanwhile, using multiple linear regression with ARIMA, the highest accuracy is obtained for staple food red chili with 99.84%. Overall, in this research, Fourier regression with ARIMA is observed better than multiple linear regression with ARIMA method, since the accuracy of Fourier regression with ARIMA is quite stable without disturbance of fluctuation existing data. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Staple food material prices can be a trending topic in the market. The fluctuation of the price is influenced by many factors. For instance, the weather, oil price, and etc are the external factors of the staple food price. Indeed, the prediction of staple food fluctuation price is important for the farmers, consumers, even government. In this paper, the Linear Regression and Fourier model with ARIMA (Autoregressive Integrated Moving Average) will be used to predict the staple food price which consider the external influences. Here, the results using those two methods are shown in a good agreement with the observation price at market. However, the highest accuracy in predicting price using Fourier regression with ARIMA is obtained for staple food onion which is 96.57%. Meanwhile, using multiple linear regression with ARIMA, the highest accuracy is obtained for staple food red chili with 99.84%. Overall, in this research, Fourier regression with ARIMA is observed better than multiple linear regression with ARIMA method, since the accuracy of Fourier regression with ARIMA is quite stable without disturbance of fluctuation existing data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2019,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "The effects of the quality of service and social media on the interests of Argo Parahyangan train passengers on Bandung-Jakarta"
        ],
        "penulis":"Hidayah, Riski Taufik;Yolinda, Syindria;Nugraha, Deden Novan Setiawan;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Argo Parahyangan Railway Transports Passengers is currently one of the best choices in traveling the Bandung-Jakarta and Jakarta-Bandung route. The purpose of this study was to find out how much influence the quality of services provided to passengers in traveling, and promotional activities through social media are used to interest passengers to use the Argo Parahyangan Railway. This research involved descriptive verification with a total sample of 100 Bandung people who conduct activities in Jakarta. Results of the study indicated that 44.89% of Purchase interest is contributed by the quality of service and 51.84% is contributed by promotional activities through Social media. \u00a9 2019 Primrose Hall Publishing Group.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Argo Parahyangan Railway Transports Passengers is currently one of the best choices in traveling the Bandung-Jakarta and Jakarta-Bandung route. The purpose of this study was to find out how much influence the quality of services provided to passengers in traveling, and promotional activities through social media are used to interest passengers to use the Argo Parahyangan Railway. This research involved descriptive verification with a total sample of 100 Bandung people who conduct activities in Jakarta. Results of the study indicated that 44.89% of Purchase interest is contributed by the quality of service and 51.84% is contributed by promotional activities through Social media. \u00a9 2019 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "SENTIMENT ANALYSIS of 'Indonesian NO DATING CAMPAIGNS' on TWITTER USING NA\u00cfVE BAYES ALGORITHM"
        ],
        "penulis":"Ardhianie, Nadia;Andreswari, Rachmadita;Hs, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The modern world has witnessed the widespread emergence of online social media. Many people use this kind of technology to share their view about anything. As consequence, it is easy to know public opinions on certain issue by utilizing social media data. One of trending issue in Indonesian Twitter user is about 'Indonesian No Dating Campaign. It is interesting to know effectiveness of that campaign by analyzing public sentiment. In order to analyze the campaign, this study employ sentiment analysis using Na\u00efve Bayes algorithm. This algorithm was chosen by considering its accuracy in several related studies. This research starts with data collection process, by crawling twitter's data that related to the campaign. The collected data will go through the data preprocessing, data classification based on its sentiment using Na\u00efve Bayes. As the result, Na\u00efve Bayes algorithm successfully classifies the twitter's data into 56% positive sentiment, negative sentiment 32% and neutral sentiment 12%. The accuracy of this classification is 74.77%. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The modern world has witnessed the widespread emergence of online social media. Many people use this kind of technology to share their view about anything. As consequence, it is easy to know public opinions on certain issue by utilizing social media data. One of trending issue in Indonesian Twitter user is about 'Indonesian No Dating Campaign. It is interesting to know effectiveness of that campaign by analyzing public sentiment. In order to analyze the campaign, this study employ sentiment analysis using Na\u00efve Bayes algorithm. This algorithm was chosen by considering its accuracy in several related studies. This research starts with data collection process, by crawling twitter's data that related to the campaign. The collected data will go through the data preprocessing, data classification based on its sentiment using Na\u00efve Bayes. As the result, Na\u00efve Bayes algorithm successfully classifies the twitter's data into 56% positive sentiment, negative sentiment 32% and neutral sentiment 12%. The accuracy of this classification is 74.77%. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Management maintenance system for remote control based on microcontroller and virtual private serve"
        ],
        "penulis":"Kamil, Idham;Julham;Lubis, Muharman;Lubis, Arif Ridho;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Open loop shaped control system is a form of system control without any feedback from the system. One example is the on-off condition which functions to connect and disconnect electricity. The condition to be studied is a dc motor that can be set to live and die via internet server-based client service. The server in this system is a virtual private server (VPS) device that will provide a source of service to the client in the form of a collection of information on dc motor conditions. In addition, its function is also to record the working time of the dc motor. So that a schedule can be determined when the dc motor is maintained. While the client is a control unit consisting of a microcontroller device, an ethernet module enc28j60 and a dc motor. In general the working principle of the system is beginning with the user accessing the desired VPS IP address through a web browser application. From the web browser the user chooses a dc motor to be activated. But before the client has been connected to the VPS regularly (every second), the point is to always get the latest dc motor condition information. Then the microcontroller will set the dc motor in active or off condition. The research method used is research and development. The results obtained from this study are that the amount of bandwidth needed for communication between VPS and microcontrollers via the internet network, when the control unit works is 6.02 kbps, while the response time for dc motor is 3.16 seconds and the response time for dc motor 2 is 3.46 seconds. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved.",
            "CH3OHH3CCH3OHHHView detailsExpand Substance 17-methyltestosterone",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Open loop shaped control system is a form of system control without any feedback from the system. One example is the on-off condition which functions to connect and disconnect electricity. The condition to be studied is a dc motor that can be set to live and die via internet server-based client service. The server in this system is a virtual private server (VPS) device that will provide a source of service to the client in the form of a collection of information on dc motor conditions. In addition, its function is also to record the working time of the dc motor. So that a schedule can be determined when the dc motor is maintained. While the client is a control unit consisting of a microcontroller device, an ethernet module enc28j60 and a dc motor. In general the working principle of the system is beginning with the user accessing the desired VPS IP address through a web browser application. From the web browser the user chooses a dc motor to be activated. But before the client has been connected to the VPS regularly (every second), the point is to always get the latest dc motor condition information. Then the microcontroller will set the dc motor in active or off condition. The research method used is research and development. The results obtained from this study are that the amount of bandwidth needed for communication between VPS and microcontrollers via the internet network, when the control unit works is 6.02 kbps, while the response time for dc motor is 3.16 seconds and the response time for dc motor 2 is 3.46 seconds. Copyright \u00a9 2019 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Business process analysis of academic information system application using process mining (case study: Final project module)"
        ],
        "penulis":"Fitriansah, Ilham Akbar;Andreswari, Rachmadita;Hasibuan, Muhammad Azani;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The development of information technology is currently influencing the organization; one of them is Telkom University. Online-Based information technology at Telkom University, namely the Integrated Academic Information System (I-Gracias). I-Gracias is an Academic Information System owned by Telkom University that provides services both academically and non-academically. One of the menus in i-Gracias is the TA \/ PA application; this menu intends for students who will take the bachelor degree final project and will carry out the bachelor degree final project. Based on the current procedure, the service standards for the TA \/ PA I-Gracias application provided do not have specific service time limits. There are differences in service for each user in the TA \/ PA application activity. Therefore, to find out the actual operations in this application, a modeling process is needed to find out the activities that have the longest time. Identification of the modeling process is made by using the process mining approach and utilizing the I-Gracias log event. The modeling process uses the Heuristic Miner modeling technique aimed at modeling the process and finding the best fitness value. The heuristic miner algorithm is chosen because of its ability to handle event logs with noise and can display primary behavior from existing business processes. After getting the modeling, then analyzing the bottleneck for the procedure. Based on the conformance checking results, the best fitness value is 0.98492914, the precision value is 0.7015873, and the structure value is 1. Modeling in performance analysis shows that there are bottlenecks in the activity of uploading proposals and completeness of print trial activities. Bottleneck shows the problem related to the bachelor degree final project guidance application. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of information technology is currently influencing the organization; one of them is Telkom University. Online-Based information technology at Telkom University, namely the Integrated Academic Information System (I-Gracias). I-Gracias is an Academic Information System owned by Telkom University that provides services both academically and non-academically. One of the menus in i-Gracias is the TA \/ PA application; this menu intends for students who will take the bachelor degree final project and will carry out the bachelor degree final project. Based on the current procedure, the service standards for the TA \/ PA I-Gracias application provided do not have specific service time limits. There are differences in service for each user in the TA \/ PA application activity. Therefore, to find out the actual operations in this application, a modeling process is needed to find out the activities that have the longest time. Identification of the modeling process is made by using the process mining approach and utilizing the I-Gracias log event. The modeling process uses the Heuristic Miner modeling technique aimed at modeling the process and finding the best fitness value. The heuristic miner algorithm is chosen because of its ability to handle event logs with noise and can display primary behavior from existing business processes. After getting the modeling, then analyzing the bottleneck for the procedure. Based on the conformance checking results, the best fitness value is 0.98492914, the precision value is 0.7015873, and the structure value is 1. Modeling in performance analysis shows that there are bottlenecks in the activity of uploading proposals and completeness of print trial activities. Bottleneck shows the problem related to the bachelor degree final project guidance application. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Enhancing the performance of smote algorithm by using attribute weighting scheme and new selective sampling method for imbalanced data set"
        ],
        "penulis":"Fahrudin, Tora;Buliali, Joko Lianto;Fatichah, Chastine;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "SMOTE is one of the well-known algorithms for balancing train data by adding synthetic data on minor class data. One of the stages in SMOTE is finding the nearest neighbors (kNN) as the basis for creating synthetic data using Euclidean dis- tance. In cases where a small number of attributes having high correlation value than others, finding kNN using Euclidean without considering this correlation may not find representative neighbors. This paper introduces AWH-SMOTE (Attribute Weighted and kNN Hub on SMOTE), which enhances SMOTE in improving neighbors and noise identification using attribute weighting and also improving selective sampling method using occurrence data in the kNN hub. Wojna and Information Gain methods are used for attribute weighting. A small number of occurrences in the kNN hub results in more syn- thetic data generated so that minority data in dangerous region are more represented. Nine public datasets from Keel repository are used to evaluate AWH-SMOTE. Evaluation shows AWH-SMOTE has better performance on minority precision and minority f-measure for both pruned and unpruned condition than other oversampling algorithms. Information Gain as attribute weighting method in AWH-SMOTE achieves best perfor- mance in unpruned condition when compared to other weighting methods for minority recall, minority precision and minority f-measure. \u00a9 2019 ICIC International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SMOTE is one of the well-known algorithms for balancing train data by adding synthetic data on minor class data. One of the stages in SMOTE is finding the nearest neighbors (kNN) as the basis for creating synthetic data using Euclidean dis- tance. In cases where a small number of attributes having high correlation value than others, finding kNN using Euclidean without considering this correlation may not find representative neighbors. This paper introduces AWH-SMOTE (Attribute Weighted and kNN Hub on SMOTE), which enhances SMOTE in improving neighbors and noise identification using attribute weighting and also improving selective sampling method using occurrence data in the kNN hub. Wojna and Information Gain methods are used for attribute weighting. A small number of occurrences in the kNN hub results in more syn- thetic data generated so that minority data in dangerous region are more represented. Nine public datasets from Keel repository are used to evaluate AWH-SMOTE. Evaluation shows AWH-SMOTE has better performance on minority precision and minority f-measure for both pruned and unpruned condition than other oversampling algorithms. Information Gain as attribute weighting method in AWH-SMOTE achieves best perfor- mance in unpruned condition when compared to other weighting methods for minority recall, minority precision and minority f-measure. \u00a9 2019 ICIC International."
        ]
    },
    {
        "judul":[
            "The design and impact of the pedagogical agent: A systematic literature review"
        ],
        "penulis":"Martha, Ati Suci Dian;Santoso, Harry B.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "A pedagogical agent is an anthropomorphic virtual character used in an online learning environment to serve instructional purposes. The design of pedagogical agents changes over time depending on the desired objectives for them. This article is a systematic review of the research from 2007 to 2017 related to the design factors of pedagogical agents and their impact on learning environments. The objective of this review is to identify and analyze pedagogical agents through the context in which they are constructed, the independent variables used in pedagogical agent research, and the impact of the pedagogical agent implementation. The review found that research on the design of pedagogical agents has different forms, namely text, voice, 2-D character, 3-D character, and human. The independent variables used in the studies are categorized into the appearance of agents and the role of agents. Moreover, the combination of pedagogical agent designs and role designs of pedagogical agents has significant positive impacts on student learning and student behavior. Recommendations are also provided at the end of this review. \u00a9 2019, Grand Canyon University. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A pedagogical agent is an anthropomorphic virtual character used in an online learning environment to serve instructional purposes. The design of pedagogical agents changes over time depending on the desired objectives for them. This article is a systematic review of the research from 2007 to 2017 related to the design factors of pedagogical agents and their impact on learning environments. The objective of this review is to identify and analyze pedagogical agents through the context in which they are constructed, the independent variables used in pedagogical agent research, and the impact of the pedagogical agent implementation. The review found that research on the design of pedagogical agents has different forms, namely text, voice, 2-D character, 3-D character, and human. The independent variables used in the studies are categorized into the appearance of agents and the role of agents. Moreover, the combination of pedagogical agent designs and role designs of pedagogical agents has significant positive impacts on student learning and student behavior. Recommendations are also provided at the end of this review. \u00a9 2019, Grand Canyon University. All rights reserved."
        ]
    },
    {
        "judul":[
            "Increasing Passive RFID-Based Smart Shopping Cart Performance using Decision Tree"
        ],
        "penulis":"Yusuf, Khalid;Abdurohman, Maman;Putrada, Aji Gautama;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper proposes the smart shopping cart based on passive RFID. While on peak season market, queues are often found at clothing store. This happens because the service time between consumers takes a long time; the cashier must scan all items one by one, and make the transaction process at the cashier slow. In proposed system, each item be equipped with an RFID tag, and the shopping cart be equipped with an RFID reader, so the items that are inserted into the shopping cart will be scanned and calculated in the system. This system makes the service time shorter and minimize the number of queues at the cashier. To support the performance of smart shopping cart, a decision tree algorithm is implemented for classifying consumer shopping lists and determine discounts. The author tests and analyzes the performance of the decision tree ID3 algorithm in the smart shopping cart. The test results show that decision tree algorithms can determine discounts with a 90% accuracy rate and 100% precision rate.  \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes the smart shopping cart based on passive RFID. While on peak season market, queues are often found at clothing store. This happens because the service time between consumers takes a long time; the cashier must scan all items one by one, and make the transaction process at the cashier slow. In proposed system, each item be equipped with an RFID tag, and the shopping cart be equipped with an RFID reader, so the items that are inserted into the shopping cart will be scanned and calculated in the system. This system makes the service time shorter and minimize the number of queues at the cashier. To support the performance of smart shopping cart, a decision tree algorithm is implemented for classifying consumer shopping lists and determine discounts. The author tests and analyzes the performance of the decision tree ID3 algorithm in the smart shopping cart. The test results show that decision tree algorithms can determine discounts with a 90% accuracy rate and 100% precision rate.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Gender differences in students' e-learning usage outcomes"
        ],
        "penulis":"Aditya, Bayu Rima;Permadi, Aditya;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "The importance of studying gender differences in student skills has been demonstrated by the emergence of various results of previous studies that discussed the recommendations for developing learning by considering gender. The question that raised in this study is whether there is a difference between the assessment of male and female students on aspects related to the learning outcomes in the context of e-learning. The main contribution of this study was to provide evidence about matters considered necessary by male and female students towards achieving their learning outcomes. This research is based on a sample of 223 students that registered as e-learning class participants on two different campuses in Indonesia. This study concludes that there are two out of six aspects of learning outcomes that shows the significant difference between the assessment of male and female students: usefulness and course content. These results confirm that there are still gaps between male and female students about the learning outcomes.  \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGender equalityGoal 5Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The importance of studying gender differences in student skills has been demonstrated by the emergence of various results of previous studies that discussed the recommendations for developing learning by considering gender. The question that raised in this study is whether there is a difference between the assessment of male and female students on aspects related to the learning outcomes in the context of e-learning. The main contribution of this study was to provide evidence about matters considered necessary by male and female students towards achieving their learning outcomes. This research is based on a sample of 223 students that registered as e-learning class participants on two different campuses in Indonesia. This study concludes that there are two out of six aspects of learning outcomes that shows the significant difference between the assessment of male and female students: usefulness and course content. These results confirm that there are still gaps between male and female students about the learning outcomes.  \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis and Implementation of Ontology Based Text Classification on Criminality Digital News"
        ],
        "penulis":"Rahma F.;Pangestuti D.D.;Herdiani A.;Selviandro N.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research, we search the trend by utillize all information about the criminality type. When the trend has found, the possibility of crime in West Java will decrease. We need to analyse the data to get the information about the criminality trend by using Ontology based Text Classification Method. A news will be grouped into some criminality classes based on the relation around that groups so the process of classification can be done simply and specifically. The criminality trend of West Java is Property Crime with 47,5% of occurrences. We used several testing method such as F1 Score, Precision, Recall, and Accuracy. Based on the methods, the performance of system is running well or not in different point of view. The researcher obtained satisfactory result with F1 score 87,05%, accuracy 86,74%, recall 100% and precision 77,08% with using comparison of composition crime dataset and non-crime dataset is 40 : 40. It happens because testing needs to be done by considering the number of both datasets. The more balance the comparison while do preprocess, the higher accuracy that will get. In order to know whether the system is able to clarify the information accurately and can separate the non-criminal news dataset. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research, we search the trend by utillize all information about the criminality type. When the trend has found, the possibility of crime in West Java will decrease. We need to analyse the data to get the information about the criminality trend by using Ontology based Text Classification Method. A news will be grouped into some criminality classes based on the relation around that groups so the process of classification can be done simply and specifically. The criminality trend of West Java is Property Crime with 47,5% of occurrences. We used several testing method such as F1 Score, Precision, Recall, and Accuracy. Based on the methods, the performance of system is running well or not in different point of view. The researcher obtained satisfactory result with F1 score 87,05%, accuracy 86,74%, recall 100% and precision 77,08% with using comparison of composition crime dataset and non-crime dataset is 40 : 40. It happens because testing needs to be done by considering the number of both datasets. The more balance the comparison while do preprocess, the higher accuracy that will get. In order to know whether the system is able to clarify the information accurately and can separate the non-criminal news dataset. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Lexical and Syntactic Simplification for Indonesian Text"
        ],
        "penulis":"Wibowo, Muhammad Satrio;Romadhony, Ade;Sa'Adah, Siti;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This paper presents a text simplification approach for Indonesian text by incorporating lexical and syntactic features that aims to improve documents accessibility for children. We employed the similar words information from word-embeddings model in lexical simplification and manually defined rules in syntactic simplification. We conducted the evaluation by presenting the simplified texts and several questions regarding text simplicity, fluency, and adequacy in form of a questionnaire to 137 fourth to sixth grade elementary students. The evaluation results show that our system is able to reduce the lexical and syntactic complexity, based on the simplicity and adequacy parameters, while we need to study the fluency parameter further. \u00a9 2019 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents a text simplification approach for Indonesian text by incorporating lexical and syntactic features that aims to improve documents accessibility for children. We employed the similar words information from word-embeddings model in lexical simplification and manually defined rules in syntactic simplification. We conducted the evaluation by presenting the simplified texts and several questions regarding text simplicity, fluency, and adequacy in form of a questionnaire to 137 fourth to sixth grade elementary students. The evaluation results show that our system is able to reduce the lexical and syntactic complexity, based on the simplicity and adequacy parameters, while we need to study the fluency parameter further. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Design of Arabic Recognition Application using Convolutional Neural Network"
        ],
        "penulis":"Rosyda, Salma Shofia;Irawan, Budhi;Prasasti, Anggunmeka Luhur;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Arabic is one of the languages which attracted, needed and used by a lot of people in the world. Many countries have used Arabic language in courses which related to the international world. Arabic also used by Muslim people, beacause Arabic is the main language of the hooly book of Muslim (Quran). The importance to know and to understand the basic of Arabic language for the temporary needs like when we travel to a country which use Arabic as their main language include during Hajj and Umrah. At this time the smartphone has become a major need for humans, based on that then made Arabic writing recognition application which aims to help pilgrims of Hajj and Umrah who can not speak Arabic. In this study, the method used is the method of Convolutional Neural Network (CNN). Test results from Arabic handwritten image classification using CNN resulted in an average accuracy of 60%. It can be concluded that the CNN method used in this application is able to do a good classification. \u00a9 Medwell Journals, 2019",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Arabic is one of the languages which attracted, needed and used by a lot of people in the world. Many countries have used Arabic language in courses which related to the international world. Arabic also used by Muslim people, beacause Arabic is the main language of the hooly book of Muslim (Quran). The importance to know and to understand the basic of Arabic language for the temporary needs like when we travel to a country which use Arabic as their main language include during Hajj and Umrah. At this time the smartphone has become a major need for humans, based on that then made Arabic writing recognition application which aims to help pilgrims of Hajj and Umrah who can not speak Arabic. In this study, the method used is the method of Convolutional Neural Network (CNN). Test results from Arabic handwritten image classification using CNN resulted in an average accuracy of 60%. It can be concluded that the CNN method used in this application is able to do a good classification. \u00a9 Medwell Journals, 2019"
        ]
    },
    {
        "judul":[
            "Potential detection of lentigo maligna melanoma on solar lentigines image based on android"
        ],
        "penulis":"Bimastro, Kurnia Zikir;Purboyo, Tito Waluyo;Setianingsih, Casi;Murti, Muhammad Ary;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "Solar Lentigines is a skin disease caused by frequent exposure to direct sunlight. Appearance in solar lentigines can resemble Lentigo Malignant Melanoma cancer at an early stage. solar lentigines a disease that is not dangerous and does not require special treatment, but if there are significant changes such as asymmetrical wounds, obscure borders, non-homogeneous colors, diameters exceeding 6 millimeters, solar lentigines are suspected as lentigo malignant early stage melanoma. lentigo malignant melanoma is a rare but dangerous type of skin cancer if it is not treated immediately with asymmetrical, unclear boundaries, non-homogeneous colors, diameters exceeding 6 millimeters. This research aims to help detect the potential of lentigo malignant melanoma disease by using the image of solar lentigines. This application uses the ABCD method for feature extraction to scratch the input image and decision tree for classification. ABCD method is a medical method used to detect cancer in terms of asymmetry, obscure borders, color, diameter. The data of this research were obtained from one hospital in Bandung and the data was presented in table form and explained informally. The result of the application is a diagnosis of the potential for disease. The accuracy value of this application is 97.5% from 60 training data. \u00a9 2019 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Solar Lentigines is a skin disease caused by frequent exposure to direct sunlight. Appearance in solar lentigines can resemble Lentigo Malignant Melanoma cancer at an early stage. solar lentigines a disease that is not dangerous and does not require special treatment, but if there are significant changes such as asymmetrical wounds, obscure borders, non-homogeneous colors, diameters exceeding 6 millimeters, solar lentigines are suspected as lentigo malignant early stage melanoma. lentigo malignant melanoma is a rare but dangerous type of skin cancer if it is not treated immediately with asymmetrical, unclear boundaries, non-homogeneous colors, diameters exceeding 6 millimeters. This research aims to help detect the potential of lentigo malignant melanoma disease by using the image of solar lentigines. This application uses the ABCD method for feature extraction to scratch the input image and decision tree for classification. ABCD method is a medical method used to detect cancer in terms of asymmetry, obscure borders, color, diameter. The data of this research were obtained from one hospital in Bandung and the data was presented in table form and explained informally. The result of the application is a diagnosis of the potential for disease. The accuracy value of this application is 97.5% from 60 training data. \u00a9 2019 IEEE."
        ]
    },
    {
        "judul":[
            "Quranic Latin query correction as a search suggestion"
        ],
        "penulis":"Satriady, Wildhan;Bijaksana, Moch Arif;Lhaksmana, Kemas M.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "This research proposes a method to help correct typo errors, such as wrong letters, missing letters, and additional letters. To date, the Lafzi search system is an example of an effective application for searching Arabic queries based on sound similarity. The Lafzi application helps correct typos due to the sound of Arabic letters that are almost the same as the pronunciation but not correct errors due to typos. Typos could prevent the search system not to display the desired results. This research proposes a solution by employing auto-complete to equipped missing trigram and the edit distance metric to calculate the differentiation value between the corrected query with the initial query. The way the system works is by separating and sorting trigram tokens from queries (user inputs) based on the verse. Each verse that has a missing trigram token will be equipped and re-transformed into a corrected query. Each corrected query will be compared to the edit distance value against the initial query (input from the user), then a corrected query will be taken which has the smallest edit distance value and will be made as a suggested query. The evaluation shows that the proposed method produces the highest recall value at 93.40% and the highest MAP value at 86%. This outperforms the previous Lafzi system approach which achieves recall at 85.23% and MAP at 79.83%. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research proposes a method to help correct typo errors, such as wrong letters, missing letters, and additional letters. To date, the Lafzi search system is an example of an effective application for searching Arabic queries based on sound similarity. The Lafzi application helps correct typos due to the sound of Arabic letters that are almost the same as the pronunciation but not correct errors due to typos. Typos could prevent the search system not to display the desired results. This research proposes a solution by employing auto-complete to equipped missing trigram and the edit distance metric to calculate the differentiation value between the corrected query with the initial query. The way the system works is by separating and sorting trigram tokens from queries (user inputs) based on the verse. Each verse that has a missing trigram token will be equipped and re-transformed into a corrected query. Each corrected query will be compared to the edit distance value against the initial query (input from the user), then a corrected query will be taken which has the smallest edit distance value and will be made as a suggested query. The evaluation shows that the proposed method produces the highest recall value at 93.40% and the highest MAP value at 86%. This outperforms the previous Lafzi system approach which achieves recall at 85.23% and MAP at 79.83%. \u00a9 2019 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:\/\/creativecommons.org\/licenses\/by-nc-nd\/4.0\/) Peer-review under responsibility of the scientific committee of the 4th International Conference on Computer Science and Computational Intelligence 2019."
        ]
    },
    {
        "judul":[
            "The implication of business partnership, company asset and strategic innovation to business valuation of digital industry in Indonesia"
        ],
        "penulis":"Witjara, Edi;Nidar, Sulaeman R.;Herwany, Aldrin;Santosa, Setyanto P.;Save all to author list",
        "tahun":2019,
        "sdgs":[
            "It was predicted that between 2013-2020 the revenue growth of global operator especially voice and data services would be decline. However, there will be an increase in automated (Non-Human intervention) data services and digital service (content, video, ecommerce, etc.). It also predicted that the presence of digital product in Telco will be able to recover negative revenue growth become positive one. Nevertheless, the business valuation of the digital companies is fluctuating within the last nine years due to the volatility caused by several factors. The poor valuation of digital industry is allegedly due to the implementation of strategic innovation has not been completely implemented. It is associated with problems in the development of the company's assets and business partnership that has been initiated. This study aims to assess the influence of company assets and business partnership on strategic innovation and its implications on the business valuation of digital industry in Indonesia. The study uses a quantitative approach with the analysis unit is digital companies in Indonesia. We are using 200 respondents that comprise of various strategic position personal of digital companies and processed the analysis by using simple random sampling technique. The results of the study has pointed out that strategic innovation has a greatest effect on business valuation. Strategic Innovation is mostly affected by company asset rather than business partnership. Company asset and business partnership effect on business valuation both directly and indirectly through Strategic Innovation. \u00a9 2019 Allied Academies.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "It was predicted that between 2013-2020 the revenue growth of global operator especially voice and data services would be decline. However, there will be an increase in automated (Non-Human intervention) data services and digital service (content, video, ecommerce, etc.). It also predicted that the presence of digital product in Telco will be able to recover negative revenue growth become positive one. Nevertheless, the business valuation of the digital companies is fluctuating within the last nine years due to the volatility caused by several factors. The poor valuation of digital industry is allegedly due to the implementation of strategic innovation has not been completely implemented. It is associated with problems in the development of the company's assets and business partnership that has been initiated. This study aims to assess the influence of company assets and business partnership on strategic innovation and its implications on the business valuation of digital industry in Indonesia. The study uses a quantitative approach with the analysis unit is digital companies in Indonesia. We are using 200 respondents that comprise of various strategic position personal of digital companies and processed the analysis by using simple random sampling technique. The results of the study has pointed out that strategic innovation has a greatest effect on business valuation. Strategic Innovation is mostly affected by company asset rather than business partnership. Company asset and business partnership effect on business valuation both directly and indirectly through Strategic Innovation. \u00a9 2019 Allied Academies."
        ]
    }
]