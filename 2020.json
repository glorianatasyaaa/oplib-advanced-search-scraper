[
    {
        "judul":[
            "Pak Choy Leaf Width Detection using Image Processing with Canny Edge Detection Extraction Method"
        ],
        "penulis":"Brenda;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2021,
        "sdgs":[
            "Pak Choy plant is a vegetable plant that can grow with soil and hydroponic media. Plant growth can be monitored by knowing the width of the plant's leaves. This research creates a tool to accurately detect plant leaf width through plant growth monitored by the people-research implementation in the form of a mobile application that can detect the width of plant leaves. Using the canny edge detection method, the results obtained system accuracy of 95.06%, the light intensity of 18.75 lux, angle of 90\u00b0, and distance of 30 cm. Pak Choy plant growth was seen for 4 weeks, the best accuracy was obtained at 2nd week with an average accuracy of 99% and an average light intensity value of 22 lux.  \u00a9 2021 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Pak Choy plant is a vegetable plant that can grow with soil and hydroponic media. Plant growth can be monitored by knowing the width of the plant's leaves. This research creates a tool to accurately detect plant leaf width through plant growth monitored by the people-research implementation in the form of a mobile application that can detect the width of plant leaves. Using the canny edge detection method, the results obtained system accuracy of 95.06%, the light intensity of 18.75 lux, angle of 90\u00b0, and distance of 30 cm. Pak Choy plant growth was seen for 4 weeks, the best accuracy was obtained at 2nd week with an average accuracy of 99% and an average light intensity value of 22 lux.  \u00a9 2021 IEEE."
        ]
    },
    {
        "judul":[
            "Internet of things based real-time vital sign monitoring system using mobile application"
        ],
        "penulis":"Hadiyoso, Sugondo;Alfaruq, Akhmad;Tulloh, Rohmat;Rohmah, Yuyun Siti;Susanto, Erwin;Save all to author list",
        "tahun":2021,
        "sdgs":[
            "The development of telehealth technology in monitoring systems has been widely used to support applications in the health sector. The aim is to provide easy access for the people. One of the implications is a real-time monitoring system based on the Internet of Things (IoT) platform. Some health vital signs that focus on observation are electrocardiogram (ECG) signal, oxygen saturation, blood pressure, and heart rate, providing heart health information. In this study, an integrated system has been implemented, namely a vital sign distributed monitoring system through the internet network. The implemented system was able to acquire vital signs then send data to the internet cloud to be stored and processed further for real-time monitoring needs by interested parties. An Android-based application called iHealthVitalSign monitor can send, process, and represent data in numerical and graphical forms. The average delay for each packet delivery was 154.73 ms and complied with the ITU-T recommendations for real-time data transfer. Heart rate (HR)detection algorithms have been evaluated on real-time ECG signals.From the test results for more than 2100 beats, the average detection accuracy is 98.78%.With this proposed application, it is hoped that it can increase the penetration of telehealth services. \u00a9 2021 Institut za Istrazivanja. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of telehealth technology in monitoring systems has been widely used to support applications in the health sector. The aim is to provide easy access for the people. One of the implications is a real-time monitoring system based on the Internet of Things (IoT) platform. Some health vital signs that focus on observation are electrocardiogram (ECG) signal, oxygen saturation, blood pressure, and heart rate, providing heart health information. In this study, an integrated system has been implemented, namely a vital sign distributed monitoring system through the internet network. The implemented system was able to acquire vital signs then send data to the internet cloud to be stored and processed further for real-time monitoring needs by interested parties. An Android-based application called iHealthVitalSign monitor can send, process, and represent data in numerical and graphical forms. The average delay for each packet delivery was 154.73 ms and complied with the ITU-T recommendations for real-time data transfer. Heart rate (HR)detection algorithms have been evaluated on real-time ECG signals.From the test results for more than 2100 beats, the average detection accuracy is 98.78%.With this proposed application, it is hoped that it can increase the penetration of telehealth services. \u00a9 2021 Institut za Istrazivanja. All rights reserved."
        ]
    },
    {
        "judul":[
            "Experimental Analysis of Vehicle-to-Vehicle Communication using Light Detection and Ranging (LIDAR) for Detection and Data Transmission"
        ],
        "penulis":"Prasetya, Dwieka Septian Arif;Arseno, Dharu;Pamukti, Brian;Vidyaningtyas, Hurianti;Save all to author list",
        "tahun":2021,
        "sdgs":[
            "In the era of technology 4.0, the automobile industry began to develop with the increasing comfort, safety and apply new technologies such as artificial intelligence. We propose a Light Detection and Ranging (LIDAR) sensor as a medium for detection and data transmission for safety between cars. Our proposal has been tested on prototype vehicles that can be used indoors, such as in a company that requires automation of the vehicle. This study uses a 2times 2 array Light Emitting Diode (LED) simultaneously to the LIDAR sensor. Prototype vehicles has been observed and analyzed for the impact of changes in distance and angle. With intensive experiments, the results show that using the LIDAR sensor in the prototype vehicle obtains accurate distance detection. We also proved that the prototype yields the optimal distance in transmitting data to be 20 cm to 120 cm at 0 degrees, 20 to 60 cm at 10 degrees, and 20 to 40 cm at 15 degrees. In addition, the maximum distance that this prototype vehicle can transmit is 260 cm at 0 degrees, 100 cm at 10 degrees, 40 cm at 15 degrees, which is still relatively safe for vehicle distance tolerance. \u00a9 2021 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the era of technology 4.0, the automobile industry began to develop with the increasing comfort, safety and apply new technologies such as artificial intelligence. We propose a Light Detection and Ranging (LIDAR) sensor as a medium for detection and data transmission for safety between cars. Our proposal has been tested on prototype vehicles that can be used indoors, such as in a company that requires automation of the vehicle. This study uses a 2times 2 array Light Emitting Diode (LED) simultaneously to the LIDAR sensor. Prototype vehicles has been observed and analyzed for the impact of changes in distance and angle. With intensive experiments, the results show that using the LIDAR sensor in the prototype vehicle obtains accurate distance detection. We also proved that the prototype yields the optimal distance in transmitting data to be 20 cm to 120 cm at 0 degrees, 20 to 60 cm at 10 degrees, and 20 to 40 cm at 15 degrees. In addition, the maximum distance that this prototype vehicle can transmit is 260 cm at 0 degrees, 100 cm at 10 degrees, 40 cm at 15 degrees, which is still relatively safe for vehicle distance tolerance. \u00a9 2021 IEEE."
        ]
    },
    {
        "judul":[
            "Fruit Ripeness Sorting Machine using Color Sensors"
        ],
        "penulis":"Andi, Adit F.;Nuha, Hilal Hudan;Abdurohman, Maman;Save all to author list",
        "tahun":2021,
        "sdgs":[
            "The process of grouping or sorting fruits that is carried out at this time is still using the manual method by humans, basically humans have properties that make the process of grouping or sorting can take a long time. Based on these conditions, a sorting machine is needed that has the ability to detect and group fruits based on color automatically and faster. So it is expected that the manufacture of this machine can assist in productivity in the process of grouping or sorting fruits. The system is made in the form of a sorting machine that will classify the colors of each fruit using a TCS3200 sensor as a color detector and all these processes will be controlled using Arduino with an ATmega328 microcontroller. \u00a9 2021 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The process of grouping or sorting fruits that is carried out at this time is still using the manual method by humans, basically humans have properties that make the process of grouping or sorting can take a long time. Based on these conditions, a sorting machine is needed that has the ability to detect and group fruits based on color automatically and faster. So it is expected that the manufacture of this machine can assist in productivity in the process of grouping or sorting fruits. The system is made in the form of a sorting machine that will classify the colors of each fruit using a TCS3200 sensor as a color detector and all these processes will be controlled using Arduino with an ATmega328 microcontroller. \u00a9 2021 IEEE."
        ]
    },
    {
        "judul":[
            "Impact of cross equatorial northerly surge (CENS) on Jakarta heavy rainfall and its interaction with tropical cyclone (Case study: 18-25 February 2020)"
        ],
        "penulis":"Saufina, Elfira;Trismidianto;Risyanto;Fathrio, Ibnu;Harjupa, Wendi;Save all to author list",
        "tahun":2021,
        "sdgs":[
            "This study analyzed the causes of flooding in Jakarta area on 18-25 February 2020. Satellite-derived-meteorological parameters were used to elaborate the underlying cause. Convective cloud index derived from Himawari-8 satellite and horizontal precipitation distribution derived from Global Satellite Mapping of Precipitation (GSMaP) dataset, as product of Global Precipitation Measurement (GPM) satellite, confirmed heavy rainfall occurred during this period. The results showed that the floods during this period were atributable to the strengthening of the notherly surface wind from the South China Sea that cross the equator well known as Cross Equtorially Notherly Surge (CENS). This notherly surge brought abundant water vapor and produce intensive rainfall over north coast of West Java Island. Strengthening of notherly surface wind was represented by CENS index derived form surface wind data obtained from Cross-calibrated multi-platform (CCMP) wind vector analysis dataset. The presence notherly surge was accompanied by cold sea surface temperture (SST) in South China Sea shown by optimally-interpolated SST (OISST) dataset. In addition, this study highlighted the role of tropical cyclone (TC) Ferdinand, formed to the southeast of Java island, that supressed convective activity over Jakarta on 22-23 February as shown by minimum rainfall during active period of CENS. \u00a9 2021 Author(s).",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study analyzed the causes of flooding in Jakarta area on 18-25 February 2020. Satellite-derived-meteorological parameters were used to elaborate the underlying cause. Convective cloud index derived from Himawari-8 satellite and horizontal precipitation distribution derived from Global Satellite Mapping of Precipitation (GSMaP) dataset, as product of Global Precipitation Measurement (GPM) satellite, confirmed heavy rainfall occurred during this period. The results showed that the floods during this period were atributable to the strengthening of the notherly surface wind from the South China Sea that cross the equator well known as Cross Equtorially Notherly Surge (CENS). This notherly surge brought abundant water vapor and produce intensive rainfall over north coast of West Java Island. Strengthening of notherly surface wind was represented by CENS index derived form surface wind data obtained from Cross-calibrated multi-platform (CCMP) wind vector analysis dataset. The presence notherly surge was accompanied by cold sea surface temperture (SST) in South China Sea shown by optimally-interpolated SST (OISST) dataset. In addition, this study highlighted the role of tropical cyclone (TC) Ferdinand, formed to the southeast of Java island, that supressed convective activity over Jakarta on 22-23 February as shown by minimum rainfall during active period of CENS. \u00a9 2021 Author(s)."
        ]
    },
    {
        "judul":[
            "Interview Bot for Improving Human Resource Management"
        ],
        "penulis":"Suakanto, Sinung;Siswanto, Joko;Febrianti Kusumasari, Tien;Reza Prasetyo, Ilham;Hardiyanti, Margareta;Save all to author list",
        "tahun":2021,
        "sdgs":[
            "This study aims to explore the feasibility of implementing a chatbot for an interview process. The development of chatbots evolved rapidly to efficiently collect information in numerous fields, including customer service, health care, and etc. However, there was limited discussion of how chatbots are used to conduct an interview process autonomously. A human-driven interview also has some major limitations, e.g., it may only be conducted on a small-scale and is susceptible to bias. Hence, this study provides the design of a chatbot to conduct an interview, as well as processing the interview result by using Artificial Intelligence (AI) or machine learning. We have identified the difference between the typical chatbot communication method and the interview bot. This finding can be an opportunity to make a new interview bot or improve the implementation of a chatbot. In the end, we also discuss the challenges and benefits of the development of an interview bot. \u00a9 2021 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to explore the feasibility of implementing a chatbot for an interview process. The development of chatbots evolved rapidly to efficiently collect information in numerous fields, including customer service, health care, and etc. However, there was limited discussion of how chatbots are used to conduct an interview process autonomously. A human-driven interview also has some major limitations, e.g., it may only be conducted on a small-scale and is susceptible to bias. Hence, this study provides the design of a chatbot to conduct an interview, as well as processing the interview result by using Artificial Intelligence (AI) or machine learning. We have identified the difference between the typical chatbot communication method and the interview bot. This finding can be an opportunity to make a new interview bot or improve the implementation of a chatbot. In the end, we also discuss the challenges and benefits of the development of an interview bot. \u00a9 2021 IEEE."
        ]
    },
    {
        "judul":[
            "RGB Channel Analysis for Glaucoma Detection in Retinal Fundus Image"
        ],
        "penulis":"Satya Nugraha, Gibran;Amelia Riyandari, Baiq;Sutoyo, Edi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The research that used digital image processing to detect glaucoma has been known as one of the popular methods. The beginning step of the research is to choose the best channel among red, green, or blue (RGB) so it can ease the glaucoma segmentation. In choosing the channel, it is important to analyze deeply the used retinal images. Choosing of best component can affect the accuracy of glaucoma diagnosis results. In this research, the most suitable component will be analyzed to detect glaucoma based on the visual, MSE (Mean Square Error) value, and PSNR (Peak Signal to Noise Ratio). In this research, we used 85 images of glaucoma from the DRISTHI-GS database and 101 normal images from the RIM-ONE database. From the visualization, it showed that the red component had high brightness level so it can differ the optic disc and other parts of retinal eyes. The green component still has vessel blood so it will make it more difficult to segment the images. Blue component results in very dark of retinal image. From MSE and PNSR values, it showed that the green component had the smallest MSE value while the blue component has the biggest MSE value. PSNR value was obtained from the green component. Both red and blue components had PSNR value which had a small difference. From these results, it can be concluded that the MSE and PSNR values do not guarantee visual results. So that for further research, it is expected that the MSE and PSNR values will be obtained from the part that we want to observe  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The research that used digital image processing to detect glaucoma has been known as one of the popular methods. The beginning step of the research is to choose the best channel among red, green, or blue (RGB) so it can ease the glaucoma segmentation. In choosing the channel, it is important to analyze deeply the used retinal images. Choosing of best component can affect the accuracy of glaucoma diagnosis results. In this research, the most suitable component will be analyzed to detect glaucoma based on the visual, MSE (Mean Square Error) value, and PSNR (Peak Signal to Noise Ratio). In this research, we used 85 images of glaucoma from the DRISTHI-GS database and 101 normal images from the RIM-ONE database. From the visualization, it showed that the red component had high brightness level so it can differ the optic disc and other parts of retinal eyes. The green component still has vessel blood so it will make it more difficult to segment the images. Blue component results in very dark of retinal image. From MSE and PNSR values, it showed that the green component had the smallest MSE value while the blue component has the biggest MSE value. PSNR value was obtained from the green component. Both red and blue components had PSNR value which had a small difference. From these results, it can be concluded that the MSE and PSNR values do not guarantee visual results. So that for further research, it is expected that the MSE and PSNR values will be obtained from the part that we want to observe  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Web Content Quality Information on the Koseeker Website Using the Web Content Audit Method and ParseHub Tools"
        ],
        "penulis":"Abiantoro, Deandra;Kusumo, Dana Sulistyo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Content Quality is one of the most critical dimensions of Website Quality. There are seven indicators to check the quality of the content. Content that has low quality can be determined with these indicators. To facilitate quality checking of the website content, the authors used a content audit method. However, there are currently not many standards that can be used for content auditing. So in this study, the authors proposed to use the website auditing framework and combine it with content quality indicators. With these methods, the authors can assess content by following the indicators of content quality. Complete information about the website was needed to conduct an audit. The authors used web scraping using Parsehub to get all these data. In this research, the case taken for quality checking was Koseeker Website. After conducting the content audit in Koseeker, the results showed that Koseeker has a quality that was not yet maximum on three of seven indicators, namely, Timely, Relevant, and Authority. After doing the test, it can be seen that the proposed web content audit can assess the quality of Koseeker website content.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Content Quality is one of the most critical dimensions of Website Quality. There are seven indicators to check the quality of the content. Content that has low quality can be determined with these indicators. To facilitate quality checking of the website content, the authors used a content audit method. However, there are currently not many standards that can be used for content auditing. So in this study, the authors proposed to use the website auditing framework and combine it with content quality indicators. With these methods, the authors can assess content by following the indicators of content quality. Complete information about the website was needed to conduct an audit. The authors used web scraping using Parsehub to get all these data. In this research, the case taken for quality checking was Koseeker Website. After conducting the content audit in Koseeker, the results showed that Koseeker has a quality that was not yet maximum on three of seven indicators, namely, Timely, Relevant, and Authority. After doing the test, it can be seen that the proposed web content audit can assess the quality of Koseeker website content.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Fuzzy Swing Up Control and Optimal State Feedback Stabilization for Self-Erecting Inverted Pendulum"
        ],
        "penulis":"Susanto, Erwin;Surya Wibowo, Agung;Ghiffary Rachman, Elvandry;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents the realisation of self-erecting inverted pendulum controls via two switched control approaches, a rule based fuzzy control for swing up inverted pendulum rod to pose upright position from downright position and an optimal state feedback control for stabilization as pendulum on upright position close to its equilibrium vertical line. The aim of this study is to solve two important problems on self-erecting inverted pendulum; swing up and stability in its upright balance position. Simulation and experimental results showed that control methods enabled the inverted pendulum swinging up and reaching its stable attitude in upright position even though small impulse and pulse disturbances were given. \u00a9 2013 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents the realisation of self-erecting inverted pendulum controls via two switched control approaches, a rule based fuzzy control for swing up inverted pendulum rod to pose upright position from downright position and an optimal state feedback control for stabilization as pendulum on upright position close to its equilibrium vertical line. The aim of this study is to solve two important problems on self-erecting inverted pendulum; swing up and stability in its upright balance position. Simulation and experimental results showed that control methods enabled the inverted pendulum swinging up and reaching its stable attitude in upright position even though small impulse and pulse disturbances were given. \u00a9 2013 IEEE."
        ]
    },
    {
        "judul":[
            "Computational Analysis and Classification of Road Surface Using Na\u00efve Bayes Classifiers"
        ],
        "penulis":"Moesya, Aditya R.;Gunawan P.H.;Indwiarti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Road becomes one of the main paths for land transportation, therefore the quality of the road plays a big role in order to achieve the convenience and safety for the community. This research works on a solution to identify the quality of road into two categories (smooth and rough). The datasets are made possible by Phyphox mobile application producing up\u00a0to 300 datasets. The extracted datasets originally have three axis such as x-axis, y-axis, and z-axis graphs. After conducting individual and multiple axis with combination of scenarios, it is found that the combination of y-axis and z-axis scenario is the best fit for current experiment. The methods that are being proposed include the classification models under Na\u00efve Bayes classifiers. The models include Gaussian Na\u00efve Bayes, Multinomial Na\u00efve Bayes with Min-max scalar, Complement Na\u00efve Bayes with Min-max scalar, Multinomial Na\u00efve Bayes with absolute number, and Complement Na\u00efve Bayes with absolute number. The accuracy of all models are being calculated and compared in this paper. Nevertheless, the Complement Na\u00efve Bayes with Min-max scalar shows the best accuracy value up\u00a0to 91.4% and 91.6% for model validation and performance measurement respectively. \u00a9 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Road becomes one of the main paths for land transportation, therefore the quality of the road plays a big role in order to achieve the convenience and safety for the community. This research works on a solution to identify the quality of road into two categories (smooth and rough). The datasets are made possible by Phyphox mobile application producing up\u00a0to 300 datasets. The extracted datasets originally have three axis such as x-axis, y-axis, and z-axis graphs. After conducting individual and multiple axis with combination of scenarios, it is found that the combination of y-axis and z-axis scenario is the best fit for current experiment. The methods that are being proposed include the classification models under Na\u00efve Bayes classifiers. The models include Gaussian Na\u00efve Bayes, Multinomial Na\u00efve Bayes with Min-max scalar, Complement Na\u00efve Bayes with Min-max scalar, Multinomial Na\u00efve Bayes with absolute number, and Complement Na\u00efve Bayes with absolute number. The accuracy of all models are being calculated and compared in this paper. Nevertheless, the Complement Na\u00efve Bayes with Min-max scalar shows the best accuracy value up\u00a0to 91.4% and 91.6% for model validation and performance measurement respectively. \u00a9 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Age Group Based Document Classification in Bahasa Indonesia"
        ],
        "penulis":"Putra, M. Iqbal D.;Irmawati, Budi;Wedashwara, Wirarama;Pramesti, Dita;Khairunnisa, Siti Oryza;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Internet provides articles that may be categorized to various target readers based on genders, ages, hobbies, etc. To make sure that readers consume a proper article based on their age group, methods and training data were proposed and collected to classify the articles. This paper reported a document classification based on age groups using a binary classification method for Indonesian documents. The document classification used the term frequency and inverse document frequency (TF-IDF) features run on the Multinomial Na\u00efve Bayes Classifier. The dataset was crowdsourced from three different sites: bobo.grid.id, hai.grid.id, and www.detik.com for three age group readers such as elementary school children, teenagers, and adults. The experimental results obtained 0.9406, 0.9341, and 0.9374 of precision, recall, and F-score respectively. This experiment also reported that for the datasets that were not stemmed performed better than those that were stemmed. It shows that the stemming process, which usually be done in the document classification, throws some information in the Indonesian texts. However, because this behavior was not happen on nouns, our future work is to elaborate further on the role of affixations in the lower age group documents. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet provides articles that may be categorized to various target readers based on genders, ages, hobbies, etc. To make sure that readers consume a proper article based on their age group, methods and training data were proposed and collected to classify the articles. This paper reported a document classification based on age groups using a binary classification method for Indonesian documents. The document classification used the term frequency and inverse document frequency (TF-IDF) features run on the Multinomial Na\u00efve Bayes Classifier. The dataset was crowdsourced from three different sites: bobo.grid.id, hai.grid.id, and www.detik.com for three age group readers such as elementary school children, teenagers, and adults. The experimental results obtained 0.9406, 0.9341, and 0.9374 of precision, recall, and F-score respectively. This experiment also reported that for the datasets that were not stemmed performed better than those that were stemmed. It shows that the stemming process, which usually be done in the document classification, throws some information in the Indonesian texts. However, because this behavior was not happen on nouns, our future work is to elaborate further on the role of affixations in the lower age group documents. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "D-ISDET: Double Intensity of Image Shadow Detection and Elimination in Autonomous Vehicle"
        ],
        "penulis":"Risnandar;Wardoyo, Riyo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We nominate the double intensity of image shadow detection and elimination method which is called D-ISDET. It offers to restore the invisible image information in the image which is covered by the shadows. The D-ISDET which supports the certainty of object detection in the autonomous vehicle is running well. Hence, the disparity of the shadowed space and the true non-shadowed space can be distinguished with using the double intensity and threshold methods. Likewise, in the big problem of imprecise detection of low-shadows and the perplexed shadows, the double intensity method is endorsed to reinforce the true shadow spaces, thereby the threshold method abolishes the shadow correctly. The experimental results of D-ISDET performance indicate the enhancement of the BER and RMSE indexes for shadow detection and elimination, respectively. D-ISDET outshines achievement between 0.24% and 1.85% of the shadow area detection and between 1.42% and 3.05% of the shadow-free area detection compared to the other methods. D-ISDET also works out between 4.11% and 16.59% of the shadow elimination and D-ISDET reaches between 0.60% and 16.57% of shadow-free elimination compared to the other methods. D-ISDET also carries out the first-rate performance compared with the other methods. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We nominate the double intensity of image shadow detection and elimination method which is called D-ISDET. It offers to restore the invisible image information in the image which is covered by the shadows. The D-ISDET which supports the certainty of object detection in the autonomous vehicle is running well. Hence, the disparity of the shadowed space and the true non-shadowed space can be distinguished with using the double intensity and threshold methods. Likewise, in the big problem of imprecise detection of low-shadows and the perplexed shadows, the double intensity method is endorsed to reinforce the true shadow spaces, thereby the threshold method abolishes the shadow correctly. The experimental results of D-ISDET performance indicate the enhancement of the BER and RMSE indexes for shadow detection and elimination, respectively. D-ISDET outshines achievement between 0.24% and 1.85% of the shadow area detection and between 1.42% and 3.05% of the shadow-free area detection compared to the other methods. D-ISDET also works out between 4.11% and 16.59% of the shadow elimination and D-ISDET reaches between 0.60% and 16.57% of shadow-free elimination compared to the other methods. D-ISDET also carries out the first-rate performance compared with the other methods. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Proximity and Dynamic Device Pairing based Authentication for IoT End Devices with Decision Tree Method"
        ],
        "penulis":"Bagaskara, Heka;Putrada, Aji Gautama;Ariyanto, Endro;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Recent researches have implemented a lot of IoT. The problem that is often faced is IoT end devices are still not user friendly in its configuration. There are still many device configurations are located at firmware level and only developers have access to firmware level and configure it. The user is still confused in configuring IoT end device. This researches proposes to apply pairing to IoT end devices. Pairing has been used by several IoT end device that are already on the market but can still be developed. Therefore, researches have been directed to designing a system that makes pairing IoT end devices easier. So that the configuration is not done at firmware level but at the application level. Users can pair an Android smartphone with an IoT end device and configure such as choosing Access Point in application. Application use proximity authentication, where pairing authentication is obtained by analyzing movements that affect RSSI variation. In addition, the system also implements dynamic device pairing to make pairing easier by viewing connection history. For determining the connection between an Android smartphone and an IoT end device, a Decision Tree is used. By using these systems and methods, the accuracy obtained is 92.19%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recent researches have implemented a lot of IoT. The problem that is often faced is IoT end devices are still not user friendly in its configuration. There are still many device configurations are located at firmware level and only developers have access to firmware level and configure it. The user is still confused in configuring IoT end device. This researches proposes to apply pairing to IoT end devices. Pairing has been used by several IoT end device that are already on the market but can still be developed. Therefore, researches have been directed to designing a system that makes pairing IoT end devices easier. So that the configuration is not done at firmware level but at the application level. Users can pair an Android smartphone with an IoT end device and configure such as choosing Access Point in application. Application use proximity authentication, where pairing authentication is obtained by analyzing movements that affect RSSI variation. In addition, the system also implements dynamic device pairing to make pairing easier by viewing connection history. For determining the connection between an Android smartphone and an IoT end device, a Decision Tree is used. By using these systems and methods, the accuracy obtained is 92.19%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Dietary Habits for Toddler Growth using Particles Swarm Optimization Algorithms"
        ],
        "penulis":"Ayu Sulistiani, Queenisti Dyah;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The age grouping of children used in the health program at the Indonesian Ministry of Health, the term baby (0 to less than one year), toddler (1 to 3 years), and preschool (3 to 5 years). Giving the wrong food to children can cause children to experience malnutrition. The danger of malnutrition in children for a long time can cause stunting. Stunting is a condition of growth failure in children (body and brain growth) due to a lack of nutrition for a long time. Thus, the child is shorter than normal children his age and has a delay in thinking. Malnourished children do not only have an impact on health complaints in the future. But it also makes children unable to grow optimally, thus interfering with their productivity when they grow up. Nutritional needs are an important factor during a child's growth period. In preparing a diet, you must pay attention to a balanced and varied menu, including the type of food in an appropriate amount. To meet the body's nutritional needs for the maintenance of cells in the body and the process of child development. Therefore, an application was created that can provide a combination of menus and dietary patterns for toddler and preschool age. This application uses the Particle Swarm Optimization algorithm in finding the best menu combination according to the child's age and physical condition. The results obtained in this study are dietary suggestions for toddlers and preschool age. The system test results have an accuracy of 90%. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentZero hungerGoal 2",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The age grouping of children used in the health program at the Indonesian Ministry of Health, the term baby (0 to less than one year), toddler (1 to 3 years), and preschool (3 to 5 years). Giving the wrong food to children can cause children to experience malnutrition. The danger of malnutrition in children for a long time can cause stunting. Stunting is a condition of growth failure in children (body and brain growth) due to a lack of nutrition for a long time. Thus, the child is shorter than normal children his age and has a delay in thinking. Malnourished children do not only have an impact on health complaints in the future. But it also makes children unable to grow optimally, thus interfering with their productivity when they grow up. Nutritional needs are an important factor during a child's growth period. In preparing a diet, you must pay attention to a balanced and varied menu, including the type of food in an appropriate amount. To meet the body's nutritional needs for the maintenance of cells in the body and the process of child development. Therefore, an application was created that can provide a combination of menus and dietary patterns for toddler and preschool age. This application uses the Particle Swarm Optimization algorithm in finding the best menu combination according to the child's age and physical condition. The results obtained in this study are dietary suggestions for toddlers and preschool age. The system test results have an accuracy of 90%. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "New product development architectural framework for sustainability and innovation within telecommunication industry"
        ],
        "penulis":"Lubis, Muharman;Fathoni, Muhammad;Lubis, Arif Ridho;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "New product development is a ready-to-use innovation method that elaborate the relevant factors such as production and development cost, time to market and product value to own a higher level of technical, logical and organizational uncertainty rather than simply redesigning the product to attract the customer. Given the increasing uncertainty in the new product development process, standard general rules cannot be applied to improving an existing product and it is necessary to conduct a more open stage of brainstorming. This study explores the investigation phase and design approach to developing a new product development framework that includes resources, activity and interference by examining three telecommunication companies as case study. To allow the identification reveal comprehensive, concrete and consistent component, the study focused on several companies within the telecommunication industry. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "New product development is a ready-to-use innovation method that elaborate the relevant factors such as production and development cost, time to market and product value to own a higher level of technical, logical and organizational uncertainty rather than simply redesigning the product to attract the customer. Given the increasing uncertainty in the new product development process, standard general rules cannot be applied to improving an existing product and it is necessary to conduct a more open stage of brainstorming. This study explores the investigation phase and design approach to developing a new product development framework that includes resources, activity and interference by examining three telecommunication companies as case study. To allow the identification reveal comprehensive, concrete and consistent component, the study focused on several companies within the telecommunication industry. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Prediction of Sea Level by Using Autoregressive Integrated Moving Average (ARIMA): Case Study in Tanjung Intan Harbour Cilacap, Indonesia"
        ],
        "penulis":"Purba, Yehezkiel K. A.;Saepudin, Deni;Adytia, Didit;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Sea Level forecasting is vital for shores engineering applications such as for engineering construction plan in the shore or in offshore, and routing of ships at harbor. Researchers have been conducting many methods to predict sea levels, such as Artificial Neural Network, SARIMA, and ARIMA. In this paper, we will use a model of Autoregressive Integrated Moving Average (ARIMA) to predict sea level in Cilacap, Indonesia. The ARIMA parameters are obtained by conducting parameter tuning so that the model gives the lowest root mean square error value (RMSE) and the highest correlation coefficient.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sea Level forecasting is vital for shores engineering applications such as for engineering construction plan in the shore or in offshore, and routing of ships at harbor. Researchers have been conducting many methods to predict sea levels, such as Artificial Neural Network, SARIMA, and ARIMA. In this paper, we will use a model of Autoregressive Integrated Moving Average (ARIMA) to predict sea level in Cilacap, Indonesia. The ARIMA parameters are obtained by conducting parameter tuning so that the model gives the lowest root mean square error value (RMSE) and the highest correlation coefficient.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Comparison of File Transfer Protocol Service between Link State and Distance Vector Routing Protocol in Software Defined Network"
        ],
        "penulis":"Tulloh, Rohmat;Amri Ginting, Jafaruddin Gusti;Mulyana, Asep;Lutfi, Muhammad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Software-Defined Network (SDN) is a new concept in computer networks where the network control function is separated from the data forwarding function (data plane). The control plane and data plane which are separated from each other is the answer for faster, more flexible, and secure internet service. File transfer protocol (FTP) is an internet protocol that runs at the application layer that is used to exchange data between server and client. Open Shortest Path First (OSPF) is a routing protocol for internet networks that belongs to the Interior Gateway Protocol (IGP) group and uses the Link State Routing algorithm (LSR). Routing Information Protocol (RIP) is a type of Distance Vector Routing protocol that is still used today. This study aims to compare the performance of FTP services using OSPF and RIP on SDN networks and conventional networks. The research was conducted with direct implementation on the device with a planned topology. The measurement results show that FTP using OSPF routing has better results than using RIP. FTP that runs on SDN also has a better quality of service value compared to conventional networks.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Software-Defined Network (SDN) is a new concept in computer networks where the network control function is separated from the data forwarding function (data plane). The control plane and data plane which are separated from each other is the answer for faster, more flexible, and secure internet service. File transfer protocol (FTP) is an internet protocol that runs at the application layer that is used to exchange data between server and client. Open Shortest Path First (OSPF) is a routing protocol for internet networks that belongs to the Interior Gateway Protocol (IGP) group and uses the Link State Routing algorithm (LSR). Routing Information Protocol (RIP) is a type of Distance Vector Routing protocol that is still used today. This study aims to compare the performance of FTP services using OSPF and RIP on SDN networks and conventional networks. The research was conducted with direct implementation on the device with a planned topology. The measurement results show that FTP using OSPF routing has better results than using RIP. FTP that runs on SDN also has a better quality of service value compared to conventional networks.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Automated white blood cell counting in nailfold capillary using deep learning segmentation and video stabilization"
        ],
        "penulis":"Kim, Byeonghwi;Hariyani, Yuli-Sun;Cho, Young-Ho;Park, Cheolsoo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "White blood cells (WBCs) are essential components of the immune system in the human body. Various invasive and noninvasive methods to monitor the condition of the WBCs have been developed. Among them, a noninvasive method exploits an optical characteristic of WBCs in a nailfold capillary image, as they appear as visual gaps. This method is inexpensive and could possibly be implemented on a portable device. However, recent studies on this method use a manual or semimanual image segmentation, which depends on recognizable features and the intervention of experts, hindering its scalability and applicability. We address and solve this problem with proposing an automated method for detecting and counting WBCs that appear as visual gaps on nailfold capillary images. The proposed method consists of an automatic capillary segmentation method using deep learning, video stabilization, and WBC event detection algorithms. Performances of the three segmentation algorithms (manual, conventional, and deep learning) with\/without video stabilization were benchmarks. Experimental results demonstrate that the proposed method improves the performance of the WBC event counting and outperforms conventional approaches. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "RnView detailsExpand Substance radon",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "White blood cells (WBCs) are essential components of the immune system in the human body. Various invasive and noninvasive methods to monitor the condition of the WBCs have been developed. Among them, a noninvasive method exploits an optical characteristic of WBCs in a nailfold capillary image, as they appear as visual gaps. This method is inexpensive and could possibly be implemented on a portable device. However, recent studies on this method use a manual or semimanual image segmentation, which depends on recognizable features and the intervention of experts, hindering its scalability and applicability. We address and solve this problem with proposing an automated method for detecting and counting WBCs that appear as visual gaps on nailfold capillary images. The proposed method consists of an automatic capillary segmentation method using deep learning, video stabilization, and WBC event detection algorithms. Performances of the three segmentation algorithms (manual, conventional, and deep learning) with\/without video stabilization were benchmarks. Experimental results demonstrate that the proposed method improves the performance of the WBC event counting and outperforms conventional approaches. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Robust license plate detection in complex scene using MSER-Dominant Vertical Sobel"
        ],
        "penulis":"Kosala, Gamma;Harjoko, Agus;Hartati, Sri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents a robust method to locate a license plate in a complex scene. In contrast to the most existing method which use the non-handcrafted feature to locate the license plate area, our method uses a modified handcrafted feature. We used Maximally Stable Extremal Region (MSER) combining with dominant vertical Sobel to construct essential biner images. Closing morphology operation is implemented to merge the contour extracted by MSER and dominant vertical edge detection. Based on the area and ratio of contour, license plate candidate area is selected. Furthermore, Support Vector Machine (SVM) is introduced to choose a license plate area by analyzing the Histogram of Oriented Gradient (HOG) of each candidate. For performance evaluation, two datasets consisting of complex scene images under different conditions are tested. The main advantage of this approach is that it is faster than non-handcrafted feature-based method while maintaining the high accuracy of plate detection. \u00a9 2020, International Association of Engineers.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents a robust method to locate a license plate in a complex scene. In contrast to the most existing method which use the non-handcrafted feature to locate the license plate area, our method uses a modified handcrafted feature. We used Maximally Stable Extremal Region (MSER) combining with dominant vertical Sobel to construct essential biner images. Closing morphology operation is implemented to merge the contour extracted by MSER and dominant vertical edge detection. Based on the area and ratio of contour, license plate candidate area is selected. Furthermore, Support Vector Machine (SVM) is introduced to choose a license plate area by analyzing the Histogram of Oriented Gradient (HOG) of each candidate. For performance evaluation, two datasets consisting of complex scene images under different conditions are tested. The main advantage of this approach is that it is faster than non-handcrafted feature-based method while maintaining the high accuracy of plate detection. \u00a9 2020, International Association of Engineers."
        ]
    },
    {
        "judul":[
            "Model of tools for requirements elicitation process for children's learning applications"
        ],
        "penulis":"Sabariah, Mira Kania;Santosa, Paulus Insap;Ferdiana, Ridi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Requirements Elicitation are the initial stages in the application development process, where a set of needs from the system will be built and obtained by communicating with stakeholders who have a direct and indirect influence on those needs. Failure in the requirements elicitation process was caused by weak communication. Communication is an essential thing in carrying out the requirements elicitation process. The selection of the right elicitation technique is not only a solution. Informants as sources of information on requirements also need to be considered. The choice of the correct technique often fails because of the tools not useful. The availability of the right form of equipment needs to be considered so that the communication between the elicitation team and the informant goes well. Children have characteristics not the same as adults. Limitations in terms of psychomotor, cognitive, and emotional children are considered in choosing elicitation techniques and tools. These limitations are also influenced by the age range of child development. The use of digital elicitation devices is recommended to be used in the requirements elicitation process. The presentation of interactive tools makes it easier for children to convey their desires. In learning applications for children, aspects of pedagogy that need to be explored are learning styles and children's thinking abilities. Every child in every age range has a different preference for learning style. That is because children do not have learning experiences. That also applies to the level of thinking ability of children. Therefore, these two things need to be appropriately explored when the learning application development process. The proposed elicitation tool model was made by taking into account both components of that pedagogical aspects. The test results of the built model show that the application has satisfaction. That means that children can communicate well in conveying the needed as requirements to the learning application. \u00a9 2020, Science and Information Organization."
        ],
        "abstrak":[
            "Requirements Elicitation are the initial stages in the application development process, where a set of needs from the system will be built and obtained by communicating with stakeholders who have a direct and indirect influence on those needs. Failure in the requirements elicitation process was caused by weak communication. Communication is an essential thing in carrying out the requirements elicitation process. The selection of the right elicitation technique is not only a solution. Informants as sources of information on requirements also need to be considered. The choice of the correct technique often fails because of the tools not useful. The availability of the right form of equipment needs to be considered so that the communication between the elicitation team and the informant goes well. Children have characteristics not the same as adults. Limitations in terms of psychomotor, cognitive, and emotional children are considered in choosing elicitation techniques and tools. These limitations are also influenced by the age range of child development. The use of digital elicitation devices is recommended to be used in the requirements elicitation process. The presentation of interactive tools makes it easier for children to convey their desires. In learning applications for children, aspects of pedagogy that need to be explored are learning styles and children's thinking abilities. Every child in every age range has a different preference for learning style. That is because children do not have learning experiences. That also applies to the level of thinking ability of children. Therefore, these two things need to be appropriately explored when the learning application development process. The proposed elicitation tool model was made by taking into account both components of that pedagogical aspects. The test results of the built model show that the application has satisfaction. That means that children can communicate well in conveying the needed as requirements to the learning application. \u00a9 2020, Science and Information Organization."
        ]
    },
    {
        "judul":[
            "Voice Delivery using the Visible Light Communication (VLC) Prototype on Line of Sight (LOS) Channels"
        ],
        "penulis":"Putri, Dewandari Adi Antika;Hambali, Akhmad;Sugesti, Erna Sri;Pamukti, Brian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Visible Light Communication (VLC) is the one of technologies used for 6th generation of telecommunications (6G), because it has a wide frequency spectrum, higher speed and safety. We have conducted an experiment using a prototype to transmit sound. Measurements were made by changing the receiving distance from 30 cm up to 300 cm in increments of 30 cm. We also shift the receiving device, so that it forms an angle 0\u00b0 up to 30\u00b0. This study analyzes the extent of changes in distance and angle to the measurement results. We use a Lux meter measurement of the light intensity received by the receiver. In addition, we also measure the ratio of the sound sent to the received by measuring dB meter. From the results of extensive testing, we got the result that the farther distance, then the sound quality is getting lower. For the 0\u00b0 angle obtained a propagation distance limit of up to 250 cm, 15\u00b0 angle 200 cm away and 30\u00b0 angle up to 150 cm. In addition, we also found that the magnitude of the angle shift decreased the intensity of the received light. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Visible Light Communication (VLC) is the one of technologies used for 6th generation of telecommunications (6G), because it has a wide frequency spectrum, higher speed and safety. We have conducted an experiment using a prototype to transmit sound. Measurements were made by changing the receiving distance from 30 cm up to 300 cm in increments of 30 cm. We also shift the receiving device, so that it forms an angle 0\u00b0 up to 30\u00b0. This study analyzes the extent of changes in distance and angle to the measurement results. We use a Lux meter measurement of the light intensity received by the receiver. In addition, we also measure the ratio of the sound sent to the received by measuring dB meter. From the results of extensive testing, we got the result that the farther distance, then the sound quality is getting lower. For the 0\u00b0 angle obtained a propagation distance limit of up to 250 cm, 15\u00b0 angle 200 cm away and 30\u00b0 angle up to 150 cm. In addition, we also found that the magnitude of the angle shift decreased the intensity of the received light. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Application of technometric to improve productivity in indonesian small medium industries (Smi)"
        ],
        "penulis":"Rumanti, Augustina Asih;Wiradmadja, Iwan Inrawan;Ajidarma, Praditya;Hidayat, Melita;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Small Medium Industry (SMI) is a group of small company that are heterogeneous in size and attitude and contribute significantly towards Indonesia\u2019s gross labor production. SMIs are expected to keep producing in a good quantity and quality to satisfy consumer and to maintain its productivity. The object of this research is Ira Silver, an SMI located in Yogyakarta, Indonesia. This study aims to measure current state of technology level within the SMI and find a correlation between such technology components and productivity. There are three concluding points made in this study. First, technometric method shows that the score of humanware and orgaware components are considerably low in terms of state of the art. Second, the result shown by SmartPLS software shows that technology components have a positive correlation to productivity, which means that SMI\u2019s productivity can be leveraged through the four technology components: technoware, humanware, infoware, and orgaware. However, only humanware component is proven to have a significant correlation to the SMI\u2019s productivity. Lastly, through this result, productivity could be enhanced by fixing humanware component at Ira Silver, so that state of the arts core in humanware component and productivity at Ira Silver can be increased. \u00a9 Springer Nature Singapore Pte Ltd. 2020.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Small Medium Industry (SMI) is a group of small company that are heterogeneous in size and attitude and contribute significantly towards Indonesia\u2019s gross labor production. SMIs are expected to keep producing in a good quantity and quality to satisfy consumer and to maintain its productivity. The object of this research is Ira Silver, an SMI located in Yogyakarta, Indonesia. This study aims to measure current state of technology level within the SMI and find a correlation between such technology components and productivity. There are three concluding points made in this study. First, technometric method shows that the score of humanware and orgaware components are considerably low in terms of state of the art. Second, the result shown by SmartPLS software shows that technology components have a positive correlation to productivity, which means that SMI\u2019s productivity can be leveraged through the four technology components: technoware, humanware, infoware, and orgaware. However, only humanware component is proven to have a significant correlation to the SMI\u2019s productivity. Lastly, through this result, productivity could be enhanced by fixing humanware component at Ira Silver, so that state of the arts core in humanware component and productivity at Ira Silver can be increased. \u00a9 Springer Nature Singapore Pte Ltd. 2020."
        ]
    },
    {
        "judul":[
            "Identification of the changing air temperature and rainfall in Bogor"
        ],
        "penulis":"Hidayat, Rahmat;Farihah, Alfi Wardah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Climate datasets were analyzed to identify the changing climatic parameters and extreme events in Bogor, West Java. This study aims to analyze the characteristic of observational datasets in Baranangsiang and Dramaga, namely, air temperature and rainfall, and to identify the changing structure of those climate parameters. The analysis has been conducted using RClimdex to understand the long-term changing air temperature and rainfall based on 10 indices for air temperature and 8 indices for temperature and rainfall. Results show that the rainfall in Baranangsiang has a daily mean of 10 mm\/day and in Dramaga of 8 mm\/day. The daily mean air temperature in Baranangsiang and Dramaga is 27\u02daC and 25.5\u02daC, respectively. Generally, the declined slopes of the temperature indices in Barangsiang, namely, TN90p, TNx, TX10p, TNn, TXn, TR20, and SU25, indicate cooler temperature. In Dramaga, the increased temperature indices, namely, TN90p, TX90p, TXx, SU25, and TXn, indicate the warmer temperature. The rainfall indices generally decline, except for consecutive dry days (CDD), which indicate the increased consecutive dry days in Baranangsiang. \u00a9 2020, Pusat Penelitian Lingkungan Hidup - Lembaga Penelitian dan Pengabdian Kepada Masyarakat Institut Pertanian Bogor (PPLH-LPPM IPB). All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Climate datasets were analyzed to identify the changing climatic parameters and extreme events in Bogor, West Java. This study aims to analyze the characteristic of observational datasets in Baranangsiang and Dramaga, namely, air temperature and rainfall, and to identify the changing structure of those climate parameters. The analysis has been conducted using RClimdex to understand the long-term changing air temperature and rainfall based on 10 indices for air temperature and 8 indices for temperature and rainfall. Results show that the rainfall in Baranangsiang has a daily mean of 10 mm\/day and in Dramaga of 8 mm\/day. The daily mean air temperature in Baranangsiang and Dramaga is 27\u02daC and 25.5\u02daC, respectively. Generally, the declined slopes of the temperature indices in Barangsiang, namely, TN90p, TNx, TX10p, TNn, TXn, TR20, and SU25, indicate cooler temperature. In Dramaga, the increased temperature indices, namely, TN90p, TX90p, TXx, SU25, and TXn, indicate the warmer temperature. The rainfall indices generally decline, except for consecutive dry days (CDD), which indicate the increased consecutive dry days in Baranangsiang. \u00a9 2020, Pusat Penelitian Lingkungan Hidup - Lembaga Penelitian dan Pengabdian Kepada Masyarakat Institut Pertanian Bogor (PPLH-LPPM IPB). All rights reserved."
        ]
    },
    {
        "judul":[
            "Building a smart city 4.0 ecosystem platform: An overview and case study"
        ],
        "penulis":"Nugraha, Yudhistira;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents an overview of a smart city 4.0 framework in accelerating digital transformation, especially during the COVID-19 pandemic, using Jakarta as a case study. The findings of this study provide new insights how to translate a vision into a reality in the form of smart city 4.0 framework that offers a significant opportunity to advance the understanding of building a smart city ecosystem with technologies, innovations and collaborations. This paper applies four principles of the framework, namely mobile-first, system-and-data driven, digital experience, and smart collaboration in building a smart city 4.0 ecosystem platform. Part of the aim of this paper is to examine Jakarta's super-app called JAKI that is compatible with such principles as a use case in the time of the pandemic. It provides a better understanding of common elements in building a new concept of a smart city. The results will inspire and give a contribution to other cities to consider the framework in building a smart city 4.0 ecosystem platform to foster quality of life, economic growth and sustainability. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents an overview of a smart city 4.0 framework in accelerating digital transformation, especially during the COVID-19 pandemic, using Jakarta as a case study. The findings of this study provide new insights how to translate a vision into a reality in the form of smart city 4.0 framework that offers a significant opportunity to advance the understanding of building a smart city ecosystem with technologies, innovations and collaborations. This paper applies four principles of the framework, namely mobile-first, system-and-data driven, digital experience, and smart collaboration in building a smart city 4.0 ecosystem platform. Part of the aim of this paper is to examine Jakarta's super-app called JAKI that is compatible with such principles as a use case in the time of the pandemic. It provides a better understanding of common elements in building a new concept of a smart city. The results will inspire and give a contribution to other cities to consider the framework in building a smart city 4.0 ecosystem platform to foster quality of life, economic growth and sustainability. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Evaluation of Effectiveness and Cost of Machine Losses using Overall Equipment Effectiveness (OEE) and Overall Equipment Cost Loss (OECL) Methods, a case study on Toshiba CNC Machine"
        ],
        "penulis":"Dewi, Sarastya;Alhilman, Judi;Atmaji, Fransiskus Tatas Dwi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In a manufacturing company, the machine is one of the most important elements in their production process because machine failure can stop the production process. Therefore, the initial step to minimizing losses caused by machine failure can be done by evaluating the machine condition. Evaluation of machine performance is carried out by measuring the effectiveness of the machine with the Overall Equipment Effectiveness (OEE) method. Based on the calculation result, the OEE value of the machine is 68.63% and this value still under the Japanese Institute of Plant Maintenance standard. Six big losses analysis is performed to determine the biggest loss that affects the effectiveness of the machine. The result of six big losses calculation shows that the most influential factor for the low OEE value of the machine is Reduced Speed Loss (39.12%). Causal analysis with a fishbone diagram is done to find out the causes of the highly reduced speed loss. To calculate the equipment cost loss use the Overall Equipment Cost Loss (OECL) methods. The total of the overall equipment cost loss is IDR 849, 839, 947.53. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a manufacturing company, the machine is one of the most important elements in their production process because machine failure can stop the production process. Therefore, the initial step to minimizing losses caused by machine failure can be done by evaluating the machine condition. Evaluation of machine performance is carried out by measuring the effectiveness of the machine with the Overall Equipment Effectiveness (OEE) method. Based on the calculation result, the OEE value of the machine is 68.63% and this value still under the Japanese Institute of Plant Maintenance standard. Six big losses analysis is performed to determine the biggest loss that affects the effectiveness of the machine. The result of six big losses calculation shows that the most influential factor for the low OEE value of the machine is Reduced Speed Loss (39.12%). Causal analysis with a fishbone diagram is done to find out the causes of the highly reduced speed loss. To calculate the equipment cost loss use the Overall Equipment Cost Loss (OECL) methods. The total of the overall equipment cost loss is IDR 849, 839, 947.53. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Classifying the Polarity of Online Media on the Indonesia Presidential Election 2019 Using Artificial Neural Network"
        ],
        "penulis":"Farisi, Muhammad Afif;Lhaksmana, Kemas M.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The 2019 presidential election is one of the mandatory national agendas that is covered by all of the mainstream news media in Indonesia. The function of news media as an information provider reaps criticism because they are suspected of having polarity towards certain candidates. In this paper, the polarity of news media is analyzed by performing sentiment assessment towards every news regarding each candidate. Since manual sentiment analysis is costly and time-consuming, because of the large amount of data that needs to be processed, we adopt a machine learning method to automate the sentiment analysis process. This research employs Artificial Neural Network (ANN) to classify scraped news texts from online media and TF-IDF weighting method for feature extraction. We found that the observed online media kompas.com, liputan tan6.com, republika.co.id, and tempo.co do not have significant polarity toward one of the candidates. In addition to ANN, we also compared other methods to investigate the appropriate methods for our dataset. Our experiment shows that on average, ANN obtains the best accuracy at 84.57%, compares to Decision Tree C4.5 (83.34%), Naive Bayes (SO.42%), and SVM (79.04%).  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The 2019 presidential election is one of the mandatory national agendas that is covered by all of the mainstream news media in Indonesia. The function of news media as an information provider reaps criticism because they are suspected of having polarity towards certain candidates. In this paper, the polarity of news media is analyzed by performing sentiment assessment towards every news regarding each candidate. Since manual sentiment analysis is costly and time-consuming, because of the large amount of data that needs to be processed, we adopt a machine learning method to automate the sentiment analysis process. This research employs Artificial Neural Network (ANN) to classify scraped news texts from online media and TF-IDF weighting method for feature extraction. We found that the observed online media kompas.com, liputan tan6.com, republika.co.id, and tempo.co do not have significant polarity toward one of the candidates. In addition to ANN, we also compared other methods to investigate the appropriate methods for our dataset. Our experiment shows that on average, ANN obtains the best accuracy at 84.57%, compares to Decision Tree C4.5 (83.34%), Naive Bayes (SO.42%), and SVM (79.04%).  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Anomaly Behavior Detection of Angkot Based on Transportation Data"
        ],
        "penulis":"Nurmalasari, Rin Rin;Putri, Elbananda Permana;Prihatmanto, Ary Setijadi;Yusuf, Rahadian;Wijaya, Rifki;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Public transportation in Indonesia as a developing country differs from developed country, and there is a certain public transportation called angkot (angkutan kota, or city transport), which became the focus of our research. This paper presents the experiments on data transportation to analyze and detect anomaly behavior of angkot. The focus is on discussing the results of experiments to calculate the length of waiting time for angkot at hotspots, clustering of angkot trips patterns and building a model to detect anomaly behavior of angkot. The results of the review and experiment indicate the length of the time needed for angkot in waiting for the passengers and show which angkot that exceeds the normal time limit set by the government in waiting for the passengers, which suggests a deviant behavior. The results for clustering angkot that have similiar trips patterns using principal component analysis and K-Means give fairly high accuracy. The result for detection of anomaly behavior using autoencoder and Long Short-Term Memory (LSTM) can be used to detect anomaly behavior of angkot when data are collected without labels. The results of the evaluation of model have a loss mean absolute error (MAE) value which is getting smaller. In addition, the output data from the detection of anomaly behavior using autoencoder and LSTM will automatically be labeled true or false, which indicates true if there is an anomalous behavior, while false if there is no anomaly behavior.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Public transportation in Indonesia as a developing country differs from developed country, and there is a certain public transportation called angkot (angkutan kota, or city transport), which became the focus of our research. This paper presents the experiments on data transportation to analyze and detect anomaly behavior of angkot. The focus is on discussing the results of experiments to calculate the length of waiting time for angkot at hotspots, clustering of angkot trips patterns and building a model to detect anomaly behavior of angkot. The results of the review and experiment indicate the length of the time needed for angkot in waiting for the passengers and show which angkot that exceeds the normal time limit set by the government in waiting for the passengers, which suggests a deviant behavior. The results for clustering angkot that have similiar trips patterns using principal component analysis and K-Means give fairly high accuracy. The result for detection of anomaly behavior using autoencoder and Long Short-Term Memory (LSTM) can be used to detect anomaly behavior of angkot when data are collected without labels. The results of the evaluation of model have a loss mean absolute error (MAE) value which is getting smaller. In addition, the output data from the detection of anomaly behavior using autoencoder and LSTM will automatically be labeled true or false, which indicates true if there is an anomalous behavior, while false if there is no anomaly behavior.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Robust audio watermarking based on transform domain and SVD with compressive sampling framework"
        ],
        "penulis":"Novamizanti, Ledya;Budiman, Gelar;Astuti, Elsa Nur Fitri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The growth of the internet and digital data has resulted forgery, modification and sharing of digital data without property rights. Audio watermarking is one of a solution to protect the copyright of an audio from copyright infringement. This paper proposes an audio watermarking method which is robust against attacks and high capacity. First, a synchronization bit is added to the audio host. After the audio host is decomposed by Lifting Wavelet Transform (LWT), then choose a subband from the output of LWT to be transformed by discrete cosine transform (DCT). Next, the matrix of the signal from DCT is selected for the singular value decomposition (SVD) process, so that is obtained U, S and V matrix. S matrix is embedded with the watermark. Before the embedding process, the watermark image is compressed by Compressive Sampling. The results show that the proposed watermarking system is highly robust against a kind attack of LPF, resampling, and linear speed change which is proven by its BER is zero. \u00a9 2020, Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The growth of the internet and digital data has resulted forgery, modification and sharing of digital data without property rights. Audio watermarking is one of a solution to protect the copyright of an audio from copyright infringement. This paper proposes an audio watermarking method which is robust against attacks and high capacity. First, a synchronization bit is added to the audio host. After the audio host is decomposed by Lifting Wavelet Transform (LWT), then choose a subband from the output of LWT to be transformed by discrete cosine transform (DCT). Next, the matrix of the signal from DCT is selected for the singular value decomposition (SVD) process, so that is obtained U, S and V matrix. S matrix is embedded with the watermark. Before the embedding process, the watermark image is compressed by Compressive Sampling. The results show that the proposed watermarking system is highly robust against a kind attack of LPF, resampling, and linear speed change which is proven by its BER is zero. \u00a9 2020, Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Development of security awareness domain and resources (SADAR) Framework: Capacity metrics to evaluate enterprise resource planning (ERP) Implementation"
        ],
        "penulis":"Lubis, Muharman;Novalia, Dina;Puspita;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One way to anticipate the failure of ERP products in the company is by increasing information security awareness (ISA). It is a starting point for every employee to feel like important part of an organization by understanding the implication of security threat and vulnerability to their future life. In terms of ISA, there are various element that should be considered such as human factor, institutional regulation, environmental condition and activity pattern. This study want to confirm the relationship of several element to determine the effect of ISA on the implementation of ERP in the company. Previous research of SADAR (Security Awareness Domain and Resources) framework has been used as the basis by adding several indicator in the incentive appreciation for institutional antecedent. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One way to anticipate the failure of ERP products in the company is by increasing information security awareness (ISA). It is a starting point for every employee to feel like important part of an organization by understanding the implication of security threat and vulnerability to their future life. In terms of ISA, there are various element that should be considered such as human factor, institutional regulation, environmental condition and activity pattern. This study want to confirm the relationship of several element to determine the effect of ISA on the implementation of ERP in the company. Previous research of SADAR (Security Awareness Domain and Resources) framework has been used as the basis by adding several indicator in the incentive appreciation for institutional antecedent. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Integrated clustering of creative industries to foster innovation: Bandung's creative industries"
        ],
        "penulis":"Aldianto, Leo;Wirawan, Christina;Anggadwita, Grisna;Rizqi, Vania Nur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Creative industries capture new economic dynamics based on creativity, skills, and talents. Creative industries grow fast and contribute more to the national economic development. In order to sustain contributions to economic development, creative industries need to innovate productively. One way to encourage innovation is to foster co-creation by strengthening the effectiveness of creative industry relationships with stakeholders, such as the community, consumers, suppliers, and other creative industries, as well as to generate information and knowledge to support them. An integrated cluster will support industry efficiency; better facilities; infrastructure; amenities; services; as well as better protection of the environment and social relationships. Placing creative industries in an integrated cluster will provide better collaboration opportunities that will support co-creation to trigger innovation. This paper will provide a conceptual framework of an integrated symbiosis of creative industry clustering to foster their innovation toward sustainability and high performance using the value co-creation platform concept. Copyright \u00a9 2020 Inderscience Enterprises Ltd.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Creative industries capture new economic dynamics based on creativity, skills, and talents. Creative industries grow fast and contribute more to the national economic development. In order to sustain contributions to economic development, creative industries need to innovate productively. One way to encourage innovation is to foster co-creation by strengthening the effectiveness of creative industry relationships with stakeholders, such as the community, consumers, suppliers, and other creative industries, as well as to generate information and knowledge to support them. An integrated cluster will support industry efficiency; better facilities; infrastructure; amenities; services; as well as better protection of the environment and social relationships. Placing creative industries in an integrated cluster will provide better collaboration opportunities that will support co-creation to trigger innovation. This paper will provide a conceptual framework of an integrated symbiosis of creative industry clustering to foster their innovation toward sustainability and high performance using the value co-creation platform concept. Copyright \u00a9 2020 Inderscience Enterprises Ltd."
        ]
    },
    {
        "judul":[
            "Linkages of financial efficacy, demographics, risks preference and consumption behavior in Malaysia"
        ],
        "penulis":"Kusairi, Suhal;Sanusi, Nur Azura;Muhamad, Suriyani;Shukri, Madihah;Zamri, Nadia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Financial literacy is one of the sustainable development goals of huge concern of governments. Governments explore solutions addressing policies to improve financial literacy. Nevertheless, financial management has such a broad scope and is not just limited to knowledge. As human nature, individuals are born with different confidence levels that include various financial abilities. This study aims to investigate the household-financial efficacy through the application of psychometric instruments, risk preference, and demographic characteristics toward consumption decision behavior. The research is based on a survey 479 households in the peninsular Malaysia, and utilizes the structural equation model, cluster proportional and systematic random sampling, and two measurements-composite reliability and average variance extracted. Results show that households' financial efficacy is one of the critical factors that explain the households' consumption decision behavior. Also, risk preference, gender and area location (rural or urban) of the household determined the consumption decision behavior of the household. The effectiveness of consumption decision is not only determined by financial literacy, but also financial efficacy. The implications of this paper may help to design policies in narrowing the broad gap between the rural and urban level of financial efficacy. The government needs to take appropriate actions to fix it. \u00a9 The Author(s).",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Financial literacy is one of the sustainable development goals of huge concern of governments. Governments explore solutions addressing policies to improve financial literacy. Nevertheless, financial management has such a broad scope and is not just limited to knowledge. As human nature, individuals are born with different confidence levels that include various financial abilities. This study aims to investigate the household-financial efficacy through the application of psychometric instruments, risk preference, and demographic characteristics toward consumption decision behavior. The research is based on a survey 479 households in the peninsular Malaysia, and utilizes the structural equation model, cluster proportional and systematic random sampling, and two measurements-composite reliability and average variance extracted. Results show that households' financial efficacy is one of the critical factors that explain the households' consumption decision behavior. Also, risk preference, gender and area location (rural or urban) of the household determined the consumption decision behavior of the household. The effectiveness of consumption decision is not only determined by financial literacy, but also financial efficacy. The implications of this paper may help to design policies in narrowing the broad gap between the rural and urban level of financial efficacy. The government needs to take appropriate actions to fix it. \u00a9 The Author(s)."
        ]
    },
    {
        "judul":[
            "Analysis of critical success factors (CSF) in enterprise resource planning (ERP) implementation using extended technology acceptance model (TAM) at trading and distribution company"
        ],
        "penulis":"Putri, Aprilianti Dwi;Lubis, Muharman;Azizah, Anik Hanifatul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Enterprise Resource Planning (ERP) is an integrated system that has been used in several companies, including this Trading and Distribution Company. The company has implemented an ERP system at a certain time. The implementation of the ERP system not only broken off until the testing phase of the deployment process but also required some periodical analysis to improve the effectiveness. Lack of human resource skills and the business process of the company could be several major problems. Consequently, a specified analysis is needed n terms of improving the implementation of ERP in a company. The purpose of this research is to analyze the critical success factors (CSF) on ERP implementation in the company with the aim of identifying success factors that can be used to improve the performance system implementation, especially the human resource. Extended Technology Acceptance Model (TAM) was adopted to run the analysis. The research used quantitative data analysis in seeking core problems. Several variables defining CSF of ERP has built based on the TAM model. The result indicates that each variable in the model is a critical factor determining the success of the system's implementation. The result of the study could be exemplary guidance to find the CSF on ERP implementation. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Enterprise Resource Planning (ERP) is an integrated system that has been used in several companies, including this Trading and Distribution Company. The company has implemented an ERP system at a certain time. The implementation of the ERP system not only broken off until the testing phase of the deployment process but also required some periodical analysis to improve the effectiveness. Lack of human resource skills and the business process of the company could be several major problems. Consequently, a specified analysis is needed n terms of improving the implementation of ERP in a company. The purpose of this research is to analyze the critical success factors (CSF) on ERP implementation in the company with the aim of identifying success factors that can be used to improve the performance system implementation, especially the human resource. Extended Technology Acceptance Model (TAM) was adopted to run the analysis. The research used quantitative data analysis in seeking core problems. Several variables defining CSF of ERP has built based on the TAM model. The result indicates that each variable in the model is a critical factor determining the success of the system's implementation. The result of the study could be exemplary guidance to find the CSF on ERP implementation. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design of Landslide Early Warning System Using Fuzzy Method Based on Android"
        ],
        "penulis":"Fatimah, Putri;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In Indonesia, landslides are one of the many natural disasters that often occur during the rainy season. Especially in mountainous areas, cliffs, hills, which cause many losses. Therefore, it is necessary to create a landslide Early Warning System. Slope, vibration, and excessive water content in the soil are the leading causes of landslides. To measure these parameters, an Internet of Things (IoT) based system is used that is connected to various sensors. In this study, the fuzzy value obtained from the measurement of the MPU6050 Accelerometer and Gyroscope sensor, also Soil Moisture sensor sent to the Antares server using LoRa. In research, Fuzzy algorithm is used to analyze the sensor detection results in the form of three final decision rules based on the knowledge of a landslide expert, namely Safe, Alert, and Watch out, which can be seen on an android device with 90% accuracy value and 10% error. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In Indonesia, landslides are one of the many natural disasters that often occur during the rainy season. Especially in mountainous areas, cliffs, hills, which cause many losses. Therefore, it is necessary to create a landslide Early Warning System. Slope, vibration, and excessive water content in the soil are the leading causes of landslides. To measure these parameters, an Internet of Things (IoT) based system is used that is connected to various sensors. In this study, the fuzzy value obtained from the measurement of the MPU6050 Accelerometer and Gyroscope sensor, also Soil Moisture sensor sent to the Antares server using LoRa. In research, Fuzzy algorithm is used to analyze the sensor detection results in the form of three final decision rules based on the knowledge of a landslide expert, namely Safe, Alert, and Watch out, which can be seen on an android device with 90% accuracy value and 10% error. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Maritime Inventory Routing Problem: Application on Discharge the Load of the Ship in Cement Companies to Minimize the Total Transportation Cost"
        ],
        "penulis":"Yusuf, Febryan Khoirun;Ridwan, Ari Yanuar;Pambudi, Hardian Kokoh;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Distribution activities are an important part and very considered in the world of logistics because distribution is one of the key drivers of profits earned by companies. One that is related to distribution is transportation. Transportation refers to moving products from one location to another where the product moves from the beginning of the supply chain to consumers where this transportation will incur costs and is one of the costs that affect the price of a product. This research aims to schedule ship transportation from 3 production ports to 6 consumption ports with a heterogeneous fleet of ships to minimize the total transportation costs in the cement industry companies. Maritime Inventory Routing Problem (MIRP) is a problem of ship scheduling which is not only related to the distribution of products from production ports to consumption ports, it also manages the inventory at these ports and is usually used for bulk industrial products. The method used in this research is MIRP with Mixed-Integer Linear Programming (MILP) approach where this method can minimize the total transportation costs. The results show that the method used can reduce the total waiting time so that the total transportation costs are also reduced.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Distribution activities are an important part and very considered in the world of logistics because distribution is one of the key drivers of profits earned by companies. One that is related to distribution is transportation. Transportation refers to moving products from one location to another where the product moves from the beginning of the supply chain to consumers where this transportation will incur costs and is one of the costs that affect the price of a product. This research aims to schedule ship transportation from 3 production ports to 6 consumption ports with a heterogeneous fleet of ships to minimize the total transportation costs in the cement industry companies. Maritime Inventory Routing Problem (MIRP) is a problem of ship scheduling which is not only related to the distribution of products from production ports to consumption ports, it also manages the inventory at these ports and is usually used for bulk industrial products. The method used in this research is MIRP with Mixed-Integer Linear Programming (MILP) approach where this method can minimize the total transportation costs. The results show that the method used can reduce the total waiting time so that the total transportation costs are also reduced.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Self-healing corrosion protective coatings in transportation industries"
        ],
        "penulis":"Yabuki, Akihiro;Fathona, Indra W.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Self-healing is a natural ability to spontaneously cure injury or illness, and this concept is now being applied in anticorrosion coatings. Recently, the design of a self-healing coating that could provide repetitive protection was proposed. In this chapter, the types, synthesis, properties, and characteristics of smart coatings in transportation industries are described and discussed. Corrosion and protection against it in various metallic materials are briefly explained. A specific discussion in self-healing coating consisting microand nanocapsules, fibers networks are presented. The future trend of self-healing coatings for corrosion protection will be described. \u00a9 2020 Elsevier Inc. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Self-healing is a natural ability to spontaneously cure injury or illness, and this concept is now being applied in anticorrosion coatings. Recently, the design of a self-healing coating that could provide repetitive protection was proposed. In this chapter, the types, synthesis, properties, and characteristics of smart coatings in transportation industries are described and discussed. Corrosion and protection against it in various metallic materials are briefly explained. A specific discussion in self-healing coating consisting microand nanocapsules, fibers networks are presented. The future trend of self-healing coatings for corrosion protection will be described. \u00a9 2020 Elsevier Inc. All rights reserved."
        ]
    },
    {
        "judul":[
            "Level of student satisfaction with laboratory facilities using the importance performance analysis (IPA) method"
        ],
        "penulis":"Darwas, Rahmadini;Syukhri;Wulandari, Astri;Afthanorhan, Asyraf;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "STMIK Indonesia Padang is a high school in the field of computers. To produce quality human resources and be able to compete in their fields, one of the efforts is to provide facilities that support the teaching and learning process, namely the computer laboratory. STMIK Indonesia Padang laboratory facilities are adequate, however there are still complaints felt by students. This study aims to take policy in improving computer laboratory facilities. The study population was students of STMIK Indonesia Padang in 2015 and 2016 from 735 students. Based on this data, the average satisfaction score is lower than the average interest score. This means that students are less satisfied with laboratory facility services. The method used in this research is importance performance analysis (IPA). The results of data processing in the form of attributes that need to be improved quality of service with top priority are internet access in the laboratory, visual facilities as supporting learning processes in the laboratory, and the quality of the hardware used so that this research is very helpful in making future policies. \u00a9 2020, Institute of Advanced Scientific Research, Inc.. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "STMIK Indonesia Padang is a high school in the field of computers. To produce quality human resources and be able to compete in their fields, one of the efforts is to provide facilities that support the teaching and learning process, namely the computer laboratory. STMIK Indonesia Padang laboratory facilities are adequate, however there are still complaints felt by students. This study aims to take policy in improving computer laboratory facilities. The study population was students of STMIK Indonesia Padang in 2015 and 2016 from 735 students. Based on this data, the average satisfaction score is lower than the average interest score. This means that students are less satisfied with laboratory facility services. The method used in this research is importance performance analysis (IPA). The results of data processing in the form of attributes that need to be improved quality of service with top priority are internet access in the laboratory, visual facilities as supporting learning processes in the laboratory, and the quality of the hardware used so that this research is very helpful in making future policies. \u00a9 2020, Institute of Advanced Scientific Research, Inc.. All rights reserved."
        ]
    },
    {
        "judul":[
            "Analysis of automotive product selection in indonesia: factors of brand image using analytical hierarchy process"
        ],
        "penulis":"Wardhana, Aditya;Jasrial, Jasrial;Pradana, Mahir;Nugraha, Diki Wahyu;Firmansyah, Iqbal;Jamiat, Nuslih;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia, as the country with the largest economy in Southeast Asia, is one of the automotive production bases for export, especially to the Southeast Asia region and as the largest domestic market for automotive sales in the Southeast Asia region. Based on data from Gaikindo, ten automotive brands are included in the ranks of automotive brands with the most sales in 2019. Based on the results of interviews with 300 respondents, a percentage of 75.5% of respondents saw that ten automotive brands were included in the highest sales in Indonesia and the results of the pre-research questionnaire showed that the brand image of automotive products in Indonesia which consists of recognition, reputation, affinity, and domain has not fulfilled good responses from respondents. The research was conducted to see and analyze the factors of automotive product brand image which are the criteria for automotive criteria in Indonesia. The method used in this research is quantitative method. The research sample was taken using multistage sampling, namely a combination of cluster sampling based on provinces in Indonesia and purposive random sampling. The population in this study was 845,825 new automotive buyers in 2019 with a sample size of 400 respondents. The analysis technique used is the Analytical Hierarchy Process (AHP). The results showed that there were three factors for the brand image of automotive products in the good category, namely Recognition (74.13%), Reputation (75.63%), and Domain (81%), and there was one brand image factor in the very category. good, namely Affinity (96%). For automotive selection based on brand image, it is ranked first and so on is occupied by Toyota, Honda, Mitsubishi, Nissan, Daihatsu, Suzuki, Isuzu, Hino, Datsun, Mazda. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia, as the country with the largest economy in Southeast Asia, is one of the automotive production bases for export, especially to the Southeast Asia region and as the largest domestic market for automotive sales in the Southeast Asia region. Based on data from Gaikindo, ten automotive brands are included in the ranks of automotive brands with the most sales in 2019. Based on the results of interviews with 300 respondents, a percentage of 75.5% of respondents saw that ten automotive brands were included in the highest sales in Indonesia and the results of the pre-research questionnaire showed that the brand image of automotive products in Indonesia which consists of recognition, reputation, affinity, and domain has not fulfilled good responses from respondents. The research was conducted to see and analyze the factors of automotive product brand image which are the criteria for automotive criteria in Indonesia. The method used in this research is quantitative method. The research sample was taken using multistage sampling, namely a combination of cluster sampling based on provinces in Indonesia and purposive random sampling. The population in this study was 845,825 new automotive buyers in 2019 with a sample size of 400 respondents. The analysis technique used is the Analytical Hierarchy Process (AHP). The results showed that there were three factors for the brand image of automotive products in the good category, namely Recognition (74.13%), Reputation (75.63%), and Domain (81%), and there was one brand image factor in the very category. good, namely Affinity (96%). For automotive selection based on brand image, it is ranked first and so on is occupied by Toyota, Honda, Mitsubishi, Nissan, Daihatsu, Suzuki, Isuzu, Hino, Datsun, Mazda. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "Cardinality Single Column Analysis for Data Profiling using an Open Source Platform"
        ],
        "penulis":"Kusumasari, Tien Fabrianti;Amethyst, Sandy Rama;Hasibuan, Muhammad Azani;Nurtrisha, Widyatasya Agustika;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Data quality is essential for an enterprise system. However, several problems can eradicate the quality of data. One of them is the unfiltered data received. To overcome this issue, data engineer usually handle this such data by deploying data profiling process. There are several tools available to do this process. Each tool has its advantages according to needs. The main focus of this research is to compare the analysis results of two open-source data profiling tools based on cardinality method. The tools are Pentaho Data Integration (PDI) and Data Cleaner. The results of this study indicate that Pentaho can search for median values and distinct values for the data performed by profiling, while data cleaners cannot search for these values. Thus that Pentaho Data Integration is more detailed and specific compared to Data Cleaner \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data quality is essential for an enterprise system. However, several problems can eradicate the quality of data. One of them is the unfiltered data received. To overcome this issue, data engineer usually handle this such data by deploying data profiling process. There are several tools available to do this process. Each tool has its advantages according to needs. The main focus of this research is to compare the analysis results of two open-source data profiling tools based on cardinality method. The tools are Pentaho Data Integration (PDI) and Data Cleaner. The results of this study indicate that Pentaho can search for median values and distinct values for the data performed by profiling, while data cleaners cannot search for these values. Thus that Pentaho Data Integration is more detailed and specific compared to Data Cleaner \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design of disaster recovery plan: State university in indonesia"
        ],
        "penulis":"Setyawan, Andri;Giri Sucahyo, Yudho;Gandhi, Arfive;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "University X is a state university in Indonesia that can independently manage its assets. In carrying out its business processes, University X uses many information systems managed by the Directorate of Information Systems and Technology (DIST). The management of IS\/IT at the State University has not yet reached risk management implementation under IT governance. This research criticized the absence of an IS\/IT recovery plan as the root cause. In this regard, University X must have a Disaster Recovery Plan (DRP) to guide risk management implementation. This research used qualitative methods, a combination of case study methods, and action research. Data collection was carried out by interviews with the university's management, literature study, documentation, and observation of business processes of IS\/IT assets and data center. The DRP document was designed based on NIST SP 800-34 Rev.1. The stages of this research consisted of the analysis of business processes, identification of IS\/IT assets, policymaking of an IS\/IT disaster recovery plan, business impact analysis, prevention control analysis on data center based on ANSI \/ TIA 942-A, and designing DRP documents. The validation process of the DRP document involved the management of DIST. This research delivered a DRP document draft that suits University X's needs as a state university in Indonesia. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "University X is a state university in Indonesia that can independently manage its assets. In carrying out its business processes, University X uses many information systems managed by the Directorate of Information Systems and Technology (DIST). The management of IS\/IT at the State University has not yet reached risk management implementation under IT governance. This research criticized the absence of an IS\/IT recovery plan as the root cause. In this regard, University X must have a Disaster Recovery Plan (DRP) to guide risk management implementation. This research used qualitative methods, a combination of case study methods, and action research. Data collection was carried out by interviews with the university's management, literature study, documentation, and observation of business processes of IS\/IT assets and data center. The DRP document was designed based on NIST SP 800-34 Rev.1. The stages of this research consisted of the analysis of business processes, identification of IS\/IT assets, policymaking of an IS\/IT disaster recovery plan, business impact analysis, prevention control analysis on data center based on ANSI \/ TIA 942-A, and designing DRP documents. The validation process of the DRP document involved the management of DIST. This research delivered a DRP document draft that suits University X's needs as a state university in Indonesia. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Evaluation of the 10 Gigabit Symmetric PON for Triple-Play Services"
        ],
        "penulis":"Solihah, Nomarhinta;Nashiruddin, Muhammad Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The massive use of triple-play service (high-speed internet, real-time voice, and high-quality video) has created an enormous capacity problem to access network infrastructures. Moreover, the triple-play service requires a large bandwidth to meet the user's expectations and satisfaction. The higher the quality of the triple-play service content, the provided bandwidth must be more significant. This condition encourages telecommunication operators to increase their capacity by using 10-Gigabit-capable symmetric passive optical network (XGS-PON) technology to deliver triple-play services at a speed of 10 Gbps for upstream and downstream directions. The implementation of triple-play services on the XGS-PON must guarantee its functions and capabilities to meet regulation and standardization requirements. However, it has been no regulation and standardization regarding triple-play services in XGS-PON in Indonesia. The test result shows internet service on XGS-PON supports IPv4 and IPv6 protocols following ITU-T G.9807. XGS-PON also supports MAC Frame format according to IEEE 802.3, and VLAN ID refers to IEEE 802.1Q. The XGS-PON also supports real-time voice service using SIP protocol and the G.711 and G.729 audio CODECS to interoperate with legacy technology. The XGS-PON supports video services according to ITU-T G.9807 with multicast video services using IGMP version 2 and IGMP version 3 and unicast video services using the UDP\/RTP protocol. All of these results were obtained by the proposed test method and performance evaluation for XGS-PON. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The massive use of triple-play service (high-speed internet, real-time voice, and high-quality video) has created an enormous capacity problem to access network infrastructures. Moreover, the triple-play service requires a large bandwidth to meet the user's expectations and satisfaction. The higher the quality of the triple-play service content, the provided bandwidth must be more significant. This condition encourages telecommunication operators to increase their capacity by using 10-Gigabit-capable symmetric passive optical network (XGS-PON) technology to deliver triple-play services at a speed of 10 Gbps for upstream and downstream directions. The implementation of triple-play services on the XGS-PON must guarantee its functions and capabilities to meet regulation and standardization requirements. However, it has been no regulation and standardization regarding triple-play services in XGS-PON in Indonesia. The test result shows internet service on XGS-PON supports IPv4 and IPv6 protocols following ITU-T G.9807. XGS-PON also supports MAC Frame format according to IEEE 802.3, and VLAN ID refers to IEEE 802.1Q. The XGS-PON also supports real-time voice service using SIP protocol and the G.711 and G.729 audio CODECS to interoperate with legacy technology. The XGS-PON supports video services according to ITU-T G.9807 with multicast video services using IGMP version 2 and IGMP version 3 and unicast video services using the UDP\/RTP protocol. All of these results were obtained by the proposed test method and performance evaluation for XGS-PON. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "QSAR Study of Fusidic Acid Derivative as Anti-Malaria Agents by using Artificial Neural Network-Genetic Algorithm"
        ],
        "penulis":"Azmi, Hamzah Faisal;Lhaksmana, Kemas Muslim;Kurniawan, Isman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Malaria is a disease that caused many adverse effects on humans. Various attempts have been done to find new anti-malarial agents due to the resistance problem of the existing drug. Fusidic acid is known as one of a compound that is promising to be used as an anti-malaria agent. However, this compound should be derived to obtain a new fusidic acid derivative that has better activity. The exploration of the compound in conventional style has a shortcoming in the term of time and cost. Therefore, an alternative method is required to accelerate the design. In this study, we applied a quantitative structure-activity relationship (QSAR) to produce a predictive model. The produced model can be used to predict the activity of the compound as an anti-malaria agent. The development of the model was performed by using genetic algorithm (GA) for feature selection and artificial neural network (ANN) for model development. We developed five models by utilizing a different number of the descriptor in each model. The validation process was performed by evaluating several validation parameters, such as accuracy. According to the results, we found that the model 3, which is comprised of seven descriptors, produce a better result with the accuracies of internal and external data set are 0.96 and 0.92, respectively.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Malaria is a disease that caused many adverse effects on humans. Various attempts have been done to find new anti-malarial agents due to the resistance problem of the existing drug. Fusidic acid is known as one of a compound that is promising to be used as an anti-malaria agent. However, this compound should be derived to obtain a new fusidic acid derivative that has better activity. The exploration of the compound in conventional style has a shortcoming in the term of time and cost. Therefore, an alternative method is required to accelerate the design. In this study, we applied a quantitative structure-activity relationship (QSAR) to produce a predictive model. The produced model can be used to predict the activity of the compound as an anti-malaria agent. The development of the model was performed by using genetic algorithm (GA) for feature selection and artificial neural network (ANN) for model development. We developed five models by utilizing a different number of the descriptor in each model. The validation process was performed by evaluating several validation parameters, such as accuracy. According to the results, we found that the model 3, which is comprised of seven descriptors, produce a better result with the accuracies of internal and external data set are 0.96 and 0.92, respectively.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Clustering nodes and discretizing movement to increase the effectiveness of HEFA for a CVRP"
        ],
        "penulis":"Abdillah, Ubassy;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A Capacitated Vehicle Routing Problem (CVRP) is an important problem in transportation and industry. It is challenging to be solved using some optimization algorithms. Unfortunately, it is not easy to achieve a global optimum solution. Hence, many researchers use a combination of two or more optimization algorithms, which based on swarm intelligence methods, to overcome the drawbacks of the single algorithm. In this research, a CVRP optimization model, which contains two main processes of clustering and optimization, based on a discrete hybrid evolutionary firefly algorithm (DHEFA), is proposed. Some evaluations on three CVRP cases show that DHEFA produces an averaged effectiveness of 91.74%, which is much more effective than the original FA that gives mean effectiveness of 87.95%. This result shows that clustering nodes into several clusters effectively reduces the problem space, and the DHEFA quickly searches the optimum solution in those partial spaces. \u00a9 2020 Science and Information Organization.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A Capacitated Vehicle Routing Problem (CVRP) is an important problem in transportation and industry. It is challenging to be solved using some optimization algorithms. Unfortunately, it is not easy to achieve a global optimum solution. Hence, many researchers use a combination of two or more optimization algorithms, which based on swarm intelligence methods, to overcome the drawbacks of the single algorithm. In this research, a CVRP optimization model, which contains two main processes of clustering and optimization, based on a discrete hybrid evolutionary firefly algorithm (DHEFA), is proposed. Some evaluations on three CVRP cases show that DHEFA produces an averaged effectiveness of 91.74%, which is much more effective than the original FA that gives mean effectiveness of 87.95%. This result shows that clustering nodes into several clusters effectively reduces the problem space, and the DHEFA quickly searches the optimum solution in those partial spaces. \u00a9 2020 Science and Information Organization."
        ]
    },
    {
        "judul":[
            "4DFlowNet: Super-Resolution 4D Flow MRI Using Deep Learning and Computational Fluid Dynamics"
        ],
        "penulis":"Ferdian, Edward;Suinesiaputra, Avan;Dubowitz, David J.;Zhao, Debbie;Wang, Alan;Cowan, Brett;Young, Alistair A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "4D flow magnetic resonance imaging (MRI) is an emerging imaging technique where spatiotemporal 3D blood velocity can be captured with full volumetric coverage in a single non-invasive examination. This enables qualitative and quantitative analysis of hemodynamic flow parameters of the heart and great vessels. An increase in the image resolution would provide more accuracy and allow better assessment of the blood flow, especially for patients with abnormal flows. However, this must be balanced with increasing imaging time. The recent success of deep learning in generating super resolution images shows promise for implementation in medical images. We utilized computational fluid dynamics simulations to generate fluid flow simulations and represent them as synthetic 4D flow MRI data. We built our training dataset to mimic actual 4D flow MRI data with its corresponding noise distribution. Our novel 4DFlowNet network was trained on this synthetic 4D flow data and was capable in producing noise-free super resolution 4D flow phase images with upsample factor of 2. We also tested the 4DFlowNet in actual 4D flow MR images of a phantom and normal volunteer data, and demonstrated comparable results with the actual flow rate measurements giving an absolute relative error of 0.6\u20135.8% and 1.1\u20133.8% in the phantom data and normal volunteer data, respectively. \u00a9 Copyright \u00a9 2020 Ferdian, Suinesiaputra, Dubowitz, Zhao, Wang, Cowan and Young.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "4D flow magnetic resonance imaging (MRI) is an emerging imaging technique where spatiotemporal 3D blood velocity can be captured with full volumetric coverage in a single non-invasive examination. This enables qualitative and quantitative analysis of hemodynamic flow parameters of the heart and great vessels. An increase in the image resolution would provide more accuracy and allow better assessment of the blood flow, especially for patients with abnormal flows. However, this must be balanced with increasing imaging time. The recent success of deep learning in generating super resolution images shows promise for implementation in medical images. We utilized computational fluid dynamics simulations to generate fluid flow simulations and represent them as synthetic 4D flow MRI data. We built our training dataset to mimic actual 4D flow MRI data with its corresponding noise distribution. Our novel 4DFlowNet network was trained on this synthetic 4D flow data and was capable in producing noise-free super resolution 4D flow phase images with upsample factor of 2. We also tested the 4DFlowNet in actual 4D flow MR images of a phantom and normal volunteer data, and demonstrated comparable results with the actual flow rate measurements giving an absolute relative error of 0.6\u20135.8% and 1.1\u20133.8% in the phantom data and normal volunteer data, respectively. \u00a9 Copyright \u00a9 2020 Ferdian, Suinesiaputra, Dubowitz, Zhao, Wang, Cowan and Young."
        ]
    },
    {
        "judul":[
            "Proposed optimal maintenance intervals for milling machine using risk based maintenance and analytical hierarchy process at manufacturing plant"
        ],
        "penulis":"Farid D.A.;Budiasih E.;Alhilman J.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT IIS is an outsourcing company that offers manufacturing spare parts and dies forging. In producing dies forging product PT IIS uses Milling machines, lathes, and CNC 20-L Liquy Hising machines. Based on machine failure data, milling machines suffered a total of 27 times failure during the 2018-2019 period, the frequency of failure will affect the production process and resulted in large maintenance costs. Thus, it takes more observation regarding the maintenance of the Milling machine. The method used for research is Risk-based maintenance (RBM) which aims to estimate and minimize risks arising from failure. The results of collection and processing using RBM revealed that Milling machines with 2880 hours maintenance intervals had a total risk of Rp6,395,124.84 with the percentage of 0.67% exceeding the company's risk tolerance limit of 0.50%. Using the approach to minimizing risks, the proposed maintenance interval is 1100 hours and is at the company's risk acceptance criteria of 0.50%. This study also uses the Analytical Hierarchy Process (AHP) method which decides the maintenance policies that are tailored to the company's conditions, for Spindel components and rags using condition-based maintenance, and coolant hose components using time-based maintenance. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT IIS is an outsourcing company that offers manufacturing spare parts and dies forging. In producing dies forging product PT IIS uses Milling machines, lathes, and CNC 20-L Liquy Hising machines. Based on machine failure data, milling machines suffered a total of 27 times failure during the 2018-2019 period, the frequency of failure will affect the production process and resulted in large maintenance costs. Thus, it takes more observation regarding the maintenance of the Milling machine. The method used for research is Risk-based maintenance (RBM) which aims to estimate and minimize risks arising from failure. The results of collection and processing using RBM revealed that Milling machines with 2880 hours maintenance intervals had a total risk of Rp6,395,124.84 with the percentage of 0.67% exceeding the company's risk tolerance limit of 0.50%. Using the approach to minimizing risks, the proposed maintenance interval is 1100 hours and is at the company's risk acceptance criteria of 0.50%. This study also uses the Analytical Hierarchy Process (AHP) method which decides the maintenance policies that are tailored to the company's conditions, for Spindel components and rags using condition-based maintenance, and coolant hose components using time-based maintenance. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Analysis of the Generator and Consistency of General Web Page Layout Structure Using Matching Algorithm Based on Set Difference"
        ],
        "penulis":"Ilhamiati, Agniya Noor;Kusumo, Dana Sulistyo;Sardi, Indra Lukmana;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "According to the website quality of the organization dimension and website usability, the consistency of the layout of the web page is how the general layout elements format is common to all pages. Consistency can make it easier for users in terms of navigation. In this study, researchers used a case study on the East Kalimantan High Prosecutors' website (http:\/\/www.kejati-kaltim.go.id\/). The inequality location of the layout makes inconsistency. In this research, web page layout structure data was collected using a Chrome Extension called HTML Tree Generator by adding additional functions according to semantic elements, so that automatically downloads HTML elements in the Document Object Model (DOM). Then, the general layout structure generator only took the semantic elements from the most common layout as its input. Matching Algorithm used to solve the problem of inconsistency in general layout structure, by looking for differences of structure using set difference. Combination functions are used to determine the comparison of each page. Set difference produce 'false' if there are one or more differences. Research on the consistency of web page layout structure from case studies yields a consistency score of 92.1%. This score indicates an inconsistency in the web page layout. However, after fixed inconsistent pages, the recalculation score can produce a consistent web page layout.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "According to the website quality of the organization dimension and website usability, the consistency of the layout of the web page is how the general layout elements format is common to all pages. Consistency can make it easier for users in terms of navigation. In this study, researchers used a case study on the East Kalimantan High Prosecutors' website (http:\/\/www.kejati-kaltim.go.id\/). The inequality location of the layout makes inconsistency. In this research, web page layout structure data was collected using a Chrome Extension called HTML Tree Generator by adding additional functions according to semantic elements, so that automatically downloads HTML elements in the Document Object Model (DOM). Then, the general layout structure generator only took the semantic elements from the most common layout as its input. Matching Algorithm used to solve the problem of inconsistency in general layout structure, by looking for differences of structure using set difference. Combination functions are used to determine the comparison of each page. Set difference produce 'false' if there are one or more differences. Research on the consistency of web page layout structure from case studies yields a consistency score of 92.1%. This score indicates an inconsistency in the web page layout. However, after fixed inconsistent pages, the recalculation score can produce a consistent web page layout.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A techno-environmental assessment of hybrid photovoltaic-thermal based combined heat and power system on a residential home"
        ],
        "penulis":"Erixno, Oon;Rahim, Nasrudin Abd;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper provides energy, exergy and environmental analyses for hybrid photovoltaic-thermal based combined heat and power system. Grid-connected configuration was used to increase the system reliability when satisfying the load. A series of battery and hot-water storages were applied for saving the excess of electricity and heat, respectively. Technical evaluations were conducted based on experimental data using real-time measurement devices throughout 31 days and estimated annual energy generation. The results showed that the average of electrical energy, thermal energy, electrical exergy and thermal exergy generations in a day were 0.34 kWh\/m2, 0.60 kWh\/m2, 0.34 kWh\/m2, and 0.01 kWh\/m2per day, respectively with the solar irradiation average of 3.25 kWh\/m2per day. The maximum efficiencies of electrical energy, thermal energy, electrical exergy, and thermal exergy generations were 16.73%, 51.09%, 16.73% and 0.85%, respectively. This research also found the electrical and thermal energy efficiencies of the system were degraded by 1.20% and 1.89% per year, respectively. The system reduced the carbon dioxide emission annually by 855.1 kg per year or approximately 26.75% lower than a conventional separated system. \u00a9 2020 Elsevier Ltd",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper provides energy, exergy and environmental analyses for hybrid photovoltaic-thermal based combined heat and power system. Grid-connected configuration was used to increase the system reliability when satisfying the load. A series of battery and hot-water storages were applied for saving the excess of electricity and heat, respectively. Technical evaluations were conducted based on experimental data using real-time measurement devices throughout 31 days and estimated annual energy generation. The results showed that the average of electrical energy, thermal energy, electrical exergy and thermal exergy generations in a day were 0.34 kWh\/m2, 0.60 kWh\/m2, 0.34 kWh\/m2, and 0.01 kWh\/m2per day, respectively with the solar irradiation average of 3.25 kWh\/m2per day. The maximum efficiencies of electrical energy, thermal energy, electrical exergy, and thermal exergy generations were 16.73%, 51.09%, 16.73% and 0.85%, respectively. This research also found the electrical and thermal energy efficiencies of the system were degraded by 1.20% and 1.89% per year, respectively. The system reduced the carbon dioxide emission annually by 855.1 kg per year or approximately 26.75% lower than a conventional separated system. \u00a9 2020 Elsevier Ltd"
        ]
    },
    {
        "judul":[
            "Tracking, Arrival Time Estimator, and Passenger Information System on Bus Rapid Transit (BRT)"
        ],
        "penulis":"Hafiizh Nur M.A.;Hadiyoso, Sugondo;Belladina, Fefa Bianca;Ramadan, Dadan Nur;Wijayanto, Inung;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Trans Metro Bandung is a new Bus Rapid Transit in Bandung, Indonesia. As a new mode of transportation, it proposes comfort, safety, and give an affordable price. However, information systems related to buses are still lacking and far from expectations. That includes the uncertainty of the bus departures and arrivals times at bus stops. Therefore, in this study, an integrated online system is designed to provide information, including bus arrival time, bus position, and the number of passengers on the bus. This information system is a website application that is connected to the Firebase real-time database so that all data can be accessed in real-time and then displayed at the bus stop. The hardware system consists of an infrared detector to count the number of passengers and a GPS module for bus tracking. From the bus position information, the system can estimate the arrival time at the nearest bus stop.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Trans Metro Bandung is a new Bus Rapid Transit in Bandung, Indonesia. As a new mode of transportation, it proposes comfort, safety, and give an affordable price. However, information systems related to buses are still lacking and far from expectations. That includes the uncertainty of the bus departures and arrivals times at bus stops. Therefore, in this study, an integrated online system is designed to provide information, including bus arrival time, bus position, and the number of passengers on the bus. This information system is a website application that is connected to the Firebase real-time database so that all data can be accessed in real-time and then displayed at the bus stop. The hardware system consists of an infrared detector to count the number of passengers and a GPS module for bus tracking. From the bus position information, the system can estimate the arrival time at the nearest bus stop.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Designing user interface using user-centered design method on reproductive health learning for visual impairment teenagers"
        ],
        "penulis":"Priowibowo B.;Effendy V.;Junaedi D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One of the non-profit organizations that have concerns in reproductive health education for high school teenagers provides materials about reproductive health on its website. However, it is not accessible for visual impairment teenagers, for example, the picture cannot be read by screen reader software, and the absence of reproductive health learning that specifically for the visual impairment teenagers causes the lack of comprehensive learning and lack of independent learning for visual impairment teenagers. Android-based application of reproductive health learning will be developed to reduce effort such as opening a browser and typing the e-learning address. The application designed to implement multimodal interaction, that can become natural interaction involving several human senses in using applications that offer flexibility, efficiency and the use of a usable environment. The application allows the user to interact through several inputs such as touch, or gesture and get an output as a sound. In this study, the User-Centered Design method had used, so the design can be focused on the user. The user interface model had tested with USE questionnaire parameters that reach an average usability percentage 87.4%, it shows that usability obtained in the excellent category. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Gender equalityGoal 5",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the non-profit organizations that have concerns in reproductive health education for high school teenagers provides materials about reproductive health on its website. However, it is not accessible for visual impairment teenagers, for example, the picture cannot be read by screen reader software, and the absence of reproductive health learning that specifically for the visual impairment teenagers causes the lack of comprehensive learning and lack of independent learning for visual impairment teenagers. Android-based application of reproductive health learning will be developed to reduce effort such as opening a browser and typing the e-learning address. The application designed to implement multimodal interaction, that can become natural interaction involving several human senses in using applications that offer flexibility, efficiency and the use of a usable environment. The application allows the user to interact through several inputs such as touch, or gesture and get an output as a sound. In this study, the User-Centered Design method had used, so the design can be focused on the user. The user interface model had tested with USE questionnaire parameters that reach an average usability percentage 87.4%, it shows that usability obtained in the excellent category. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Modeling Traffic Flow on Buah Batu Exit Toll Gate Using Cellular Automata"
        ],
        "penulis":"Ketaren, Raymondo Fitrah;Danufane, Fadil Habibi;Kurniawan, Isman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the last decade, Bandung has become one of the tourism destination places in Indonesia. It is reported that almost 6.7 million visitors come to Bandung in 2018, and the number increased by almost 4% per year since 2014. This rise in the number of visitors leads to the establishment of several toll gates as main access points throughout the city. As one of the busiest ones, Buah Batu toll gate is frequently congested because of the location that is close to the southern part of Bandung. To overcome this problem, a traffic regulation based on computer simulation is urgently required. In this study, we simulate the traffic system on the Buah Batu toll gate by using a combination of Nagel-Schreckenberg (NaSch) and Daoudia and Moussa (DM) models. NaSch model was used to defined vehicle movement, while the DM model was used to allow a vehicle to change lane. We defined three scenarios to evaluate the effectivity of the closing gate scheme. We found that the closing of gate 5 is more effective than the closing of gate 1. We also investigated the contribution of traffic density and driver's behavior, e.g., stopping behavior and lane-changing behavior, to the average velocity of the vehicles.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the last decade, Bandung has become one of the tourism destination places in Indonesia. It is reported that almost 6.7 million visitors come to Bandung in 2018, and the number increased by almost 4% per year since 2014. This rise in the number of visitors leads to the establishment of several toll gates as main access points throughout the city. As one of the busiest ones, Buah Batu toll gate is frequently congested because of the location that is close to the southern part of Bandung. To overcome this problem, a traffic regulation based on computer simulation is urgently required. In this study, we simulate the traffic system on the Buah Batu toll gate by using a combination of Nagel-Schreckenberg (NaSch) and Daoudia and Moussa (DM) models. NaSch model was used to defined vehicle movement, while the DM model was used to allow a vehicle to change lane. We defined three scenarios to evaluate the effectivity of the closing gate scheme. We found that the closing of gate 5 is more effective than the closing of gate 1. We also investigated the contribution of traffic density and driver's behavior, e.g., stopping behavior and lane-changing behavior, to the average velocity of the vehicles.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Profile matching for students specialization in industrial engineering major"
        ],
        "penulis":"Awaliyah M.M.;Kurniawati A.;Rizana A.F.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, various specific skills are needed in the global work environment. Because of that, many university majors provide specializations within majors. The Industrial Engineering major at Telkom University has eleven specializations that can be selected by the fourth-year students. The class maximum capacity for each specialization is 45 students. Every academic year, some specializations have registrants more that the class maximum capacity. Therefore, this study aims to create a selection procedure. The methodology used in the selection procedure is profile matching. The matching is done between the students' capacity and the requirements of the specializations. The capacity and the requirements are measured by using seven previous first to third-year courses as the criteria. The value of the criteria is measured by the grade index of the seven courses. The gap is identified between the students' grade achievement and the highest grade. This study is limited to two specializations that have 55 and 47 registrants in the academic year of 2019\/2020. The profile matching calculation is simulated using the data of three students for each specialization. The highest and the lowest match score from the six students are 4.9 and 3.6 (on a scale of 5). \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, various specific skills are needed in the global work environment. Because of that, many university majors provide specializations within majors. The Industrial Engineering major at Telkom University has eleven specializations that can be selected by the fourth-year students. The class maximum capacity for each specialization is 45 students. Every academic year, some specializations have registrants more that the class maximum capacity. Therefore, this study aims to create a selection procedure. The methodology used in the selection procedure is profile matching. The matching is done between the students' capacity and the requirements of the specializations. The capacity and the requirements are measured by using seven previous first to third-year courses as the criteria. The value of the criteria is measured by the grade index of the seven courses. The gap is identified between the students' grade achievement and the highest grade. This study is limited to two specializations that have 55 and 47 registrants in the academic year of 2019\/2020. The profile matching calculation is simulated using the data of three students for each specialization. The highest and the lowest match score from the six students are 4.9 and 3.6 (on a scale of 5). \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Sentiment Analysis on Youtube Social Media Using Decision Tree and Random Forest Algorithm: A Case Study"
        ],
        "penulis":"Aufar, Mohammad;Andreswari, Rachmadita;Pramesti, Dita;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "People often gives opinions and thoughts on Social Media. Social media invites anyone who is interested to participate by giving feedback openly, giving comments, and sharing information in a fast and unlimited time. One of the social media that is still widely used in the community is Youtube. With so much video content, Youtube, one of which is also commonly used to promote a product. Case studies taken by researchers are public comments on Nokia's products. Nokia was one of the best consumer stock, and was a global-scale product, but took its downfall at year 2013. By classifying positive, negative, and neutral sentiments from various opinions on Nokia's Products, a sentiment will be conducted. From this analysis it can be determined whether the product quality is generally good or not. However, the comments are neutral labelled in dominance. The stages of sentiment analysis in this study is data preparation, data processing and evaluation. The resulting model is tested and evaluated by looking at the values of accuracy, precision, recall, and Fl-measure. The algorithm used in the conducted sentiment analysis are the Decision Tree and Random Forest Algorithm. Decision Tree algorithm has a slightly higher accuracy of 89.4% rather than Random Forest algorithm which is 88.2%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "People often gives opinions and thoughts on Social Media. Social media invites anyone who is interested to participate by giving feedback openly, giving comments, and sharing information in a fast and unlimited time. One of the social media that is still widely used in the community is Youtube. With so much video content, Youtube, one of which is also commonly used to promote a product. Case studies taken by researchers are public comments on Nokia's products. Nokia was one of the best consumer stock, and was a global-scale product, but took its downfall at year 2013. By classifying positive, negative, and neutral sentiments from various opinions on Nokia's Products, a sentiment will be conducted. From this analysis it can be determined whether the product quality is generally good or not. However, the comments are neutral labelled in dominance. The stages of sentiment analysis in this study is data preparation, data processing and evaluation. The resulting model is tested and evaluated by looking at the values of accuracy, precision, recall, and Fl-measure. The algorithm used in the conducted sentiment analysis are the Decision Tree and Random Forest Algorithm. Decision Tree algorithm has a slightly higher accuracy of 89.4% rather than Random Forest algorithm which is 88.2%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Function of PMO for successful program-project management in the bank company - A case study"
        ],
        "penulis":"Yana, Rika Rizki;Sasongko, Danarto Tri;Wardhana, Aditya Wisnu;Ilona, Kwee Felicia;Shihab, Muhammad Rifki;Ranti, Benny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this paper is to investigate the specific function of Program Management Office (PMO) to manage multiple Kaizen or improvement projects and how we can implement PMO with more effective and more efficient to deliver value, benefits and achieve business goal in bank company. Research indicate that project management become increasingly difficult to manage when multiple projects are many overlapping projects in a project-oriented company, the goal in a need for enhanced bank company controls to increase success rates. It caused with implementation of a system that help project management, the system named Project Management Office (PMO) that is essential for bank company that are project-oriented and faced many overlapping projects. The PMO with an essential model that will explain to us to have management system of multiple project effectively in a banking company. Using a case study in one of banking industry in Indonesia, to test the method of research found that PMO deliver excellent value for bank company. The survey result of PMO function saw that most of project stakeholders in banking company agreed to 5 (five) categories and 20 (twenty) specified of PMO function implementation to manage several banking projects excellent. based on the results of the questionnaire, stakeholders answered more agreeably with the function of PMO for success project management at bank company and it could answer to the question that the method has deliver benefit and create goals for project management office performance in bank company.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this paper is to investigate the specific function of Program Management Office (PMO) to manage multiple Kaizen or improvement projects and how we can implement PMO with more effective and more efficient to deliver value, benefits and achieve business goal in bank company. Research indicate that project management become increasingly difficult to manage when multiple projects are many overlapping projects in a project-oriented company, the goal in a need for enhanced bank company controls to increase success rates. It caused with implementation of a system that help project management, the system named Project Management Office (PMO) that is essential for bank company that are project-oriented and faced many overlapping projects. The PMO with an essential model that will explain to us to have management system of multiple project effectively in a banking company. Using a case study in one of banking industry in Indonesia, to test the method of research found that PMO deliver excellent value for bank company. The survey result of PMO function saw that most of project stakeholders in banking company agreed to 5 (five) categories and 20 (twenty) specified of PMO function implementation to manage several banking projects excellent. based on the results of the questionnaire, stakeholders answered more agreeably with the function of PMO for success project management at bank company and it could answer to the question that the method has deliver benefit and create goals for project management office performance in bank company.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "New reconstruction method for needle contrast optimization in b-mode ultrasound image by extracting rf signal parameters in frequency domain"
        ],
        "penulis":"Susanti, Hesty;Suprijanto;Kurniadi, Deddy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Ultrasound-guided needle insertion has become standard in medical interventional procedures. Regardless of its advantages, it still has crucial problems related to needle visibility. Some technical factors affect the visibility with non-linear characteristic, i.e. frequency, insertion angle and depth. Here, backscattered signal parameters from measurement were compared to a simulation of a resonance scattering model. Raw radio frequency (RF) data were reconstructed with a new method to represent unique information on total backpropagation from the needle, which consists of non-resonance and resonance scattering components. The result suggests that reconstruction of the needle in B-mode images should be derived from the maximum power spectral density and the energy spectral density to optimize the contrast of the needle. In measurements with the center frequency at 1.87 MHz, the effect of resonance scattering on the total backpropagation around critical angles could be observed more clearly with this method than with standard reconstruction based on the signal envelope. The simulation showed that the fractional bandwidth of the spectrum of the backscattered pressure field centered at 1.87 MHz was relatively optimal at 40% to 100%. So that the simulation of the resonance scattering model can be used to predict the backscattered response from the needle, it must be able to confirm it to the real conditions of RF data with random characteristics. Therefore, extraction of the backscattered pressure field in a simulation with fractional bandwidth should be a concern. \u00a9 2020 Published by ITB Institute for Research and Community Services,.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ultrasound-guided needle insertion has become standard in medical interventional procedures. Regardless of its advantages, it still has crucial problems related to needle visibility. Some technical factors affect the visibility with non-linear characteristic, i.e. frequency, insertion angle and depth. Here, backscattered signal parameters from measurement were compared to a simulation of a resonance scattering model. Raw radio frequency (RF) data were reconstructed with a new method to represent unique information on total backpropagation from the needle, which consists of non-resonance and resonance scattering components. The result suggests that reconstruction of the needle in B-mode images should be derived from the maximum power spectral density and the energy spectral density to optimize the contrast of the needle. In measurements with the center frequency at 1.87 MHz, the effect of resonance scattering on the total backpropagation around critical angles could be observed more clearly with this method than with standard reconstruction based on the signal envelope. The simulation showed that the fractional bandwidth of the spectrum of the backscattered pressure field centered at 1.87 MHz was relatively optimal at 40% to 100%. So that the simulation of the resonance scattering model can be used to predict the backscattered response from the needle, it must be able to confirm it to the real conditions of RF data with random characteristics. Therefore, extraction of the backscattered pressure field in a simulation with fractional bandwidth should be a concern. \u00a9 2020 Published by ITB Institute for Research and Community Services,."
        ]
    },
    {
        "judul":[
            "Exploiting non-orthogonal multiple access in downlink coordinated multipoint transmission with the presence of imperfect channel state information"
        ],
        "penulis":"Murti, Fahri Wisnu;Siregar, Rahmat Faddli;Royyan, Muhammad;Shin, Soo Young;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, the impact of imperfect channel state information (CSI) on a downlink coordinated multipoint (CoMP) transmission system with non-orthogonal multiple access (NOMA) is investigated since perfect knowledge of a channel cannot be guaranteed in practice. Furthermore, the channel estimation error is applied to estimate the channel information wherein its a priori of variance is assumed to be known. The impact of the number of coordinated base stations (BSs) on downlink CoMP NOMA is investigated. Users are classified into one of two groups according to their position within the cell, namely, cell-center user (CCU) and cell-edge user (CEU). In this paper, ergodic capacity and sum capacity for both CCU and CEU are derived as closed forms. In addition, various experiments are conducted with different parameters such as SNR, error variance, and power allocation to show their impact on the CoMP method. The results show that CoMP NOMA outperforms the CoMP orthogonal multiple access (OMA) wherein the condition of the channel impacts the performance of CoMP NOMA less. It is worth noting that a higher number of coordinated BSs enhances the total capacity of CoMP NOMA. Finally, the performance analysis is validated due to the close accordance between the analytical and simulation results. \u00a9 2020 John Wiley & Sons, Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, the impact of imperfect channel state information (CSI) on a downlink coordinated multipoint (CoMP) transmission system with non-orthogonal multiple access (NOMA) is investigated since perfect knowledge of a channel cannot be guaranteed in practice. Furthermore, the channel estimation error is applied to estimate the channel information wherein its a priori of variance is assumed to be known. The impact of the number of coordinated base stations (BSs) on downlink CoMP NOMA is investigated. Users are classified into one of two groups according to their position within the cell, namely, cell-center user (CCU) and cell-edge user (CEU). In this paper, ergodic capacity and sum capacity for both CCU and CEU are derived as closed forms. In addition, various experiments are conducted with different parameters such as SNR, error variance, and power allocation to show their impact on the CoMP method. The results show that CoMP NOMA outperforms the CoMP orthogonal multiple access (OMA) wherein the condition of the channel impacts the performance of CoMP NOMA less. It is worth noting that a higher number of coordinated BSs enhances the total capacity of CoMP NOMA. Finally, the performance analysis is validated due to the close accordance between the analytical and simulation results. \u00a9 2020 John Wiley & Sons, Ltd."
        ]
    },
    {
        "judul":[
            "An improvement of led lighting system accuracy with voltage control system"
        ],
        "penulis":"Abdurohman, Maman;Nugraha, Ramdhan;Gautama Putrada, Aji;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper proposes an effective LED lighting control system to increase the accuracy of electric power usage. The efficient use of electric power is a problem that needs to be pursued a solution. There are several previous works have been proposed to reduce electric power consumption. However, no one has focused on saving LED lights by using a voltage control system. In this paper, a LED lighting control system has been developed by adjusting environmental conditions using light intensity sensors and the presence of people. Some experiments have been carried out to prove the effectiveness of the system. The results show that the system has successfully adjusted the light intensity based on the presence of people in the room and room light intensity. So, the light intensity could adapt to the environment as the control system work. PWM control system has a high correlation, more than 99%, compare to room light intensity. It shows the effectiveness of the control system. Thus the goal of lighting efficiency has been achieved effectively. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes an effective LED lighting control system to increase the accuracy of electric power usage. The efficient use of electric power is a problem that needs to be pursued a solution. There are several previous works have been proposed to reduce electric power consumption. However, no one has focused on saving LED lights by using a voltage control system. In this paper, a LED lighting control system has been developed by adjusting environmental conditions using light intensity sensors and the presence of people. Some experiments have been carried out to prove the effectiveness of the system. The results show that the system has successfully adjusted the light intensity based on the presence of people in the room and room light intensity. So, the light intensity could adapt to the environment as the control system work. PWM control system has a high correlation, more than 99%, compare to room light intensity. It shows the effectiveness of the control system. Thus the goal of lighting efficiency has been achieved effectively. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "The Analysis of User Intention Detection Related to Conventional Poster Advertisement by Using the Features of Face and Eye(s)"
        ],
        "penulis":"Modesty, Yolanda;Sudiharto, Dodi Wisaksono;Wijiutomo, Catur Wirawan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "There are official media to display conventional advertisements such as posters and billboards. However, those cannot tell to the owner related to the effectiveness of the advertisements directly. It can be recognized after the product items have been sold. Based on that problem, there is a requirement related to the media demonstrate an ability to instantly detect user intention. That function explained, generally, is held by a smart advertisement display. On that one, smart components can instantly detect the user intention, are attached to the monitor. Unfortunately, for some companies, the monitor is still expensive to be performed. This condition makes a potential desire to modify the existing smart advertisement system by gently moving the smart components (as an embedded system and a sensor) to other conventional displayed media such as posters. There is an underline state that has to be proven then that the smart modules attached on has to act similarly, likes when they are attached on the monitor. This study observes the ability of the smart components if they are attached to the posters to detect user intention directly. This study uses the previous observation result for elaborating user intention detection by using face and eye(s) features. The result gives a proven fact that smart parts attached to the posters produce the scoring which is relatively the same as the scoring by the smart display system in an arrangement, related to the effectiveness of the advertisement.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "There are official media to display conventional advertisements such as posters and billboards. However, those cannot tell to the owner related to the effectiveness of the advertisements directly. It can be recognized after the product items have been sold. Based on that problem, there is a requirement related to the media demonstrate an ability to instantly detect user intention. That function explained, generally, is held by a smart advertisement display. On that one, smart components can instantly detect the user intention, are attached to the monitor. Unfortunately, for some companies, the monitor is still expensive to be performed. This condition makes a potential desire to modify the existing smart advertisement system by gently moving the smart components (as an embedded system and a sensor) to other conventional displayed media such as posters. There is an underline state that has to be proven then that the smart modules attached on has to act similarly, likes when they are attached on the monitor. This study observes the ability of the smart components if they are attached to the posters to detect user intention directly. This study uses the previous observation result for elaborating user intention detection by using face and eye(s) features. The result gives a proven fact that smart parts attached to the posters produce the scoring which is relatively the same as the scoring by the smart display system in an arrangement, related to the effectiveness of the advertisement.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Combined Firefly Algorithm-Random Forest to Classify Autistic Spectrum Disorders"
        ],
        "penulis":"Farrell, Mochammad;Ramadhani, Kurniawan Nur;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Early diagnosis of autistic spectrum disorder, an imperfect neurological development condition, is one way to reduce the sufferer condition. However, the diagnosis of ASD is costly. A popular classification model based on a machine learning technique, such as random forest, can reduce the cost. In general, an RF that is designed by a domain expert gives high accuracy for various datasets. Unfortunately, RF commonly produces a low F1-score for an imbalanced-class dataset. Therefore, in this paper, a firefly algorithm, one of the popular swarm intelligence algorithms, is exploited to automatically design an optimum RF. First, a decision tree is formed based on random features chosen by RF. The decision trees have different features, which cause RF to have new knowledge to classify data continually. The feature used to form a decision tree is 20% of the total attributes. This decision tree is then formed into a forest. Finally, it classifies data using a voting scheme. In FA-based optimization, an individual firefly represents one decision tree. The objective function of a firefly is based on its accuracy. An evaluation using the ASD datasets shows that the proposed combination of FA and RF (FARF) performs better than the original RF for a decision tree of 30. FARF reaches an accuracy of 94.32% and F1-scores of 35.67%, while RF gives an accuracy of 90.78% and F1-scores of 34.09%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Early diagnosis of autistic spectrum disorder, an imperfect neurological development condition, is one way to reduce the sufferer condition. However, the diagnosis of ASD is costly. A popular classification model based on a machine learning technique, such as random forest, can reduce the cost. In general, an RF that is designed by a domain expert gives high accuracy for various datasets. Unfortunately, RF commonly produces a low F1-score for an imbalanced-class dataset. Therefore, in this paper, a firefly algorithm, one of the popular swarm intelligence algorithms, is exploited to automatically design an optimum RF. First, a decision tree is formed based on random features chosen by RF. The decision trees have different features, which cause RF to have new knowledge to classify data continually. The feature used to form a decision tree is 20% of the total attributes. This decision tree is then formed into a forest. Finally, it classifies data using a voting scheme. In FA-based optimization, an individual firefly represents one decision tree. The objective function of a firefly is based on its accuracy. An evaluation using the ASD datasets shows that the proposed combination of FA and RF (FARF) performs better than the original RF for a decision tree of 30. FARF reaches an accuracy of 94.32% and F1-scores of 35.67%, while RF gives an accuracy of 90.78% and F1-scores of 34.09%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Melanoma Classification Using Combination of Color and Shape Feature"
        ],
        "penulis":"Wiranata, Dimas Agusta;Rachmawati, Ema;Utama, Dody Qori;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "According to the WHO, about 132 thousand cases of melanoma occurred each year. British Association of Dermatologists also launched, 77% of people do not recognize the symptoms of malignant skin cancer. Melanoma has a deadly effect and including one type of silent killer, but this can be early detected to be cured entirely. To recognize melanoma early, we proposed melanoma classification using Histogram of Oriented Gradients and Color Histogram. Histogram of Oriented Gradients is used to extract the shape features, while Color Histogram is used to extract the color features in HSV color space. Using Random Forest as the classifier, we obtained F1Score 93.3%, with the pixels per cell is 10x10 and cells per block is 1x1 for HOG and five bins for Color Histogram.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "According to the WHO, about 132 thousand cases of melanoma occurred each year. British Association of Dermatologists also launched, 77% of people do not recognize the symptoms of malignant skin cancer. Melanoma has a deadly effect and including one type of silent killer, but this can be early detected to be cured entirely. To recognize melanoma early, we proposed melanoma classification using Histogram of Oriented Gradients and Color Histogram. Histogram of Oriented Gradients is used to extract the shape features, while Color Histogram is used to extract the color features in HSV color space. Using Random Forest as the classifier, we obtained F1Score 93.3%, with the pixels per cell is 10x10 and cells per block is 1x1 for HOG and five bins for Color Histogram.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance analysis of cache based on popularity and class in named data network"
        ],
        "penulis":"Yovita, Leanna Vidya;Syambas, Nana Rachmana;Edward, Ian Joseph Matheus;Kamiyama, Noriaki;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The communication network is growing with some unique characteristics, such as consumers repeatedly request the same content to the server, similarity in local demand trend, and dynamic changes to requests within a specific period. Therefore, a different network paradigm is needed to replace the IP network, namely Named Data Network (NDN). The content store, which acts as a crucial component in the NDN nodes is a limited resource. In addition, a cache mechanism is needed to optimize the router\u2019s content store by exploiting the different content services characters in the network. This paper proposes a new caching algorithm called Cache Based on Popularity and Class (CAPIC) with dynamic mechanism, and the detail explanation about the static method also presented. The goal of Static-CAPIC was to enhance the total cache hit ratio on the network by pre-determining the cache proportion for each content class. However, this technique is not appropriate to control the cache hit ratio for priority class. Therefore, the Dynamic-CAPIC is used to provide flexibility to change the cache proportion based on the frequency of requests in real-time. The formula involves considering the consumers\u2019 request all the time. It gives a higher cache hit ratio for the priority content class. This method outperforms Static-CAPIC, and the LCD+sharing scheme in the total network cache hit ratio parameter and channels it to the priority class. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The communication network is growing with some unique characteristics, such as consumers repeatedly request the same content to the server, similarity in local demand trend, and dynamic changes to requests within a specific period. Therefore, a different network paradigm is needed to replace the IP network, namely Named Data Network (NDN). The content store, which acts as a crucial component in the NDN nodes is a limited resource. In addition, a cache mechanism is needed to optimize the router\u2019s content store by exploiting the different content services characters in the network. This paper proposes a new caching algorithm called Cache Based on Popularity and Class (CAPIC) with dynamic mechanism, and the detail explanation about the static method also presented. The goal of Static-CAPIC was to enhance the total cache hit ratio on the network by pre-determining the cache proportion for each content class. However, this technique is not appropriate to control the cache hit ratio for priority class. Therefore, the Dynamic-CAPIC is used to provide flexibility to change the cache proportion based on the frequency of requests in real-time. The formula involves considering the consumers\u2019 request all the time. It gives a higher cache hit ratio for the priority content class. This method outperforms Static-CAPIC, and the LCD+sharing scheme in the total network cache hit ratio parameter and channels it to the priority class. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Narrowband-IoT network for asset tracking system"
        ],
        "penulis":"Bima I.W.K.;Suryani V.;Wardana A.A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Narrowband-IoT is one of the emerging LPWAN technologies in the market. Traditionally asset tracking employs Global Positioning System (GPS) and General Packet Radio Service (GPRS) connections to send telemetry data to database servers. Compared to GPRS, NB-IoT has a smaller power usage, given proper implementation. This paper discusses NB-IoT implementation in asset tracking applications. Our test includes these parameters: latency, throughput, packet loss, and power usage for both technologies. The result obtained showed that NB-IoT was underperformed in HTTP but in UDP test, NB-IoT showed better power consumption compared to GPRS (0.352 W vs. 0.542 W) even though both have similar uplink throughput (around 350 B\/s). From these findings, this new cellular standard is deemed appropriate in the Asset Tracking application, given the correct protocol and architecture. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Narrowband-IoT is one of the emerging LPWAN technologies in the market. Traditionally asset tracking employs Global Positioning System (GPS) and General Packet Radio Service (GPRS) connections to send telemetry data to database servers. Compared to GPRS, NB-IoT has a smaller power usage, given proper implementation. This paper discusses NB-IoT implementation in asset tracking applications. Our test includes these parameters: latency, throughput, packet loss, and power usage for both technologies. The result obtained showed that NB-IoT was underperformed in HTTP but in UDP test, NB-IoT showed better power consumption compared to GPRS (0.352 W vs. 0.542 W) even though both have similar uplink throughput (around 350 B\/s). From these findings, this new cellular standard is deemed appropriate in the Asset Tracking application, given the correct protocol and architecture. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Automatic segmentation scheme for effective synchronization of EMG-EEG quantification"
        ],
        "penulis":"Suprijanto;Noor, Azizah S.;Risangtuni, Ayu G.;Susanti, Hesty;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Effective segmentation of electromyography (EMG) burst that synchronizes with electroencephalography (EEG) for long-duration recording is important steps to better understand the quantification of brain-muscle connectivity in periodic motoric activities. The work proposes an alternative automatic EMG segmentation scheme consists of four main steps, i.e. denoising of EMG burst signal using discrete wavelet transform, enveloping signal using time-windows averaging of RMS amplitude, an adaptive threshold to detect start\/end burst envelope with accommodation of muscle contraction characteristic and the final step is conversion enveloping signal to binary segmentation signal. The proposed scheme is evaluated to detect contraction period\/duration of EMG for the subject under repetitive holding and releasing grasp using a physiotherapy device. During exercise, the bio-amplifier board is customized to acquire simultaneous EEG and EMG from the region of flexor digitorum superficialis (FDS) of muscle and cortical motor of the brain, with total 284 EMG burst that counting by manual segmentation. The automatic segmentation can detect the total EMG burst by 6.25% error of false burst detection. The usefulness of proposed scheme is also tested to association analysis according to the power of EMG burst and the power of mu-wave of EEG recorded on the motor cortex. The changing trend of the power of mu-wave associated with muscle relaxation, muscle contraction strength and the synchronization level on the motor cortex during exercise are analyzed with integrated information that is relevant with biofeedback concept. The results demonstrate that proposed scheme has potential to be an effective method for the evaluation of biofeedback rehabilitation exercise. \u00a9 2020 North Atlantic University Union NAUN. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Effective segmentation of electromyography (EMG) burst that synchronizes with electroencephalography (EEG) for long-duration recording is important steps to better understand the quantification of brain-muscle connectivity in periodic motoric activities. The work proposes an alternative automatic EMG segmentation scheme consists of four main steps, i.e. denoising of EMG burst signal using discrete wavelet transform, enveloping signal using time-windows averaging of RMS amplitude, an adaptive threshold to detect start\/end burst envelope with accommodation of muscle contraction characteristic and the final step is conversion enveloping signal to binary segmentation signal. The proposed scheme is evaluated to detect contraction period\/duration of EMG for the subject under repetitive holding and releasing grasp using a physiotherapy device. During exercise, the bio-amplifier board is customized to acquire simultaneous EEG and EMG from the region of flexor digitorum superficialis (FDS) of muscle and cortical motor of the brain, with total 284 EMG burst that counting by manual segmentation. The automatic segmentation can detect the total EMG burst by 6.25% error of false burst detection. The usefulness of proposed scheme is also tested to association analysis according to the power of EMG burst and the power of mu-wave of EEG recorded on the motor cortex. The changing trend of the power of mu-wave associated with muscle relaxation, muscle contraction strength and the synchronization level on the motor cortex during exercise are analyzed with integrated information that is relevant with biofeedback concept. The results demonstrate that proposed scheme has potential to be an effective method for the evaluation of biofeedback rehabilitation exercise. \u00a9 2020 North Atlantic University Union NAUN. All rights reserved."
        ]
    },
    {
        "judul":[
            "Comparison of EMD, VMD and EEMD Methods in Respiration Wave Extraction Based on PPG Waves"
        ],
        "penulis":"Hadiyoso S.;Dewi E.M.;Wijayanto I.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Plethysmographic (PPG) wave analysis can provide interesting information including heart rate and oxygen saturation. Since PPG signals are modulated by breathing waves, further analysis can provide additional information that is the respiration rate (RR). This is a way to simplify sensor devices. This paper discusses a respiration wave extraction mechanism to calculate RR using the signal decomposition approach. Decomposition methods which are applied in this study include empirical mode decomposition (EMD), variational mode decomposition (VMD) and ensemble empirical mode decomposition (EEMD). This paper specifically addresses the performance of EEMD to EMD and VMD. This proposed method has been tested on an open PPG dataset (containing PPG and RR wave signals). Test results on 20 PPG signals, each of which had a duration of 1 minute showed that the EEMD was able to estimate the RR with an accuracy of more than 90% with an average error rate of 1 rate\/minute. \u00a9 2020 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Plethysmographic (PPG) wave analysis can provide interesting information including heart rate and oxygen saturation. Since PPG signals are modulated by breathing waves, further analysis can provide additional information that is the respiration rate (RR). This is a way to simplify sensor devices. This paper discusses a respiration wave extraction mechanism to calculate RR using the signal decomposition approach. Decomposition methods which are applied in this study include empirical mode decomposition (EMD), variational mode decomposition (VMD) and ensemble empirical mode decomposition (EEMD). This paper specifically addresses the performance of EEMD to EMD and VMD. This proposed method has been tested on an open PPG dataset (containing PPG and RR wave signals). Test results on 20 PPG signals, each of which had a duration of 1 minute showed that the EEMD was able to estimate the RR with an accuracy of more than 90% with an average error rate of 1 rate\/minute. \u00a9 2020 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Minimax robust landmine detection using forward-looking ground-penetrating radar"
        ],
        "penulis":"Pambudi, Afief D.;Faub, Michael;Ahmad, Fauzia;Zoubir, Abdelhak M.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We propose a robust likelihood-ratio test (LRT) to detect landmines and unexploded ordnance using forward-looking ground-penetrating radar. Instead of modeling the distributions of the target and clutter returns with parametric families, we construct a band of feasible probability densities under each hypothesis. The LRT is then devised based on the least favorable densities within the bands. This detector is designed to maximize the worst case performance over all feasible density pairs and, hence, does not require strong assumptions about the clutter and noise distributions. The proposed technique is evaluated using electromagnetic field simulation data of shallow-buried targets. We show that, compared to detectors based on parametric models, robust detectors can lead to significantly reduced false alarm rates, particularly in cases where there is a mismatch between the assumed model and the true distributions.  \u00a9 1980-2012 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We propose a robust likelihood-ratio test (LRT) to detect landmines and unexploded ordnance using forward-looking ground-penetrating radar. Instead of modeling the distributions of the target and clutter returns with parametric families, we construct a band of feasible probability densities under each hypothesis. The LRT is then devised based on the least favorable densities within the bands. This detector is designed to maximize the worst case performance over all feasible density pairs and, hence, does not require strong assumptions about the clutter and noise distributions. The proposed technique is evaluated using electromagnetic field simulation data of shallow-buried targets. We show that, compared to detectors based on parametric models, robust detectors can lead to significantly reduced false alarm rates, particularly in cases where there is a mismatch between the assumed model and the true distributions.  \u00a9 1980-2012 IEEE."
        ]
    },
    {
        "judul":[
            "Exploratory factor analysis (Efa) to measure entrepreneur satisfaction"
        ],
        "penulis":"Iskamto, Dedi;Ghazali, Puspa Liza;Aftanorhan, Asyraf ;Jenita;Sukono;Bon, Abdul Talib;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper reports on developing a conceptualization for measuring the satisfaction of entrepreneurs. The paper, in doing so, first establishes a theoretical framework by defining constructs of entrepreneur satisfaction from the literature. Secondly, the identification of evaluating requirements from the literature for these constructs, and thirdly, the validation of the theoretical model for measuring the satisfaction of entrepreneurs in Indonesia. The theoretical model consists of 9 entrepreneur satisfaction. The empirical process of validation employed data collected from 100 respondents of pilot test what Micro and Small Enterprises in Pekanbaru Indonesia. The validation method aimed at validating the parameters which measure each of the constructs by statistically determining that the sample used is adequate, using the Bartlett test to ensuring the usefulness of the data for multivariate statistical analysis, validating the measurement requirements as applicable to entrepreneur satisfaction and determining the reliability of each entrepreneur satisfaction. All those goals were accomplished. This coincided in the end result, perhaps even an adjusted statistical model to measure the satisfaction of entrepreneurs in Indonesia. The design has been statistically tested to become a valid and reliable design. \u00a9 IEOM Society International.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper reports on developing a conceptualization for measuring the satisfaction of entrepreneurs. The paper, in doing so, first establishes a theoretical framework by defining constructs of entrepreneur satisfaction from the literature. Secondly, the identification of evaluating requirements from the literature for these constructs, and thirdly, the validation of the theoretical model for measuring the satisfaction of entrepreneurs in Indonesia. The theoretical model consists of 9 entrepreneur satisfaction. The empirical process of validation employed data collected from 100 respondents of pilot test what Micro and Small Enterprises in Pekanbaru Indonesia. The validation method aimed at validating the parameters which measure each of the constructs by statistically determining that the sample used is adequate, using the Bartlett test to ensuring the usefulness of the data for multivariate statistical analysis, validating the measurement requirements as applicable to entrepreneur satisfaction and determining the reliability of each entrepreneur satisfaction. All those goals were accomplished. This coincided in the end result, perhaps even an adjusted statistical model to measure the satisfaction of entrepreneurs in Indonesia. The design has been statistically tested to become a valid and reliable design. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "QoS Performance of Software Define Network Using Open Network Operating System Controller"
        ],
        "penulis":"Ramadhan, Rafli;Armi, Nasrullah;Magdalena, Rita;Nurkahfi, Galih Nugraha;Dinata, Mochamad Mardi Marta;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The demand of network services implies many provider services on the bandwidth and devices quality, respectively. It causes the high time consumption in the network configuration and construction. We study the software define network (SDN) by using open network operating system (ONOS) controller. This controller separates every controller and data plane which is placed in the same network device. The ONOS supports virtual devices like the router and switch by using mininet. The ONOS also emulates a complete host networks, links, and switches on a single machine. We treat 20 hosts and 10 switches which have the linear and ring topologies to investigate the throughput, packet loss, delay, and jitter performance, respectively. The simulation results show that the linear topology achieves 4.9 kbits, 2.69 ms, 0.7 \u03bcs, and 1.4 % on the throughput, delay, jitter, and packet loss, respectively. Meanwhile, the ring topology accomplishes 4.2 mbps, 1.96 ms, 3.4 \u03bcs, and 1.2 ms, respectively. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The demand of network services implies many provider services on the bandwidth and devices quality, respectively. It causes the high time consumption in the network configuration and construction. We study the software define network (SDN) by using open network operating system (ONOS) controller. This controller separates every controller and data plane which is placed in the same network device. The ONOS supports virtual devices like the router and switch by using mininet. The ONOS also emulates a complete host networks, links, and switches on a single machine. We treat 20 hosts and 10 switches which have the linear and ring topologies to investigate the throughput, packet loss, delay, and jitter performance, respectively. The simulation results show that the linear topology achieves 4.9 kbits, 2.69 ms, 0.7 \u03bcs, and 1.4 % on the throughput, delay, jitter, and packet loss, respectively. Meanwhile, the ring topology accomplishes 4.2 mbps, 1.96 ms, 3.4 \u03bcs, and 1.2 ms, respectively. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Image Retrieval using Modified Multi Texton and Rotation Invariant Local Binary Pattern"
        ],
        "penulis":"Bimantoro, Fitri;Aziz, Ashri Annisaak;Husodo, Ario Yudo;Musnansyah, Ahmad;Minarno, Agus Eko;Kurniawardhani, Arrie;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Image retrieval is a standard method used to search a digital image in large image databases. One of the most critical things in image retrieval is the feature extraction process. Several techniques can be used in the image feature extraction process, one of which is Multi Texton Histogram (MTH). MTH is usually carried out with two main processes, namely color quantization, and texture orientation. Improvement of MTH method performance can be made by adding texton. In our experiment, we test the method by using rotated images. In this paper, we develop the use of an invariant method for rotation, namely the Local Binary Pattern Rotation Invariant (LBPROT) method to improve image retrieval precision. The results of combining these two methods produce features of each image. The features produced by each image are compared using a distance matrix. A query image that has the smallest distance matrix value is an image that has the same class as the compared database image. Based on our experiments on typical images, the use of Modified MTH and LBPROT can improve image retrieval performance by increasing the percentage of precision and recall by 3.63% and 0.62%. However, The Modified MTH is better when compared to the merging of the Modified MTH and LBPROT on 45 \u00b0, 135 \u00b0, 225 \u00b0, and 315 \u00b0 angle rotations with precision values by 24% -27%. Meanwhile, our testing result using rotated images, the combination of Modified MTH and LBPROT produces an increase in precision at angles rotation of 90 \u00b0, 180 \u00b0, and 270 \u00b0 by 2% -3%. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Image retrieval is a standard method used to search a digital image in large image databases. One of the most critical things in image retrieval is the feature extraction process. Several techniques can be used in the image feature extraction process, one of which is Multi Texton Histogram (MTH). MTH is usually carried out with two main processes, namely color quantization, and texture orientation. Improvement of MTH method performance can be made by adding texton. In our experiment, we test the method by using rotated images. In this paper, we develop the use of an invariant method for rotation, namely the Local Binary Pattern Rotation Invariant (LBPROT) method to improve image retrieval precision. The results of combining these two methods produce features of each image. The features produced by each image are compared using a distance matrix. A query image that has the smallest distance matrix value is an image that has the same class as the compared database image. Based on our experiments on typical images, the use of Modified MTH and LBPROT can improve image retrieval performance by increasing the percentage of precision and recall by 3.63% and 0.62%. However, The Modified MTH is better when compared to the merging of the Modified MTH and LBPROT on 45 \u00b0, 135 \u00b0, 225 \u00b0, and 315 \u00b0 angle rotations with precision values by 24% -27%. Meanwhile, our testing result using rotated images, the combination of Modified MTH and LBPROT produces an increase in precision at angles rotation of 90 \u00b0, 180 \u00b0, and 270 \u00b0 by 2% -3%. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Throughput-Maximum Energy-Aware Rate Adaptation in W-NCSs over Quasi-Static Fading Channels"
        ],
        "penulis":"Royyan, Muhammad;Vehkapera, Mikko;Charalambous, Themistoklis;Wichman, Risto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, we consider a wireless networked control system (W-NCS) and seek to optimize the performance of the system by adapting the transmission throughput of the communication link, which is assumed to be a quasi-static fading channel. Towards this end, an optimization problem is formulated and solved, herein called Maximum Throughput with Energy Constraints (MaxTEC), in which the optimal achievable throughput is selected subject to the limited available energy per transmission. It is demonstrated that the larger the available energy, the higher the throughput, and, subsequently, the better the control performance. The performance of our proposed scheme is illustrated via simulations of an inverted pendulum on a cart. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we consider a wireless networked control system (W-NCS) and seek to optimize the performance of the system by adapting the transmission throughput of the communication link, which is assumed to be a quasi-static fading channel. Towards this end, an optimization problem is formulated and solved, herein called Maximum Throughput with Energy Constraints (MaxTEC), in which the optimal achievable throughput is selected subject to the limited available energy per transmission. It is demonstrated that the larger the available energy, the higher the throughput, and, subsequently, the better the control performance. The performance of our proposed scheme is illustrated via simulations of an inverted pendulum on a cart. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design and Characterization of Rectangular Array Microstrip Antenna for Cubesat S-Band Transmitter"
        ],
        "penulis":"Benyamin, Sherin Octavani;Wijanto, Heroe;Edwar;Prabowo, Vinsensius Sigit Widhi;Prananditya, Haris;Oktaviani, Shindi Marlina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Automatic Dependent Surveillance-Broadcast (ADS-B) is an air traffic surveillance technology that automatically and periodically broadcasts onboard aircraft flight information such as identity numbers, positions, speeds, and destinations during all phases of flight to avoid collisions. In the future, the radar system will be equipped or even replaced by the ADS-B ground station. Therefore, the Nano-Satellite Laboratory of Telkom University is developing a satellite technology called Tel-USat which the ADS-B receiver is one of the missions. This work focuses on the design and characterization of the antenna to send all the collected ADS-B data to the ground. This antenna is designed by using an FR-4 substrate material with two rectangular patches, linear array, T-junction powerdivider, and proximity coupled rationing. The results obtained during the measurement are return loss values at 2.4 GHz frequency of -18.5 dB, VSWR of 1.2, antenna bandwidth of 163 MHz, and the gainof 6.08 dB. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Automatic Dependent Surveillance-Broadcast (ADS-B) is an air traffic surveillance technology that automatically and periodically broadcasts onboard aircraft flight information such as identity numbers, positions, speeds, and destinations during all phases of flight to avoid collisions. In the future, the radar system will be equipped or even replaced by the ADS-B ground station. Therefore, the Nano-Satellite Laboratory of Telkom University is developing a satellite technology called Tel-USat which the ADS-B receiver is one of the missions. This work focuses on the design and characterization of the antenna to send all the collected ADS-B data to the ground. This antenna is designed by using an FR-4 substrate material with two rectangular patches, linear array, T-junction powerdivider, and proximity coupled rationing. The results obtained during the measurement are return loss values at 2.4 GHz frequency of -18.5 dB, VSWR of 1.2, antenna bandwidth of 163 MHz, and the gainof 6.08 dB. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Modulation Performance of Underwater Visible Light Communication with Variable Wavelength"
        ],
        "penulis":"Ibrahimy, Arya Maulana;Fadilah, Budi Ikhwan;Pamukti, Brian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper evaluates the performance of Underwater Visible Light Communication (UVLC) with various modulation and wavelength. The first scenario will analyze the Signalto-Noise Ratio (SNR) of the UVLC with 450, 480, and 500 nm wavelength. The second scenario will compare the performance of Bit Error Rate (BER) with various modulation from Onoff Keying No-Return Zero (OOK-NRZ), On-Off Keying Return Zero (OOK-RZ), 8 Pulse Position Modulation (8-PPM), and 8 Pulse Amplitude Modulation (8-PAM). Same as the first scenario the comparison of BER use 450, 480, and 500 nm wavelength. From thesimulation of the first scenario, the used of 500 nm wavelength get the result 13.1147, which is the best result of SNR in this simulation. Meanwhile, in the second scenario, the combination of 8-PPM with 500 nm wavelength get the result 1.8922 $\\times 10^{-10}$, which is the best result and the value is smaller from Optical Wireless Communication (OWC) BER which is $10^{-9}$ \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper evaluates the performance of Underwater Visible Light Communication (UVLC) with various modulation and wavelength. The first scenario will analyze the Signalto-Noise Ratio (SNR) of the UVLC with 450, 480, and 500 nm wavelength. The second scenario will compare the performance of Bit Error Rate (BER) with various modulation from Onoff Keying No-Return Zero (OOK-NRZ), On-Off Keying Return Zero (OOK-RZ), 8 Pulse Position Modulation (8-PPM), and 8 Pulse Amplitude Modulation (8-PAM). Same as the first scenario the comparison of BER use 450, 480, and 500 nm wavelength. From thesimulation of the first scenario, the used of 500 nm wavelength get the result 13.1147, which is the best result of SNR in this simulation. Meanwhile, in the second scenario, the combination of 8-PPM with 500 nm wavelength get the result 1.8922 $\\times 10^{-10}$, which is the best result and the value is smaller from Optical Wireless Communication (OWC) BER which is $10^{-9}$ \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Passive node-assisted wireless networks forming raptor codes with random access"
        ],
        "penulis":"Hendraningrat, Denny Kusuma;Ramatryana, I. Nyoman Apraz;Narottama, Bhaskara;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, wireless networks with passive nodes forming a pre-code of Raptor codes, also known as Raptor code-structured wireless networks (RCS-WN), are considered. In RCS-WN, the passive nodes utilize a decode-and-forward (DF) scheme and send the decoded data to the destination by using a scheduling scheme. We propose to deploy random access (RA) in passive nodes, to achieve a solution referred to as an RA-based RCS-WN (RAR-WN), and attempt to compare it with conventional wireless networks applying irregular repetition slotted ALOHA (IRSA). We investigate regular and irregular degree distributions for repetition codes to test the capacity of the proposed RAR-WN, using the extrinsic information transfer (EXIT) chart. This paper also examines the capabilities of the stopping set (both with regular and irregular degree distribution) in RAR-WN. Performance of the proposed system is evaluated in terms of EXIT chart, packet loss rate (PLR), and throughput. The results show that the proposed system is capable of achieving non-dropped throughput performance. \u00a9 2020 National Institute of Telecommunications. All rights reserved.",
            "ONHOOView detailsExpand Substance 1,3-benzoxazine-2,4-dione",
            "Powered by"
        ],
        "abstrak":[
            "In this paper, wireless networks with passive nodes forming a pre-code of Raptor codes, also known as Raptor code-structured wireless networks (RCS-WN), are considered. In RCS-WN, the passive nodes utilize a decode-and-forward (DF) scheme and send the decoded data to the destination by using a scheduling scheme. We propose to deploy random access (RA) in passive nodes, to achieve a solution referred to as an RA-based RCS-WN (RAR-WN), and attempt to compare it with conventional wireless networks applying irregular repetition slotted ALOHA (IRSA). We investigate regular and irregular degree distributions for repetition codes to test the capacity of the proposed RAR-WN, using the extrinsic information transfer (EXIT) chart. This paper also examines the capabilities of the stopping set (both with regular and irregular degree distribution) in RAR-WN. Performance of the proposed system is evaluated in terms of EXIT chart, packet loss rate (PLR), and throughput. The results show that the proposed system is capable of achieving non-dropped throughput performance. \u00a9 2020 National Institute of Telecommunications. All rights reserved."
        ]
    },
    {
        "judul":[
            "Design of blockchain-based electronic health records for indonesian context: Narrative review"
        ],
        "penulis":"Sari, Puspita Kencana;Yazid, Setiadi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Healthcare providers in developing countries manage their medical data in Electronic Health Records (EHRs) system in silos with different structures and data formats that causes the problem of data sharing, interoperability, and data security. This paper aims to propose a concept of blockchain-based EHRs that is relevant to the case of developing countries, especially in Indonesia. The research method used is a narrative review of several literature related to the design of blockchain-based EHRs using Smart Contract from 2016-2020. The design proposed permissioned blockchain with several health care stakeholders as nodes in the network. Different with most previous research that using proof-based, we propose to use vote-based consensus protocol to execute transaction faster. Based on number of national health insurance policy holders, outpatient, and inpatient visits per year, the storage capacity required to keep the transaction is estimated around 2,7 TB per year with 77 transactions per seconds. This design is intended to be a contribution for EHRs platform architecture in the future.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Healthcare providers in developing countries manage their medical data in Electronic Health Records (EHRs) system in silos with different structures and data formats that causes the problem of data sharing, interoperability, and data security. This paper aims to propose a concept of blockchain-based EHRs that is relevant to the case of developing countries, especially in Indonesia. The research method used is a narrative review of several literature related to the design of blockchain-based EHRs using Smart Contract from 2016-2020. The design proposed permissioned blockchain with several health care stakeholders as nodes in the network. Different with most previous research that using proof-based, we propose to use vote-based consensus protocol to execute transaction faster. Based on number of national health insurance policy holders, outpatient, and inpatient visits per year, the storage capacity required to keep the transaction is estimated around 2,7 TB per year with 77 transactions per seconds. This design is intended to be a contribution for EHRs platform architecture in the future.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "City-TSP with Objective Minimizing Distance and Noise"
        ],
        "penulis":"Aurachman, Rio;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Urbanization has encouraged people to have a home in the city. The process of transportation and logistics is also forced to pass through the city area. There is a need to formulate solutions to transportation, supply chain, and logistics problems for cities. One of the commonly used transportation models is the TSP, the Traveling Salesman Problem. Through this paper, we propose a City-TSP, which is a TSP that considers objectives, parameters, and constraints in urban areas. One of the parameters considered is the noise generated from a truck trip. This paper presents the City-TSP model that simultaneously minimizes distance and noise.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Urbanization has encouraged people to have a home in the city. The process of transportation and logistics is also forced to pass through the city area. There is a need to formulate solutions to transportation, supply chain, and logistics problems for cities. One of the commonly used transportation models is the TSP, the Traveling Salesman Problem. Through this paper, we propose a City-TSP, which is a TSP that considers objectives, parameters, and constraints in urban areas. One of the parameters considered is the noise generated from a truck trip. This paper presents the City-TSP model that simultaneously minimizes distance and noise.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The effectiveness of online calculus 2 learning during the Covid-19 pandemic"
        ],
        "penulis":"Susilawati T.;Darmawan I.;Desiasni R.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study aims to analyze the effectiveness of online learning in calculus 2 during the Covid-19 pandemic. The study was conducted in a civil engineering study program at a private tertiary institution on Sumbawa Island. This research is a quasi-experimental research design model non-equivalent control group design. The number of subjects in this study was 71 people. Data analysis used a paired sample t-test analysis with the help of SPSS software. Based on the results of data analysis, online learning is not effective in calculus 2 subjects in the pandemic covid-19 period, there is a significant relationship between conventional learning and online learning and there is a significant difference between conventional learning and online learning. The average value of student learning outcomes is decreased when the online learning system is applied. From these results it can be concluded the online learning system in the 2nd calculus course during the Covid-19 pandemic has not been effective. \u00a9 2020 Institute of Physics Publishing. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Quality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to analyze the effectiveness of online learning in calculus 2 during the Covid-19 pandemic. The study was conducted in a civil engineering study program at a private tertiary institution on Sumbawa Island. This research is a quasi-experimental research design model non-equivalent control group design. The number of subjects in this study was 71 people. Data analysis used a paired sample t-test analysis with the help of SPSS software. Based on the results of data analysis, online learning is not effective in calculus 2 subjects in the pandemic covid-19 period, there is a significant relationship between conventional learning and online learning and there is a significant difference between conventional learning and online learning. The average value of student learning outcomes is decreased when the online learning system is applied. From these results it can be concluded the online learning system in the 2nd calculus course during the Covid-19 pandemic has not been effective. \u00a9 2020 Institute of Physics Publishing. All rights reserved."
        ]
    },
    {
        "judul":[
            "Performance assessment analysis of UHF machines using Reliability, Availability, Maintainability and Safety (RAMS) analysis methods"
        ],
        "penulis":"Nurrahman F.;Atmaji F.T.D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "XYZ Company is manufacturing engaged in the rubber industry located in the city of Bandung, because economic growth and demand from consumers are increasing, making companies demanded to meet the target orders promptly. One way to minimize losses and the possibilities that must be borne by the company is to increase Reliability, Availability, Maintainability of the production and the safety value. Data in the form of Mean Downtime, Mean Time to Failure, Mean Time to Repair is useful for system performance that works. MTTF data can be used to assess safety systems found in PT XYZ with the safety standards of IEC 61508 using Safety Integrity Level. From the results of processing RAMS data using Reliability Block Diagram modeling based on the analytical approach, for 120 hours, the system has a Reliability value (91.12%). The average value of system Maintainability at t = 2 hours is 100%. The Inherent Availability value is 99,981% and the Operational Availability value is 99,980%. Based on the world-class maintenance Key Performace Indicator, leading and lagging availability indicators have reached the indicator target standard. Safety Integrity Level values from calculations based on PFD and RRF values of each system are in SIL 1. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "XYZ Company is manufacturing engaged in the rubber industry located in the city of Bandung, because economic growth and demand from consumers are increasing, making companies demanded to meet the target orders promptly. One way to minimize losses and the possibilities that must be borne by the company is to increase Reliability, Availability, Maintainability of the production and the safety value. Data in the form of Mean Downtime, Mean Time to Failure, Mean Time to Repair is useful for system performance that works. MTTF data can be used to assess safety systems found in PT XYZ with the safety standards of IEC 61508 using Safety Integrity Level. From the results of processing RAMS data using Reliability Block Diagram modeling based on the analytical approach, for 120 hours, the system has a Reliability value (91.12%). The average value of system Maintainability at t = 2 hours is 100%. The Inherent Availability value is 99,981% and the Operational Availability value is 99,980%. Based on the world-class maintenance Key Performace Indicator, leading and lagging availability indicators have reached the indicator target standard. Safety Integrity Level values from calculations based on PFD and RRF values of each system are in SIL 1. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Optimizing BTS Placement Using Hybrid Evolutionary Firefly Algorithm"
        ],
        "penulis":"Afuzagani, Dzakyta;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The internet has become one of the basic needs of today's society. Increasing internet users causes the addition of Base Transceiver Station (BTS) for each region. The construction of BTS certainly requires many costs if the placement is not optimum and leads to the futile placement of BTS. Therefore, it must be optimized for placement. In this research, a Hybrid Evolutionary Firefly Algorithm (HEFA) is implemented and compared to the original Firefly Algorithm (FA) in tackling this problem. Some computer simulations show that the HEFA gives an average fitness value up to 98.62%, which is slightly higher than the FA that produces 97.73%. It optimizes the BTS up to half of the initial generation.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The internet has become one of the basic needs of today's society. Increasing internet users causes the addition of Base Transceiver Station (BTS) for each region. The construction of BTS certainly requires many costs if the placement is not optimum and leads to the futile placement of BTS. Therefore, it must be optimized for placement. In this research, a Hybrid Evolutionary Firefly Algorithm (HEFA) is implemented and compared to the original Firefly Algorithm (FA) in tackling this problem. Some computer simulations show that the HEFA gives an average fitness value up to 98.62%, which is slightly higher than the FA that produces 97.73%. It optimizes the BTS up to half of the initial generation.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Investigation of a measles transmission with vaccination: A case study in Jakarta, Indonesia"
        ],
        "penulis":"Fakhruddin, Muhammad;Suandi, Dani;Sumiati;Fahlena, Hilda;Nuraini, Nuning;Soewono, Edy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Measles is a contagious disease caused by the measles virus of genus Morbillivirus, which has been spreading in many affected regions. This infection is characterized by the appearance of rashes all over the body and potentially cause serious complications, especially among infants and children. Before measles immunization was promoted, it is one of the endemic diseases that caused the most fatalities each year in the world. This paper aims to analyze and to investigate measles transmission in Jakarta via an SIHR epidemic model involving vaccination from January to December 2017. Jakarta Health Office collected the observed data of measles incidence. We then derived the basic reproduction number as a threshold of disease transmission and obtained the local as well as global stability of the equilibria under certain conditions. The unobserved parameters and initial conditions were estimated by minimizing errors between data and numerical results. Furthermore, a stochastic model was developed to capture the data and to accommodate the randomness of the transmission. Sensitivity analysis was also performed to analyze and to identify the parameters which give significant contributions to the spread of the virus. We then obtained simulations of vaccine level coverage. The data is shown within a 95% confidence interval of the stochastic solutions, and the average of the stochastic solutions is relatively close to the solution of the deterministic model. The most sensitive parameter in the infected compartment is the hospitalized rate, which can be considered to be one of the essential factors to reduce the number of cases for policymakers. We hence proposed a control strategy which is providing treatment accesses easier for infected individuals is better than vaccinating when an outbreak occurs. \u00a9 2020 the Author(s), licensee AIMS Press. This is an open access article distributed under the terms of the Creative Commons Attribution License (http:\/\/creativecommons.org\/licenses\/by\/4.0)",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Measles is a contagious disease caused by the measles virus of genus Morbillivirus, which has been spreading in many affected regions. This infection is characterized by the appearance of rashes all over the body and potentially cause serious complications, especially among infants and children. Before measles immunization was promoted, it is one of the endemic diseases that caused the most fatalities each year in the world. This paper aims to analyze and to investigate measles transmission in Jakarta via an SIHR epidemic model involving vaccination from January to December 2017. Jakarta Health Office collected the observed data of measles incidence. We then derived the basic reproduction number as a threshold of disease transmission and obtained the local as well as global stability of the equilibria under certain conditions. The unobserved parameters and initial conditions were estimated by minimizing errors between data and numerical results. Furthermore, a stochastic model was developed to capture the data and to accommodate the randomness of the transmission. Sensitivity analysis was also performed to analyze and to identify the parameters which give significant contributions to the spread of the virus. We then obtained simulations of vaccine level coverage. The data is shown within a 95% confidence interval of the stochastic solutions, and the average of the stochastic solutions is relatively close to the solution of the deterministic model. The most sensitive parameter in the infected compartment is the hospitalized rate, which can be considered to be one of the essential factors to reduce the number of cases for policymakers. We hence proposed a control strategy which is providing treatment accesses easier for infected individuals is better than vaccinating when an outbreak occurs. \u00a9 2020 the Author(s), licensee AIMS Press. This is an open access article distributed under the terms of the Creative Commons Attribution License (http:\/\/creativecommons.org\/licenses\/by\/4.0)"
        ]
    },
    {
        "judul":[
            "Design of Open Loop Single Axis Solar Tracker System"
        ],
        "penulis":"Rinaldi, Rizal;Aprillia, Bandiyah Sri;Ekaputri, Cahyantari;Reza, Muhamad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The amount of power output in a solar power system depends on the intensity of solar radiation. The earth's movements however cause changes in the intensity of solar radiation received by solar panels on the daily. Therefore, the implementation of a controller that can track the position of the sun (solar tracker) is believed to increase the power output of solar panels. This research focuses on the design of a photovoltaic panel drive system using an Android-based application as a monitoring media. The application is used to monitor the current temperature and provide a desired angle input. Based on the test results, the average power output of a fixed PV reached only 17.15 Watt, while on a single axis PV, average output reached 21.50 Watt. It can be concluded that in the single axis PV, average power output increased by more than 25% compared to the fixed PV.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The amount of power output in a solar power system depends on the intensity of solar radiation. The earth's movements however cause changes in the intensity of solar radiation received by solar panels on the daily. Therefore, the implementation of a controller that can track the position of the sun (solar tracker) is believed to increase the power output of solar panels. This research focuses on the design of a photovoltaic panel drive system using an Android-based application as a monitoring media. The application is used to monitor the current temperature and provide a desired angle input. Based on the test results, the average power output of a fixed PV reached only 17.15 Watt, while on a single axis PV, average output reached 21.50 Watt. It can be concluded that in the single axis PV, average power output increased by more than 25% compared to the fixed PV.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Physicochemical parameters data assimilation for efficient improvement of water quality index prediction: Comparative assessment of a noise suppression hybridization approach"
        ],
        "penulis":"Rezaie-Balf, Mohammad;Attar, Nasrin Fathollahzadeh;Mohammadzadeh, Ardashir;Murti, Muhammad Ary;Ahmed, Ali Najah;Fai, Chow Ming;Nabipour, Narjes;Alaghmand, Sina;El-Shafie, Ahmed;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Water quality has a crucial impact on human health; therefore, water quality index modeling is one of the challenging issues in the water sector. The accurate prediction of water quality index is an essential requisite for water quality management, human health, public consumption, and domestic uses. A comprehensive review as an initial attempt is conducted on existing solutions through data-driven models. In addition, the ensemble Kalman filter is found to be a suitable data assimilation method, which is successfully applied in hydrological variables modeling and other complexes, nonlinear, and chaotic problems. In this study, a new application of ensemble Kalman filter-artificial neural network is proposed to predict water quality index using physicochemical parameters for two commonly pollutant rivers, namely Klang and Langat, in Malaysia. As a further attempt, in order to improve the models\u2019 performance, a new preprocessing technique is adopted as the newly constructed assimilated model. The results confirm that ensemble hybrid based intrinsic time-scale decomposition has reduced root mean square error by 24% for Klang and 34% for Langat, respectively, compared with the intrinsic time-scale decomposition-conventional neural network model. Overall, the developed assimilated methodology shows the robustness of the proposed ensemble hybrid model in analyzing water quality index over monthly horizons that experts could evaluate the water quality of rivers more efficiently. \u00a9 2020 Elsevier Ltd",
            "OOOHONOOHHView detailsExpand Substance isosorbide mononitrate",
            "Powered by",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Clean water and sanitationGoal 6Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Water quality has a crucial impact on human health; therefore, water quality index modeling is one of the challenging issues in the water sector. The accurate prediction of water quality index is an essential requisite for water quality management, human health, public consumption, and domestic uses. A comprehensive review as an initial attempt is conducted on existing solutions through data-driven models. In addition, the ensemble Kalman filter is found to be a suitable data assimilation method, which is successfully applied in hydrological variables modeling and other complexes, nonlinear, and chaotic problems. In this study, a new application of ensemble Kalman filter-artificial neural network is proposed to predict water quality index using physicochemical parameters for two commonly pollutant rivers, namely Klang and Langat, in Malaysia. As a further attempt, in order to improve the models\u2019 performance, a new preprocessing technique is adopted as the newly constructed assimilated model. The results confirm that ensemble hybrid based intrinsic time-scale decomposition has reduced root mean square error by 24% for Klang and 34% for Langat, respectively, compared with the intrinsic time-scale decomposition-conventional neural network model. Overall, the developed assimilated methodology shows the robustness of the proposed ensemble hybrid model in analyzing water quality index over monthly horizons that experts could evaluate the water quality of rivers more efficiently. \u00a9 2020 Elsevier Ltd"
        ]
    },
    {
        "judul":[
            "Human-Like Constrained-Mating to Make Genetic Algorithm More Explorative"
        ],
        "penulis":"Rizal, Achmad Choirul;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A genetic algorithm (GA) is widely used to solve many optimization problems. It does not promise accurate results but provides an acceptable ones in various practical applications. Sometimes, it is trapped at a premature convergence or a local optimum for a complex problem. Hence, a Human-Like Constrained-Mating Genetic Algorithm (HLCMGA) is proposed in this paper to tackle such a problem. HLCMGA can be simply described as a crossover with human-like constrained mating to improve exploration ability. Computer simulation on ten benchmark multi-modal functions shows that it performs better than the simple GA (SGA). Compared to a state-of-the-art Rao algorithm on five benchmark functions, it reaches the same performances on the four functions and just loses on one function. The simulation also informs that it has a higher exploration ability to converge at the global optimum on various complex search spaces.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A genetic algorithm (GA) is widely used to solve many optimization problems. It does not promise accurate results but provides an acceptable ones in various practical applications. Sometimes, it is trapped at a premature convergence or a local optimum for a complex problem. Hence, a Human-Like Constrained-Mating Genetic Algorithm (HLCMGA) is proposed in this paper to tackle such a problem. HLCMGA can be simply described as a crossover with human-like constrained mating to improve exploration ability. Computer simulation on ten benchmark multi-modal functions shows that it performs better than the simple GA (SGA). Compared to a state-of-the-art Rao algorithm on five benchmark functions, it reaches the same performances on the four functions and just loses on one function. The simulation also informs that it has a higher exploration ability to converge at the global optimum on various complex search spaces.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Hate speech detection in Indonesian language instagram"
        ],
        "penulis":"Putra, I. Gede Manggala;Nurjanah, Dade;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Hate speech is a form of communication which contains hatred by doing things, such as inciting, insulting, disparaging, or demeaning a person or group. Hate speech issues in Indonesia often have linkages to politics. In 2018 and 2019, for example, the hate speech relates to the local leader and presidential elections. The hate speech actors commonly use social networks, such as Instagram, to spread their hatred words. About 60% of hate speech is found in the comments of the posts and it will be a real threat if not quickly detected. Our study aims to detect hate speech in Instagram comments. We propose the use of a word2vec method with skip-gram models and a modified TextCNN to learn and detect hate speech texts. Furthermore, random oversampling, random under sampling, and class weight was used to solve imbalanced dataset problems. The results show that the best accuracy, in term of F-score, is 93.70%, gained from a combination of word2vec skip-gram with window size 15, a modified TextCNN, and random oversampling methods. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hate speech is a form of communication which contains hatred by doing things, such as inciting, insulting, disparaging, or demeaning a person or group. Hate speech issues in Indonesia often have linkages to politics. In 2018 and 2019, for example, the hate speech relates to the local leader and presidential elections. The hate speech actors commonly use social networks, such as Instagram, to spread their hatred words. About 60% of hate speech is found in the comments of the posts and it will be a real threat if not quickly detected. Our study aims to detect hate speech in Instagram comments. We propose the use of a word2vec method with skip-gram models and a modified TextCNN to learn and detect hate speech texts. Furthermore, random oversampling, random under sampling, and class weight was used to solve imbalanced dataset problems. The results show that the best accuracy, in term of F-score, is 93.70%, gained from a combination of word2vec skip-gram with window size 15, a modified TextCNN, and random oversampling methods. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Work loyalty: Organizational commitment or compulsion"
        ],
        "penulis":"Rizki, Maulidyah Amalina;Aisyah, Siti;Pristyadi, Budiyono;Sukaris, Sukaris;Handayani, Anita;Hidayati, Roziana Ainul;Santoso, Rahmat Agus;Himawan, Abdurrahman Faris Indriya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, the company is facing a challenge in managing human resources, on the one hand, the company hopes to get employees who are loyal to their work, but sometimes measuring loyalty becomes very difficult because it is not only measured by the willingness to linger i n work but also the loyalty that results in productivity. The purpose of this study is to find out employee loyalty in work as loyalty or compulsion. Analytical techniques using phenomenological studies with stages of data reduction, data display and making conclusions. The results showed that employees have a work loyalty to the company that is due to the comfort in working, co-workers who are compact, closeness to colleagues who are like family, salary and benefits, and the last is a supportive work environment. Another finding is that the dominant factor in influencing employee work loyalty is an organizational commitment and the absence of compulsion at work. \u00a9 IJSTR 2020.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, the company is facing a challenge in managing human resources, on the one hand, the company hopes to get employees who are loyal to their work, but sometimes measuring loyalty becomes very difficult because it is not only measured by the willingness to linger i n work but also the loyalty that results in productivity. The purpose of this study is to find out employee loyalty in work as loyalty or compulsion. Analytical techniques using phenomenological studies with stages of data reduction, data display and making conclusions. The results showed that employees have a work loyalty to the company that is due to the comfort in working, co-workers who are compact, closeness to colleagues who are like family, salary and benefits, and the last is a supportive work environment. Another finding is that the dominant factor in influencing employee work loyalty is an organizational commitment and the absence of compulsion at work. \u00a9 IJSTR 2020."
        ]
    },
    {
        "judul":[
            "The Implementation of Stream Architecture for Handling Big Data Velocity in Social Media"
        ],
        "penulis":"Hamami F.;Dahlan I.A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Big data is a term of complex data and difficult to process. It consists of several characteristics called 6 Vs. Many applications generate huge data and grow rapidly in seconds. This kind of data comes from many sources such as social media, Internet of Things, log system, e-commerce and soon. This rapid data should be handled with a different approach in big data solutions. This paper proposes to create stream architecture for big data velocity with open source technologies such as Apache Kafka and NoSQL database. The implementation is to handle massive incoming data from social media with specific keywords from Twitter and ingested to NoSQL Database though stream architecture.Historical data then processed to gain valuable insight for better information. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Big data is a term of complex data and difficult to process. It consists of several characteristics called 6 Vs. Many applications generate huge data and grow rapidly in seconds. This kind of data comes from many sources such as social media, Internet of Things, log system, e-commerce and soon. This rapid data should be handled with a different approach in big data solutions. This paper proposes to create stream architecture for big data velocity with open source technologies such as Apache Kafka and NoSQL database. The implementation is to handle massive incoming data from social media with specific keywords from Twitter and ingested to NoSQL Database though stream architecture.Historical data then processed to gain valuable insight for better information. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "City brand attractiveness on tourism using rasch model approach"
        ],
        "penulis":"Miftahuddin, Asep;Hermanto, Bambang;Raharja, Sam'un Jaja;Chan, Arianis;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The study presented in this paper analyzes City Brand Attractiveness. Focusing on the city in Indonesia, namely West Bandung Regency, this study aims to examine the factors that affect the City Brand Attractiveness. The empirical application is per-formed on the basis of a sample of 373 visitors who have traveled to West Bandung Regency, analyzed by using Rasch Model. The findings show that tourists response to the city's attractiveness is low, the Ancillary Service factor with a low response, and the Tourism Attraction factor get high expectations from tourists responses. To the researcher understanding, there are limited studies on city brand attractiveness from the perspective of visitors, this could be a novelty of this paper is to explain how the city brand attractiveness affect city branding, Hence, the findings provide a guideline for future researchers or city branding stakeholders an overview of city brand attractiveness on city branding. \u00a9 ExcelingTech Pub, UK.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The study presented in this paper analyzes City Brand Attractiveness. Focusing on the city in Indonesia, namely West Bandung Regency, this study aims to examine the factors that affect the City Brand Attractiveness. The empirical application is per-formed on the basis of a sample of 373 visitors who have traveled to West Bandung Regency, analyzed by using Rasch Model. The findings show that tourists response to the city's attractiveness is low, the Ancillary Service factor with a low response, and the Tourism Attraction factor get high expectations from tourists responses. To the researcher understanding, there are limited studies on city brand attractiveness from the perspective of visitors, this could be a novelty of this paper is to explain how the city brand attractiveness affect city branding, Hence, the findings provide a guideline for future researchers or city branding stakeholders an overview of city brand attractiveness on city branding. \u00a9 ExcelingTech Pub, UK."
        ]
    },
    {
        "judul":[
            "Appraising Personal Data Protection in Startup Companies in Financial Technology: A Case Study of ABC Corp"
        ],
        "penulis":"Rozi, Muhamad Fahru;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Financial Technology (fintech) has been immerged extensively in the last decade. In the realm of disruptive world, there are many areas in which startup companies are developing their business. There is always contradiction when dealing with innovation as core of digital disruption and how privacy remains as hot issues at the edge of everybody's talks. Internet plays important roles to sustain the trends. As rapidly growing country, 68% of Indonesian has access to the Internet. It drives startup companies on financial technology to innovate more and besides that they must comply to regulation in regard with personal data protection. This research aims to appraise how startup company on financial technology protect users' personal data. Personal data protection principles from international organization and Indonesian regulation regarding personal data protection are used to appraise how ABC Corp as a startup company that deliver financial technology service in Indonesian society. To ensure that its service is qualified and trustable, ABC Corp should be appraised using relevant criteria and qualitative approach. The results showed that most of regulations from sectorial supervising agency have been adhered by ABC Corp. The results bring meaningful insight to improve performance on personal data protection. They can became lessons for similar emerging startup companies in financial technology when acquiring their qualifications to protect users' personal data and keep their sustainability. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Financial Technology (fintech) has been immerged extensively in the last decade. In the realm of disruptive world, there are many areas in which startup companies are developing their business. There is always contradiction when dealing with innovation as core of digital disruption and how privacy remains as hot issues at the edge of everybody's talks. Internet plays important roles to sustain the trends. As rapidly growing country, 68% of Indonesian has access to the Internet. It drives startup companies on financial technology to innovate more and besides that they must comply to regulation in regard with personal data protection. This research aims to appraise how startup company on financial technology protect users' personal data. Personal data protection principles from international organization and Indonesian regulation regarding personal data protection are used to appraise how ABC Corp as a startup company that deliver financial technology service in Indonesian society. To ensure that its service is qualified and trustable, ABC Corp should be appraised using relevant criteria and qualitative approach. The results showed that most of regulations from sectorial supervising agency have been adhered by ABC Corp. The results bring meaningful insight to improve performance on personal data protection. They can became lessons for similar emerging startup companies in financial technology when acquiring their qualifications to protect users' personal data and keep their sustainability. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Principal Component Analysis to Determine Main Factors Stock Price of Consumer Goods Industry"
        ],
        "penulis":"Fitriyana, Rahma Firsty;Rikumahu, Brady;Widiyanesti;Alamsyah, Andry;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The ability to predict the stock price is the important factor in achieving the profit in stock investment, and the prediction is usually done by relating the price of a stock to factors that influence it. The problem is, there are a large number of variables that can be used to predict the stock prices so it is difficult for a potential investor to choose which variables should be used in predicting the stock prices. This research used the Principal Component Analysis as the dimension reduction method to form major components that influence the stock prices without losing the information and uses data from five companies which have the highest market capitalization that listed in the Consumer Goods Sector of the Indonesia Stock Exchange: Companies A, B, C, D, and E. Using Principal Component Analysis, this research reduces eighteen variables into factors that influence the stock price the most. Result shows that Profitability Ratio has a high contribution in determining stock price.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The ability to predict the stock price is the important factor in achieving the profit in stock investment, and the prediction is usually done by relating the price of a stock to factors that influence it. The problem is, there are a large number of variables that can be used to predict the stock prices so it is difficult for a potential investor to choose which variables should be used in predicting the stock prices. This research used the Principal Component Analysis as the dimension reduction method to form major components that influence the stock prices without losing the information and uses data from five companies which have the highest market capitalization that listed in the Consumer Goods Sector of the Indonesia Stock Exchange: Companies A, B, C, D, and E. Using Principal Component Analysis, this research reduces eighteen variables into factors that influence the stock price the most. Result shows that Profitability Ratio has a high contribution in determining stock price.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Design of Multicriteria Decision Making Tools for IT Project Selection: A Case from Software House"
        ],
        "penulis":"Soesanto R.P.;Tripiawan W.;Darmawan I.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information Technology as an enabler helps organization to improve business by gaining more competitive advantage, it plays a significant role for organization to compete. Many organizations sense the pressure to leverage their investment towards information system. Selecting the optimal portfolio of IT projects is becoming increasingly important as the dependency on IT for organizational performance increases. The purpose of this research is to design tools for IT project selection tools in the software house. Combination of Delphi, AHP, and Factor rating method is used to gain the prioritize of the projects. Agile method is used to develop the application. The application is built in web platform to help the organization decision. Future research can be done to consider more variables for choosing the right project for the organization. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information Technology as an enabler helps organization to improve business by gaining more competitive advantage, it plays a significant role for organization to compete. Many organizations sense the pressure to leverage their investment towards information system. Selecting the optimal portfolio of IT projects is becoming increasingly important as the dependency on IT for organizational performance increases. The purpose of this research is to design tools for IT project selection tools in the software house. Combination of Delphi, AHP, and Factor rating method is used to gain the prioritize of the projects. Agile method is used to develop the application. The application is built in web platform to help the organization decision. Future research can be done to consider more variables for choosing the right project for the organization. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Measurement of Feasibility and Risk Level on Modern Embroidery Kebaya Boutique Establishment in Jakarta"
        ],
        "penulis":"Hanaa R.W.;Chumaidiyah E.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Business X is a creative business in Kebaya clothing, fabrics, and modern embroidered batik. The survey states that many medium business category turn into micro businesses due to the increasing number of imported textile products, resulting in a narrower market share. Under this condition, the company decided to create a Business X boutique considering that the products were not sold alone but at department stores that has a very high competition because of the large apparel industry continued to expand its business. In this paper, a feasibility analysis and the risk level measurement of the opening of this boutique are carried out. The market aspect begins with the distribution of questionnaires to obtain the demand and income projections. The technical aspects is for determining location using factor rating, layout and funding needs. Financial aspects estimate sales revenue and cashflow. The calculation results show NPV>0, PBP in 2, 989 years, and IRR(40%)>MARR(10.99%), it can be concluded that the Business X boutique establishment is feasible. The risk is 21.7% and with a MARR (10.99%), the rate is 32.69%. Based on the rate value that is smaller than the IRR(40%) and NPV>0, then by observing the level of risk, this business is feasible. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Business X is a creative business in Kebaya clothing, fabrics, and modern embroidered batik. The survey states that many medium business category turn into micro businesses due to the increasing number of imported textile products, resulting in a narrower market share. Under this condition, the company decided to create a Business X boutique considering that the products were not sold alone but at department stores that has a very high competition because of the large apparel industry continued to expand its business. In this paper, a feasibility analysis and the risk level measurement of the opening of this boutique are carried out. The market aspect begins with the distribution of questionnaires to obtain the demand and income projections. The technical aspects is for determining location using factor rating, layout and funding needs. Financial aspects estimate sales revenue and cashflow. The calculation results show NPV>0, PBP in 2, 989 years, and IRR(40%)>MARR(10.99%), it can be concluded that the Business X boutique establishment is feasible. The risk is 21.7% and with a MARR (10.99%), the rate is 32.69%. Based on the rate value that is smaller than the IRR(40%) and NPV>0, then by observing the level of risk, this business is feasible. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Prediction of Tide level by using Holtz-Winters Exponential Smoothing: Case study in Cilacap Bay"
        ],
        "penulis":"Wibowo, Dwinov Satrio;Adytia, Didit;Saepudin, Deni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Sea level rise is a phenomenon that causes the sea level to rise to some extent, And the impact from The changes in the tide level can influence flooding in coastal area that can damage the structure of the building around that area and also disturb the health of functionally linked neighboring ecosystems. But now with the development of technology and science it is possible to make some projection of the future tidal level by using a time series data, which is very important for an island country like Indonesia, this forecasted data can be used to make a planning and implementing a projects in port and coastal area. Now, there are many methods to predict the future value of several things. In this paper, the Holt-Winters Exponential Smoothings applied to forecast the tidal level in Cilacap. Then the Holt-Winters forecasting performance compared with the Autoregressive Integrated Moving Average (ARIMA), and Seasonal-Autoregressive Integrated Moving Average (SARIMA), in order to see which one that can produce the best forecast. The method performance measured by using root mean square error (RMSE) and R-Square. The Holt-Winters Exponential smoothing produces RMSE and R-Square that are better than ARIMA and SARIMA. The choice of seasonal period significantly affects the forecasting result produced by the Holt-Winters method.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sea level rise is a phenomenon that causes the sea level to rise to some extent, And the impact from The changes in the tide level can influence flooding in coastal area that can damage the structure of the building around that area and also disturb the health of functionally linked neighboring ecosystems. But now with the development of technology and science it is possible to make some projection of the future tidal level by using a time series data, which is very important for an island country like Indonesia, this forecasted data can be used to make a planning and implementing a projects in port and coastal area. Now, there are many methods to predict the future value of several things. In this paper, the Holt-Winters Exponential Smoothings applied to forecast the tidal level in Cilacap. Then the Holt-Winters forecasting performance compared with the Autoregressive Integrated Moving Average (ARIMA), and Seasonal-Autoregressive Integrated Moving Average (SARIMA), in order to see which one that can produce the best forecast. The method performance measured by using root mean square error (RMSE) and R-Square. The Holt-Winters Exponential smoothing produces RMSE and R-Square that are better than ARIMA and SARIMA. The choice of seasonal period significantly affects the forecasting result produced by the Holt-Winters method.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Green Innovative Product and Its Effects on Environmental"
        ],
        "penulis":"Widodo, Arry;Wahid, Nabsiah Abdul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The presence of green innovative product (GIP) is observed to influence consumers' purchasing decisions as they become more ecologically aware of the effects caused by conventional products' consumption to the environment. This article reviews the concept behind GIP and its effect on consumer's behavior. The article focuses on the meaning and classification of GIP and on how it affects consumer's behavior in terms of their satisfaction, environmental attitude and also purchase. Several issues that arise for customer when they consume GIP will be raised. The article will also address why the industry such as oil and gas needs to cater to the need for GIP and provide basic guidelines on how this is achieved without too much difficulty. The insights are expected to help build our understanding on the importance of GIP to be researched and on the potential of its commercial value that encourages consumers to repeat purchase after consuming it. In addition, the insights may give an idea for government and the industry in forming and formulating appropriate policies as well as increasing public's environmental sensitivity. The article implies the important connection between GIP and individual's identity as well as their ecological beliefs. \u00a9 2020 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The presence of green innovative product (GIP) is observed to influence consumers' purchasing decisions as they become more ecologically aware of the effects caused by conventional products' consumption to the environment. This article reviews the concept behind GIP and its effect on consumer's behavior. The article focuses on the meaning and classification of GIP and on how it affects consumer's behavior in terms of their satisfaction, environmental attitude and also purchase. Several issues that arise for customer when they consume GIP will be raised. The article will also address why the industry such as oil and gas needs to cater to the need for GIP and provide basic guidelines on how this is achieved without too much difficulty. The insights are expected to help build our understanding on the importance of GIP to be researched and on the potential of its commercial value that encourages consumers to repeat purchase after consuming it. In addition, the insights may give an idea for government and the industry in forming and formulating appropriate policies as well as increasing public's environmental sensitivity. The article implies the important connection between GIP and individual's identity as well as their ecological beliefs. \u00a9 2020 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Industrial internet of things: Recent advances, enabling technologies and open challenges"
        ],
        "penulis":"Khan W.Z.;Rehman M.H.;Zangoti H.M.;Afzal M.K.;Armi N.;Salah K.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The adoption of emerging technological trends and applications of the Internet of Things (IoT) in the industrial systems is leading towards the development of Industrial IoT (IIoT). IIoT serves as a new vision of IoT in the industrial sector by automating smart objects for sensing, collecting, processing and communicating the real-time events in industrial systems. The major objective of IIoT is to achieve high operational efficiency, increased productivity, and better management of industrial assets and processes through product customization, intelligent monitoring applications for production floor shops and machine health, and predictive and preventive maintenance of industrial equipment. In this paper, we present a new and clear definition of IIoT, which can help the readers to understand the concept of IIoT. We have described the state-of-the-art research efforts in IIoT. Finally, we have highlighted the enabling technologies for IIoT and recent challenges faced by IIoT. \u00a9 2019",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The adoption of emerging technological trends and applications of the Internet of Things (IoT) in the industrial systems is leading towards the development of Industrial IoT (IIoT). IIoT serves as a new vision of IoT in the industrial sector by automating smart objects for sensing, collecting, processing and communicating the real-time events in industrial systems. The major objective of IIoT is to achieve high operational efficiency, increased productivity, and better management of industrial assets and processes through product customization, intelligent monitoring applications for production floor shops and machine health, and predictive and preventive maintenance of industrial equipment. In this paper, we present a new and clear definition of IIoT, which can help the readers to understand the concept of IIoT. We have described the state-of-the-art research efforts in IIoT. Finally, we have highlighted the enabling technologies for IIoT and recent challenges faced by IIoT. \u00a9 2019"
        ]
    },
    {
        "judul":[
            "FFT-based data hiding on audio in LWT-domain using spread spectrum technique"
        ],
        "penulis":"Budiman, Gelar;Suksmono, Andriyan Bayu;Danudirdjo, Donny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Audio watermarking is a process to hide digital data without being seen or heard by the sense of sight or hearing. Watermaking is applied to insert the copyright on digital media, such as an image file, an audio file or a video file. In this paper, we propose watermarking procedure to embed spread spectrum watermark into frequency domain of adaptive selected subband from host audio. Lifting Wavelet Transform (LWT) is used to decompose the host audio into several subbands, and then Fast Fourier Transform (FFT) transforms selected several subbands with lowest energy. The watermark image is converted into one-dimensional signal, then it is modulated by imperceptible pseudo-noise (PN) code with controlled gain. Next, the frequency domain of audio is added by modulated and imperceptible watermark prior to transforming it to time domain by Inverse FFT (IFFT) obtaining watermarked subbands. Finally, the watermarked subbands are combined with other unused subbands by inverse LWT (ILWT) becoming the perfect version of watermarked audio. The result of this method has good robustness against most attacks from stirmark benchmark experiments, good imperceptibility with Signal to Noise Ratio (SNR) more than 30 dB and payload 172.66 bps. \u00a9 2020 Kauno Technologijos Universitetas. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Audio watermarking is a process to hide digital data without being seen or heard by the sense of sight or hearing. Watermaking is applied to insert the copyright on digital media, such as an image file, an audio file or a video file. In this paper, we propose watermarking procedure to embed spread spectrum watermark into frequency domain of adaptive selected subband from host audio. Lifting Wavelet Transform (LWT) is used to decompose the host audio into several subbands, and then Fast Fourier Transform (FFT) transforms selected several subbands with lowest energy. The watermark image is converted into one-dimensional signal, then it is modulated by imperceptible pseudo-noise (PN) code with controlled gain. Next, the frequency domain of audio is added by modulated and imperceptible watermark prior to transforming it to time domain by Inverse FFT (IFFT) obtaining watermarked subbands. Finally, the watermarked subbands are combined with other unused subbands by inverse LWT (ILWT) becoming the perfect version of watermarked audio. The result of this method has good robustness against most attacks from stirmark benchmark experiments, good imperceptibility with Signal to Noise Ratio (SNR) more than 30 dB and payload 172.66 bps. \u00a9 2020 Kauno Technologijos Universitetas. All rights reserved."
        ]
    },
    {
        "judul":[
            "Classification of Student Academic Performance using Fuzzy Soft Set"
        ],
        "penulis":"Riyadi Yanto, Iwan Tri;Sutoyo, Edi;Rahman, Arif;Hidayat, Rahmat;Ramli, Azizul Azhar;Fudzee, Mohd Farhan Md.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Students are one of the substances that need to be considered in relation to the world of education, because students are translators of the dynamics of science, and carry out the task of exploring that knowledge. As a subject with potential and, at the same time, objects in their activities and creativity, students are expected to be able to develop their qualities. The quality can be seen from the academic achievements achieved, which are evidence of the effort earned by students. Student academic achievement is evaluated at the end of each semester to determine the learning outcomes that have been achieved. If a student cannot meet certain academic criteria to be declared eligible to continue their studies, the student is declared to be not graduating on time or even dropout (DO). The high number of students not graduating on time or dropouts at higher institutions can be minimized by the policies of higher institutions by directing and detecting at-risk students in the early stages of education. Therefore, in this paper, we present the use of Fuzzy Soft Set Classification (FSSC), which is based on the Fuzzy Soft set theory to predict student graduation. The 2068 dataset was taken from the Directorate of Information Systems, Ahmad Dahlan University. The results showed that the FSSC reached up to 0.893292 in terms of accuracy. So, it is expected to be able to detect students at risk in the early stages of education so that higher education can minimize students not graduating on time or dropout by providing appropriate treatment and designing strategic programs. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Students are one of the substances that need to be considered in relation to the world of education, because students are translators of the dynamics of science, and carry out the task of exploring that knowledge. As a subject with potential and, at the same time, objects in their activities and creativity, students are expected to be able to develop their qualities. The quality can be seen from the academic achievements achieved, which are evidence of the effort earned by students. Student academic achievement is evaluated at the end of each semester to determine the learning outcomes that have been achieved. If a student cannot meet certain academic criteria to be declared eligible to continue their studies, the student is declared to be not graduating on time or even dropout (DO). The high number of students not graduating on time or dropouts at higher institutions can be minimized by the policies of higher institutions by directing and detecting at-risk students in the early stages of education. Therefore, in this paper, we present the use of Fuzzy Soft Set Classification (FSSC), which is based on the Fuzzy Soft set theory to predict student graduation. The 2068 dataset was taken from the Directorate of Information Systems, Ahmad Dahlan University. The results showed that the FSSC reached up to 0.893292 in terms of accuracy. So, it is expected to be able to detect students at risk in the early stages of education so that higher education can minimize students not graduating on time or dropout by providing appropriate treatment and designing strategic programs. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Simulation of transport problem with clustering velocity-density function"
        ],
        "penulis":"Daniswara, Ferdian Akbar;Gunawan P.H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper discusses the use of K-Means clustering method in finding an estimate of the velocity-density function in the traffic flow model. Two clusters will be obtained using KMeans clustering process, which are jammed and light cluster. These two clusters will have different velocity-density functions based on clustering result. Here, velocity-density function is obtained from linear regression of each data cluster. For measuring the velocity-density function, then this paper will provide the value of RMSE and R-Squared. The results show that RMSE is 2.3396 and R-squared is 0.3591 when no cluster is implemented in numerical simulation. Meanwhile, for the light cluster, the RMSE is found 1.1795 and R-squared 0.1388. Moreover, for the jammed cluster, RMSE is 0.8723 and R-squared is 0.1357. Finally, the process of identifying traffic conditions in the numerical simulation is done by computing Euclidean distance from centroid of clusters.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper discusses the use of K-Means clustering method in finding an estimate of the velocity-density function in the traffic flow model. Two clusters will be obtained using KMeans clustering process, which are jammed and light cluster. These two clusters will have different velocity-density functions based on clustering result. Here, velocity-density function is obtained from linear regression of each data cluster. For measuring the velocity-density function, then this paper will provide the value of RMSE and R-Squared. The results show that RMSE is 2.3396 and R-squared is 0.3591 when no cluster is implemented in numerical simulation. Meanwhile, for the light cluster, the RMSE is found 1.1795 and R-squared 0.1388. Moreover, for the jammed cluster, RMSE is 0.8723 and R-squared is 0.1357. Finally, the process of identifying traffic conditions in the numerical simulation is done by computing Euclidean distance from centroid of clusters.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Comparison of PSO, FA, and BA for Discrete Optimization Problems"
        ],
        "penulis":"Pratama, Denni Huda;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Swarm intelligence (SI) is widely applied for optimizing both continuous and discrete problems. Many papers have investigated them for continuous optimizations since most swarm-based algorithms are designed based on continuous movements, which are simply calculated using vector-based mathematical operations. It is quite easy to select the best SI algorithm for a given continuous problem. However, it is quite hard to pick an optimum SI algorithm for a discrete problem since the individual movement is difficult to develop. Therefore, in this paper, three SI algorithms: particle swarm optimization (PSO), firefly algorithm (FA), and bat algorithm (BA), are compared to solve some cases of traveling salesman problem (TSP). Evaluation on four TSP cases show that FA is the most effective and efficient since it dynamically evolves some individuals' groups and balances the exploitative-explorative movements.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Swarm intelligence (SI) is widely applied for optimizing both continuous and discrete problems. Many papers have investigated them for continuous optimizations since most swarm-based algorithms are designed based on continuous movements, which are simply calculated using vector-based mathematical operations. It is quite easy to select the best SI algorithm for a given continuous problem. However, it is quite hard to pick an optimum SI algorithm for a discrete problem since the individual movement is difficult to develop. Therefore, in this paper, three SI algorithms: particle swarm optimization (PSO), firefly algorithm (FA), and bat algorithm (BA), are compared to solve some cases of traveling salesman problem (TSP). Evaluation on four TSP cases show that FA is the most effective and efficient since it dynamically evolves some individuals' groups and balances the exploitative-explorative movements.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Exploring the Pattern of Voters' Characteristics: Partial Least Square Analysis"
        ],
        "penulis":"Lubis, Muharman;Ridho Lubis, Arif;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Understanding of characteristics can be assessed either by public decision-makers, who have been the primary concern of political actors or by voters themselves, who have participated directly in the process of election. Therefore, this study focused on the voters' self-evaluation to look out on the voter decisions with survey questionnaire have been used as the tools to collect the data independently in relation to create formative measurement model. In addition, major influences to the public also involves the role of emotion, political socialization and tolerance to the diversity of media views. This study investigated gender-based patterns of 790 samples using PLS as a data analysis tool, which found interesting result, which suggested that Social Norm (SNorm) have strongest effect to both PCon and PBen with 0.179 and 0.066 respectively followed by Technology Solution (TSol) with 0.057 and 0.022 as well Legal Regulation (LReg) with 0.043 and 0.020 accordingly. Thus, in the developed model, the researcher recommend that social factors can lead to determination of demand and participation in the voting to have public confidence and good behaviour in the protective manner. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Understanding of characteristics can be assessed either by public decision-makers, who have been the primary concern of political actors or by voters themselves, who have participated directly in the process of election. Therefore, this study focused on the voters' self-evaluation to look out on the voter decisions with survey questionnaire have been used as the tools to collect the data independently in relation to create formative measurement model. In addition, major influences to the public also involves the role of emotion, political socialization and tolerance to the diversity of media views. This study investigated gender-based patterns of 790 samples using PLS as a data analysis tool, which found interesting result, which suggested that Social Norm (SNorm) have strongest effect to both PCon and PBen with 0.179 and 0.066 respectively followed by Technology Solution (TSol) with 0.057 and 0.022 as well Legal Regulation (LReg) with 0.043 and 0.020 accordingly. Thus, in the developed model, the researcher recommend that social factors can lead to determination of demand and participation in the voting to have public confidence and good behaviour in the protective manner. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Evaluating the Gamification in TripAdvisor: Is it Effective for Crowdsourcing Platform?"
        ],
        "penulis":"Ranas, Tammyana;Sucahyo, Yudho Giri;Gandhi, Arfive;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The survival of crowdsourcing platforms depends on active crowdsourcee participation. Tripadvisor is one of the crowdsourcing platforms. However, the number of Tripadvisor visitors has stagnant growth. One of the gamification objectives is to increase the user's intrinsic motivation to engage in certain activities or behaviors. This study aims to determine the effect of gamification in motivating Tripadvisor users to participate actively. Furthermore, this study aims to evaluate gamification's effectiveness in motivating crowdsourcee to participate in a reference for further gamification development actively. This study uses the Self-Determination Theory (SDT) and Motivational Affordance Perspective (MAP) to analyze gamification's effect in motivating Tripadvisor users. This research uses a quantitative approach and the PLS-SEM method using SmartPLS3 for processing data. Respondents of this research were 154 Tripadvisor users as valid respondents. In this study, there were fifteen hypotheses with seven accepted hypotheses and eight rejected hypotheses. This study indicates that only the badges rewarding and level of achievement can motivate Tripadvisor users' participation. It because the user feels that getting gamification is not their purpose of participating in Tripadvisor. They participated because they are indeed like shared their travel experience. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The survival of crowdsourcing platforms depends on active crowdsourcee participation. Tripadvisor is one of the crowdsourcing platforms. However, the number of Tripadvisor visitors has stagnant growth. One of the gamification objectives is to increase the user's intrinsic motivation to engage in certain activities or behaviors. This study aims to determine the effect of gamification in motivating Tripadvisor users to participate actively. Furthermore, this study aims to evaluate gamification's effectiveness in motivating crowdsourcee to participate in a reference for further gamification development actively. This study uses the Self-Determination Theory (SDT) and Motivational Affordance Perspective (MAP) to analyze gamification's effect in motivating Tripadvisor users. This research uses a quantitative approach and the PLS-SEM method using SmartPLS3 for processing data. Respondents of this research were 154 Tripadvisor users as valid respondents. In this study, there were fifteen hypotheses with seven accepted hypotheses and eight rejected hypotheses. This study indicates that only the badges rewarding and level of achievement can motivate Tripadvisor users' participation. It because the user feels that getting gamification is not their purpose of participating in Tripadvisor. They participated because they are indeed like shared their travel experience. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Prognostics Health Management (PHM) System for Power Transformer Using Kernel Extreme Learning Machine (K-ELM)"
        ],
        "penulis":"Abdillah, Muhammad;Krismanto, Awan Uji;Nugroho, Teguh Aryo;Setiadi, Herlambang;Pertiwi, Nita Indriani;Mahmoud, Karar;Prasetio, Murman Dwi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A power transformer is one of the most important and valuable components for the power system network. This device is critical to ensure power quality and reliable electricity supply for consumers. When the power transformer could not work properly or out of service in unforeseen ways, it provides a severe impact on power system utilities and customers in term of the expensive of transformer's replacement cost and revenue lost caused by the electrical blackout. To overcome these issues, the proper prognostics health management (PHM) system as a tool for condition monitoring and health assessment of these valuable assets is required. This paper proposed a PHM system based on a kernel extreme learning machine (K-ELM) for power transformer's health assessment. Two sets of variable combinations called Set-1 and Set-2 were considered to examine the robustness and efficacy of the proposed method. In Set-1, the input variables were water content, total acidity, breakdown voltage, dissipation factor, dissolved combustible gases, and 2-furfuraldehyde. While the output of PHM system was the health condition which categorized as good, moderate, and bad circumstances. Set-2 utilized water content, total acidity, breakdown voltage, dissipation factor, and interfacial tension as input variables. Whereas, the PHM system outputs consisted of four categories: normal, good, moderate, and bad. The proposed method with two sets of variables had showed the satisfactory results for transformer's health condition assessment compared to an extreme learning machine (ELM), support vector machine (SVM), and least-square support vector machine (LS-SVM) in terms of learning and testing accuracies and computation time. The proposed PHM system using the Set-1 dataset could assess the transformer health as of 100% while in terms of the testing process, the proposed PHM system has an excellent accuracy result as of 68.67%. Furthermore, the proposed PHM system using the Set-2 dataset had successfully assessed the transformer health as of 100%. In the testing phase, the proposed PHM system model has a rigorous result for its accuracy result as of 93.61%. \u00a9 2020 Association for Computing Machinery.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A power transformer is one of the most important and valuable components for the power system network. This device is critical to ensure power quality and reliable electricity supply for consumers. When the power transformer could not work properly or out of service in unforeseen ways, it provides a severe impact on power system utilities and customers in term of the expensive of transformer's replacement cost and revenue lost caused by the electrical blackout. To overcome these issues, the proper prognostics health management (PHM) system as a tool for condition monitoring and health assessment of these valuable assets is required. This paper proposed a PHM system based on a kernel extreme learning machine (K-ELM) for power transformer's health assessment. Two sets of variable combinations called Set-1 and Set-2 were considered to examine the robustness and efficacy of the proposed method. In Set-1, the input variables were water content, total acidity, breakdown voltage, dissipation factor, dissolved combustible gases, and 2-furfuraldehyde. While the output of PHM system was the health condition which categorized as good, moderate, and bad circumstances. Set-2 utilized water content, total acidity, breakdown voltage, dissipation factor, and interfacial tension as input variables. Whereas, the PHM system outputs consisted of four categories: normal, good, moderate, and bad. The proposed method with two sets of variables had showed the satisfactory results for transformer's health condition assessment compared to an extreme learning machine (ELM), support vector machine (SVM), and least-square support vector machine (LS-SVM) in terms of learning and testing accuracies and computation time. The proposed PHM system using the Set-1 dataset could assess the transformer health as of 100% while in terms of the testing process, the proposed PHM system has an excellent accuracy result as of 68.67%. Furthermore, the proposed PHM system using the Set-2 dataset had successfully assessed the transformer health as of 100%. In the testing phase, the proposed PHM system model has a rigorous result for its accuracy result as of 93.61%. \u00a9 2020 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Product Segmentation Based on Sales Transaction Data Using Agglomerative Hierarchical Clustering and FMC Model (Case Study: XYZ Company)"
        ],
        "penulis":"Mardiantien, Crisnandra Rahmita;Atastina, Imelda;Asror, Ibnu;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The availability of a large number of data and overgrowing data dimensions is a challenge for companies to create business opportunities by utilizing the data. A large number of data causes companies to search for information from the data so that the information can be used to grow their business. Knowledge or information from data can be found by using one of the techniques in data mining, namely cluster analysis. Cluster analysis allows companies to get information about the object cluster in the data owned by the company. In this research, cluster analysis for medicinal product cluster was conducted on XYZ Company transaction data using the FMC (Frequency, Monetary, and Customer Variety) business approach model and the Agglomerative Hierarchical Clustering algorithm. The results showed that in the XYZ Company transaction data, there are eight product clusters that can provide information to XYZ Company. Around 60.5% of products in 2018 and 78.8% of products in 2019 belong to clusters with a low FMC score. Therefore, by segmenting products, XYZ Company can find outproducts that require more attention and determine the right marketing strategy for the product. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The availability of a large number of data and overgrowing data dimensions is a challenge for companies to create business opportunities by utilizing the data. A large number of data causes companies to search for information from the data so that the information can be used to grow their business. Knowledge or information from data can be found by using one of the techniques in data mining, namely cluster analysis. Cluster analysis allows companies to get information about the object cluster in the data owned by the company. In this research, cluster analysis for medicinal product cluster was conducted on XYZ Company transaction data using the FMC (Frequency, Monetary, and Customer Variety) business approach model and the Agglomerative Hierarchical Clustering algorithm. The results showed that in the XYZ Company transaction data, there are eight product clusters that can provide information to XYZ Company. Around 60.5% of products in 2018 and 78.8% of products in 2019 belong to clusters with a low FMC score. Therefore, by segmenting products, XYZ Company can find outproducts that require more attention and determine the right marketing strategy for the product. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis Simple Additive Weighting and Genetic Algorithm for Traffic Management System"
        ],
        "penulis":"Aziz, Abdul;Nasution, Surya Michrandi;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Bandung Tourism is currently developing rapidly, where every year the number of tourist attractions has increased. The convenience provided by today's technology such as Google Maps is still lacking in helping tourists. Until now, software that is useful for determining the route by selecting tourist attractions is still small. The problem of tourists in making a tour include traffic jams, distances and tourist attractions to be visited. Application development to help find the best route is very much needed by tourists. The best route search optimization can be done using Genetic Algorithms. Genetic Algorithms are often used in determining the route because based on previous research it produces optimal results. Weighting for a path can be done using the Simple Additive Weighting Algorithm. In this study optimization of route selection is done in the hope that it can provide solutions to tourists in route selection. \u00a9 2020 Universiti Tun Hussein Onn Malaysia Publisher\u2019s Office",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Bandung Tourism is currently developing rapidly, where every year the number of tourist attractions has increased. The convenience provided by today's technology such as Google Maps is still lacking in helping tourists. Until now, software that is useful for determining the route by selecting tourist attractions is still small. The problem of tourists in making a tour include traffic jams, distances and tourist attractions to be visited. Application development to help find the best route is very much needed by tourists. The best route search optimization can be done using Genetic Algorithms. Genetic Algorithms are often used in determining the route because based on previous research it produces optimal results. Weighting for a path can be done using the Simple Additive Weighting Algorithm. In this study optimization of route selection is done in the hope that it can provide solutions to tourists in route selection. \u00a9 2020 Universiti Tun Hussein Onn Malaysia Publisher\u2019s Office"
        ]
    },
    {
        "judul":[
            "Topic-Based Tweet Clustering for Public Figures Using Ant Clustering"
        ],
        "penulis":"Firdaus, Diaz Harizky;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The aspects of life on a public figure, discussed by the community, are often exploited by the news media as topic information to create an article that can attract the attention of the reader. Efficiently, the media only needs to pay attention to social media to get some of the information. The more information needed leads to a vast amount of data involved, so the process becomes hard. In this paper, a tweet clustering system to determine topics from many documents in the form of text through text mining method using an ant clustering (AC) technique. AC is one of swarm intelligence algorithms inspired by the behavior of the ant colony in sorting corpses. Evaluation of a small dataset of text documents shows that four topics are successfully concluded: economy, social, politics, and government. The developed AC-based tweet clustering system produces an average cluster quality of the Dunn Index up to 0,3455.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aspects of life on a public figure, discussed by the community, are often exploited by the news media as topic information to create an article that can attract the attention of the reader. Efficiently, the media only needs to pay attention to social media to get some of the information. The more information needed leads to a vast amount of data involved, so the process becomes hard. In this paper, a tweet clustering system to determine topics from many documents in the form of text through text mining method using an ant clustering (AC) technique. AC is one of swarm intelligence algorithms inspired by the behavior of the ant colony in sorting corpses. Evaluation of a small dataset of text documents shows that four topics are successfully concluded: economy, social, politics, and government. The developed AC-based tweet clustering system produces an average cluster quality of the Dunn Index up to 0,3455.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Indonesian Ethnicity Recognition Based on Face Image Using Uniform Local Binary Pattern (ULBP) and Color Histogram"
        ],
        "penulis":"Putri, Tiani Tiara;Rachmawati, Ema;Sthevanie, Febryanti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Ethnicity is one of identity every human has and can be used to categorize individuals in populations or large groups. We presented an Indonesian ethnicity recognition based on facial images using Uniform Local Binary Pattern (ULBP) and Color Histogram as a feature extraction method. We used the five largest ethnic groups in Indonesia, namely Sundanese, Javanese, Banjar, Buginese, and Malay. In the experiment, we used Random Forest as a classification method. The research obtained a performance accuracy of 98.25% using 2290 facial images. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ethnicity is one of identity every human has and can be used to categorize individuals in populations or large groups. We presented an Indonesian ethnicity recognition based on facial images using Uniform Local Binary Pattern (ULBP) and Color Histogram as a feature extraction method. We used the five largest ethnic groups in Indonesia, namely Sundanese, Javanese, Banjar, Buginese, and Malay. In the experiment, we used Random Forest as a classification method. The research obtained a performance accuracy of 98.25% using 2290 facial images. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Automation Financial Processing in Account Receivable for Integrated Hospital System using ERP and Quickstart Approach"
        ],
        "penulis":"Nasution, Febriansyah;Puspitasari, Warih;Saputra, Muhardi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Health is one of the most important aspects of human life. Hospital support in health maintenance in several areas. There is a public and private hospital in Indonesia to fulfill the health services for society. XYZ hospital is one of the government hospitals that operated in Bandung District. Currently, XYZ hospital still has no good information systems in performing hospital business processes. There is no integrated system that supports the hospital in data exchange within another business function. In caused by a lack of information systems, XYZ hospitals not effective enough in monitoring hospital daily activity and manage the hospital activity. This research focused on designing ERP systems in XYZ hospital financial management using Odoo software with a financial accounting module and used the Quickstart method. The result of this research is the model design of ERP systems regarding financial management that integrated with another module. The systems can support the financial department to manage financial activity automatically and integrated with another module to pursuing XYZ hospital as a smart hospital. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Health is one of the most important aspects of human life. Hospital support in health maintenance in several areas. There is a public and private hospital in Indonesia to fulfill the health services for society. XYZ hospital is one of the government hospitals that operated in Bandung District. Currently, XYZ hospital still has no good information systems in performing hospital business processes. There is no integrated system that supports the hospital in data exchange within another business function. In caused by a lack of information systems, XYZ hospitals not effective enough in monitoring hospital daily activity and manage the hospital activity. This research focused on designing ERP systems in XYZ hospital financial management using Odoo software with a financial accounting module and used the Quickstart method. The result of this research is the model design of ERP systems regarding financial management that integrated with another module. The systems can support the financial department to manage financial activity automatically and integrated with another module to pursuing XYZ hospital as a smart hospital. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Study on error correction capability of simple concatenated polar codes"
        ],
        "penulis":"Sinurat, Robin;Maulana, Muhamad Rizki;Anwar, Khoirul;Ismail, Nanang;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Polar codes are mathematically proven to achieve the Shannon limit, where the error probability is reduced with the help of frozen bits. Since the frozen bits are detrimental in terms of transmission efficiency, this paper investigates the importance of the frozen bits and the possibility of being replaced by other protected bits via a concatenation with other outer channel coding schemes. We evaluate the impact of frozen bits to the capability of error correction of original Polar codes (OPC) and the concatenated Polar codes (CPC) in short block-length in terms of bit-error-rate (BER) performances. Repetition codes are used as outer channel encoder prior to the Polar codes and are divided into two schemes, i.e., (i) irregular repetition-CPC (IR-CPC) codes and (ii) regular repetition-CPC (RR-CPC) codes. We evaluate BER performances using computer simulations based on Log-Likelihood Ratio (LLR) with the modulation of Binary Phase Shift Keying (BPSK) under Additive White Gaussian Noise (AWGN) and frequency-flat Rayleigh Fading channels. We found that the OPC is better than the IR-CPC codes or RR-CPC codes for the same channel coding rate and block-length. This finding indicates that the frozen bits in OPC has strong contribution to the error correction capability of the Polar codes and may not be replaced by other bits even though the bits are protected by other channel coding schemes. \u00a9 2020, Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Polar codes are mathematically proven to achieve the Shannon limit, where the error probability is reduced with the help of frozen bits. Since the frozen bits are detrimental in terms of transmission efficiency, this paper investigates the importance of the frozen bits and the possibility of being replaced by other protected bits via a concatenation with other outer channel coding schemes. We evaluate the impact of frozen bits to the capability of error correction of original Polar codes (OPC) and the concatenated Polar codes (CPC) in short block-length in terms of bit-error-rate (BER) performances. Repetition codes are used as outer channel encoder prior to the Polar codes and are divided into two schemes, i.e., (i) irregular repetition-CPC (IR-CPC) codes and (ii) regular repetition-CPC (RR-CPC) codes. We evaluate BER performances using computer simulations based on Log-Likelihood Ratio (LLR) with the modulation of Binary Phase Shift Keying (BPSK) under Additive White Gaussian Noise (AWGN) and frequency-flat Rayleigh Fading channels. We found that the OPC is better than the IR-CPC codes or RR-CPC codes for the same channel coding rate and block-length. This finding indicates that the frozen bits in OPC has strong contribution to the error correction capability of the Polar codes and may not be replaced by other bits even though the bits are protected by other channel coding schemes. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[
            "Recommendations for Improving Data Management Process in Government of Bandung Regency using COBIT 4.1 Framework"
        ],
        "penulis":"Nugroho, Heru;Gumilang, Soni Fajar Surya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Data is an valuable asset that potentially provides substantial benefits for the government and society. To make the performance of local government apparatus runs optimally and the public gets the best service, the government of Bandung Regency strives to improve data management. The initial stage of optimizing data management is the assessment of the maturity level in managing data (DS-11) using COBIT 4.1. Base on the assessment maturity level for DS-11, the government of Bandung Regency needs to raise the level from 2.46 (Repeatable but Intuitive) to 3.0 (Defined). Recommendations given to improve data management in Government with focuses on maintaining the completeness, accuracy, availability, and protection of data. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data is an valuable asset that potentially provides substantial benefits for the government and society. To make the performance of local government apparatus runs optimally and the public gets the best service, the government of Bandung Regency strives to improve data management. The initial stage of optimizing data management is the assessment of the maturity level in managing data (DS-11) using COBIT 4.1. Base on the assessment maturity level for DS-11, the government of Bandung Regency needs to raise the level from 2.46 (Repeatable but Intuitive) to 3.0 (Defined). Recommendations given to improve data management in Government with focuses on maintaining the completeness, accuracy, availability, and protection of data. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Image transmission using visible light communication in data communication"
        ],
        "penulis":"Tsaqifurrosyid, Alfajri;Rosmiati, Mia;Rizal, Moch. Fachru;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The development of network communication technology is currently emerging rapidly, one of which is the use of LED lights that are not only used as lighting in the room but can also be used as a medium of data communication between users through light media. VLC is the latest innovation in the field of data communication that is currently being developed where light media is used in the process of sending data. The simulation of sending data using VLC can be done on the transmitter and receiver side by using Visual Studio application as an application that can visualize the process of sending data. By using this system, the process of sending data can be seen bit by bit so that the success rate of sending data can be easily seen by the user. system used Arduino Uno as microprocessor. From the test results obtained the success rate of displaying images sent by the transmitter is 100% with a maximum distance of 50 cm with an image capacity of 20 KB with a delivery time of approximately 30 minutes. \u00a9 2020 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of network communication technology is currently emerging rapidly, one of which is the use of LED lights that are not only used as lighting in the room but can also be used as a medium of data communication between users through light media. VLC is the latest innovation in the field of data communication that is currently being developed where light media is used in the process of sending data. The simulation of sending data using VLC can be done on the transmitter and receiver side by using Visual Studio application as an application that can visualize the process of sending data. By using this system, the process of sending data can be seen bit by bit so that the success rate of sending data can be easily seen by the user. system used Arduino Uno as microprocessor. From the test results obtained the success rate of displaying images sent by the transmitter is 100% with a maximum distance of 50 cm with an image capacity of 20 KB with a delivery time of approximately 30 minutes. \u00a9 2020 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Project performance analysis using earned value management method in telecommunication"
        ],
        "penulis":"Widiningrum, Adelia;Pratami, Devi;Haryono, Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One of telecommunication project in Indonesia is shut downing the obsolete telecommunication infrastructure such as Sentral Telephone Otomate in Tanjungsari Bandung. This project is a modernization project of fiber optic network for 334 locations in Tanjungsari Sub-district. To compare actual performance of the scope, schedule and cost with planning for making right decisions in project's status and performance, required controlling by using Earned Value Management method since it can integrate these three things at the same time. Status and index of project performance on the 22nd day indicate that project was behind schedule that caused loss revenue of Rp 2,600,000.00 with 98% of delays from planning and project get 94% of overruns budget from issued value with amount of Rp 7,410,000.00. In addition, forecasting is done as a corrective action of past project status and performance. It is estimated that the project duration to complete work is 31 days with total cost for the remaining work (EAC) of Rp. 140,170,00.00 from previous project performance. It is also estimated that cost for remaining work until the project is completed or ETC is Rp. 7,770,000.00 with size of the project's forecasting status is a deficit from VAC value that calculated about (Rp 7,410,000.00) and the project will complete based on the TCPI forecasting calculation. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of telecommunication project in Indonesia is shut downing the obsolete telecommunication infrastructure such as Sentral Telephone Otomate in Tanjungsari Bandung. This project is a modernization project of fiber optic network for 334 locations in Tanjungsari Sub-district. To compare actual performance of the scope, schedule and cost with planning for making right decisions in project's status and performance, required controlling by using Earned Value Management method since it can integrate these three things at the same time. Status and index of project performance on the 22nd day indicate that project was behind schedule that caused loss revenue of Rp 2,600,000.00 with 98% of delays from planning and project get 94% of overruns budget from issued value with amount of Rp 7,410,000.00. In addition, forecasting is done as a corrective action of past project status and performance. It is estimated that the project duration to complete work is 31 days with total cost for the remaining work (EAC) of Rp. 140,170,00.00 from previous project performance. It is also estimated that cost for remaining work until the project is completed or ETC is Rp. 7,770,000.00 with size of the project's forecasting status is a deficit from VAC value that calculated about (Rp 7,410,000.00) and the project will complete based on the TCPI forecasting calculation. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office."
        ]
    },
    {
        "judul":[
            "Absorption Characteristics of Tunable AMC-based Wave Absorber using Varactor Diode"
        ],
        "penulis":"Hanifah, Muthia;Nur, Levy Olivia;Munir, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, the absorption characteristics of tunable electromagnetics (EM) wave absorber developed using artificial magnetic conductor (AMC) is investigated by incorporating varactor diode into the structure. The proposed wave absorber configured by 5\u00d75 cells of AMC structure is designed on an FR4 epoxy dielectric substrate with the thickness of 1.6 mm. Each cell which is composed of a square patch has the dimension of 20.8 mm \u00d7 20.8 mm, hence the total dimension of AMC-based wave absorber is 104 mm \u00d7 104 mm. To gain a tunable frequency response with the optimum absorptivity, a varactor diode with varied DC bias voltage is incorporated midway along the square patch in parallel to the incident wave. The equivalent circuit of varactor diode is used to characterize the performance of proposed tunable AMC-based wave absorber. Prior characterizing the effect of varactor diode incorporation, parametric studies upon the characteristic of AMC-based wave absorber is investigated by incorporating some passive elements such as resistor and capacitor. The characterization results show that the frequency response of tunable AMC-based wave absorber can be tuned from the frequency of 1.55 GHz to 2.51 GHz which corresponds to the DC bias voltages variation of varactor diode from 10V to 0V. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, the absorption characteristics of tunable electromagnetics (EM) wave absorber developed using artificial magnetic conductor (AMC) is investigated by incorporating varactor diode into the structure. The proposed wave absorber configured by 5\u00d75 cells of AMC structure is designed on an FR4 epoxy dielectric substrate with the thickness of 1.6 mm. Each cell which is composed of a square patch has the dimension of 20.8 mm \u00d7 20.8 mm, hence the total dimension of AMC-based wave absorber is 104 mm \u00d7 104 mm. To gain a tunable frequency response with the optimum absorptivity, a varactor diode with varied DC bias voltage is incorporated midway along the square patch in parallel to the incident wave. The equivalent circuit of varactor diode is used to characterize the performance of proposed tunable AMC-based wave absorber. Prior characterizing the effect of varactor diode incorporation, parametric studies upon the characteristic of AMC-based wave absorber is investigated by incorporating some passive elements such as resistor and capacitor. The characterization results show that the frequency response of tunable AMC-based wave absorber can be tuned from the frequency of 1.55 GHz to 2.51 GHz which corresponds to the DC bias voltages variation of varactor diode from 10V to 0V. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Implementation of Simulated Annealing-Support Vector Machine on QSAR Study of Fusidic Acid Derivatives as Anti-Malarial Agent"
        ],
        "penulis":"Rahman, Farisi;Lhaksmana, Kemas Muslim;Kurniawan, Isman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Malaria is a disease caused by the Plasmodium falciparum parasite and leads to many cases of deaths. Recently, the combination of several drugs has been used to treat this disease. However, the parasite is known to be resistant to the anti-malarial agent. Hence, a new candidate for an anti-malarial drug is required to solve the resistance problem. One compound that is promising as an anti-malarial agent is fusidic acid derivatives. Fusidic acid is an antibiotic that is work by preventing parasite growth. Besides, fusidic acid is known to have antiplasmodial activity although the IC50 is still poor. However, the activity can be improved by optimizing the structure through its derivatives. In this study, we developed a QSAR model to predict the activity of fusidic acid derivatives as anti-malarial agent. The model was developed by using Simulated Annealing (SA) for feature selection and Support Vector Machine (SVM) for model development. The results show that SA produces a satisfying combination of features that are indicated by the trend of MSE value during the selection process. Regarding the performance, SVM with RBF kernel produces the best result of the validation parameter. This indicates that the model is valid to be used to predict a compound with unknown activity values for anti-malarial agents.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Malaria is a disease caused by the Plasmodium falciparum parasite and leads to many cases of deaths. Recently, the combination of several drugs has been used to treat this disease. However, the parasite is known to be resistant to the anti-malarial agent. Hence, a new candidate for an anti-malarial drug is required to solve the resistance problem. One compound that is promising as an anti-malarial agent is fusidic acid derivatives. Fusidic acid is an antibiotic that is work by preventing parasite growth. Besides, fusidic acid is known to have antiplasmodial activity although the IC50 is still poor. However, the activity can be improved by optimizing the structure through its derivatives. In this study, we developed a QSAR model to predict the activity of fusidic acid derivatives as anti-malarial agent. The model was developed by using Simulated Annealing (SA) for feature selection and Support Vector Machine (SVM) for model development. The results show that SA produces a satisfying combination of features that are indicated by the trend of MSE value during the selection process. Regarding the performance, SVM with RBF kernel produces the best result of the validation parameter. This indicates that the model is valid to be used to predict a compound with unknown activity values for anti-malarial agents.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Vulnerability Assessment and Penetration Testing (VAPT) Framework: Case Study of Government\u2019s Website"
        ],
        "penulis":"Almaarif, Ahmad;Lubis, Muharman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information security often neglected by individual or employee or even by the enterprise, with there is no proper strategy to raise awareness, promote consistency and maintain performance regarding protect sensitive, confidential, and critical data. One of the common techniques used is a vulnerability assessment and penetration testing (VAPT) to assure the security strategy has been implemented into the computer system by analyzing both its strength and weakness. SQL plays an essential role in the Relation Database Management System (RDBMS) and its relationship to the existence of a website and its flexible operation because of its simplicity and integrity. To anticipate these types of threats or other Internet attacks, a goal-oriented penetration test that has a framework is recommended to identify specific types of vulnerabilities that lead to business concessions and to avoid the risks that adversely affect the enterprise Thus. This study conducts VAPT to uncover the possibility of threats and evaluate the potential impact to be reported to the system owner through a proper engagement framework that allows systematic measurement. Government websites have been identified for this purpose of the research to show the current trend that occurred in cyber communities, especially in Indonesia. This study has found various vulnerabilities lies in the directory listing, full path disclosure, PHP info disclosure, folder webserver disclosure, and other potential threats, which present 2 (two) critical, 6 (six) medium, and 2 (two) low level of risk. \u00a9",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information security often neglected by individual or employee or even by the enterprise, with there is no proper strategy to raise awareness, promote consistency and maintain performance regarding protect sensitive, confidential, and critical data. One of the common techniques used is a vulnerability assessment and penetration testing (VAPT) to assure the security strategy has been implemented into the computer system by analyzing both its strength and weakness. SQL plays an essential role in the Relation Database Management System (RDBMS) and its relationship to the existence of a website and its flexible operation because of its simplicity and integrity. To anticipate these types of threats or other Internet attacks, a goal-oriented penetration test that has a framework is recommended to identify specific types of vulnerabilities that lead to business concessions and to avoid the risks that adversely affect the enterprise Thus. This study conducts VAPT to uncover the possibility of threats and evaluate the potential impact to be reported to the system owner through a proper engagement framework that allows systematic measurement. Government websites have been identified for this purpose of the research to show the current trend that occurred in cyber communities, especially in Indonesia. This study has found various vulnerabilities lies in the directory listing, full path disclosure, PHP info disclosure, folder webserver disclosure, and other potential threats, which present 2 (two) critical, 6 (six) medium, and 2 (two) low level of risk. \u00a9"
        ]
    },
    {
        "judul":[
            "Spare part requirement and inventory policy for Rovema's 1 machine using Reliability Centered Spare (RCS) and Min-Max stock methods"
        ],
        "penulis":"Angelina C.F.;Atmaji F.T.D.;Santosa B.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "XYZ company is a manufacturing company engaged in the field of medicines, food, and natural products. One of the problems found in the machine delay, called \"outstanding\". An outstanding occurs is mostly caused by the unavailability of the spare parts. Based on the downtime losses data, the highest downtime, as well as unavailability spare parts, was owned by Rovema's machine, one of the packaging machines in food plant division. Therefore in this research, the Reliability Centered Spare (RCS) method was applied to calculate the optimal critical spare part policy using the Poisson process and Min-Max stock analysis. The analysis result shows that the critical component of Rovema's machine is steel band and brass insert are must be stored in a technical warehouse for one year ahead with optimal inventory quantity is 18 and 15 pieces with minimum stock is 10 pieces each. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "XYZ company is a manufacturing company engaged in the field of medicines, food, and natural products. One of the problems found in the machine delay, called \"outstanding\". An outstanding occurs is mostly caused by the unavailability of the spare parts. Based on the downtime losses data, the highest downtime, as well as unavailability spare parts, was owned by Rovema's machine, one of the packaging machines in food plant division. Therefore in this research, the Reliability Centered Spare (RCS) method was applied to calculate the optimal critical spare part policy using the Poisson process and Min-Max stock analysis. The analysis result shows that the critical component of Rovema's machine is steel band and brass insert are must be stored in a technical warehouse for one year ahead with optimal inventory quantity is 18 and 15 pieces with minimum stock is 10 pieces each. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Fully automated myocardial strain estimation from cardiovascular MRI\u2013Tagged images using a deep learning framework in the UK biobank"
        ],
        "penulis":"Ferdian, Edward;Suinesiaputra, Avan;Fung, Kenneth;Aung, Nay;Lukaschuk, Elena;Barutcu, Ahmet;Maclean, Edd;Paiva, Jose;Piechnik, Stefan K.;Neubauer, Stefan;Petersen, Steffen E.;Young, Alistair A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Purpose: To demonstrate the feasibility and performance of a fully automated deep learning framework to estimate myocardial strain from short-axis cardiac MRI\u2013tagged images. Materials and Methods: In this retrospective cross-sectional study, 4508 cases from the U.K. Biobank were split randomly into 3244 training cases, 812 validation cases, and 452 test cases. Ground truth myocardial landmarks were defined and tracked by manual initialization and correction of deformable image registration using previously validated software with five readers. The fully automatic framework consisted of (a) a convolutional neural network (CNN) for localization and (b) a combination of a recurrent neural network (RNN) and a CNN to detect and track the myocardial landmarks through the image sequence for each slice. Radial and circumferential strain were then calculated from the motion of the landmarks and averaged on a slice basis. Results: Within the test set, myocardial end-systolic circumferential Green strain errors were 20.001 \u00b1 0.025, 20.001 \u00b1 0.021, and 0.004 \u00b1 0.035 in the basal, mid-, and apical slices, respectively (mean \u00b1 standard deviation of differences between predicted and manual strain). The framework reproduced significant reductions in circumferential strain in participants with diabetes, hypertensive participants, and participants with a previous heart attack. Typical processing time was approximately 260 frames (approximately 13 slices) per second on a GPU with 12 GB RAM compared with 6\u20138 minutes per slice for the manual analysis. Conclusion: The fully automated combined RNN and CNN framework for analysis of myocardial strain enabled unbiased strain evaluation in a high-throughput workflow, with similar ability to distinguish impairment due to diabetes, hypertension, and previous heart attack. \u00a9 Published under a CC BY 4.0 license.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: To demonstrate the feasibility and performance of a fully automated deep learning framework to estimate myocardial strain from short-axis cardiac MRI\u2013tagged images. Materials and Methods: In this retrospective cross-sectional study, 4508 cases from the U.K. Biobank were split randomly into 3244 training cases, 812 validation cases, and 452 test cases. Ground truth myocardial landmarks were defined and tracked by manual initialization and correction of deformable image registration using previously validated software with five readers. The fully automatic framework consisted of (a) a convolutional neural network (CNN) for localization and (b) a combination of a recurrent neural network (RNN) and a CNN to detect and track the myocardial landmarks through the image sequence for each slice. Radial and circumferential strain were then calculated from the motion of the landmarks and averaged on a slice basis. Results: Within the test set, myocardial end-systolic circumferential Green strain errors were 20.001 \u00b1 0.025, 20.001 \u00b1 0.021, and 0.004 \u00b1 0.035 in the basal, mid-, and apical slices, respectively (mean \u00b1 standard deviation of differences between predicted and manual strain). The framework reproduced significant reductions in circumferential strain in participants with diabetes, hypertensive participants, and participants with a previous heart attack. Typical processing time was approximately 260 frames (approximately 13 slices) per second on a GPU with 12 GB RAM compared with 6\u20138 minutes per slice for the manual analysis. Conclusion: The fully automated combined RNN and CNN framework for analysis of myocardial strain enabled unbiased strain evaluation in a high-throughput workflow, with similar ability to distinguish impairment due to diabetes, hypertension, and previous heart attack. \u00a9 Published under a CC BY 4.0 license."
        ]
    },
    {
        "judul":[
            "Optimal routing of pedestrian flow in a complex topological network with multiple entrances and exits"
        ],
        "penulis":"Khalid, Ruzelan;Nawawi, Mohd Kamal Mohd;Kawsar, Luthful A.;Ghani, Noraida A.;Kamil, Anton A.;Mustafa, Adli;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A real-world topological network consists of multiple entrances along its source nodes. Routing appropriate percentages of pedestrians from these entrances to the particular available routes with relevant arrival rates will improve the network\u2019s performance. This paper presents a framework for finding the optimal arrival rates of pedestrians from all available entrances and routes to downstream nodes maximising the network\u2019s throughput. The calculation of the arrival rates and movement directions is based on M\/G\/C\/C analytical and simulation models and the network flow model and considers the real distances of the entrances along the source nodes. The framework was tested on the Tuanku Syed Putra Hall, Universiti Sains Malaysia, Malaysia. Extensive analyses of the performances of its available nodes especially on the achievable optimal throughputs were documented and discussed. Quantitative results show that the hall\u2019s throughput is optimised when pedestrians\u2019 arrival rates to all the available entrances and their movement directions are controlled within certain ranges. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A real-world topological network consists of multiple entrances along its source nodes. Routing appropriate percentages of pedestrians from these entrances to the particular available routes with relevant arrival rates will improve the network\u2019s performance. This paper presents a framework for finding the optimal arrival rates of pedestrians from all available entrances and routes to downstream nodes maximising the network\u2019s throughput. The calculation of the arrival rates and movement directions is based on M\/G\/C\/C analytical and simulation models and the network flow model and considers the real distances of the entrances along the source nodes. The framework was tested on the Tuanku Syed Putra Hall, Universiti Sains Malaysia, Malaysia. Extensive analyses of the performances of its available nodes especially on the achievable optimal throughputs were documented and discussed. Quantitative results show that the hall\u2019s throughput is optimised when pedestrians\u2019 arrival rates to all the available entrances and their movement directions are controlled within certain ranges. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group."
        ]
    },
    {
        "judul":[
            "Complexity Based Multilevel Signal Analysis for Epileptic Seizure Detection"
        ],
        "penulis":"Wijayanto, Inung;Hartanto, Rudy;Nugroho, Hanung Adi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The electroencephalogram (EEG) signal is a signal produced by a complex biological system. Thus, a signal complexity analysis can be useful for analyzing the EEG signal. Many studies have shownthe vast development of signal complexity analysis in the EEG. The most commonly used methods were the entropy and fractal dimension measurement. These methods were able to perform well in the epileptic EEG seizure detection system. They were suitable for time, frequency, and wavelet domain signal processing. The use of wavelet analysis, such as discrete wavelet transform (DWT) and wavelet packet decomposition (WPD), was quite famous. In many studies, the feature extraction process was performed in the DWT or WPD process sub-band signal. One of the developments of WPD was called as the multilevel wavelet packet entropy (MWPE), which produced less features than that of WPD. This study developed a new method based on WPE, which used signal complexity measurement at each level as in MWPE. The seizure detection process in this study was started with a channel selection method to reduce the processed channels. EEG signals from selected channels were then decomposed using a five-level of wavelet packet decomposition (WPD), producing 32 wavelet coefficients. The feature extraction process was performed using the entropy and fractal dimension for all 32 sub-bands, that were segmented using a ten-minute non-overlapping window. A support vector machine (SVM) was used to classify the feature set into a seizure and normal conditions. The system was evaluated using the CHBMIT EEG dataset, which was recorded from 24 patients having a total of 198 seizure events. The highest average accuracy of 91% was achieved by using multilevel wavelet higuchi fractal dimension (MWHF) analysis. This indicates that the use of fractal based measurement has a good opportunity to be implemented in epileptic seizure detection and prediction system. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The electroencephalogram (EEG) signal is a signal produced by a complex biological system. Thus, a signal complexity analysis can be useful for analyzing the EEG signal. Many studies have shownthe vast development of signal complexity analysis in the EEG. The most commonly used methods were the entropy and fractal dimension measurement. These methods were able to perform well in the epileptic EEG seizure detection system. They were suitable for time, frequency, and wavelet domain signal processing. The use of wavelet analysis, such as discrete wavelet transform (DWT) and wavelet packet decomposition (WPD), was quite famous. In many studies, the feature extraction process was performed in the DWT or WPD process sub-band signal. One of the developments of WPD was called as the multilevel wavelet packet entropy (MWPE), which produced less features than that of WPD. This study developed a new method based on WPE, which used signal complexity measurement at each level as in MWPE. The seizure detection process in this study was started with a channel selection method to reduce the processed channels. EEG signals from selected channels were then decomposed using a five-level of wavelet packet decomposition (WPD), producing 32 wavelet coefficients. The feature extraction process was performed using the entropy and fractal dimension for all 32 sub-bands, that were segmented using a ten-minute non-overlapping window. A support vector machine (SVM) was used to classify the feature set into a seizure and normal conditions. The system was evaluated using the CHBMIT EEG dataset, which was recorded from 24 patients having a total of 198 seizure events. The highest average accuracy of 91% was achieved by using multilevel wavelet higuchi fractal dimension (MWHF) analysis. This indicates that the use of fractal based measurement has a good opportunity to be implemented in epileptic seizure detection and prediction system. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design and Characterization of Rectangular Array Microstrip Antenna for Cubesat S-Band Transmitter"
        ],
        "penulis":"Benyamin, Sherin Octavani;Wijanto, Heroe;Edwar;Prabowo, Vinsensius Sigit Widhi;Prananditya, Haris;Oktaviani, Shindi Marlina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Automatic Dependent Surveillance-Broadcast (ADS-B) is an air traffic surveillance technology that automatically and periodically broadcasts onboard aircraft flight information such as identity numbers, positions, speeds, and destinations during all phases of flight to avoid collisions. In the future, the radar system will be equipped or even replaced by the ADS-B ground station. Therefore, the Nano-Satellite Laboratory of Telkom University is developing a satellite technology called Tel-USat which the ADS-B receiver is one of the missions. This work focuses on the design and characterization of the antenna to send all the collected ADS-B data to the ground. This antenna is designed by using an FR-4 substrate material with two rectangular patches, linear array, T-junction powerdivider, and proximity coupled rationing. The results obtained during the measurement are return loss values at 2.4 GHz frequency of -18.5 dB, VSWR of 1.2, antenna bandwidth of 163 MHz, and the gainof 6.08 dB. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Automatic Dependent Surveillance-Broadcast (ADS-B) is an air traffic surveillance technology that automatically and periodically broadcasts onboard aircraft flight information such as identity numbers, positions, speeds, and destinations during all phases of flight to avoid collisions. In the future, the radar system will be equipped or even replaced by the ADS-B ground station. Therefore, the Nano-Satellite Laboratory of Telkom University is developing a satellite technology called Tel-USat which the ADS-B receiver is one of the missions. This work focuses on the design and characterization of the antenna to send all the collected ADS-B data to the ground. This antenna is designed by using an FR-4 substrate material with two rectangular patches, linear array, T-junction powerdivider, and proximity coupled rationing. The results obtained during the measurement are return loss values at 2.4 GHz frequency of -18.5 dB, VSWR of 1.2, antenna bandwidth of 163 MHz, and the gainof 6.08 dB. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "What Users Want for Gig Economy Platforms: Sentiment Analysis Approach"
        ],
        "penulis":"Indrawan, Nadina Adelia;Sucahyo, Yudho Giri;Ruldeviyani, Yova;Gandhi, Arfive;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Gig economy-based mobile applications are increasingly in demand by the public. An increment in the number of users rises the number of downloads and reviews. However, the number of reviews makes it difficult for developers to understand the information contained in reviews. Besides, one review can have a variety of information. This study proposes a model that can categorize content and sentiment reviews using Support Vector Machine (SVM), Multinomial Na\u00efve Bayes, Complement Na\u00efve Bayes classifier, and Binary Relevance, Classifier Chain, and Label Power Sets as the data transformation method. This study used the reviews contained in the Gojek, Sampingan, and Ruang Guru applications, with 10, 123 reviews. This study found the review text's length influenced accuracy based on the evaluation of Gojek application. Generally, this study results showed that the SVM algorithm (both in the classification of sentiment reviews and review categorization) and Label Power Sets as the transformation method, yielded the best accuracy. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Gig economy-based mobile applications are increasingly in demand by the public. An increment in the number of users rises the number of downloads and reviews. However, the number of reviews makes it difficult for developers to understand the information contained in reviews. Besides, one review can have a variety of information. This study proposes a model that can categorize content and sentiment reviews using Support Vector Machine (SVM), Multinomial Na\u00efve Bayes, Complement Na\u00efve Bayes classifier, and Binary Relevance, Classifier Chain, and Label Power Sets as the data transformation method. This study used the reviews contained in the Gojek, Sampingan, and Ruang Guru applications, with 10, 123 reviews. This study found the review text's length influenced accuracy based on the evaluation of Gojek application. Generally, this study results showed that the SVM algorithm (both in the classification of sentiment reviews and review categorization) and Label Power Sets as the transformation method, yielded the best accuracy. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Big Data Analytics for Processing Real-time Unstructured Data from CCTV in Traffic Management"
        ],
        "penulis":"Hamami, Faqih;Dahlan, Iqbal Ahmad;Prakosa, Setya Widyawan;Somantri, Khamal Fauzan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Todays many devices generate data everywhere and anytime. Data grow massively and becomes complex thing that needs to be handled. Unstructured data is one type of big data that is difficult to process and consists of unstable attributes. In traffic management, CCTVs are installed to monitor the specific location in the highway. CCTV generates unstructured data in image and video format. These data are difficult to process due to the complexity of the data. This research proposes to implement big data analytics to process real-time unstructured data from CCTV into knowledge displayed in web dashboard. We implement the YOLO framework with YoloV4 Architecture and COCO dataset for traffic flow counting and detecting illegal parking which is categorized as abnormal situation. Unstructured data from CCTV then transformed into semi-structured format in JSON. Data also can be visualized in real time to facilitate local authority to understand the highway situation. Historical data are stored in the NoSQL database to deep more knowledge such as vehicle traffic pattern. The proposed system requires the ROI drawing line as trigger to count the passing vehicles. These experiments are conducted from open CCTV for traffic online in Bali Tower Public Streaming. The prototype result is able to detect the object with 10 fps.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Todays many devices generate data everywhere and anytime. Data grow massively and becomes complex thing that needs to be handled. Unstructured data is one type of big data that is difficult to process and consists of unstable attributes. In traffic management, CCTVs are installed to monitor the specific location in the highway. CCTV generates unstructured data in image and video format. These data are difficult to process due to the complexity of the data. This research proposes to implement big data analytics to process real-time unstructured data from CCTV into knowledge displayed in web dashboard. We implement the YOLO framework with YoloV4 Architecture and COCO dataset for traffic flow counting and detecting illegal parking which is categorized as abnormal situation. Unstructured data from CCTV then transformed into semi-structured format in JSON. Data also can be visualized in real time to facilitate local authority to understand the highway situation. Historical data are stored in the NoSQL database to deep more knowledge such as vehicle traffic pattern. The proposed system requires the ROI drawing line as trigger to count the passing vehicles. These experiments are conducted from open CCTV for traffic online in Bali Tower Public Streaming. The prototype result is able to detect the object with 10 fps.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Machine instruction analysis for DCT algorithm using DLX architecture"
        ],
        "penulis":"Dyanneley, Believa;Karna, Nyoman;Patmasari, Raditiana;Kim, Dong-Seong;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One of the methods to reduce the size of images is by compressing the images. This research tried to find out the machine instruction set of DLX microprocessor to do image compression, in which the result will be used to design an ASIP microprocessor that has less power consumption compared to a general-purpose microprocessor with dozens of machine instruction. This ASIP microprocessor will become the heart of our next project, which is the autonomous seabed robot scanner that will be installed under the sea which relying on a rechargeable battery to supply the power. That is why this research is very crucial to reduce the power consumption of the microprocessor to save more energy for long term use. This research uses a simulation tool for DLX microprocessor, namely the WinDLX, to implement the algorithm of Discrete Cosine Transform (DCT) for image compression process. The result shows that the program requires a total of 14763 cycles executed with a total of 5920 instructions. The instructions which are often used in this experiment are LF (Load Float) which is used to load the value of matrices before being stored in the memory and multiplied to other matrices.  \u00a9 2020 IEEE."
        ],
        "abstrak":[
            "One of the methods to reduce the size of images is by compressing the images. This research tried to find out the machine instruction set of DLX microprocessor to do image compression, in which the result will be used to design an ASIP microprocessor that has less power consumption compared to a general-purpose microprocessor with dozens of machine instruction. This ASIP microprocessor will become the heart of our next project, which is the autonomous seabed robot scanner that will be installed under the sea which relying on a rechargeable battery to supply the power. That is why this research is very crucial to reduce the power consumption of the microprocessor to save more energy for long term use. This research uses a simulation tool for DLX microprocessor, namely the WinDLX, to implement the algorithm of Discrete Cosine Transform (DCT) for image compression process. The result shows that the program requires a total of 14763 cycles executed with a total of 5920 instructions. The instructions which are often used in this experiment are LF (Load Float) which is used to load the value of matrices before being stored in the memory and multiplied to other matrices.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Anatomy of magnetic anisotropy and voltage-controlled magnetic anisotropy in metal oxide heterostructure from first principles"
        ],
        "penulis":"Pardede, Indra;Yoshikawa, Daiki;Kanagawa, Tomosato;Ikhsan, Nurul;Obata, Masao;Oda, Tatsuki;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Voltage control of magnetic anisotropy (VCMA) is one of the promising approaches for magnetoelectric control of magnetic tunnel junction (MTJ). Here, we systematically calculated the magnetic anisotropy (MA) and the VCMA energies in the well-known MTJ structure consisting of Fe\/MgO interface with Cr buffer layer. In this calculation, we investigated an alloying between Fe and Cr and a strain effect. We used a spin density functional approach which includes both contributions from magnetocrystalline anisotropy energy (MCAE) originating from spin\u2013orbit coupling and shape magnetic anisotropy energy from spin dipole\u2013dipole interaction. In the present approach, the MCAE part, in addition to a common scheme of total energy, was evaluated using a grand canonical force theorem scheme. In the latter scheme, atom-resolved and k-resolved analyses for MA and VCMA can be performed. At first, we found that, as the alloying is introduced, the perpendicular MCAE increases by a factor of two. Next, as the strain is introduced, we found that the MCAE increases with increasing compressive strain with the maximum value of 2.2 mJ\/m2. For the VCMA coefficient, as the compressive strain increases, the sign becomes negative and the absolute value becomes enhanced to the number of 170 fJ\/Vm. By using the atom-resolved and k-resolved analyses, we clarified that these enhancements of MCAE and VCMA mainly originates from the Fe interface with MgO (Fe1) and are located at certain lines in the two dimensional Brillouin zone. The findings on MCAE and VCMA are fully explained by the spin-orbit couplings between the certain d-orbital states in the second-order perturbation theory. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Voltage control of magnetic anisotropy (VCMA) is one of the promising approaches for magnetoelectric control of magnetic tunnel junction (MTJ). Here, we systematically calculated the magnetic anisotropy (MA) and the VCMA energies in the well-known MTJ structure consisting of Fe\/MgO interface with Cr buffer layer. In this calculation, we investigated an alloying between Fe and Cr and a strain effect. We used a spin density functional approach which includes both contributions from magnetocrystalline anisotropy energy (MCAE) originating from spin\u2013orbit coupling and shape magnetic anisotropy energy from spin dipole\u2013dipole interaction. In the present approach, the MCAE part, in addition to a common scheme of total energy, was evaluated using a grand canonical force theorem scheme. In the latter scheme, atom-resolved and k-resolved analyses for MA and VCMA can be performed. At first, we found that, as the alloying is introduced, the perpendicular MCAE increases by a factor of two. Next, as the strain is introduced, we found that the MCAE increases with increasing compressive strain with the maximum value of 2.2 mJ\/m2. For the VCMA coefficient, as the compressive strain increases, the sign becomes negative and the absolute value becomes enhanced to the number of 170 fJ\/Vm. By using the atom-resolved and k-resolved analyses, we clarified that these enhancements of MCAE and VCMA mainly originates from the Fe interface with MgO (Fe1) and are located at certain lines in the two dimensional Brillouin zone. The findings on MCAE and VCMA are fully explained by the spin-orbit couplings between the certain d-orbital states in the second-order perturbation theory. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Measuring information credibility in social media using combination of user profile and message content dimensions"
        ],
        "penulis":"Setiawan, Erwin B.;Widyantoro, Dwi H.;Surendro, Kridanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information credibility in social media is becoming the most important part of information sharing in the society. The literatures have shown that there is no labeling information credibility based on user competencies and their posted topics. This paper increases the information credibility by adding new 17 features for Twitter and 49 features for Facebook. In the first step, we perform a labeling process based on user competencies and their posted topic to classify the users into two groups, credible and not credible users, regarding their posted topics. These approaches are evaluated over ten thousand samples of real-field data obtained from Twitter and Facebook networks using classification of Naive Bayes (NB), Support Vector Machine (SVM), Logistic Regression (Logit) and J48 Algorithm (J48). With the proposed new features, the credibility of information provided in social media is increasing significantly indicated by better accuracy compared to the existing technique for all classifiers. Copyright \u00a9 2020 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information credibility in social media is becoming the most important part of information sharing in the society. The literatures have shown that there is no labeling information credibility based on user competencies and their posted topics. This paper increases the information credibility by adding new 17 features for Twitter and 49 features for Facebook. In the first step, we perform a labeling process based on user competencies and their posted topic to classify the users into two groups, credible and not credible users, regarding their posted topics. These approaches are evaluated over ten thousand samples of real-field data obtained from Twitter and Facebook networks using classification of Naive Bayes (NB), Support Vector Machine (SVM), Logistic Regression (Logit) and J48 Algorithm (J48). With the proposed new features, the credibility of information provided in social media is increasing significantly indicated by better accuracy compared to the existing technique for all classifiers. Copyright \u00a9 2020 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Using a multi-level process comparison for process change analysis in cancer pathways"
        ],
        "penulis":"Kurniati, Angelina Prima;McInerney, Ciar\u00e1n;Zucker, Kieran;Hall, Geoff;Hogg, David;Johnson, Owen;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The area of process change over time is a particular concern in healthcare, where patterns of care emerge and evolve in response to individual patient needs. We propose a structured approach to analyse process change over time that is suitable for the complex domain of healthcare. Our approach applies a qualitative process comparison at three levels of abstraction: a holistic perspective (process model), a middle-level perspective (trace), and a fine-grained detail (activity). Our aim was to detect change points, localise and characterise the change, and unravel\/understand the process evolution. We illustrate the approach using a case study of cancer pathways in Leeds where we found evidence of change points identified at multiple levels. In this paper, we extend our study by analysing the miners used in process discovery and providing a deeper analysis of the activity of investigation in trace and activity levels. In the experiment, we show that this qualitative approach provides a useful understanding of process change over time. Examining change at three levels provides confirmatory evidence of process change where perspectives agree, while contradictory evidence can lead to focused discussions with domain experts. This approach should be of interest to others dealing with processes that undergo complex change over time. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "BaView detailsExpand Substance barium",
            "Powered by",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The area of process change over time is a particular concern in healthcare, where patterns of care emerge and evolve in response to individual patient needs. We propose a structured approach to analyse process change over time that is suitable for the complex domain of healthcare. Our approach applies a qualitative process comparison at three levels of abstraction: a holistic perspective (process model), a middle-level perspective (trace), and a fine-grained detail (activity). Our aim was to detect change points, localise and characterise the change, and unravel\/understand the process evolution. We illustrate the approach using a case study of cancer pathways in Leeds where we found evidence of change points identified at multiple levels. In this paper, we extend our study by analysing the miners used in process discovery and providing a deeper analysis of the activity of investigation in trace and activity levels. In the experiment, we show that this qualitative approach provides a useful understanding of process change over time. Examining change at three levels provides confirmatory evidence of process change where perspectives agree, while contradictory evidence can lead to focused discussions with domain experts. This approach should be of interest to others dealing with processes that undergo complex change over time. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Spare part requirement and inventory policy for Rovema's 1 machine using Reliability Centered Spare (RCS) and Min-Max stock methods"
        ],
        "penulis":"Angelina C.F.;Atmaji F.T.D.;Santosa B.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "XYZ company is a manufacturing company engaged in the field of medicines, food, and natural products. One of the problems found in the machine delay, called \"outstanding\". An outstanding occurs is mostly caused by the unavailability of the spare parts. Based on the downtime losses data, the highest downtime, as well as unavailability spare parts, was owned by Rovema's machine, one of the packaging machines in food plant division. Therefore in this research, the Reliability Centered Spare (RCS) method was applied to calculate the optimal critical spare part policy using the Poisson process and Min-Max stock analysis. The analysis result shows that the critical component of Rovema's machine is steel band and brass insert are must be stored in a technical warehouse for one year ahead with optimal inventory quantity is 18 and 15 pieces with minimum stock is 10 pieces each. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "XYZ company is a manufacturing company engaged in the field of medicines, food, and natural products. One of the problems found in the machine delay, called \"outstanding\". An outstanding occurs is mostly caused by the unavailability of the spare parts. Based on the downtime losses data, the highest downtime, as well as unavailability spare parts, was owned by Rovema's machine, one of the packaging machines in food plant division. Therefore in this research, the Reliability Centered Spare (RCS) method was applied to calculate the optimal critical spare part policy using the Poisson process and Min-Max stock analysis. The analysis result shows that the critical component of Rovema's machine is steel band and brass insert are must be stored in a technical warehouse for one year ahead with optimal inventory quantity is 18 and 15 pieces with minimum stock is 10 pieces each. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Evaluation and Recommendation for Scrum Implementation Improvement with Hybrid Scrum Maturity Model: A Case Study of A New Telco Product"
        ],
        "penulis":"Freedrikson Arifin, Nala;Purwandari, Betty;Setiadi, Farisya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In 2019, a telco company launched a new product for the youth. It has the tagline 'Everything You Want' that gave young customers the freedom to bundle their mobile communication packages. The Blue team developed the product guided by Scrum, However, there were troubles during software development, such as missing the targeted deliverables. A measurement of the Scrum process maturity level was conducted to address the problems. It followed the modified Scrum Maturity Model, which was updated from the 2017 Scrum Guide and Scrum Body of Knowledge version 3. The assessment showed that the Blue team achieved maturity level 1 (Initial). It was attained with 16 'Fully Achieved' practices, 49 'Largely Achieved' practices, and 14 'Partially Achieved' practices. Once the maturity level and existing problems were identified, recommendations based on Scrum components (Scrum roles, Scrum artifacts, and Scrum events) were proposed. It aimed to improve Scrum practices that had not been fully achieved by the Blue team. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In 2019, a telco company launched a new product for the youth. It has the tagline 'Everything You Want' that gave young customers the freedom to bundle their mobile communication packages. The Blue team developed the product guided by Scrum, However, there were troubles during software development, such as missing the targeted deliverables. A measurement of the Scrum process maturity level was conducted to address the problems. It followed the modified Scrum Maturity Model, which was updated from the 2017 Scrum Guide and Scrum Body of Knowledge version 3. The assessment showed that the Blue team achieved maturity level 1 (Initial). It was attained with 16 'Fully Achieved' practices, 49 'Largely Achieved' practices, and 14 'Partially Achieved' practices. Once the maturity level and existing problems were identified, recommendations based on Scrum components (Scrum roles, Scrum artifacts, and Scrum events) were proposed. It aimed to improve Scrum practices that had not been fully achieved by the Blue team. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Modeling of idol dynamic based on social media"
        ],
        "penulis":"Nuraini, Nuning;Kallista, Meta;Sukandar, Kamal Khairudin;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The emergence of idols in music industries, especially recently in South Korea, has led to an increase in the number of fans from around the world, especially among teenagers. The popularity of these idols is also due to the influence of social media reporting on their performances, way of life and daily activities, which covers both positive and negative news. In this research, we develop mathematical models to analyze the impact of media on the idols' popularity using a statistical approach. To apply the models, we collect data from Google Trends for searching statistics graphs that display the popularity of the Korean idols BTS and EXO, and the American idols Taylor Swift and Selena Gomez. We observe the effect of negative and positive news on the popularity of these Eastern and Western idols. It was expected that positive news would increase the number of fanatical fans while negative news would make the fans become bored with the idol quickly. The results show that negative news about Korean idols can reduce their popularity, but on the contrary, negative news about the American idols does not affect their popularity. \u00a9 2020 - IOS Press and the authors. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The emergence of idols in music industries, especially recently in South Korea, has led to an increase in the number of fans from around the world, especially among teenagers. The popularity of these idols is also due to the influence of social media reporting on their performances, way of life and daily activities, which covers both positive and negative news. In this research, we develop mathematical models to analyze the impact of media on the idols' popularity using a statistical approach. To apply the models, we collect data from Google Trends for searching statistics graphs that display the popularity of the Korean idols BTS and EXO, and the American idols Taylor Swift and Selena Gomez. We observe the effect of negative and positive news on the popularity of these Eastern and Western idols. It was expected that positive news would increase the number of fanatical fans while negative news would make the fans become bored with the idol quickly. The results show that negative news about Korean idols can reduce their popularity, but on the contrary, negative news about the American idols does not affect their popularity. \u00a9 2020 - IOS Press and the authors. All rights reserved."
        ]
    },
    {
        "judul":[
            "Performance Comparison of File Transfer Protocol Service between Link State and Distance Vector Routing Protocol in Software Defined Network"
        ],
        "penulis":"Tulloh, Rohmat;Amri Ginting, Jafaruddin Gusti;Mulyana, Asep;Lutfi, Muhammad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Software-Defined Network (SDN) is a new concept in computer networks where the network control function is separated from the data forwarding function (data plane). The control plane and data plane which are separated from each other is the answer for faster, more flexible, and secure internet service. File transfer protocol (FTP) is an internet protocol that runs at the application layer that is used to exchange data between server and client. Open Shortest Path First (OSPF) is a routing protocol for internet networks that belongs to the Interior Gateway Protocol (IGP) group and uses the Link State Routing algorithm (LSR). Routing Information Protocol (RIP) is a type of Distance Vector Routing protocol that is still used today. This study aims to compare the performance of FTP services using OSPF and RIP on SDN networks and conventional networks. The research was conducted with direct implementation on the device with a planned topology. The measurement results show that FTP using OSPF routing has better results than using RIP. FTP that runs on SDN also has a better quality of service value compared to conventional networks.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Software-Defined Network (SDN) is a new concept in computer networks where the network control function is separated from the data forwarding function (data plane). The control plane and data plane which are separated from each other is the answer for faster, more flexible, and secure internet service. File transfer protocol (FTP) is an internet protocol that runs at the application layer that is used to exchange data between server and client. Open Shortest Path First (OSPF) is a routing protocol for internet networks that belongs to the Interior Gateway Protocol (IGP) group and uses the Link State Routing algorithm (LSR). Routing Information Protocol (RIP) is a type of Distance Vector Routing protocol that is still used today. This study aims to compare the performance of FTP services using OSPF and RIP on SDN networks and conventional networks. The research was conducted with direct implementation on the device with a planned topology. The measurement results show that FTP using OSPF routing has better results than using RIP. FTP that runs on SDN also has a better quality of service value compared to conventional networks.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Indonesian text classification using back propagation and sastrawi stemming analysis with information gain for selection feature"
        ],
        "penulis":"Purbolaksono, Mahendra Dwifebri;Reskyadita, Feddy Dea;Adiwijaya;Suryani, Arie Ardiyanti;Huda, Arief Fatchul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The second fundamental source of law for Moslems is the Hadith. The Hadith can be used to explain Quranic texts. However, Hadith still needs to be translated according to each national language to easily understand its meaning [1]. In Indonesia Hadith more usually refers to a special class of relevance to more particular religious concern [1]. Base on that, this research will Classify the translation Hadith Text into three classes: Obligation, Prohibition, and Information. From previous research, the Back Propagation Neural Network (BPNN) showed good performance in classifying hadith text. Therefore, BPNN was used to solve the problem of hadith text classification in this study. However, the dataset has a huge number of varied bag-of-words, which are features that will be used in the classification process. Hence, Information Gain (IG) was utilized to select influential features, and as the sequential process before the classification process. To measure the performance of this system, the Macro F1-Score was used. The F1-Score enables one to observe exactness from precision and completeness from recall. The Macro F1-score is also needed for the performance evaluation of more than two classes. Based on the experiment conducted, the system was able to classify hadith text using BPNN, IG, and without stemming, yielding the highest F1-score of 84.63%. However, the system performance that included the stemming process yielded an F1-score of 80.92%. This shows that the stemming process could decrease classification performance. This decreasing performance is due to some influential words merging with more noninfluential words. \u00a9 2020 Insight Society.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The second fundamental source of law for Moslems is the Hadith. The Hadith can be used to explain Quranic texts. However, Hadith still needs to be translated according to each national language to easily understand its meaning [1]. In Indonesia Hadith more usually refers to a special class of relevance to more particular religious concern [1]. Base on that, this research will Classify the translation Hadith Text into three classes: Obligation, Prohibition, and Information. From previous research, the Back Propagation Neural Network (BPNN) showed good performance in classifying hadith text. Therefore, BPNN was used to solve the problem of hadith text classification in this study. However, the dataset has a huge number of varied bag-of-words, which are features that will be used in the classification process. Hence, Information Gain (IG) was utilized to select influential features, and as the sequential process before the classification process. To measure the performance of this system, the Macro F1-Score was used. The F1-Score enables one to observe exactness from precision and completeness from recall. The Macro F1-score is also needed for the performance evaluation of more than two classes. Based on the experiment conducted, the system was able to classify hadith text using BPNN, IG, and without stemming, yielding the highest F1-score of 84.63%. However, the system performance that included the stemming process yielded an F1-score of 80.92%. This shows that the stemming process could decrease classification performance. This decreasing performance is due to some influential words merging with more noninfluential words. \u00a9 2020 Insight Society."
        ]
    },
    {
        "judul":[
            "Organization and IT Strategic Alignment, Determination of IT Process Priorities using COBIT 5"
        ],
        "penulis":"Hanafi, Ridha;Wibowo, Lili Adi;Rahayu, Agus;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The role of information technology (IT) for many organizations today is not just a supporting role, but already has strategic role as an organizational enabler. Organizations that do not utilize information systems and technology will inevitably be unable to compete in fierce business competition and satisfy customers. Therefore companies need to align organizational strategies with IT strategies in order to achieve organizational goals. However, it is often difficult for organizations to translate their business strategy into an appropriate IT strategy. There a needs to be an appropriate, comprehensive and easy approach for organizations to be able to align organizational and IT strategies. COBIT 5 provides a fairly generic, comprehensive and easy approach to doing this. The approach is expected to provide guidance on aligning organizational and IT strategies while providing direction at the operational level for organizations to identify the IT business processes that suit their needs and determine their priority levels. COBIT 5 is best practices framework, provides a reference guide for IT governance and management processes, in total 37 processes. This research takes the object of a company in the field of sales distribution of mechanical and electrical products and services, which are quite competitive that seeks to implement appropriate IT strategies to support the achievement of their organizational goals. In the implementation of IT governance and management, the company found difficulty to determine priority of which IT processes need to be implemented first in order to be aligned with the organization and IT strategy, due to their limited resources. This study can help companies align their business and IT strategies and can provide priority proposals for IT business processes that companies should implement. By using COBIT 5 approach, companies can map IT process priorities based on mapping of organizational goals, IT objectives and IT processes. The results of this study are IT process priorities recommended for the company: Manage IT Risk, Manage IT Programs and Projects, Manage Change Acceptance and Transitioning, Manage IT Security, Manage IT Changes, Manage IT Services Operations, Manage IT Portfolios, and Manage Availability and Capacity. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The role of information technology (IT) for many organizations today is not just a supporting role, but already has strategic role as an organizational enabler. Organizations that do not utilize information systems and technology will inevitably be unable to compete in fierce business competition and satisfy customers. Therefore companies need to align organizational strategies with IT strategies in order to achieve organizational goals. However, it is often difficult for organizations to translate their business strategy into an appropriate IT strategy. There a needs to be an appropriate, comprehensive and easy approach for organizations to be able to align organizational and IT strategies. COBIT 5 provides a fairly generic, comprehensive and easy approach to doing this. The approach is expected to provide guidance on aligning organizational and IT strategies while providing direction at the operational level for organizations to identify the IT business processes that suit their needs and determine their priority levels. COBIT 5 is best practices framework, provides a reference guide for IT governance and management processes, in total 37 processes. This research takes the object of a company in the field of sales distribution of mechanical and electrical products and services, which are quite competitive that seeks to implement appropriate IT strategies to support the achievement of their organizational goals. In the implementation of IT governance and management, the company found difficulty to determine priority of which IT processes need to be implemented first in order to be aligned with the organization and IT strategy, due to their limited resources. This study can help companies align their business and IT strategies and can provide priority proposals for IT business processes that companies should implement. By using COBIT 5 approach, companies can map IT process priorities based on mapping of organizational goals, IT objectives and IT processes. The results of this study are IT process priorities recommended for the company: Manage IT Risk, Manage IT Programs and Projects, Manage Change Acceptance and Transitioning, Manage IT Security, Manage IT Changes, Manage IT Services Operations, Manage IT Portfolios, and Manage Availability and Capacity. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Green Production Using ERP: Case Study in the Leather Tanning Industry"
        ],
        "penulis":"Ikhsan, Ihwanul;Ridwan, Ari Yanuar;Saputra, Muhardi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Along with the times, information technology must be a public need that must be approved, including for companies. PT. Elco Indonesia Sejahtera is a company engaged in the trading of leather for the production of garment materials, gloves, and various other leather goods. This company is located on the street of Gagak Lumayung, Wetan City, Garut Kota District, Garut Regency, West Java. Production processes that produce complex solid and liquid environments use clam fuel in the process. This will be dangerous for the environment. Green Production is one way to overcome the process of making goods that can support business processes at PT. Elco Indonesia Sejahtera. Therefore in this study will develop a Green ERP application in the production module to realize an environmentally friendly green industry. This research uses SAP Activate method that starts from the interview process, starts with observation, and analyzes business processes, and analyzes and discusses the system by configuring and discussing module production. This study uses a system that supports the business process of PT Elco Indonesia Sejahtera, Odoo. The results of this study are ERP systems that are supported by Odoo and have been adapted to the company's business processes that have been redesigned and are expected to facilitate the company in carrying out business process activities specifically produced at PT. Elco Indonesia Sejahtera. This research is able to integrate the manufacturing module with the green procurement and green sales and distribution modules. The green production module can produce monitoring reports (Manufacturing Orders, Work Orders, and Overall Equipment Affection) from manufacturing orders in the Manufacturing module for the Odoo-based leather tanning industry.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Along with the times, information technology must be a public need that must be approved, including for companies. PT. Elco Indonesia Sejahtera is a company engaged in the trading of leather for the production of garment materials, gloves, and various other leather goods. This company is located on the street of Gagak Lumayung, Wetan City, Garut Kota District, Garut Regency, West Java. Production processes that produce complex solid and liquid environments use clam fuel in the process. This will be dangerous for the environment. Green Production is one way to overcome the process of making goods that can support business processes at PT. Elco Indonesia Sejahtera. Therefore in this study will develop a Green ERP application in the production module to realize an environmentally friendly green industry. This research uses SAP Activate method that starts from the interview process, starts with observation, and analyzes business processes, and analyzes and discusses the system by configuring and discussing module production. This study uses a system that supports the business process of PT Elco Indonesia Sejahtera, Odoo. The results of this study are ERP systems that are supported by Odoo and have been adapted to the company's business processes that have been redesigned and are expected to facilitate the company in carrying out business process activities specifically produced at PT. Elco Indonesia Sejahtera. This research is able to integrate the manufacturing module with the green procurement and green sales and distribution modules. The green production module can produce monitoring reports (Manufacturing Orders, Work Orders, and Overall Equipment Affection) from manufacturing orders in the Manufacturing module for the Odoo-based leather tanning industry.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Combination of extraction features based on texture and colour feature for beef and pork classification"
        ],
        "penulis":"Priyatno A.M.;Putra F.M.;Cholidhazia P.;Ningsih L.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Behaviour of traders mixing beef and pork is very detrimental to consumers, especially followers of Islam because it is related to legal or forbidden food. So, consumers must be protected from these rogue traders. However, differentiating beef and pork is not easy for ordinary people, especially if you only see from one information that is the colour or texture. In this paper, we proposed a new combination of extraction features based on texture and colour features for the classification of beef and pork. The feature of the texture is to see the local information optimally by using a local optimal-oriented pattern (LOOP) so that it can provide better texture information. The colour features that will be used are hue, saturation, and value (HSV). Texture and colour features are combined into one, so that more enrich the information used. The combination of optimal local-oriented pattern features and hue saturation value gives increased accuracy for the classification of pork and beef. The results of tests that have been done show that the success rate of calcification by using a combination of features has increased. accuracy obtained is equal to 99.16 percent, recall 100 percent and precision 98.36 percent. this shows that by utilizing the colour features and texture features can provide improved classification due to increased information that can be used to do the classification. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Behaviour of traders mixing beef and pork is very detrimental to consumers, especially followers of Islam because it is related to legal or forbidden food. So, consumers must be protected from these rogue traders. However, differentiating beef and pork is not easy for ordinary people, especially if you only see from one information that is the colour or texture. In this paper, we proposed a new combination of extraction features based on texture and colour features for the classification of beef and pork. The feature of the texture is to see the local information optimally by using a local optimal-oriented pattern (LOOP) so that it can provide better texture information. The colour features that will be used are hue, saturation, and value (HSV). Texture and colour features are combined into one, so that more enrich the information used. The combination of optimal local-oriented pattern features and hue saturation value gives increased accuracy for the classification of pork and beef. The results of tests that have been done show that the success rate of calcification by using a combination of features has increased. accuracy obtained is equal to 99.16 percent, recall 100 percent and precision 98.36 percent. this shows that by utilizing the colour features and texture features can provide improved classification due to increased information that can be used to do the classification. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Feed of reflectarray antenna for high speed data communication at X band frequency for CubeSat 3U"
        ],
        "penulis":"Putra Y.D.;Syihabuddin B.;Edwar;Pramudita A.A.;Vidyaningtyas H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Telkom University through Nanosatellite Laboratory has a project to design a nanosatellite that based on CubeSat 3U standard with one of its missions high-speed data communication at X Band frequency. An antenna is needed to succeed in the communication with the desired data-rate (100 Mbps) and BER at the receiver which required 19 dBi. Limitation of dimensions and mass allowed makes it impossible to implement parabolic antenna. A reflectarray antenna b offered as a solution for the limitation of dimensions, mass, and gain. To radiate an efficient reflectarray, a feed is needed as the Illuminator of electromagnetic waves to the reflectarray panel. This paper focused on ndcrostrip antenna that used as the feed of reflectarray antenna prototype based on the CubeSat 3U structure. Gain of 133 dBi and -54.7 dB return loss at 8.2125 GHz are achieved with a unidirectional pattern and bandwidth of 384 MHz. \u00a9 2020 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Telkom University through Nanosatellite Laboratory has a project to design a nanosatellite that based on CubeSat 3U standard with one of its missions high-speed data communication at X Band frequency. An antenna is needed to succeed in the communication with the desired data-rate (100 Mbps) and BER at the receiver which required 19 dBi. Limitation of dimensions and mass allowed makes it impossible to implement parabolic antenna. A reflectarray antenna b offered as a solution for the limitation of dimensions, mass, and gain. To radiate an efficient reflectarray, a feed is needed as the Illuminator of electromagnetic waves to the reflectarray panel. This paper focused on ndcrostrip antenna that used as the feed of reflectarray antenna prototype based on the CubeSat 3U structure. Gain of 133 dBi and -54.7 dB return loss at 8.2125 GHz are achieved with a unidirectional pattern and bandwidth of 384 MHz. \u00a9 2020 IEEE"
        ]
    },
    {
        "judul":[
            "Phonological similarity-based backoff smoothing to boost a bigram syllable boundary detection"
        ],
        "penulis":"Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Swapping one or more consonant-graphemes in a word into other phonologically similar ones, which based on both place and manner of articulation, interestingly produces some other words without shifting the syllable boundary (or point). For examples, in the Indonesian language, swapping consonant-graphemes in a word \u201cba.ra\u201d (embers) creates three new words: \u201cba.la\u201d (disaster), \u201cpa.ra\u201d (reference to a group), and \u201cpa.la\u201d (nutmeg) without changing the syllabification points since both graphemes \u27e8 b \u27e9 and \u27e8 p \u27e9 are in the same category of plosive-bilabial while both \u27e8 r \u27e9 and \u27e8 l \u27e9 are trill\/lateral-dental. An observation on 50k Indonesian words shows that replacing consonant-graphemes in those words impressively increases the number of unigrams by 16.52 times and significantly increases the number of bigrams by 14.12 times. Therefore, in this paper, a procedure of swapping consonant-graphemes based on phonological similarity is proposed to boost the standard bigram-based orthographic syllabification, which commonly has a low performance for a dataset with many out-of-vocabulary (OOV) bigrams. Some examinations on the 50k words using the k-fold cross-validation scheme, with k= 5 , prove that the proposed procedure significantly boosts the standard bigram-syllabification, where it gives a relative reduction of mean syllable error rate (SER) up to 31.39%. It also shows an improvement for the dataset of 15k named-entities by relatively decreasing the average SER by 9.53%. It is better than a flipping onsets-based model for both datasets. Compared to a nearest neighbor-based model, its performance is a little worse, but it provides much lower complexity. Another important finding is that the proposed model can produce a relatively small SER, even for a tiny training-set. \u00a9 2020, Springer Science+Business Media, LLC, part of Springer Nature.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Swapping one or more consonant-graphemes in a word into other phonologically similar ones, which based on both place and manner of articulation, interestingly produces some other words without shifting the syllable boundary (or point). For examples, in the Indonesian language, swapping consonant-graphemes in a word \u201cba.ra\u201d (embers) creates three new words: \u201cba.la\u201d (disaster), \u201cpa.ra\u201d (reference to a group), and \u201cpa.la\u201d (nutmeg) without changing the syllabification points since both graphemes \u27e8 b \u27e9 and \u27e8 p \u27e9 are in the same category of plosive-bilabial while both \u27e8 r \u27e9 and \u27e8 l \u27e9 are trill\/lateral-dental. An observation on 50k Indonesian words shows that replacing consonant-graphemes in those words impressively increases the number of unigrams by 16.52 times and significantly increases the number of bigrams by 14.12 times. Therefore, in this paper, a procedure of swapping consonant-graphemes based on phonological similarity is proposed to boost the standard bigram-based orthographic syllabification, which commonly has a low performance for a dataset with many out-of-vocabulary (OOV) bigrams. Some examinations on the 50k words using the k-fold cross-validation scheme, with k= 5 , prove that the proposed procedure significantly boosts the standard bigram-syllabification, where it gives a relative reduction of mean syllable error rate (SER) up to 31.39%. It also shows an improvement for the dataset of 15k named-entities by relatively decreasing the average SER by 9.53%. It is better than a flipping onsets-based model for both datasets. Compared to a nearest neighbor-based model, its performance is a little worse, but it provides much lower complexity. Another important finding is that the proposed model can produce a relatively small SER, even for a tiny training-set. \u00a9 2020, Springer Science+Business Media, LLC, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "Antibiotic Inventory Policy Design for Minimizing Total Inventory Costs in Pharmacies based on ABC-Fuzzy Classification Analysis Approach using Probabilistic Continuous Review Method"
        ],
        "penulis":"Shiddieq, Naufaldanny Farhan;Ridwan, Ari Yanuar;Santosa, Budi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT XYZ is a company that providing the medication needs company employess. Problems that occur at the PT XYZ Pharmacies is the excess inventory in the pharmacy storage of PT XYZ Pharmacieswithout being balanced with customer requests that cause overstock. Ordering goods at the PT XYZ Pharmaciesis done every time there is a shortage of inventory, but the amount of antibiotics purchased at the ordering time does not have a standard that is standard so that there is an excess inventory of antibiotic category drugs. This research was conducted on the category of antibiotic drugs which have a total SKU of 1339 SKU and has a normally distributed demand pattern. Existing antibiotics at PT XYZ has not yet been classified, so it does not yet have priority handling, also caused an overbudget on company finances. The results of this study indicate that the classification of anitibiotics uses the ABC-Fuzzy Classification which is divided into three categories, namely very important with 142 SKU, important with 135 SKU, unimportant with 1062 SKU. The results of the calculation of total inventory costs using the probabilistic continuous review policy resulted in savings of Rp 59,840,285 or 24% lower than the total cost of existing inventory. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT XYZ is a company that providing the medication needs company employess. Problems that occur at the PT XYZ Pharmacies is the excess inventory in the pharmacy storage of PT XYZ Pharmacieswithout being balanced with customer requests that cause overstock. Ordering goods at the PT XYZ Pharmaciesis done every time there is a shortage of inventory, but the amount of antibiotics purchased at the ordering time does not have a standard that is standard so that there is an excess inventory of antibiotic category drugs. This research was conducted on the category of antibiotic drugs which have a total SKU of 1339 SKU and has a normally distributed demand pattern. Existing antibiotics at PT XYZ has not yet been classified, so it does not yet have priority handling, also caused an overbudget on company finances. The results of this study indicate that the classification of anitibiotics uses the ABC-Fuzzy Classification which is divided into three categories, namely very important with 142 SKU, important with 135 SKU, unimportant with 1062 SKU. The results of the calculation of total inventory costs using the probabilistic continuous review policy resulted in savings of Rp 59,840,285 or 24% lower than the total cost of existing inventory. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Stable shape for copper film using low-temperature thermal decomposition of copper microparticles for printable electronics"
        ],
        "penulis":"Yabuki, Akihiro;Iwamura, Yuta;Fathona, Indra Wahyudhin;Lee, Ji Ha;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A paste of copper microparticles, formic acid, and octylamine was developed to produce thick copper films with a stable shape and low electrical resistivity via low-temperature calcination. This study examined (1) the effect of cleaning the copper microparticle surface with formic acid, (2) the effect of calcination temperature, and (3) the effect that the addition of amine exerted on volume resistivity and on the shape of the copper film. The volume resistivities of the thick copper film were measured using a 4-point probe method. The thickness and shape of the copper film was observed via FE-SEM using an optical microscope. \u00a9 2020",
            "HOOHOCH3View detailsExpand Substance formic acid-ethanolOOCu2View detailsExpand Substance copper(II) formateNHCH3H3CView detailsExpand Substance dihexylamineNH2H3CView detailsExpand Substance n-OctylamineOHOHView detailsExpand Substance formic acidNHCH3H3CView detailsExpand Substance Di-n-amylamineNHCH3H3CView detailsExpand Substance di-n-propylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A paste of copper microparticles, formic acid, and octylamine was developed to produce thick copper films with a stable shape and low electrical resistivity via low-temperature calcination. This study examined (1) the effect of cleaning the copper microparticle surface with formic acid, (2) the effect of calcination temperature, and (3) the effect that the addition of amine exerted on volume resistivity and on the shape of the copper film. The volume resistivities of the thick copper film were measured using a 4-point probe method. The thickness and shape of the copper film was observed via FE-SEM using an optical microscope. \u00a9 2020"
        ]
    },
    {
        "judul":[
            "The Effect of Overlap Value and Grid Coefficient on Yang Method: Super-Resolution Image Reconstruction Using Random Raw Patches"
        ],
        "penulis":"Atmaja, Ratri Dwi;Suksmono, Andriyan Bayu;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Super-resolution images are often needed in computer vision applications because having high pixel density can provide more detailed information. Super-resolution images can be obtained by interpolation-based methods and training-reconstruction based methods. Although needs more processing time, the image quality of the training-reconstruction based method is better than the interpolation-based method. This paper contributes to investigating the effect of overlap value and grid coefficient on the Yang method. This Yang method works based on random raw patches obtained through the sampling process. The overlap value and the grid coefficient are set by the user in the sampling process. In testing, we use a grayscale image with a size of 60 \u00d7 80. The image is reconstructed with magnification factor 3. The result shows that the bigger overlap value produces a smaller RMSE and a longer processing time. While grid coefficient = 1 produces a big RMSE. This is because the grid coefficient gives a few sampling points. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Super-resolution images are often needed in computer vision applications because having high pixel density can provide more detailed information. Super-resolution images can be obtained by interpolation-based methods and training-reconstruction based methods. Although needs more processing time, the image quality of the training-reconstruction based method is better than the interpolation-based method. This paper contributes to investigating the effect of overlap value and grid coefficient on the Yang method. This Yang method works based on random raw patches obtained through the sampling process. The overlap value and the grid coefficient are set by the user in the sampling process. In testing, we use a grayscale image with a size of 60 \u00d7 80. The image is reconstructed with magnification factor 3. The result shows that the bigger overlap value produces a smaller RMSE and a longer processing time. While grid coefficient = 1 produces a big RMSE. This is because the grid coefficient gives a few sampling points. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Anatomy of large perpendicular magnetic anisotropy in free-standing Co\/Ni (1 1 1) multilayer"
        ],
        "penulis":"Pardede, Indra;Yoshikawa, Daiki;Kanagawa, Tomosato;Ikhsan, Nurul;Murata, Itsuki;Obata, Masao;Oda, Tatsuki;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We investigated the magnetic anisotropy energy (MAE) in the free-standing Co\/Ni (1 1 1) multilayer as both Ni thickness dependence (tNi= 1-4MLs) and number of multilayer repetition times (N = 1\u20133) by means of a first-principles electronic structure calculation based on spin density functional theory. We included both contributions to the MAE from magnetocrystalline anisotropy energy (MCAE) originating from spin-orbit coupling and shape magnetic anisotropy energy (SMAE) originating from spin dipole-dipole interaction. The MCAE part was evaluated from both methods of total energy (TE) and grand-canonical force theorem (GCFT). The SMAE part was calculated by using a spin density approach (SDA). All MCAE values from the TE are well reproduced by those from the GCFT method. In N = 1, the total MAE (MCAE + SMAE) for tNishowed a perpendicular MAE (PMAE) with a maximum value of 1.67 mJ\/m2at tNi= 2MLs. The PMAE increases with increasing N. The series of tNi= 3MLs showed a linear behavior as N dependence with an increasing ratio of 0.68 mJ\/m2, which is in good agreement with experimental measurement. By using the GCFT, we evaluated the atom-resolved and k-resolved MCAEs. The atom-resolved MCAE indicates that the Co\/Ni interface is the main origin of PMAE. The PMAE is mainly located at \u0393\u00af-K\u00af line in the two dimensional Brillouin zone. This is attributed to large components of the d-orbitals extending along the multilayer plane on Co and Ni near the Fermi energy. We also calculated the SMAE using a discrete approach (DA) and found that there is a reduction of SMAE part in the SDA, compared to the DA. This reduction originates from a prolate quadrupole component of spin density distribution. The present comprehensive study may provide a better understanding of magnetic properties in Co\/Ni multilayers as widely used in spintronic devices. \u00a9 2019 Elsevier B.V.",
            "HONH2CH3HHView detailsExpand Substance (1S,2S)-2-amino-1-phenylpropanolNNHCH3View detailsExpand Substance Desipramin",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We investigated the magnetic anisotropy energy (MAE) in the free-standing Co\/Ni (1 1 1) multilayer as both Ni thickness dependence (tNi= 1-4MLs) and number of multilayer repetition times (N = 1\u20133) by means of a first-principles electronic structure calculation based on spin density functional theory. We included both contributions to the MAE from magnetocrystalline anisotropy energy (MCAE) originating from spin-orbit coupling and shape magnetic anisotropy energy (SMAE) originating from spin dipole-dipole interaction. The MCAE part was evaluated from both methods of total energy (TE) and grand-canonical force theorem (GCFT). The SMAE part was calculated by using a spin density approach (SDA). All MCAE values from the TE are well reproduced by those from the GCFT method. In N = 1, the total MAE (MCAE + SMAE) for tNishowed a perpendicular MAE (PMAE) with a maximum value of 1.67 mJ\/m2at tNi= 2MLs. The PMAE increases with increasing N. The series of tNi= 3MLs showed a linear behavior as N dependence with an increasing ratio of 0.68 mJ\/m2, which is in good agreement with experimental measurement. By using the GCFT, we evaluated the atom-resolved and k-resolved MCAEs. The atom-resolved MCAE indicates that the Co\/Ni interface is the main origin of PMAE. The PMAE is mainly located at \u0393\u00af-K\u00af line in the two dimensional Brillouin zone. This is attributed to large components of the d-orbitals extending along the multilayer plane on Co and Ni near the Fermi energy. We also calculated the SMAE using a discrete approach (DA) and found that there is a reduction of SMAE part in the SDA, compared to the DA. This reduction originates from a prolate quadrupole component of spin density distribution. The present comprehensive study may provide a better understanding of magnetic properties in Co\/Ni multilayers as widely used in spintronic devices. \u00a9 2019 Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Data of innovation ambidexterity as a mediator in the absorptive capacity effect on sustainable competitive advantage"
        ],
        "penulis":"Pangarso, Astadi;Astuti, Endang Siti;Raharjo, Kusdi;Afrianty, Tri Wulida;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This data article shows the nexus between absorptive capacity (X), innovation ambidexterity (Y1) and sustainable competitive advantage (Y2). There are three nexus points between the constructs, namely the direct nexuses of X to Y1, X to Y2 and the indirect nexus from X to Y2 through Y1. The raw data of 530 self-administrated questionnaires were obtained from 64 non-vocational private higher education institutions in the Bandung area of West Java, Indonesia. Data analyzing were conducted using SPPS and Smart PLS. The data are useful as the data can be reproduced, reused and reanalysed. This data article also opens up better research opportunities going forward through collaboration with other researchers. \u00a9 2020 The Author(s)",
            "HNNH3CView detailsExpand Substance harmane",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This data article shows the nexus between absorptive capacity (X), innovation ambidexterity (Y1) and sustainable competitive advantage (Y2). There are three nexus points between the constructs, namely the direct nexuses of X to Y1, X to Y2 and the indirect nexus from X to Y2 through Y1. The raw data of 530 self-administrated questionnaires were obtained from 64 non-vocational private higher education institutions in the Bandung area of West Java, Indonesia. Data analyzing were conducted using SPPS and Smart PLS. The data are useful as the data can be reproduced, reused and reanalysed. This data article also opens up better research opportunities going forward through collaboration with other researchers. \u00a9 2020 The Author(s)"
        ]
    },
    {
        "judul":[
            "Energy Saving Management with Suggestion Method in Home Automation based on User Habits"
        ],
        "penulis":"Nurfadilah, Muhammad Fahmi;Hariyanto, Nurman;Prihatmanto, Ary Setijadi;Darmakusuma, Reza;Wijaya, Rifki;Pratama, Vitradisa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In designing an automation system to help make it easier for humans to control and monitor household appliances or smart houses often experience problems with the problem of estimating the increasing burden of electric current because it uses additional tools to control the household appliances. To reduce this view, it can be solved by regulating the energy to be consumed from the household appliance by using a smart meter as a monitoring device specifically designed with excess internet to send data taken from the energy meter and then the incoming data can be processed analyzed from the peak current demand of electric current using the User Habits method which will be combined with the energy scheduling method and combined with suggestion turning on or off the household appliances, so that it is expected to provide comfort and effectiveness in using Home Automation. Effectiveness means that all home appliances or intruments must be running properly first, such as KWH meters, the lamp, switches, dispensers, mini server (local saving), and data center (global saving). And then, after the effectiveness has been running good or smooth the author continues his research into efficiency, namely an energy saving mode with an energy management process based on user habits.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In designing an automation system to help make it easier for humans to control and monitor household appliances or smart houses often experience problems with the problem of estimating the increasing burden of electric current because it uses additional tools to control the household appliances. To reduce this view, it can be solved by regulating the energy to be consumed from the household appliance by using a smart meter as a monitoring device specifically designed with excess internet to send data taken from the energy meter and then the incoming data can be processed analyzed from the peak current demand of electric current using the User Habits method which will be combined with the energy scheduling method and combined with suggestion turning on or off the household appliances, so that it is expected to provide comfort and effectiveness in using Home Automation. Effectiveness means that all home appliances or intruments must be running properly first, such as KWH meters, the lamp, switches, dispensers, mini server (local saving), and data center (global saving). And then, after the effectiveness has been running good or smooth the author continues his research into efficiency, namely an energy saving mode with an energy management process based on user habits.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Speech recognition implementation using MFCC and DTW algorithm for home automation"
        ],
        "penulis":"Haq, Abdulloh Salahul;Nasrun, Muhammad;Setianingsih, Casi;Murti, Muhammad Ary;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The use of speech recognition as part of home automation, especially for smart homes, is an exciting thing that is still being developed. That is because of human needs for comfort, convenience, quality of life, and better safety. Speech recognition built in this study is used as a device to control smart home devices by identifying the commands spoken by users, especially in a state of clean speech. The command used is a predetermined consecutive word. For the extraction of voice commands, the MFCC algorithm is used to match spoken words with templates using the Dynamic Time Warping (DTW) algorithm. DTW algorithm can find the difference between 2-time series that have different lengths of time. The results of the accuracy of this system by using these algorithms were successfully carried out by 86.67%, with an average time required to identify the commands of 5.28 seconds. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of speech recognition as part of home automation, especially for smart homes, is an exciting thing that is still being developed. That is because of human needs for comfort, convenience, quality of life, and better safety. Speech recognition built in this study is used as a device to control smart home devices by identifying the commands spoken by users, especially in a state of clean speech. The command used is a predetermined consecutive word. For the extraction of voice commands, the MFCC algorithm is used to match spoken words with templates using the Dynamic Time Warping (DTW) algorithm. DTW algorithm can find the difference between 2-time series that have different lengths of time. The results of the accuracy of this system by using these algorithms were successfully carried out by 86.67%, with an average time required to identify the commands of 5.28 seconds. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "New product development architectural framework for sustainability and innovation within telecommunication industry"
        ],
        "penulis":"Lubis, Muharman;Fathoni, Muhammad;Lubis, Arif Ridho;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "New product development is a ready-to-use innovation method that elaborate the relevant factors such as production and development cost, time to market and product value to own a higher level of technical, logical and organizational uncertainty rather than simply redesigning the product to attract the customer. Given the increasing uncertainty in the new product development process, standard general rules cannot be applied to improving an existing product and it is necessary to conduct a more open stage of brainstorming. This study explores the investigation phase and design approach to developing a new product development framework that includes resources, activity and interference by examining three telecommunication companies as case study. To allow the identification reveal comprehensive, concrete and consistent component, the study focused on several companies within the telecommunication industry. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "New product development is a ready-to-use innovation method that elaborate the relevant factors such as production and development cost, time to market and product value to own a higher level of technical, logical and organizational uncertainty rather than simply redesigning the product to attract the customer. Given the increasing uncertainty in the new product development process, standard general rules cannot be applied to improving an existing product and it is necessary to conduct a more open stage of brainstorming. This study explores the investigation phase and design approach to developing a new product development framework that includes resources, activity and interference by examining three telecommunication companies as case study. To allow the identification reveal comprehensive, concrete and consistent component, the study focused on several companies within the telecommunication industry. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Deep Learning Based Heart Rate Estimation Using Smart Shoes Sensor"
        ],
        "penulis":"Baek, Suwhan;Eom, Heesang;Hariyani, Yuli Sun;Kim, Gwangho;Roh, Jongryum;Kim, Sayup;Park, Chelsoo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Although heart rate is an important biomarker of the physical condition at active states of users, it is still difficult to be measured due to an ambient noise and movements. There have been several approaches proposed to obtain stable measurements in an active condition. However, these methods still need direct contact to users, and thus additional equipment to keep the contact are requested, resulting in inconvenience of its usage. This paper proposes a method to estimate the heart rate of the user using activity information from smart shoes sensors, which is relatively easy and robust to be recorded. For the accurate estimation of the heart rate, a new design of deep neural networks is proposed. The architecture extracts features of time-sequential patterns of sensor data with implementing CNN and LSTM model together. The model was validated with a 'Leave-OneOut Cross-Validation method'. The results of the experiments are 10.21 \u00b1 3.31 RMSE, 8.31 \u00b1 2.81 MAE and 0.91 \u00b1 0.09 correlation coefficient (Pearson) for the estimation of heart rate from smart shoes sensor data. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Although heart rate is an important biomarker of the physical condition at active states of users, it is still difficult to be measured due to an ambient noise and movements. There have been several approaches proposed to obtain stable measurements in an active condition. However, these methods still need direct contact to users, and thus additional equipment to keep the contact are requested, resulting in inconvenience of its usage. This paper proposes a method to estimate the heart rate of the user using activity information from smart shoes sensors, which is relatively easy and robust to be recorded. For the accurate estimation of the heart rate, a new design of deep neural networks is proposed. The architecture extracts features of time-sequential patterns of sensor data with implementing CNN and LSTM model together. The model was validated with a 'Leave-OneOut Cross-Validation method'. The results of the experiments are 10.21 \u00b1 3.31 RMSE, 8.31 \u00b1 2.81 MAE and 0.91 \u00b1 0.09 correlation coefficient (Pearson) for the estimation of heart rate from smart shoes sensor data. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Determining optimal location for mangrove planting using remote sensing and climate model projection in southeast asia"
        ],
        "penulis":"Syahid, Luri Nurlaila;Sakti, Anjar Dimara;Virtriana, Riantini;Wikantika, Ketut;Windupranata, Wiwin;Tsuyuki, Satoshi;Caraka, Rezzy Eko;Pribadi, Rudhi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The decreasing area of mangroves is an ongoing problem since, between 1980 and 2005, one-third of the world\u2019s mangroves were lost. Rehabilitation and restoration strategies are required to address this situation. However, mangroves do not always respond well to these strategies and have high mortality due to several growth limiting parameters. This study developed a land suitability map for new mangrove plantations in different Southeast Asian countries for both current and future climates at a 250-m resolution. Hydrodynamic, geomorphological, climatic, and socio-economic parameters and three representative concentration pathway (RCP) scenarios (RCP 2.6, 4.5, and 8.5) for 2050 and 2070 with two global climate model datasets (the Centre National de Recherches M\u00e9t\u00e9orologiques Climate model version 5 [CNRM-CM5.1] and the Model for Interdisciplinary Research on Climate [MIROC5]) were used to predict suitable areas for mangrove planting. An analytical hierarchy process (AHP) was used to determine the level of importance for each parameter. To test the accuracy of the results, the mangrove land suitability analysis were further compared using different weights in every parameter. The sensitivity test using the Wilcoxon test was also carried out to test which variables had changed with the first weight and the AHP weight. The land suitability products from this study were compared with those from previous studies. The differences in land suitability for each country in Southeast Asia in 2050 and 2070 to analyze the differences in each RCP scenario and their effects on the mangrove land suitability were also assessed. Currently, there is 398,000 ha of potentially suitable land for mangrove planting in Southeast Asia, and this study shows that it will increase between now and 2070. Indonesia account for 67.34% of the total land area in the \u201cvery suitable\u201d and \u201csuitable\u201d class categories. The RCP 8.5 scenario in 2070, with both the MIROC5 and CNRM-CM5.1 models, resulted in the largest area of a \u201cvery suitable\u201d class category for mangrove planting. This study provides information for the migration of mangrove forests to the land, alleviating many drawbacks, especially for ecosystems. \u00a9 MDPI AG. All rights reserved.",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14Life on landGoal 15Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The decreasing area of mangroves is an ongoing problem since, between 1980 and 2005, one-third of the world\u2019s mangroves were lost. Rehabilitation and restoration strategies are required to address this situation. However, mangroves do not always respond well to these strategies and have high mortality due to several growth limiting parameters. This study developed a land suitability map for new mangrove plantations in different Southeast Asian countries for both current and future climates at a 250-m resolution. Hydrodynamic, geomorphological, climatic, and socio-economic parameters and three representative concentration pathway (RCP) scenarios (RCP 2.6, 4.5, and 8.5) for 2050 and 2070 with two global climate model datasets (the Centre National de Recherches M\u00e9t\u00e9orologiques Climate model version 5 [CNRM-CM5.1] and the Model for Interdisciplinary Research on Climate [MIROC5]) were used to predict suitable areas for mangrove planting. An analytical hierarchy process (AHP) was used to determine the level of importance for each parameter. To test the accuracy of the results, the mangrove land suitability analysis were further compared using different weights in every parameter. The sensitivity test using the Wilcoxon test was also carried out to test which variables had changed with the first weight and the AHP weight. The land suitability products from this study were compared with those from previous studies. The differences in land suitability for each country in Southeast Asia in 2050 and 2070 to analyze the differences in each RCP scenario and their effects on the mangrove land suitability were also assessed. Currently, there is 398,000 ha of potentially suitable land for mangrove planting in Southeast Asia, and this study shows that it will increase between now and 2070. Indonesia account for 67.34% of the total land area in the \u201cvery suitable\u201d and \u201csuitable\u201d class categories. The RCP 8.5 scenario in 2070, with both the MIROC5 and CNRM-CM5.1 models, resulted in the largest area of a \u201cvery suitable\u201d class category for mangrove planting. This study provides information for the migration of mangrove forests to the land, alleviating many drawbacks, especially for ecosystems. \u00a9 MDPI AG. All rights reserved."
        ]
    },
    {
        "judul":[
            "Language Modeling for Journalistic Robot based on Generative Pretrained Transformer 2"
        ],
        "penulis":"Suraperwata, Raihan Hamid;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The language model is typically represented as an unsupervised distribution estimate from a set of examples, each consisting of symbol sequences, and it could predict over sequences of words. We demonstrate the language model based on Generative Pretrained 2 will have a readable generated article for the journalistic robot. Nowadays, there is some trending of journalistic in Indonesia, freedom of the press, and it enables every journalist to make unprofessional news on the media. The problem affects the raise of journalist numbers who have lack journalistic knowledge and increases the amount of inappropriate news content in Indonesia. Therefore, to improve the quality of news produced by the mass media in Indonesia, a journalistic robot is needed to produce news content by the guidelines and the journalistic code of ethics. This research uses language modeling based on GPT-2 to generate articles. The program has four primary steps: building dataset, fine tuning GPT-2, modeling the trained data, and create articles. Furthermore, this research will add an Indonesian model for GPT-2 since the main purpose of this research is Indonesian articles. This paper proposes GPT-2 to be applied to news contents and calculate the result with BLEU scores to check if the results are readable content. These findings show that the proposed model is capable of generating a readable article after trained by 110 Indonesian articles with an excellent score of BLEU.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The language model is typically represented as an unsupervised distribution estimate from a set of examples, each consisting of symbol sequences, and it could predict over sequences of words. We demonstrate the language model based on Generative Pretrained 2 will have a readable generated article for the journalistic robot. Nowadays, there is some trending of journalistic in Indonesia, freedom of the press, and it enables every journalist to make unprofessional news on the media. The problem affects the raise of journalist numbers who have lack journalistic knowledge and increases the amount of inappropriate news content in Indonesia. Therefore, to improve the quality of news produced by the mass media in Indonesia, a journalistic robot is needed to produce news content by the guidelines and the journalistic code of ethics. This research uses language modeling based on GPT-2 to generate articles. The program has four primary steps: building dataset, fine tuning GPT-2, modeling the trained data, and create articles. Furthermore, this research will add an Indonesian model for GPT-2 since the main purpose of this research is Indonesian articles. This paper proposes GPT-2 to be applied to news contents and calculate the result with BLEU scores to check if the results are readable content. These findings show that the proposed model is capable of generating a readable article after trained by 110 Indonesian articles with an excellent score of BLEU.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of naive bayes algorithm on IoT-based smart laundry mobile application system"
        ],
        "penulis":"Akbar, Ramadhan;Nasution, Surya Michrandi;Prasasti, Anggunmeka Luhur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Laundry is one of the services to facilitate the homework in washing clothes. Customers are given convenience, just by delivering the package and waiting for the finished clothes until the time specified by the laundry. As the time progresses, the processing of laundry becomes less practical because customers must visit the laundry place in advance when they want to wash their clothes. The benefit of this laundry application aims to help customers who have high mobility, especially in urban areas and not have much time to come to the laundry. This IoT-based laundry (Internet of Things) Android application is very helpful because customers receive notifications and don't need to process manually, clothes will be carried over automatically by the laundry officers, by applying the Na\u00efve Bayes algorithm which Measures the weight, distance, and moisture levels of the clothing ready to be taken by the laundry personnel, to determine which clothes will be processed first. If you want to see the progress of your clothes and payment transactions everything is enough on your smartphone, and for laundry parties is facilitated to take customer clothing, because there is already a list of customer names ready to be processed first.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Laundry is one of the services to facilitate the homework in washing clothes. Customers are given convenience, just by delivering the package and waiting for the finished clothes until the time specified by the laundry. As the time progresses, the processing of laundry becomes less practical because customers must visit the laundry place in advance when they want to wash their clothes. The benefit of this laundry application aims to help customers who have high mobility, especially in urban areas and not have much time to come to the laundry. This IoT-based laundry (Internet of Things) Android application is very helpful because customers receive notifications and don't need to process manually, clothes will be carried over automatically by the laundry officers, by applying the Na\u00efve Bayes algorithm which Measures the weight, distance, and moisture levels of the clothing ready to be taken by the laundry personnel, to determine which clothes will be processed first. If you want to see the progress of your clothes and payment transactions everything is enough on your smartphone, and for laundry parties is facilitated to take customer clothing, because there is already a list of customer names ready to be processed first.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Complete solutions of particle in three dimensional box with variations in main quantum number"
        ],
        "penulis":"Supriadi B.;Nuraini L.;Maulani A.S.R.;Damayanti D.D.;Sugihartin A.F.;Baihaqi M.I.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Particle in a box is one of the applications of the Schrodinger equation. Schrodinger equation gives wave function which is used to determine the probability and expectation value of particle in a box. It is also can explain the energy levels of the particle. This study aimed to determine the probability, expectation values, and energy levels of a particle in a three-dimensional box with variations in main quantum numbers in each coordinate axis. The magnitude of the wave function and energy levels are influenced by the main quantum number and the width of the box. The results show that variations in the main quantum number influence the probability of particle in the three-dimensional box except for the width of the box and L the probability of particle showing the same value in all variations of the main quantum number. Variations in the main quantum number also influence the expectation value of particle in a three-dimensional box except for the width of the box L the expectation value shows the same value in all variations of the main quantum number. All variations of the main quantum number also influence the magnitude of the energy level of the particle. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Particle in a box is one of the applications of the Schrodinger equation. Schrodinger equation gives wave function which is used to determine the probability and expectation value of particle in a box. It is also can explain the energy levels of the particle. This study aimed to determine the probability, expectation values, and energy levels of a particle in a three-dimensional box with variations in main quantum numbers in each coordinate axis. The magnitude of the wave function and energy levels are influenced by the main quantum number and the width of the box. The results show that variations in the main quantum number influence the probability of particle in the three-dimensional box except for the width of the box and L the probability of particle showing the same value in all variations of the main quantum number. Variations in the main quantum number also influence the expectation value of particle in a three-dimensional box except for the width of the box L the expectation value shows the same value in all variations of the main quantum number. All variations of the main quantum number also influence the magnitude of the energy level of the particle. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Increasing Residential Capacity in Gigabit-capable Passive Optical Network using High Splitting Ratio"
        ],
        "penulis":"Putri N.R.;Apriono, Catur;Natali Y.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, multimedia technology has led to broadband services such as the delivery of data, voice, and video or multiple-play services. PONs (Passive Optical Networks) gives these services worthwhile. Fiber to The Home (FTTH) with Gigabit-capable PON, is generally based on tree network topologies that use passive optical splitters. Splitting level for passive optical splitter can be employed in one or two levels in Optical Distribution Networks (ODNs) with the configuration of passive splitter 1:2, 1:4, 1:8, 1:16, 1:32, and 1:64. This paper discusses FTTH deployment using a high splitting ratio method by utilizing 1:8 passive splitters in each of the two levels in ODNs for residential areas. This high splitting ratio can increase the user capacity for the time ahead of user scaling. The proposed method is simulated by employing Optisystem software. The power link budget andbit error rate (BER) are considered as the G-PON eligibility standards in this paper. The received power and BER meet the eligibility standard set by ITU-T G.984.2, which is greater than -28 dBm, and not worse than 10-12 for broadband services, respectively. This method illustrates that the proposed configuration can be implemented in a rapid residential because every G-PON port can serve 64 users. It escalates 2560 users for every G-PON network, which is double the number of increasing users than the usual splitting method of 1: 4 and 1: 8. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, multimedia technology has led to broadband services such as the delivery of data, voice, and video or multiple-play services. PONs (Passive Optical Networks) gives these services worthwhile. Fiber to The Home (FTTH) with Gigabit-capable PON, is generally based on tree network topologies that use passive optical splitters. Splitting level for passive optical splitter can be employed in one or two levels in Optical Distribution Networks (ODNs) with the configuration of passive splitter 1:2, 1:4, 1:8, 1:16, 1:32, and 1:64. This paper discusses FTTH deployment using a high splitting ratio method by utilizing 1:8 passive splitters in each of the two levels in ODNs for residential areas. This high splitting ratio can increase the user capacity for the time ahead of user scaling. The proposed method is simulated by employing Optisystem software. The power link budget andbit error rate (BER) are considered as the G-PON eligibility standards in this paper. The received power and BER meet the eligibility standard set by ITU-T G.984.2, which is greater than -28 dBm, and not worse than 10-12 for broadband services, respectively. This method illustrates that the proposed configuration can be implemented in a rapid residential because every G-PON port can serve 64 users. It escalates 2560 users for every G-PON network, which is double the number of increasing users than the usual splitting method of 1: 4 and 1: 8. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Range expansion method on heterogeneous network to increase picocell coverage"
        ],
        "penulis":"Supriadi, Hadi;Putri, Hasanah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this study, picocell planning was carried out on heterogeneous networks by applying the range expansion method. The case study was conducted in Coblong Subdistrict-Bandung on the 1800 MHz frequency. Heterogeneous network (HetNet) is a system that combines microcell networks and small cell networks (picocell and femtocell). The application of the range expansion method in picocell was aimed to broaden the scope of picocell. For the simulation, Atoll 3.3.0 software with observational parameters was implemented, including RSRP, SINR, throughput, and user connected. The planning results showed that the application of expansion method increased the coverage and quality of network, where the RSRP value \u2265 -90 dBm was 97.72%, SINR \u2265 5 dB was 70.99%, uplink throughput was 17.80 Mbps, downlink throughput was 21.37 Mbps, and user connected was 99.2%. \u00a9 2020, Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this study, picocell planning was carried out on heterogeneous networks by applying the range expansion method. The case study was conducted in Coblong Subdistrict-Bandung on the 1800 MHz frequency. Heterogeneous network (HetNet) is a system that combines microcell networks and small cell networks (picocell and femtocell). The application of the range expansion method in picocell was aimed to broaden the scope of picocell. For the simulation, Atoll 3.3.0 software with observational parameters was implemented, including RSRP, SINR, throughput, and user connected. The planning results showed that the application of expansion method increased the coverage and quality of network, where the RSRP value \u2265 -90 dBm was 97.72%, SINR \u2265 5 dB was 70.99%, uplink throughput was 17.80 Mbps, downlink throughput was 21.37 Mbps, and user connected was 99.2%. \u00a9 2020, Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Using LSTM for Context Based Approach of Sarcasm Detection in Twitter"
        ],
        "penulis":"Khotijah, Siti;Tirtawangsa, Jimmy;Suryani, Arie A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this research, we propose a sarcasm detection by taking into consideration its many varying contexts, related to the word or phrase in a tweet. To get the related context, we extract the information with paragraph2vec to simplify the process of finding the contextual meaning. The result paragraph2vec will provide the features to help classification in Long Short Term Memory (LSTM). Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. We applied a sarcasm detection method to identify sarcasm in two different languages: English and Indonesian and classification with balanced and imbalanced data. It aims to measure the reliability of the proposed approach and how effective the method is in detecting sarcasm. The result of the experiment shows that in Indonesian, balanced data has a good accuracy of 88.33 % and imbalanced data of 76.66 %, whereas in English the balanced data has an accuracy of 79% and imbalanced data of 54.5%. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this research, we propose a sarcasm detection by taking into consideration its many varying contexts, related to the word or phrase in a tweet. To get the related context, we extract the information with paragraph2vec to simplify the process of finding the contextual meaning. The result paragraph2vec will provide the features to help classification in Long Short Term Memory (LSTM). Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. We applied a sarcasm detection method to identify sarcasm in two different languages: English and Indonesian and classification with balanced and imbalanced data. It aims to measure the reliability of the proposed approach and how effective the method is in detecting sarcasm. The result of the experiment shows that in Indonesian, balanced data has a good accuracy of 88.33 % and imbalanced data of 76.66 %, whereas in English the balanced data has an accuracy of 79% and imbalanced data of 54.5%. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Identification of upwelling area of the western territorial waters of Indonesia from 2000 to 2017"
        ],
        "penulis":"Supriyadi, Eko;Hidayat, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The Western Waters of Indonesian (WWI) present a diverse interaction of ocean-atmosphere dynamics. One of them represents the event of Indian Ocean Dipole (IOD), El Nino-Southern Oscillation (ENSO), and upwelling. The objective of this study is to determine the dynamics of chlorophyll-a concentration (Chl-a), especially during IOD and ENSO. Also, this study is aimed to examine the temporal and spatial distribution of the upwelling area from 2000 to 2017. The data utilized consisted of Chl-a, wind stress, Sea Level Anomaly (SLA), and Sea Surface Temperature (SST). The technique used to determine the upwelling area was by examining the maximum conditions of Chl-a, the low temperature of SST, and SLA. The results showed the sea surface temperature had a relationship with the concentration of Chl-a. It was obtained if the Directional Movement Index (DMI) and N3.4 (Nino 3.4 Index) moved stably (not too fluctuation) resulting in high concentrations of Chl-a. High standard deviations of SST are recognized around the Sunda Strait (June - October). When the standard deviation of SST is high, there is also a tendency for high Chl-a concentrations, while the results of empirical calculations show that large areas of upwelling occurred in January and September respectively at 12,447.72 km2and 8,146.20 km2. Based on the results of the analysis, it can be concluded that the upwelling does not only occur at the coastal area of Western Sumatra (coastal upwelling), but it also occurs in the eastern territorial waters of the Indian Ocean. In addition, the upwelling area has the same pattern as the Chl-a concentration in January - October. \u00a9 2020 by the authors. Licensee Indonesian Journal of Geography, Indonesia",
            "NNOOOCH3H3CCH3NOONH3CCH3CH3CH2CH3CH3CH3H3CCH3MgView detailsExpand Substance chlorophyll a",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Western Waters of Indonesian (WWI) present a diverse interaction of ocean-atmosphere dynamics. One of them represents the event of Indian Ocean Dipole (IOD), El Nino-Southern Oscillation (ENSO), and upwelling. The objective of this study is to determine the dynamics of chlorophyll-a concentration (Chl-a), especially during IOD and ENSO. Also, this study is aimed to examine the temporal and spatial distribution of the upwelling area from 2000 to 2017. The data utilized consisted of Chl-a, wind stress, Sea Level Anomaly (SLA), and Sea Surface Temperature (SST). The technique used to determine the upwelling area was by examining the maximum conditions of Chl-a, the low temperature of SST, and SLA. The results showed the sea surface temperature had a relationship with the concentration of Chl-a. It was obtained if the Directional Movement Index (DMI) and N3.4 (Nino 3.4 Index) moved stably (not too fluctuation) resulting in high concentrations of Chl-a. High standard deviations of SST are recognized around the Sunda Strait (June - October). When the standard deviation of SST is high, there is also a tendency for high Chl-a concentrations, while the results of empirical calculations show that large areas of upwelling occurred in January and September respectively at 12,447.72 km2and 8,146.20 km2. Based on the results of the analysis, it can be concluded that the upwelling does not only occur at the coastal area of Western Sumatra (coastal upwelling), but it also occurs in the eastern territorial waters of the Indian Ocean. In addition, the upwelling area has the same pattern as the Chl-a concentration in January - October. \u00a9 2020 by the authors. Licensee Indonesian Journal of Geography, Indonesia"
        ]
    },
    {
        "judul":[
            "Consumer Trust to Buy Green Product: Investigation of Green Perceived Value with Green Satisfaction Mediation"
        ],
        "penulis":"Lutfie, Harrie;Marcelino, Dandy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The current level of human awareness of the environment began to grow since the emergence of negative environmental issues like global warming. Global warming causes consumers to be more interested in buying products from companies that care about the environment. One form of consumer concern today is the emergence of green lifestyle trends. Green lifestyle is currently being widely adopted by the community as natural damage caused by that community as well. Consumers who have an environmental concern will make changes by buying products that are proven to be environmentally friendly. This study aims to determine whether the green marketing strategy implemented by Starbucks runs effectively and to find out the role of Green Perceived Value towards Green Trust mediated by Green Satisfaction on Starbucks Bandung consumers. The analysis method employed in this research is quantitative with causal type research, as well as data analysis techniques using path analysis which is divided into two substructures. The results showed the Green Perceived Value and Green Satisfaction variables had a positive and significant effect on the Green Trust variables simultaneously. The total effect of the independent variables studied is equal to 68.68% and the rest 31.32% is influenced by other variables or factors not examined that could increase Green Trust. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The current level of human awareness of the environment began to grow since the emergence of negative environmental issues like global warming. Global warming causes consumers to be more interested in buying products from companies that care about the environment. One form of consumer concern today is the emergence of green lifestyle trends. Green lifestyle is currently being widely adopted by the community as natural damage caused by that community as well. Consumers who have an environmental concern will make changes by buying products that are proven to be environmentally friendly. This study aims to determine whether the green marketing strategy implemented by Starbucks runs effectively and to find out the role of Green Perceived Value towards Green Trust mediated by Green Satisfaction on Starbucks Bandung consumers. The analysis method employed in this research is quantitative with causal type research, as well as data analysis techniques using path analysis which is divided into two substructures. The results showed the Green Perceived Value and Green Satisfaction variables had a positive and significant effect on the Green Trust variables simultaneously. The total effect of the independent variables studied is equal to 68.68% and the rest 31.32% is influenced by other variables or factors not examined that could increase Green Trust. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Synonyms-Based Augmentation to Improve Fake News Detection using Bidirectional LSTM"
        ],
        "penulis":"Ghinadya;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Fake news is the news which contains propaganda and not relevant to the actual news. Today, the news in social media are troubling internet user. Hence, a fake news detector is needed to solve the problem. In this research, a fake news detector system based on Recurrent Neural Network (RNN) is developed. The architecture is designed using Bidirectional Long Short-Term Memories (Bi-LSTM) with exploit stance detection for the headline and the body of the news. Evaluation on 50 k news articles from FNC-1 shows that the proposed method produces F1-score of 0.2423 in detecting the fake news.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Fake news is the news which contains propaganda and not relevant to the actual news. Today, the news in social media are troubling internet user. Hence, a fake news detector is needed to solve the problem. In this research, a fake news detector system based on Recurrent Neural Network (RNN) is developed. The architecture is designed using Bidirectional Long Short-Term Memories (Bi-LSTM) with exploit stance detection for the headline and the body of the news. Evaluation on 50 k news articles from FNC-1 shows that the proposed method produces F1-score of 0.2423 in detecting the fake news.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "5G Channel Model for 28 GHz frequency in Palembang"
        ],
        "penulis":"Alfaresi B.;Nawawi Z.;Malik R.F.;Anwar K.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Next generation wireless technology require a wide frequency band. Current technology use a frequency of below 3 GHz which cannot provide a wide frequency band due to quite dense frequency utilization. The mm-Wave frequency guarantee to provide a wide band frequency band. The use of mm-Wave frequency will be influenced by climate factors. The characteristics of a place will cause a different channel model. Channel Model is useful for minimizes errors and maximizes information transmission or bitrate in communication model. The Channel Model will be represented as a PDP (Power Delay Profile). Channel model performance uses the Outage performance parameter in Shannon Theorem Implementation. Validation results using the CP-OFDM system with 5G BPSK. The parameters used for validation are FER and BER. In this paper, channel models will be analysed based on the characteristic of Palembang area as a reference channel model in Outer of Indonesia. Hopefully, it can be used as a reference for the development 5G wireless system. \u00a9 2020 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Next generation wireless technology require a wide frequency band. Current technology use a frequency of below 3 GHz which cannot provide a wide frequency band due to quite dense frequency utilization. The mm-Wave frequency guarantee to provide a wide band frequency band. The use of mm-Wave frequency will be influenced by climate factors. The characteristics of a place will cause a different channel model. Channel Model is useful for minimizes errors and maximizes information transmission or bitrate in communication model. The Channel Model will be represented as a PDP (Power Delay Profile). Channel model performance uses the Outage performance parameter in Shannon Theorem Implementation. Validation results using the CP-OFDM system with 5G BPSK. The parameters used for validation are FER and BER. In this paper, channel models will be analysed based on the characteristic of Palembang area as a reference channel model in Outer of Indonesia. Hopefully, it can be used as a reference for the development 5G wireless system. \u00a9 2020 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Numerical Simulation of Wave Runup and Overtopping for Short and Long Waves Using Staggered Grid Variational Boussinesq"
        ],
        "penulis":"Adytia, Didit;Pudjaprasetya, Sri Redjeki;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In designing a numerical tool for simulating a wide variety of water waves, i.e. short to long waves, an accurate and robust wave model and numerical implementation are needed. Dispersion and nonlinearity are the two most important physical aspects that should be modeled accurately. To be applicable to simulate many coastal engineering applications, the numerical scheme should be capable of simulating wave runup and overtopping. In this paper, we extend the capability of a Boussinesq-type model called Variational Boussinesq (VB) model for simulating the runup and overtopping of water waves. To that end, the vertical layer of the \u00b0uid is modeled continuously by a linear combination of three functions. If two of these three functions have been incorporated in the previous numerical approximation called the SVB model, this paper discusses the improvement of SVB model by incorporating all the three functions. This approach improve the dispersive property of the SVB model due to its ability to simulate short waves up to kd = 20, compared to the previous model which was only up to kd = 7, where k denotes wave number and d water depth. Furthermore, the model is implemented numerically by using the staggered conservative scheme. In the new implementation, the model is switched to the non-dispersive Shallow Water Equations (SWE) when dealing with a dry area for runup and overtopping phenomena. The new implementation is tested against analytical solutions of soliton propagation and standing wave phenomenon; moreover, it is also tested against experimental data from hydrodynamic laboratories for simulating solitary wave breaking above a sloping bottom, composite beach, and in a structure for simulating overtopping phenomenon. The implementation is also tested against experimental data for simulating irregular wave propagation and runup above a fringing reef. The results of numerical simulation agree quite well with experimental data.  \u00a9 World Scientific Publishing Company.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In designing a numerical tool for simulating a wide variety of water waves, i.e. short to long waves, an accurate and robust wave model and numerical implementation are needed. Dispersion and nonlinearity are the two most important physical aspects that should be modeled accurately. To be applicable to simulate many coastal engineering applications, the numerical scheme should be capable of simulating wave runup and overtopping. In this paper, we extend the capability of a Boussinesq-type model called Variational Boussinesq (VB) model for simulating the runup and overtopping of water waves. To that end, the vertical layer of the \u00b0uid is modeled continuously by a linear combination of three functions. If two of these three functions have been incorporated in the previous numerical approximation called the SVB model, this paper discusses the improvement of SVB model by incorporating all the three functions. This approach improve the dispersive property of the SVB model due to its ability to simulate short waves up to kd = 20, compared to the previous model which was only up to kd = 7, where k denotes wave number and d water depth. Furthermore, the model is implemented numerically by using the staggered conservative scheme. In the new implementation, the model is switched to the non-dispersive Shallow Water Equations (SWE) when dealing with a dry area for runup and overtopping phenomena. The new implementation is tested against analytical solutions of soliton propagation and standing wave phenomenon; moreover, it is also tested against experimental data from hydrodynamic laboratories for simulating solitary wave breaking above a sloping bottom, composite beach, and in a structure for simulating overtopping phenomenon. The implementation is also tested against experimental data for simulating irregular wave propagation and runup above a fringing reef. The results of numerical simulation agree quite well with experimental data.  \u00a9 World Scientific Publishing Company."
        ]
    },
    {
        "judul":[
            "Integration the 6th category Business Excellence Framework, the 8th clause ISO 9001:2015 and the 6th category KPKU Indonesia Framework"
        ],
        "penulis":"Widaningrum, Sri;Mohammad, Musli;Ibrahim, Rasidi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "KPKU (Kriteria Penilaian Kinerja Unggul) Indonesia framework 2015 adopted Business Excellence Framework 2013-2014, that is a framework used by the \u201cMinistry of State-Owned Enterprises\u201d of the Republic of Indonesia to assess the performance of SOEs in Indonesia. One of the KPKU criteria is the operation, that is the most dominant criteria in company performance. They are proven by the score in Baldrige Excellence Framework (110 point is the highest score) for product and process results which are influenced by operational criteria in the 6th category of BEF. Currently, Indonesia does not have yet business excellence framework based on companies in Indonesia and does not have yet Indonesia operational excellence model, either in Indonesia or based on previous research. Currently, there is no model that integrates (Baldrige Excellence Framework, ISO 9001: 2015, and KPKU). This research will develop the Indonesia operational excellence model based on the Baldrige Excellence Framework, ISO 9001:2015, and KPKU Indonesia framework. Stage of the research is the literature survey, identifying the 6th Category Baldrige Excellence Framework; KPKU and the 8th Clause ISO 9001:2015, and integration the 6th KPKU framework and the 8th Clause ISO 9001:2015 to the 6th Category Baldrige Excellence framework. The results of the study are the Indonesian operational excellence framework that consists of 5 criteria and 14 sub-criteria, namely Product and Process Design, Process Management, Process Efficiency and Effectiveness, Process Improvement, and Safety and Emergency Preparedness. This model is appropriate for company performance measurement, especially operational performance. \u00a9 2020 Universiti Tun Hussein Onn Malaysia Publisher's Office. All Rights Reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "KPKU (Kriteria Penilaian Kinerja Unggul) Indonesia framework 2015 adopted Business Excellence Framework 2013-2014, that is a framework used by the \u201cMinistry of State-Owned Enterprises\u201d of the Republic of Indonesia to assess the performance of SOEs in Indonesia. One of the KPKU criteria is the operation, that is the most dominant criteria in company performance. They are proven by the score in Baldrige Excellence Framework (110 point is the highest score) for product and process results which are influenced by operational criteria in the 6th category of BEF. Currently, Indonesia does not have yet business excellence framework based on companies in Indonesia and does not have yet Indonesia operational excellence model, either in Indonesia or based on previous research. Currently, there is no model that integrates (Baldrige Excellence Framework, ISO 9001: 2015, and KPKU). This research will develop the Indonesia operational excellence model based on the Baldrige Excellence Framework, ISO 9001:2015, and KPKU Indonesia framework. Stage of the research is the literature survey, identifying the 6th Category Baldrige Excellence Framework; KPKU and the 8th Clause ISO 9001:2015, and integration the 6th KPKU framework and the 8th Clause ISO 9001:2015 to the 6th Category Baldrige Excellence framework. The results of the study are the Indonesian operational excellence framework that consists of 5 criteria and 14 sub-criteria, namely Product and Process Design, Process Management, Process Efficiency and Effectiveness, Process Improvement, and Safety and Emergency Preparedness. This model is appropriate for company performance measurement, especially operational performance. \u00a9 2020 Universiti Tun Hussein Onn Malaysia Publisher's Office. All Rights Reserved."
        ]
    },
    {
        "judul":[
            "Modified FMCW system for non-contact sensing of human respiration"
        ],
        "penulis":"Pramudita, Aloysius Adya;Suratman, Fiky Y.;Arseno, Dharu;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Small displacement detection capability becomes an important key for developing non-contact sensor for human respiration based on radar system. Frequency modulated continuous wave (FMCW) radar has been widely studied and applied for many applications. With respect to the conventional perspective, large bandwidth is needed for detecting the small displacement related to the human respiration. Meanwhile, extracting the respiration pattern from Doppler response has a drawback in identifying the small displacement location. In this paper, the modification on FMCW system was proposed for obtaining the capability in detecting the human respiration and its distance from the radar. Detecting the phase value of the low pass filter (LPF), output from conventional FMCW was investigated and applied as a modification concept. The pattern, rate and amplitude of respiration are extracted from phase detector output. Beat frequency detection is still elaborated for synthesising the reference signal for phase detection. The result shows that the modified FMCW system proposed the capability of detecting the rate and amplitude respiration and location of the target. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Small displacement detection capability becomes an important key for developing non-contact sensor for human respiration based on radar system. Frequency modulated continuous wave (FMCW) radar has been widely studied and applied for many applications. With respect to the conventional perspective, large bandwidth is needed for detecting the small displacement related to the human respiration. Meanwhile, extracting the respiration pattern from Doppler response has a drawback in identifying the small displacement location. In this paper, the modification on FMCW system was proposed for obtaining the capability in detecting the human respiration and its distance from the radar. Detecting the phase value of the low pass filter (LPF), output from conventional FMCW was investigated and applied as a modification concept. The pattern, rate and amplitude of respiration are extracted from phase detector output. Beat frequency detection is still elaborated for synthesising the reference signal for phase detection. The result shows that the modified FMCW system proposed the capability of detecting the rate and amplitude respiration and location of the target. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group."
        ]
    },
    {
        "judul":[
            "A Proposed user requirements document for children's learning application"
        ],
        "penulis":"Sabariah, Mira Kania;Santosa, Paulus Insap;Ferdiana, Ridi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "User requirements are the highest level of requirements. Flawed user requirements document can cause defects in the software being built-aspects of applications that were not presented in the user requirements document to cause a defect. In learning applications for children, there are aspects of pedagogy that need to be well documented. This aspect is not available in the general user requirements document, so it is often not well presented. The learning style and thinking skills level is crucial to be well presented in the user requirements document. That was because the children's persona cannot be compared at every range criteria of developmental age. That factor will undoubtedly affect the specifications of the software to be built. Users' viewpoints about different requirements can also make developers wrong in determining requirements. Applying requirements prioritization in the user requirements document can help resolve the problem. Measurement of document quality was also performed using parameters in measuring the quality of the user requirements document. The results of measuring the quality of the user requirements document found that it is reliable for use. \u00a9 2020, Science and Information Organization.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "User requirements are the highest level of requirements. Flawed user requirements document can cause defects in the software being built-aspects of applications that were not presented in the user requirements document to cause a defect. In learning applications for children, there are aspects of pedagogy that need to be well documented. This aspect is not available in the general user requirements document, so it is often not well presented. The learning style and thinking skills level is crucial to be well presented in the user requirements document. That was because the children's persona cannot be compared at every range criteria of developmental age. That factor will undoubtedly affect the specifications of the software to be built. Users' viewpoints about different requirements can also make developers wrong in determining requirements. Applying requirements prioritization in the user requirements document can help resolve the problem. Measurement of document quality was also performed using parameters in measuring the quality of the user requirements document. The results of measuring the quality of the user requirements document found that it is reliable for use. \u00a9 2020, Science and Information Organization."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Investigating Facebook Advertising Feature through Performance Expectancy on Customer Purchase Intention"
        ],
        "penulis":"Lutfie, Harrie;Marcelino, Dandy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Over time, many Facebook users use Facebook not only for sharing photos but also used as a means for advertising and promoting. Promotion in the form of advertising on social media is believed to be more effective because it does not require much time, cost, and effort for the company, and makes it easy for consumers to find out information. Facebook ads or paid advertisements from Facebook are features offered by Facebook to promote or advertise a business product or service with different reach and can be arranged by the advertiser. Ads from Facebook can reach more people than just posting both fan pages and personal accounts. The aims of this research are to determine the influence of hedonic motivation, interactivity, informativeness, and perceived relevance of consumer purchase intentions through performance expectancy on advertising on Facebook's social media. The research method used is quantitative with SEM (Structural Equation Model) analysis technique. The results showed that hedonic motivation, interactivity, informativeness, and perceived relevance have a direct effect to purchase intention and indirect effect through performance expectancy. There were empirical findings on this study that hedonic motivation and perceived relevance built higher influence to purchase intention than other variables. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Over time, many Facebook users use Facebook not only for sharing photos but also used as a means for advertising and promoting. Promotion in the form of advertising on social media is believed to be more effective because it does not require much time, cost, and effort for the company, and makes it easy for consumers to find out information. Facebook ads or paid advertisements from Facebook are features offered by Facebook to promote or advertise a business product or service with different reach and can be arranged by the advertiser. Ads from Facebook can reach more people than just posting both fan pages and personal accounts. The aims of this research are to determine the influence of hedonic motivation, interactivity, informativeness, and perceived relevance of consumer purchase intentions through performance expectancy on advertising on Facebook's social media. The research method used is quantitative with SEM (Structural Equation Model) analysis technique. The results showed that hedonic motivation, interactivity, informativeness, and perceived relevance have a direct effect to purchase intention and indirect effect through performance expectancy. There were empirical findings on this study that hedonic motivation and perceived relevance built higher influence to purchase intention than other variables. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Public perception on transparency and trust in government information released during the COVID-19 pandemic"
        ],
        "penulis":"Pramiyanti, Alila;Mayangsari, Ira Dwi;Nuraeni, Reni;Firdaus, Yasinta Darin;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A low level of transparency and trust in the release of government information during the COVID-19 pandemic could decrease the chance of success in handling the coronavirus outbreak. This worldwide pandemic has damaged not only human health but also created an economic and social crisis. Indonesia is no exception. Unfortunately, an analysis of a mixed-method survey of 500 participants found that public perception of transparency in the government\u2019s release of COVID-19 information is still at a low level. This perceived low level of transparency generates minimum trust in the information. Only 8% of participants trust the government\u2019s information regarding the virus. Even though the Indonesian government launched an official website, www.covid19.go.id, which is intended as a primary source of valid information about COVID-19 in Indonesia, most survey participants had never used the website. However, contrary to the low levels of perceived transparency and trust, most participants said that the messages from the government are clear and easy to understand. This contradiction resulted from skepticism toward the government. Therefore, this research presents a better understanding of how the level of transparency and trust is also related to the level of skepticism of the government. \u00a9 2020, Center for Asian Public Opinion Research and Collaboration Initiative. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Peace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A low level of transparency and trust in the release of government information during the COVID-19 pandemic could decrease the chance of success in handling the coronavirus outbreak. This worldwide pandemic has damaged not only human health but also created an economic and social crisis. Indonesia is no exception. Unfortunately, an analysis of a mixed-method survey of 500 participants found that public perception of transparency in the government\u2019s release of COVID-19 information is still at a low level. This perceived low level of transparency generates minimum trust in the information. Only 8% of participants trust the government\u2019s information regarding the virus. Even though the Indonesian government launched an official website, www.covid19.go.id, which is intended as a primary source of valid information about COVID-19 in Indonesia, most survey participants had never used the website. However, contrary to the low levels of perceived transparency and trust, most participants said that the messages from the government are clear and easy to understand. This contradiction resulted from skepticism toward the government. Therefore, this research presents a better understanding of how the level of transparency and trust is also related to the level of skepticism of the government. \u00a9 2020, Center for Asian Public Opinion Research and Collaboration Initiative. All rights reserved."
        ]
    },
    {
        "judul":[
            "Two factor authentication framework based on ethereum blockchain with dapp as token generation system instead of third-party on web application"
        ],
        "penulis":"Putri, Marsha Chikita Intania;Sukarno, Parman;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Authentication is a method for securing an account by verifying the user identity by inputting email with a password. Two factor authentications is an authentication system that combines the first-factor authentication with the second factor. General two factor authentication by entering an email or username with a password are similar. However, two factor authentication requires additional information that must be inputted by the user. Additional information can be in the form of tokens or one-time passwords (OTP). Two factor authentications generally still uses third-party services to generate token or OTP still have vulnerable because can attacked from tokens steal through MITM and found that the generated tokens with the same value. Therefore, we propose a two-factor authentication framework based on ethereum blockchain with dApp as token generation system. Firstly, outcome from the analysis of the system, next succeeded in creating a two-factor authentication system without using third-parties. Second, token system generate up to 3164 different tokens in one second and has been collisions tested. Third, security method to protect token from MITM attack. The attacker unable to get access caused all the checking are done by dApp user authentication. \u00a9 2020, Universitas Pesantren Tinggi Darul Ulum. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Authentication is a method for securing an account by verifying the user identity by inputting email with a password. Two factor authentications is an authentication system that combines the first-factor authentication with the second factor. General two factor authentication by entering an email or username with a password are similar. However, two factor authentication requires additional information that must be inputted by the user. Additional information can be in the form of tokens or one-time passwords (OTP). Two factor authentications generally still uses third-party services to generate token or OTP still have vulnerable because can attacked from tokens steal through MITM and found that the generated tokens with the same value. Therefore, we propose a two-factor authentication framework based on ethereum blockchain with dApp as token generation system. Firstly, outcome from the analysis of the system, next succeeded in creating a two-factor authentication system without using third-parties. Second, token system generate up to 3164 different tokens in one second and has been collisions tested. Third, security method to protect token from MITM attack. The attacker unable to get access caused all the checking are done by dApp user authentication. \u00a9 2020, Universitas Pesantren Tinggi Darul Ulum. All rights reserved."
        ]
    },
    {
        "judul":[
            "A fast scheduling method to solve economic load dispatch problem"
        ],
        "penulis":"Wachjoe, Conny K.;Zein, Hermagasantos;Raharjo, Jangkung;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Optimal scheduling of the generating units in one hour ahead considerably affects the electricity cost because the fuel cost component will bring up the economic load dispatch problem. Fuel cost is an essential parameter to calculate the optimal cost function of the power systems subject to the operating constraints and transmission loss. Generally, the economic load dispatch problem is resolved through the iteration step and using many variables so that it uses long computation time. The accuracy can also be low because the point of the solution can fall near the minimum local point. This paper proposes a method to provide better efficiency and accuracy of the economic load dispatch problem. The methodology forms a fuel cost function in the quadratic equation mathematically derived in order to obtain a faster solution without iteration processes. The B-loss matrix determines the transmission loss after receiving the optimal solution without considering transmission losses. The method validation simulates the economic load dispatch for the 26-Bus power system and the 6-generating units. After comparing with the Genetic Algorithm, the proposed method can save fuel costs significantly of about $ 29876.46 in 24 hours, while computing time in executing the application program is short enough, namely 0.15 seconds. Copyright \u00a9 2020 Praise Worthy Prize S.r.l.-All rights reserved. \u00a9 2020 Praise Worthy Prize S.r.l.-All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Optimal scheduling of the generating units in one hour ahead considerably affects the electricity cost because the fuel cost component will bring up the economic load dispatch problem. Fuel cost is an essential parameter to calculate the optimal cost function of the power systems subject to the operating constraints and transmission loss. Generally, the economic load dispatch problem is resolved through the iteration step and using many variables so that it uses long computation time. The accuracy can also be low because the point of the solution can fall near the minimum local point. This paper proposes a method to provide better efficiency and accuracy of the economic load dispatch problem. The methodology forms a fuel cost function in the quadratic equation mathematically derived in order to obtain a faster solution without iteration processes. The B-loss matrix determines the transmission loss after receiving the optimal solution without considering transmission losses. The method validation simulates the economic load dispatch for the 26-Bus power system and the 6-generating units. After comparing with the Genetic Algorithm, the proposed method can save fuel costs significantly of about $ 29876.46 in 24 hours, while computing time in executing the application program is short enough, namely 0.15 seconds. Copyright \u00a9 2020 Praise Worthy Prize S.r.l.-All rights reserved. \u00a9 2020 Praise Worthy Prize S.r.l.-All rights reserved."
        ]
    },
    {
        "judul":[
            "Design and investigate of flushing system for electrical discharge machining (EDM) application"
        ],
        "penulis":"Rachmat, Haris;Ibrahim, Rasidi;Ming, Kee Hem;Ismail, Al Emran;Rahim, Zulafif;Swangsari, Worapong;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Electrical Discharge Machining (EDM) is high precision machining process in which no actual contact between the workpiece and electrode during sparking. Dielectric fluid play a role as flushing medium and semiconductor between workpiece and electrode to stabilization and controlled spark gap ionization condition. In real condition, nozzle flushing system in EDM machine not able to complete remove debris formed during machining and affect the machining performance. Improper flushing due to lack of guideline at setup position of nozzle and inlet pressure caused low material removal rate, irregular tool and higher cost on raw material. To overcome this problem, the design and investigate of flushing system in EDM application is required. The design and investigation undergo by simulation of ANSYS Computational Fluid Dynamics (CFD) with a virtual experiment to accurate prediction of flushing performance. The influence of nozzle size and inlet pressure supplied on flushing efficiency were analyzed to avoid improper flushing on die-sinking EDM process. The simulation and experiments clarified that the higher inlet pressure, P=0.20 bar and larger nozzle diameter, D=6mm resulting in higher total pressure which is 2647.16 Pa. Furthermore, the streamline of velocity and eddy viscosity contour in the work tank using to analyze the turbulence zone by nozzle flushing obtained by the CFD analysis. The condition in case 5 (D=5mm, P=0.15 bar) is more efficiency on debris removal rate based on the result of high total pressure on machining zone and eddy viscosity contour showed the turbulence zone only formed area near to outlet of system. The model results have been shown good agreement with experiment and co-relation data. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electrical Discharge Machining (EDM) is high precision machining process in which no actual contact between the workpiece and electrode during sparking. Dielectric fluid play a role as flushing medium and semiconductor between workpiece and electrode to stabilization and controlled spark gap ionization condition. In real condition, nozzle flushing system in EDM machine not able to complete remove debris formed during machining and affect the machining performance. Improper flushing due to lack of guideline at setup position of nozzle and inlet pressure caused low material removal rate, irregular tool and higher cost on raw material. To overcome this problem, the design and investigate of flushing system in EDM application is required. The design and investigation undergo by simulation of ANSYS Computational Fluid Dynamics (CFD) with a virtual experiment to accurate prediction of flushing performance. The influence of nozzle size and inlet pressure supplied on flushing efficiency were analyzed to avoid improper flushing on die-sinking EDM process. The simulation and experiments clarified that the higher inlet pressure, P=0.20 bar and larger nozzle diameter, D=6mm resulting in higher total pressure which is 2647.16 Pa. Furthermore, the streamline of velocity and eddy viscosity contour in the work tank using to analyze the turbulence zone by nozzle flushing obtained by the CFD analysis. The condition in case 5 (D=5mm, P=0.15 bar) is more efficiency on debris removal rate based on the result of high total pressure on machining zone and eddy viscosity contour showed the turbulence zone only formed area near to outlet of system. The model results have been shown good agreement with experiment and co-relation data. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office."
        ]
    },
    {
        "judul":[
            "Green supply chain, green communication and firm performance: Empirical evidence from Thailand"
        ],
        "penulis":"Candrasa, Limega;Cen, Cia Cai;Cahyadi, Willy;Cahyadi, Lukieto;Pratama, Ikbar;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Present study investigates the mediating role of green communication (GRC) on the relationship between green supply chain (GRSC) and firm performance (FP). Study uses three different dimensions of GRSC such as green purchasing (GRPU), green manufacturing (GRM), green packing (GRPK), and green distribution (GRD). For this purpose, study collects the data from 429 employees of three polluting industries i.e., automobile, chemical and manufacturing industries of Thailand. Study applies partial least square structural equational modeling (PLS_SEM) for examining the empirical results. Study used measurement model for testing the reliability and validity of the data. Structural model is used for testing the hypothesized relationship of variables. Results of the study shows the positive impact of GRPU, GRM, GRPK and GRD on FP. Study further shows GRC significantly mediates the relationship between GRPU & FP, GRM & FP, and GRD & FP. Results of the study suggest that manager of the firm should provide the incentive to the employees who adapt GRSC practices. \u00a9 2020 EManuscript Technologies. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Present study investigates the mediating role of green communication (GRC) on the relationship between green supply chain (GRSC) and firm performance (FP). Study uses three different dimensions of GRSC such as green purchasing (GRPU), green manufacturing (GRM), green packing (GRPK), and green distribution (GRD). For this purpose, study collects the data from 429 employees of three polluting industries i.e., automobile, chemical and manufacturing industries of Thailand. Study applies partial least square structural equational modeling (PLS_SEM) for examining the empirical results. Study used measurement model for testing the reliability and validity of the data. Structural model is used for testing the hypothesized relationship of variables. Results of the study shows the positive impact of GRPU, GRM, GRPK and GRD on FP. Study further shows GRC significantly mediates the relationship between GRPU & FP, GRM & FP, and GRD & FP. Results of the study suggest that manager of the firm should provide the incentive to the employees who adapt GRSC practices. \u00a9 2020 EManuscript Technologies. All rights reserved."
        ]
    },
    {
        "judul":[
            "Supervised Artificial Neural Network approach for Tsunami Inversion: A Case Study from 2018 Gunung Anak Krakatau"
        ],
        "penulis":"Abdurrahman, Nunun;Adytia, Didit;Subasita, Nugrahinggil;Adiwijaya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The eruption of Gunung Anak Krakatau (GAK) in 2018 caused a flank failure which resulted in a tsunami that affecting the coast of Western Java and Southern Sumatra. However, the location and mechanism of the landslide are still unclear. In this study, the location of the avalanche point, and the initial shape of the tsunami will be predicted by using a tsunami inversion via sof t computing approach. The inversion utilized the measured signals from four buoy stations in the Sunda Strait. To that aim, a soft computing approach Artificial Neural Network (ANN) is used for the inversion. Training data for the ANN model are obtained by performing several scenarios of tsunami numerical simulations. The numerical simulations are simulated by using SWASH model. Ten shapes of initial conditions are simulated for every 2 hours of simulation with the aim to obtain signals at four buoy locations. These four measured signals are then used for the inversion. The result of inversion shows a promising result with the accuracy of R value of 0.96.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The eruption of Gunung Anak Krakatau (GAK) in 2018 caused a flank failure which resulted in a tsunami that affecting the coast of Western Java and Southern Sumatra. However, the location and mechanism of the landslide are still unclear. In this study, the location of the avalanche point, and the initial shape of the tsunami will be predicted by using a tsunami inversion via sof t computing approach. The inversion utilized the measured signals from four buoy stations in the Sunda Strait. To that aim, a soft computing approach Artificial Neural Network (ANN) is used for the inversion. Training data for the ANN model are obtained by performing several scenarios of tsunami numerical simulations. The numerical simulations are simulated by using SWASH model. Ten shapes of initial conditions are simulated for every 2 hours of simulation with the aim to obtain signals at four buoy locations. These four measured signals are then used for the inversion. The result of inversion shows a promising result with the accuracy of R value of 0.96.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "IoT-based weather station with python user interface for measurement technique ofeducational purpose"
        ],
        "penulis":"Iswanto;Megantoro, Prisma;Pramudita, Brahmantya Aji;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A measurement of physical quantities requires the right technique to do it. This is done to obtain the characteristics of the system and an accurate measuring sensor. With accurate measurements, the quality of a sensor or measurement system can be known precisely. Educational method about measuring and calibrating a measuring instrument and control require practical and relevant media to be implemented directly in the field. This article discusses the devising of an Internet of Things (IoT)-based system to measure, read and process the physical quantities of weather conditions. The weather conditions mentioned are; temperature and humidity, intensity of sunlight, rainfall, also wind speed and direction. The reading of these quantities was carried out with analog and digital sensors integrated with the E S P 8266 microcontroller. This sensory system was placed in the field station. The results of reading and processing on the microcontroller are uploaded to the online server. A client system, called a base station, requests periodic sensor data to the server. The results of data acquisition are then processed again in Raspberry Pi media to be displayed in layers and stored in E x c e l form. The results of this study can be used for calibration media analog and digital sensors that can measure the quantities measured by weather stations. Stored data can also be used as a learning medium Measurement analysis and characterization of measuring instruments. \u00a9 2020 American Institute of Physics Inc.. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A measurement of physical quantities requires the right technique to do it. This is done to obtain the characteristics of the system and an accurate measuring sensor. With accurate measurements, the quality of a sensor or measurement system can be known precisely. Educational method about measuring and calibrating a measuring instrument and control require practical and relevant media to be implemented directly in the field. This article discusses the devising of an Internet of Things (IoT)-based system to measure, read and process the physical quantities of weather conditions. The weather conditions mentioned are; temperature and humidity, intensity of sunlight, rainfall, also wind speed and direction. The reading of these quantities was carried out with analog and digital sensors integrated with the E S P 8266 microcontroller. This sensory system was placed in the field station. The results of reading and processing on the microcontroller are uploaded to the online server. A client system, called a base station, requests periodic sensor data to the server. The results of data acquisition are then processed again in Raspberry Pi media to be displayed in layers and stored in E x c e l form. The results of this study can be used for calibration media analog and digital sensors that can measure the quantities measured by weather stations. Stored data can also be used as a learning medium Measurement analysis and characterization of measuring instruments. \u00a9 2020 American Institute of Physics Inc.. All rights reserved."
        ]
    },
    {
        "judul":[
            "Analysis of USB Based Spying Method Using Arduino and Metasploit Framework in Windows Operating System"
        ],
        "penulis":"Ferryansa;Budiono, Avon;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The use of a very wide windows operating system is undeniably also followed by increasing attacks on the operating system. Universal Serial Bus (USB) is one of the mechanisms used by many people with plug and play functionality that is very easy to use, making data transfers fast and easy compared to other hardware. Some research shows that the Windows operating system has weaknesses so that it is often exploited by using various attacks and malware. There are various methods used to exploit the Windows operating system, one of them by using a USB device. By using a USB device, a criminal can plant a backdoor reverse shell to exploit the victim's computer just by connecting the USB device to the victim's computer without being noticed. This research was conducted by planting a reverse shell backdoor through a USB device to exploit the victim's device, especially the webcam and microphone device on the target computer. From 35 experiments that have been carried out, it was found that 83% of spying attacks using USB devices on the Windows operating system were successfully carried out.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of a very wide windows operating system is undeniably also followed by increasing attacks on the operating system. Universal Serial Bus (USB) is one of the mechanisms used by many people with plug and play functionality that is very easy to use, making data transfers fast and easy compared to other hardware. Some research shows that the Windows operating system has weaknesses so that it is often exploited by using various attacks and malware. There are various methods used to exploit the Windows operating system, one of them by using a USB device. By using a USB device, a criminal can plant a backdoor reverse shell to exploit the victim's computer just by connecting the USB device to the victim's computer without being noticed. This research was conducted by planting a reverse shell backdoor through a USB device to exploit the victim's device, especially the webcam and microphone device on the target computer. From 35 experiments that have been carried out, it was found that 83% of spying attacks using USB devices on the Windows operating system were successfully carried out.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Dashboard information system development as visualization of transaction reports in the application BackInd (backpacker reservation system)"
        ],
        "penulis":"Lubis, Muharman;Dennis, Filhan;Andreswari, Rachmadita;Ridho Lubis, Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The accuracy and clarity of information becomes primary source for decision making process to bring effective and efficient of technology utilization. For this purpose, the 'BackInd' has been developed as reservation system to help travellers obtain complete information regarding the tourist attractions and any relevant information. Therefore, there are several problems that occur in term of presenting information, such as the use of complex tables as a means of detail information about business conditions, information overload in single page that become deterrent in term of identification of relevant data and unintuitive data presentation that bring exhaustive understanding. Thus, the implementation of dashboard can visualize the key performance and metric in real-time to support the executive gain valuable insight lead to quick and accurate decision making. The results of this study related to the process and context analysis by visualizing the data group into various sections such as transactions, finances, testimonials, visits and business performance to bring resourceful and usable information. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The accuracy and clarity of information becomes primary source for decision making process to bring effective and efficient of technology utilization. For this purpose, the 'BackInd' has been developed as reservation system to help travellers obtain complete information regarding the tourist attractions and any relevant information. Therefore, there are several problems that occur in term of presenting information, such as the use of complex tables as a means of detail information about business conditions, information overload in single page that become deterrent in term of identification of relevant data and unintuitive data presentation that bring exhaustive understanding. Thus, the implementation of dashboard can visualize the key performance and metric in real-time to support the executive gain valuable insight lead to quick and accurate decision making. The results of this study related to the process and context analysis by visualizing the data group into various sections such as transactions, finances, testimonials, visits and business performance to bring resourceful and usable information. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Industrial internet of things: Recent advances, enabling technologies and open challenges"
        ],
        "penulis":"Khan W.Z.;Rehman M.H.;Zangoti H.M.;Afzal M.K.;Armi N.;Salah K.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The adoption of emerging technological trends and applications of the Internet of Things (IoT) in the industrial systems is leading towards the development of Industrial IoT (IIoT). IIoT serves as a new vision of IoT in the industrial sector by automating smart objects for sensing, collecting, processing and communicating the real-time events in industrial systems. The major objective of IIoT is to achieve high operational efficiency, increased productivity, and better management of industrial assets and processes through product customization, intelligent monitoring applications for production floor shops and machine health, and predictive and preventive maintenance of industrial equipment. In this paper, we present a new and clear definition of IIoT, which can help the readers to understand the concept of IIoT. We have described the state-of-the-art research efforts in IIoT. Finally, we have highlighted the enabling technologies for IIoT and recent challenges faced by IIoT. \u00a9 2019",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The adoption of emerging technological trends and applications of the Internet of Things (IoT) in the industrial systems is leading towards the development of Industrial IoT (IIoT). IIoT serves as a new vision of IoT in the industrial sector by automating smart objects for sensing, collecting, processing and communicating the real-time events in industrial systems. The major objective of IIoT is to achieve high operational efficiency, increased productivity, and better management of industrial assets and processes through product customization, intelligent monitoring applications for production floor shops and machine health, and predictive and preventive maintenance of industrial equipment. In this paper, we present a new and clear definition of IIoT, which can help the readers to understand the concept of IIoT. We have described the state-of-the-art research efforts in IIoT. Finally, we have highlighted the enabling technologies for IIoT and recent challenges faced by IIoT. \u00a9 2019"
        ]
    },
    {
        "judul":[
            "Language Modeling for Journalistic Robot based on Generative Pretrained Transformer 2"
        ],
        "penulis":"Suraperwata, Raihan Hamid;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The language model is typically represented as an unsupervised distribution estimate from a set of examples, each consisting of symbol sequences, and it could predict over sequences of words. We demonstrate the language model based on Generative Pretrained 2 will have a readable generated article for the journalistic robot. Nowadays, there is some trending of journalistic in Indonesia, freedom of the press, and it enables every journalist to make unprofessional news on the media. The problem affects the raise of journalist numbers who have lack journalistic knowledge and increases the amount of inappropriate news content in Indonesia. Therefore, to improve the quality of news produced by the mass media in Indonesia, a journalistic robot is needed to produce news content by the guidelines and the journalistic code of ethics. This research uses language modeling based on GPT-2 to generate articles. The program has four primary steps: building dataset, fine tuning GPT-2, modeling the trained data, and create articles. Furthermore, this research will add an Indonesian model for GPT-2 since the main purpose of this research is Indonesian articles. This paper proposes GPT-2 to be applied to news contents and calculate the result with BLEU scores to check if the results are readable content. These findings show that the proposed model is capable of generating a readable article after trained by 110 Indonesian articles with an excellent score of BLEU.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The language model is typically represented as an unsupervised distribution estimate from a set of examples, each consisting of symbol sequences, and it could predict over sequences of words. We demonstrate the language model based on Generative Pretrained 2 will have a readable generated article for the journalistic robot. Nowadays, there is some trending of journalistic in Indonesia, freedom of the press, and it enables every journalist to make unprofessional news on the media. The problem affects the raise of journalist numbers who have lack journalistic knowledge and increases the amount of inappropriate news content in Indonesia. Therefore, to improve the quality of news produced by the mass media in Indonesia, a journalistic robot is needed to produce news content by the guidelines and the journalistic code of ethics. This research uses language modeling based on GPT-2 to generate articles. The program has four primary steps: building dataset, fine tuning GPT-2, modeling the trained data, and create articles. Furthermore, this research will add an Indonesian model for GPT-2 since the main purpose of this research is Indonesian articles. This paper proposes GPT-2 to be applied to news contents and calculate the result with BLEU scores to check if the results are readable content. These findings show that the proposed model is capable of generating a readable article after trained by 110 Indonesian articles with an excellent score of BLEU.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Hybrid Configuration in Information Technology Value Model"
        ],
        "penulis":"Abdurrahman, Lukman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Thus far, the IT value study model is typically in a serial configuration correlating its subsystems. This article attempts to propose a hybrid configuration merging serial and parallel configurations to be a proposed IT value model. A methodology is the meta-analysis approach to determine the subsystem model and to rationalize the relationships among subsystems. To complete the analysis, the research also puts on the partial adjustment valuation functioning as a valuation method to calculate the numerical magnitude of the operating revenue of each subsystem. The resulted model undergoes a case study using Telkom's data, which is the Indonesian information and communication technology industry provider. It indicates that the variance of the hybrid configuration is extraordinarily insignificant and tolerable, in which the portion of the average deviation to the Telkom's average revenue is only-0.08% during the period 2005-2015. Thus, the hybrid configuration can nearly be acceptable in the IT value study due to its validity theoretically and empirically.  \u00a9 2007-2012 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Thus far, the IT value study model is typically in a serial configuration correlating its subsystems. This article attempts to propose a hybrid configuration merging serial and parallel configurations to be a proposed IT value model. A methodology is the meta-analysis approach to determine the subsystem model and to rationalize the relationships among subsystems. To complete the analysis, the research also puts on the partial adjustment valuation functioning as a valuation method to calculate the numerical magnitude of the operating revenue of each subsystem. The resulted model undergoes a case study using Telkom's data, which is the Indonesian information and communication technology industry provider. It indicates that the variance of the hybrid configuration is extraordinarily insignificant and tolerable, in which the portion of the average deviation to the Telkom's average revenue is only-0.08% during the period 2005-2015. Thus, the hybrid configuration can nearly be acceptable in the IT value study due to its validity theoretically and empirically.  \u00a9 2007-2012 IEEE."
        ]
    },
    {
        "judul":[
            "Combination of program evaluation and review technique (PERT) and critical path method (CPM) for project schedule development"
        ],
        "penulis":"Baits, Hamzah Abdul;Puspita, Ika Arum;Bay, Achmad Fuad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One of the problems faced by the contractors is an inappropriate scheduling method. For project scheduling, the contractor using Bar chart. Although this method still can be used, but in its application is limited to scheduling large-scale projects, because this method cannot describe the interdependence of activity. The problem can be solved using Program Evaluation and Review Technique (PERT) and Critical Path Method (CPM). PERT is a method that can be used to estimate the duration of activity and can calculate the probability of project time completion, while CPM is a scheduling method used to find the path of critical path and can describe the relationship between activities. Scheduling results using CPM found that the minimum duration to complete the project was 135 days with 20 activities on the critical path with 50% project probability. Further analysis using PERT found that for a greater probability of the project completion was 68% for 139.78 days duration, 95% for 144.56 days, and 99.7% for 149.34 days. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the problems faced by the contractors is an inappropriate scheduling method. For project scheduling, the contractor using Bar chart. Although this method still can be used, but in its application is limited to scheduling large-scale projects, because this method cannot describe the interdependence of activity. The problem can be solved using Program Evaluation and Review Technique (PERT) and Critical Path Method (CPM). PERT is a method that can be used to estimate the duration of activity and can calculate the probability of project time completion, while CPM is a scheduling method used to find the path of critical path and can describe the relationship between activities. Scheduling results using CPM found that the minimum duration to complete the project was 135 days with 20 activities on the critical path with 50% project probability. Further analysis using PERT found that for a greater probability of the project completion was 68% for 139.78 days duration, 95% for 144.56 days, and 99.7% for 149.34 days. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office."
        ]
    },
    {
        "judul":[
            "Comparative Analysis of Load Balancing Dynamic Ratio and Server Ratio Algorithms"
        ],
        "penulis":"Murti, Krisna Wahyu;Riza, Tengku Ahmad;Mulyana, Asep;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Load balancing is a technique for dividing traffic loads and reading the availability of resources on the server. Dividing the traffic load use server hardware such as CPU, memory, and disk. This research designed load balancing using dynamic ratio and ratio algorithms on three types of services namely web server, FTP server, and VoIP server, FTP server, and VoIP server. The highest throughput average value is found in the 3:2 of dynamic ratio algorithm, i.e. 114.18 KB\/s of web server and 118.9 KB\/s of FTP server. The fastest response time average value is the 3:2 ratio algorithm for 8.7 seconds of web server and 32.3 seconds of FTP server. The average results for the least number of request losses are the 1: 1 of ratio algorithm, i.e. web server for 17 request failures, FTP server for 1 file transfer failure, and VoIP server for 0.18% call failure. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Load balancing is a technique for dividing traffic loads and reading the availability of resources on the server. Dividing the traffic load use server hardware such as CPU, memory, and disk. This research designed load balancing using dynamic ratio and ratio algorithms on three types of services namely web server, FTP server, and VoIP server, FTP server, and VoIP server. The highest throughput average value is found in the 3:2 of dynamic ratio algorithm, i.e. 114.18 KB\/s of web server and 118.9 KB\/s of FTP server. The fastest response time average value is the 3:2 ratio algorithm for 8.7 seconds of web server and 32.3 seconds of FTP server. The average results for the least number of request losses are the 1: 1 of ratio algorithm, i.e. web server for 17 request failures, FTP server for 1 file transfer failure, and VoIP server for 0.18% call failure. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "An artificial neural network approach to predict energy consumption and surface roughness of a natural material"
        ],
        "penulis":"Arafat, Mohammad;Sjafrizal, Teddy;Anugraha, Rino Andias;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Constructing a prediction model of machining performance is useful to improve its process efficiency. Artificial neural network (ANN) has been widely used in prediction works, capable of solving complex problems with numerous parameters. The present study aims to describe the application of the ANN technique in predicting the machining performance of a natural material. Bovine horns were the selected natural materials. Bovine horns are sustainable, recyclable, and abundant source for industrial applications. The outputs of the predictive model were surface roughness and energy consumption, whereas the input data were spindle speed, depth of cut and feed rate of a face milling. It was found that the ANN-based prediction model of bovine horns produced a high accuracy prediction (95.4%). The outcome of this study may be referred by similar studies on other natural materials, supporting the global efforts in improving the industrialization of natural materials. \u00a9 2020, Springer Nature Switzerland AG.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Constructing a prediction model of machining performance is useful to improve its process efficiency. Artificial neural network (ANN) has been widely used in prediction works, capable of solving complex problems with numerous parameters. The present study aims to describe the application of the ANN technique in predicting the machining performance of a natural material. Bovine horns were the selected natural materials. Bovine horns are sustainable, recyclable, and abundant source for industrial applications. The outputs of the predictive model were surface roughness and energy consumption, whereas the input data were spindle speed, depth of cut and feed rate of a face milling. It was found that the ANN-based prediction model of bovine horns produced a high accuracy prediction (95.4%). The outcome of this study may be referred by similar studies on other natural materials, supporting the global efforts in improving the industrialization of natural materials. \u00a9 2020, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Enhancing student learning achievement using competency-based modules on basic competencies examining the characteristics of refrigerants and lubricating oils"
        ],
        "penulis":"Suherman A.;Wiyono A.;Yayat Y.;Negara R.M.H.K.;Berman E.T.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study was to determine the increase in student achievement using competency-based modules. The study was conducted on the subject of system and the installation of refrigeration with basic competencies examining the characteristics of refrigerants and lubricating oils. This study uses quasi-experimental research methods. Participants in this study were 60 students from the vocational high school in Bandung. The research instrument used was a test, which consisted of pre-test and post-test. Improved student achievement was analyzed using the concept of normalized gain (N-gain) based on pre test and post test score data. The results showed the use of competency-based modules can improve student learning achievement. The achievement of the post test scores of the experimental class students above the minimum completion criteria with an average post test score of 89.39, while the score of the control class was 72.42. Based on the N-Gain value there are differences between the experimental class and the control class which are 79.5 and 46.94, respectively. The use of competency-based modules has implications for improving student achievement to be more optimal. The content of interesting module materials can increase student motivation and activity in learning in the classroom. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study was to determine the increase in student achievement using competency-based modules. The study was conducted on the subject of system and the installation of refrigeration with basic competencies examining the characteristics of refrigerants and lubricating oils. This study uses quasi-experimental research methods. Participants in this study were 60 students from the vocational high school in Bandung. The research instrument used was a test, which consisted of pre-test and post-test. Improved student achievement was analyzed using the concept of normalized gain (N-gain) based on pre test and post test score data. The results showed the use of competency-based modules can improve student learning achievement. The achievement of the post test scores of the experimental class students above the minimum completion criteria with an average post test score of 89.39, while the score of the control class was 72.42. Based on the N-Gain value there are differences between the experimental class and the control class which are 79.5 and 46.94, respectively. The use of competency-based modules has implications for improving student achievement to be more optimal. The content of interesting module materials can increase student motivation and activity in learning in the classroom. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Analysis and Design of Master Data Monitoring Application using Open Source Tools: A Case Study at Government Agency"
        ],
        "penulis":"Naufal, Muhammad Ariq;Kusumasari, Tien Fabrianti;Alam, Ekky Novriza;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Master data management is a process to integrate several data sources into one for good, consistent, and evenly standardized data. Several companies have been successful in creating a good quality data source for their data. However, some companies yet to have this system. A government agency in Indonesia finds difficulties in managing their data source. The problem lies in data duplication, lack of control on data reference, and the lack of application to monitor all data sources. This paper is carried out to fix the MDM monitoring dashboard that has been created in advance. The monitoring dashboard is created with the pureshare method. This paper designed a monitoring dashboardthat can monitor the process and quality of master data. The benefit of this research is to get good quality and consistent master data, which can be used in all organizations, and its authenticity can be guaranteed. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Master data management is a process to integrate several data sources into one for good, consistent, and evenly standardized data. Several companies have been successful in creating a good quality data source for their data. However, some companies yet to have this system. A government agency in Indonesia finds difficulties in managing their data source. The problem lies in data duplication, lack of control on data reference, and the lack of application to monitor all data sources. This paper is carried out to fix the MDM monitoring dashboard that has been created in advance. The monitoring dashboard is created with the pureshare method. This paper designed a monitoring dashboardthat can monitor the process and quality of master data. The benefit of this research is to get good quality and consistent master data, which can be used in all organizations, and its authenticity can be guaranteed. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Tracking, Arrival Time Estimator, and Passenger Information System on Bus Rapid Transit (BRT)"
        ],
        "penulis":"Hafiizh Nur M.A.;Hadiyoso, Sugondo;Belladina, Fefa Bianca;Ramadan, Dadan Nur;Wijayanto, Inung;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Trans Metro Bandung is a new Bus Rapid Transit in Bandung, Indonesia. As a new mode of transportation, it proposes comfort, safety, and give an affordable price. However, information systems related to buses are still lacking and far from expectations. That includes the uncertainty of the bus departures and arrivals times at bus stops. Therefore, in this study, an integrated online system is designed to provide information, including bus arrival time, bus position, and the number of passengers on the bus. This information system is a website application that is connected to the Firebase real-time database so that all data can be accessed in real-time and then displayed at the bus stop. The hardware system consists of an infrared detector to count the number of passengers and a GPS module for bus tracking. From the bus position information, the system can estimate the arrival time at the nearest bus stop.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Trans Metro Bandung is a new Bus Rapid Transit in Bandung, Indonesia. As a new mode of transportation, it proposes comfort, safety, and give an affordable price. However, information systems related to buses are still lacking and far from expectations. That includes the uncertainty of the bus departures and arrivals times at bus stops. Therefore, in this study, an integrated online system is designed to provide information, including bus arrival time, bus position, and the number of passengers on the bus. This information system is a website application that is connected to the Firebase real-time database so that all data can be accessed in real-time and then displayed at the bus stop. The hardware system consists of an infrared detector to count the number of passengers and a GPS module for bus tracking. From the bus position information, the system can estimate the arrival time at the nearest bus stop.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Creating employee job satisfaction in a telecommunications company: Perceived organisational support and work stress as antecedents"
        ],
        "penulis":"Prasetio, Arif Partono;Anggadwita, Grisna;Dewi, Nadya Ariana;Istitania, Rizky;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Job satisfaction is one of the important factors when it comes to companies to retaining their employees. Telecommunication companies in Indonesia continue to strive to develop the professionalism of their human resources through various programs and support. This article empirically investigates the effect of the perceived organisational support and work stress on job satisfaction in a telecommunication company. The data was collected from a sample of employees in a public telecommunications company; 200 questionnaires were distributed with a 51% response rate. The mediation analysis procedure was carried out to test the research hypotheses. The results revealed that perceived organisational support has a direct effect on job satisfaction and work stress. Work stress does not affect job satisfaction. This study contributes practically as a management guide in terms of helping companies to provide various types of support and empowerment for their employees. The implications of these findings have been further explored in this study. Copyright \u00a9 2020 Inderscience Enterprises Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Job satisfaction is one of the important factors when it comes to companies to retaining their employees. Telecommunication companies in Indonesia continue to strive to develop the professionalism of their human resources through various programs and support. This article empirically investigates the effect of the perceived organisational support and work stress on job satisfaction in a telecommunication company. The data was collected from a sample of employees in a public telecommunications company; 200 questionnaires were distributed with a 51% response rate. The mediation analysis procedure was carried out to test the research hypotheses. The results revealed that perceived organisational support has a direct effect on job satisfaction and work stress. Work stress does not affect job satisfaction. This study contributes practically as a management guide in terms of helping companies to provide various types of support and empowerment for their employees. The implications of these findings have been further explored in this study. Copyright \u00a9 2020 Inderscience Enterprises Ltd."
        ]
    },
    {
        "judul":[
            "Mining shift work operation from event logs"
        ],
        "penulis":"Utama, Nur Ichsan;Sutrisnowati, Riska Asriana;Kamal, Imam Mustafa;Bae, Hyerim;Park, You-Jin;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Event logs are records of events that are generally used in process mining to determine the manner in which various processes are practically implemented. Previous studies on process mining attempted to combine the results based on different perspectives such as control flow, data, performance, and resources (organizational) to create a simulation model. This study focuses on the resource perspective. A prior study from the resource perspective focused on clustering the resources into organizational units. Implementing the results of the above study in a simulation model will yield inaccurate results because the resources are assumed to always be available if no task is performed. In a practical scenario, resources (particularly humans) tend to work based on shifts. Thus, we propose mining the shift work operation of resources from event logs to tackle this issue. We utilized a self-organizing map and k-means clustering to incorporate the shift work information from the event logs into the simulation model. Moreover, we introduce a distance function and weight-centroid updating rule in the clustering technique to realize our objective. We conducted extensive experiments with artificial data sets to assess the effectiveness of the proposed method. The simulation shows that introducing the shift work operation time of resources can yield more accurate results. Furthermore, the proposed distance function can capture the shift work operation of the resources more precisely compared with the general distance function. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "SNSSNView detailsExpand Substance 2-(thiocyanomethylthio)benzothiazole",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Event logs are records of events that are generally used in process mining to determine the manner in which various processes are practically implemented. Previous studies on process mining attempted to combine the results based on different perspectives such as control flow, data, performance, and resources (organizational) to create a simulation model. This study focuses on the resource perspective. A prior study from the resource perspective focused on clustering the resources into organizational units. Implementing the results of the above study in a simulation model will yield inaccurate results because the resources are assumed to always be available if no task is performed. In a practical scenario, resources (particularly humans) tend to work based on shifts. Thus, we propose mining the shift work operation of resources from event logs to tackle this issue. We utilized a self-organizing map and k-means clustering to incorporate the shift work information from the event logs into the simulation model. Moreover, we introduce a distance function and weight-centroid updating rule in the clustering technique to realize our objective. We conducted extensive experiments with artificial data sets to assess the effectiveness of the proposed method. The simulation shows that introducing the shift work operation time of resources can yield more accurate results. Furthermore, the proposed distance function can capture the shift work operation of the resources more precisely compared with the general distance function. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Dew computing: Concept and its implementation strategy"
        ],
        "penulis":"Utomo, Prayudi;Falahah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Dew computing is one of the distributed computing paradigms which is considered as an extension of the cloud computing paradigm. In dew computing, users can perform full system functionality without depending on internet availability. All data will be stored on the local storage of the user's device, and when an internet connection is available, synchronization will be carried out to synchronize the information on cloud-based applications. There have been many implementations of dew computing in existing applications, but research done in the field of dew computing is not as much as in other distributed computing fields. This study intends to discuss the dew computing concept and its implementation, what constraints might exist on implementation, and what strategies need to be considered in designing dew computing implementations. The results is a proposed framework for consideration on determining the specifications of applications running on dew computing, both for desktop, mobile and cloud environments, which covered four aspects, which are: data storage, synchronization, authorization and collaboration. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Dew computing is one of the distributed computing paradigms which is considered as an extension of the cloud computing paradigm. In dew computing, users can perform full system functionality without depending on internet availability. All data will be stored on the local storage of the user's device, and when an internet connection is available, synchronization will be carried out to synchronize the information on cloud-based applications. There have been many implementations of dew computing in existing applications, but research done in the field of dew computing is not as much as in other distributed computing fields. This study intends to discuss the dew computing concept and its implementation, what constraints might exist on implementation, and what strategies need to be considered in designing dew computing implementations. The results is a proposed framework for consideration on determining the specifications of applications running on dew computing, both for desktop, mobile and cloud environments, which covered four aspects, which are: data storage, synchronization, authorization and collaboration. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The application of inventory model in material planning department atcompany of XYZ"
        ],
        "penulis":"Saragiha, Nova Indah;Tobinga, Martin Decker Lumban;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Company of XYZ is the first company in Indonesia to produce airplanes. Materials needed to produce the airplanes consist of metal, non-metal, and others. In the production process, there is condition where materials of metals are not available or run out. The unavailable materials are then substituted with other materials of metals. The problem is there are several substituted materials that are more expensive than the initial materials. On average, the difference or the price gap between the substituted materials and the initial materials is 105.78%. This gap shows that the Company of XYZ needs to control their inventory more effectively. An inventory model is applicated to the real system which is Material Planning Department to decrease this gap. That inventory model is simple probabilistic model. The result shows that the simple probabilistic model is able to decrease the gap to become 32.81%. \u00a9 2020, Hampstead Psychological Associates. All rights reserved."
        ],
        "abstrak":[
            "Company of XYZ is the first company in Indonesia to produce airplanes. Materials needed to produce the airplanes consist of metal, non-metal, and others. In the production process, there is condition where materials of metals are not available or run out. The unavailable materials are then substituted with other materials of metals. The problem is there are several substituted materials that are more expensive than the initial materials. On average, the difference or the price gap between the substituted materials and the initial materials is 105.78%. This gap shows that the Company of XYZ needs to control their inventory more effectively. An inventory model is applicated to the real system which is Material Planning Department to decrease this gap. That inventory model is simple probabilistic model. The result shows that the simple probabilistic model is able to decrease the gap to become 32.81%. \u00a9 2020, Hampstead Psychological Associates. All rights reserved."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "The effect of a secos in crude palm oil forecasting to improve business intelligence"
        ],
        "penulis":"Al-Khowarizmi;Nasution, Ilham Ramadhan;Lubis, Muharman;Lubis, Arif Ridho;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Crude palm oil is a crop that has a harvest period of \u00b1 2 weeks and is in dire need of dissemination of information using e-commerce in order to be able to predict the price of the yield of companies or individual gardens within the next 2 weeks in order to improve studies on business intelligence. The disadvantage of not implementing e-commerce is certainly detrimental to the garden owner because they have to go through an agent so prices are set based on the agent. So with the application of e-commerce, buyers of crude palm oil can predict prices in conducting business processes to the future. So the need to forecasting the price of crude palm oil heads in order to improve the application of business intelligence using the evolution-based artificial neural network (ANN) method which in this paper is tested with SECoS get a MAPE value of 0.035% and by applying business intelligence can protect transaction costs by 33.3%. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Crude palm oil is a crop that has a harvest period of \u00b1 2 weeks and is in dire need of dissemination of information using e-commerce in order to be able to predict the price of the yield of companies or individual gardens within the next 2 weeks in order to improve studies on business intelligence. The disadvantage of not implementing e-commerce is certainly detrimental to the garden owner because they have to go through an agent so prices are set based on the agent. So with the application of e-commerce, buyers of crude palm oil can predict prices in conducting business processes to the future. So the need to forecasting the price of crude palm oil heads in order to improve the application of business intelligence using the evolution-based artificial neural network (ANN) method which in this paper is tested with SECoS get a MAPE value of 0.035% and by applying business intelligence can protect transaction costs by 33.3%. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Indonesian Graphemic Syllabification Using n-Gram Tagger with State-Elimination"
        ],
        "penulis":"Ismail, Rezza Nafi;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Syllabification can be approached using either grapheme or phoneme-based. Graphemic syllabification is simpler than phonemic syllabification since it does not require grapheme-to-phoneme conversion (G2P). Both phonemic and graphemic syllabification has been done on Indonesian words with average SER of 0.64% and 2.27%, respectively. The performance of Indonesian graphemic syllabification is considerably lower than the phonemic one. This research aims to improve Indonesian graphemic syllabification using a syllable boundary tagger based on the statistical n-gram model. Using fivefold cross-validation on 50k formal Indonesian words, the proposed model gives an average syllable error rate (SER) of 0.94% while the introduced state-elimination procedure reduces the SER to 0.92%, which is much lower than the previous Indonesian graphemic syllabification. Most syllabification errors come from derivative words and adapted foreign terms.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Syllabification can be approached using either grapheme or phoneme-based. Graphemic syllabification is simpler than phonemic syllabification since it does not require grapheme-to-phoneme conversion (G2P). Both phonemic and graphemic syllabification has been done on Indonesian words with average SER of 0.64% and 2.27%, respectively. The performance of Indonesian graphemic syllabification is considerably lower than the phonemic one. This research aims to improve Indonesian graphemic syllabification using a syllable boundary tagger based on the statistical n-gram model. Using fivefold cross-validation on 50k formal Indonesian words, the proposed model gives an average syllable error rate (SER) of 0.94% while the introduced state-elimination procedure reduces the SER to 0.92%, which is much lower than the previous Indonesian graphemic syllabification. Most syllabification errors come from derivative words and adapted foreign terms.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Accuracy Analysis Transliteration Balinese Script-to-Latin Text Using Hexadecimal Labeling Method"
        ],
        "penulis":"Aranta, Arik;Witarsyah, Deden;Murpratiwi, Santi Ika;Abawajy, Jemal;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Balinese script is a collection of symbols used to communicate via text messages used by Balinese. Since the 804s or 9th century until now, the use of the Balinese script has been intensified by the Bali Provincial Government. The government has made various innovations to using the Balinese script in daily activities. Currently, technology has started to be applied in the Balinese script learning process, especially in the transliteration Latin characters into Balinese characters. This makes it easier to learn the Balinese script for all circles. However, behind the rapid development of Latin transliteration application technology to Balinese script, the reverse transliteration process from Balinese script to Latin script has become an interesting topic to be researched. In this study, the optimized string replacement method with the hexadecimal number format was used to improve the string replacement algorithm to translate Balinese script sentences into understandable Latin sentences. The optimization of this method resultedin an accuracy of 95.1 % from 464 test data. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Balinese script is a collection of symbols used to communicate via text messages used by Balinese. Since the 804s or 9th century until now, the use of the Balinese script has been intensified by the Bali Provincial Government. The government has made various innovations to using the Balinese script in daily activities. Currently, technology has started to be applied in the Balinese script learning process, especially in the transliteration Latin characters into Balinese characters. This makes it easier to learn the Balinese script for all circles. However, behind the rapid development of Latin transliteration application technology to Balinese script, the reverse transliteration process from Balinese script to Latin script has become an interesting topic to be researched. In this study, the optimized string replacement method with the hexadecimal number format was used to improve the string replacement algorithm to translate Balinese script sentences into understandable Latin sentences. The optimization of this method resultedin an accuracy of 95.1 % from 464 test data. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Reduction of number of empty-truck trips in inter-terminal transportation using multi-agent Q-learning"
        ],
        "penulis":"Adi, Taufik Nur;Iskandar, Yelita Anggiane;Bae, Hyerim;Choi, Yulim;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In a port consisting of multiple container terminals, the demand for transportation of containers and cargo among port facilities is high. Almost all transshipment containers bound for a vessel generally are transported from one terminal to another within a short period, which process is known as inter-terminal transportation (ITT). Adequate ITT planning is required in order to reduce ITT-related costs. Minimization of the number of Empty-Truck trips has gained attention, as the ITT problem incurs ITT-related costs. A single Q-Learning-based technique developed in a previous study for minimization of the number of empty-truck trips required high computational time while learning from a considerable amount of orders data. This paper proposes multi-agent Q-Learning to improve the performance offered by the previous single-agent-based model. Our results show that multi-agent Q-Learning performs better than the single-agent alternative in terms of computation time and, therefore too, the quality of its results. \u00a9 Interconnected Supply Chains in an Era of Innovation - Proceedings of the 8th International Conference on Information Systems, Logistics and Supply Chain, ILS 2020. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a port consisting of multiple container terminals, the demand for transportation of containers and cargo among port facilities is high. Almost all transshipment containers bound for a vessel generally are transported from one terminal to another within a short period, which process is known as inter-terminal transportation (ITT). Adequate ITT planning is required in order to reduce ITT-related costs. Minimization of the number of Empty-Truck trips has gained attention, as the ITT problem incurs ITT-related costs. A single Q-Learning-based technique developed in a previous study for minimization of the number of empty-truck trips required high computational time while learning from a considerable amount of orders data. This paper proposes multi-agent Q-Learning to improve the performance offered by the previous single-agent-based model. Our results show that multi-agent Q-Learning performs better than the single-agent alternative in terms of computation time and, therefore too, the quality of its results. \u00a9 Interconnected Supply Chains in an Era of Innovation - Proceedings of the 8th International Conference on Information Systems, Logistics and Supply Chain, ILS 2020. All rights reserved."
        ]
    },
    {
        "judul":[
            "Accuracy improvement in through the wall radar based on deconvolution and delay estimation"
        ],
        "penulis":"Purwandani, Agita;Pramudita, A. A;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Through the Wall Radar (TWR) which works at Ultra Wideband (UWB) frequencies us to detect objects behind a wall. This radar can be used to search or evacuate victims of natural disasters buried behind a wall and to speed up the evacuation process. Wall as Obstacles become the main problems that need to be overcome in applying the TWR for a certain purposed. The wall effect can reduce the accuracy of the detection results. The wall causes masking effect on target reflection signal and give a difficulty in detecting the target. The delay propagation that contributes by the wall reduces the accuracy in detecting the location. The characteristics of the wall are needed to achieve for improving the accuracy, therefore the objects can be detected precisely. The method that proposed composes of two subsystems. The first subsystem is the extraction of antenna and wall effects that performed by deconvolution. The second part is delay estimation method. In this study, laboratory experiments were carried out study the performance of the proposed method. The TWR was modeled using a vector network analyzer (VNA). The results obtained by using the deconvolution method and reducing object delay can be detected according to the target with a 2 cm error margin. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Through the Wall Radar (TWR) which works at Ultra Wideband (UWB) frequencies us to detect objects behind a wall. This radar can be used to search or evacuate victims of natural disasters buried behind a wall and to speed up the evacuation process. Wall as Obstacles become the main problems that need to be overcome in applying the TWR for a certain purposed. The wall effect can reduce the accuracy of the detection results. The wall causes masking effect on target reflection signal and give a difficulty in detecting the target. The delay propagation that contributes by the wall reduces the accuracy in detecting the location. The characteristics of the wall are needed to achieve for improving the accuracy, therefore the objects can be detected precisely. The method that proposed composes of two subsystems. The first subsystem is the extraction of antenna and wall effects that performed by deconvolution. The second part is delay estimation method. In this study, laboratory experiments were carried out study the performance of the proposed method. The TWR was modeled using a vector network analyzer (VNA). The results obtained by using the deconvolution method and reducing object delay can be detected according to the target with a 2 cm error margin. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A Quantification System of Needle Visibility in B-mode Ultrasound with Linear and Curved Transducer"
        ],
        "penulis":"Susanti, Hesty;Septyvergy, Arkanty;Suprijanto;Kurniadi, Deddy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "\u2014Apart from its usefulness in interventional procedure, ultrasound-guided needle insertion has also crucial problem in terms of needle visibility. The inconsistency of needle visibility is needed to be quantified to evaluate the significance of possible technical factors, e.g., imaging strategies, needle type, and needle-transducer relative position. Needle visibility quantification is important as an initial step before further investigation about fundamental physics behind it and further development of needle visibility enhancement. 20G, 150 mm spinal needle inserted in degassed water phantom is imaged with B-mode Flex Focus 800 BK-Medical using 12 MHz linear transducer and 6 MHz curved transducer. The insertion angles are varied between 15\u00b0-70\u00b0. The quantified visibility representing each needle position are combined into a comprehensive visibility map covering the whole insertion area. It is also evaluated based on insertion length. The results suggest that both linear and curved transducer, for all insertion angles, the distributions of needle visibility have similar pattern and they are not affected by the insertion length. Practically, this applied method of visibility quantification can be used as specific reference and to predict the distribution of needle visibility limited by the specification of needle and ultrasound system, i.e., range of transducer\u2019s frequency and needle\u2019s size. \u00a9 2020 North Atlantic University Union NAUN. All rights reserved.",
            "Results list, loading...Table contains details of the trade names associated with this documentTradenameCountryManufacturerUniplex Nano LineGermanyPajunkFlex Focus 800DenmarkBK Medical",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "\u2014Apart from its usefulness in interventional procedure, ultrasound-guided needle insertion has also crucial problem in terms of needle visibility. The inconsistency of needle visibility is needed to be quantified to evaluate the significance of possible technical factors, e.g., imaging strategies, needle type, and needle-transducer relative position. Needle visibility quantification is important as an initial step before further investigation about fundamental physics behind it and further development of needle visibility enhancement. 20G, 150 mm spinal needle inserted in degassed water phantom is imaged with B-mode Flex Focus 800 BK-Medical using 12 MHz linear transducer and 6 MHz curved transducer. The insertion angles are varied between 15\u00b0-70\u00b0. The quantified visibility representing each needle position are combined into a comprehensive visibility map covering the whole insertion area. It is also evaluated based on insertion length. The results suggest that both linear and curved transducer, for all insertion angles, the distributions of needle visibility have similar pattern and they are not affected by the insertion length. Practically, this applied method of visibility quantification can be used as specific reference and to predict the distribution of needle visibility limited by the specification of needle and ultrasound system, i.e., range of transducer\u2019s frequency and needle\u2019s size. \u00a9 2020 North Atlantic University Union NAUN. All rights reserved."
        ]
    },
    {
        "judul":[
            "IoT Products Adoption for Smart Living in Indonesia: Technology Challenges and Prospects"
        ],
        "penulis":"Yasirandi, Rahmat;Lander, Alvin;Sakinah, Hana Rifdah;Insan, Isa Mulia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Internet of Things (IoT) Products have been popular in every country in the world nowadays. Indonesia has become one of the countries that have been affected positively by this technology. One of them is the realization of lifestyle paradigms, which is smart living. This research found that there are five main sectors in smart living, which are entertainment, health, energy management, security, and retail. IoT products functionality has become an important part of the impact of implementing smart living. But it was found that the existence of challenges and prospects from this technology adoption is not limited, mainly because Indonesia is a developing country that supports regulations related to the adoption of IoT technology. In results, there are data findings in this research that show facts related to the adoption of IoT Products for Smart Living in Indonesia.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet of Things (IoT) Products have been popular in every country in the world nowadays. Indonesia has become one of the countries that have been affected positively by this technology. One of them is the realization of lifestyle paradigms, which is smart living. This research found that there are five main sectors in smart living, which are entertainment, health, energy management, security, and retail. IoT products functionality has become an important part of the impact of implementing smart living. But it was found that the existence of challenges and prospects from this technology adoption is not limited, mainly because Indonesia is a developing country that supports regulations related to the adoption of IoT technology. In results, there are data findings in this research that show facts related to the adoption of IoT Products for Smart Living in Indonesia.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Automatic battery charging system on android smartphones"
        ],
        "penulis":"Djuanda D.S.R.;Ramdhani M.;Ekaputri C.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A smartphone needs a battery source to work well. During the battery charging process, the state of charge can be increased by up to 100%. One habit of charging batteries is to leave the smartphone connected to the charger all night long. Batteries that are already 100% but still connected to the charger will continue to receive an electric current even though a small value can cause a decrease in battery life and durability. This final project aims to create an automatic battery charging system based on the Android operating system. The result of this system is when the percentage limit that we have set is the same as the percentage of the battery on the smartphone, the system will automatically cut off the incoming current so that the charging process will stop. This system is designed using a microcontroller, Bluetooth module, relay module, Android apps, and smartphone with an Android operating system. The tests are the suitability of the apps with the smartphone, the charging and discharging conditions on the system, and automatic battery charging. From the results of the tests, the system can cut the current to a value of 0 amperes from the charger manually and automatically controlled through the apps, the apps can be used on smartphones that have Android version 2.1 or higher. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A smartphone needs a battery source to work well. During the battery charging process, the state of charge can be increased by up to 100%. One habit of charging batteries is to leave the smartphone connected to the charger all night long. Batteries that are already 100% but still connected to the charger will continue to receive an electric current even though a small value can cause a decrease in battery life and durability. This final project aims to create an automatic battery charging system based on the Android operating system. The result of this system is when the percentage limit that we have set is the same as the percentage of the battery on the smartphone, the system will automatically cut off the incoming current so that the charging process will stop. This system is designed using a microcontroller, Bluetooth module, relay module, Android apps, and smartphone with an Android operating system. The tests are the suitability of the apps with the smartphone, the charging and discharging conditions on the system, and automatic battery charging. From the results of the tests, the system can cut the current to a value of 0 amperes from the charger manually and automatically controlled through the apps, the apps can be used on smartphones that have Android version 2.1 or higher. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Study of EDFA Placement in 10 Gbps Single-Mode Fiber Link to Support 5G Networks"
        ],
        "penulis":"Effendi, Nabila Syadzwina;Natali, Yus;Apriono, Catur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The new generation of mobile communication technology plays a crucial role in driving the future of Industry 4.0. The 5G networks will have high network flexibility and guarantee the Quality of Service (QoS) requirement. As a basic 5G network connection, the transport network must guarantee bandwidth, delay, synchronization, and reliability. Interconnection between 5G wireless networks and fiber optic networks as a transport network offers a more cohesive experience across fixed and cellular applications. As a transport network, optical fiber supports the application of metropolitan, regional, and national networks, which require long transmission distances. However, when optical signals propagate through the fiber, fiber attenuation appears as a disturbance due to much longer use of transmission distance. This research investigates the effects of different placement of EDFA in single-channel of single-mode fiber (SMF) link using a 10 Gbps bit rate data transmission at various transmission distance and source power levels. This research considers the parametric study of pre-amplifier and booster amplifier with NRZ modulation format at different transmission distances from 70 km to 130 km, and input powers from-18 dBm to 30 dBm simulated by using OptiSystem to characterize the Bit Error Rate (BER). The results show that in different situations, the system will require different EDFA schemes to meet the signal amplifier requirements. This result is useful for selecting different schemes of EDFA in designing a long-haul transmission with high data rates. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The new generation of mobile communication technology plays a crucial role in driving the future of Industry 4.0. The 5G networks will have high network flexibility and guarantee the Quality of Service (QoS) requirement. As a basic 5G network connection, the transport network must guarantee bandwidth, delay, synchronization, and reliability. Interconnection between 5G wireless networks and fiber optic networks as a transport network offers a more cohesive experience across fixed and cellular applications. As a transport network, optical fiber supports the application of metropolitan, regional, and national networks, which require long transmission distances. However, when optical signals propagate through the fiber, fiber attenuation appears as a disturbance due to much longer use of transmission distance. This research investigates the effects of different placement of EDFA in single-channel of single-mode fiber (SMF) link using a 10 Gbps bit rate data transmission at various transmission distance and source power levels. This research considers the parametric study of pre-amplifier and booster amplifier with NRZ modulation format at different transmission distances from 70 km to 130 km, and input powers from-18 dBm to 30 dBm simulated by using OptiSystem to characterize the Bit Error Rate (BER). The results show that in different situations, the system will require different EDFA schemes to meet the signal amplifier requirements. This result is useful for selecting different schemes of EDFA in designing a long-haul transmission with high data rates. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "ECG-based prediction algorithm for imminent malignant ventricular arrhythmias using decision tree"
        ],
        "penulis":"Mandala, Satria;Cai Di, Tham;Sunar, Mohd Shahrizal;Adiwijaya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Spontaneous prediction of malignant ventricular arrhythmia (MVA) is useful to avoid delay in rescue operations. Recently, researchers have developed several algorithms to predict MVA using various features derived from electrocardiogram (ECG). However, there are several unresolved issues regarding MVA prediction such as the effect of number of ECG features on a prediction remaining unclear, possibility that an alert for occurring MVA may arrive very late and uncertainty in the performance of the algorithm predicting MVA minutes before onset. To overcome the aforementioned problems, this research conducts an in-depth study on the number and types of ECG features that are implemented in a decision tree classifier. In addition, this research also investigates an algorithm\u2019s execution time before the occurrence of MVA to minimize delays in warnings for MVA. Lastly, this research aims to study both the sensitivity and specificity of an algorithm to reveal the performance of MVA prediction algorithms from time to time. To strengthen the results of analysis, several classifiers such as support vector machine and naive Bayes are also examined for the purpose of comparison study. There are three phases required to achieve the objectives. The first phase is literature review on existing relevant studies. The second phase deals with design and development of four modules for predicting MVA. Rigorous experiments are performed in the feature selection and classification modules. The results show that eight ECG features with decision tree classifier achieved good prediction performance in terms of execution time and sensitivity. In addition, the results show that the highest percentage for sensitivity and specificity is 95% and 90% respectively, in the fourth 5-minute interval (15.1 minutes\u201320 minutes) that preceded the onset of an arrhythmia event. Such results imply that the fourth 5-minute interval would be the best time to perform prediction. \u00a9 2020 Mandala et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Spontaneous prediction of malignant ventricular arrhythmia (MVA) is useful to avoid delay in rescue operations. Recently, researchers have developed several algorithms to predict MVA using various features derived from electrocardiogram (ECG). However, there are several unresolved issues regarding MVA prediction such as the effect of number of ECG features on a prediction remaining unclear, possibility that an alert for occurring MVA may arrive very late and uncertainty in the performance of the algorithm predicting MVA minutes before onset. To overcome the aforementioned problems, this research conducts an in-depth study on the number and types of ECG features that are implemented in a decision tree classifier. In addition, this research also investigates an algorithm\u2019s execution time before the occurrence of MVA to minimize delays in warnings for MVA. Lastly, this research aims to study both the sensitivity and specificity of an algorithm to reveal the performance of MVA prediction algorithms from time to time. To strengthen the results of analysis, several classifiers such as support vector machine and naive Bayes are also examined for the purpose of comparison study. There are three phases required to achieve the objectives. The first phase is literature review on existing relevant studies. The second phase deals with design and development of four modules for predicting MVA. Rigorous experiments are performed in the feature selection and classification modules. The results show that eight ECG features with decision tree classifier achieved good prediction performance in terms of execution time and sensitivity. In addition, the results show that the highest percentage for sensitivity and specificity is 95% and 90% respectively, in the fourth 5-minute interval (15.1 minutes\u201320 minutes) that preceded the onset of an arrhythmia event. Such results imply that the fourth 5-minute interval would be the best time to perform prediction. \u00a9 2020 Mandala et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited."
        ]
    },
    {
        "judul":[
            "Vertical Axis Wind Turbine Improvement using DC-DC Boost Converter"
        ],
        "penulis":"Khairunnisa, Khairunnisa;Rachman, Syaiful;Yohanes, Edi;Uji Krismanto, Awan;Fadil, Jazuli;Soedibyo, Soedibyo;Ashari, Mochamad;Abuzalata, Mahmoud;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Vertical axis wind turbine (VAWT) can be operated in any direction of wind speed, but it has low rotation. To improve the performance of VAWT in which low rotation, this paper presents a simple control strategy of VAWT using a DC-DC boost converter to tap constant voltage in a standalone application. The main objective of this research is to maintain a constant output voltage of converter despite variation input voltage affected by variable wind speed. A simple proportional-integral (PI) controller has been used for a DC-DC boost converter and tested in MATLAB-Simulink environment, with the closed-loop system of the converter maintain constant output voltage although the wind speed is kept changing. The PI controller obtains the feedback from the output voltage of the boost converter to produce the correct pulse width modulation (PWM) duty cycle and trigger the metal oxide semiconductor field effect transistor (MOSFET) following the reference voltage of the turbine. This system has suppressed the value of overshoot and increased the efficiency of wind turbines as 34 %.  \u00a9 The Authors, published by EDP Sciences, 2020.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Vertical axis wind turbine (VAWT) can be operated in any direction of wind speed, but it has low rotation. To improve the performance of VAWT in which low rotation, this paper presents a simple control strategy of VAWT using a DC-DC boost converter to tap constant voltage in a standalone application. The main objective of this research is to maintain a constant output voltage of converter despite variation input voltage affected by variable wind speed. A simple proportional-integral (PI) controller has been used for a DC-DC boost converter and tested in MATLAB-Simulink environment, with the closed-loop system of the converter maintain constant output voltage although the wind speed is kept changing. The PI controller obtains the feedback from the output voltage of the boost converter to produce the correct pulse width modulation (PWM) duty cycle and trigger the metal oxide semiconductor field effect transistor (MOSFET) following the reference voltage of the turbine. This system has suppressed the value of overshoot and increased the efficiency of wind turbines as 34 %.  \u00a9 The Authors, published by EDP Sciences, 2020."
        ]
    },
    {
        "judul":[
            "Marketing of identity politics in digital world (netnography study on indonesian presidential election 2019)"
        ],
        "penulis":"Mahestu, Gayes;Sumbogo, Tri Adi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia held the General Election of the President and Vice-President in April 2019 with two candidates. This national political succession became a magnet for all Indonesian people to discuss it in daily conversation. Interaction between candidates supporters held in the digital world too. This phenomenon leads to the interaction and conversation of online forums such as political forums in social media. This forum is one of form computer-mediated communication that facilitated interaction between the internal public in the political marketing context. The problem arise when these forums were created to discredit and distribute fake news and hate speech about their political opponents. This study aims to investigate the form of interaction and conversation that contained Ethnic, Religion, Race, and Intergroup issues, then identity politics in Facebook online forums during the 2019 Presidential Election. The research method used the virtual ethnography method by analyzing the Facebook Forums that supporting each candidate. The results show that distribution content on each Facebook Forum strengthening the value of politics identity through news link\/photo with narration, meme, narration, videos, and advertisement. This type of Facebook posting consists of satire, hoax, contention, opinion, campaign, and clarification. The research also find that technological progress and digital literacy are imbalance, so people easily consume, reproduce, and distribute fake news. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia held the General Election of the President and Vice-President in April 2019 with two candidates. This national political succession became a magnet for all Indonesian people to discuss it in daily conversation. Interaction between candidates supporters held in the digital world too. This phenomenon leads to the interaction and conversation of online forums such as political forums in social media. This forum is one of form computer-mediated communication that facilitated interaction between the internal public in the political marketing context. The problem arise when these forums were created to discredit and distribute fake news and hate speech about their political opponents. This study aims to investigate the form of interaction and conversation that contained Ethnic, Religion, Race, and Intergroup issues, then identity politics in Facebook online forums during the 2019 Presidential Election. The research method used the virtual ethnography method by analyzing the Facebook Forums that supporting each candidate. The results show that distribution content on each Facebook Forum strengthening the value of politics identity through news link\/photo with narration, meme, narration, videos, and advertisement. This type of Facebook posting consists of satire, hoax, contention, opinion, campaign, and clarification. The research also find that technological progress and digital literacy are imbalance, so people easily consume, reproduce, and distribute fake news. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Three-stream network with context convolution module for human\u2013object interaction detection"
        ],
        "penulis":"Siadari, Thomhert S.;Han, Mikyong;Yoon, Hyunjin;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Human\u2013object interaction (HOI) detection is a popular computer vision task that detects interactions between humans and objects. This task can be useful in many applications that require a deeper understanding of semantic scenes. Current HOI detection networks typically consist of a feature extractor followed by detection layers comprising small filters (eg, 1\u00a0\u00d7\u00a01 or 3\u00a0\u00d7\u00a03). Although small filters can capture local spatial features with a few parameters, they fail to capture larger context information relevant for recognizing interactions between humans and distant objects owing to their small receptive regions. Hence, we herein propose a three-stream HOI detection network that employs a context convolution module (CCM) in each stream branch. The CCM can capture larger contexts from input feature maps by adopting combinations of large separable convolution layers and residual-based convolution layers without increasing the number of parameters by using fewer large separable filters. We evaluate our HOI detection method using two benchmark datasets, V-COCO and HICO-DET, and demonstrate its state-of-the-art performance. \u00a9 2020 ETRI",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Human\u2013object interaction (HOI) detection is a popular computer vision task that detects interactions between humans and objects. This task can be useful in many applications that require a deeper understanding of semantic scenes. Current HOI detection networks typically consist of a feature extractor followed by detection layers comprising small filters (eg, 1\u00a0\u00d7\u00a01 or 3\u00a0\u00d7\u00a03). Although small filters can capture local spatial features with a few parameters, they fail to capture larger context information relevant for recognizing interactions between humans and distant objects owing to their small receptive regions. Hence, we herein propose a three-stream HOI detection network that employs a context convolution module (CCM) in each stream branch. The CCM can capture larger contexts from input feature maps by adopting combinations of large separable convolution layers and residual-based convolution layers without increasing the number of parameters by using fewer large separable filters. We evaluate our HOI detection method using two benchmark datasets, V-COCO and HICO-DET, and demonstrate its state-of-the-art performance. \u00a9 2020 ETRI"
        ]
    },
    {
        "judul":[
            "Assessment of potential probiotic lactic acid bacteria from tempe and tape"
        ],
        "penulis":"Sulistiani;Novarina I.;Inawati;Dinoto A.;Julistiono H.;Handayani R.;Saputra S.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Probiotics are living organisms with many beneficial effects on the health of host if consumed in sufficient quantities. These beneficial effects have been initiating efforts directed towards exploring strains Lactic Acid Bacteria (LAB) as probiotic from fermented food such tempe and tape. Although several groups of microorganism from fermented foods such as tempe and tape were reported, the potential LAB derived from those food sources is limited. The aim of this study was to assess probiotic candidate from LAB strains isolated from tempe and tape based on in vitro analysis. A total of 30 LAB isolates were tested for probiotic properties including tolerance to bile salt and acid, antimicrobial activity, simulated gastric juice (SGJ) and simulated intestinal juice (SIJ), physiology and enzymatic properties. The results showed eight bacterial isolates (Pediococcus pentosaceus Su-ls13, P. pentosaceus Su-ls14, Enterococcus faecalis Su-ls15, P. pentosaceus Su-ls16, P. pentosaceus Su-ls21, P. pentosaceus Su-ls22, P. pentosaceus Su-ls24 and Lactobacillus plantarum Su-ls29) fulfilled the criteria as probiotic candidates, including the capability of producing antimicrobial activity by inhibiting the growth of 12 pathogenic bacteria, have survivability under the condition of (or high tolerance to) low pH, and being exposed to bile salt, simulated gastric juice and simulated intestinal juice. All isolates were able to grow at NaCl 3-6.5%, 30-45C and produce phytase. In addition, six isolates (Su-ls13, Su-ls14, Su-ls15, Su-ls16, Su-ls21, Su-ls22) were able to produce protease and two isolates (Su-ls22, Su-ls24) were able to produce amylase. \u00a9 the author(s)",
            "CFFF[removed]View detailsExpand Substance trifluoromethyl radical",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Probiotics are living organisms with many beneficial effects on the health of host if consumed in sufficient quantities. These beneficial effects have been initiating efforts directed towards exploring strains Lactic Acid Bacteria (LAB) as probiotic from fermented food such tempe and tape. Although several groups of microorganism from fermented foods such as tempe and tape were reported, the potential LAB derived from those food sources is limited. The aim of this study was to assess probiotic candidate from LAB strains isolated from tempe and tape based on in vitro analysis. A total of 30 LAB isolates were tested for probiotic properties including tolerance to bile salt and acid, antimicrobial activity, simulated gastric juice (SGJ) and simulated intestinal juice (SIJ), physiology and enzymatic properties. The results showed eight bacterial isolates (Pediococcus pentosaceus Su-ls13, P. pentosaceus Su-ls14, Enterococcus faecalis Su-ls15, P. pentosaceus Su-ls16, P. pentosaceus Su-ls21, P. pentosaceus Su-ls22, P. pentosaceus Su-ls24 and Lactobacillus plantarum Su-ls29) fulfilled the criteria as probiotic candidates, including the capability of producing antimicrobial activity by inhibiting the growth of 12 pathogenic bacteria, have survivability under the condition of (or high tolerance to) low pH, and being exposed to bile salt, simulated gastric juice and simulated intestinal juice. All isolates were able to grow at NaCl 3-6.5%, 30-45C and produce phytase. In addition, six isolates (Su-ls13, Su-ls14, Su-ls15, Su-ls16, Su-ls21, Su-ls22) were able to produce protease and two isolates (Su-ls22, Su-ls24) were able to produce amylase. \u00a9 the author(s)"
        ]
    },
    {
        "judul":[
            "The Function of PMO for successful program-project management in the bank company - A case study"
        ],
        "penulis":"Yana, Rika Rizki;Sasongko, Danarto Tri;Wardhana, Aditya Wisnu;Ilona, Kwee Felicia;Shihab, Muhammad Rifki;Ranti, Benny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this paper is to investigate the specific function of Program Management Office (PMO) to manage multiple Kaizen or improvement projects and how we can implement PMO with more effective and more efficient to deliver value, benefits and achieve business goal in bank company. Research indicate that project management become increasingly difficult to manage when multiple projects are many overlapping projects in a project-oriented company, the goal in a need for enhanced bank company controls to increase success rates. It caused with implementation of a system that help project management, the system named Project Management Office (PMO) that is essential for bank company that are project-oriented and faced many overlapping projects. The PMO with an essential model that will explain to us to have management system of multiple project effectively in a banking company. Using a case study in one of banking industry in Indonesia, to test the method of research found that PMO deliver excellent value for bank company. The survey result of PMO function saw that most of project stakeholders in banking company agreed to 5 (five) categories and 20 (twenty) specified of PMO function implementation to manage several banking projects excellent. based on the results of the questionnaire, stakeholders answered more agreeably with the function of PMO for success project management at bank company and it could answer to the question that the method has deliver benefit and create goals for project management office performance in bank company.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this paper is to investigate the specific function of Program Management Office (PMO) to manage multiple Kaizen or improvement projects and how we can implement PMO with more effective and more efficient to deliver value, benefits and achieve business goal in bank company. Research indicate that project management become increasingly difficult to manage when multiple projects are many overlapping projects in a project-oriented company, the goal in a need for enhanced bank company controls to increase success rates. It caused with implementation of a system that help project management, the system named Project Management Office (PMO) that is essential for bank company that are project-oriented and faced many overlapping projects. The PMO with an essential model that will explain to us to have management system of multiple project effectively in a banking company. Using a case study in one of banking industry in Indonesia, to test the method of research found that PMO deliver excellent value for bank company. The survey result of PMO function saw that most of project stakeholders in banking company agreed to 5 (five) categories and 20 (twenty) specified of PMO function implementation to manage several banking projects excellent. based on the results of the questionnaire, stakeholders answered more agreeably with the function of PMO for success project management at bank company and it could answer to the question that the method has deliver benefit and create goals for project management office performance in bank company.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Complete solutions of particle in three dimensional box with variations in main quantum number"
        ],
        "penulis":"Supriadi B.;Nuraini L.;Maulani A.S.R.;Damayanti D.D.;Sugihartin A.F.;Baihaqi M.I.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Particle in a box is one of the applications of the Schrodinger equation. Schrodinger equation gives wave function which is used to determine the probability and expectation value of particle in a box. It is also can explain the energy levels of the particle. This study aimed to determine the probability, expectation values, and energy levels of a particle in a three-dimensional box with variations in main quantum numbers in each coordinate axis. The magnitude of the wave function and energy levels are influenced by the main quantum number and the width of the box. The results show that variations in the main quantum number influence the probability of particle in the three-dimensional box except for the width of the box and L the probability of particle showing the same value in all variations of the main quantum number. Variations in the main quantum number also influence the expectation value of particle in a three-dimensional box except for the width of the box L the expectation value shows the same value in all variations of the main quantum number. All variations of the main quantum number also influence the magnitude of the energy level of the particle. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Particle in a box is one of the applications of the Schrodinger equation. Schrodinger equation gives wave function which is used to determine the probability and expectation value of particle in a box. It is also can explain the energy levels of the particle. This study aimed to determine the probability, expectation values, and energy levels of a particle in a three-dimensional box with variations in main quantum numbers in each coordinate axis. The magnitude of the wave function and energy levels are influenced by the main quantum number and the width of the box. The results show that variations in the main quantum number influence the probability of particle in the three-dimensional box except for the width of the box and L the probability of particle showing the same value in all variations of the main quantum number. Variations in the main quantum number also influence the expectation value of particle in a three-dimensional box except for the width of the box L the expectation value shows the same value in all variations of the main quantum number. All variations of the main quantum number also influence the magnitude of the energy level of the particle. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Dynamic interaction between tidal current and upstream discharge at the Kapuas River mouth"
        ],
        "penulis":"Danial M.M.;Herawati H.;Budiman F.;Ramdani;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper explores the dynamic interaction between tidal current and upstream discharge at the Kapuas River mouth. Long term time series data of tidal current and river discharge obtained from software Windwave 05 and hydrograph data, respectively. Three prominent parameters, i.e., river discharge, tides, and tidal current were analyzed using the wavelet method, Hilbert function, and low pass filter to evaluate the tidal characteristics and phase difference of M2, M4, K1, O1. The relationship between the tidal current and water level shows a mimic standing wave with the phase difference around \u223c -180 - 900, indicating the tidal current leads the water level. The low-pass filter results indicate that the increasing river discharge hampers the tides and reduces the tidal current at the mouth. The Hilbert function result reveals the asymmetric tide and flood dominant flow which has the opposite direction with the seaward direction of the current. Moreover, the subtidal water level flows in a seaward direction. This happened because the net seaward current modulated by the river discharge. The currents at the mouth are affected significantly by the swell wave.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper explores the dynamic interaction between tidal current and upstream discharge at the Kapuas River mouth. Long term time series data of tidal current and river discharge obtained from software Windwave 05 and hydrograph data, respectively. Three prominent parameters, i.e., river discharge, tides, and tidal current were analyzed using the wavelet method, Hilbert function, and low pass filter to evaluate the tidal characteristics and phase difference of M2, M4, K1, O1. The relationship between the tidal current and water level shows a mimic standing wave with the phase difference around \u223c -180 - 900, indicating the tidal current leads the water level. The low-pass filter results indicate that the increasing river discharge hampers the tides and reduces the tidal current at the mouth. The Hilbert function result reveals the asymmetric tide and flood dominant flow which has the opposite direction with the seaward direction of the current. Moreover, the subtidal water level flows in a seaward direction. This happened because the net seaward current modulated by the river discharge. The currents at the mouth are affected significantly by the swell wave.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Wirelessly powered dielectrophoresis of metal oxide particles using spark-gap Tesla coil"
        ],
        "penulis":"Budiman, Faisal;Silalahi, Desri Kristina;Muhamad, Bagaskoro;Fathurahman, Muhammad Rafi;Rozana, Monna;Tanaka, Hirofumi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Wirelessly powered dielectrophoresis (DEP) of metal oxide particles was performed using a spark-gap Tesla coil (TC). The main contribution of this work is the simplification of the conventional DEP setup that requires attaching wires directly to the electrodes. Wireless power from the TC generates a high output frequency and voltage, which corresponds to that used for the DEP. Therefore, a spark-gap TC was built and utilized to conduct the DEP process. Metal oxides (ZnO and Fe2O3) were used as targets for the assembly. The results showed that the wirelessly powered DEP technique via a TC was successful in assembling the metal oxide particles. Positive and negative DEP phenomena were observed. Positive DEP occurred during ZnO assembly, making particles chain grow 0.92\u00a0mm toward the sparks within 60 s. Negative DEP was observed during Fe2O3assembly, where the repulsion of particles formed a void around the sparks with a 1.45\u00a0mm radius. The mechanism of this wireless DEP system is discussed. \u00a9 2020 Wiley-VCH GmbH",
            "CuView detailsExpand Substance copper",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Wirelessly powered dielectrophoresis (DEP) of metal oxide particles was performed using a spark-gap Tesla coil (TC). The main contribution of this work is the simplification of the conventional DEP setup that requires attaching wires directly to the electrodes. Wireless power from the TC generates a high output frequency and voltage, which corresponds to that used for the DEP. Therefore, a spark-gap TC was built and utilized to conduct the DEP process. Metal oxides (ZnO and Fe2O3) were used as targets for the assembly. The results showed that the wirelessly powered DEP technique via a TC was successful in assembling the metal oxide particles. Positive and negative DEP phenomena were observed. Positive DEP occurred during ZnO assembly, making particles chain grow 0.92\u00a0mm toward the sparks within 60 s. Negative DEP was observed during Fe2O3assembly, where the repulsion of particles formed a void around the sparks with a 1.45\u00a0mm radius. The mechanism of this wireless DEP system is discussed. \u00a9 2020 Wiley-VCH GmbH"
        ]
    },
    {
        "judul":[
            "COVID-19 Confirmed Case Correlation Analysis Based on Spearman and Kendall Correlation"
        ],
        "penulis":"Fahrudin, Tora;Wijaya, Dedy Rahman;Agung, Anak Agung Gde;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Corona Virus Disease 2019 (COVID-19), which was declared by World Health organization (WHO) as a pandemic in march 2020, is a severe problem which is faced by 175 countries in the world. This virus is very easily transmitted by close contact and via respiratory droplets produced when people cough or sneeze. Started from Wuhan, it spreads fast to many other countries. This paper investigates the confirmed case analysis of a COVID-19 in all countries based on Spearman and Kendall correlation and grouping those countries which have the same level correlation. There are 134 countries for the shortest period and 16 for the longest period have been evaluated. In the shortest period, 39 and 27 countries have high correlation value based on Spearman and Kendall, respectively. In the longest period, 11 and 6 countries have high correlation value based on Spearman and Kendall, respectively. Those groups indicate that the strength of association of confirmed case between them are similar. The darker color shows there is a high correlation value among those countries. So, by using those groups, the decision-maker can analyze the characteristic of those countries and make the decision better.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Corona Virus Disease 2019 (COVID-19), which was declared by World Health organization (WHO) as a pandemic in march 2020, is a severe problem which is faced by 175 countries in the world. This virus is very easily transmitted by close contact and via respiratory droplets produced when people cough or sneeze. Started from Wuhan, it spreads fast to many other countries. This paper investigates the confirmed case analysis of a COVID-19 in all countries based on Spearman and Kendall correlation and grouping those countries which have the same level correlation. There are 134 countries for the shortest period and 16 for the longest period have been evaluated. In the shortest period, 39 and 27 countries have high correlation value based on Spearman and Kendall, respectively. In the longest period, 11 and 6 countries have high correlation value based on Spearman and Kendall, respectively. Those groups indicate that the strength of association of confirmed case between them are similar. The darker color shows there is a high correlation value among those countries. So, by using those groups, the decision-maker can analyze the characteristic of those countries and make the decision better.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Classification of air pollution levels using artificial neural network"
        ],
        "penulis":"Hamami, Faqih;Fithriyah, Inayatul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Air pollution can be a threat to the human environment. It becomes a global issue in the world for every country. Air pollution is caused by many factors and becomes dangerous if the concentration level exceeds the normal levels. Several gasses including PM10, SO2, CO, O3, and NO2 can be hazard pollution. These gasses concentration can be sensed by IoT sensors. When the concentration is exceeds the threshold, it become unhealthy condition for human life. This paper proposes to classify air pollution level from IoT data for understanding current condition of air quality. This research proposes neural network methods to classify data into three air pollution levels. The neural network architecture is built from a combination of hidden layers, number of neurons and number of epochs. Based on the experiment, the accuracy of the neural network model can achieve up to 96.61%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Air pollution can be a threat to the human environment. It becomes a global issue in the world for every country. Air pollution is caused by many factors and becomes dangerous if the concentration level exceeds the normal levels. Several gasses including PM10, SO2, CO, O3, and NO2 can be hazard pollution. These gasses concentration can be sensed by IoT sensors. When the concentration is exceeds the threshold, it become unhealthy condition for human life. This paper proposes to classify air pollution level from IoT data for understanding current condition of air quality. This research proposes neural network methods to classify data into three air pollution levels. The neural network architecture is built from a combination of hidden layers, number of neurons and number of epochs. Based on the experiment, the accuracy of the neural network model can achieve up to 96.61%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Bipolar disorder classification based on electrocardiogram signal using support vector machine"
        ],
        "penulis":"Ainunhusna, Izzatunnisa;Rizal, Achmad;Sumaryo, Sony;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Bipolar Disorder (BD) is one of kinds of mental disease that is quite common found in Indonesia. Those suffering from this disease will drastically experience a shift in mood in a certain period of time. This shift in mood, in turn, can cause many undesired things. The detection of Bipolar Disorder can be done through various diagnosing methods, one of which is by using EEG (Electroencephalogram) signal or ECG (electrocardiogram). One of the methods to detect BD using the ECG signal is by assessing the heart-rate variability (HRV) in which HRV in the patients of Bipolar Disorder tends to be lower than that of normal persons. In this research, an analysis method of HRV was developed to detect Bipolar Disorder using the ECG signal. The method proposed consisted of notch filter, wavelet decomposition, R-R detection, and HRV analysis using Mean Heart Rate (MHR), Standard Deviation of Normal to Normal (SDNN) and Root Mean Square of successive RR interval differences (RMSSD), and SVM for classification. From the experiment, it was found the highest accuracy of 93.8% using three features and quadratic SVM. This showed that the ability of method designed to differentiate HRV with the high accuracy. Here, the verification using the larger dataset was required to test the consistency of the proposed method. \u00a9 2020 IJSTR.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Bipolar Disorder (BD) is one of kinds of mental disease that is quite common found in Indonesia. Those suffering from this disease will drastically experience a shift in mood in a certain period of time. This shift in mood, in turn, can cause many undesired things. The detection of Bipolar Disorder can be done through various diagnosing methods, one of which is by using EEG (Electroencephalogram) signal or ECG (electrocardiogram). One of the methods to detect BD using the ECG signal is by assessing the heart-rate variability (HRV) in which HRV in the patients of Bipolar Disorder tends to be lower than that of normal persons. In this research, an analysis method of HRV was developed to detect Bipolar Disorder using the ECG signal. The method proposed consisted of notch filter, wavelet decomposition, R-R detection, and HRV analysis using Mean Heart Rate (MHR), Standard Deviation of Normal to Normal (SDNN) and Root Mean Square of successive RR interval differences (RMSSD), and SVM for classification. From the experiment, it was found the highest accuracy of 93.8% using three features and quadratic SVM. This showed that the ability of method designed to differentiate HRV with the high accuracy. Here, the verification using the larger dataset was required to test the consistency of the proposed method. \u00a9 2020 IJSTR."
        ]
    },
    {
        "judul":[
            "Designing Green Procurement based on ERP for Leather Tanning Industry"
        ],
        "penulis":"Fajriani, Mahsya;Ridwan, Ari Yanuar;Saputra, Muhardi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A high population and livestock production in Garut is the beginning of the development leather tanning industry, And now the leather tanning industry is the largest sector industry in Indonesia. A Leather tanning industry has the potential to harm the environment. PT. Elco Indonesia Sejahtera is one of the Leather tanning industry in Garut. They do not have a system to support the activities and it is reported with a paper as documentation. This research will design a green procurement system to minimize hazardous waste.The green procurement system will able to monitor the material and the supplier by using KPI (Key Performance Indicator). To design this green procurement system is by implementing ERP (Enterprise Resource Planning) with SAP Activate method. The Result of this research is an ERP system that is to help all the procurement activity with a green system. And this system is integrated with production, sales and distribution, and reverse logistics. These are will help the industry to monitor the business process.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A high population and livestock production in Garut is the beginning of the development leather tanning industry, And now the leather tanning industry is the largest sector industry in Indonesia. A Leather tanning industry has the potential to harm the environment. PT. Elco Indonesia Sejahtera is one of the Leather tanning industry in Garut. They do not have a system to support the activities and it is reported with a paper as documentation. This research will design a green procurement system to minimize hazardous waste.The green procurement system will able to monitor the material and the supplier by using KPI (Key Performance Indicator). To design this green procurement system is by implementing ERP (Enterprise Resource Planning) with SAP Activate method. The Result of this research is an ERP system that is to help all the procurement activity with a green system. And this system is integrated with production, sales and distribution, and reverse logistics. These are will help the industry to monitor the business process.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The role of trust to enhance the recommendation system based on social network"
        ],
        "penulis":"Abd Alkhalec Tharwat, Muhammed E.;Jacob, Deden Witarsyah;Md Fudzee, Mohd Farhan;Kasim, Shahreen;Ramli, Azizul Azhar;Lubis, Muharman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Recommendation systems or recommender system (RSs) is one of the hottest topics nowadays, which is widely utilized to predict an item to the end-user based on his\/her preferences primary. Recommendation systems applied in many areas mainly in commercial applications. This work aims to collect evidence of utilizing social network information between users to enhance the quality of traditional recommendation system. It provides an overview of traditional and modern approaches used by RSs such as collaborative filter (CF) approach, content-based (CB) approach, and hybrid filter approach. CF is one of the most famous traditional approaches in RSs, which is facing many limitations due to the lack of information available during a performance such as Cold start, Sparsity and Shilling attack. Additionally, this content focused on the role of incorporating a trust relationship from the social network to enhance the weaknesses of CF and achieve better quality in the recommendation process. Trust-aware Recommendation Systems (TaRSs) is a modern approach proposed to overcome the limitations of CF recommendation system in a social network. The trust relationship between users can boost and enhance CF limitations. Many researchers are focusing on trust in the recommendation system but fewer works are highlighting the role of trust in the recommendation system. In the end, limitations, and open issues of the current picture of the recommendation system come across. \u00a9 2020, Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recommendation systems or recommender system (RSs) is one of the hottest topics nowadays, which is widely utilized to predict an item to the end-user based on his\/her preferences primary. Recommendation systems applied in many areas mainly in commercial applications. This work aims to collect evidence of utilizing social network information between users to enhance the quality of traditional recommendation system. It provides an overview of traditional and modern approaches used by RSs such as collaborative filter (CF) approach, content-based (CB) approach, and hybrid filter approach. CF is one of the most famous traditional approaches in RSs, which is facing many limitations due to the lack of information available during a performance such as Cold start, Sparsity and Shilling attack. Additionally, this content focused on the role of incorporating a trust relationship from the social network to enhance the weaknesses of CF and achieve better quality in the recommendation process. Trust-aware Recommendation Systems (TaRSs) is a modern approach proposed to overcome the limitations of CF recommendation system in a social network. The trust relationship between users can boost and enhance CF limitations. Many researchers are focusing on trust in the recommendation system but fewer works are highlighting the role of trust in the recommendation system. In the end, limitations, and open issues of the current picture of the recommendation system come across. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[
            "Syllable-Based Indonesian Lip Reading Model"
        ],
        "penulis":"Kurniawan, Adriana;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Lip reading is a communication method by reading the lips movement of a speaker. It is also called visual speech recognition, which converts a video into a text. The text is consisting of some words or even sentences spoken by the speakers. One of the challenges often encountered in a lip reading is the high variances of inputs. The variances, like facial features and different speed of speech, can decrease the accuracy. Nowadays, deep learning provides promising results in extracting visual features. In order to be able to use a video as the input, a 3D Deep Learning architecture is exploited. Besides, the out-of-vocabulary (OOV) problem also makes the visual speech recognition system harder to apply in the real world. It can only predict the words appear in the dictionary. However, the vocabulary continues to grow each year, especially in the Indonesian language. It is hard to fit all possible words into the system. Hence, a syllable-based model is proposed in this research to handle such a problem. The syllable-based model gives a chance to build a new word that does not appear in the dictionary. The combination of the existing syllable is used to construct a new word. Since the data obtained too small for deep learning, the augmentation process is performed 40 times. Evaluation using the augmented data, the proposed model reaches a high accuracy of 100% for the testing set. An examination using ten OOV words informs that the developed model gives a lower accuracy of 80%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Lip reading is a communication method by reading the lips movement of a speaker. It is also called visual speech recognition, which converts a video into a text. The text is consisting of some words or even sentences spoken by the speakers. One of the challenges often encountered in a lip reading is the high variances of inputs. The variances, like facial features and different speed of speech, can decrease the accuracy. Nowadays, deep learning provides promising results in extracting visual features. In order to be able to use a video as the input, a 3D Deep Learning architecture is exploited. Besides, the out-of-vocabulary (OOV) problem also makes the visual speech recognition system harder to apply in the real world. It can only predict the words appear in the dictionary. However, the vocabulary continues to grow each year, especially in the Indonesian language. It is hard to fit all possible words into the system. Hence, a syllable-based model is proposed in this research to handle such a problem. The syllable-based model gives a chance to build a new word that does not appear in the dictionary. The combination of the existing syllable is used to construct a new word. Since the data obtained too small for deep learning, the augmentation process is performed 40 times. Evaluation using the augmented data, the proposed model reaches a high accuracy of 100% for the testing set. An examination using ten OOV words informs that the developed model gives a lower accuracy of 80%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Optimizing Data Storage in Handling Dynamic Input Fields with JSON String Compression"
        ],
        "penulis":"Darmawan, Irfan;Rahmatulloh, Alam;Nuralam, Iqbal Muhammad Fajar;Rianto;Gunawan, Rohmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Dynamic input fields are a solution for managing multiple input values in a web-based application form. Dynamic multiple image upload is an implementation of the dynamic input field. Handling dynamic upload of multiple images by storing the image path will cause the existence of similar string data in one field in the table stored in the database. Creating a unique table in a database to store dynamic data is a workable solution. However, it is potentially a waste of tables and records, so that the database file size becomes larger and data access speeds are longer. To overcome this problem in this study, string data obtained from the dynamic input field are converted into JSON format and compressed with Zlib, before being saved into the database. The experimental results in this study indicate that the integration of JSON and Zlib can be applied to the handling of dynamic input field forms. The average speed of the data storage process by applying this technique is 50.36% faster than the conventional method. In comparison, the database file size decreased by about 37.58% smaller than using conventional techniques.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Dynamic input fields are a solution for managing multiple input values in a web-based application form. Dynamic multiple image upload is an implementation of the dynamic input field. Handling dynamic upload of multiple images by storing the image path will cause the existence of similar string data in one field in the table stored in the database. Creating a unique table in a database to store dynamic data is a workable solution. However, it is potentially a waste of tables and records, so that the database file size becomes larger and data access speeds are longer. To overcome this problem in this study, string data obtained from the dynamic input field are converted into JSON format and compressed with Zlib, before being saved into the database. The experimental results in this study indicate that the integration of JSON and Zlib can be applied to the handling of dynamic input field forms. The average speed of the data storage process by applying this technique is 50.36% faster than the conventional method. In comparison, the database file size decreased by about 37.58% smaller than using conventional techniques.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Network Fault Effectiveness and Implementation at Service Industry in Indonesia"
        ],
        "penulis":"Lubis, Fahrurrozi;Lubis, Muharman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The efficiency of network administrators have been decreased concurrently due to complexity and heterogeneous of network built in certain environment of company. Actually, large heterogeneous network has created a crisis and conflict for many organizations. Available network tools and solutions are not only expensive but also difficult to install, configure, manage and maintain. This paper discusses the implementation of network fault in the service industry to match with the expectations of stakeholders to be able to achieve the higher efficiency and to carry out proactive processes although the practical truth is often the opposite way. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The efficiency of network administrators have been decreased concurrently due to complexity and heterogeneous of network built in certain environment of company. Actually, large heterogeneous network has created a crisis and conflict for many organizations. Available network tools and solutions are not only expensive but also difficult to install, configure, manage and maintain. This paper discusses the implementation of network fault in the service industry to match with the expectations of stakeholders to be able to achieve the higher efficiency and to carry out proactive processes although the practical truth is often the opposite way. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Comparative Analysis of Load Balancing Dynamic Ratio and Server Ratio Algorithms"
        ],
        "penulis":"Murti, Krisna Wahyu;Riza, Tengku Ahmad;Mulyana, Asep;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Load balancing is a technique for dividing traffic loads and reading the availability of resources on the server. Dividing the traffic load use server hardware such as CPU, memory, and disk. This research designed load balancing using dynamic ratio and ratio algorithms on three types of services namely web server, FTP server, and VoIP server, FTP server, and VoIP server. The highest throughput average value is found in the 3:2 of dynamic ratio algorithm, i.e. 114.18 KB\/s of web server and 118.9 KB\/s of FTP server. The fastest response time average value is the 3:2 ratio algorithm for 8.7 seconds of web server and 32.3 seconds of FTP server. The average results for the least number of request losses are the 1: 1 of ratio algorithm, i.e. web server for 17 request failures, FTP server for 1 file transfer failure, and VoIP server for 0.18% call failure. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Load balancing is a technique for dividing traffic loads and reading the availability of resources on the server. Dividing the traffic load use server hardware such as CPU, memory, and disk. This research designed load balancing using dynamic ratio and ratio algorithms on three types of services namely web server, FTP server, and VoIP server, FTP server, and VoIP server. The highest throughput average value is found in the 3:2 of dynamic ratio algorithm, i.e. 114.18 KB\/s of web server and 118.9 KB\/s of FTP server. The fastest response time average value is the 3:2 ratio algorithm for 8.7 seconds of web server and 32.3 seconds of FTP server. The average results for the least number of request losses are the 1: 1 of ratio algorithm, i.e. web server for 17 request failures, FTP server for 1 file transfer failure, and VoIP server for 0.18% call failure. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "D-ISDET: Double Intensity of Image Shadow Detection and Elimination in Autonomous Vehicle"
        ],
        "penulis":"Risnandar;Wardoyo, Riyo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We nominate the double intensity of image shadow detection and elimination method which is called D-ISDET. It offers to restore the invisible image information in the image which is covered by the shadows. The D-ISDET which supports the certainty of object detection in the autonomous vehicle is running well. Hence, the disparity of the shadowed space and the true non-shadowed space can be distinguished with using the double intensity and threshold methods. Likewise, in the big problem of imprecise detection of low-shadows and the perplexed shadows, the double intensity method is endorsed to reinforce the true shadow spaces, thereby the threshold method abolishes the shadow correctly. The experimental results of D-ISDET performance indicate the enhancement of the BER and RMSE indexes for shadow detection and elimination, respectively. D-ISDET outshines achievement between 0.24% and 1.85% of the shadow area detection and between 1.42% and 3.05% of the shadow-free area detection compared to the other methods. D-ISDET also works out between 4.11% and 16.59% of the shadow elimination and D-ISDET reaches between 0.60% and 16.57% of shadow-free elimination compared to the other methods. D-ISDET also carries out the first-rate performance compared with the other methods. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We nominate the double intensity of image shadow detection and elimination method which is called D-ISDET. It offers to restore the invisible image information in the image which is covered by the shadows. The D-ISDET which supports the certainty of object detection in the autonomous vehicle is running well. Hence, the disparity of the shadowed space and the true non-shadowed space can be distinguished with using the double intensity and threshold methods. Likewise, in the big problem of imprecise detection of low-shadows and the perplexed shadows, the double intensity method is endorsed to reinforce the true shadow spaces, thereby the threshold method abolishes the shadow correctly. The experimental results of D-ISDET performance indicate the enhancement of the BER and RMSE indexes for shadow detection and elimination, respectively. D-ISDET outshines achievement between 0.24% and 1.85% of the shadow area detection and between 1.42% and 3.05% of the shadow-free area detection compared to the other methods. D-ISDET also works out between 4.11% and 16.59% of the shadow elimination and D-ISDET reaches between 0.60% and 16.57% of shadow-free elimination compared to the other methods. D-ISDET also carries out the first-rate performance compared with the other methods. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Project performance analysis using earned value management method in telecommunication"
        ],
        "penulis":"Widiningrum, Adelia;Pratami, Devi;Haryono, Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One of telecommunication project in Indonesia is shut downing the obsolete telecommunication infrastructure such as Sentral Telephone Otomate in Tanjungsari Bandung. This project is a modernization project of fiber optic network for 334 locations in Tanjungsari Sub-district. To compare actual performance of the scope, schedule and cost with planning for making right decisions in project's status and performance, required controlling by using Earned Value Management method since it can integrate these three things at the same time. Status and index of project performance on the 22nd day indicate that project was behind schedule that caused loss revenue of Rp 2,600,000.00 with 98% of delays from planning and project get 94% of overruns budget from issued value with amount of Rp 7,410,000.00. In addition, forecasting is done as a corrective action of past project status and performance. It is estimated that the project duration to complete work is 31 days with total cost for the remaining work (EAC) of Rp. 140,170,00.00 from previous project performance. It is also estimated that cost for remaining work until the project is completed or ETC is Rp. 7,770,000.00 with size of the project's forecasting status is a deficit from VAC value that calculated about (Rp 7,410,000.00) and the project will complete based on the TCPI forecasting calculation. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of telecommunication project in Indonesia is shut downing the obsolete telecommunication infrastructure such as Sentral Telephone Otomate in Tanjungsari Bandung. This project is a modernization project of fiber optic network for 334 locations in Tanjungsari Sub-district. To compare actual performance of the scope, schedule and cost with planning for making right decisions in project's status and performance, required controlling by using Earned Value Management method since it can integrate these three things at the same time. Status and index of project performance on the 22nd day indicate that project was behind schedule that caused loss revenue of Rp 2,600,000.00 with 98% of delays from planning and project get 94% of overruns budget from issued value with amount of Rp 7,410,000.00. In addition, forecasting is done as a corrective action of past project status and performance. It is estimated that the project duration to complete work is 31 days with total cost for the remaining work (EAC) of Rp. 140,170,00.00 from previous project performance. It is also estimated that cost for remaining work until the project is completed or ETC is Rp. 7,770,000.00 with size of the project's forecasting status is a deficit from VAC value that calculated about (Rp 7,410,000.00) and the project will complete based on the TCPI forecasting calculation. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office."
        ]
    },
    {
        "judul":[
            "Maritime Inventory Routing Problem: Application on Discharge the Load of the Ship in Cement Companies to Minimize the Total Transportation Cost"
        ],
        "penulis":"Yusuf, Febryan Khoirun;Ridwan, Ari Yanuar;Pambudi, Hardian Kokoh;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Distribution activities are an important part and very considered in the world of logistics because distribution is one of the key drivers of profits earned by companies. One that is related to distribution is transportation. Transportation refers to moving products from one location to another where the product moves from the beginning of the supply chain to consumers where this transportation will incur costs and is one of the costs that affect the price of a product. This research aims to schedule ship transportation from 3 production ports to 6 consumption ports with a heterogeneous fleet of ships to minimize the total transportation costs in the cement industry companies. Maritime Inventory Routing Problem (MIRP) is a problem of ship scheduling which is not only related to the distribution of products from production ports to consumption ports, it also manages the inventory at these ports and is usually used for bulk industrial products. The method used in this research is MIRP with Mixed-Integer Linear Programming (MILP) approach where this method can minimize the total transportation costs. The results show that the method used can reduce the total waiting time so that the total transportation costs are also reduced.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Distribution activities are an important part and very considered in the world of logistics because distribution is one of the key drivers of profits earned by companies. One that is related to distribution is transportation. Transportation refers to moving products from one location to another where the product moves from the beginning of the supply chain to consumers where this transportation will incur costs and is one of the costs that affect the price of a product. This research aims to schedule ship transportation from 3 production ports to 6 consumption ports with a heterogeneous fleet of ships to minimize the total transportation costs in the cement industry companies. Maritime Inventory Routing Problem (MIRP) is a problem of ship scheduling which is not only related to the distribution of products from production ports to consumption ports, it also manages the inventory at these ports and is usually used for bulk industrial products. The method used in this research is MIRP with Mixed-Integer Linear Programming (MILP) approach where this method can minimize the total transportation costs. The results show that the method used can reduce the total waiting time so that the total transportation costs are also reduced.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Smart Controlling System for Green Centralized Air Conditioner based on System Engineering Approach"
        ],
        "penulis":"Saputra, Muhardi;Sutoyo, Edi;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "System monitoring and remote control is a necessity in order to achieve maximum service for service users. Because of shortcomings in the movement and control of Air Conditioner (AC), which still relies on manual systems, resulting in waste for AC energy released, in addition, there is no system that can monitor and control air conditioners remotely or centrally. Author tries to make the process of monitoring and controlling being centralized through the control room that can be used more easily for officers, specifically related to the AC control unit. In the other hand, energy from the AC can be more monitored. The temperature of the room will be monitored and controlled through a computer in the control room. That will make efficiency of energy used and become Green Air Conditioner, specifically in the use of centralized AC in office buildings. The concept of system that designed based on service-oriented by using the system engineering method as a benchmark in system design. Workflow of the system that created is temperature of the room will be taken by the sensor that installed in each room. Data from the sensor will be processed in the microcontroller and sent to the computer via the internet network, which will be showed in real time by using an internet connection, it will necessary to set the AC temperature from the control room automatically. In addition, web service programs are also used to monitor, control, and schedule centralized AC systems, it will m create more efficiency in the use of AC energy.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "System monitoring and remote control is a necessity in order to achieve maximum service for service users. Because of shortcomings in the movement and control of Air Conditioner (AC), which still relies on manual systems, resulting in waste for AC energy released, in addition, there is no system that can monitor and control air conditioners remotely or centrally. Author tries to make the process of monitoring and controlling being centralized through the control room that can be used more easily for officers, specifically related to the AC control unit. In the other hand, energy from the AC can be more monitored. The temperature of the room will be monitored and controlled through a computer in the control room. That will make efficiency of energy used and become Green Air Conditioner, specifically in the use of centralized AC in office buildings. The concept of system that designed based on service-oriented by using the system engineering method as a benchmark in system design. Workflow of the system that created is temperature of the room will be taken by the sensor that installed in each room. Data from the sensor will be processed in the microcontroller and sent to the computer via the internet network, which will be showed in real time by using an internet connection, it will necessary to set the AC temperature from the control room automatically. In addition, web service programs are also used to monitor, control, and schedule centralized AC systems, it will m create more efficiency in the use of AC energy.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Combined Firefly Algorithm-Random Forest to Classify Autistic Spectrum Disorders"
        ],
        "penulis":"Farrell, Mochammad;Ramadhani, Kurniawan Nur;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Early diagnosis of autistic spectrum disorder, an imperfect neurological development condition, is one way to reduce the sufferer condition. However, the diagnosis of ASD is costly. A popular classification model based on a machine learning technique, such as random forest, can reduce the cost. In general, an RF that is designed by a domain expert gives high accuracy for various datasets. Unfortunately, RF commonly produces a low F1-score for an imbalanced-class dataset. Therefore, in this paper, a firefly algorithm, one of the popular swarm intelligence algorithms, is exploited to automatically design an optimum RF. First, a decision tree is formed based on random features chosen by RF. The decision trees have different features, which cause RF to have new knowledge to classify data continually. The feature used to form a decision tree is 20% of the total attributes. This decision tree is then formed into a forest. Finally, it classifies data using a voting scheme. In FA-based optimization, an individual firefly represents one decision tree. The objective function of a firefly is based on its accuracy. An evaluation using the ASD datasets shows that the proposed combination of FA and RF (FARF) performs better than the original RF for a decision tree of 30. FARF reaches an accuracy of 94.32% and F1-scores of 35.67%, while RF gives an accuracy of 90.78% and F1-scores of 34.09%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Early diagnosis of autistic spectrum disorder, an imperfect neurological development condition, is one way to reduce the sufferer condition. However, the diagnosis of ASD is costly. A popular classification model based on a machine learning technique, such as random forest, can reduce the cost. In general, an RF that is designed by a domain expert gives high accuracy for various datasets. Unfortunately, RF commonly produces a low F1-score for an imbalanced-class dataset. Therefore, in this paper, a firefly algorithm, one of the popular swarm intelligence algorithms, is exploited to automatically design an optimum RF. First, a decision tree is formed based on random features chosen by RF. The decision trees have different features, which cause RF to have new knowledge to classify data continually. The feature used to form a decision tree is 20% of the total attributes. This decision tree is then formed into a forest. Finally, it classifies data using a voting scheme. In FA-based optimization, an individual firefly represents one decision tree. The objective function of a firefly is based on its accuracy. An evaluation using the ASD datasets shows that the proposed combination of FA and RF (FARF) performs better than the original RF for a decision tree of 30. FARF reaches an accuracy of 94.32% and F1-scores of 35.67%, while RF gives an accuracy of 90.78% and F1-scores of 34.09%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Prototyping the li-fi system based on ieee 802.15.7 phy.ii.1 standard compliance"
        ],
        "penulis":"Fuada, Syifaul;Adiono, Trio;Ismail, Fuad;Setiawan, Erwin;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "\u2014By using Visible Light Communication (VLC), in contrast to radio waves, the secure connection can be established more efficiently since the visible light could not radiate through most solid objects. VLC has been applied for many use cases, one of them is Light-Fidelity (Li-Fi). With Li-Fi, internet access is no longer using conventional RF spectrum as employed in Wi-Fi technology but apply visible light. In this paper, we present the design and implementation of a Li-Fi on a System on Chip (SoC) with a low-cost discrete analog front end (AFE). We used ZYBO Zynq-7000 as a digital signal processing, 8 Watt yellow-colored high-brightness LED (HBLED) for downlink transmitter, and 3 Watts infrared LED (IR LED) for uplink transmitter. Our system is developed compliant with the IEEE 802.15.7 standard, i.e. PHY II.1. According to the result, our Li-Fi system makes the PC\/Laptop connected to any internet sources with a maximum speed up to 500 kb\/s, and the maximum optical channel distance (range between the light source and the light receptors) is about 110 cm with two lenses. \u00a9 2020 Journal of Communications.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "\u2014By using Visible Light Communication (VLC), in contrast to radio waves, the secure connection can be established more efficiently since the visible light could not radiate through most solid objects. VLC has been applied for many use cases, one of them is Light-Fidelity (Li-Fi). With Li-Fi, internet access is no longer using conventional RF spectrum as employed in Wi-Fi technology but apply visible light. In this paper, we present the design and implementation of a Li-Fi on a System on Chip (SoC) with a low-cost discrete analog front end (AFE). We used ZYBO Zynq-7000 as a digital signal processing, 8 Watt yellow-colored high-brightness LED (HBLED) for downlink transmitter, and 3 Watts infrared LED (IR LED) for uplink transmitter. Our system is developed compliant with the IEEE 802.15.7 standard, i.e. PHY II.1. According to the result, our Li-Fi system makes the PC\/Laptop connected to any internet sources with a maximum speed up to 500 kb\/s, and the maximum optical channel distance (range between the light source and the light receptors) is about 110 cm with two lenses. \u00a9 2020 Journal of Communications."
        ]
    },
    {
        "judul":[
            "Improved Residual Neural Network for Breast Cancer Classification"
        ],
        "penulis":"Erwandi, Reynold;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Breast cancer is one of the most dangerous types of cancer, especially for women. In 2015, it became the deadliest cancer after lung cancer in America. Some studies found that both self-detection and prevention are important factors in dealing with this cancer. The process of diagnosing breast cancer traditionally takes a long time. Moreover, pathologists are not 100% sure of the results of their diagnosis. Therefore, in this research, a computer-aided system is developed to help doctors to classify cell types based on histopathological images. In this research, a new model based onconvolutional neural networks with an improved Residual Neural Network (ResNet) architecture is proposed to distinguish histopathological images into some classes of breast cancers. Testing on the BreakHis dataset shows that the best performance of the proposed method gives the average accuraciesof 99.3% and 94.6% for binary and eight-class classifications, respectively. These results are comparable to state-of-the-art results in the recent study. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Breast cancer is one of the most dangerous types of cancer, especially for women. In 2015, it became the deadliest cancer after lung cancer in America. Some studies found that both self-detection and prevention are important factors in dealing with this cancer. The process of diagnosing breast cancer traditionally takes a long time. Moreover, pathologists are not 100% sure of the results of their diagnosis. Therefore, in this research, a computer-aided system is developed to help doctors to classify cell types based on histopathological images. In this research, a new model based onconvolutional neural networks with an improved Residual Neural Network (ResNet) architecture is proposed to distinguish histopathological images into some classes of breast cancers. Testing on the BreakHis dataset shows that the best performance of the proposed method gives the average accuraciesof 99.3% and 94.6% for binary and eight-class classifications, respectively. These results are comparable to state-of-the-art results in the recent study. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design of planning model for ERP system in warehouse management: An empirical study of public hospital in Indonesia"
        ],
        "penulis":"Utami F.D.;Puspitasari W.;Saputra M.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Public Hospital is one of the complicated information in the healthcare industry. ERP provides a concept that integrates a whole series of business processes, so they are mutually sustainable as part of business management to achieve the goals of an organization. In line with the hospital's information system, ERP provides a solution for managing data information that runs in hospitals. As one of District Government Hospitals in Indonesia that provide health services, RSUD XYZ does not have an independent information system that manages the hospital's vital data specifically in warehouse management yet. Procurement and management of goods on a regular basis without a system managing in terms of inventory bring through redundancy, ineffective, and inefficient management of data in the warehouse. This research focuses on the planning model system for the public hospital in inventory management business processes, developed using OpenERP at Inventory Management module and QuickStart method. The results of this study is a design of a planning model for inventory management system in the public hospital. This research explains how the ERP system can help improve health services in the public hospital under business processes that should be in the healthcare industry.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Public Hospital is one of the complicated information in the healthcare industry. ERP provides a concept that integrates a whole series of business processes, so they are mutually sustainable as part of business management to achieve the goals of an organization. In line with the hospital's information system, ERP provides a solution for managing data information that runs in hospitals. As one of District Government Hospitals in Indonesia that provide health services, RSUD XYZ does not have an independent information system that manages the hospital's vital data specifically in warehouse management yet. Procurement and management of goods on a regular basis without a system managing in terms of inventory bring through redundancy, ineffective, and inefficient management of data in the warehouse. This research focuses on the planning model system for the public hospital in inventory management business processes, developed using OpenERP at Inventory Management module and QuickStart method. The results of this study is a design of a planning model for inventory management system in the public hospital. This research explains how the ERP system can help improve health services in the public hospital under business processes that should be in the healthcare industry.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Recycling of Wood Saw Dust Waste as Green Pore Forming Agent for Porous Ceramic"
        ],
        "penulis":"Zakaria, Siti Koriah;Hakim Md Zulkifli, Muhammad Luqman;Azhar Taib, Mustaffa Ali;Budiman, Faisal;Mohamed, Mazlan;Ali, Arlina;Yusoff, Abdul Hafidz;Teo, Pao Ter;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Porous ceramic fabrication using natural pore forming agents have received more and more attention in the past few years. However, researchers have encountered an issue with an inconsistent particle size, which led to uneven pore distribution. Considering waste material as pore forming agent, this research seeks to explore the potential application of wood sawdust in porous ceramic production. Moreover, the effects of wood sawdust weight percentage (wt.%) and firing temperature towards the physical and mechanical properties of porous ceramic will also be investigated. Porous ceramic was fabricated by introducing two different proportions of wood sawdust (10 and 20 wt.%) into China clay, followed by drying at 110\u00b0C and firing at 900\u00b0C. The characterization analyses were performed by means of Fourier Transform Infrared spectroscopy, water absorption, apparent porosity, bulk density, and X-Ray Diffraction. The results showed that the compressive strength appears to decrease as the composition of the waste wood sawdust increases. Relatively, the water absorption value increases as the wood sawdust incorporation increased. This is because more porosity formation is observed at a higher sawdust ratio, leading to a lower density of the ceramic. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Porous ceramic fabrication using natural pore forming agents have received more and more attention in the past few years. However, researchers have encountered an issue with an inconsistent particle size, which led to uneven pore distribution. Considering waste material as pore forming agent, this research seeks to explore the potential application of wood sawdust in porous ceramic production. Moreover, the effects of wood sawdust weight percentage (wt.%) and firing temperature towards the physical and mechanical properties of porous ceramic will also be investigated. Porous ceramic was fabricated by introducing two different proportions of wood sawdust (10 and 20 wt.%) into China clay, followed by drying at 110\u00b0C and firing at 900\u00b0C. The characterization analyses were performed by means of Fourier Transform Infrared spectroscopy, water absorption, apparent porosity, bulk density, and X-Ray Diffraction. The results showed that the compressive strength appears to decrease as the composition of the waste wood sawdust increases. Relatively, the water absorption value increases as the wood sawdust incorporation increased. This is because more porosity formation is observed at a higher sawdust ratio, leading to a lower density of the ceramic. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Demand Forecasting for Drinking Water Products to Reduce Gap between Estimation and Realization of Demand Using Artificial Neural Network (ANN) Methods in PT. XYZ"
        ],
        "penulis":"Syafitri, Rizka Cahya;Ridwan, Ari Yanuar;Novitasari, Nia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Supply Chain has components such as vendors, manufacturers, factories, warehouses retailers, customers, etc. Every relationship between components must have good information in order to create informed business decisions. Sales forecast are part of a decline in supply chain function and are a way to predict future product sales. The large gap between demand forecasting and actual demand proves that the forecasting method used in forecasting is not quite right so it can cause high error rates. In this study, the calculation of demand forecasting using the Artificial Neural Network (ANN) method was chosen as a good method because ANN learning method that works through an iterative process using training data comparing the predicted value of the network each sample of data and the weight of the network relation in each process is modified to minimize the value of Mean Squared Error (MSE). With the right parameters and good training in the data, the error number at the ANN calculation output using MATLAB will produce demand forecasting numbers that are getting closer to the actual demand numbers. The application of the ANN method to demand forecasting can make improvements to the error value performance using the MSE, MAD equation. and MAPE. The decline in MSE in 2018 from 1,894,299,389 to 26,612,567, in 2019 from 1,035,177,794 to 16,889,433, and in 2020 from 426,876,921 to 2,647,350. The decline in MAD in 2018 from 42,089 to 3,324, in 2019 from 26,924 to 2,888, and in 2020 from 20,661 to 1,627. MAPE reduction in 2018 from 23% to 2%, 2019 from 15% to 2%, and in 2020 from 11% to 1%. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Supply Chain has components such as vendors, manufacturers, factories, warehouses retailers, customers, etc. Every relationship between components must have good information in order to create informed business decisions. Sales forecast are part of a decline in supply chain function and are a way to predict future product sales. The large gap between demand forecasting and actual demand proves that the forecasting method used in forecasting is not quite right so it can cause high error rates. In this study, the calculation of demand forecasting using the Artificial Neural Network (ANN) method was chosen as a good method because ANN learning method that works through an iterative process using training data comparing the predicted value of the network each sample of data and the weight of the network relation in each process is modified to minimize the value of Mean Squared Error (MSE). With the right parameters and good training in the data, the error number at the ANN calculation output using MATLAB will produce demand forecasting numbers that are getting closer to the actual demand numbers. The application of the ANN method to demand forecasting can make improvements to the error value performance using the MSE, MAD equation. and MAPE. The decline in MSE in 2018 from 1,894,299,389 to 26,612,567, in 2019 from 1,035,177,794 to 16,889,433, and in 2020 from 426,876,921 to 2,647,350. The decline in MAD in 2018 from 42,089 to 3,324, in 2019 from 26,924 to 2,888, and in 2020 from 20,661 to 1,627. MAPE reduction in 2018 from 23% to 2%, 2019 from 15% to 2%, and in 2020 from 11% to 1%. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Using hierarchical likelihood towards support vector machine: Theory and its application"
        ],
        "penulis":"Caraka, Rezzy Eko;Lee, Youngjo;Chen, Rung Ching;Toharudin, Toni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The H-likelihood method proposed by Lee and Nelder (1996) is extensively used in a wide range of data. In terms of direction, repetitive measured data within classification can be examined employing hierarchical generalized linear models (HGLMs). Whether we are concerned in multiple endpoints which are correlated, instead Multivariate Double Hierarchical Generalized Linear Models (DHGLM) can be taken into consideration. This paper addresses the implementation of this principle to vector selection and support machines. Based on the analysis with the fish morphology class Sardinella lemuru (Bali sardinella) and setting the best epsilon 0.7 cost 4 parameter reaching best performance: 0.2327401. Predictive value of fish sex was calculated 0.997319 and Region under the curve: 0.8967. At the same time, we extend the large-scale case studies for stress testing of the SVM method by using three datasets from UCI machine learning repository including the Bank marketing dataset, the car evaluation database and Human Activity Recognition Using Smartphones dataset. In a nutshell by employing SVM-DHGLM increased the accuracy, precision, recall, for feature selection and classification. Long story short, the H-likelihood provides an excellent and usable structure for statistical inference of the unobservable general deterministic model, while preserving the advantages of the original probability structure for fixed parameters. We presume that more new groups of models will be created and that the H-likelihood will be commonly used for their inferences and the application in big data and machine learning. \u00a9 2020 BMJ Publishing Group. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The H-likelihood method proposed by Lee and Nelder (1996) is extensively used in a wide range of data. In terms of direction, repetitive measured data within classification can be examined employing hierarchical generalized linear models (HGLMs). Whether we are concerned in multiple endpoints which are correlated, instead Multivariate Double Hierarchical Generalized Linear Models (DHGLM) can be taken into consideration. This paper addresses the implementation of this principle to vector selection and support machines. Based on the analysis with the fish morphology class Sardinella lemuru (Bali sardinella) and setting the best epsilon 0.7 cost 4 parameter reaching best performance: 0.2327401. Predictive value of fish sex was calculated 0.997319 and Region under the curve: 0.8967. At the same time, we extend the large-scale case studies for stress testing of the SVM method by using three datasets from UCI machine learning repository including the Bank marketing dataset, the car evaluation database and Human Activity Recognition Using Smartphones dataset. In a nutshell by employing SVM-DHGLM increased the accuracy, precision, recall, for feature selection and classification. Long story short, the H-likelihood provides an excellent and usable structure for statistical inference of the unobservable general deterministic model, while preserving the advantages of the original probability structure for fixed parameters. We presume that more new groups of models will be created and that the H-likelihood will be commonly used for their inferences and the application in big data and machine learning. \u00a9 2020 BMJ Publishing Group. All rights reserved."
        ]
    },
    {
        "judul":[
            "One-step direct fabrication of manganese oxide electrodes by low-temperature thermal decomposition of manganese formate-amine ink for supercapacitors"
        ],
        "penulis":"Yabuki, Akihiro;Matsuo, Yuki;Kang, Soonchul;Wahyudhin Fathona, Indra;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A one-step direct fabrication of thin-film manganese oxide electrodes was accomplished via low-temperature thermal decomposition of inks composed of manganese formate (Mnf), alkylamines, and hexanol. As complexing agents, amines were used in molar ratios of Mnf:amine that ranged from 1:1 to 1:4. Prepared inks were directly coated onto the substrate, and then calcined at 170\u2013210 \u00b0C under air. Cyclic voltammetry and charge\/discharge measurements of the thin films were conducted in an electrolyte solution. Following immersion, the specific capacitance of the electrodes increased and eventually reached a constant value. Based on the results of cyclic voltammetry (CV) at 1 mV s\u22121, a thin-film electrode fabricated at 180 \u00b0C from Mnf-octylamine-hexanol ink at a molar ratio of 1:3:0.5 had the highest level of specific capacitance at 400 F g\u22121. CV measurement at 1000 cycles revealed a deterioration of specific capacitance of only 5%, which indicates good stability for this thin-film electrode. \u00a9 2020 Elsevier B.V.",
            "OOMn2View detailsExpand Substance manganese(II) formateOONH2Mn2View detailsExpand Substance MangancarbamatH2NCH3View detailsExpand Substance n-NonylaminH2NCH3View detailsExpand Substance 1-HeptylamineNH2H3CView detailsExpand Substance n-OctylamineOHONView detailsExpand Substance nicotinic acidManganese oxideView detailsExpand Substance manganese oxideManganese dioxideView detailsExpand Substance manganese dioxide",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A one-step direct fabrication of thin-film manganese oxide electrodes was accomplished via low-temperature thermal decomposition of inks composed of manganese formate (Mnf), alkylamines, and hexanol. As complexing agents, amines were used in molar ratios of Mnf:amine that ranged from 1:1 to 1:4. Prepared inks were directly coated onto the substrate, and then calcined at 170\u2013210 \u00b0C under air. Cyclic voltammetry and charge\/discharge measurements of the thin films were conducted in an electrolyte solution. Following immersion, the specific capacitance of the electrodes increased and eventually reached a constant value. Based on the results of cyclic voltammetry (CV) at 1 mV s\u22121, a thin-film electrode fabricated at 180 \u00b0C from Mnf-octylamine-hexanol ink at a molar ratio of 1:3:0.5 had the highest level of specific capacitance at 400 F g\u22121. CV measurement at 1000 cycles revealed a deterioration of specific capacitance of only 5%, which indicates good stability for this thin-film electrode. \u00a9 2020 Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Discovering the Influencing Factors of Trust on Social Commerce in the Jastip Business Model"
        ],
        "penulis":"Nefiratika, Afifah;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, social media does not only have functions to communicate with family and friends but also has a function as a place to do business. Online shopping activities carried out on social media are called social commerce. One of the social commerce business models is currently being carried out on social media is the Jastip business. However, the high level of risk and uncertainty in Jastip makes it difficult for Jastip businesses to gain customer trust. This research aims to identify the factors that influence customer trust in Jastip market on social media. Data obtained through the distribution of questionnaires to 213 respondents who have social media and know Jastip business. Data was collected and analyzed by PLS-SEM using SmartPLS3. Based on the results of the analysis of key opinion leaders (an expert in a particular field), emotional support, endorsements by social media influencers, familiarity, and word of mouth (recommendations and comments) can influence trust in Jastip business on social media positively. The results of this study can be used as input to be able to determine the best strategy to be able to gain customer trust on social media.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, social media does not only have functions to communicate with family and friends but also has a function as a place to do business. Online shopping activities carried out on social media are called social commerce. One of the social commerce business models is currently being carried out on social media is the Jastip business. However, the high level of risk and uncertainty in Jastip makes it difficult for Jastip businesses to gain customer trust. This research aims to identify the factors that influence customer trust in Jastip market on social media. Data obtained through the distribution of questionnaires to 213 respondents who have social media and know Jastip business. Data was collected and analyzed by PLS-SEM using SmartPLS3. Based on the results of the analysis of key opinion leaders (an expert in a particular field), emotional support, endorsements by social media influencers, familiarity, and word of mouth (recommendations and comments) can influence trust in Jastip business on social media positively. The results of this study can be used as input to be able to determine the best strategy to be able to gain customer trust on social media.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance analysis of software defined network using intent monitor and reroute method on ONOS controller"
        ],
        "penulis":"Monika, Putri;Negara, Ridha Muldina;Sanjoyo, Danu Dwi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Software Defined Network (SDN) provides high service flexibility to optimize network configuration based on network traffic. Traffic management able to solve traffic density in SDN. However, it will misuse the network bandwidth and links. One variant of the SDN controller, namely Open Network Operating System (ONOS), provides an Intent Monitor and Reroute (IMR) method that can optimize traffic management based on the description of an object in the ONOS application. This method can optimize the network bandwidth and links of SDN. The IMR can monitor the network and reconfigure the network to restore network connectivity by maximizing the use of each link when transmitting data. This study examines the impact of using IMR with a custom topology on ONOS to find the best scenario by performing traffic management on a data plane consisting of switches totaling 8-12 switches. The parameters measured in this study are bandwidth usage and quality of service (QoS). The results obtained in this study are IMR able to optimize the use of each link and maximize bandwidth usage in a network when distributing data and following TIPHON standards. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Software Defined Network (SDN) provides high service flexibility to optimize network configuration based on network traffic. Traffic management able to solve traffic density in SDN. However, it will misuse the network bandwidth and links. One variant of the SDN controller, namely Open Network Operating System (ONOS), provides an Intent Monitor and Reroute (IMR) method that can optimize traffic management based on the description of an object in the ONOS application. This method can optimize the network bandwidth and links of SDN. The IMR can monitor the network and reconfigure the network to restore network connectivity by maximizing the use of each link when transmitting data. This study examines the impact of using IMR with a custom topology on ONOS to find the best scenario by performing traffic management on a data plane consisting of switches totaling 8-12 switches. The parameters measured in this study are bandwidth usage and quality of service (QoS). The results obtained in this study are IMR able to optimize the use of each link and maximize bandwidth usage in a network when distributing data and following TIPHON standards. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Developing web-based e-news application as an it-based facility"
        ],
        "penulis":"Kartawinata, Budi Rustandi;Pradana, Mahir;Maharani, Dyah;Nugraha, Diki Wahyu;Helmi, M. Yusril;Saputra, M. Harry K.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information technology is one of the fastest growing technologies at this time. With the advancement of information technology, access to data or information available can take place quickly, efficiently and accurately. The function and purpose of this application is to provide convenience in posting articles in a web to provide information processing convenience by using CI-based web services. This application is made with web-based and uses the PHP programming language, in addition to using the PHP and MySQL programming languages as the database. In making this application adjusted Web-Based E-News Development as a Means of Information Technology. Information with website-based and by using the Mysql database to collect data on active users, posting with categories, clear and accurate information, making it easier for readers to find out information on E-News web users and any information will be known by visitors who have subscribed via the website. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information technology is one of the fastest growing technologies at this time. With the advancement of information technology, access to data or information available can take place quickly, efficiently and accurately. The function and purpose of this application is to provide convenience in posting articles in a web to provide information processing convenience by using CI-based web services. This application is made with web-based and uses the PHP programming language, in addition to using the PHP and MySQL programming languages as the database. In making this application adjusted Web-Based E-News Development as a Means of Information Technology. Information with website-based and by using the Mysql database to collect data on active users, posting with categories, clear and accurate information, making it easier for readers to find out information on E-News web users and any information will be known by visitors who have subscribed via the website. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "Assessment of potential probiotic lactic acid bacteria from tempe and tape"
        ],
        "penulis":"Sulistiani;Novarina I.;Inawati;Dinoto A.;Julistiono H.;Handayani R.;Saputra S.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Probiotics are living organisms with many beneficial effects on the health of host if consumed in sufficient quantities. These beneficial effects have been initiating efforts directed towards exploring strains Lactic Acid Bacteria (LAB) as probiotic from fermented food such tempe and tape. Although several groups of microorganism from fermented foods such as tempe and tape were reported, the potential LAB derived from those food sources is limited. The aim of this study was to assess probiotic candidate from LAB strains isolated from tempe and tape based on in vitro analysis. A total of 30 LAB isolates were tested for probiotic properties including tolerance to bile salt and acid, antimicrobial activity, simulated gastric juice (SGJ) and simulated intestinal juice (SIJ), physiology and enzymatic properties. The results showed eight bacterial isolates (Pediococcus pentosaceus Su-ls13, P. pentosaceus Su-ls14, Enterococcus faecalis Su-ls15, P. pentosaceus Su-ls16, P. pentosaceus Su-ls21, P. pentosaceus Su-ls22, P. pentosaceus Su-ls24 and Lactobacillus plantarum Su-ls29) fulfilled the criteria as probiotic candidates, including the capability of producing antimicrobial activity by inhibiting the growth of 12 pathogenic bacteria, have survivability under the condition of (or high tolerance to) low pH, and being exposed to bile salt, simulated gastric juice and simulated intestinal juice. All isolates were able to grow at NaCl 3-6.5%, 30-45C and produce phytase. In addition, six isolates (Su-ls13, Su-ls14, Su-ls15, Su-ls16, Su-ls21, Su-ls22) were able to produce protease and two isolates (Su-ls22, Su-ls24) were able to produce amylase. \u00a9 the author(s)",
            "CFFF[removed]View detailsExpand Substance trifluoromethyl radical",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Probiotics are living organisms with many beneficial effects on the health of host if consumed in sufficient quantities. These beneficial effects have been initiating efforts directed towards exploring strains Lactic Acid Bacteria (LAB) as probiotic from fermented food such tempe and tape. Although several groups of microorganism from fermented foods such as tempe and tape were reported, the potential LAB derived from those food sources is limited. The aim of this study was to assess probiotic candidate from LAB strains isolated from tempe and tape based on in vitro analysis. A total of 30 LAB isolates were tested for probiotic properties including tolerance to bile salt and acid, antimicrobial activity, simulated gastric juice (SGJ) and simulated intestinal juice (SIJ), physiology and enzymatic properties. The results showed eight bacterial isolates (Pediococcus pentosaceus Su-ls13, P. pentosaceus Su-ls14, Enterococcus faecalis Su-ls15, P. pentosaceus Su-ls16, P. pentosaceus Su-ls21, P. pentosaceus Su-ls22, P. pentosaceus Su-ls24 and Lactobacillus plantarum Su-ls29) fulfilled the criteria as probiotic candidates, including the capability of producing antimicrobial activity by inhibiting the growth of 12 pathogenic bacteria, have survivability under the condition of (or high tolerance to) low pH, and being exposed to bile salt, simulated gastric juice and simulated intestinal juice. All isolates were able to grow at NaCl 3-6.5%, 30-45C and produce phytase. In addition, six isolates (Su-ls13, Su-ls14, Su-ls15, Su-ls16, Su-ls21, Su-ls22) were able to produce protease and two isolates (Su-ls22, Su-ls24) were able to produce amylase. \u00a9 the author(s)"
        ]
    },
    {
        "judul":[
            "Human-Like Constrained-Mating to Make Genetic Algorithm More Explorative"
        ],
        "penulis":"Rizal, Achmad Choirul;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A genetic algorithm (GA) is widely used to solve many optimization problems. It does not promise accurate results but provides an acceptable ones in various practical applications. Sometimes, it is trapped at a premature convergence or a local optimum for a complex problem. Hence, a Human-Like Constrained-Mating Genetic Algorithm (HLCMGA) is proposed in this paper to tackle such a problem. HLCMGA can be simply described as a crossover with human-like constrained mating to improve exploration ability. Computer simulation on ten benchmark multi-modal functions shows that it performs better than the simple GA (SGA). Compared to a state-of-the-art Rao algorithm on five benchmark functions, it reaches the same performances on the four functions and just loses on one function. The simulation also informs that it has a higher exploration ability to converge at the global optimum on various complex search spaces.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A genetic algorithm (GA) is widely used to solve many optimization problems. It does not promise accurate results but provides an acceptable ones in various practical applications. Sometimes, it is trapped at a premature convergence or a local optimum for a complex problem. Hence, a Human-Like Constrained-Mating Genetic Algorithm (HLCMGA) is proposed in this paper to tackle such a problem. HLCMGA can be simply described as a crossover with human-like constrained mating to improve exploration ability. Computer simulation on ten benchmark multi-modal functions shows that it performs better than the simple GA (SGA). Compared to a state-of-the-art Rao algorithm on five benchmark functions, it reaches the same performances on the four functions and just loses on one function. The simulation also informs that it has a higher exploration ability to converge at the global optimum on various complex search spaces.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Hate speech detection in Indonesian language instagram"
        ],
        "penulis":"Putra, I. Gede Manggala;Nurjanah, Dade;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Hate speech is a form of communication which contains hatred by doing things, such as inciting, insulting, disparaging, or demeaning a person or group. Hate speech issues in Indonesia often have linkages to politics. In 2018 and 2019, for example, the hate speech relates to the local leader and presidential elections. The hate speech actors commonly use social networks, such as Instagram, to spread their hatred words. About 60% of hate speech is found in the comments of the posts and it will be a real threat if not quickly detected. Our study aims to detect hate speech in Instagram comments. We propose the use of a word2vec method with skip-gram models and a modified TextCNN to learn and detect hate speech texts. Furthermore, random oversampling, random under sampling, and class weight was used to solve imbalanced dataset problems. The results show that the best accuracy, in term of F-score, is 93.70%, gained from a combination of word2vec skip-gram with window size 15, a modified TextCNN, and random oversampling methods. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hate speech is a form of communication which contains hatred by doing things, such as inciting, insulting, disparaging, or demeaning a person or group. Hate speech issues in Indonesia often have linkages to politics. In 2018 and 2019, for example, the hate speech relates to the local leader and presidential elections. The hate speech actors commonly use social networks, such as Instagram, to spread their hatred words. About 60% of hate speech is found in the comments of the posts and it will be a real threat if not quickly detected. Our study aims to detect hate speech in Instagram comments. We propose the use of a word2vec method with skip-gram models and a modified TextCNN to learn and detect hate speech texts. Furthermore, random oversampling, random under sampling, and class weight was used to solve imbalanced dataset problems. The results show that the best accuracy, in term of F-score, is 93.70%, gained from a combination of word2vec skip-gram with window size 15, a modified TextCNN, and random oversampling methods. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Work loyalty: Organizational commitment or compulsion"
        ],
        "penulis":"Rizki, Maulidyah Amalina;Aisyah, Siti;Pristyadi, Budiyono;Sukaris, Sukaris;Handayani, Anita;Hidayati, Roziana Ainul;Santoso, Rahmat Agus;Himawan, Abdurrahman Faris Indriya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, the company is facing a challenge in managing human resources, on the one hand, the company hopes to get employees who are loyal to their work, but sometimes measuring loyalty becomes very difficult because it is not only measured by the willingness to linger i n work but also the loyalty that results in productivity. The purpose of this study is to find out employee loyalty in work as loyalty or compulsion. Analytical techniques using phenomenological studies with stages of data reduction, data display and making conclusions. The results showed that employees have a work loyalty to the company that is due to the comfort in working, co-workers who are compact, closeness to colleagues who are like family, salary and benefits, and the last is a supportive work environment. Another finding is that the dominant factor in influencing employee work loyalty is an organizational commitment and the absence of compulsion at work. \u00a9 IJSTR 2020.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, the company is facing a challenge in managing human resources, on the one hand, the company hopes to get employees who are loyal to their work, but sometimes measuring loyalty becomes very difficult because it is not only measured by the willingness to linger i n work but also the loyalty that results in productivity. The purpose of this study is to find out employee loyalty in work as loyalty or compulsion. Analytical techniques using phenomenological studies with stages of data reduction, data display and making conclusions. The results showed that employees have a work loyalty to the company that is due to the comfort in working, co-workers who are compact, closeness to colleagues who are like family, salary and benefits, and the last is a supportive work environment. Another finding is that the dominant factor in influencing employee work loyalty is an organizational commitment and the absence of compulsion at work. \u00a9 IJSTR 2020."
        ]
    },
    {
        "judul":[
            "Data pixelization for predicting completion time of events"
        ],
        "penulis":"Kamal, Imam Mustafa;Bae, Hyerim;Utama, Nur Ichsan;Yulim, Choi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, a company uses many sensors to record its entire activity process; the recorded data are called event-log. However, event-log prevalently contains discrete data that many powerful machine-learning algorithms are unable to deal with. One-hot encoding is an outstanding method for transforming discrete data into a binary vector. Nonetheless, if there are many distinct values, the problem of dimensionality will be incurred. To tackle this issue, we propose a new approach, called the Pixelization method, which transforms event data into images. We experimentally performed causal inference for prediction of pixels (representing the processing time of each event) by using a generative model with our novel convolution technique. We compared our approach with a baseline method, one-hot encoding, and an entity-embedded approach combined with a neural network model. The results showed that our approach outperforms the state-of-the-art methods in terms of accuracy. \u00a9 2019 Elsevier B.V.",
            "SNSSNView detailsExpand Substance 2-(thiocyanomethylthio)benzothiazole",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, a company uses many sensors to record its entire activity process; the recorded data are called event-log. However, event-log prevalently contains discrete data that many powerful machine-learning algorithms are unable to deal with. One-hot encoding is an outstanding method for transforming discrete data into a binary vector. Nonetheless, if there are many distinct values, the problem of dimensionality will be incurred. To tackle this issue, we propose a new approach, called the Pixelization method, which transforms event data into images. We experimentally performed causal inference for prediction of pixels (representing the processing time of each event) by using a generative model with our novel convolution technique. We compared our approach with a baseline method, one-hot encoding, and an entity-embedded approach combined with a neural network model. The results showed that our approach outperforms the state-of-the-art methods in terms of accuracy. \u00a9 2019 Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Optimization of distance formula in k-nearest neighbor method"
        ],
        "penulis":"Lubis, Arif Ridho;Lubis, Muharman;Al-Khowarizmi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "K-Nearest Neighbor (KNN) is a method applied in classifying objects based on learning data that is closest to the object based on comparison between previous and current data. In the learning process, KNN calculates the distance of the nearest neighbor by applying the euclidean distance formula, while in other methods, optimization has been done on the distance formula by comparing it with the other similar in order to get optimal results. This study will discuss the calculation of the euclidean distance formula in KNN compared with the normalized euclidean distance, manhattan and normalized manhattan to achieve optimization results or optimal value in finding the distance of the nearest neighbor. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "K-Nearest Neighbor (KNN) is a method applied in classifying objects based on learning data that is closest to the object based on comparison between previous and current data. In the learning process, KNN calculates the distance of the nearest neighbor by applying the euclidean distance formula, while in other methods, optimization has been done on the distance formula by comparing it with the other similar in order to get optimal results. This study will discuss the calculation of the euclidean distance formula in KNN compared with the normalized euclidean distance, manhattan and normalized manhattan to achieve optimization results or optimal value in finding the distance of the nearest neighbor. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Influence of sputtering temperature of TiO2deposited onto reduced graphene oxide nanosheet as efficient photoanodes in dye-sensitized solar cells"
        ],
        "penulis":"Low, Foo Wah;Hock, Goh Chin;Kashif, Muhammad;Samsudin, Nurul Asma;Chau, Chien Fat;Utami, Amaliyah Rohsari Indah;Islam, Mohammad Aminul;Heah, Cheng Yong;Liew, Yun Ming;Lai, Chin Wei;Amin, Nowshad;Tiong, Sieh Kiong;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Renewable solar energy is the key target to reduce fossil fuel consumption, minimize global warming issues, and indirectly minimizes erratic weather patterns. Herein, the authors synthesized an ultrathin reduced graphene oxide (rGO) nanosheet with ~47 nm via an improved Hummer\u2019s method. The TiO2was deposited by RF sputtering onto an rGO nanosheet with a variation of temperature to enhance the photogenerated electron or charge carrier mobility transport for the photoanode component. The morphology, topologies, element composition, crystallinity as well as dye-sensitized solar cells\u2019 (DSSCs) performance were determined accordingly. Based on the results, FTIR spectra revealed presence of Ti-O-C bonds in every rGO-TiO2nanocomposite samples at 800 cm\u20131. Besides, XRD revealed that a broad peak of anatase TiO2was detected at ~25.4\u25e6after incorporation with the rGO. Furthermore, it was discovered that sputtering temperature of 120\u25e6C created a desired power conversion energy (PCE) of 7.27% based on the J-V plot. Further increase of the sputtering temperature to 160\u25e6C and 200\u25e6C led to excessive TiO2growth on the rGO nanosheet, thus resulting in undesirable charge recombination formed at the photoanode in the DSSC device. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Renewable solar energy is the key target to reduce fossil fuel consumption, minimize global warming issues, and indirectly minimizes erratic weather patterns. Herein, the authors synthesized an ultrathin reduced graphene oxide (rGO) nanosheet with ~47 nm via an improved Hummer\u2019s method. The TiO2was deposited by RF sputtering onto an rGO nanosheet with a variation of temperature to enhance the photogenerated electron or charge carrier mobility transport for the photoanode component. The morphology, topologies, element composition, crystallinity as well as dye-sensitized solar cells\u2019 (DSSCs) performance were determined accordingly. Based on the results, FTIR spectra revealed presence of Ti-O-C bonds in every rGO-TiO2nanocomposite samples at 800 cm\u20131. Besides, XRD revealed that a broad peak of anatase TiO2was detected at ~25.4\u25e6after incorporation with the rGO. Furthermore, it was discovered that sputtering temperature of 120\u25e6C created a desired power conversion energy (PCE) of 7.27% based on the J-V plot. Further increase of the sputtering temperature to 160\u25e6C and 200\u25e6C led to excessive TiO2growth on the rGO nanosheet, thus resulting in undesirable charge recombination formed at the photoanode in the DSSC device. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Principal Component Analysis to Determine Main Factors Stock Price of Consumer Goods Industry"
        ],
        "penulis":"Fitriyana, Rahma Firsty;Rikumahu, Brady;Widiyanesti;Alamsyah, Andry;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The ability to predict the stock price is the important factor in achieving the profit in stock investment, and the prediction is usually done by relating the price of a stock to factors that influence it. The problem is, there are a large number of variables that can be used to predict the stock prices so it is difficult for a potential investor to choose which variables should be used in predicting the stock prices. This research used the Principal Component Analysis as the dimension reduction method to form major components that influence the stock prices without losing the information and uses data from five companies which have the highest market capitalization that listed in the Consumer Goods Sector of the Indonesia Stock Exchange: Companies A, B, C, D, and E. Using Principal Component Analysis, this research reduces eighteen variables into factors that influence the stock price the most. Result shows that Profitability Ratio has a high contribution in determining stock price.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The ability to predict the stock price is the important factor in achieving the profit in stock investment, and the prediction is usually done by relating the price of a stock to factors that influence it. The problem is, there are a large number of variables that can be used to predict the stock prices so it is difficult for a potential investor to choose which variables should be used in predicting the stock prices. This research used the Principal Component Analysis as the dimension reduction method to form major components that influence the stock prices without losing the information and uses data from five companies which have the highest market capitalization that listed in the Consumer Goods Sector of the Indonesia Stock Exchange: Companies A, B, C, D, and E. Using Principal Component Analysis, this research reduces eighteen variables into factors that influence the stock price the most. Result shows that Profitability Ratio has a high contribution in determining stock price.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Measurement of Feasibility and Risk Level on Modern Embroidery Kebaya Boutique Establishment in Jakarta"
        ],
        "penulis":"Hanaa R.W.;Chumaidiyah E.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Business X is a creative business in Kebaya clothing, fabrics, and modern embroidered batik. The survey states that many medium business category turn into micro businesses due to the increasing number of imported textile products, resulting in a narrower market share. Under this condition, the company decided to create a Business X boutique considering that the products were not sold alone but at department stores that has a very high competition because of the large apparel industry continued to expand its business. In this paper, a feasibility analysis and the risk level measurement of the opening of this boutique are carried out. The market aspect begins with the distribution of questionnaires to obtain the demand and income projections. The technical aspects is for determining location using factor rating, layout and funding needs. Financial aspects estimate sales revenue and cashflow. The calculation results show NPV>0, PBP in 2, 989 years, and IRR(40%)>MARR(10.99%), it can be concluded that the Business X boutique establishment is feasible. The risk is 21.7% and with a MARR (10.99%), the rate is 32.69%. Based on the rate value that is smaller than the IRR(40%) and NPV>0, then by observing the level of risk, this business is feasible. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Business X is a creative business in Kebaya clothing, fabrics, and modern embroidered batik. The survey states that many medium business category turn into micro businesses due to the increasing number of imported textile products, resulting in a narrower market share. Under this condition, the company decided to create a Business X boutique considering that the products were not sold alone but at department stores that has a very high competition because of the large apparel industry continued to expand its business. In this paper, a feasibility analysis and the risk level measurement of the opening of this boutique are carried out. The market aspect begins with the distribution of questionnaires to obtain the demand and income projections. The technical aspects is for determining location using factor rating, layout and funding needs. Financial aspects estimate sales revenue and cashflow. The calculation results show NPV>0, PBP in 2, 989 years, and IRR(40%)>MARR(10.99%), it can be concluded that the Business X boutique establishment is feasible. The risk is 21.7% and with a MARR (10.99%), the rate is 32.69%. Based on the rate value that is smaller than the IRR(40%) and NPV>0, then by observing the level of risk, this business is feasible. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Feasibility Study of Determination a New Distribution Warehouse Location Using P-Median and Analytical Network Process Methods in One of the Cement Industries"
        ],
        "penulis":"Ramadhanti, Nadya Saniyya;Ridwan, Ari Yanuar;Pambudi, Hardian Kokoh;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research was carried out at one of the companies engaged in the cement industry, which distributed its products throughout Indonesia. However, based on audit results for the Central Java region, there are still a number of minor and major statuses in warehouse management perspectives and the percentage of warehousing cost components to the total distribution costs that exceed the maximum limit set at the warehouses rented from the distributor. Therefore, it's necessary to determine a new distribution warehouse location owned by the company by considering qualitative and quantitative aspects, then stop the operation of a rented warehouse from a distributor because of the high subsidy costs. The method used in this research is investment feasibility analysis using Net Present Value and Benefit Cost Ratio calculations, determining optimal locations using the P-Median method, and determining location based on multi-criteria using the Analytical Network Process method. The results showed that the location with the highest weight based on multi-criteria decision making and declared feasible based on investment feasibility analysis was located in Cilacap Regency with the optimal location in North Cilacap District. If this decision is carried out, the company can reduce the total distribution costs that must be incurred by the company.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research was carried out at one of the companies engaged in the cement industry, which distributed its products throughout Indonesia. However, based on audit results for the Central Java region, there are still a number of minor and major statuses in warehouse management perspectives and the percentage of warehousing cost components to the total distribution costs that exceed the maximum limit set at the warehouses rented from the distributor. Therefore, it's necessary to determine a new distribution warehouse location owned by the company by considering qualitative and quantitative aspects, then stop the operation of a rented warehouse from a distributor because of the high subsidy costs. The method used in this research is investment feasibility analysis using Net Present Value and Benefit Cost Ratio calculations, determining optimal locations using the P-Median method, and determining location based on multi-criteria using the Analytical Network Process method. The results showed that the location with the highest weight based on multi-criteria decision making and declared feasible based on investment feasibility analysis was located in Cilacap Regency with the optimal location in North Cilacap District. If this decision is carried out, the company can reduce the total distribution costs that must be incurred by the company.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Effects of ordered mutations on dynamics in signaling networks"
        ],
        "penulis":"Mazaya, Maulida;Trinh, Hung-Cuong;Kwon, Yung-Keun;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Background: Many previous clinical studies have found that accumulated sequential mutations are statistically related to tumorigenesis. However, they are limited in fully elucidating the significance of the ordered-mutation because they did not focus on the network dynamics. Therefore, there is a pressing need to investigate the dynamics characteristics induced by ordered-mutations. Methods: To quantify the ordered-mutation-inducing dynamics, we defined the mutation-sensitivity and the order-specificity that represent if the network is sensitive against a double knockout mutation and if mutation-sensitivity is specific to the mutation order, respectively, using a Boolean network model. Results: Through intensive investigations, we found that a signaling network is more sensitive when a double-mutation occurs in the direction order inducing a longer path and a smaller number of paths than in the reverse order. In addition, feedback loops involving a gene pair decreased both the mutation-sensitivity and the order-specificity. Next, we investigated relationships of functionally important genes with ordered-mutation-inducing dynamics. The network is more sensitive to mutations subject to drug-targets, whereas it is less specific to the mutation order. Both the sensitivity and specificity are increased when different-drug-targeted genes are mutated. Further, we found that tumor suppressors can efficiently suppress the amplification of oncogenes when the former are mutated earlier than the latter. Conclusion: Taken together, our results help to understand the importance of the order of mutations with respect to the dynamical effects in complex biological systems. \u00a9 2020 The Author(s).",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Background: Many previous clinical studies have found that accumulated sequential mutations are statistically related to tumorigenesis. However, they are limited in fully elucidating the significance of the ordered-mutation because they did not focus on the network dynamics. Therefore, there is a pressing need to investigate the dynamics characteristics induced by ordered-mutations. Methods: To quantify the ordered-mutation-inducing dynamics, we defined the mutation-sensitivity and the order-specificity that represent if the network is sensitive against a double knockout mutation and if mutation-sensitivity is specific to the mutation order, respectively, using a Boolean network model. Results: Through intensive investigations, we found that a signaling network is more sensitive when a double-mutation occurs in the direction order inducing a longer path and a smaller number of paths than in the reverse order. In addition, feedback loops involving a gene pair decreased both the mutation-sensitivity and the order-specificity. Next, we investigated relationships of functionally important genes with ordered-mutation-inducing dynamics. The network is more sensitive to mutations subject to drug-targets, whereas it is less specific to the mutation order. Both the sensitivity and specificity are increased when different-drug-targeted genes are mutated. Further, we found that tumor suppressors can efficiently suppress the amplification of oncogenes when the former are mutated earlier than the latter. Conclusion: Taken together, our results help to understand the importance of the order of mutations with respect to the dynamical effects in complex biological systems. \u00a9 2020 The Author(s)."
        ]
    },
    {
        "judul":[
            "Identification of upwelling area of the western territorial waters of Indonesia from 2000 to 2017"
        ],
        "penulis":"Supriyadi, Eko;Hidayat, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The Western Waters of Indonesian (WWI) present a diverse interaction of ocean-atmosphere dynamics. One of them represents the event of Indian Ocean Dipole (IOD), El Nino-Southern Oscillation (ENSO), and upwelling. The objective of this study is to determine the dynamics of chlorophyll-a concentration (Chl-a), especially during IOD and ENSO. Also, this study is aimed to examine the temporal and spatial distribution of the upwelling area from 2000 to 2017. The data utilized consisted of Chl-a, wind stress, Sea Level Anomaly (SLA), and Sea Surface Temperature (SST). The technique used to determine the upwelling area was by examining the maximum conditions of Chl-a, the low temperature of SST, and SLA. The results showed the sea surface temperature had a relationship with the concentration of Chl-a. It was obtained if the Directional Movement Index (DMI) and N3.4 (Nino 3.4 Index) moved stably (not too fluctuation) resulting in high concentrations of Chl-a. High standard deviations of SST are recognized around the Sunda Strait (June - October). When the standard deviation of SST is high, there is also a tendency for high Chl-a concentrations, while the results of empirical calculations show that large areas of upwelling occurred in January and September respectively at 12,447.72 km2and 8,146.20 km2. Based on the results of the analysis, it can be concluded that the upwelling does not only occur at the coastal area of Western Sumatra (coastal upwelling), but it also occurs in the eastern territorial waters of the Indian Ocean. In addition, the upwelling area has the same pattern as the Chl-a concentration in January - October. \u00a9 2020 by the authors. Licensee Indonesian Journal of Geography, Indonesia",
            "NNOOOCH3H3CCH3NOONH3CCH3CH3CH2CH3CH3CH3H3CCH3MgView detailsExpand Substance chlorophyll a",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Western Waters of Indonesian (WWI) present a diverse interaction of ocean-atmosphere dynamics. One of them represents the event of Indian Ocean Dipole (IOD), El Nino-Southern Oscillation (ENSO), and upwelling. The objective of this study is to determine the dynamics of chlorophyll-a concentration (Chl-a), especially during IOD and ENSO. Also, this study is aimed to examine the temporal and spatial distribution of the upwelling area from 2000 to 2017. The data utilized consisted of Chl-a, wind stress, Sea Level Anomaly (SLA), and Sea Surface Temperature (SST). The technique used to determine the upwelling area was by examining the maximum conditions of Chl-a, the low temperature of SST, and SLA. The results showed the sea surface temperature had a relationship with the concentration of Chl-a. It was obtained if the Directional Movement Index (DMI) and N3.4 (Nino 3.4 Index) moved stably (not too fluctuation) resulting in high concentrations of Chl-a. High standard deviations of SST are recognized around the Sunda Strait (June - October). When the standard deviation of SST is high, there is also a tendency for high Chl-a concentrations, while the results of empirical calculations show that large areas of upwelling occurred in January and September respectively at 12,447.72 km2and 8,146.20 km2. Based on the results of the analysis, it can be concluded that the upwelling does not only occur at the coastal area of Western Sumatra (coastal upwelling), but it also occurs in the eastern territorial waters of the Indian Ocean. In addition, the upwelling area has the same pattern as the Chl-a concentration in January - October. \u00a9 2020 by the authors. Licensee Indonesian Journal of Geography, Indonesia"
        ]
    },
    {
        "judul":[
            "Attribute Selection Effect on Tree-Based Classifiers for Letter Recognition"
        ],
        "penulis":"Prayogo, Rizal Dwi;Ikhsan, Nurul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study presents evaluation measures for attribute selection effect on classification performance in classifying the 26 uppercase letters in the English alphabet. Attribute selection is an essential method in the classification phase to measure the attribute significance related to the class label since not all attributes are significant for letter recognition. Therefore, insignificant attributes should be reduced by applying dimensionality reduction. The filter-based attribute selection methods using Information Gain, Gain Ratio, Correlation, and Chi-square are proposed. The performances of attribute selection are evaluated by tree-based classifiers using J48, CART, and Random Forest algorithms with the measures of accuracy, precision, recall, F-measure, and processing time. The results indicate that the use of attribute selection methods provides the increase of classification performances for letter recognition. The reduction of insignificant attributes is discussed in terms of the effect on classification accuracy and the processing time. The optimal number of selected attributes is determined for each attribute selection, it provides better classification accuracy with more time-efficient.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study presents evaluation measures for attribute selection effect on classification performance in classifying the 26 uppercase letters in the English alphabet. Attribute selection is an essential method in the classification phase to measure the attribute significance related to the class label since not all attributes are significant for letter recognition. Therefore, insignificant attributes should be reduced by applying dimensionality reduction. The filter-based attribute selection methods using Information Gain, Gain Ratio, Correlation, and Chi-square are proposed. The performances of attribute selection are evaluated by tree-based classifiers using J48, CART, and Random Forest algorithms with the measures of accuracy, precision, recall, F-measure, and processing time. The results indicate that the use of attribute selection methods provides the increase of classification performances for letter recognition. The reduction of insignificant attributes is discussed in terms of the effect on classification accuracy and the processing time. The optimal number of selected attributes is determined for each attribute selection, it provides better classification accuracy with more time-efficient.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Rural entrepreneurship: Towards collaborative participative models for economic sustainability"
        ],
        "penulis":"Dhewanto, Wawan;Ratnaningtyas, Sudrajati;Permatasari, Anggraeni;Anggadwita, Grisna;Prasetio, Eko Agus;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Rural entrepreneurship development is one of the strategies for encouraging the acceleration of rural development by focusing on the exploration of local resources. The role of rural entrepreneurship is crucial in creating new economic activities that can help to reduce unemployment and poverty, especially in rural areas. One of the Indonesian government's programs for encouraging rural entrepreneurship is establishing BUMDes-a village-owned enterprise. This study aims to propose a participatory rural development model to optimize stakeholder collaboration in promoting local economic growth in rural areas. This study uses a qualitative method with a multi-case study approach. There are three BUMDes from three regencies in West Java, Indonesia participated in this research. Triangulation used to check the validity of the data by comparing the results of interviews, FGD's, observations and secondary data. The results of the study found three sustainability dimensions to measure the success of BUMDes performance such as economic sustainability, social sustainability and market sustainability. The results suggest a collaborative model to optimizing BUMDes performance. The new model illustrates the collaboration between stakeholders to pursue rural entrepreneurship sustainability. \u00a9 Entrepreneurship and Sustainability Center. All rights reserved.",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1Decent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rural entrepreneurship development is one of the strategies for encouraging the acceleration of rural development by focusing on the exploration of local resources. The role of rural entrepreneurship is crucial in creating new economic activities that can help to reduce unemployment and poverty, especially in rural areas. One of the Indonesian government's programs for encouraging rural entrepreneurship is establishing BUMDes-a village-owned enterprise. This study aims to propose a participatory rural development model to optimize stakeholder collaboration in promoting local economic growth in rural areas. This study uses a qualitative method with a multi-case study approach. There are three BUMDes from three regencies in West Java, Indonesia participated in this research. Triangulation used to check the validity of the data by comparing the results of interviews, FGD's, observations and secondary data. The results of the study found three sustainability dimensions to measure the success of BUMDes performance such as economic sustainability, social sustainability and market sustainability. The results suggest a collaborative model to optimizing BUMDes performance. The new model illustrates the collaboration between stakeholders to pursue rural entrepreneurship sustainability. \u00a9 Entrepreneurship and Sustainability Center. All rights reserved."
        ]
    },
    {
        "judul":[
            "Mining shift work operation from event logs"
        ],
        "penulis":"Utama, Nur Ichsan;Sutrisnowati, Riska Asriana;Kamal, Imam Mustafa;Bae, Hyerim;Park, You-Jin;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Event logs are records of events that are generally used in process mining to determine the manner in which various processes are practically implemented. Previous studies on process mining attempted to combine the results based on different perspectives such as control flow, data, performance, and resources (organizational) to create a simulation model. This study focuses on the resource perspective. A prior study from the resource perspective focused on clustering the resources into organizational units. Implementing the results of the above study in a simulation model will yield inaccurate results because the resources are assumed to always be available if no task is performed. In a practical scenario, resources (particularly humans) tend to work based on shifts. Thus, we propose mining the shift work operation of resources from event logs to tackle this issue. We utilized a self-organizing map and k-means clustering to incorporate the shift work information from the event logs into the simulation model. Moreover, we introduce a distance function and weight-centroid updating rule in the clustering technique to realize our objective. We conducted extensive experiments with artificial data sets to assess the effectiveness of the proposed method. The simulation shows that introducing the shift work operation time of resources can yield more accurate results. Furthermore, the proposed distance function can capture the shift work operation of the resources more precisely compared with the general distance function. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "SNSSNView detailsExpand Substance 2-(thiocyanomethylthio)benzothiazole",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Event logs are records of events that are generally used in process mining to determine the manner in which various processes are practically implemented. Previous studies on process mining attempted to combine the results based on different perspectives such as control flow, data, performance, and resources (organizational) to create a simulation model. This study focuses on the resource perspective. A prior study from the resource perspective focused on clustering the resources into organizational units. Implementing the results of the above study in a simulation model will yield inaccurate results because the resources are assumed to always be available if no task is performed. In a practical scenario, resources (particularly humans) tend to work based on shifts. Thus, we propose mining the shift work operation of resources from event logs to tackle this issue. We utilized a self-organizing map and k-means clustering to incorporate the shift work information from the event logs into the simulation model. Moreover, we introduce a distance function and weight-centroid updating rule in the clustering technique to realize our objective. We conducted extensive experiments with artificial data sets to assess the effectiveness of the proposed method. The simulation shows that introducing the shift work operation time of resources can yield more accurate results. Furthermore, the proposed distance function can capture the shift work operation of the resources more precisely compared with the general distance function. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Mapping of Telkom University Roadshow Location Using Geographic Information System"
        ],
        "penulis":"Kurniawan, Ramadhani;Kurniawati, Amelia;Rizana, Afrin Fauzya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Based on data on the New Student Selection (NSS) at Telkom University in the last three years, there are international study programs that have experienced a decrease in the ratio of the number of participants for the NSS compared to the capacity. A limited number of employees can also be an obstacle in marketing Telkom University to schools on-site in various cities. Based on enrollment data in 2019, there were more than 500 schools from which participants participated in international class study programs. Because there are quite a lot of cities, it would be better if displayed in the form of a map that can display the number of participants who took part in the selection of new students from each city. In this research, a case study was conducted in an international class aimed at designing a geographical information system to map the Telkom University roadshow locations. The system will be built using the Rapid Application Development (RAD) model. This research produces a GIS that maps alternatives that provide information related to registrants from various cities by mapping the data of each alternative city into a map so that users can be helped in considering the cities that need to be visited for the roadshow and also the resources needed for the visit. Based on black-box testing and user acceptance tests, it is concluded that the system is successfully carrying out its functions according to the design. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Based on data on the New Student Selection (NSS) at Telkom University in the last three years, there are international study programs that have experienced a decrease in the ratio of the number of participants for the NSS compared to the capacity. A limited number of employees can also be an obstacle in marketing Telkom University to schools on-site in various cities. Based on enrollment data in 2019, there were more than 500 schools from which participants participated in international class study programs. Because there are quite a lot of cities, it would be better if displayed in the form of a map that can display the number of participants who took part in the selection of new students from each city. In this research, a case study was conducted in an international class aimed at designing a geographical information system to map the Telkom University roadshow locations. The system will be built using the Rapid Application Development (RAD) model. This research produces a GIS that maps alternatives that provide information related to registrants from various cities by mapping the data of each alternative city into a map so that users can be helped in considering the cities that need to be visited for the roadshow and also the resources needed for the visit. Based on black-box testing and user acceptance tests, it is concluded that the system is successfully carrying out its functions according to the design. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Service Design through Subscription Scheme Business Model in Foodritious Start-up"
        ],
        "penulis":"Raafi, Engla;Lubis, Muharman;Andreswari, Rachmadita;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Based on a questionnaire survey that has been conducted showed 31.5% of the samples have been complained about current health program in term of lacking response and uncomfortable experience when following the recipe from service providers. Thus, Foodritious application have been introduced to utilize the small portion of chance in the market to cater the requirement of the daily food consumed. Its design concept focused on the feature to maintain customer loyalty by subscribing to the web-based service. Several features, which have been designed to maintain the enthusiasm such as affinity program of chatting with nutritionists and competitive repeat purchase with Getritious. This study developed the application through iterative incremental method for developing the features within the repeated cycle in ensure the enhanced function work accordingly with the market demand. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Based on a questionnaire survey that has been conducted showed 31.5% of the samples have been complained about current health program in term of lacking response and uncomfortable experience when following the recipe from service providers. Thus, Foodritious application have been introduced to utilize the small portion of chance in the market to cater the requirement of the daily food consumed. Its design concept focused on the feature to maintain customer loyalty by subscribing to the web-based service. Several features, which have been designed to maintain the enthusiasm such as affinity program of chatting with nutritionists and competitive repeat purchase with Getritious. This study developed the application through iterative incremental method for developing the features within the repeated cycle in ensure the enhanced function work accordingly with the market demand. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The effect of a secos in crude palm oil forecasting to improve business intelligence"
        ],
        "penulis":"Al-Khowarizmi;Nasution, Ilham Ramadhan;Lubis, Muharman;Lubis, Arif Ridho;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Crude palm oil is a crop that has a harvest period of \u00b1 2 weeks and is in dire need of dissemination of information using e-commerce in order to be able to predict the price of the yield of companies or individual gardens within the next 2 weeks in order to improve studies on business intelligence. The disadvantage of not implementing e-commerce is certainly detrimental to the garden owner because they have to go through an agent so prices are set based on the agent. So with the application of e-commerce, buyers of crude palm oil can predict prices in conducting business processes to the future. So the need to forecasting the price of crude palm oil heads in order to improve the application of business intelligence using the evolution-based artificial neural network (ANN) method which in this paper is tested with SECoS get a MAPE value of 0.035% and by applying business intelligence can protect transaction costs by 33.3%. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Crude palm oil is a crop that has a harvest period of \u00b1 2 weeks and is in dire need of dissemination of information using e-commerce in order to be able to predict the price of the yield of companies or individual gardens within the next 2 weeks in order to improve studies on business intelligence. The disadvantage of not implementing e-commerce is certainly detrimental to the garden owner because they have to go through an agent so prices are set based on the agent. So with the application of e-commerce, buyers of crude palm oil can predict prices in conducting business processes to the future. So the need to forecasting the price of crude palm oil heads in order to improve the application of business intelligence using the evolution-based artificial neural network (ANN) method which in this paper is tested with SECoS get a MAPE value of 0.035% and by applying business intelligence can protect transaction costs by 33.3%. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "The 16S rRNA analysis of proteolytic bacteria isolated from recirculating aquaculture system"
        ],
        "penulis":"Dinoto A.;Handayani R.;Saputra S.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Unused feed containing protein in the water affects the fish survivability under the recirculating aquaculture systems. Microbial communities play important roles in nutrient cycling in the aquatic ecosystems, however, bacteria that may help in protein degradation remains underexplored. This study aimed to identify the proteolytic bacteria obtained from aquaculture system based on 16S rRNA genes. Bacteria were isolated using non-selective medium and then assayed for proteolytic activity on skim milk agar. Characterizations were conducted for selected proteolytic bacteria before subjected to Sanger dideoxy DNA sequencing. The results of BLAST show that five representative isolates are closely related to Flavobacterium nitratireducens, Micrococcus aloeverae, Acinetobacter baumannii, and Exiguobacter\u00edum indicum at the level similarity of 99%. The nucleotides of collected proteolytic bacterial strains have been deposited in NCBI Genbank. Finding of those proteolytic bacteria in the recirculating aquaculture system may lead the further ecological studies about their roles in the ecosystem. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Unused feed containing protein in the water affects the fish survivability under the recirculating aquaculture systems. Microbial communities play important roles in nutrient cycling in the aquatic ecosystems, however, bacteria that may help in protein degradation remains underexplored. This study aimed to identify the proteolytic bacteria obtained from aquaculture system based on 16S rRNA genes. Bacteria were isolated using non-selective medium and then assayed for proteolytic activity on skim milk agar. Characterizations were conducted for selected proteolytic bacteria before subjected to Sanger dideoxy DNA sequencing. The results of BLAST show that five representative isolates are closely related to Flavobacterium nitratireducens, Micrococcus aloeverae, Acinetobacter baumannii, and Exiguobacter\u00edum indicum at the level similarity of 99%. The nucleotides of collected proteolytic bacterial strains have been deposited in NCBI Genbank. Finding of those proteolytic bacteria in the recirculating aquaculture system may lead the further ecological studies about their roles in the ecosystem. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Design and analysis of a multiple input single output converter to support the development of DC house in Indonesia"
        ],
        "penulis":"Hidayat, Mohammad Noor;Yustika, Lindiasari Martha;Putri, Ratna Ika;Nurhadi, Slamet;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia has a considerable potential for renewable energy, which is around 168GW. This potential can be utilized to support the government programs as an alternative solution to fulfill the need of electricity, especially in remote areas. One of the problems that arises is that the power generated by renewable energy sources, especially those derived from wind resources and solar radiation, is in the form of DC power while the load supplied is in the form of AC power. The conversion of DC power into AC power will cause power losses so that it will reduce the generator efficiency. One solution related to this problem is to develop DC House, i.e. a residential with DC power loads in it. In its development, a DC House can be supplied by several renewable energy sources, all of which are DC power sources. Then a converter is needed which has several input voltage sources with one output voltage or referred to as the Multiple Input Single Output (MISO) converter. This study simulates a Multiple Input Single Output (MISO) converter, which consists of 3 DC input voltage sources originating from wind power generation, solar cell and battery with one output voltage to supply DC loads. The MISO design and analysis developed emphasizes the regulation of input voltage variations from 3 different sources to produce an output voltage to be supplied to a DC bus.  \u00a9 2020 Author(s).",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia has a considerable potential for renewable energy, which is around 168GW. This potential can be utilized to support the government programs as an alternative solution to fulfill the need of electricity, especially in remote areas. One of the problems that arises is that the power generated by renewable energy sources, especially those derived from wind resources and solar radiation, is in the form of DC power while the load supplied is in the form of AC power. The conversion of DC power into AC power will cause power losses so that it will reduce the generator efficiency. One solution related to this problem is to develop DC House, i.e. a residential with DC power loads in it. In its development, a DC House can be supplied by several renewable energy sources, all of which are DC power sources. Then a converter is needed which has several input voltage sources with one output voltage or referred to as the Multiple Input Single Output (MISO) converter. This study simulates a Multiple Input Single Output (MISO) converter, which consists of 3 DC input voltage sources originating from wind power generation, solar cell and battery with one output voltage to supply DC loads. The MISO design and analysis developed emphasizes the regulation of input voltage variations from 3 different sources to produce an output voltage to be supplied to a DC bus.  \u00a9 2020 Author(s)."
        ]
    },
    {
        "judul":[
            "The influence of internet on financial reporting practices, financial secrecy and firm value of ASEAN companies"
        ],
        "penulis":"Sukmadilaga, Citra;Abubakar, Lastuti;Handayani, Tri;Ghani, Erlane K.;Lestari, Tri Utami;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study aims to examine the factors influencing firm value in countries in the ASEAN region. Specifically, this study examines the effect of internet financial reporting practices and financial secrecy on form value in five countries namely: Indonesia, Malaysia, Singapore, Thailand and the Philippines. Using content analysis on 185 companies, this study shows that IFR does not influence firm value. On the other hand, this study shows that secrecy influences firm value. This study contributes to the existing literature by providing an empirical result of IFR in the ASEAN region. The findings in this study implicates that since secrecy has a significant negative effect on firm value, hence those countries that have high secrecy index must reduce the level of high secrecy index in order to increase firm value through levelling investor's trust on the financial reporting practices of the firms in the ASEAN region. \u00a9 2020 Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to examine the factors influencing firm value in countries in the ASEAN region. Specifically, this study examines the effect of internet financial reporting practices and financial secrecy on form value in five countries namely: Indonesia, Malaysia, Singapore, Thailand and the Philippines. Using content analysis on 185 companies, this study shows that IFR does not influence firm value. On the other hand, this study shows that secrecy influences firm value. This study contributes to the existing literature by providing an empirical result of IFR in the ASEAN region. The findings in this study implicates that since secrecy has a significant negative effect on firm value, hence those countries that have high secrecy index must reduce the level of high secrecy index in order to increase firm value through levelling investor's trust on the financial reporting practices of the firms in the ASEAN region. \u00a9 2020 Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Discretizing Whale Optimization Algorithm to Optimize a Long Short-Term Memory"
        ],
        "penulis":"Riyanto, Rizki Achmad;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "If previous data can influence data, then the data can be said to have sequential properties. Unlike the data that is not sequential, the randomization of sequential data sequences can change the data. A common neural network model generally cannot distinguish a sequential data from the non-sequential ones. Thus, the recurrent model is made specifically for managing data with sequential properties that must be considered by studying the relationship between data with the previous ones.To create a recurrent model, some parameters should be carefully designed. One of them is the architecture of the model. In this paper, discretizing the whale optimization algorithm (WOA), which is performed by determining the hidden layer number of neurons and dropout an architecture, is proposed to optimize the long short-term memory (LSTM). Evaluations on the large movie review dataset showthat the proposed discrete WOA is capable of significantly giving an absolute improvement of the LSTM mean accuracy by up to 1.50% (from 91.23% to 92.73%). \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "If previous data can influence data, then the data can be said to have sequential properties. Unlike the data that is not sequential, the randomization of sequential data sequences can change the data. A common neural network model generally cannot distinguish a sequential data from the non-sequential ones. Thus, the recurrent model is made specifically for managing data with sequential properties that must be considered by studying the relationship between data with the previous ones.To create a recurrent model, some parameters should be carefully designed. One of them is the architecture of the model. In this paper, discretizing the whale optimization algorithm (WOA), which is performed by determining the hidden layer number of neurons and dropout an architecture, is proposed to optimize the long short-term memory (LSTM). Evaluations on the large movie review dataset showthat the proposed discrete WOA is capable of significantly giving an absolute improvement of the LSTM mean accuracy by up to 1.50% (from 91.23% to 92.73%). \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Reduction of number of empty-truck trips in inter-terminal transportation using multi-agent Q-learning"
        ],
        "penulis":"Adi, Taufik Nur;Iskandar, Yelita Anggiane;Bae, Hyerim;Choi, Yulim;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In a port consisting of multiple container terminals, the demand for transportation of containers and cargo among port facilities is high. Almost all transshipment containers bound for a vessel generally are transported from one terminal to another within a short period, which process is known as inter-terminal transportation (ITT). Adequate ITT planning is required in order to reduce ITT-related costs. Minimization of the number of Empty-Truck trips has gained attention, as the ITT problem incurs ITT-related costs. A single Q-Learning-based technique developed in a previous study for minimization of the number of empty-truck trips required high computational time while learning from a considerable amount of orders data. This paper proposes multi-agent Q-Learning to improve the performance offered by the previous single-agent-based model. Our results show that multi-agent Q-Learning performs better than the single-agent alternative in terms of computation time and, therefore too, the quality of its results. \u00a9 Interconnected Supply Chains in an Era of Innovation - Proceedings of the 8th International Conference on Information Systems, Logistics and Supply Chain, ILS 2020. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a port consisting of multiple container terminals, the demand for transportation of containers and cargo among port facilities is high. Almost all transshipment containers bound for a vessel generally are transported from one terminal to another within a short period, which process is known as inter-terminal transportation (ITT). Adequate ITT planning is required in order to reduce ITT-related costs. Minimization of the number of Empty-Truck trips has gained attention, as the ITT problem incurs ITT-related costs. A single Q-Learning-based technique developed in a previous study for minimization of the number of empty-truck trips required high computational time while learning from a considerable amount of orders data. This paper proposes multi-agent Q-Learning to improve the performance offered by the previous single-agent-based model. Our results show that multi-agent Q-Learning performs better than the single-agent alternative in terms of computation time and, therefore too, the quality of its results. \u00a9 Interconnected Supply Chains in an Era of Innovation - Proceedings of the 8th International Conference on Information Systems, Logistics and Supply Chain, ILS 2020. All rights reserved."
        ]
    },
    {
        "judul":[
            "The P1- P1NCFinite Element Method for 1D wave simulation using Shallow Water Equations"
        ],
        "penulis":"Swastika P.V.;Pudjaprasetya S.R.;Adytia D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We study a simple numerical scheme based on a new type of Finite Element Method (FEM) to solve the 1D Shallow Water Equations. In the new scheme, the surface elevation variable is approximated by a linear continuous basis function (P 1) and the velocity potential variable is approximated by the one-dimensional discontinuous linear non-conforming basis function (P1NC). Here, we implement the P 1 - P1NC finite element pair to solve the 1D Shallow Water Equations on a structured grid, whereas the Runge Kutta method is adopted for time integration. We verified the resulting scheme by conducting several simulations such as a standing wave simulation, and propagation of an initial hump over sloping bathymetry. The resulting scheme free from numerical damping error, conservative and both standing wave and shoaling phenomena are well simulated.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We study a simple numerical scheme based on a new type of Finite Element Method (FEM) to solve the 1D Shallow Water Equations. In the new scheme, the surface elevation variable is approximated by a linear continuous basis function (P 1) and the velocity potential variable is approximated by the one-dimensional discontinuous linear non-conforming basis function (P1NC). Here, we implement the P 1 - P1NC finite element pair to solve the 1D Shallow Water Equations on a structured grid, whereas the Runge Kutta method is adopted for time integration. We verified the resulting scheme by conducting several simulations such as a standing wave simulation, and propagation of an initial hump over sloping bathymetry. The resulting scheme free from numerical damping error, conservative and both standing wave and shoaling phenomena are well simulated.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Life Cycle Cost Analysis in Construction of Green Building Concept, A Case Study"
        ],
        "penulis":"Kamaralo M.K.;Alhilman J.;Atmaji F.T.D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Based on data from the Green Building Council of Indonesia, more than one-third of CO2gas emissions worldwide are generated by buildings, it has an impact on the environment such as global warming, ozone layer depletion, and accumulation of waste. The concept of Green Building is considered very necessary to overcome global warming and improve energy and resource efficiency. In the process of building a building that is Green Building requires a relatively high cost when compared to conventional buildings. Therefore, the Life Cycle Cost (LCC) method is used to determine the total cost needed, the optimal cost of the building, the economic age of the building, the number of crew maintenance and the level of energy efficiency. The analysis using the Life Cycle Cost method requires several related costs such as Initial Costs, Maintenance Costs, Energy Costs, Replacement Costs, and Utility Costs. The analysis was conducted using the Present Worth method within a period of 8 years from the start of building construction. Based on data processing using the Life Cycle Cost method, the optimal cost of a green building concept building is IDR 232, 296, 615, 337 with the economic life of the building being 8 years, the optimal number of maintenance crews is 1 person and the level of energy consumption intensity is very efficient. \u00a9 Published under licence by IOP Publishing Ltd.",
            "OOOView detailsExpand Substance ozone",
            "Powered by",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Decent work and economic growthGoal 8Responsible consumption and productionGoal 12Climate actionGoal 13Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Based on data from the Green Building Council of Indonesia, more than one-third of CO2gas emissions worldwide are generated by buildings, it has an impact on the environment such as global warming, ozone layer depletion, and accumulation of waste. The concept of Green Building is considered very necessary to overcome global warming and improve energy and resource efficiency. In the process of building a building that is Green Building requires a relatively high cost when compared to conventional buildings. Therefore, the Life Cycle Cost (LCC) method is used to determine the total cost needed, the optimal cost of the building, the economic age of the building, the number of crew maintenance and the level of energy efficiency. The analysis using the Life Cycle Cost method requires several related costs such as Initial Costs, Maintenance Costs, Energy Costs, Replacement Costs, and Utility Costs. The analysis was conducted using the Present Worth method within a period of 8 years from the start of building construction. Based on data processing using the Life Cycle Cost method, the optimal cost of a green building concept building is IDR 232, 296, 615, 337 with the economic life of the building being 8 years, the optimal number of maintenance crews is 1 person and the level of energy consumption intensity is very efficient. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Study of EDFA Placement in 10 Gbps Single-Mode Fiber Link to Support 5G Networks"
        ],
        "penulis":"Effendi, Nabila Syadzwina;Natali, Yus;Apriono, Catur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The new generation of mobile communication technology plays a crucial role in driving the future of Industry 4.0. The 5G networks will have high network flexibility and guarantee the Quality of Service (QoS) requirement. As a basic 5G network connection, the transport network must guarantee bandwidth, delay, synchronization, and reliability. Interconnection between 5G wireless networks and fiber optic networks as a transport network offers a more cohesive experience across fixed and cellular applications. As a transport network, optical fiber supports the application of metropolitan, regional, and national networks, which require long transmission distances. However, when optical signals propagate through the fiber, fiber attenuation appears as a disturbance due to much longer use of transmission distance. This research investigates the effects of different placement of EDFA in single-channel of single-mode fiber (SMF) link using a 10 Gbps bit rate data transmission at various transmission distance and source power levels. This research considers the parametric study of pre-amplifier and booster amplifier with NRZ modulation format at different transmission distances from 70 km to 130 km, and input powers from-18 dBm to 30 dBm simulated by using OptiSystem to characterize the Bit Error Rate (BER). The results show that in different situations, the system will require different EDFA schemes to meet the signal amplifier requirements. This result is useful for selecting different schemes of EDFA in designing a long-haul transmission with high data rates. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The new generation of mobile communication technology plays a crucial role in driving the future of Industry 4.0. The 5G networks will have high network flexibility and guarantee the Quality of Service (QoS) requirement. As a basic 5G network connection, the transport network must guarantee bandwidth, delay, synchronization, and reliability. Interconnection between 5G wireless networks and fiber optic networks as a transport network offers a more cohesive experience across fixed and cellular applications. As a transport network, optical fiber supports the application of metropolitan, regional, and national networks, which require long transmission distances. However, when optical signals propagate through the fiber, fiber attenuation appears as a disturbance due to much longer use of transmission distance. This research investigates the effects of different placement of EDFA in single-channel of single-mode fiber (SMF) link using a 10 Gbps bit rate data transmission at various transmission distance and source power levels. This research considers the parametric study of pre-amplifier and booster amplifier with NRZ modulation format at different transmission distances from 70 km to 130 km, and input powers from-18 dBm to 30 dBm simulated by using OptiSystem to characterize the Bit Error Rate (BER). The results show that in different situations, the system will require different EDFA schemes to meet the signal amplifier requirements. This result is useful for selecting different schemes of EDFA in designing a long-haul transmission with high data rates. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of ensemble methods on QSAR Study of NS3 inhibitor activity as anti-dengue agent"
        ],
        "penulis":"Kurniawan I.;Rosalinda M.;Ikhsan N.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Dengue fever is a disease transmitted by infected mosquitoes. This disease spreads in several countries, especially those with a tropical climate. To date, there is no specific drug that can be used to treat dengue. Use of clinically investigated drugs, such as Balapiravir, is still not effective in inhibiting the activity of virus replication. The design of a drug candidate can be performed by using the non-structural protein 3 (NS3) as target. This study aimed to develop QSAR models to predict the inhibitory activity class of NS3 inhibitors. The classification was performed by using feature importance analysis for selecting the descriptors and three ensemble methods, i.e. random forest (RF), adaptive boosting (AdaBoost), and extremely randomized trees (ERT), for model design and prediction. Hyperparameter tuning was performed to improve the performance of the models. Based on the results, we found that model 9, developed from ERT produced the best performance with values of accuracy and AUC equal to 0.73 and 0.82, respectively. Use of y-scrambling method allowed us to confirm that the model was not related to the chance correlation. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Dengue fever is a disease transmitted by infected mosquitoes. This disease spreads in several countries, especially those with a tropical climate. To date, there is no specific drug that can be used to treat dengue. Use of clinically investigated drugs, such as Balapiravir, is still not effective in inhibiting the activity of virus replication. The design of a drug candidate can be performed by using the non-structural protein 3 (NS3) as target. This study aimed to develop QSAR models to predict the inhibitory activity class of NS3 inhibitors. The classification was performed by using feature importance analysis for selecting the descriptors and three ensemble methods, i.e. random forest (RF), adaptive boosting (AdaBoost), and extremely randomized trees (ERT), for model design and prediction. Hyperparameter tuning was performed to improve the performance of the models. Based on the results, we found that model 9, developed from ERT produced the best performance with values of accuracy and AUC equal to 0.73 and 0.82, respectively. Use of y-scrambling method allowed us to confirm that the model was not related to the chance correlation. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group."
        ]
    },
    {
        "judul":[
            "Knowing Opposing Arguments in Persuasive Essays Using Random Forest Classifier"
        ],
        "penulis":"Rachmanto, Daulat;Asror, Ibnu;Herdiani, Anisa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Argumentation mining is a relatively new field of research in the perspective of computational linguistics. It can be used to improve the quality of arguments in persuasive essays by detecting whether in a persuasive essay there are opposing arguments or not. This is because the importance of opposing arguments in persuasive essays that can improve the quality of arguments, precision and author's claims. This research adapted the research conducted by Stab and Gurevych who used the SVM classification method with an accuracy 75,6% and macro F1-score 0,734. While in this research used the Random Forest method and get accuracy of 85,125% and macro F1-score of 0,841 by using three features, namely unigram, production rules, and adversative transitions.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Argumentation mining is a relatively new field of research in the perspective of computational linguistics. It can be used to improve the quality of arguments in persuasive essays by detecting whether in a persuasive essay there are opposing arguments or not. This is because the importance of opposing arguments in persuasive essays that can improve the quality of arguments, precision and author's claims. This research adapted the research conducted by Stab and Gurevych who used the SVM classification method with an accuracy 75,6% and macro F1-score 0,734. While in this research used the Random Forest method and get accuracy of 85,125% and macro F1-score of 0,841 by using three features, namely unigram, production rules, and adversative transitions.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Vertical Axis Wind Turbine Improvement using DC-DC Boost Converter"
        ],
        "penulis":"Khairunnisa, Khairunnisa;Rachman, Syaiful;Yohanes, Edi;Uji Krismanto, Awan;Fadil, Jazuli;Soedibyo, Soedibyo;Ashari, Mochamad;Abuzalata, Mahmoud;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Vertical axis wind turbine (VAWT) can be operated in any direction of wind speed, but it has low rotation. To improve the performance of VAWT in which low rotation, this paper presents a simple control strategy of VAWT using a DC-DC boost converter to tap constant voltage in a standalone application. The main objective of this research is to maintain a constant output voltage of converter despite variation input voltage affected by variable wind speed. A simple proportional-integral (PI) controller has been used for a DC-DC boost converter and tested in MATLAB-Simulink environment, with the closed-loop system of the converter maintain constant output voltage although the wind speed is kept changing. The PI controller obtains the feedback from the output voltage of the boost converter to produce the correct pulse width modulation (PWM) duty cycle and trigger the metal oxide semiconductor field effect transistor (MOSFET) following the reference voltage of the turbine. This system has suppressed the value of overshoot and increased the efficiency of wind turbines as 34 %.  \u00a9 The Authors, published by EDP Sciences, 2020.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Vertical axis wind turbine (VAWT) can be operated in any direction of wind speed, but it has low rotation. To improve the performance of VAWT in which low rotation, this paper presents a simple control strategy of VAWT using a DC-DC boost converter to tap constant voltage in a standalone application. The main objective of this research is to maintain a constant output voltage of converter despite variation input voltage affected by variable wind speed. A simple proportional-integral (PI) controller has been used for a DC-DC boost converter and tested in MATLAB-Simulink environment, with the closed-loop system of the converter maintain constant output voltage although the wind speed is kept changing. The PI controller obtains the feedback from the output voltage of the boost converter to produce the correct pulse width modulation (PWM) duty cycle and trigger the metal oxide semiconductor field effect transistor (MOSFET) following the reference voltage of the turbine. This system has suppressed the value of overshoot and increased the efficiency of wind turbines as 34 %.  \u00a9 The Authors, published by EDP Sciences, 2020."
        ]
    },
    {
        "judul":[
            "Tracking, Arrival Time Estimator, and Passenger Information System on Bus Rapid Transit (BRT)"
        ],
        "penulis":"Hafiizh Nur M.A.;Hadiyoso, Sugondo;Belladina, Fefa Bianca;Ramadan, Dadan Nur;Wijayanto, Inung;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Trans Metro Bandung is a new Bus Rapid Transit in Bandung, Indonesia. As a new mode of transportation, it proposes comfort, safety, and give an affordable price. However, information systems related to buses are still lacking and far from expectations. That includes the uncertainty of the bus departures and arrivals times at bus stops. Therefore, in this study, an integrated online system is designed to provide information, including bus arrival time, bus position, and the number of passengers on the bus. This information system is a website application that is connected to the Firebase real-time database so that all data can be accessed in real-time and then displayed at the bus stop. The hardware system consists of an infrared detector to count the number of passengers and a GPS module for bus tracking. From the bus position information, the system can estimate the arrival time at the nearest bus stop.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Trans Metro Bandung is a new Bus Rapid Transit in Bandung, Indonesia. As a new mode of transportation, it proposes comfort, safety, and give an affordable price. However, information systems related to buses are still lacking and far from expectations. That includes the uncertainty of the bus departures and arrivals times at bus stops. Therefore, in this study, an integrated online system is designed to provide information, including bus arrival time, bus position, and the number of passengers on the bus. This information system is a website application that is connected to the Firebase real-time database so that all data can be accessed in real-time and then displayed at the bus stop. The hardware system consists of an infrared detector to count the number of passengers and a GPS module for bus tracking. From the bus position information, the system can estimate the arrival time at the nearest bus stop.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "University Student\u2019s Knowledge Toward Energy Conservation and the Implementation on Their Design Project"
        ],
        "penulis":"Harsritanto, Bangun I. R.;Rusyda, Hana F. S.;Putra, Gentina Pratama;Prabowo, Aditya Rio;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Energy conservation performed important role on responding the climate changes on personal and organizational position. Personal responses are known as crucial part toward lower carbon emission, energy consumption, water usage, etc. Nowadays every architecture students in the world has responsibility to design more green building or environment friendly city during their study at campus so they will become agent of change on their future world. However there is less evidence of the on those global movement such endeavors on the student\u2019s behavior and actions. This study objective is to analyze the knowledge of energy conservation from architecture students and their implementation on design project. Literature studies, questionnaires, and statistical analysis were performed to pursue the objective. In the result, we can summarize that student energy conservation awareness and design project were related in unique ways. \u00a9 2020, Springer Nature Singapore Pte Ltd.",
            "CView detailsExpand Substance pyrographite",
            "Powered by",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Responsible consumption and productionGoal 12Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Energy conservation performed important role on responding the climate changes on personal and organizational position. Personal responses are known as crucial part toward lower carbon emission, energy consumption, water usage, etc. Nowadays every architecture students in the world has responsibility to design more green building or environment friendly city during their study at campus so they will become agent of change on their future world. However there is less evidence of the on those global movement such endeavors on the student\u2019s behavior and actions. This study objective is to analyze the knowledge of energy conservation from architecture students and their implementation on design project. Literature studies, questionnaires, and statistical analysis were performed to pursue the objective. In the result, we can summarize that student energy conservation awareness and design project were related in unique ways. \u00a9 2020, Springer Nature Singapore Pte Ltd."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Machine learning on named data network: A survey routing and forwarding strategy"
        ],
        "penulis":"Mayasari, Ratna;Syambas, Nana Rachmana;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "NDN, a data-centric network which can reduce the load on the network (especially on the server side) is widely developed using Machine Learning (ML) recently. The main reason is the capability of ML to examine a huge data, for example in FIB. In FIB, to identify the longest prefix is expensive and hard to operate without precise optimization. The goal of this study is to serve as guidelines for future research by conducting surveys on current NDN development with ML, especially for routing and forwarding classification.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "NDN, a data-centric network which can reduce the load on the network (especially on the server side) is widely developed using Machine Learning (ML) recently. The main reason is the capability of ML to examine a huge data, for example in FIB. In FIB, to identify the longest prefix is expensive and hard to operate without precise optimization. The goal of this study is to serve as guidelines for future research by conducting surveys on current NDN development with ML, especially for routing and forwarding classification.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Iot architecture that supports the stimulation of gross motor development in children aged 5-6 years using drop box game"
        ],
        "penulis":"Wajdi, Halim;Suwastika, Novian Anggis;Yasirandi, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Gross motor development in children influences the development of self-confidence and the concept of self-formation as they mature. Many people assume that gross motor development is often ruled out compared to other aspects of child development because the perception of gross motor development will automatically increase with age, when in fact the gross motor development must continue to be stimulated so that it develops perfectly. The activity used in this research is the game of putting balls into a hole by moving the game box (Drop Box). This research aims to build a device that has been designed and assess the ability\/performance of the system based on the parameters of functionality, the accuracy of values, and reading speed. In this research, the Drop Box game implements Internet of Things (IoT) to support recording activities and processing data obtained from recording children's activities. In this research also proposed a suitable IoT architecture and has been applied in the development of the Drop Box game device. We carry out functional system testing and system performance testing based on accuracy parameters and speed-reading parameters. The test results show that the functionality of the system runs with an average of 100%. For system performance, the result is 86.59% for 20 ms as the optimal delay in testing accuracy and 79 ms for reading speed. \u00a9 2020 Register: Jurnal Ilmiah Teknologi Sistem Informasi (Scientific Journal of Information System Technology) with CC BY NC SA license.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Gross motor development in children influences the development of self-confidence and the concept of self-formation as they mature. Many people assume that gross motor development is often ruled out compared to other aspects of child development because the perception of gross motor development will automatically increase with age, when in fact the gross motor development must continue to be stimulated so that it develops perfectly. The activity used in this research is the game of putting balls into a hole by moving the game box (Drop Box). This research aims to build a device that has been designed and assess the ability\/performance of the system based on the parameters of functionality, the accuracy of values, and reading speed. In this research, the Drop Box game implements Internet of Things (IoT) to support recording activities and processing data obtained from recording children's activities. In this research also proposed a suitable IoT architecture and has been applied in the development of the Drop Box game device. We carry out functional system testing and system performance testing based on accuracy parameters and speed-reading parameters. The test results show that the functionality of the system runs with an average of 100%. For system performance, the result is 86.59% for 20 ms as the optimal delay in testing accuracy and 79 ms for reading speed. \u00a9 2020 Register: Jurnal Ilmiah Teknologi Sistem Informasi (Scientific Journal of Information System Technology) with CC BY NC SA license."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Using a multi-level process comparison for process change analysis in cancer pathways"
        ],
        "penulis":"Kurniati, Angelina Prima;McInerney, Ciar\u00e1n;Zucker, Kieran;Hall, Geoff;Hogg, David;Johnson, Owen;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The area of process change over time is a particular concern in healthcare, where patterns of care emerge and evolve in response to individual patient needs. We propose a structured approach to analyse process change over time that is suitable for the complex domain of healthcare. Our approach applies a qualitative process comparison at three levels of abstraction: a holistic perspective (process model), a middle-level perspective (trace), and a fine-grained detail (activity). Our aim was to detect change points, localise and characterise the change, and unravel\/understand the process evolution. We illustrate the approach using a case study of cancer pathways in Leeds where we found evidence of change points identified at multiple levels. In this paper, we extend our study by analysing the miners used in process discovery and providing a deeper analysis of the activity of investigation in trace and activity levels. In the experiment, we show that this qualitative approach provides a useful understanding of process change over time. Examining change at three levels provides confirmatory evidence of process change where perspectives agree, while contradictory evidence can lead to focused discussions with domain experts. This approach should be of interest to others dealing with processes that undergo complex change over time. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "BaView detailsExpand Substance barium",
            "Powered by",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The area of process change over time is a particular concern in healthcare, where patterns of care emerge and evolve in response to individual patient needs. We propose a structured approach to analyse process change over time that is suitable for the complex domain of healthcare. Our approach applies a qualitative process comparison at three levels of abstraction: a holistic perspective (process model), a middle-level perspective (trace), and a fine-grained detail (activity). Our aim was to detect change points, localise and characterise the change, and unravel\/understand the process evolution. We illustrate the approach using a case study of cancer pathways in Leeds where we found evidence of change points identified at multiple levels. In this paper, we extend our study by analysing the miners used in process discovery and providing a deeper analysis of the activity of investigation in trace and activity levels. In the experiment, we show that this qualitative approach provides a useful understanding of process change over time. Examining change at three levels provides confirmatory evidence of process change where perspectives agree, while contradictory evidence can lead to focused discussions with domain experts. This approach should be of interest to others dealing with processes that undergo complex change over time. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "ANALYSIS OF THE IMPACT OF TERRORIST BOMBING ACTS ON ABNORMAL RETURN AND TRADING VOLUME ACTIVITY: STUDY OF TERRORIST BOMBINGS WORLDWIDE (2008\u20132017)"
        ],
        "penulis":"Firli, Anisah;Rahadian, Dadan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Several studies and research related to event study and terrorist bombing acts have different conclusions. Moreover, research on terrorist bombings worldwide has never been conducted. Hence, this research aims at examining the impact of terrorist bombing using the abnormal return variables by looking at all bombings around the world in the past 10 years. This research uses a paired t-test by looking at the abnormal return before, during, and after a bombing act. Results show no significant difference between the abnormal return before, during, and after bombing acts. \u00a9 2020 by Emerald Publishing Limited",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Several studies and research related to event study and terrorist bombing acts have different conclusions. Moreover, research on terrorist bombings worldwide has never been conducted. Hence, this research aims at examining the impact of terrorist bombing using the abnormal return variables by looking at all bombings around the world in the past 10 years. This research uses a paired t-test by looking at the abnormal return before, during, and after a bombing act. Results show no significant difference between the abnormal return before, during, and after bombing acts. \u00a9 2020 by Emerald Publishing Limited"
        ]
    },
    {
        "judul":[
            "Zigbee wireless network-based indoor mobile robot monitoring and positioning method under binocular vision"
        ],
        "penulis":"Chen, Xiaowei;Le, Quoc Tien;Saedudin, Rd Rohmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "\u2013 Accuracy of the positioning system can be improved by a low-cost and practical ZigBee wireless network indoor mobile robot monitoring and positioning system. Based on the application requirements, the software design and hardware design of the indoor mobile robot are carried out to build an intelligent mobile robot system independently. Under the binocular vision system, the Received Signal Strength Indication (RSSI) ranging technology is adopted as the ZigBee positioning algorithm. The deficiencies of the traditional RSSI algorithm are improved, and the system is tested in the hall corridors and rooms. In the indoor rooms, the mean relative error (MRE) of the RSSI algorithm before the improvement is 23.27%, and the MRE of the RSSI algorithm after the improvement is 13.91%, with an increase of 9.36%. In the hall corridor, the MRE of the RSSI algorithm before the improvement is 14.86%, and the MRE of the RSSI algorithm after the improvement is 10.82%, with an increase of 4.04%. The improved RSSI algorithm can meet the monitoring and positioning requirements of indoor mobile robot based on ZigBee wireless network under binocular vision. \u00a9 2020, Cefin Publishing House. All rights reserved."
        ],
        "abstrak":[
            "\u2013 Accuracy of the positioning system can be improved by a low-cost and practical ZigBee wireless network indoor mobile robot monitoring and positioning system. Based on the application requirements, the software design and hardware design of the indoor mobile robot are carried out to build an intelligent mobile robot system independently. Under the binocular vision system, the Received Signal Strength Indication (RSSI) ranging technology is adopted as the ZigBee positioning algorithm. The deficiencies of the traditional RSSI algorithm are improved, and the system is tested in the hall corridors and rooms. In the indoor rooms, the mean relative error (MRE) of the RSSI algorithm before the improvement is 23.27%, and the MRE of the RSSI algorithm after the improvement is 13.91%, with an increase of 9.36%. In the hall corridor, the MRE of the RSSI algorithm before the improvement is 14.86%, and the MRE of the RSSI algorithm after the improvement is 10.82%, with an increase of 4.04%. The improved RSSI algorithm can meet the monitoring and positioning requirements of indoor mobile robot based on ZigBee wireless network under binocular vision. \u00a9 2020, Cefin Publishing House. All rights reserved."
        ]
    },
    {
        "judul":[
            "Competency Profile for Software Development Team that Support Project Success"
        ],
        "penulis":"Kusumasari, Tien Fabrianti;Trilaksono, Bambang Riyanto;Aisha, Atya Nur;Fitria;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The success of software development depends very much on the competencies possessed by human resources within the development team. These competencies include hard and soft skills. In this study, a team competency model will be proposed, which consists of the minimum competency level for the project manager, analyst, and programmer job roles. The types of competencies that are focused on in this paper consist of soft competencies and hard competencies. The method used to determine the competency model is to use the Focus Discussion Group (FGD) by adopting the Behavior Event Interview (BEI) technique. The result of FGD validates with expert judgments, questionnaires, and team member interviews. This research provides the results of profiling the competency of the software development team on project manager job analysts, analysts, and programmers. This study's competencies profile stated that the average minimum level of soft competency for project managers is 3, 3 for analysts, and 2 for programmers. In comparison, the average minimum level of hard competency for a project manager is 3, analyst 2, and programmer 2. Job Role for project managers requires high enough competence both in terms of technical (hard competency) and soft competency. A job as an Analyst requires a level of soft competence higher than hard competency. At the same time, the job role programmer requires soft and hard competency at a low level, 2. The results of this paper can be useful for the recruitment team to get the right individuals to ensure the success of the project. \u00a9 (2020). All Rights Reserved.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The success of software development depends very much on the competencies possessed by human resources within the development team. These competencies include hard and soft skills. In this study, a team competency model will be proposed, which consists of the minimum competency level for the project manager, analyst, and programmer job roles. The types of competencies that are focused on in this paper consist of soft competencies and hard competencies. The method used to determine the competency model is to use the Focus Discussion Group (FGD) by adopting the Behavior Event Interview (BEI) technique. The result of FGD validates with expert judgments, questionnaires, and team member interviews. This research provides the results of profiling the competency of the software development team on project manager job analysts, analysts, and programmers. This study's competencies profile stated that the average minimum level of soft competency for project managers is 3, 3 for analysts, and 2 for programmers. In comparison, the average minimum level of hard competency for a project manager is 3, analyst 2, and programmer 2. Job Role for project managers requires high enough competence both in terms of technical (hard competency) and soft competency. A job as an Analyst requires a level of soft competence higher than hard competency. At the same time, the job role programmer requires soft and hard competency at a low level, 2. The results of this paper can be useful for the recruitment team to get the right individuals to ensure the success of the project. \u00a9 (2020). All Rights Reserved."
        ]
    },
    {
        "judul":[
            "Selecting critical features for data classification based on machine learning methods"
        ],
        "penulis":"Chen, Rung-Ching;Dewi, Christine;Huang, Su-Wen;Caraka, Rezzy Eko;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Feature selection becomes prominent, especially in the data sets with many variables and features. It will eliminate unimportant variables and improve the accuracy as well as the performance of classification. Random Forest has emerged as a quite useful algorithm that can handle the feature selection issue even with a higher number of variables. In this paper, we use three popular datasets with a higher number of variables (Bank Marketing, Car Evaluation Database, Human Activity Recognition Using Smartphones) to conduct the experiment. There are four main reasons why feature selection is essential. First, to simplify the model by reducing the number of parameters, next to decrease the training time, to reduce overfilling by enhancing generalization, and to avoid the curse of dimensionality. Besides, we evaluate and compare each accuracy and performance of the classification model, such as Random Forest (RF), Support Vector Machines (SVM), K-Nearest Neighbors (KNN), and Linear Discriminant Analysis (LDA). The highest accuracy of the model is the best classifier. Practically, this paper adopts Random Forest to select the important feature in classification. Our experiments clearly show the comparative study of the RF algorithm from different perspectives. Furthermore, we compare the result of the dataset with and without essential features selection by RF methods varImp(), Boruta, and Recursive Feature Elimination (RFE) to get the best percentage accuracy and kappa. Experimental results demonstrate that Random Forest achieves a better performance in all experiment groups. \u00a9 2020, The Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Feature selection becomes prominent, especially in the data sets with many variables and features. It will eliminate unimportant variables and improve the accuracy as well as the performance of classification. Random Forest has emerged as a quite useful algorithm that can handle the feature selection issue even with a higher number of variables. In this paper, we use three popular datasets with a higher number of variables (Bank Marketing, Car Evaluation Database, Human Activity Recognition Using Smartphones) to conduct the experiment. There are four main reasons why feature selection is essential. First, to simplify the model by reducing the number of parameters, next to decrease the training time, to reduce overfilling by enhancing generalization, and to avoid the curse of dimensionality. Besides, we evaluate and compare each accuracy and performance of the classification model, such as Random Forest (RF), Support Vector Machines (SVM), K-Nearest Neighbors (KNN), and Linear Discriminant Analysis (LDA). The highest accuracy of the model is the best classifier. Practically, this paper adopts Random Forest to select the important feature in classification. Our experiments clearly show the comparative study of the RF algorithm from different perspectives. Furthermore, we compare the result of the dataset with and without essential features selection by RF methods varImp(), Boruta, and Recursive Feature Elimination (RFE) to get the best percentage accuracy and kappa. Experimental results demonstrate that Random Forest achieves a better performance in all experiment groups. \u00a9 2020, The Author(s)."
        ]
    },
    {
        "judul":[
            "Service plan of service composition in pervasive computing: A systematic literature review"
        ],
        "penulis":"Pranita, Ryche;Suhardi;Muhamad, Wardani;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Service composition made by arranging set of services to achieve specific goals from user task. The steps taken in building service composition are obtained from the service life cycle, consisting of definition, selection, deployment, and execution phase. Service composition is more complicated in pervasive computing since service is created by a simple task deployed in distributed devices. The devices in the pervasive environment can be a service itself. Several challenges are faced in making service composition in pervasive computing, such as limited system knowledge and resource, unpredictable service availability, and heterogeneity. Hence, it requires service plan that can mapping user requests containing the planning goal and the composition corresponds to the plan. This planning process is carried out by the transformation of user requirements and business processes. In this paper, we adopt systematic literature review (SLR) and define some research question (RQ) to research in various database journal. Twenty-two articles were selected based on the search result and then reviewed. We extracted and summarized service composition using planning approach and find the implementation area in pervasive computing.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Service composition made by arranging set of services to achieve specific goals from user task. The steps taken in building service composition are obtained from the service life cycle, consisting of definition, selection, deployment, and execution phase. Service composition is more complicated in pervasive computing since service is created by a simple task deployed in distributed devices. The devices in the pervasive environment can be a service itself. Several challenges are faced in making service composition in pervasive computing, such as limited system knowledge and resource, unpredictable service availability, and heterogeneity. Hence, it requires service plan that can mapping user requests containing the planning goal and the composition corresponds to the plan. This planning process is carried out by the transformation of user requirements and business processes. In this paper, we adopt systematic literature review (SLR) and define some research question (RQ) to research in various database journal. Twenty-two articles were selected based on the search result and then reviewed. We extracted and summarized service composition using planning approach and find the implementation area in pervasive computing.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis and Design of Policy and Standard Operating Procedure (SOP) for Information Technology in the Communication and Information Services Department"
        ],
        "penulis":"Lubis, Muharman;Ananza, Hikam Haikal Radya;Suryoputro, Fritasya Dwiputri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "SOP as quality standards to perform the process of the instruction and executing tasks and activities are important for an organization. The communication and information services in West Java Province has developed a service known as Management of West Java province domain emails. SOP for service provided is to support the procedures needed for the continuity of service provided needed for the continuity of service. This research uses an observation and interview as a method to collect data. SOP will divide into 5 categories by the answer of a data interview that has been collected. This paper tries to explain what are necessary and which type of work needs to be done for writing SOPs for service provided in the communication and information services of West Java Province.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SOP as quality standards to perform the process of the instruction and executing tasks and activities are important for an organization. The communication and information services in West Java Province has developed a service known as Management of West Java province domain emails. SOP for service provided is to support the procedures needed for the continuity of service provided needed for the continuity of service. This research uses an observation and interview as a method to collect data. SOP will divide into 5 categories by the answer of a data interview that has been collected. This paper tries to explain what are necessary and which type of work needs to be done for writing SOPs for service provided in the communication and information services of West Java Province.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A Review of Light Gradient Boosting Machine Method for Hate Speech Classification on Twitter"
        ],
        "penulis":"Abdurrahman, Muhammad Hafizh;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Hate speech is a form of verbal communication with the purpose to insult, to provoke, or to incite the victim. With social media such as Twitter, it becomes easier to spread or find hate speech. To reduce online hate speech, we made a classification system to detect hate speech from Twitter. This system uses LightGBM, which was the development of a Gradient Boosting Decision Tree (GBDT) Algorithm. GBDT was often used for this type of classification, but the outcome was less satisfactory. LightGBM uses Gradient-based One Side Sampling (GOSS) and Exclusive Feature Bundling (EFB). With these two techniques implemented in GBDT, this research experiment's accuracy is 86,05% with a total of 1000 data, a 0.175 learning rate, 30% test data, and 70% training data. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hate speech is a form of verbal communication with the purpose to insult, to provoke, or to incite the victim. With social media such as Twitter, it becomes easier to spread or find hate speech. To reduce online hate speech, we made a classification system to detect hate speech from Twitter. This system uses LightGBM, which was the development of a Gradient Boosting Decision Tree (GBDT) Algorithm. GBDT was often used for this type of classification, but the outcome was less satisfactory. LightGBM uses Gradient-based One Side Sampling (GOSS) and Exclusive Feature Bundling (EFB). With these two techniques implemented in GBDT, this research experiment's accuracy is 86,05% with a total of 1000 data, a 0.175 learning rate, 30% test data, and 70% training data. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Industrial internet of things: Recent advances, enabling technologies and open challenges"
        ],
        "penulis":"Khan W.Z.;Rehman M.H.;Zangoti H.M.;Afzal M.K.;Armi N.;Salah K.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The adoption of emerging technological trends and applications of the Internet of Things (IoT) in the industrial systems is leading towards the development of Industrial IoT (IIoT). IIoT serves as a new vision of IoT in the industrial sector by automating smart objects for sensing, collecting, processing and communicating the real-time events in industrial systems. The major objective of IIoT is to achieve high operational efficiency, increased productivity, and better management of industrial assets and processes through product customization, intelligent monitoring applications for production floor shops and machine health, and predictive and preventive maintenance of industrial equipment. In this paper, we present a new and clear definition of IIoT, which can help the readers to understand the concept of IIoT. We have described the state-of-the-art research efforts in IIoT. Finally, we have highlighted the enabling technologies for IIoT and recent challenges faced by IIoT. \u00a9 2019",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The adoption of emerging technological trends and applications of the Internet of Things (IoT) in the industrial systems is leading towards the development of Industrial IoT (IIoT). IIoT serves as a new vision of IoT in the industrial sector by automating smart objects for sensing, collecting, processing and communicating the real-time events in industrial systems. The major objective of IIoT is to achieve high operational efficiency, increased productivity, and better management of industrial assets and processes through product customization, intelligent monitoring applications for production floor shops and machine health, and predictive and preventive maintenance of industrial equipment. In this paper, we present a new and clear definition of IIoT, which can help the readers to understand the concept of IIoT. We have described the state-of-the-art research efforts in IIoT. Finally, we have highlighted the enabling technologies for IIoT and recent challenges faced by IIoT. \u00a9 2019"
        ]
    },
    {
        "judul":[
            "Classification of Student Academic Performance using Fuzzy Soft Set"
        ],
        "penulis":"Riyadi Yanto, Iwan Tri;Sutoyo, Edi;Rahman, Arif;Hidayat, Rahmat;Ramli, Azizul Azhar;Fudzee, Mohd Farhan Md.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Students are one of the substances that need to be considered in relation to the world of education, because students are translators of the dynamics of science, and carry out the task of exploring that knowledge. As a subject with potential and, at the same time, objects in their activities and creativity, students are expected to be able to develop their qualities. The quality can be seen from the academic achievements achieved, which are evidence of the effort earned by students. Student academic achievement is evaluated at the end of each semester to determine the learning outcomes that have been achieved. If a student cannot meet certain academic criteria to be declared eligible to continue their studies, the student is declared to be not graduating on time or even dropout (DO). The high number of students not graduating on time or dropouts at higher institutions can be minimized by the policies of higher institutions by directing and detecting at-risk students in the early stages of education. Therefore, in this paper, we present the use of Fuzzy Soft Set Classification (FSSC), which is based on the Fuzzy Soft set theory to predict student graduation. The 2068 dataset was taken from the Directorate of Information Systems, Ahmad Dahlan University. The results showed that the FSSC reached up to 0.893292 in terms of accuracy. So, it is expected to be able to detect students at risk in the early stages of education so that higher education can minimize students not graduating on time or dropout by providing appropriate treatment and designing strategic programs. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Students are one of the substances that need to be considered in relation to the world of education, because students are translators of the dynamics of science, and carry out the task of exploring that knowledge. As a subject with potential and, at the same time, objects in their activities and creativity, students are expected to be able to develop their qualities. The quality can be seen from the academic achievements achieved, which are evidence of the effort earned by students. Student academic achievement is evaluated at the end of each semester to determine the learning outcomes that have been achieved. If a student cannot meet certain academic criteria to be declared eligible to continue their studies, the student is declared to be not graduating on time or even dropout (DO). The high number of students not graduating on time or dropouts at higher institutions can be minimized by the policies of higher institutions by directing and detecting at-risk students in the early stages of education. Therefore, in this paper, we present the use of Fuzzy Soft Set Classification (FSSC), which is based on the Fuzzy Soft set theory to predict student graduation. The 2068 dataset was taken from the Directorate of Information Systems, Ahmad Dahlan University. The results showed that the FSSC reached up to 0.893292 in terms of accuracy. So, it is expected to be able to detect students at risk in the early stages of education so that higher education can minimize students not graduating on time or dropout by providing appropriate treatment and designing strategic programs. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Simulation of transport problem with clustering velocity-density function"
        ],
        "penulis":"Daniswara, Ferdian Akbar;Gunawan P.H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper discusses the use of K-Means clustering method in finding an estimate of the velocity-density function in the traffic flow model. Two clusters will be obtained using KMeans clustering process, which are jammed and light cluster. These two clusters will have different velocity-density functions based on clustering result. Here, velocity-density function is obtained from linear regression of each data cluster. For measuring the velocity-density function, then this paper will provide the value of RMSE and R-Squared. The results show that RMSE is 2.3396 and R-squared is 0.3591 when no cluster is implemented in numerical simulation. Meanwhile, for the light cluster, the RMSE is found 1.1795 and R-squared 0.1388. Moreover, for the jammed cluster, RMSE is 0.8723 and R-squared is 0.1357. Finally, the process of identifying traffic conditions in the numerical simulation is done by computing Euclidean distance from centroid of clusters.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper discusses the use of K-Means clustering method in finding an estimate of the velocity-density function in the traffic flow model. Two clusters will be obtained using KMeans clustering process, which are jammed and light cluster. These two clusters will have different velocity-density functions based on clustering result. Here, velocity-density function is obtained from linear regression of each data cluster. For measuring the velocity-density function, then this paper will provide the value of RMSE and R-Squared. The results show that RMSE is 2.3396 and R-squared is 0.3591 when no cluster is implemented in numerical simulation. Meanwhile, for the light cluster, the RMSE is found 1.1795 and R-squared 0.1388. Moreover, for the jammed cluster, RMSE is 0.8723 and R-squared is 0.1357. Finally, the process of identifying traffic conditions in the numerical simulation is done by computing Euclidean distance from centroid of clusters.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Analysis of On-Off Keying Modulation on Underwater Visible Light Communication"
        ],
        "penulis":"Amalia, Annisa Izmi;Hambali, Akhmad;Pamukti, Brian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research evaluates the performance of On-Off Keying (OOK) Modulation on the Underwater Visible Light Communication (UVLC) system. This research analyses the performance of two types of OOK signal formats, Non-Return to Zero (OOK-NRZ) and Return to Zero (OOK-RZ). This signal formats tested on distance, acceptability, Signal to Noise Ratio (SNR), Q-factor and Bit Error Rate (BER) parameters. From extensive simulations that have been done, the results show that the received power decreased 21.7249 % at the maximum distance. In this condition, the UVLC system produced the BER value of the NRZ format 3.28 \u00d7 smaller than the RZ format. The SNR minimum that produced BER value less than the threshold for NRZ format is 17.925% smaller than the RZ format. Meanwhile, the minimum Q-factor that produced BER value less than 10-3for NRZ modulation is 6 \u00d7 smaller than the RZ modulation format. From the results, we take the conclusion that the OOK-NRZ better than OOK-RZ on the UVLC system. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research evaluates the performance of On-Off Keying (OOK) Modulation on the Underwater Visible Light Communication (UVLC) system. This research analyses the performance of two types of OOK signal formats, Non-Return to Zero (OOK-NRZ) and Return to Zero (OOK-RZ). This signal formats tested on distance, acceptability, Signal to Noise Ratio (SNR), Q-factor and Bit Error Rate (BER) parameters. From extensive simulations that have been done, the results show that the received power decreased 21.7249 % at the maximum distance. In this condition, the UVLC system produced the BER value of the NRZ format 3.28 \u00d7 smaller than the RZ format. The SNR minimum that produced BER value less than the threshold for NRZ format is 17.925% smaller than the RZ format. Meanwhile, the minimum Q-factor that produced BER value less than 10-3for NRZ modulation is 6 \u00d7 smaller than the RZ modulation format. From the results, we take the conclusion that the OOK-NRZ better than OOK-RZ on the UVLC system. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Student Activities Recommendations to Achieve First Job Waiting Time Target of Graduates in Telkom University: Decision Tree Approach"
        ],
        "penulis":"Rifansyah, Muhammad;Kurniawati, Amelia;Supratman,, Nurdinitya Athari;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The first job search time is one of the measurement values of a university, an \"A\"accredited university if the average time for a student's job search is less than three months. According to the Telkom University tracer study in 2016-2018, there was a significant increase of students who experience the first job search time for more than three months from 18% up to 54%. The purpose of this study is to classify which students will have the potential to experience the first job search time for more than three months based on tracer study, history of organization type, position, Grade Point Average (GPA), and remaining semester credit units. With the results of using the classification process with decision tree C5.0 algorithm, the model has accuracy 54.7% with three attributes that are considered, GPA, study period, and participating in educational\/reasoning\/arts organizations. This helps Telkom University in monitoring students who are indicated to be experiencing a short or long first job waiting time. Therefore, Telkom University can provide specific activity recommendations for students, based on their GPA, remaining semester credits, and organizational activities. For further research, it can be more variables can be added to develop a model with higher accuracy. \u00a9 2020 Association for Computing Machinery.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The first job search time is one of the measurement values of a university, an \"A\"accredited university if the average time for a student's job search is less than three months. According to the Telkom University tracer study in 2016-2018, there was a significant increase of students who experience the first job search time for more than three months from 18% up to 54%. The purpose of this study is to classify which students will have the potential to experience the first job search time for more than three months based on tracer study, history of organization type, position, Grade Point Average (GPA), and remaining semester credit units. With the results of using the classification process with decision tree C5.0 algorithm, the model has accuracy 54.7% with three attributes that are considered, GPA, study period, and participating in educational\/reasoning\/arts organizations. This helps Telkom University in monitoring students who are indicated to be experiencing a short or long first job waiting time. Therefore, Telkom University can provide specific activity recommendations for students, based on their GPA, remaining semester credits, and organizational activities. For further research, it can be more variables can be added to develop a model with higher accuracy. \u00a9 2020 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "The effect of e-service quality on e-satisfaction: Case study of lazada users in pekanbaru, indonesia"
        ],
        "penulis":"Wardhana, Aditya;Kartawinata, Budi Rustandi;Nugraha, Diki Wahyu;Firmansyah, Iqbal;Prahara, Galang Tegar;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study aims to determine the effect of the influence of service quality consisting of Efficiency, Reability, Fulfilment, Privation, Responability to E-Costumer satisfaction in Pekanbaru. This research is a survey research using a questionnaire as an instrument. The population used in this study is lazada users in Pekanbaru. using a purposive sampling method, which is a sample selection technique where an individual chooses a sample based on a personal assessment of some appropriate characteristics of the sample members. Test the validity of the instrument using SPSS software, the analysis technique used is regression analysis. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to determine the effect of the influence of service quality consisting of Efficiency, Reability, Fulfilment, Privation, Responability to E-Costumer satisfaction in Pekanbaru. This research is a survey research using a questionnaire as an instrument. The population used in this study is lazada users in Pekanbaru. using a purposive sampling method, which is a sample selection technique where an individual chooses a sample based on a personal assessment of some appropriate characteristics of the sample members. Test the validity of the instrument using SPSS software, the analysis technique used is regression analysis. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "User Interface Design of P2P Lending Mobile Application Using Design Thinking"
        ],
        "penulis":"Yusaliano, Muhammad Rozzaq;Syahrina, Alvi;Kusumasari, Tien Fabrianti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The maturity of mobile technology made market transaction activities to be shifted online. This cause the development of a good user interface to become more important due to the power of a first impression in gaining a potential customer. This paper presents a detailed, step-by-step user interface design for a peer-to-peer lending mobile application called Minjemin. This is done using a well-known iterative process called Design Thinking, which is implemented to ensure a good design compared to not using any methodology. The paper will explore each step (microcycle) of Design Thinking while also describing how to implement the related design methodologies for each step. The proposed designs were tested by more than thirty testers to ensure removal of bias and resulting in a design that is satisfactory according to the Maze Prototype Usability Score and System Usability Scale scores. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The maturity of mobile technology made market transaction activities to be shifted online. This cause the development of a good user interface to become more important due to the power of a first impression in gaining a potential customer. This paper presents a detailed, step-by-step user interface design for a peer-to-peer lending mobile application called Minjemin. This is done using a well-known iterative process called Design Thinking, which is implemented to ensure a good design compared to not using any methodology. The paper will explore each step (microcycle) of Design Thinking while also describing how to implement the related design methodologies for each step. The proposed designs were tested by more than thirty testers to ensure removal of bias and resulting in a design that is satisfactory according to the Maze Prototype Usability Score and System Usability Scale scores. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Designing A Reading Chair using Kansei Engineering Approach"
        ],
        "penulis":"Rahayu, Mira;Ekananda, Hilman Ardian;Mufidah, Ilma;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Supporting facilities such as reading chair are often used as a scene to read books. However, the existing reading chair has not satisfied the user. This Research uses Kansei Engineering which purpose to design a reading chair that fulfil user needs. Kansei Engineering was chosen in this research because it can translate customer's impression, feeling, and demands on existing products or concepts to design concrete solutions and parameters into product design. This research is done on students in the Bandung area who use reading chair. Using a questionnaire as a tool to collect data that distributed online with google form to 347 respondents. Questionnaire data was processed using KMO statistical test and Barlett test, so from 23 Kansei word that had been obtained there was a reduction to 15 Kansei word would be used into designing reading chair in this research. The results of this research states, the implementation of Kansei Engineering could be done in the design of reading chairs, and there are innovations to meet user needs such as, armrest, headrest and footrest. Also USB port, lights, and book storage area. All of that can be used by users. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Supporting facilities such as reading chair are often used as a scene to read books. However, the existing reading chair has not satisfied the user. This Research uses Kansei Engineering which purpose to design a reading chair that fulfil user needs. Kansei Engineering was chosen in this research because it can translate customer's impression, feeling, and demands on existing products or concepts to design concrete solutions and parameters into product design. This research is done on students in the Bandung area who use reading chair. Using a questionnaire as a tool to collect data that distributed online with google form to 347 respondents. Questionnaire data was processed using KMO statistical test and Barlett test, so from 23 Kansei word that had been obtained there was a reduction to 15 Kansei word would be used into designing reading chair in this research. The results of this research states, the implementation of Kansei Engineering could be done in the design of reading chairs, and there are innovations to meet user needs such as, armrest, headrest and footrest. Also USB port, lights, and book storage area. All of that can be used by users. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Indonesian university students' entrepreneurial intention: A conceptual study"
        ],
        "penulis":"Pradana, Mahir;Wardhana, Aditya;Wijayangka, Candra;Kartawinata, Budi Rustandi;Wahyuddin S.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Either in public, private or vocational universities, entrepreneurship is recognized as a decent field of study, as a derivation of economics and business. Therefore, it is quite important to measure the entrepreneurial intention of the students. Therefore, entrepreneurship is a process requiring someone or group to act or behave in finding, evaluating, and exploiting the existing opportunities in production of items, service, or new effective process, so they will be able to compete with their own resources. While entrepreneurship intention can be defined as first step in a construction process of a commonly long-term effort or seen as an intention to commence a new business. there is contextual element including academic support, social support, and environment condition. Therefore, this study aims to provide theoretical approach on entrepreneurship intention of university students. \u00a9 2020 by Advance Scientific Research. This is an open-access article under the CC BY license (http:\/\/creativecommons.org\/licenses\/by\/4.0\/)",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Either in public, private or vocational universities, entrepreneurship is recognized as a decent field of study, as a derivation of economics and business. Therefore, it is quite important to measure the entrepreneurial intention of the students. Therefore, entrepreneurship is a process requiring someone or group to act or behave in finding, evaluating, and exploiting the existing opportunities in production of items, service, or new effective process, so they will be able to compete with their own resources. While entrepreneurship intention can be defined as first step in a construction process of a commonly long-term effort or seen as an intention to commence a new business. there is contextual element including academic support, social support, and environment condition. Therefore, this study aims to provide theoretical approach on entrepreneurship intention of university students. \u00a9 2020 by Advance Scientific Research. This is an open-access article under the CC BY license (http:\/\/creativecommons.org\/licenses\/by\/4.0\/)"
        ]
    },
    {
        "judul":[
            "English Adjectives in Indonesian Cosmetic Advertisement: A Study of Emphatic Personal Metadiscourse Markers"
        ],
        "penulis":"Kurniasih, Nia;Nurhayati, Lis Kurnia;Lestari, Puji Audina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The growth of the globalization of brands in international markets has led to the inevitable importance of advertisement and hence to scholarship on advertisement, such as with methods of metadiscourse. This descriptive qualitative study was aimed at determining interpersonal metadiscourse markers used in eight advertisements of Indonesian cosmetic products using English in the construction of beauty within contemporary Indonesian contexts. The results evidence an emerging new terminology in defining and classifying the types of beauty as a social construct presented in product advertisements. Employing a discourse analysis and Hylans's emphatic personal metadiscourse marker adjectives, it was found that the advertising makers have used adjectives to describe nouns in the advertising texts due to their persuasive meanings, namely those of aesthetic adjectives. The adjectives found in the data belong to several categories, i.e. evaluativity, dimensionality (unidimensional and multidimensional), and mcasurability. All of these adjectives have constructed the concept of green beauty, healthy beauty, modern beauty, religious beauty and aesthetic beauty. This study is expected to contribute to the development of language and media studies, and to enrich media studies, especially those that can enhance the strategies used by advertising agencies to choose the most effective kind of language in their advertisements. \u00a9 2020 GLOCAL Conference Proceedings. All rights reserved."
        ],
        "abstrak":[
            "The growth of the globalization of brands in international markets has led to the inevitable importance of advertisement and hence to scholarship on advertisement, such as with methods of metadiscourse. This descriptive qualitative study was aimed at determining interpersonal metadiscourse markers used in eight advertisements of Indonesian cosmetic products using English in the construction of beauty within contemporary Indonesian contexts. The results evidence an emerging new terminology in defining and classifying the types of beauty as a social construct presented in product advertisements. Employing a discourse analysis and Hylans's emphatic personal metadiscourse marker adjectives, it was found that the advertising makers have used adjectives to describe nouns in the advertising texts due to their persuasive meanings, namely those of aesthetic adjectives. The adjectives found in the data belong to several categories, i.e. evaluativity, dimensionality (unidimensional and multidimensional), and mcasurability. All of these adjectives have constructed the concept of green beauty, healthy beauty, modern beauty, religious beauty and aesthetic beauty. This study is expected to contribute to the development of language and media studies, and to enrich media studies, especially those that can enhance the strategies used by advertising agencies to choose the most effective kind of language in their advertisements. \u00a9 2020 GLOCAL Conference Proceedings. All rights reserved."
        ]
    },
    {
        "judul":[
            "Foot Plantar Pressure to Detect Obesity"
        ],
        "penulis":"Nursida, Yulistia Elsa;Erfianto, Bayu;Rakhmatsyah, Andrian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Physically we can see that there is a difference between obese and non-obese people, it's seen from a fatter body posture. Then we can categorize the person into obese or not by calculating the Body Mass Index (BMI). But this still must be done manually because we have to check weight and height first, then calculated BMI according to the BMI formula. Therefore we need a system that can be used to detect obesity automatically. In this study, we created a system that can detect obesity automatically based on foot plantar pressure. On foot plantar pressure there is a significant change between foot pressure in obese and non-obese people. In obese people the pressure will be further increased in the metatarsal foot, heel, and midfoot. This is because the heel is part of the foot which is the main support of the body and in the midfoot there are different levels of leg curvature between obese and non-obese people. The system is built using Fuzzy Inference System based on Fuzzy Logic Concept. So, the system can provide an automatic output whether the person is categorized as thin, normal, or obese.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Physically we can see that there is a difference between obese and non-obese people, it's seen from a fatter body posture. Then we can categorize the person into obese or not by calculating the Body Mass Index (BMI). But this still must be done manually because we have to check weight and height first, then calculated BMI according to the BMI formula. Therefore we need a system that can be used to detect obesity automatically. In this study, we created a system that can detect obesity automatically based on foot plantar pressure. On foot plantar pressure there is a significant change between foot pressure in obese and non-obese people. In obese people the pressure will be further increased in the metatarsal foot, heel, and midfoot. This is because the heel is part of the foot which is the main support of the body and in the midfoot there are different levels of leg curvature between obese and non-obese people. The system is built using Fuzzy Inference System based on Fuzzy Logic Concept. So, the system can provide an automatic output whether the person is categorized as thin, normal, or obese.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Evaluation of Radio Resource Allocation Algorithm for 5G Device-to-Device Communication Underlying on 4G LTE Networks"
        ],
        "penulis":"Ramadhan, Mohamad Yasin;Nashiruddin, Muhammad Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One of the advanced features of 5G technology is the Device-to-Device (D2D) communication, which capable of serving peer to peer communication, and D2D pair can communicate directly without having to pass through the Base Transceiver Station by re-using the frequency spectrum (resource) from the cellular user. D2D communication led to significant interference on mobile networks when sharing radio resources, and precise radio resource allocation requires algorithms to reduce interference. This study aims to evaluate the most optimal radio resource allocation algorithm of 5G D2D communication underlying on a 4G LTE network using heuristic algorithms, minimum interference algorithms, and random allocation algorithms. Each algorithm tested with the scenario that involved variations of the cell radius distance, the value of data rate, fairness, and energy efficiency to determine the most optimal algorithm. The result shows that the higher amount of cell radius distance in a system makes the value of the system's data rate, fairness, and energy efficiency smaller because the gain on the device in the system also becomes smaller. Heuristic algorithms were having better data rates and energy efficiency compared to other algorithms. Therefore, it is suitable to be used when the level of system complexity is high. However, it works less optimally when a system has a vast cell radius because the heuristic algorithm's performance value tends to decrease with a more significant difference at each increase. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the advanced features of 5G technology is the Device-to-Device (D2D) communication, which capable of serving peer to peer communication, and D2D pair can communicate directly without having to pass through the Base Transceiver Station by re-using the frequency spectrum (resource) from the cellular user. D2D communication led to significant interference on mobile networks when sharing radio resources, and precise radio resource allocation requires algorithms to reduce interference. This study aims to evaluate the most optimal radio resource allocation algorithm of 5G D2D communication underlying on a 4G LTE network using heuristic algorithms, minimum interference algorithms, and random allocation algorithms. Each algorithm tested with the scenario that involved variations of the cell radius distance, the value of data rate, fairness, and energy efficiency to determine the most optimal algorithm. The result shows that the higher amount of cell radius distance in a system makes the value of the system's data rate, fairness, and energy efficiency smaller because the gain on the device in the system also becomes smaller. Heuristic algorithms were having better data rates and energy efficiency compared to other algorithms. Therefore, it is suitable to be used when the level of system complexity is high. However, it works less optimally when a system has a vast cell radius because the heuristic algorithm's performance value tends to decrease with a more significant difference at each increase. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Proposed optimal maintenance intervals for milling machine using risk based maintenance and analytical hierarchy process at manufacturing plant"
        ],
        "penulis":"Farid D.A.;Budiasih E.;Alhilman J.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT IIS is an outsourcing company that offers manufacturing spare parts and dies forging. In producing dies forging product PT IIS uses Milling machines, lathes, and CNC 20-L Liquy Hising machines. Based on machine failure data, milling machines suffered a total of 27 times failure during the 2018-2019 period, the frequency of failure will affect the production process and resulted in large maintenance costs. Thus, it takes more observation regarding the maintenance of the Milling machine. The method used for research is Risk-based maintenance (RBM) which aims to estimate and minimize risks arising from failure. The results of collection and processing using RBM revealed that Milling machines with 2880 hours maintenance intervals had a total risk of Rp6,395,124.84 with the percentage of 0.67% exceeding the company's risk tolerance limit of 0.50%. Using the approach to minimizing risks, the proposed maintenance interval is 1100 hours and is at the company's risk acceptance criteria of 0.50%. This study also uses the Analytical Hierarchy Process (AHP) method which decides the maintenance policies that are tailored to the company's conditions, for Spindel components and rags using condition-based maintenance, and coolant hose components using time-based maintenance. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT IIS is an outsourcing company that offers manufacturing spare parts and dies forging. In producing dies forging product PT IIS uses Milling machines, lathes, and CNC 20-L Liquy Hising machines. Based on machine failure data, milling machines suffered a total of 27 times failure during the 2018-2019 period, the frequency of failure will affect the production process and resulted in large maintenance costs. Thus, it takes more observation regarding the maintenance of the Milling machine. The method used for research is Risk-based maintenance (RBM) which aims to estimate and minimize risks arising from failure. The results of collection and processing using RBM revealed that Milling machines with 2880 hours maintenance intervals had a total risk of Rp6,395,124.84 with the percentage of 0.67% exceeding the company's risk tolerance limit of 0.50%. Using the approach to minimizing risks, the proposed maintenance interval is 1100 hours and is at the company's risk acceptance criteria of 0.50%. This study also uses the Analytical Hierarchy Process (AHP) method which decides the maintenance policies that are tailored to the company's conditions, for Spindel components and rags using condition-based maintenance, and coolant hose components using time-based maintenance. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Phonocardiogram Classification using Multilevel Wavelet Packet Entropy and Random Forest"
        ],
        "penulis":"Rizal, Achmad;Wijayanto, Inung;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Heart sound is an acoustic signal that occurs due to the pumping process of blood in the heart. Heart sounds have different information than ECG signals because they reflect different processes. Heart sounds are heard using a stethoscope and are assessed subjectively. Various methods are used to analyze heart sounds digitally. In this study, a multilevel wavelet packet entropy (MWPE) method was proposed for the heart sounds feature extraction. MWPE was performed using five types of mother wavelets with decomposition level 7 and tested on four classes of heart sound data. The highest classification accuracy reached 96.7% using the random forest as a classifier. These results indicated that the proposed method provides pretty good performance for the classification of heart sounds. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Heart sound is an acoustic signal that occurs due to the pumping process of blood in the heart. Heart sounds have different information than ECG signals because they reflect different processes. Heart sounds are heard using a stethoscope and are assessed subjectively. Various methods are used to analyze heart sounds digitally. In this study, a multilevel wavelet packet entropy (MWPE) method was proposed for the heart sounds feature extraction. MWPE was performed using five types of mother wavelets with decomposition level 7 and tested on four classes of heart sound data. The highest classification accuracy reached 96.7% using the random forest as a classifier. These results indicated that the proposed method provides pretty good performance for the classification of heart sounds. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Undesignated Academic Mosque Response Toward COVID-19 Pandemic"
        ],
        "penulis":"Harsritanto, Bangun I.R.;Nugroho, Satrio;Dewanta, Favian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Mosque is a unique building by the function as muslim prayer room. Indonesia as the world biggest muslim country has mandated each building to provide prayer room especially mosque by issuance of Ministry of Public Work-Housing Settlement decree no.14\/2017. Academic building like cam-puss also mandated to have the campus mosque to facilitate the Muslim's civitas academia performing their prayer. However, the campus buildings commonly were not designed with mosque facility in purpose. Thus, campus designer performed remodelling their building to meet this demand. During the pandemic COVID-19 in Indonesia, some of undesignated academic mosques in Architecture Undip were responded it with various adaptation. This study purposed to investigate the responses of those mosque and try to figure the scheme of adaptation phase using descriptive analysis. The result of this study found that the places were follow the government advices and brought alone prayer into common practice.  \u00a9 The Authors, published by EDP Sciences, 2020.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mosque is a unique building by the function as muslim prayer room. Indonesia as the world biggest muslim country has mandated each building to provide prayer room especially mosque by issuance of Ministry of Public Work-Housing Settlement decree no.14\/2017. Academic building like cam-puss also mandated to have the campus mosque to facilitate the Muslim's civitas academia performing their prayer. However, the campus buildings commonly were not designed with mosque facility in purpose. Thus, campus designer performed remodelling their building to meet this demand. During the pandemic COVID-19 in Indonesia, some of undesignated academic mosques in Architecture Undip were responded it with various adaptation. This study purposed to investigate the responses of those mosque and try to figure the scheme of adaptation phase using descriptive analysis. The result of this study found that the places were follow the government advices and brought alone prayer into common practice.  \u00a9 The Authors, published by EDP Sciences, 2020."
        ]
    },
    {
        "judul":[
            "Healthy food intake advisor using decision support system"
        ],
        "penulis":"Hwee, Lee Jia;Witarsyah, Deden;Kasim, Shahreen;Fudzee, Mohd Farhan Md;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The difficulties to decide the food to eat and do not have enough knowledge that what foods should be avoided when pregnant or when facing some health problem. Healthy Food Advisor is an Android based application which acts as a healthy controller to all of the users. The purpose of developing this application is to suggest healthy food to users based on their personal condition in order to make them have a healthy lifestyle. Users are required to record all of the details such as age, height and weight, so the application and calculate the Body Mass Index (BMI) value and caloric needs to user. Application will recommended the most suitable food lists to users according to their personal condition. Through this application, users no longer need to spend more time to think on a meal and busy to search from online that the nutrition information of food. The methodology used to develop this Android based application is Object-oriented Software Development (OOSD) model. Software technology used to develop this application is Ionic Framework where this technology uses web technology language to develop mobile hybrid application. Database used for this system is Firebase while programming language used to develop this application is AngularJS, HTML, TypeScript and SCSS. Hereby, this application is able to provide a simple and portable solution to help people decide the food and increase the knowledge of the public. \u00a9 2020, IJSTR.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The difficulties to decide the food to eat and do not have enough knowledge that what foods should be avoided when pregnant or when facing some health problem. Healthy Food Advisor is an Android based application which acts as a healthy controller to all of the users. The purpose of developing this application is to suggest healthy food to users based on their personal condition in order to make them have a healthy lifestyle. Users are required to record all of the details such as age, height and weight, so the application and calculate the Body Mass Index (BMI) value and caloric needs to user. Application will recommended the most suitable food lists to users according to their personal condition. Through this application, users no longer need to spend more time to think on a meal and busy to search from online that the nutrition information of food. The methodology used to develop this Android based application is Object-oriented Software Development (OOSD) model. Software technology used to develop this application is Ionic Framework where this technology uses web technology language to develop mobile hybrid application. Database used for this system is Firebase while programming language used to develop this application is AngularJS, HTML, TypeScript and SCSS. Hereby, this application is able to provide a simple and portable solution to help people decide the food and increase the knowledge of the public. \u00a9 2020, IJSTR."
        ]
    },
    {
        "judul":[
            "Brand Awareness Using Network Modeling Method"
        ],
        "penulis":"Firdaus, Muhamad Fulki;Baizal Z.K.A.;Bratawisnu, Made Kevin;Gusman, Hanafi Abdullah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The using of online social network has made powerful evolution in digital era. Nowadays, social network is a center of information exchange. Online social networks provide information in the form of user opinion about their brand awareness. The user's opinion represents the level of awareness of the user regarding the existence of the brand. The circulation of information on the social network is widely known as User Generated Content (UGC). Organizations can use the UGC data to assess their brand rankings. The proper method is needed to be able to process UGC so that it is able to generate insight for the organization. This study utilizes social network phenomena to measure brand ranking in analyzing human awareness of a brand using Social Network Analysis (SNA). SNA is an analysis method for observing social network (or social media) by graph modelling. We use network properties to measure interaction intensity on Traveloka.com, Tiket.com, and Pegi-Pegi.com. The results show that the brand awareness of Pegi-Pegi is superior compared to the others. Network property valuation can be used as an alternative for ranking the company's position based on UGC in social media, especially Twitter.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The using of online social network has made powerful evolution in digital era. Nowadays, social network is a center of information exchange. Online social networks provide information in the form of user opinion about their brand awareness. The user's opinion represents the level of awareness of the user regarding the existence of the brand. The circulation of information on the social network is widely known as User Generated Content (UGC). Organizations can use the UGC data to assess their brand rankings. The proper method is needed to be able to process UGC so that it is able to generate insight for the organization. This study utilizes social network phenomena to measure brand ranking in analyzing human awareness of a brand using Social Network Analysis (SNA). SNA is an analysis method for observing social network (or social media) by graph modelling. We use network properties to measure interaction intensity on Traveloka.com, Tiket.com, and Pegi-Pegi.com. The results show that the brand awareness of Pegi-Pegi is superior compared to the others. Network property valuation can be used as an alternative for ranking the company's position based on UGC in social media, especially Twitter.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Accuracy Analysis Transliteration Balinese Script-to-Latin Text Using Hexadecimal Labeling Method"
        ],
        "penulis":"Aranta, Arik;Witarsyah, Deden;Murpratiwi, Santi Ika;Abawajy, Jemal;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Balinese script is a collection of symbols used to communicate via text messages used by Balinese. Since the 804s or 9th century until now, the use of the Balinese script has been intensified by the Bali Provincial Government. The government has made various innovations to using the Balinese script in daily activities. Currently, technology has started to be applied in the Balinese script learning process, especially in the transliteration Latin characters into Balinese characters. This makes it easier to learn the Balinese script for all circles. However, behind the rapid development of Latin transliteration application technology to Balinese script, the reverse transliteration process from Balinese script to Latin script has become an interesting topic to be researched. In this study, the optimized string replacement method with the hexadecimal number format was used to improve the string replacement algorithm to translate Balinese script sentences into understandable Latin sentences. The optimization of this method resultedin an accuracy of 95.1 % from 464 test data. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Balinese script is a collection of symbols used to communicate via text messages used by Balinese. Since the 804s or 9th century until now, the use of the Balinese script has been intensified by the Bali Provincial Government. The government has made various innovations to using the Balinese script in daily activities. Currently, technology has started to be applied in the Balinese script learning process, especially in the transliteration Latin characters into Balinese characters. This makes it easier to learn the Balinese script for all circles. However, behind the rapid development of Latin transliteration application technology to Balinese script, the reverse transliteration process from Balinese script to Latin script has become an interesting topic to be researched. In this study, the optimized string replacement method with the hexadecimal number format was used to improve the string replacement algorithm to translate Balinese script sentences into understandable Latin sentences. The optimization of this method resultedin an accuracy of 95.1 % from 464 test data. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Syllable-Based Indonesian Lip Reading Model"
        ],
        "penulis":"Kurniawan, Adriana;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Lip reading is a communication method by reading the lips movement of a speaker. It is also called visual speech recognition, which converts a video into a text. The text is consisting of some words or even sentences spoken by the speakers. One of the challenges often encountered in a lip reading is the high variances of inputs. The variances, like facial features and different speed of speech, can decrease the accuracy. Nowadays, deep learning provides promising results in extracting visual features. In order to be able to use a video as the input, a 3D Deep Learning architecture is exploited. Besides, the out-of-vocabulary (OOV) problem also makes the visual speech recognition system harder to apply in the real world. It can only predict the words appear in the dictionary. However, the vocabulary continues to grow each year, especially in the Indonesian language. It is hard to fit all possible words into the system. Hence, a syllable-based model is proposed in this research to handle such a problem. The syllable-based model gives a chance to build a new word that does not appear in the dictionary. The combination of the existing syllable is used to construct a new word. Since the data obtained too small for deep learning, the augmentation process is performed 40 times. Evaluation using the augmented data, the proposed model reaches a high accuracy of 100% for the testing set. An examination using ten OOV words informs that the developed model gives a lower accuracy of 80%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Lip reading is a communication method by reading the lips movement of a speaker. It is also called visual speech recognition, which converts a video into a text. The text is consisting of some words or even sentences spoken by the speakers. One of the challenges often encountered in a lip reading is the high variances of inputs. The variances, like facial features and different speed of speech, can decrease the accuracy. Nowadays, deep learning provides promising results in extracting visual features. In order to be able to use a video as the input, a 3D Deep Learning architecture is exploited. Besides, the out-of-vocabulary (OOV) problem also makes the visual speech recognition system harder to apply in the real world. It can only predict the words appear in the dictionary. However, the vocabulary continues to grow each year, especially in the Indonesian language. It is hard to fit all possible words into the system. Hence, a syllable-based model is proposed in this research to handle such a problem. The syllable-based model gives a chance to build a new word that does not appear in the dictionary. The combination of the existing syllable is used to construct a new word. Since the data obtained too small for deep learning, the augmentation process is performed 40 times. Evaluation using the augmented data, the proposed model reaches a high accuracy of 100% for the testing set. An examination using ten OOV words informs that the developed model gives a lower accuracy of 80%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Choice Shrimp Technology based on Business Process, Productivity, Financial and Risk"
        ],
        "penulis":"Akbar, Wydzka Tasha Aulia;Chumaidiyah, Endang;Rendra, Meldi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The application of new technology in shrimp ponds, autofeeder, has many advantages, but carries a greater risk compared to conventional shrimp ponds, therefore a more structured analysis is needed to decide the best shrimp pond technology. The comparison is seen from business processes, productivity, financial and risk. The results of business process efficiency level with conventional worth 67.19% while for the autofeeder level worth 88.71%. The productivity results show FCR 1.34 (conventional) and 1.34 (autofeeder); SR 79% (conventional) and 90% (autofeeder); and productivity of 13 tons\/ha (conventional) and 25 tons\/ha (autofeeder). The financial shows an NPV of Rp 1, 515, 178.503 (conventional) and Rp 7, 721, 596, 229 (autofeeder); IRR 38.24% (conventional) and 51.23% (autofeeder); payback period 2.68 years (conventional) and 2.17 years (autofeeder); BCR 1, 696 (conventional) and 2, 065 (autofeeder). Furthermore, for the calculation of risk consisting of production risk and revenue risk with a total risk of 6% for conventional and 31% for autofeeder. In the results of technology selection with an assessment of the 15 criteria above, the results obtained 4 criteria are better for conventional technology and 11 criteria are better for autofeeder technology. So between the two technologies, the selected shrimp pond system is the Autofeeder technology. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The application of new technology in shrimp ponds, autofeeder, has many advantages, but carries a greater risk compared to conventional shrimp ponds, therefore a more structured analysis is needed to decide the best shrimp pond technology. The comparison is seen from business processes, productivity, financial and risk. The results of business process efficiency level with conventional worth 67.19% while for the autofeeder level worth 88.71%. The productivity results show FCR 1.34 (conventional) and 1.34 (autofeeder); SR 79% (conventional) and 90% (autofeeder); and productivity of 13 tons\/ha (conventional) and 25 tons\/ha (autofeeder). The financial shows an NPV of Rp 1, 515, 178.503 (conventional) and Rp 7, 721, 596, 229 (autofeeder); IRR 38.24% (conventional) and 51.23% (autofeeder); payback period 2.68 years (conventional) and 2.17 years (autofeeder); BCR 1, 696 (conventional) and 2, 065 (autofeeder). Furthermore, for the calculation of risk consisting of production risk and revenue risk with a total risk of 6% for conventional and 31% for autofeeder. In the results of technology selection with an assessment of the 15 criteria above, the results obtained 4 criteria are better for conventional technology and 11 criteria are better for autofeeder technology. So between the two technologies, the selected shrimp pond system is the Autofeeder technology. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "ECG-based prediction algorithm for imminent malignant ventricular arrhythmias using decision tree"
        ],
        "penulis":"Mandala, Satria;Cai Di, Tham;Sunar, Mohd Shahrizal;Adiwijaya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Spontaneous prediction of malignant ventricular arrhythmia (MVA) is useful to avoid delay in rescue operations. Recently, researchers have developed several algorithms to predict MVA using various features derived from electrocardiogram (ECG). However, there are several unresolved issues regarding MVA prediction such as the effect of number of ECG features on a prediction remaining unclear, possibility that an alert for occurring MVA may arrive very late and uncertainty in the performance of the algorithm predicting MVA minutes before onset. To overcome the aforementioned problems, this research conducts an in-depth study on the number and types of ECG features that are implemented in a decision tree classifier. In addition, this research also investigates an algorithm\u2019s execution time before the occurrence of MVA to minimize delays in warnings for MVA. Lastly, this research aims to study both the sensitivity and specificity of an algorithm to reveal the performance of MVA prediction algorithms from time to time. To strengthen the results of analysis, several classifiers such as support vector machine and naive Bayes are also examined for the purpose of comparison study. There are three phases required to achieve the objectives. The first phase is literature review on existing relevant studies. The second phase deals with design and development of four modules for predicting MVA. Rigorous experiments are performed in the feature selection and classification modules. The results show that eight ECG features with decision tree classifier achieved good prediction performance in terms of execution time and sensitivity. In addition, the results show that the highest percentage for sensitivity and specificity is 95% and 90% respectively, in the fourth 5-minute interval (15.1 minutes\u201320 minutes) that preceded the onset of an arrhythmia event. Such results imply that the fourth 5-minute interval would be the best time to perform prediction. \u00a9 2020 Mandala et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Spontaneous prediction of malignant ventricular arrhythmia (MVA) is useful to avoid delay in rescue operations. Recently, researchers have developed several algorithms to predict MVA using various features derived from electrocardiogram (ECG). However, there are several unresolved issues regarding MVA prediction such as the effect of number of ECG features on a prediction remaining unclear, possibility that an alert for occurring MVA may arrive very late and uncertainty in the performance of the algorithm predicting MVA minutes before onset. To overcome the aforementioned problems, this research conducts an in-depth study on the number and types of ECG features that are implemented in a decision tree classifier. In addition, this research also investigates an algorithm\u2019s execution time before the occurrence of MVA to minimize delays in warnings for MVA. Lastly, this research aims to study both the sensitivity and specificity of an algorithm to reveal the performance of MVA prediction algorithms from time to time. To strengthen the results of analysis, several classifiers such as support vector machine and naive Bayes are also examined for the purpose of comparison study. There are three phases required to achieve the objectives. The first phase is literature review on existing relevant studies. The second phase deals with design and development of four modules for predicting MVA. Rigorous experiments are performed in the feature selection and classification modules. The results show that eight ECG features with decision tree classifier achieved good prediction performance in terms of execution time and sensitivity. In addition, the results show that the highest percentage for sensitivity and specificity is 95% and 90% respectively, in the fourth 5-minute interval (15.1 minutes\u201320 minutes) that preceded the onset of an arrhythmia event. Such results imply that the fourth 5-minute interval would be the best time to perform prediction. \u00a9 2020 Mandala et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited."
        ]
    },
    {
        "judul":[
            "Fuzzy Swing Up Control and Optimal State Feedback Stabilization for Self-Erecting Inverted Pendulum"
        ],
        "penulis":"Susanto, Erwin;Surya Wibowo, Agung;Ghiffary Rachman, Elvandry;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents the realisation of self-erecting inverted pendulum controls via two switched control approaches, a rule based fuzzy control for swing up inverted pendulum rod to pose upright position from downright position and an optimal state feedback control for stabilization as pendulum on upright position close to its equilibrium vertical line. The aim of this study is to solve two important problems on self-erecting inverted pendulum; swing up and stability in its upright balance position. Simulation and experimental results showed that control methods enabled the inverted pendulum swinging up and reaching its stable attitude in upright position even though small impulse and pulse disturbances were given. \u00a9 2013 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents the realisation of self-erecting inverted pendulum controls via two switched control approaches, a rule based fuzzy control for swing up inverted pendulum rod to pose upright position from downright position and an optimal state feedback control for stabilization as pendulum on upright position close to its equilibrium vertical line. The aim of this study is to solve two important problems on self-erecting inverted pendulum; swing up and stability in its upright balance position. Simulation and experimental results showed that control methods enabled the inverted pendulum swinging up and reaching its stable attitude in upright position even though small impulse and pulse disturbances were given. \u00a9 2013 IEEE."
        ]
    },
    {
        "judul":[
            "Prediction of Sea Level by Using Autoregressive Integrated Moving Average (ARIMA): Case Study in Tanjung Intan Harbour Cilacap, Indonesia"
        ],
        "penulis":"Purba, Yehezkiel K. A.;Saepudin, Deni;Adytia, Didit;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Sea Level forecasting is vital for shores engineering applications such as for engineering construction plan in the shore or in offshore, and routing of ships at harbor. Researchers have been conducting many methods to predict sea levels, such as Artificial Neural Network, SARIMA, and ARIMA. In this paper, we will use a model of Autoregressive Integrated Moving Average (ARIMA) to predict sea level in Cilacap, Indonesia. The ARIMA parameters are obtained by conducting parameter tuning so that the model gives the lowest root mean square error value (RMSE) and the highest correlation coefficient.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sea Level forecasting is vital for shores engineering applications such as for engineering construction plan in the shore or in offshore, and routing of ships at harbor. Researchers have been conducting many methods to predict sea levels, such as Artificial Neural Network, SARIMA, and ARIMA. In this paper, we will use a model of Autoregressive Integrated Moving Average (ARIMA) to predict sea level in Cilacap, Indonesia. The ARIMA parameters are obtained by conducting parameter tuning so that the model gives the lowest root mean square error value (RMSE) and the highest correlation coefficient.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A multi tone modeling for seismic data compression"
        ],
        "penulis":"Liu, Bo;Mohandes M.;Nuha H.;Deriche M.;Iqbal, Naveed;Fekri, Faramarz;McClellan, James H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG"
        ]
    },
    {
        "judul":[
            "Software entrepreneurs\u2019 competencies based on business growth"
        ],
        "penulis":"Sudirman, Iman;Siswanto, Joko;Aisha, Atya Nur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Purpose: This study aims to identify the competencies of small- and medium-sized enterprises\u2019 (SMEs) entrepreneurs in the software sector and the perceived level of attainment in each competency. It also examines whether these competencies and their levels affect business turnover and growth (in terms of business scale and duration). Design\/methodology\/approach: To accomplish this purpose, the study took a quantitative approach, involving a survey of 33 SME entrepreneurs, which was then processed using statistical tests, including chi-square test, Kruskal\u2013Wallis test and ordinal regression. Findings: There were four findings of the study. Firstly, software SME entrepreneurs need 17 competencies, with high levels of soft competencies being required and average levels of technical competencies. Secondly, there are significant differences in perceived levels of customer service orientation (p = 0.089) depending on the scale of the business and in perceived levels of project management (p = 0.087) depending on the duration of the business. Thirdly, customer service orientation (p = 0.031) and project management (p = 0.01) both have a significant influence on business revenues. Fourthly, there were significant gaps in perceived levels of competency (p < 0.05) in achievement orientation, customer service orientation and project management. Originality\/value: There is existing research that conducts competency mappings at the managerial level in large-scale organizations; however, this sort of research in relation to SME entrepreneurs is still lacking. The present study seeks to fill this gap. It also maps integrated entrepreneurial competencies, including soft and technical competencies; a focus that is lacking in previous studies. \u00a9 2020, Emerald Publishing Limited.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: This study aims to identify the competencies of small- and medium-sized enterprises\u2019 (SMEs) entrepreneurs in the software sector and the perceived level of attainment in each competency. It also examines whether these competencies and their levels affect business turnover and growth (in terms of business scale and duration). Design\/methodology\/approach: To accomplish this purpose, the study took a quantitative approach, involving a survey of 33 SME entrepreneurs, which was then processed using statistical tests, including chi-square test, Kruskal\u2013Wallis test and ordinal regression. Findings: There were four findings of the study. Firstly, software SME entrepreneurs need 17 competencies, with high levels of soft competencies being required and average levels of technical competencies. Secondly, there are significant differences in perceived levels of customer service orientation (p = 0.089) depending on the scale of the business and in perceived levels of project management (p = 0.087) depending on the duration of the business. Thirdly, customer service orientation (p = 0.031) and project management (p = 0.01) both have a significant influence on business revenues. Fourthly, there were significant gaps in perceived levels of competency (p < 0.05) in achievement orientation, customer service orientation and project management. Originality\/value: There is existing research that conducts competency mappings at the managerial level in large-scale organizations; however, this sort of research in relation to SME entrepreneurs is still lacking. The present study seeks to fill this gap. It also maps integrated entrepreneurial competencies, including soft and technical competencies; a focus that is lacking in previous studies. \u00a9 2020, Emerald Publishing Limited."
        ]
    },
    {
        "judul":[
            "Model of tools for requirements elicitation process for children's learning applications"
        ],
        "penulis":"Sabariah, Mira Kania;Santosa, Paulus Insap;Ferdiana, Ridi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Requirements Elicitation are the initial stages in the application development process, where a set of needs from the system will be built and obtained by communicating with stakeholders who have a direct and indirect influence on those needs. Failure in the requirements elicitation process was caused by weak communication. Communication is an essential thing in carrying out the requirements elicitation process. The selection of the right elicitation technique is not only a solution. Informants as sources of information on requirements also need to be considered. The choice of the correct technique often fails because of the tools not useful. The availability of the right form of equipment needs to be considered so that the communication between the elicitation team and the informant goes well. Children have characteristics not the same as adults. Limitations in terms of psychomotor, cognitive, and emotional children are considered in choosing elicitation techniques and tools. These limitations are also influenced by the age range of child development. The use of digital elicitation devices is recommended to be used in the requirements elicitation process. The presentation of interactive tools makes it easier for children to convey their desires. In learning applications for children, aspects of pedagogy that need to be explored are learning styles and children's thinking abilities. Every child in every age range has a different preference for learning style. That is because children do not have learning experiences. That also applies to the level of thinking ability of children. Therefore, these two things need to be appropriately explored when the learning application development process. The proposed elicitation tool model was made by taking into account both components of that pedagogical aspects. The test results of the built model show that the application has satisfaction. That means that children can communicate well in conveying the needed as requirements to the learning application. \u00a9 2020, Science and Information Organization."
        ],
        "abstrak":[
            "Requirements Elicitation are the initial stages in the application development process, where a set of needs from the system will be built and obtained by communicating with stakeholders who have a direct and indirect influence on those needs. Failure in the requirements elicitation process was caused by weak communication. Communication is an essential thing in carrying out the requirements elicitation process. The selection of the right elicitation technique is not only a solution. Informants as sources of information on requirements also need to be considered. The choice of the correct technique often fails because of the tools not useful. The availability of the right form of equipment needs to be considered so that the communication between the elicitation team and the informant goes well. Children have characteristics not the same as adults. Limitations in terms of psychomotor, cognitive, and emotional children are considered in choosing elicitation techniques and tools. These limitations are also influenced by the age range of child development. The use of digital elicitation devices is recommended to be used in the requirements elicitation process. The presentation of interactive tools makes it easier for children to convey their desires. In learning applications for children, aspects of pedagogy that need to be explored are learning styles and children's thinking abilities. Every child in every age range has a different preference for learning style. That is because children do not have learning experiences. That also applies to the level of thinking ability of children. Therefore, these two things need to be appropriately explored when the learning application development process. The proposed elicitation tool model was made by taking into account both components of that pedagogical aspects. The test results of the built model show that the application has satisfaction. That means that children can communicate well in conveying the needed as requirements to the learning application. \u00a9 2020, Science and Information Organization."
        ]
    },
    {
        "judul":[
            "Network Security Analysis Using HTTPS with SSL on General Election Quick Count Website"
        ],
        "penulis":"Wibowo, Faiq;Nuha, Hilal Hudan;Wibowo, Sidik;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The general election is a democratic event held every five years to elect the candidate who will lead the country during the period. There are several pilot websites for data processing by the quick count survey institution. However, in terms of security, the sites are still lacking because of the applicability have not implemented security systems for the anticipation of the attacks were not responsible. In this proposal, the authors designed a security application quick count based crowd-sourcing. HTTPS and SSL is a security protocol that is commonly used to secure web or internet transactions. The use of HTTPS and SSL on a quick count of applications is expected to be able to anticipate and secure communications between the client and the server of the intruder's attack or unauthorized access. A simple implementation of SSL installation is shown to be able to reduce the vulnerability level and prevent the SQL injection attack. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The general election is a democratic event held every five years to elect the candidate who will lead the country during the period. There are several pilot websites for data processing by the quick count survey institution. However, in terms of security, the sites are still lacking because of the applicability have not implemented security systems for the anticipation of the attacks were not responsible. In this proposal, the authors designed a security application quick count based crowd-sourcing. HTTPS and SSL is a security protocol that is commonly used to secure web or internet transactions. The use of HTTPS and SSL on a quick count of applications is expected to be able to anticipate and secure communications between the client and the server of the intruder's attack or unauthorized access. A simple implementation of SSL installation is shown to be able to reduce the vulnerability level and prevent the SQL injection attack. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Level of student satisfaction with laboratory facilities using the importance performance analysis (IPA) method"
        ],
        "penulis":"Darwas, Rahmadini;Syukhri;Wulandari, Astri;Afthanorhan, Asyraf;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "STMIK Indonesia Padang is a high school in the field of computers. To produce quality human resources and be able to compete in their fields, one of the efforts is to provide facilities that support the teaching and learning process, namely the computer laboratory. STMIK Indonesia Padang laboratory facilities are adequate, however there are still complaints felt by students. This study aims to take policy in improving computer laboratory facilities. The study population was students of STMIK Indonesia Padang in 2015 and 2016 from 735 students. Based on this data, the average satisfaction score is lower than the average interest score. This means that students are less satisfied with laboratory facility services. The method used in this research is importance performance analysis (IPA). The results of data processing in the form of attributes that need to be improved quality of service with top priority are internet access in the laboratory, visual facilities as supporting learning processes in the laboratory, and the quality of the hardware used so that this research is very helpful in making future policies. \u00a9 2020, Institute of Advanced Scientific Research, Inc.. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "STMIK Indonesia Padang is a high school in the field of computers. To produce quality human resources and be able to compete in their fields, one of the efforts is to provide facilities that support the teaching and learning process, namely the computer laboratory. STMIK Indonesia Padang laboratory facilities are adequate, however there are still complaints felt by students. This study aims to take policy in improving computer laboratory facilities. The study population was students of STMIK Indonesia Padang in 2015 and 2016 from 735 students. Based on this data, the average satisfaction score is lower than the average interest score. This means that students are less satisfied with laboratory facility services. The method used in this research is importance performance analysis (IPA). The results of data processing in the form of attributes that need to be improved quality of service with top priority are internet access in the laboratory, visual facilities as supporting learning processes in the laboratory, and the quality of the hardware used so that this research is very helpful in making future policies. \u00a9 2020, Institute of Advanced Scientific Research, Inc.. All rights reserved."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Earthquake early warning system prototype based on lot using backpropagation algorithm"
        ],
        "penulis":"Pranesthi, Adi;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Earthquakes are vibrations that occur on the earth's surface due to the sudden release of energy from the inside that creates seismic waves. An earthquake is caused by the movement of the earth's crust (the earth's plate). The frequency of a region refers to the type and size of earthquakes experienced during a period. Along with the development of early earthquake detection system technology provides a solution to minimize earthquake events. This research will discuss the system's design to determine the occurrence of earthquakes through time pattern analysis and Peak Ground Acceleration value. By using the Radial Basis Function Method, which later to minimize the loss of life from earthquakes. And help the main tools owned by the government. This study aims to determine the occurrence of earthquakes from Peak Ground Acceleration values and time analysis patterns, which are obtained from the decision of the Backpropagation method with an accuracy rate of 88%. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Earthquakes are vibrations that occur on the earth's surface due to the sudden release of energy from the inside that creates seismic waves. An earthquake is caused by the movement of the earth's crust (the earth's plate). The frequency of a region refers to the type and size of earthquakes experienced during a period. Along with the development of early earthquake detection system technology provides a solution to minimize earthquake events. This research will discuss the system's design to determine the occurrence of earthquakes through time pattern analysis and Peak Ground Acceleration value. By using the Radial Basis Function Method, which later to minimize the loss of life from earthquakes. And help the main tools owned by the government. This study aims to determine the occurrence of earthquakes from Peak Ground Acceleration values and time analysis patterns, which are obtained from the decision of the Backpropagation method with an accuracy rate of 88%. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Implementation of Data Cleansing Null Method for Data Quality Management Dashboard using Pentaho Data Integration"
        ],
        "penulis":"Sulistyo, Haidar Alvinanda;Kusumasari, Tien Febrianti;Alam, Ekky Novriza;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Data is a collection of facts or information collected from various sources that are dirty andwill affect the quality of decision-making in an organization. Data cleansing ensures that the datais correct, useable, and consistent. Data may be incomplete, inaccurate, or has the wrong format and needs to be corrected or deleted. Data cleansing processing can improve the quality of the data significantly. The data cleansing processing requires to create useful quality data that provides significant benefits for the recipient. The availability of data is crucial in an organization to develop competent, valid, and trustworthy decisions. The null or blank field in data is one of many problems to maintain data quality management in an organization, especially in Indonesian government agencies. The brand registration number permits contain many blank fields, including the complete data needed for the next step processing. Therefore, to solve the amount of blank data, this research will discuss the design and implementation of the data cleansing null method using Pentaho Data Integration (PDI). The result will be implemented to the data quality management (DQM) dashboard using the laravel framework and MySQL as a DBMS. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data is a collection of facts or information collected from various sources that are dirty andwill affect the quality of decision-making in an organization. Data cleansing ensures that the datais correct, useable, and consistent. Data may be incomplete, inaccurate, or has the wrong format and needs to be corrected or deleted. Data cleansing processing can improve the quality of the data significantly. The data cleansing processing requires to create useful quality data that provides significant benefits for the recipient. The availability of data is crucial in an organization to develop competent, valid, and trustworthy decisions. The null or blank field in data is one of many problems to maintain data quality management in an organization, especially in Indonesian government agencies. The brand registration number permits contain many blank fields, including the complete data needed for the next step processing. Therefore, to solve the amount of blank data, this research will discuss the design and implementation of the data cleansing null method using Pentaho Data Integration (PDI). The result will be implemented to the data quality management (DQM) dashboard using the laravel framework and MySQL as a DBMS. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Event-based dynamic banking network exploration for economic anomaly detection"
        ],
        "penulis":"Alamsyah, Andry;Ramadhani, Dian Puteri;Kristanti, Farida Titik;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The instability of financial system issues might trigger a bank failure, evoke spillovers, and generate contagion effects which negatively impacted the financial system, ultimately on the economy. This phenomenon is the result of the highly interconnected banking transaction. The banking transactions network is considered as a financial architecture backbone. The strong interconnectedness between banks escalates contagion disruption spreading over the banking network and trigger the entire system collapse. This far, the financial instability is generally detected using macro approach mainly the uncontrolled transaction deficits amount and unpaid foreign debt. This research proposes financial instability detection in another point of view, through the macro view where the banking network structure are explored globally and micro view where focuses on the detailed network patterns called motif. Network triadic motif patterns used as a denomination to detect financial instability. The most related network triadic motif changes related to the instability period are determined as detector. We explore the banking network behavior under financial instability phenomenon along with the major religious event in Indonesia, Eid al-Fitr. We discover one motif pattern as the financial instability underlying detector. This research help to support the financial system stability supervision. \u00a9 2005 - ongoing JATIT & LLS.",
            "Sustainable Development Goals mapped to this documentReduced inequalitiesGoal 10Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The instability of financial system issues might trigger a bank failure, evoke spillovers, and generate contagion effects which negatively impacted the financial system, ultimately on the economy. This phenomenon is the result of the highly interconnected banking transaction. The banking transactions network is considered as a financial architecture backbone. The strong interconnectedness between banks escalates contagion disruption spreading over the banking network and trigger the entire system collapse. This far, the financial instability is generally detected using macro approach mainly the uncontrolled transaction deficits amount and unpaid foreign debt. This research proposes financial instability detection in another point of view, through the macro view where the banking network structure are explored globally and micro view where focuses on the detailed network patterns called motif. Network triadic motif patterns used as a denomination to detect financial instability. The most related network triadic motif changes related to the instability period are determined as detector. We explore the banking network behavior under financial instability phenomenon along with the major religious event in Indonesia, Eid al-Fitr. We discover one motif pattern as the financial instability underlying detector. This research help to support the financial system stability supervision. \u00a9 2005 - ongoing JATIT & LLS."
        ]
    },
    {
        "judul":[
            "Mask Classification and Head Temperature Detection Combined with Deep Learning Networks"
        ],
        "penulis":"Farady, Isack;Lin, Chih-Yang;Rojanasarit, Amornthep;Prompol, Kanatip;Akhyar, Fityanul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Due to the COVID-19 pandemic, wearing a mask is mandatory in public spaces, as properly wearing a mask offers a maximum preventive effect against viral transmission. Body temperature has also become an important consideration in determining whether an individual is healthy. In this work, we design a real-Time deep learning model to meet current demand to detect the mask-wearing position and head temperature of a person before he or she enters a public space. In this experiment, we use a deep learning object detection method to create a mask position and head temperature detector using a popular one-stage object detection, RetinaNet. We build two modules for the RetinaNet model to detect three categories of mask-wearing positions and the temperature of the head. We implement an RGB camera and thermal camera to generate input images and capture a person's temperature respectively. The output of these experiments is a live video that carries accurate information about whether a person is wearing a mask properly and what his or her head temperature is. Our model is light and fast, achieving a confidence score of 81.31% for the prediction object and a prediction speed below 0. 1s\/image. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Due to the COVID-19 pandemic, wearing a mask is mandatory in public spaces, as properly wearing a mask offers a maximum preventive effect against viral transmission. Body temperature has also become an important consideration in determining whether an individual is healthy. In this work, we design a real-Time deep learning model to meet current demand to detect the mask-wearing position and head temperature of a person before he or she enters a public space. In this experiment, we use a deep learning object detection method to create a mask position and head temperature detector using a popular one-stage object detection, RetinaNet. We build two modules for the RetinaNet model to detect three categories of mask-wearing positions and the temperature of the head. We implement an RGB camera and thermal camera to generate input images and capture a person's temperature respectively. The output of these experiments is a live video that carries accurate information about whether a person is wearing a mask properly and what his or her head temperature is. Our model is light and fast, achieving a confidence score of 81.31% for the prediction object and a prediction speed below 0. 1s\/image. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Typo handling in searching of quran verse based on phonetic similarities"
        ],
        "penulis":"Purwita, Naila Iffah;Bijaksana, Moch. Arif;Lhaksmana, Kemas Muslim;Naf\u2019an, Muhammad Zidny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The Quran search system is a search system that was built to make it easier for Indonesians to find a verse with text by Indonesian pronunciation, this is a solution for users who have difficulty writing or typing Arabic characters. Quran search system with phonetic similarity can make it easier for Indonesian Muslims to find a particular verse. Lafzi was one of the systems that developed the search, then Lafzi was further developed under the name Lafzi+. The Lafzi+ system can handle searches with typo queries but there are still fewer variations regarding typing error types. In this research Lafzi++, an improvement from previous development to handle typographical error types was carried out by applying typo correction using the autocomplete method to correct incorrect queries and Damerau Levenshtein distance to calculate the edit distance, so that the system can provide query suggestions when a user mistypes a search, either in the form of substitution, insertion, deletion, or transposition. Users can also search easily because they use Latin characters according to pronunciation in Indonesian. Based on the evaluation results it is known that the system can be better developed, this can be seen from the accuracy value in each query that is tested can surpass the accuracy of the previous system, by getting the highest recall of 96.20% and the highest Mean Average Precision (MAP) reaching 90.69%. The Lafzi++ system can improve the previous system. \u00a9 2020 Register: Jurnal Ilmiah Teknologi Sistem Informasi (Scientific Journal of Information System Technology) with CC BY NC SA license.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Quran search system is a search system that was built to make it easier for Indonesians to find a verse with text by Indonesian pronunciation, this is a solution for users who have difficulty writing or typing Arabic characters. Quran search system with phonetic similarity can make it easier for Indonesian Muslims to find a particular verse. Lafzi was one of the systems that developed the search, then Lafzi was further developed under the name Lafzi+. The Lafzi+ system can handle searches with typo queries but there are still fewer variations regarding typing error types. In this research Lafzi++, an improvement from previous development to handle typographical error types was carried out by applying typo correction using the autocomplete method to correct incorrect queries and Damerau Levenshtein distance to calculate the edit distance, so that the system can provide query suggestions when a user mistypes a search, either in the form of substitution, insertion, deletion, or transposition. Users can also search easily because they use Latin characters according to pronunciation in Indonesian. Based on the evaluation results it is known that the system can be better developed, this can be seen from the accuracy value in each query that is tested can surpass the accuracy of the previous system, by getting the highest recall of 96.20% and the highest Mean Average Precision (MAP) reaching 90.69%. The Lafzi++ system can improve the previous system. \u00a9 2020 Register: Jurnal Ilmiah Teknologi Sistem Informasi (Scientific Journal of Information System Technology) with CC BY NC SA license."
        ]
    },
    {
        "judul":[
            "Resource Allocation with Random Orientation Using the Greedy Algorithm Method for Visible Light Communication"
        ],
        "penulis":"Putra, Raga Filydevilia;Adriansyah, Nachwan Mufti;Pamukti, Brian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Visible Light Communication Technology (VLC) is a communication technology that has a large capacity in sending data. The allocation process is needed to improve the system quality in its implementation. This research will be focused to the process of allocating time slots to User Equipment (UE) by scheduling Greedy Algorithm. UE distribution is spreaded randomly in a 5x5x4 meter room with amounts from 6 to 24 UE and each direction of UE is changed gradually between 0\u00b0,15\u00b0, and30\u00b0. The test results shows that the average of the total increase value in system channel capacity to variations of UE increases 0.034% when the system using the scheduling Greedy algorithm andit requires power consumption which 2.19 times more efficient. Changing the receiver's point of view to 30\u00b0 results in an average total channel capacity of 1444.096 Mbps and the highest at 0\u00b0 with 1503.478 Mbps in variations of the UE, then the fairness value of the system is affected by the available UE. The highest fairness value is 0.833 when the number of UE is 6 while the lowest fairness value is 0.208 when there are 24 UE in the system. This is prove that with adding the amounts of UE can increase the total channel capacity and reduce the value of fairness system. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Visible Light Communication Technology (VLC) is a communication technology that has a large capacity in sending data. The allocation process is needed to improve the system quality in its implementation. This research will be focused to the process of allocating time slots to User Equipment (UE) by scheduling Greedy Algorithm. UE distribution is spreaded randomly in a 5x5x4 meter room with amounts from 6 to 24 UE and each direction of UE is changed gradually between 0\u00b0,15\u00b0, and30\u00b0. The test results shows that the average of the total increase value in system channel capacity to variations of UE increases 0.034% when the system using the scheduling Greedy algorithm andit requires power consumption which 2.19 times more efficient. Changing the receiver's point of view to 30\u00b0 results in an average total channel capacity of 1444.096 Mbps and the highest at 0\u00b0 with 1503.478 Mbps in variations of the UE, then the fairness value of the system is affected by the available UE. The highest fairness value is 0.833 when the number of UE is 6 while the lowest fairness value is 0.208 when there are 24 UE in the system. This is prove that with adding the amounts of UE can increase the total channel capacity and reduce the value of fairness system. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Human-Like Constrained-Mating to Make Genetic Algorithm More Explorative"
        ],
        "penulis":"Rizal, Achmad Choirul;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A genetic algorithm (GA) is widely used to solve many optimization problems. It does not promise accurate results but provides an acceptable ones in various practical applications. Sometimes, it is trapped at a premature convergence or a local optimum for a complex problem. Hence, a Human-Like Constrained-Mating Genetic Algorithm (HLCMGA) is proposed in this paper to tackle such a problem. HLCMGA can be simply described as a crossover with human-like constrained mating to improve exploration ability. Computer simulation on ten benchmark multi-modal functions shows that it performs better than the simple GA (SGA). Compared to a state-of-the-art Rao algorithm on five benchmark functions, it reaches the same performances on the four functions and just loses on one function. The simulation also informs that it has a higher exploration ability to converge at the global optimum on various complex search spaces.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A genetic algorithm (GA) is widely used to solve many optimization problems. It does not promise accurate results but provides an acceptable ones in various practical applications. Sometimes, it is trapped at a premature convergence or a local optimum for a complex problem. Hence, a Human-Like Constrained-Mating Genetic Algorithm (HLCMGA) is proposed in this paper to tackle such a problem. HLCMGA can be simply described as a crossover with human-like constrained mating to improve exploration ability. Computer simulation on ten benchmark multi-modal functions shows that it performs better than the simple GA (SGA). Compared to a state-of-the-art Rao algorithm on five benchmark functions, it reaches the same performances on the four functions and just loses on one function. The simulation also informs that it has a higher exploration ability to converge at the global optimum on various complex search spaces.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Stress and Deformation of Optimally Shaped Silicon Microneedles for Transdermal Drug Delivery"
        ],
        "penulis":"Zainal Abidin, Hafzaliza Erny;Ooi, Poh Choon;Tiong, Teck Yaw;Marsi, Noraini;Ismardi, Abrar;Mohd Noor, Mimiwaty;Nik Zaini Fathi, Nik Amni Fathi;Abd Aziz, Norazreen;Sahari, Siti Kudnie;Sugandi, Gandi;Yunas, Jumril;Dee, Chang Fu;Yeop Majlis, Burhanuddin;Hamzah, Azrul Azlan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this study, we demonstrated the fabrication of the concave conic shape microneedle with the aid of COMSOL Multiphysics simulation. The stress and buckling of the microneedle structure were simulated by applying various loads ranging from 50 to 800 g perpendiculars to the tip in order to predict the occurrence of microneedles structure deformation. The simulation study indicated that the surface buckling deformation does not occur to the microneedle structure with the increment of the load. The microneedles with dimensions of height and diameter tip ranging from 60 to 100 \u03bcm and 1 to 4 \u03bcm, respectively had been fabricated via an etching process in a mixture of hydrofluoric acid, nitric acid, and acetic acid. Three optimized microneedles but different in the structures were fabricated via the acidic etching process. The reproducibility of 3 different microneedle structures was 15, 20, and 60%, respectively. Stress and buckling analyses of the fabricated microneedles were further carried out on the rat skin. The obtained experimental results show promising applications for the deep dermis, stratum corneum to epidermis layer penetration. \u00a9 2020 American Pharmacists Association\u00ae",
            "SiNView detailsExpand Substance silicon nitride",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this study, we demonstrated the fabrication of the concave conic shape microneedle with the aid of COMSOL Multiphysics simulation. The stress and buckling of the microneedle structure were simulated by applying various loads ranging from 50 to 800 g perpendiculars to the tip in order to predict the occurrence of microneedles structure deformation. The simulation study indicated that the surface buckling deformation does not occur to the microneedle structure with the increment of the load. The microneedles with dimensions of height and diameter tip ranging from 60 to 100 \u03bcm and 1 to 4 \u03bcm, respectively had been fabricated via an etching process in a mixture of hydrofluoric acid, nitric acid, and acetic acid. Three optimized microneedles but different in the structures were fabricated via the acidic etching process. The reproducibility of 3 different microneedle structures was 15, 20, and 60%, respectively. Stress and buckling analyses of the fabricated microneedles were further carried out on the rat skin. The obtained experimental results show promising applications for the deep dermis, stratum corneum to epidermis layer penetration. \u00a9 2020 American Pharmacists Association\u00ae"
        ]
    },
    {
        "judul":[
            "A Qualitative Study of Teenagers Viewpoint in Dealing with Parents\u2019 Divorce in Indonesia"
        ],
        "penulis":"Supratman, Lucy Pujasari;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Divorce in Indonesia has considered to be a stigma. The stigma does not only affect the spouses, but also their kids. This qualitative study explored the viewpoint of Indonesia teenagers in dealing with parents\u2019 divorce. There were 20 teenagers between 18 to 19 years old who were interviewed. The findings shown that they felt self-pity, blaming the parents, and disappointed as the result of their parent\u2019s divorce decision. During the teenager\u2019s acceptance process, their single parent had done the interpersonal communication to explain the reasons for divorce simultaneously. Their interpersonal communication messages about being whole-hearted, accepting God's destiny, respecting the elder and upholding harmonization among family members, helped them to deal with parents\u2019 divorce. \u00a9 2019, \u00a9 2019 Taylor & Francis Group, LLC.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Divorce in Indonesia has considered to be a stigma. The stigma does not only affect the spouses, but also their kids. This qualitative study explored the viewpoint of Indonesia teenagers in dealing with parents\u2019 divorce. There were 20 teenagers between 18 to 19 years old who were interviewed. The findings shown that they felt self-pity, blaming the parents, and disappointed as the result of their parent\u2019s divorce decision. During the teenager\u2019s acceptance process, their single parent had done the interpersonal communication to explain the reasons for divorce simultaneously. Their interpersonal communication messages about being whole-hearted, accepting God's destiny, respecting the elder and upholding harmonization among family members, helped them to deal with parents\u2019 divorce. \u00a9 2019, \u00a9 2019 Taylor & Francis Group, LLC."
        ]
    },
    {
        "judul":[
            "Low Density Parity Check Code (LDPC) for Enhancement of Visible Light Communication (VLC) Performance"
        ],
        "penulis":"Pamukti, Brian;Arifin, Fernaldy;Adriansyah, Nachwan Mufti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Visible Light Communication (VLC) that utilizes free space optics as a transmission channel has a high-speed data communication capability, which uses Light Emitting Diode (LED) as a transmitter. Problems occurred in this wireless communication is the distance. VLC can only reach relatively short distance if compared to Radio Frequency (RF). There are many ways to reach a better distance performance on VLC and one of them is the error correction. In this paper, a comparison between uncoded and Quasi-Cyclic-Low Density Parity Check (QC-LDPC) codes implementation on VLC has been compared and the number of decoding iterations is simulated to reach better performance. The encoding technique of QC-LDPC codes is using the G-Matrix and Bit Flipping algorithm as the decoding. The result shows that distance increases 7% in case of QC-LDPC codes from the uncoded VLC system and 27.5% energy efficiency are increased. The number of decoding iterations also contributes an impact to Bit Error Rate (BER) performance. The simulation results proof that on VLC system using QC-LDPC codes shows better performance compared to the uncoded system.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Visible Light Communication (VLC) that utilizes free space optics as a transmission channel has a high-speed data communication capability, which uses Light Emitting Diode (LED) as a transmitter. Problems occurred in this wireless communication is the distance. VLC can only reach relatively short distance if compared to Radio Frequency (RF). There are many ways to reach a better distance performance on VLC and one of them is the error correction. In this paper, a comparison between uncoded and Quasi-Cyclic-Low Density Parity Check (QC-LDPC) codes implementation on VLC has been compared and the number of decoding iterations is simulated to reach better performance. The encoding technique of QC-LDPC codes is using the G-Matrix and Bit Flipping algorithm as the decoding. The result shows that distance increases 7% in case of QC-LDPC codes from the uncoded VLC system and 27.5% energy efficiency are increased. The number of decoding iterations also contributes an impact to Bit Error Rate (BER) performance. The simulation results proof that on VLC system using QC-LDPC codes shows better performance compared to the uncoded system.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Sentiment analysis of tokopedia application review to service product recommender system using neural collaborative filtering for marketplace in Indonesia"
        ],
        "penulis":"Meifitrah, Restu;Darmawan, Irfan;Nurul Pratiwi, Oktariani;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Tokopedia is one of the leading e-commerce companies in Indonesia and ranks second in the top 10 e-commerce in Indonesia in 2018 based on Statista data. Large companies like Tokopedia need to find out what users think of the products or services offered. User opinions on the Tokopedia application can be seen in the review column on the Google Play Store, but processing a review is not easy. To overcome this we need a sentiment analysis method or technique. Sentiment analysis is performed using the Naive Bayes algorithm. The results of positive sentiments obtained are used as a reference to maintain service quality and the results of negative sentiments can be used as an evaluation material in improving Tokopedia services and applications.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tokopedia is one of the leading e-commerce companies in Indonesia and ranks second in the top 10 e-commerce in Indonesia in 2018 based on Statista data. Large companies like Tokopedia need to find out what users think of the products or services offered. User opinions on the Tokopedia application can be seen in the review column on the Google Play Store, but processing a review is not easy. To overcome this we need a sentiment analysis method or technique. Sentiment analysis is performed using the Naive Bayes algorithm. The results of positive sentiments obtained are used as a reference to maintain service quality and the results of negative sentiments can be used as an evaluation material in improving Tokopedia services and applications.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Personalized E-Learning Content Based on Felder-Silverman Learning Style Model"
        ],
        "penulis":"Sihombing, Jeremiah Hasudungan;Laksitowening, Kusuma Ayu;Darwiyanto, Eko;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A Personalization of E-learning can be done by personalize E-learning features, which are learning content and learning activities provided. In this study, E-learning content personalization was carried out based on the Felder Silverman Learning Style Model (FSLSM). FSLSM is a method of classifying learning styles into 4 dimensions, namely perception, processing, input and understanding. FSLSM classifies learning styles using the Index of Learning Styles (ILS) questionnaire, consisting of 44 questions. In the system that was built, the ILS questionnaire was digitized to map E-learning users, based on their learning style. Afterwards, content personalization algorithms were designed, so users could access content that were suitable to their learning styles while using the system, after that learning content was designed for each dimension of the FSLSM with ADDIE modelling, which was the stage for creating E-learning content. To test the designed algorithm, Delphi method was used, which is a method that collects expert opinion on a problem. For system test, System Usability Scale (SUS) method was used to measure acceptance of user. The results of this research, getting agreement on the accuracy of the design of content personalization algorithms from 3 E-learning experts, the system that was built got SUS 75.33 which was acceptable with grade B, means the system was accepted as a learning tools to help them in learning process based on SUS assessment.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A Personalization of E-learning can be done by personalize E-learning features, which are learning content and learning activities provided. In this study, E-learning content personalization was carried out based on the Felder Silverman Learning Style Model (FSLSM). FSLSM is a method of classifying learning styles into 4 dimensions, namely perception, processing, input and understanding. FSLSM classifies learning styles using the Index of Learning Styles (ILS) questionnaire, consisting of 44 questions. In the system that was built, the ILS questionnaire was digitized to map E-learning users, based on their learning style. Afterwards, content personalization algorithms were designed, so users could access content that were suitable to their learning styles while using the system, after that learning content was designed for each dimension of the FSLSM with ADDIE modelling, which was the stage for creating E-learning content. To test the designed algorithm, Delphi method was used, which is a method that collects expert opinion on a problem. For system test, System Usability Scale (SUS) method was used to measure acceptance of user. The results of this research, getting agreement on the accuracy of the design of content personalization algorithms from 3 E-learning experts, the system that was built got SUS 75.33 which was acceptable with grade B, means the system was accepted as a learning tools to help them in learning process based on SUS assessment.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Blood glucose prediction model for type 1 diabetes based on artificial neural network with time-domain features"
        ],
        "penulis":"Alfian, Ganjar;Syafrudin, Muhammad;Anshari, Muhammad;Benes, Filip;Atmaji, Fransiskus Tatas Dwi;Fahrurrozi, Imam;Hidayatullah, Ahmad Fathan;Rhee, Jongtae;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Predicting future blood glucose (BG) levels for diabetic patients will help them avoid potentially critical health issues. We demonstrate the use of machine learning models to predict future blood glucose levels given a history of blood glucose values as the single input parameter. We propose an Artificial Neural Network (ANN) model with time-domain attributes to predict blood glucose levels 15, 30, 45 and 60 min in the future. Initially, the model's features are selected based on the previous 30 min of BG measurements before a trained model is generated for each patient. These features are combined with time-domain attributes to give additional inputs to the proposed ANN. The prediction model was tested on 12 patients with Type 1 diabetes (T1D) and the results were compared with other data-driven models including the Support Vector Regression (SVR), K-Nearest Neighbor (KNN), C4.5 Decision Tree (DT), Random Forest (RF), Adaptive Boosting (AdaBoost) and eXtreme Gradient Boosting (XGBoost) models. Our results show that the proposed BG prediction model that is based on an ANN outperformed all other models with an average Root Mean Square Error (RMSE) of 2.82, 6.31, 10.65 and 15.33 mg\/dL for Prediction Horizons (PHs) of 15, 30, 45 and 60 min, respectively. Our testing showed that combining time-domain attributes into the input data resulted in enhanced performance of majority of prediction models. The implementation of proposed prediction model allows patients to obtain future blood glucose levels, so that the preventive alerts can be generated before critical hypoglycemic\/ hyperglycemic events occur. \u00a9 2020 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Predicting future blood glucose (BG) levels for diabetic patients will help them avoid potentially critical health issues. We demonstrate the use of machine learning models to predict future blood glucose levels given a history of blood glucose values as the single input parameter. We propose an Artificial Neural Network (ANN) model with time-domain attributes to predict blood glucose levels 15, 30, 45 and 60 min in the future. Initially, the model's features are selected based on the previous 30 min of BG measurements before a trained model is generated for each patient. These features are combined with time-domain attributes to give additional inputs to the proposed ANN. The prediction model was tested on 12 patients with Type 1 diabetes (T1D) and the results were compared with other data-driven models including the Support Vector Regression (SVR), K-Nearest Neighbor (KNN), C4.5 Decision Tree (DT), Random Forest (RF), Adaptive Boosting (AdaBoost) and eXtreme Gradient Boosting (XGBoost) models. Our results show that the proposed BG prediction model that is based on an ANN outperformed all other models with an average Root Mean Square Error (RMSE) of 2.82, 6.31, 10.65 and 15.33 mg\/dL for Prediction Horizons (PHs) of 15, 30, 45 and 60 min, respectively. Our testing showed that combining time-domain attributes into the input data resulted in enhanced performance of majority of prediction models. The implementation of proposed prediction model allows patients to obtain future blood glucose levels, so that the preventive alerts can be generated before critical hypoglycemic\/ hyperglycemic events occur. \u00a9 2020 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences"
        ]
    },
    {
        "judul":[
            "Analyzing TF-IDF and Word Embedding for Implementing Automation in Job Interview Grading"
        ],
        "penulis":"Romadon, Annalisa Wahyu;Lhaksmana, Kemas M;Kurniawan, Isman;Richasdy, Donni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Selecting the best talents from a large number of job applicants is challenging, especially for big companies that usually receive tens of thousands of applicants for every job opening. One of the most costly and time-consuming applicant selection stages is the interview process, since it usually performs face to face meetings and involves third parties to do the interviews and analyze the result. To this end, Human Capital Directorate at Telkom Indonesia adopts AI technology to automate some stages of job applicant selection to reduce manual process and third-party involvement. In this paper, we investigate appropriate feature extraction methods to automate job interview grading for reducing bias and human errors. TFIDF, one of the most popular feature extractions, is compared with word embedding to find the optimal method and parameters in classifying interview verbatims with ANN classifier. Based on the test results, the average accuracy for TFIDF outperforms word embedding by 85.22% against 74.88%, respectively. Therefore, for the case of job interview grading using our dataset, TF-IDF performs better to reduce the number of dimensions.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Selecting the best talents from a large number of job applicants is challenging, especially for big companies that usually receive tens of thousands of applicants for every job opening. One of the most costly and time-consuming applicant selection stages is the interview process, since it usually performs face to face meetings and involves third parties to do the interviews and analyze the result. To this end, Human Capital Directorate at Telkom Indonesia adopts AI technology to automate some stages of job applicant selection to reduce manual process and third-party involvement. In this paper, we investigate appropriate feature extraction methods to automate job interview grading for reducing bias and human errors. TFIDF, one of the most popular feature extractions, is compared with word embedding to find the optimal method and parameters in classifying interview verbatims with ANN classifier. Based on the test results, the average accuracy for TFIDF outperforms word embedding by 85.22% against 74.88%, respectively. Therefore, for the case of job interview grading using our dataset, TF-IDF performs better to reduce the number of dimensions.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Automatic Gate System Based on Water Flow Within the Intake of a Micro-Hydro Power Plant"
        ],
        "penulis":"Pangaribuan P.;Aprillia B.S.;Wibowo A.S.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The micro-hydro power plant is an alternative to provide electricity especially in regions that are far from the PLN network. The micro-hydro power plant uses water flow to generate electricity. The micro-hydro power plant uses a gate that is utilised to distribute water to the turbine. However, the watergate is commonly controlled manually which results in drawbacks such as unfavourable stabilization and the need for direct monitoring that requires lots of constant expense as well as labour. The objective of this research is to make equipment that can work automatically in substituting a labourer's role in opening and closing the watergate according to the required water flow. A water flow sensor is used to measure the water flow, the result of the sensor reading is carried on to microcontroller (set up as Fuzzy Logic Control) and Controler sends the control signal to the actuator (DC motor). The Fuzzy Logic method as the watergate controller is used as the research's prototype system. Based on the data acquired by the research that has been done, the system is oscillated towards the change of the water flow. However, it's capable to approach the set value point. It can be seen from the water flow trial with a set point of 3 L\/min the steady-state response of system undergoes at range of 2,92 L\/min-2,95 L\/min and with a set point of 3,5 L\/min, the steady-state response of system undergoes at range of 3,44 L\/min - 3,47 L\/min. \u00a9 2020 IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The micro-hydro power plant is an alternative to provide electricity especially in regions that are far from the PLN network. The micro-hydro power plant uses water flow to generate electricity. The micro-hydro power plant uses a gate that is utilised to distribute water to the turbine. However, the watergate is commonly controlled manually which results in drawbacks such as unfavourable stabilization and the need for direct monitoring that requires lots of constant expense as well as labour. The objective of this research is to make equipment that can work automatically in substituting a labourer's role in opening and closing the watergate according to the required water flow. A water flow sensor is used to measure the water flow, the result of the sensor reading is carried on to microcontroller (set up as Fuzzy Logic Control) and Controler sends the control signal to the actuator (DC motor). The Fuzzy Logic method as the watergate controller is used as the research's prototype system. Based on the data acquired by the research that has been done, the system is oscillated towards the change of the water flow. However, it's capable to approach the set value point. It can be seen from the water flow trial with a set point of 3 L\/min the steady-state response of system undergoes at range of 2,92 L\/min-2,95 L\/min and with a set point of 3,5 L\/min, the steady-state response of system undergoes at range of 3,44 L\/min - 3,47 L\/min. \u00a9 2020 IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Optical camera communications: Principles, modulations, potential and challenges"
        ],
        "penulis":"Cahyadi, Willy Anugrah;Chung, Yeon Ho;Ghassemlooy, Zabih;Hassan, Navid Bani;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Optical wireless communications (OWC) are emerging as cost-effective and practical solutions to the congested radio frequency-based wireless technologies. As part of OWC, optical camera communications (OCC) have become very attractive, considering recent developments in cameras and the use of fitted cameras in smart devices. OCC together with visible light communications (VLC) is considered within the framework of the IEEE 802.15.7m standardization. OCCs based on both organic and inorganic light sources as well as cameras are being considered for low-rate transmissions and localization in indoor as well as outdoor short-range applications and within the framework of the IEEE 802.15.7m standardization together with VLC. This paper introduces the underlying principles of OCC and gives a comprehensive overview of this emerging technology with recent standardization activities in OCC. It also outlines the key technical issues such as mobility, coverage, interference, performance enhancement, etc. Future research directions and open issues are also presented. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Optical wireless communications (OWC) are emerging as cost-effective and practical solutions to the congested radio frequency-based wireless technologies. As part of OWC, optical camera communications (OCC) have become very attractive, considering recent developments in cameras and the use of fitted cameras in smart devices. OCC together with visible light communications (VLC) is considered within the framework of the IEEE 802.15.7m standardization. OCCs based on both organic and inorganic light sources as well as cameras are being considered for low-rate transmissions and localization in indoor as well as outdoor short-range applications and within the framework of the IEEE 802.15.7m standardization together with VLC. This paper introduces the underlying principles of OCC and gives a comprehensive overview of this emerging technology with recent standardization activities in OCC. It also outlines the key technical issues such as mobility, coverage, interference, performance enhancement, etc. Future research directions and open issues are also presented. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Achromatic Huygens\u2019 Metalenses with Deeply Subwavelength Thickness"
        ],
        "penulis":"Fathnan, Ashif A.;Liu, Mingkai;Powell, David A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Matching magnetic and electric responses has proven key to achieving high-efficiency transmissive Huygens\u2019 metasurfaces. However, the complex frequency dependence of the required magnetic and electric responses is difficult to control, causing inevitable mismatch and undesired narrowband responses. Here, a rigorous design methodology is proposed to obtain a metasurface in which the Huygens\u2019 condition is maintained over a broad bandwidth and range of phase tuning. By utilizing three patterned metallic layers separated by dielectrics, it is shown how the resonant modes with electric and magnetic dipole moments can be controlled almost independently, enabling broadband transparency with controllable dispersion. Representing the resonant elements as series and parallel inductance\u2013capacitance configurations, a convenient implementation of a macro-level design into a realistic geometry is demonstrated. Based on the proposed method, a subwavelength thickness metasurface lens that maintains constant focal length over 11% of fractional bandwidth is designed and characterized. It is also shown that the method can be utilized to achieve specified values of chromatic dispersion of a metasurface lens, enabling various functional devices and applications. \u00a9 2020 Wiley-VCH GmbH",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Matching magnetic and electric responses has proven key to achieving high-efficiency transmissive Huygens\u2019 metasurfaces. However, the complex frequency dependence of the required magnetic and electric responses is difficult to control, causing inevitable mismatch and undesired narrowband responses. Here, a rigorous design methodology is proposed to obtain a metasurface in which the Huygens\u2019 condition is maintained over a broad bandwidth and range of phase tuning. By utilizing three patterned metallic layers separated by dielectrics, it is shown how the resonant modes with electric and magnetic dipole moments can be controlled almost independently, enabling broadband transparency with controllable dispersion. Representing the resonant elements as series and parallel inductance\u2013capacitance configurations, a convenient implementation of a macro-level design into a realistic geometry is demonstrated. Based on the proposed method, a subwavelength thickness metasurface lens that maintains constant focal length over 11% of fractional bandwidth is designed and characterized. It is also shown that the method can be utilized to achieve specified values of chromatic dispersion of a metasurface lens, enabling various functional devices and applications. \u00a9 2020 Wiley-VCH GmbH"
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Towards a comprehensive exploration and mapping of maturity models in digital business: A systematic literature review"
        ],
        "penulis":"Gandhi, Arfive;Sucahyo, Yudho Giri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Many Maturity Models (MM) in digital business were difficult to be implemented and adopted in real world due to lack of validation. In order to solve the theoretical gap, this study conducted Systematic Literature Review (SLR) to generate comprehensive exploration and mapping of MM. Out of 179 articles captured using Scopus, 28 articles were eligible. Using Kitchenham et.al\u2019s SLR phases, this study classified type, schemes, and technique on MM creation. Nine research method attributes were employed: referred methodologies, hierarchical type, maturity status, cascading scheme, leveling, criteria sources, classification scheme, implementation technique, and evaluation\/ verification\/validation technique. Moreover, this study provided rationalisation on each alternative so that acceptance of MM can be increased. \u00a9 2020, DESIDOC.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Many Maturity Models (MM) in digital business were difficult to be implemented and adopted in real world due to lack of validation. In order to solve the theoretical gap, this study conducted Systematic Literature Review (SLR) to generate comprehensive exploration and mapping of MM. Out of 179 articles captured using Scopus, 28 articles were eligible. Using Kitchenham et.al\u2019s SLR phases, this study classified type, schemes, and technique on MM creation. Nine research method attributes were employed: referred methodologies, hierarchical type, maturity status, cascading scheme, leveling, criteria sources, classification scheme, implementation technique, and evaluation\/ verification\/validation technique. Moreover, this study provided rationalisation on each alternative so that acceptance of MM can be increased. \u00a9 2020, DESIDOC."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Optimizing Data Storage in Handling Dynamic Input Fields with JSON String Compression"
        ],
        "penulis":"Darmawan, Irfan;Rahmatulloh, Alam;Nuralam, Iqbal Muhammad Fajar;Rianto;Gunawan, Rohmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Dynamic input fields are a solution for managing multiple input values in a web-based application form. Dynamic multiple image upload is an implementation of the dynamic input field. Handling dynamic upload of multiple images by storing the image path will cause the existence of similar string data in one field in the table stored in the database. Creating a unique table in a database to store dynamic data is a workable solution. However, it is potentially a waste of tables and records, so that the database file size becomes larger and data access speeds are longer. To overcome this problem in this study, string data obtained from the dynamic input field are converted into JSON format and compressed with Zlib, before being saved into the database. The experimental results in this study indicate that the integration of JSON and Zlib can be applied to the handling of dynamic input field forms. The average speed of the data storage process by applying this technique is 50.36% faster than the conventional method. In comparison, the database file size decreased by about 37.58% smaller than using conventional techniques.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Dynamic input fields are a solution for managing multiple input values in a web-based application form. Dynamic multiple image upload is an implementation of the dynamic input field. Handling dynamic upload of multiple images by storing the image path will cause the existence of similar string data in one field in the table stored in the database. Creating a unique table in a database to store dynamic data is a workable solution. However, it is potentially a waste of tables and records, so that the database file size becomes larger and data access speeds are longer. To overcome this problem in this study, string data obtained from the dynamic input field are converted into JSON format and compressed with Zlib, before being saved into the database. The experimental results in this study indicate that the integration of JSON and Zlib can be applied to the handling of dynamic input field forms. The average speed of the data storage process by applying this technique is 50.36% faster than the conventional method. In comparison, the database file size decreased by about 37.58% smaller than using conventional techniques.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Scabies Classification in Animal Using Uniform Local Binary Patterns"
        ],
        "penulis":"Salsabila, Annisa Suciati;Sthevanie, Febryanti;Ramadhani, Kurniawan Nur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Scabies is a disease caused by the Sarcoptes Scabiei mite and can affect humans and animals. In animals, this disease is recognized by crusted skin on the ears, nose, and feet, but if the disease is not treated immediately, the mites will spread throughout the animal's body and can even cause death.Image processing has been done a lot to classify diseases in humans and plants, but there are still a few that involve scabies in animals, so in this research the authors build a system that can classify animal skin images into two classes, namely animals with scabies disease, and animals with other skin diseases.The Uniform Local Binary Pattern feature extraction method has been proven to optimize the feature extraction results and minimize the processing time for the feature extraction process, so the system is built by processing the dataset using the Uniform Local Binary Pattern method and the Random Forest classification method so that the system performance reaches 52% \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Scabies is a disease caused by the Sarcoptes Scabiei mite and can affect humans and animals. In animals, this disease is recognized by crusted skin on the ears, nose, and feet, but if the disease is not treated immediately, the mites will spread throughout the animal's body and can even cause death.Image processing has been done a lot to classify diseases in humans and plants, but there are still a few that involve scabies in animals, so in this research the authors build a system that can classify animal skin images into two classes, namely animals with scabies disease, and animals with other skin diseases.The Uniform Local Binary Pattern feature extraction method has been proven to optimize the feature extraction results and minimize the processing time for the feature extraction process, so the system is built by processing the dataset using the Uniform Local Binary Pattern method and the Random Forest classification method so that the system performance reaches 52% \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Topic-Based Tweet Clustering for Public Figures Using Ant Clustering"
        ],
        "penulis":"Firdaus, Diaz Harizky;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The aspects of life on a public figure, discussed by the community, are often exploited by the news media as topic information to create an article that can attract the attention of the reader. Efficiently, the media only needs to pay attention to social media to get some of the information. The more information needed leads to a vast amount of data involved, so the process becomes hard. In this paper, a tweet clustering system to determine topics from many documents in the form of text through text mining method using an ant clustering (AC) technique. AC is one of swarm intelligence algorithms inspired by the behavior of the ant colony in sorting corpses. Evaluation of a small dataset of text documents shows that four topics are successfully concluded: economy, social, politics, and government. The developed AC-based tweet clustering system produces an average cluster quality of the Dunn Index up to 0,3455.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aspects of life on a public figure, discussed by the community, are often exploited by the news media as topic information to create an article that can attract the attention of the reader. Efficiently, the media only needs to pay attention to social media to get some of the information. The more information needed leads to a vast amount of data involved, so the process becomes hard. In this paper, a tweet clustering system to determine topics from many documents in the form of text through text mining method using an ant clustering (AC) technique. AC is one of swarm intelligence algorithms inspired by the behavior of the ant colony in sorting corpses. Evaluation of a small dataset of text documents shows that four topics are successfully concluded: economy, social, politics, and government. The developed AC-based tweet clustering system produces an average cluster quality of the Dunn Index up to 0,3455.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Indonesian Ethnicity Recognition Based on Face Image Using Uniform Local Binary Pattern (ULBP) and Color Histogram"
        ],
        "penulis":"Putri, Tiani Tiara;Rachmawati, Ema;Sthevanie, Febryanti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Ethnicity is one of identity every human has and can be used to categorize individuals in populations or large groups. We presented an Indonesian ethnicity recognition based on facial images using Uniform Local Binary Pattern (ULBP) and Color Histogram as a feature extraction method. We used the five largest ethnic groups in Indonesia, namely Sundanese, Javanese, Banjar, Buginese, and Malay. In the experiment, we used Random Forest as a classification method. The research obtained a performance accuracy of 98.25% using 2290 facial images. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ethnicity is one of identity every human has and can be used to categorize individuals in populations or large groups. We presented an Indonesian ethnicity recognition based on facial images using Uniform Local Binary Pattern (ULBP) and Color Histogram as a feature extraction method. We used the five largest ethnic groups in Indonesia, namely Sundanese, Javanese, Banjar, Buginese, and Malay. In the experiment, we used Random Forest as a classification method. The research obtained a performance accuracy of 98.25% using 2290 facial images. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Automation Financial Processing in Account Receivable for Integrated Hospital System using ERP and Quickstart Approach"
        ],
        "penulis":"Nasution, Febriansyah;Puspitasari, Warih;Saputra, Muhardi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Health is one of the most important aspects of human life. Hospital support in health maintenance in several areas. There is a public and private hospital in Indonesia to fulfill the health services for society. XYZ hospital is one of the government hospitals that operated in Bandung District. Currently, XYZ hospital still has no good information systems in performing hospital business processes. There is no integrated system that supports the hospital in data exchange within another business function. In caused by a lack of information systems, XYZ hospitals not effective enough in monitoring hospital daily activity and manage the hospital activity. This research focused on designing ERP systems in XYZ hospital financial management using Odoo software with a financial accounting module and used the Quickstart method. The result of this research is the model design of ERP systems regarding financial management that integrated with another module. The systems can support the financial department to manage financial activity automatically and integrated with another module to pursuing XYZ hospital as a smart hospital. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Health is one of the most important aspects of human life. Hospital support in health maintenance in several areas. There is a public and private hospital in Indonesia to fulfill the health services for society. XYZ hospital is one of the government hospitals that operated in Bandung District. Currently, XYZ hospital still has no good information systems in performing hospital business processes. There is no integrated system that supports the hospital in data exchange within another business function. In caused by a lack of information systems, XYZ hospitals not effective enough in monitoring hospital daily activity and manage the hospital activity. This research focused on designing ERP systems in XYZ hospital financial management using Odoo software with a financial accounting module and used the Quickstart method. The result of this research is the model design of ERP systems regarding financial management that integrated with another module. The systems can support the financial department to manage financial activity automatically and integrated with another module to pursuing XYZ hospital as a smart hospital. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Study on error correction capability of simple concatenated polar codes"
        ],
        "penulis":"Sinurat, Robin;Maulana, Muhamad Rizki;Anwar, Khoirul;Ismail, Nanang;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Polar codes are mathematically proven to achieve the Shannon limit, where the error probability is reduced with the help of frozen bits. Since the frozen bits are detrimental in terms of transmission efficiency, this paper investigates the importance of the frozen bits and the possibility of being replaced by other protected bits via a concatenation with other outer channel coding schemes. We evaluate the impact of frozen bits to the capability of error correction of original Polar codes (OPC) and the concatenated Polar codes (CPC) in short block-length in terms of bit-error-rate (BER) performances. Repetition codes are used as outer channel encoder prior to the Polar codes and are divided into two schemes, i.e., (i) irregular repetition-CPC (IR-CPC) codes and (ii) regular repetition-CPC (RR-CPC) codes. We evaluate BER performances using computer simulations based on Log-Likelihood Ratio (LLR) with the modulation of Binary Phase Shift Keying (BPSK) under Additive White Gaussian Noise (AWGN) and frequency-flat Rayleigh Fading channels. We found that the OPC is better than the IR-CPC codes or RR-CPC codes for the same channel coding rate and block-length. This finding indicates that the frozen bits in OPC has strong contribution to the error correction capability of the Polar codes and may not be replaced by other bits even though the bits are protected by other channel coding schemes. \u00a9 2020, Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Polar codes are mathematically proven to achieve the Shannon limit, where the error probability is reduced with the help of frozen bits. Since the frozen bits are detrimental in terms of transmission efficiency, this paper investigates the importance of the frozen bits and the possibility of being replaced by other protected bits via a concatenation with other outer channel coding schemes. We evaluate the impact of frozen bits to the capability of error correction of original Polar codes (OPC) and the concatenated Polar codes (CPC) in short block-length in terms of bit-error-rate (BER) performances. Repetition codes are used as outer channel encoder prior to the Polar codes and are divided into two schemes, i.e., (i) irregular repetition-CPC (IR-CPC) codes and (ii) regular repetition-CPC (RR-CPC) codes. We evaluate BER performances using computer simulations based on Log-Likelihood Ratio (LLR) with the modulation of Binary Phase Shift Keying (BPSK) under Additive White Gaussian Noise (AWGN) and frequency-flat Rayleigh Fading channels. We found that the OPC is better than the IR-CPC codes or RR-CPC codes for the same channel coding rate and block-length. This finding indicates that the frozen bits in OPC has strong contribution to the error correction capability of the Polar codes and may not be replaced by other bits even though the bits are protected by other channel coding schemes. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[
            "Recommendations for Improving Data Management Process in Government of Bandung Regency using COBIT 4.1 Framework"
        ],
        "penulis":"Nugroho, Heru;Gumilang, Soni Fajar Surya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Data is an valuable asset that potentially provides substantial benefits for the government and society. To make the performance of local government apparatus runs optimally and the public gets the best service, the government of Bandung Regency strives to improve data management. The initial stage of optimizing data management is the assessment of the maturity level in managing data (DS-11) using COBIT 4.1. Base on the assessment maturity level for DS-11, the government of Bandung Regency needs to raise the level from 2.46 (Repeatable but Intuitive) to 3.0 (Defined). Recommendations given to improve data management in Government with focuses on maintaining the completeness, accuracy, availability, and protection of data. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data is an valuable asset that potentially provides substantial benefits for the government and society. To make the performance of local government apparatus runs optimally and the public gets the best service, the government of Bandung Regency strives to improve data management. The initial stage of optimizing data management is the assessment of the maturity level in managing data (DS-11) using COBIT 4.1. Base on the assessment maturity level for DS-11, the government of Bandung Regency needs to raise the level from 2.46 (Repeatable but Intuitive) to 3.0 (Defined). Recommendations given to improve data management in Government with focuses on maintaining the completeness, accuracy, availability, and protection of data. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Classification of premature ventricular contraction (Pvc) based on ecg signal using convolutional neural network (cnn)"
        ],
        "penulis":"Jondri;Rizal, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study observes one of the ECG signal abnormalities, which is the Premature Ventricular Contraction (PVC). Many studies applied a machine learning technique to develop a computer-aided diagnosis to classify normal and PVC conditions of ECG signals. The common process to obtain information from the ECG signal is by performing a feature extraction process. Since the ECG signal is a complex signal, there is a need to reduce the signal dimension to produce an optimal feature set. However, these processes can remove the information contained in the signal. Therefore, this study process the original ECG signal using a Convolutional Neural Network to avoid losing information. The input data were in the form of both one beat of normal ECG signal or PVC with size 1x200. The classification used four layers of convolutional neural network (CNN). There were eight 1x1 filters used in the input. Simultaneously, 16 and 32 of 1x1 filters were used in the second and the fourth convolutional layers, respectively. Thus the system produced a fully connected layer consisted of 512 neurons, while the output layer consisted of 2 neurons. The system is tested using 11361 beats of ECG data and achieved the highest accuracy of 99.59%, with the 10-fold cross-validation. This study emphasizes an opportunity to develop a wearable device to detect PVC since CNN can be implemented into an embedded system or an IoT based system. \u00a9 2020 Institute of Advanced Engineering and Science.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study observes one of the ECG signal abnormalities, which is the Premature Ventricular Contraction (PVC). Many studies applied a machine learning technique to develop a computer-aided diagnosis to classify normal and PVC conditions of ECG signals. The common process to obtain information from the ECG signal is by performing a feature extraction process. Since the ECG signal is a complex signal, there is a need to reduce the signal dimension to produce an optimal feature set. However, these processes can remove the information contained in the signal. Therefore, this study process the original ECG signal using a Convolutional Neural Network to avoid losing information. The input data were in the form of both one beat of normal ECG signal or PVC with size 1x200. The classification used four layers of convolutional neural network (CNN). There were eight 1x1 filters used in the input. Simultaneously, 16 and 32 of 1x1 filters were used in the second and the fourth convolutional layers, respectively. Thus the system produced a fully connected layer consisted of 512 neurons, while the output layer consisted of 2 neurons. The system is tested using 11361 beats of ECG data and achieved the highest accuracy of 99.59%, with the 10-fold cross-validation. This study emphasizes an opportunity to develop a wearable device to detect PVC since CNN can be implemented into an embedded system or an IoT based system. \u00a9 2020 Institute of Advanced Engineering and Science."
        ]
    },
    {
        "judul":[
            "Reduction of number of empty-truck trips in inter-terminal transportation using multi-agent Q-learning"
        ],
        "penulis":"Adi, Taufik Nur;Iskandar, Yelita Anggiane;Bae, Hyerim;Choi, Yulim;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In a port consisting of multiple container terminals, the demand for transportation of containers and cargo among port facilities is high. Almost all transshipment containers bound for a vessel generally are transported from one terminal to another within a short period, which process is known as inter-terminal transportation (ITT). Adequate ITT planning is required in order to reduce ITT-related costs. Minimization of the number of Empty-Truck trips has gained attention, as the ITT problem incurs ITT-related costs. A single Q-Learning-based technique developed in a previous study for minimization of the number of empty-truck trips required high computational time while learning from a considerable amount of orders data. This paper proposes multi-agent Q-Learning to improve the performance offered by the previous single-agent-based model. Our results show that multi-agent Q-Learning performs better than the single-agent alternative in terms of computation time and, therefore too, the quality of its results. \u00a9 Interconnected Supply Chains in an Era of Innovation - Proceedings of the 8th International Conference on Information Systems, Logistics and Supply Chain, ILS 2020. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a port consisting of multiple container terminals, the demand for transportation of containers and cargo among port facilities is high. Almost all transshipment containers bound for a vessel generally are transported from one terminal to another within a short period, which process is known as inter-terminal transportation (ITT). Adequate ITT planning is required in order to reduce ITT-related costs. Minimization of the number of Empty-Truck trips has gained attention, as the ITT problem incurs ITT-related costs. A single Q-Learning-based technique developed in a previous study for minimization of the number of empty-truck trips required high computational time while learning from a considerable amount of orders data. This paper proposes multi-agent Q-Learning to improve the performance offered by the previous single-agent-based model. Our results show that multi-agent Q-Learning performs better than the single-agent alternative in terms of computation time and, therefore too, the quality of its results. \u00a9 Interconnected Supply Chains in an Era of Innovation - Proceedings of the 8th International Conference on Information Systems, Logistics and Supply Chain, ILS 2020. All rights reserved."
        ]
    },
    {
        "judul":[
            "Accuracy improvement in through the wall radar based on deconvolution and delay estimation"
        ],
        "penulis":"Purwandani, Agita;Pramudita, A. A;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Through the Wall Radar (TWR) which works at Ultra Wideband (UWB) frequencies us to detect objects behind a wall. This radar can be used to search or evacuate victims of natural disasters buried behind a wall and to speed up the evacuation process. Wall as Obstacles become the main problems that need to be overcome in applying the TWR for a certain purposed. The wall effect can reduce the accuracy of the detection results. The wall causes masking effect on target reflection signal and give a difficulty in detecting the target. The delay propagation that contributes by the wall reduces the accuracy in detecting the location. The characteristics of the wall are needed to achieve for improving the accuracy, therefore the objects can be detected precisely. The method that proposed composes of two subsystems. The first subsystem is the extraction of antenna and wall effects that performed by deconvolution. The second part is delay estimation method. In this study, laboratory experiments were carried out study the performance of the proposed method. The TWR was modeled using a vector network analyzer (VNA). The results obtained by using the deconvolution method and reducing object delay can be detected according to the target with a 2 cm error margin. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Through the Wall Radar (TWR) which works at Ultra Wideband (UWB) frequencies us to detect objects behind a wall. This radar can be used to search or evacuate victims of natural disasters buried behind a wall and to speed up the evacuation process. Wall as Obstacles become the main problems that need to be overcome in applying the TWR for a certain purposed. The wall effect can reduce the accuracy of the detection results. The wall causes masking effect on target reflection signal and give a difficulty in detecting the target. The delay propagation that contributes by the wall reduces the accuracy in detecting the location. The characteristics of the wall are needed to achieve for improving the accuracy, therefore the objects can be detected precisely. The method that proposed composes of two subsystems. The first subsystem is the extraction of antenna and wall effects that performed by deconvolution. The second part is delay estimation method. In this study, laboratory experiments were carried out study the performance of the proposed method. The TWR was modeled using a vector network analyzer (VNA). The results obtained by using the deconvolution method and reducing object delay can be detected according to the target with a 2 cm error margin. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Determination of the radiological risk from the natural radioactivity in irrigation at selected areas of peninsular malaysia"
        ],
        "penulis":"Abdul Rahim, Khoirul Solehah;Zainuddin, Zalita;Idris, Mohd Idzat;Priharti, Wahmisari;Aswood, Murtadha S.H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study involves a comprehensive analysis of226Ra,232Th, and40K concentration from irrigation water samples. Water samples were obtained, and the physical parameters were examined. Subsequently, the corresponding radiological risks to human health were estimated. The concentration levels of226Ra,232Th, and40K in water samples amounted to 1.51 \u00b1 0.30, 0.17 \u00b1 0.09, and 7.67 \u00b1 3.07 Bq L-1, respectively, which were within the concentration levels reported in the literature from Malaysia and other countries worldwide. Based on the food intake rate by MoH and UNSCEAR, the annual ingestion effective dose (ID) and the cancer risks corresponding to radionuclide intake in irrigation were below the recommended maximum values. Meanwhile, the average hazard indices and annual outdoor effective dose (ED) amounted to 0.01 and 1.39 mSv year-1, respectively. It was inferred from the findings of this study that the water used as the sample does not have any significant radiological impacts to human body and is safe to be used as irrigation in the related area. \u00a9 2020 Penerbit Universiti Kebangsaan Malaysia. All rights reserved.",
            "H2RaView detailsExpand Substance radium on hydroxyapatiteThView detailsExpand Substance thorium",
            "Powered by",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study involves a comprehensive analysis of226Ra,232Th, and40K concentration from irrigation water samples. Water samples were obtained, and the physical parameters were examined. Subsequently, the corresponding radiological risks to human health were estimated. The concentration levels of226Ra,232Th, and40K in water samples amounted to 1.51 \u00b1 0.30, 0.17 \u00b1 0.09, and 7.67 \u00b1 3.07 Bq L-1, respectively, which were within the concentration levels reported in the literature from Malaysia and other countries worldwide. Based on the food intake rate by MoH and UNSCEAR, the annual ingestion effective dose (ID) and the cancer risks corresponding to radionuclide intake in irrigation were below the recommended maximum values. Meanwhile, the average hazard indices and annual outdoor effective dose (ED) amounted to 0.01 and 1.39 mSv year-1, respectively. It was inferred from the findings of this study that the water used as the sample does not have any significant radiological impacts to human body and is safe to be used as irrigation in the related area. \u00a9 2020 Penerbit Universiti Kebangsaan Malaysia. All rights reserved."
        ]
    },
    {
        "judul":[
            "Simultaneous Wireless Information and Power Transfer (SWIPT) for Internet of Things: Novel Receiver Design and Experimental Validation"
        ],
        "penulis":"Choi, Kae Won;Hwang, Sa Il;Aziz, Arif Abdul;Jang, Hyeon Ho;Kim, Ji Su;Kang, Dong Soo;Kim, Dong In;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this article, we propose a novel simultaneous wireless information and power transfer (SWIPT) scheme for the Internet of Things (IoT). Different from the conventional power splitting (PS) and time switching (TS) schemes, the proposed scheme sends the wireless power via the unmodulated high-power continuous wave (CW) and transmits information by using a small modulated signal in order to reduce the interference and to enhance the power amplifier efficiency. We design a receiver circuit for processing such SWIPT signals, which is designed with the aim of minimizing the circuit complexity and power consumption for information decoding. This goal is achieved by first rectifying the received signal and then splitting the power and information signals. We analyze the proposed receiver circuit and derive the closed-form expression for the energy harvesting efficiency and the frequency response of the communication signal. We have implemented the proposed receiver circuit and built the real-time testbed for experimenting with simultaneous transmission of information and power. By experiments, we have verified the correctness of the receiver circuit analysis and shown the validity of the proposed SWIPT scheme. \u00a9 2014 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this article, we propose a novel simultaneous wireless information and power transfer (SWIPT) scheme for the Internet of Things (IoT). Different from the conventional power splitting (PS) and time switching (TS) schemes, the proposed scheme sends the wireless power via the unmodulated high-power continuous wave (CW) and transmits information by using a small modulated signal in order to reduce the interference and to enhance the power amplifier efficiency. We design a receiver circuit for processing such SWIPT signals, which is designed with the aim of minimizing the circuit complexity and power consumption for information decoding. This goal is achieved by first rectifying the received signal and then splitting the power and information signals. We analyze the proposed receiver circuit and derive the closed-form expression for the energy harvesting efficiency and the frequency response of the communication signal. We have implemented the proposed receiver circuit and built the real-time testbed for experimenting with simultaneous transmission of information and power. By experiments, we have verified the correctness of the receiver circuit analysis and shown the validity of the proposed SWIPT scheme. \u00a9 2014 IEEE."
        ]
    },
    {
        "judul":[
            "Vertical Axis Wind Turbine Improvement using DC-DC Boost Converter"
        ],
        "penulis":"Khairunnisa, Khairunnisa;Rachman, Syaiful;Yohanes, Edi;Uji Krismanto, Awan;Fadil, Jazuli;Soedibyo, Soedibyo;Ashari, Mochamad;Abuzalata, Mahmoud;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Vertical axis wind turbine (VAWT) can be operated in any direction of wind speed, but it has low rotation. To improve the performance of VAWT in which low rotation, this paper presents a simple control strategy of VAWT using a DC-DC boost converter to tap constant voltage in a standalone application. The main objective of this research is to maintain a constant output voltage of converter despite variation input voltage affected by variable wind speed. A simple proportional-integral (PI) controller has been used for a DC-DC boost converter and tested in MATLAB-Simulink environment, with the closed-loop system of the converter maintain constant output voltage although the wind speed is kept changing. The PI controller obtains the feedback from the output voltage of the boost converter to produce the correct pulse width modulation (PWM) duty cycle and trigger the metal oxide semiconductor field effect transistor (MOSFET) following the reference voltage of the turbine. This system has suppressed the value of overshoot and increased the efficiency of wind turbines as 34 %.  \u00a9 The Authors, published by EDP Sciences, 2020.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Vertical axis wind turbine (VAWT) can be operated in any direction of wind speed, but it has low rotation. To improve the performance of VAWT in which low rotation, this paper presents a simple control strategy of VAWT using a DC-DC boost converter to tap constant voltage in a standalone application. The main objective of this research is to maintain a constant output voltage of converter despite variation input voltage affected by variable wind speed. A simple proportional-integral (PI) controller has been used for a DC-DC boost converter and tested in MATLAB-Simulink environment, with the closed-loop system of the converter maintain constant output voltage although the wind speed is kept changing. The PI controller obtains the feedback from the output voltage of the boost converter to produce the correct pulse width modulation (PWM) duty cycle and trigger the metal oxide semiconductor field effect transistor (MOSFET) following the reference voltage of the turbine. This system has suppressed the value of overshoot and increased the efficiency of wind turbines as 34 %.  \u00a9 The Authors, published by EDP Sciences, 2020."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Implementation and Analysis of Keyboard Injection Attack using USB Devices in Windows Operating System"
        ],
        "penulis":"Ramadhanty, Annisa Dwiayu;Budiono, Avon;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Windows is one of the popular operating systems in use today, while Universal Serial Bus (USB) is one of the mechanisms used by many people with practical plug and play functions. USB has long been used as a vector of attacks on computers. One method of attack is Keylogger. The Keylogger can take advantage of existing vulnerabilities in the Windows 10 operating system attacks carried out in the form of recording computer keystroke activity without the victim knowing. In this research, an attack will be carried out by running a Powershell Script using BadUSB to be able to activate the Keylogger program. The script is embedded in the Arduino Pro Micro device. The results obtained in the Keyboard Injection Attack research using Arduino Pro Micro were successfully carried out with an average time needed to run the keylogger is 7.474 seconds with a computer connected to the internet. The results of the keylogger will be sent to the attacker via email.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Windows is one of the popular operating systems in use today, while Universal Serial Bus (USB) is one of the mechanisms used by many people with practical plug and play functions. USB has long been used as a vector of attacks on computers. One method of attack is Keylogger. The Keylogger can take advantage of existing vulnerabilities in the Windows 10 operating system attacks carried out in the form of recording computer keystroke activity without the victim knowing. In this research, an attack will be carried out by running a Powershell Script using BadUSB to be able to activate the Keylogger program. The script is embedded in the Arduino Pro Micro device. The results obtained in the Keyboard Injection Attack research using Arduino Pro Micro were successfully carried out with an average time needed to run the keylogger is 7.474 seconds with a computer connected to the internet. The results of the keylogger will be sent to the attacker via email.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Marketing of identity politics in digital world (netnography study on indonesian presidential election 2019)"
        ],
        "penulis":"Mahestu, Gayes;Sumbogo, Tri Adi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia held the General Election of the President and Vice-President in April 2019 with two candidates. This national political succession became a magnet for all Indonesian people to discuss it in daily conversation. Interaction between candidates supporters held in the digital world too. This phenomenon leads to the interaction and conversation of online forums such as political forums in social media. This forum is one of form computer-mediated communication that facilitated interaction between the internal public in the political marketing context. The problem arise when these forums were created to discredit and distribute fake news and hate speech about their political opponents. This study aims to investigate the form of interaction and conversation that contained Ethnic, Religion, Race, and Intergroup issues, then identity politics in Facebook online forums during the 2019 Presidential Election. The research method used the virtual ethnography method by analyzing the Facebook Forums that supporting each candidate. The results show that distribution content on each Facebook Forum strengthening the value of politics identity through news link\/photo with narration, meme, narration, videos, and advertisement. This type of Facebook posting consists of satire, hoax, contention, opinion, campaign, and clarification. The research also find that technological progress and digital literacy are imbalance, so people easily consume, reproduce, and distribute fake news. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia held the General Election of the President and Vice-President in April 2019 with two candidates. This national political succession became a magnet for all Indonesian people to discuss it in daily conversation. Interaction between candidates supporters held in the digital world too. This phenomenon leads to the interaction and conversation of online forums such as political forums in social media. This forum is one of form computer-mediated communication that facilitated interaction between the internal public in the political marketing context. The problem arise when these forums were created to discredit and distribute fake news and hate speech about their political opponents. This study aims to investigate the form of interaction and conversation that contained Ethnic, Religion, Race, and Intergroup issues, then identity politics in Facebook online forums during the 2019 Presidential Election. The research method used the virtual ethnography method by analyzing the Facebook Forums that supporting each candidate. The results show that distribution content on each Facebook Forum strengthening the value of politics identity through news link\/photo with narration, meme, narration, videos, and advertisement. This type of Facebook posting consists of satire, hoax, contention, opinion, campaign, and clarification. The research also find that technological progress and digital literacy are imbalance, so people easily consume, reproduce, and distribute fake news. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Lip Motion Recognition for Indonesian Vowel Phonemes Using 3D Convolutional Neural Networks"
        ],
        "penulis":"Maxalmina;Kahfi, Satria;Ramadhani, Kurniawan Nur;Arifianto, Anditya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Lip motion recognition is a technique for interpreting visual data that focuses on the mouth area and aims to recognize lip movement. The development of lip motion recognition is expected to be used to develop communication tools with deaf people and to automate the speech-to-text process visually. In the Indonesian language, the existence of vowel phonemes is needed to produce sounds so that words and sentences in the Indonesian language can be formed. This paper proposes a model that can recognize Indonesian vowel phonemes (\/a\/,\/i\/,\/u\/,\/e\/, and\/o\/) in lip movements. We proposed a model that uses 3D Convolutional Neural Networks. The data in this paper were processed by resizing into 112x56 pixel resolution then, proceed to the data augmentation by reversing the data horizontally and add blur to the data. The results of the testing of the vowel phoneme recognition model on lip motion show the highest accuracy rate of 84%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Lip motion recognition is a technique for interpreting visual data that focuses on the mouth area and aims to recognize lip movement. The development of lip motion recognition is expected to be used to develop communication tools with deaf people and to automate the speech-to-text process visually. In the Indonesian language, the existence of vowel phonemes is needed to produce sounds so that words and sentences in the Indonesian language can be formed. This paper proposes a model that can recognize Indonesian vowel phonemes (\/a\/,\/i\/,\/u\/,\/e\/, and\/o\/) in lip movements. We proposed a model that uses 3D Convolutional Neural Networks. The data in this paper were processed by resizing into 112x56 pixel resolution then, proceed to the data augmentation by reversing the data horizontally and add blur to the data. The results of the testing of the vowel phoneme recognition model on lip motion show the highest accuracy rate of 84%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Designing IT Service Management at Indonesia Internet Domain Names Registry Association's Helpdesk Function"
        ],
        "penulis":"Hermita, Evelyn Sevina;Sucahyo, Yudho Giri;Gandhi, Arfive;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia Internet Domain Names Registry Association (PANDI) hosts helpdesk function as a part of .id domain management. It is a one-stop facility for all registrants and the public to submit questions and complaints regarding .id domain names. Previously, helpdesk function had poor performance since its business processes were manual and slow. This research aimed to design Information Technology Service Management (ITSM) implementation as guidelines for PANDI helpdesk. It demonstrated case study research using qualitative approach by involving helpdesk officers, and c-level in depth interview. This research relied on ITIL V3 2011 framework to generate ITSM design: service catalog, Service Level Agreement, and Standard Operating Procedures. It resulted in tracking status, priority label, reporting feature, and service categories can be added on the application side. Those artifacts guided helpdesk to improve the quality of services provided by PANDI. They consisted of a service catalog that includes 11 Customer Facing Service (CFS) and Resource Facing Service (RFS), five SLAs for helpdesk business process services, and three SOPs for account changes request service.  \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia Internet Domain Names Registry Association (PANDI) hosts helpdesk function as a part of .id domain management. It is a one-stop facility for all registrants and the public to submit questions and complaints regarding .id domain names. Previously, helpdesk function had poor performance since its business processes were manual and slow. This research aimed to design Information Technology Service Management (ITSM) implementation as guidelines for PANDI helpdesk. It demonstrated case study research using qualitative approach by involving helpdesk officers, and c-level in depth interview. This research relied on ITIL V3 2011 framework to generate ITSM design: service catalog, Service Level Agreement, and Standard Operating Procedures. It resulted in tracking status, priority label, reporting feature, and service categories can be added on the application side. Those artifacts guided helpdesk to improve the quality of services provided by PANDI. They consisted of a service catalog that includes 11 Customer Facing Service (CFS) and Resource Facing Service (RFS), five SLAs for helpdesk business process services, and three SOPs for account changes request service.  \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Innovation as the key to gain performance from absorptive capacity and human capital"
        ],
        "penulis":"Pradana, Mahir;P\u00e9rez-Lu\u00f1o, Ana;Fuentes-Blasco, Maria;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study aims to investigate how firms can achieve high levels of organisational performance through innovation, absorptive capacity (ACAP) and human capital (HC). Using a sample of 138 Spanish companies from the wine industry, our findings show that ACAP and HC allow businesses to fully capture the benefits of innovation. These results contribute to the literature of ACAP, human resources management (HRM) innovation and resource-based view (RBV) of the firm by showing that a number of resources and capabilities (ACAP, HC, and innovation) can be seen as good drivers of performance and, by extension, of competitive advantage. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to investigate how firms can achieve high levels of organisational performance through innovation, absorptive capacity (ACAP) and human capital (HC). Using a sample of 138 Spanish companies from the wine industry, our findings show that ACAP and HC allow businesses to fully capture the benefits of innovation. These results contribute to the literature of ACAP, human resources management (HRM) innovation and resource-based view (RBV) of the firm by showing that a number of resources and capabilities (ACAP, HC, and innovation) can be seen as good drivers of performance and, by extension, of competitive advantage. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group."
        ]
    },
    {
        "judul":[
            "Towards a collaborative framework for the large-scale social collaboration: A case of Jakarta's response to the Covid-19 pandemic"
        ],
        "penulis":"Anandhika, Muhammad Rizqy;Hassan, Fazlur Rahman;Nugraha, Yudhistira;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Covid-19 pandemic has driven many governments to discover solutions for various problems faced during the pandemic, including the Regional Government of Jakarta (GOJ). In light of such crisis and pandemic situation, there have been a group of people that need additional primary food supply. In contrast, wealthy people are keen to help the vulnerable. Several attempts have been made to distribute social aids to residents with financial difficulties. However, the nature of social welfare services remains unclear and unscheduled. In this paper, we present a framework for a collaborative digital platform as a hub for the people in need and potential contributors. Such a framework calls as Large-scale Social Collaboration (KSBB) for better aid distribution management. The KSBB framework serves as a basis for: (1) analyzing need assessment of individuals\/communities in need; (2) mapping of targeted individuals\/communities in need; and (3) facilitating coordination with local communities. This paper shows that strong policy mandate, binding institution, and professional information technology support in government is crucial for the deliverable. The program can be implemented with the role of the government as platform providers rather than executors of social donation programs. The real applicability of the framework is demonstrated in the paper through the case of Jakarta during the first Large-scale Social Restrictions (PSBB). The use of such a framework can also inspire other initiatives to consider the model in developing similar and related programs. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Covid-19 pandemic has driven many governments to discover solutions for various problems faced during the pandemic, including the Regional Government of Jakarta (GOJ). In light of such crisis and pandemic situation, there have been a group of people that need additional primary food supply. In contrast, wealthy people are keen to help the vulnerable. Several attempts have been made to distribute social aids to residents with financial difficulties. However, the nature of social welfare services remains unclear and unscheduled. In this paper, we present a framework for a collaborative digital platform as a hub for the people in need and potential contributors. Such a framework calls as Large-scale Social Collaboration (KSBB) for better aid distribution management. The KSBB framework serves as a basis for: (1) analyzing need assessment of individuals\/communities in need; (2) mapping of targeted individuals\/communities in need; and (3) facilitating coordination with local communities. This paper shows that strong policy mandate, binding institution, and professional information technology support in government is crucial for the deliverable. The program can be implemented with the role of the government as platform providers rather than executors of social donation programs. The real applicability of the framework is demonstrated in the paper through the case of Jakarta during the first Large-scale Social Restrictions (PSBB). The use of such a framework can also inspire other initiatives to consider the model in developing similar and related programs. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Choice Shrimp Technology based on Business Process, Productivity, Financial and Risk"
        ],
        "penulis":"Akbar, Wydzka Tasha Aulia;Chumaidiyah, Endang;Rendra, Meldi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The application of new technology in shrimp ponds, autofeeder, has many advantages, but carries a greater risk compared to conventional shrimp ponds, therefore a more structured analysis is needed to decide the best shrimp pond technology. The comparison is seen from business processes, productivity, financial and risk. The results of business process efficiency level with conventional worth 67.19% while for the autofeeder level worth 88.71%. The productivity results show FCR 1.34 (conventional) and 1.34 (autofeeder); SR 79% (conventional) and 90% (autofeeder); and productivity of 13 tons\/ha (conventional) and 25 tons\/ha (autofeeder). The financial shows an NPV of Rp 1, 515, 178.503 (conventional) and Rp 7, 721, 596, 229 (autofeeder); IRR 38.24% (conventional) and 51.23% (autofeeder); payback period 2.68 years (conventional) and 2.17 years (autofeeder); BCR 1, 696 (conventional) and 2, 065 (autofeeder). Furthermore, for the calculation of risk consisting of production risk and revenue risk with a total risk of 6% for conventional and 31% for autofeeder. In the results of technology selection with an assessment of the 15 criteria above, the results obtained 4 criteria are better for conventional technology and 11 criteria are better for autofeeder technology. So between the two technologies, the selected shrimp pond system is the Autofeeder technology. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The application of new technology in shrimp ponds, autofeeder, has many advantages, but carries a greater risk compared to conventional shrimp ponds, therefore a more structured analysis is needed to decide the best shrimp pond technology. The comparison is seen from business processes, productivity, financial and risk. The results of business process efficiency level with conventional worth 67.19% while for the autofeeder level worth 88.71%. The productivity results show FCR 1.34 (conventional) and 1.34 (autofeeder); SR 79% (conventional) and 90% (autofeeder); and productivity of 13 tons\/ha (conventional) and 25 tons\/ha (autofeeder). The financial shows an NPV of Rp 1, 515, 178.503 (conventional) and Rp 7, 721, 596, 229 (autofeeder); IRR 38.24% (conventional) and 51.23% (autofeeder); payback period 2.68 years (conventional) and 2.17 years (autofeeder); BCR 1, 696 (conventional) and 2, 065 (autofeeder). Furthermore, for the calculation of risk consisting of production risk and revenue risk with a total risk of 6% for conventional and 31% for autofeeder. In the results of technology selection with an assessment of the 15 criteria above, the results obtained 4 criteria are better for conventional technology and 11 criteria are better for autofeeder technology. So between the two technologies, the selected shrimp pond system is the Autofeeder technology. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "DCT-based Visual Feature Extraction for Indonesian Audiovisual Speech Recognition"
        ],
        "penulis":"Rijal, Hilman Fauzi;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Today, the internet traffic is dominated by video data. It leads many researchers to develop an audiovisual automatic speech recognition (AVSR). They have proven that AVSR is more accurate and more resistant to noise than the audio-based automatic speech recognition (ASR). However, there are three issues in developing an AVSR system, namely: how to create an optimum combination of audio and visual features; the acoustic model based on phonemes and graphemes\/characters\/letters is commonly not robust to noise; and the feature extraction that is generally based on Mel Frequency Cepstral Coefficient (MFCC) and Gaussian Mixture Model (GMM) has high complexity. This paper describes the development of a syllable-based Indonesian AVSR system (INAVSR) using the fusion of both audio and visual features. The system is developed using a Hidden Markov Toolkit (HTK) along with visual feature extraction using both discrete cosine transform (DCT) and principal component analysis (PCA). The dataset of 43 recorded videos with resolution of 640 \u00d7 360 pixels, 25 frames per second, and the audio sample rate of 16 kHz is also developed to evaluate the system. The dataset is split into two subsets: 28 videos for the training set and 15 videos for the testing set. The evaluation shows that the developed system is capable of absolutely reducing the word error rate (WER) produced by the audio-based ASR by up to 6.07%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Today, the internet traffic is dominated by video data. It leads many researchers to develop an audiovisual automatic speech recognition (AVSR). They have proven that AVSR is more accurate and more resistant to noise than the audio-based automatic speech recognition (ASR). However, there are three issues in developing an AVSR system, namely: how to create an optimum combination of audio and visual features; the acoustic model based on phonemes and graphemes\/characters\/letters is commonly not robust to noise; and the feature extraction that is generally based on Mel Frequency Cepstral Coefficient (MFCC) and Gaussian Mixture Model (GMM) has high complexity. This paper describes the development of a syllable-based Indonesian AVSR system (INAVSR) using the fusion of both audio and visual features. The system is developed using a Hidden Markov Toolkit (HTK) along with visual feature extraction using both discrete cosine transform (DCT) and principal component analysis (PCA). The dataset of 43 recorded videos with resolution of 640 \u00d7 360 pixels, 25 frames per second, and the audio sample rate of 16 kHz is also developed to evaluate the system. The dataset is split into two subsets: 28 videos for the training set and 15 videos for the testing set. The evaluation shows that the developed system is capable of absolutely reducing the word error rate (WER) produced by the audio-based ASR by up to 6.07%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Competency evaluation of project manager performance in network construction projects"
        ],
        "penulis":"Fajar Sitohang, Yohanes;Pratami, Devi;Fuad Bay, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A company engaged in providing telecommunications network services in Indonesia, carry out various network construction projects. All construction projects are run and led by a project manager who is responsible for the sustainability and success of the project. Unfortunately, the company has never assessed and evaluated the competence of a project manager. This causes project success can not always be achieved, some mistakes often repeat themselves, and sometimes there are irregularities when the project is running. Therefore, this research will evaluate the competence of the project manager to identify deficiencies that the project manager has and how to fix them. The evaluation will be carried out using the Project Manager Competency Development Framework (PMCDF) method developed by PMI (Project Management Institute) which can objectively assess the performance competency of the project manager. PMCDF has ten units of performance competencies that can be performed. It is necessary to eliminate competency units that will be chosen by the company experts through a pairwise comparison questionnaire and after that, the results of the questionnaire are processed using the AHP method. The selection of competency units aims to ensure that the competency units that are assessed and evaluated are units that have a big influence on the running of the project at the company. From the processing results, three competency units that have a major influence on the course of the project in the company project quality management (33%), project cost management (21 %), and project Human Resources (HR) management (17%). Through the results of the evaluation that has been carried out, the project manager already has sufficient competence in the project quality management unit, however, in the cost management unit and project HR management, there are still deficiencies that need to be fixed. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A company engaged in providing telecommunications network services in Indonesia, carry out various network construction projects. All construction projects are run and led by a project manager who is responsible for the sustainability and success of the project. Unfortunately, the company has never assessed and evaluated the competence of a project manager. This causes project success can not always be achieved, some mistakes often repeat themselves, and sometimes there are irregularities when the project is running. Therefore, this research will evaluate the competence of the project manager to identify deficiencies that the project manager has and how to fix them. The evaluation will be carried out using the Project Manager Competency Development Framework (PMCDF) method developed by PMI (Project Management Institute) which can objectively assess the performance competency of the project manager. PMCDF has ten units of performance competencies that can be performed. It is necessary to eliminate competency units that will be chosen by the company experts through a pairwise comparison questionnaire and after that, the results of the questionnaire are processed using the AHP method. The selection of competency units aims to ensure that the competency units that are assessed and evaluated are units that have a big influence on the running of the project at the company. From the processing results, three competency units that have a major influence on the course of the project in the company project quality management (33%), project cost management (21 %), and project Human Resources (HR) management (17%). Through the results of the evaluation that has been carried out, the project manager already has sufficient competence in the project quality management unit, however, in the cost management unit and project HR management, there are still deficiencies that need to be fixed. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Fuzzy Swing Up Control and Optimal State Feedback Stabilization for Self-Erecting Inverted Pendulum"
        ],
        "penulis":"Susanto, Erwin;Surya Wibowo, Agung;Ghiffary Rachman, Elvandry;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents the realisation of self-erecting inverted pendulum controls via two switched control approaches, a rule based fuzzy control for swing up inverted pendulum rod to pose upright position from downright position and an optimal state feedback control for stabilization as pendulum on upright position close to its equilibrium vertical line. The aim of this study is to solve two important problems on self-erecting inverted pendulum; swing up and stability in its upright balance position. Simulation and experimental results showed that control methods enabled the inverted pendulum swinging up and reaching its stable attitude in upright position even though small impulse and pulse disturbances were given. \u00a9 2013 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents the realisation of self-erecting inverted pendulum controls via two switched control approaches, a rule based fuzzy control for swing up inverted pendulum rod to pose upright position from downright position and an optimal state feedback control for stabilization as pendulum on upright position close to its equilibrium vertical line. The aim of this study is to solve two important problems on self-erecting inverted pendulum; swing up and stability in its upright balance position. Simulation and experimental results showed that control methods enabled the inverted pendulum swinging up and reaching its stable attitude in upright position even though small impulse and pulse disturbances were given. \u00a9 2013 IEEE."
        ]
    },
    {
        "judul":[
            "Attendance system using machine learning-based face detection for meeting room application"
        ],
        "penulis":"Muttaqin, Rahmat;Nopendri;Fuada, Syifaul;Mulyana, Eueung;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In a modern meeting room, a smart system to make attendance quickly is mandatory. Most of the existing systems perform manual attendance, such as registration and fingerprint. Despite the fingerprint method can reject the Unknown person and give the grant access to the Known person, it will take time to register first a person one-by-one. Moreover, it is possible to create long queues for fingerprint checking before entering the meeting room. Machine learning, along with the Internet of Things (IoT) technology is the best solution; it offers many advantages when applied in the meeting rooms. Generally, the method used is to create a presence by detecting faces. In this paper, we present a facial recognition authentication based on machine learning technology for connection to the meeting rooms. Furthermore, specific website to display the detection result and data storage design testing is developed. The method uses 1) the Dlib library for deep learning purposes, 2) OpenCV for video camera processing, and 3) Face Recognition for Dlib processing. The proposed system allows placing the multiple cameras in a meeting room as needed. However, in this work, we only used one camera as the main system. Tests conducted include identification of one Known person, identification of one Unknown person, identification of two people, and three people. The parameter to be focused is the required time in detecting the number of faces recorded by the camera. The results reveal that the face can be recognized or not recognized, then it will be displayed on the website. \u00a9 2020, Science and Information Organization.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a modern meeting room, a smart system to make attendance quickly is mandatory. Most of the existing systems perform manual attendance, such as registration and fingerprint. Despite the fingerprint method can reject the Unknown person and give the grant access to the Known person, it will take time to register first a person one-by-one. Moreover, it is possible to create long queues for fingerprint checking before entering the meeting room. Machine learning, along with the Internet of Things (IoT) technology is the best solution; it offers many advantages when applied in the meeting rooms. Generally, the method used is to create a presence by detecting faces. In this paper, we present a facial recognition authentication based on machine learning technology for connection to the meeting rooms. Furthermore, specific website to display the detection result and data storage design testing is developed. The method uses 1) the Dlib library for deep learning purposes, 2) OpenCV for video camera processing, and 3) Face Recognition for Dlib processing. The proposed system allows placing the multiple cameras in a meeting room as needed. However, in this work, we only used one camera as the main system. Tests conducted include identification of one Known person, identification of one Unknown person, identification of two people, and three people. The parameter to be focused is the required time in detecting the number of faces recorded by the camera. The results reveal that the face can be recognized or not recognized, then it will be displayed on the website. \u00a9 2020, Science and Information Organization."
        ]
    },
    {
        "judul":[
            "Technical specification for effective next generation network interconnection in Indonesia"
        ],
        "penulis":"Abdurohman, Maman;Nugroho, Bambang Setia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper proposes technical specifications for effectively implementing the interconnection of Next Generation Network (NGN) in Indonesia. NGN is one of the current telecommunication infrastructure network technology trends. It provides a simpler concept with only two layers of service and transport. The NGN IP-based transport system can connect with various types of networks, which leads to low management costs by offering different kinds of services. Meanwhile, there are currently various types of telecommunication networks depending on the services provided, such as Public Switched Telephone Network (PSTN), IPv4 Internet as well as Public Switched Data Network (PSDN). PSTN is a circuit-switched voice communications network, and PSDN is a network for data-based communications with International Telecommunication Union (ITU)-T X.121 standards. Another type is a packet-switched based network that uses IPv4 addressing systems. Each network has its customers. One of the problems that arise, however, is how to transform the current network system to the NGN network effectively. The effectiveness of network transformation in the service provision for users is determined by the technical aspects used. Some of the technical aspects issues on implementation of NGN networks in Indonesia are the use of a protocol for signaling, coding standards, Quality of Service (QoS), numbering and addressing, and security. This paper proposes technical specifications for the effectiveness of NGN network implementation in Indonesia. Through the technical specification model, we propose, the risks that will arise in the implementation of NGN networks in Indonesia can be managed. Appropriate technical specifications have an essential role in the effectiveness of NGN network implementation in Indonesia. \u00a9 2020, Insight Society.",
            "OH3CCH3SHSView detailsExpand Substance isopropylxanthic acid",
            "Powered by",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes technical specifications for effectively implementing the interconnection of Next Generation Network (NGN) in Indonesia. NGN is one of the current telecommunication infrastructure network technology trends. It provides a simpler concept with only two layers of service and transport. The NGN IP-based transport system can connect with various types of networks, which leads to low management costs by offering different kinds of services. Meanwhile, there are currently various types of telecommunication networks depending on the services provided, such as Public Switched Telephone Network (PSTN), IPv4 Internet as well as Public Switched Data Network (PSDN). PSTN is a circuit-switched voice communications network, and PSDN is a network for data-based communications with International Telecommunication Union (ITU)-T X.121 standards. Another type is a packet-switched based network that uses IPv4 addressing systems. Each network has its customers. One of the problems that arise, however, is how to transform the current network system to the NGN network effectively. The effectiveness of network transformation in the service provision for users is determined by the technical aspects used. Some of the technical aspects issues on implementation of NGN networks in Indonesia are the use of a protocol for signaling, coding standards, Quality of Service (QoS), numbering and addressing, and security. This paper proposes technical specifications for the effectiveness of NGN network implementation in Indonesia. Through the technical specification model, we propose, the risks that will arise in the implementation of NGN networks in Indonesia can be managed. Appropriate technical specifications have an essential role in the effectiveness of NGN network implementation in Indonesia. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[
            "Deep Neural Networks with Extreme Learning Machine for Seismic Data Compression"
        ],
        "penulis":"Nuha, Hilal H.;Balghonaim, Adil;Liu, Bo;Mohandes, Mohamed;Deriche, Mohamed;Fekri, Faramarz;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Advances on seismic survey techniques require a large number of geophones. This leads to an exponential growth in the size of data and prohibitive demands on storage and network communication resources. Therefore, it is desirable to compress the seismic data to the minimum possible, without losing important information. In this paper, a stacked auto-encoder extreme learning machine (AE-ELM) for seismic data compression is proposed. First, a deep asymmetric auto-encoder is constructed, in which nonlinear activation functions are used in the encoder hidden layers and linear activation functions are utilized in the decoder layers. Second, the encoder hidden layers are connected in a cascade way, so that outputs of a hidden layer are considered as the inputs to the succeeding hidden layer. Third, the optimal weights of connections between the layers of the decoder are solved analytically. Lastly, the AE-ELMs are stacked to create the complete encoder\/decoder. The extreme learning machine (ELM) is selected due to its analytical calculation of weights efficient training that is suitable for practical implementation. In this neural network, data compression is achieved by transforming the original data through the encoder layers where the size of outputs from the last encoder hidden layer is smaller than the original data size. The proposed method exhibits a comparable reconstruction quality on a real dataset but with a much shorter training duration than other deep neural networks methods. This neural network with more than 8000 hidden units achieved 1.28 \u00d7 10- 3of normalized mean-squared error for 10:1 of compression ratio with only 8.23\u00a0s of training time. \u00a9 2019, King Fahd University of Petroleum & Minerals.",
            "ClClNView detailsExpand Substance 2,6-dichloro-benzonitrile",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Advances on seismic survey techniques require a large number of geophones. This leads to an exponential growth in the size of data and prohibitive demands on storage and network communication resources. Therefore, it is desirable to compress the seismic data to the minimum possible, without losing important information. In this paper, a stacked auto-encoder extreme learning machine (AE-ELM) for seismic data compression is proposed. First, a deep asymmetric auto-encoder is constructed, in which nonlinear activation functions are used in the encoder hidden layers and linear activation functions are utilized in the decoder layers. Second, the encoder hidden layers are connected in a cascade way, so that outputs of a hidden layer are considered as the inputs to the succeeding hidden layer. Third, the optimal weights of connections between the layers of the decoder are solved analytically. Lastly, the AE-ELMs are stacked to create the complete encoder\/decoder. The extreme learning machine (ELM) is selected due to its analytical calculation of weights efficient training that is suitable for practical implementation. In this neural network, data compression is achieved by transforming the original data through the encoder layers where the size of outputs from the last encoder hidden layer is smaller than the original data size. The proposed method exhibits a comparable reconstruction quality on a real dataset but with a much shorter training duration than other deep neural networks methods. This neural network with more than 8000 hidden units achieved 1.28 \u00d7 10- 3of normalized mean-squared error for 10:1 of compression ratio with only 8.23\u00a0s of training time. \u00a9 2019, King Fahd University of Petroleum & Minerals."
        ]
    },
    {
        "judul":[
            "End-to-End Speech Recognition Models for a Low-Resourced Indonesian Language"
        ],
        "penulis":"Suyanto, Suyanto;Arifianto, Anditya;Sirwan, Anis;Rizaendra, Angga P.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Recent automatic speech recognition (ASR) is commonly developed using deep learning (DL), instead of the Hidden Markov Model (HMM). Many researchers show that DL is much better than HMM in noisy environments. However, DL needs a huge speech corpus but does not require any dictionary as well as the concept of either phonemes or syllables. Many DL-based tools are developed and claimed as a language-independent ASR, such as Mozma DeepSpeech (MDS) and Kaituoxu SpeechTransformer (KST). Both MDS and KST are classified as End-to-End ASR (E2EASR), but MDS uses a Recurrent Neural Network (RNN) while KST exploits a Transformer Network. In this paper, two Indonesian ASR (INASR) are developed using both MDS and KST to see their performances to handle a low-resourced language. Evaluation using a small speech corpus of Bahasa Indonesia containing 40 k utterances shows that KST is slightly better than MDS, where it gives a word error rate (WER) of 22.00% while MDS produces a WER of 23.10%.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recent automatic speech recognition (ASR) is commonly developed using deep learning (DL), instead of the Hidden Markov Model (HMM). Many researchers show that DL is much better than HMM in noisy environments. However, DL needs a huge speech corpus but does not require any dictionary as well as the concept of either phonemes or syllables. Many DL-based tools are developed and claimed as a language-independent ASR, such as Mozma DeepSpeech (MDS) and Kaituoxu SpeechTransformer (KST). Both MDS and KST are classified as End-to-End ASR (E2EASR), but MDS uses a Recurrent Neural Network (RNN) while KST exploits a Transformer Network. In this paper, two Indonesian ASR (INASR) are developed using both MDS and KST to see their performances to handle a low-resourced language. Evaluation using a small speech corpus of Bahasa Indonesia containing 40 k utterances shows that KST is slightly better than MDS, where it gives a word error rate (WER) of 22.00% while MDS produces a WER of 23.10%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Simulated Annealing-Support Vector Machine on QSAR Study of Fusidic Acid Derivatives as Anti-Malarial Agent"
        ],
        "penulis":"Rahman, Farisi;Lhaksmana, Kemas Muslim;Kurniawan, Isman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Malaria is a disease caused by the Plasmodium falciparum parasite and leads to many cases of deaths. Recently, the combination of several drugs has been used to treat this disease. However, the parasite is known to be resistant to the anti-malarial agent. Hence, a new candidate for an anti-malarial drug is required to solve the resistance problem. One compound that is promising as an anti-malarial agent is fusidic acid derivatives. Fusidic acid is an antibiotic that is work by preventing parasite growth. Besides, fusidic acid is known to have antiplasmodial activity although the IC50 is still poor. However, the activity can be improved by optimizing the structure through its derivatives. In this study, we developed a QSAR model to predict the activity of fusidic acid derivatives as anti-malarial agent. The model was developed by using Simulated Annealing (SA) for feature selection and Support Vector Machine (SVM) for model development. The results show that SA produces a satisfying combination of features that are indicated by the trend of MSE value during the selection process. Regarding the performance, SVM with RBF kernel produces the best result of the validation parameter. This indicates that the model is valid to be used to predict a compound with unknown activity values for anti-malarial agents.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Malaria is a disease caused by the Plasmodium falciparum parasite and leads to many cases of deaths. Recently, the combination of several drugs has been used to treat this disease. However, the parasite is known to be resistant to the anti-malarial agent. Hence, a new candidate for an anti-malarial drug is required to solve the resistance problem. One compound that is promising as an anti-malarial agent is fusidic acid derivatives. Fusidic acid is an antibiotic that is work by preventing parasite growth. Besides, fusidic acid is known to have antiplasmodial activity although the IC50 is still poor. However, the activity can be improved by optimizing the structure through its derivatives. In this study, we developed a QSAR model to predict the activity of fusidic acid derivatives as anti-malarial agent. The model was developed by using Simulated Annealing (SA) for feature selection and Support Vector Machine (SVM) for model development. The results show that SA produces a satisfying combination of features that are indicated by the trend of MSE value during the selection process. Regarding the performance, SVM with RBF kernel produces the best result of the validation parameter. This indicates that the model is valid to be used to predict a compound with unknown activity values for anti-malarial agents.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Developing web-based e-news application as an it-based facility"
        ],
        "penulis":"Kartawinata, Budi Rustandi;Pradana, Mahir;Maharani, Dyah;Nugraha, Diki Wahyu;Helmi, M. Yusril;Saputra, M. Harry K.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information technology is one of the fastest growing technologies at this time. With the advancement of information technology, access to data or information available can take place quickly, efficiently and accurately. The function and purpose of this application is to provide convenience in posting articles in a web to provide information processing convenience by using CI-based web services. This application is made with web-based and uses the PHP programming language, in addition to using the PHP and MySQL programming languages as the database. In making this application adjusted Web-Based E-News Development as a Means of Information Technology. Information with website-based and by using the Mysql database to collect data on active users, posting with categories, clear and accurate information, making it easier for readers to find out information on E-News web users and any information will be known by visitors who have subscribed via the website. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information technology is one of the fastest growing technologies at this time. With the advancement of information technology, access to data or information available can take place quickly, efficiently and accurately. The function and purpose of this application is to provide convenience in posting articles in a web to provide information processing convenience by using CI-based web services. This application is made with web-based and uses the PHP programming language, in addition to using the PHP and MySQL programming languages as the database. In making this application adjusted Web-Based E-News Development as a Means of Information Technology. Information with website-based and by using the Mysql database to collect data on active users, posting with categories, clear and accurate information, making it easier for readers to find out information on E-News web users and any information will be known by visitors who have subscribed via the website. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "Freight route planning in intermodal transportation network to deal with combinational disruptions"
        ],
        "penulis":"Rosyida, Erly E;Santosa, Budi;Pujawan, I Nyoman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this study, we developed an intermodal transportation model that extends the VRP model and its recovery model. This study emphasizes re-identifying the best route, departure time, and the selection of the best ship with the right type of capacity booking that produces the lowest total cost after dealing with disruption. The re-routing process is shifted by transforming the disruption to a virtual node in order to define the added time and cost after a disruption occurred. The disruption types include link and customer disruptions. The numerical experiment uses the metaheuristics, namely, Genetic Algorithm and Simulated Annealing, because it is an np-hard problem. The results of the optimization process yielded the total cost increased when the average vehicle speed was enhanced. The starting service time provides cost savings through a reduction of penalties because the arrival is not within the time window that had been agreed upon. Besides, the type of capacity order, more specifically the type of direct purchase (on the spot), provides better costs when the level of disruption is heavy. In contrast, a lighter level of disruption can cause a minimal total cost for purchasing the up-front type of fee. However, the scenario of capacity cost shows that lower prices can make the direct purchasing type more profitable. On the other hand, increasing the price of renting a ship\u2019s capacity makes the up-front type of fees more profitable. \u00a9 2020 The Author(s). This open access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this study, we developed an intermodal transportation model that extends the VRP model and its recovery model. This study emphasizes re-identifying the best route, departure time, and the selection of the best ship with the right type of capacity booking that produces the lowest total cost after dealing with disruption. The re-routing process is shifted by transforming the disruption to a virtual node in order to define the added time and cost after a disruption occurred. The disruption types include link and customer disruptions. The numerical experiment uses the metaheuristics, namely, Genetic Algorithm and Simulated Annealing, because it is an np-hard problem. The results of the optimization process yielded the total cost increased when the average vehicle speed was enhanced. The starting service time provides cost savings through a reduction of penalties because the arrival is not within the time window that had been agreed upon. Besides, the type of capacity order, more specifically the type of direct purchase (on the spot), provides better costs when the level of disruption is heavy. In contrast, a lighter level of disruption can cause a minimal total cost for purchasing the up-front type of fee. However, the scenario of capacity cost shows that lower prices can make the direct purchasing type more profitable. On the other hand, increasing the price of renting a ship\u2019s capacity makes the up-front type of fees more profitable. \u00a9 2020 The Author(s). This open access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license."
        ]
    },
    {
        "judul":[
            "Performance Analysis of On-Off Keying Modulation on Underwater Visible Light Communication"
        ],
        "penulis":"Amalia, Annisa Izmi;Hambali, Akhmad;Pamukti, Brian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research evaluates the performance of On-Off Keying (OOK) Modulation on the Underwater Visible Light Communication (UVLC) system. This research analyses the performance of two types of OOK signal formats, Non-Return to Zero (OOK-NRZ) and Return to Zero (OOK-RZ). This signal formats tested on distance, acceptability, Signal to Noise Ratio (SNR), Q-factor and Bit Error Rate (BER) parameters. From extensive simulations that have been done, the results show that the received power decreased 21.7249 % at the maximum distance. In this condition, the UVLC system produced the BER value of the NRZ format 3.28 \u00d7 smaller than the RZ format. The SNR minimum that produced BER value less than the threshold for NRZ format is 17.925% smaller than the RZ format. Meanwhile, the minimum Q-factor that produced BER value less than 10-3for NRZ modulation is 6 \u00d7 smaller than the RZ modulation format. From the results, we take the conclusion that the OOK-NRZ better than OOK-RZ on the UVLC system. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research evaluates the performance of On-Off Keying (OOK) Modulation on the Underwater Visible Light Communication (UVLC) system. This research analyses the performance of two types of OOK signal formats, Non-Return to Zero (OOK-NRZ) and Return to Zero (OOK-RZ). This signal formats tested on distance, acceptability, Signal to Noise Ratio (SNR), Q-factor and Bit Error Rate (BER) parameters. From extensive simulations that have been done, the results show that the received power decreased 21.7249 % at the maximum distance. In this condition, the UVLC system produced the BER value of the NRZ format 3.28 \u00d7 smaller than the RZ format. The SNR minimum that produced BER value less than the threshold for NRZ format is 17.925% smaller than the RZ format. Meanwhile, the minimum Q-factor that produced BER value less than 10-3for NRZ modulation is 6 \u00d7 smaller than the RZ modulation format. From the results, we take the conclusion that the OOK-NRZ better than OOK-RZ on the UVLC system. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Change management to support institutional amendment of higher education based on Kotter's model"
        ],
        "penulis":"Iskandar, Ade;Saon, Sharifah;Chandra, Indra;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Change Management needs to be implemented for all academic communities of Telkom Jakarta Academy, due to institutional changes to be Institute level. This paper aims to support successful change management for shareholders and stakeholders of Telkom Jakarta Academy and Telkom Education Foundation to implement The Jakarta Telecommunications Institute of Technology based on measurement results of five indicators studied (implementation team, Telkom Education Foundations, individuals, leaders, and implementation readiness). The method conducted in this paper is Action Research, where the deep interviews with some chairmen of Telkom Education Foundation are conducted, questionnaire for Akademi Telkom's stakeholder based on Kotter's model guidance in managing Change Management. The results of this reseacrh indicate that there are differences between the five research indicators compared (the implementation team, Telkom Education Foundations, individuals, leaders, and implementation readiness).  \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Change Management needs to be implemented for all academic communities of Telkom Jakarta Academy, due to institutional changes to be Institute level. This paper aims to support successful change management for shareholders and stakeholders of Telkom Jakarta Academy and Telkom Education Foundation to implement The Jakarta Telecommunications Institute of Technology based on measurement results of five indicators studied (implementation team, Telkom Education Foundations, individuals, leaders, and implementation readiness). The method conducted in this paper is Action Research, where the deep interviews with some chairmen of Telkom Education Foundation are conducted, questionnaire for Akademi Telkom's stakeholder based on Kotter's model guidance in managing Change Management. The results of this reseacrh indicate that there are differences between the five research indicators compared (the implementation team, Telkom Education Foundations, individuals, leaders, and implementation readiness).  \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "The Prototype of In-Store Visitor and People Passing Counters using Single Shot Detector Performed by OpenCV"
        ],
        "penulis":"Herviana, Andes;Sudiharto, Dodi Wisaksono;Yulianto, Fazmah Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information related to the power hours of a mall or store is important. By typically knowing it, the manager of the store or the mall can wisely determine the staff planning decision. Without the right decision, it potentially decreases customer satisfaction. The decision can be defined by utilizing in-store visitors and people passing traffic patterns. The other problem also arises when the calculation of in-store visitors and people passing are executed manually, so it requires much effort. This study proposes a prototype design of the system which can automatically calculate visitors by utilizing Single Shot Detector (SSD) method. This method is performed by operating OpenCV library. It is used to detect a human object marked as in-store visitor or people passing. The embedded computer is conducted to process images captured by Pi Camera. Based on the study, the result accuracy is 65.08% for the system counts in-store visitors, and 66.12% for the system marks objects as people pass around in front of the store. Although the accuracy values obtained is not high, but all patterns show that the highest average values of in-store visitors and people passing occur on the days nearing weekend and also on the weekend, such as Friday, Saturday and Sunday. The peak time of in-store visitors (e.g. power hour) on Friday is between 12 PM and 1 PM. The peak time of in-store visitors on Saturday is between 3 PM and 4 PM, and on Monday, it is between 4 PM and 5 PM.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information related to the power hours of a mall or store is important. By typically knowing it, the manager of the store or the mall can wisely determine the staff planning decision. Without the right decision, it potentially decreases customer satisfaction. The decision can be defined by utilizing in-store visitors and people passing traffic patterns. The other problem also arises when the calculation of in-store visitors and people passing are executed manually, so it requires much effort. This study proposes a prototype design of the system which can automatically calculate visitors by utilizing Single Shot Detector (SSD) method. This method is performed by operating OpenCV library. It is used to detect a human object marked as in-store visitor or people passing. The embedded computer is conducted to process images captured by Pi Camera. Based on the study, the result accuracy is 65.08% for the system counts in-store visitors, and 66.12% for the system marks objects as people pass around in front of the store. Although the accuracy values obtained is not high, but all patterns show that the highest average values of in-store visitors and people passing occur on the days nearing weekend and also on the weekend, such as Friday, Saturday and Sunday. The peak time of in-store visitors (e.g. power hour) on Friday is between 12 PM and 1 PM. The peak time of in-store visitors on Saturday is between 3 PM and 4 PM, and on Monday, it is between 4 PM and 5 PM.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Modulation Performance of Underwater Visible Light Communication with Variable Wavelength"
        ],
        "penulis":"Ibrahimy, Arya Maulana;Fadilah, Budi Ikhwan;Pamukti, Brian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper evaluates the performance of Underwater Visible Light Communication (UVLC) with various modulation and wavelength. The first scenario will analyze the Signalto-Noise Ratio (SNR) of the UVLC with 450, 480, and 500 nm wavelength. The second scenario will compare the performance of Bit Error Rate (BER) with various modulation from Onoff Keying No-Return Zero (OOK-NRZ), On-Off Keying Return Zero (OOK-RZ), 8 Pulse Position Modulation (8-PPM), and 8 Pulse Amplitude Modulation (8-PAM). Same as the first scenario the comparison of BER use 450, 480, and 500 nm wavelength. From thesimulation of the first scenario, the used of 500 nm wavelength get the result 13.1147, which is the best result of SNR in this simulation. Meanwhile, in the second scenario, the combination of 8-PPM with 500 nm wavelength get the result 1.8922 $\\times 10^{-10}$, which is the best result and the value is smaller from Optical Wireless Communication (OWC) BER which is $10^{-9}$ \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper evaluates the performance of Underwater Visible Light Communication (UVLC) with various modulation and wavelength. The first scenario will analyze the Signalto-Noise Ratio (SNR) of the UVLC with 450, 480, and 500 nm wavelength. The second scenario will compare the performance of Bit Error Rate (BER) with various modulation from Onoff Keying No-Return Zero (OOK-NRZ), On-Off Keying Return Zero (OOK-RZ), 8 Pulse Position Modulation (8-PPM), and 8 Pulse Amplitude Modulation (8-PAM). Same as the first scenario the comparison of BER use 450, 480, and 500 nm wavelength. From thesimulation of the first scenario, the used of 500 nm wavelength get the result 13.1147, which is the best result of SNR in this simulation. Meanwhile, in the second scenario, the combination of 8-PPM with 500 nm wavelength get the result 1.8922 $\\times 10^{-10}$, which is the best result and the value is smaller from Optical Wireless Communication (OWC) BER which is $10^{-9}$ \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Measurement of Criterion Weight to Determine Industrial Area Location Using AHP for Economic Growth"
        ],
        "penulis":"Chumaidiyah E.;Dewantoro M.D.R.;Hakimah D.A.;Arffan Z.;Robbi R.M.N.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Industrial area is an infrastructure for the process of industrialization as a source that can trigger economic growth. Industrial areas that are structured and can support production operations are an appeal to foreign investors. However, the development of industrial areas requires careful planning because it impacts on the environmental carrying capacity and land loss. Therefore, industrial area development needs attention to a variety of important criteria as considerations in determining the location of an industrial area. This study aims to determine the criteria and measure the importance of each relative criterion to other criteria. The method used is Analytical Hierarchy Process (AHP). The results show that there are four important factors that need to be considered with each of the importance level, namely Infrastructure by 33.97%, Distance to Access by 31.74%, Land Soil by 19.57%, and Production Factors by 14.72%. The four factors have ten important criteria that need to be considered in making decisions to determine the location of an industrial area where the two highest criteria are electricity infrastructure with a significance level of 19.05% and telecommunications infrastructure with an importance level of 14.92%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industrial area is an infrastructure for the process of industrialization as a source that can trigger economic growth. Industrial areas that are structured and can support production operations are an appeal to foreign investors. However, the development of industrial areas requires careful planning because it impacts on the environmental carrying capacity and land loss. Therefore, industrial area development needs attention to a variety of important criteria as considerations in determining the location of an industrial area. This study aims to determine the criteria and measure the importance of each relative criterion to other criteria. The method used is Analytical Hierarchy Process (AHP). The results show that there are four important factors that need to be considered with each of the importance level, namely Infrastructure by 33.97%, Distance to Access by 31.74%, Land Soil by 19.57%, and Production Factors by 14.72%. The four factors have ten important criteria that need to be considered in making decisions to determine the location of an industrial area where the two highest criteria are electricity infrastructure with a significance level of 19.05% and telecommunications infrastructure with an importance level of 14.92%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Ability to Adapt jBatik Software Technology for Traditional Batik Craftsmen"
        ],
        "penulis":"Ciptandi, Fajar;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study is to find out the adaptability of traditional batik craftsmen in using jBatik software technology to create motif development. The traditional batik industry in Tuban, East Java was choosen as an example of case because it is considered to represent other traditional batik industries in Java. In previous studies, the use of jBatik software has been tested and resulted in the development of several designs of traditional Tuban batik motifs. This study was conducted to analyze the factors driving as well as inhibiting traditional batik craftsmen in adapting jBatik software technology through an experimental approach by referring to the diffusion of innovation theory. This is useful as one of the solutions today as an effort to measure the readiness level of traditional batik craftsmen to adapt technology, as well as being a way of self-evaluation for the technology to adapt to the needs of traditional batik craftsmen in Indonesia.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to find out the adaptability of traditional batik craftsmen in using jBatik software technology to create motif development. The traditional batik industry in Tuban, East Java was choosen as an example of case because it is considered to represent other traditional batik industries in Java. In previous studies, the use of jBatik software has been tested and resulted in the development of several designs of traditional Tuban batik motifs. This study was conducted to analyze the factors driving as well as inhibiting traditional batik craftsmen in adapting jBatik software technology through an experimental approach by referring to the diffusion of innovation theory. This is useful as one of the solutions today as an effort to measure the readiness level of traditional batik craftsmen to adapt technology, as well as being a way of self-evaluation for the technology to adapt to the needs of traditional batik craftsmen in Indonesia.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Low Density Parity Check Code (LDPC) for Enhancement of Visible Light Communication (VLC) Performance"
        ],
        "penulis":"Pamukti, Brian;Arifin, Fernaldy;Adriansyah, Nachwan Mufti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Visible Light Communication (VLC) that utilizes free space optics as a transmission channel has a high-speed data communication capability, which uses Light Emitting Diode (LED) as a transmitter. Problems occurred in this wireless communication is the distance. VLC can only reach relatively short distance if compared to Radio Frequency (RF). There are many ways to reach a better distance performance on VLC and one of them is the error correction. In this paper, a comparison between uncoded and Quasi-Cyclic-Low Density Parity Check (QC-LDPC) codes implementation on VLC has been compared and the number of decoding iterations is simulated to reach better performance. The encoding technique of QC-LDPC codes is using the G-Matrix and Bit Flipping algorithm as the decoding. The result shows that distance increases 7% in case of QC-LDPC codes from the uncoded VLC system and 27.5% energy efficiency are increased. The number of decoding iterations also contributes an impact to Bit Error Rate (BER) performance. The simulation results proof that on VLC system using QC-LDPC codes shows better performance compared to the uncoded system.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Visible Light Communication (VLC) that utilizes free space optics as a transmission channel has a high-speed data communication capability, which uses Light Emitting Diode (LED) as a transmitter. Problems occurred in this wireless communication is the distance. VLC can only reach relatively short distance if compared to Radio Frequency (RF). There are many ways to reach a better distance performance on VLC and one of them is the error correction. In this paper, a comparison between uncoded and Quasi-Cyclic-Low Density Parity Check (QC-LDPC) codes implementation on VLC has been compared and the number of decoding iterations is simulated to reach better performance. The encoding technique of QC-LDPC codes is using the G-Matrix and Bit Flipping algorithm as the decoding. The result shows that distance increases 7% in case of QC-LDPC codes from the uncoded VLC system and 27.5% energy efficiency are increased. The number of decoding iterations also contributes an impact to Bit Error Rate (BER) performance. The simulation results proof that on VLC system using QC-LDPC codes shows better performance compared to the uncoded system.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "On the Feature Extraction for Sentiment Analysis of Movie Reviews Based on SVM"
        ],
        "penulis":"Cahyanti, Fitri Eka;Adiwijaya;Faraby, Said Al;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Watching a movie is one of the activities that reduce bored, so it is necessary to look for information about the movie, which is packaged in the form of a movie review to determine whether the movie considered for viewing or no. However, in searching for information through movie reviews, there are obstacles because there are many reviews conducted by reviewers. Therefore, sentiment analysis is needed aims to classify the movie review into positive and negative sentiments. Machine learning methods can use as a sentiment analysis classification because that can produce the best performance, the method called Support Vector Machine (SVM). That was a reason SVM classification used in sentiment analysis on movie review data. Use feature extraction of Term Frequency- Inverse Document Frequency (TF-IDF) was also carried out in the research this as a method of weighting words which then combined with the extraction of Latent features Dirichlet Allocation (LDA) as a method of modeling topics that can overcome the shortcomings of SVM. This research produced the best performance on a combination of TF-IDF and LDA, with 240 topics has 29792 features, which is 82.16%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Watching a movie is one of the activities that reduce bored, so it is necessary to look for information about the movie, which is packaged in the form of a movie review to determine whether the movie considered for viewing or no. However, in searching for information through movie reviews, there are obstacles because there are many reviews conducted by reviewers. Therefore, sentiment analysis is needed aims to classify the movie review into positive and negative sentiments. Machine learning methods can use as a sentiment analysis classification because that can produce the best performance, the method called Support Vector Machine (SVM). That was a reason SVM classification used in sentiment analysis on movie review data. Use feature extraction of Term Frequency- Inverse Document Frequency (TF-IDF) was also carried out in the research this as a method of weighting words which then combined with the extraction of Latent features Dirichlet Allocation (LDA) as a method of modeling topics that can overcome the shortcomings of SVM. This research produced the best performance on a combination of TF-IDF and LDA, with 240 topics has 29792 features, which is 82.16%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Digital mastery in Indonesia: the organization and individual contrast"
        ],
        "penulis":"Nasution, Reza Ashari;Arnita, Devi;Rusnandi, Linda Sendy Lediana;Qodariah, Elis;Rudito, Priyantono;Sinaga, Mardi Fretdi Natalina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Purpose: Our research objective here is to contribute theoretically and empirically to providing a gap model of digital mastery development in a company. The gap model will be a reference for the companies to develop their digital mastery. Design\/methodology\/approach: To gain deeper insights into the study, a mixed method of qualitative and quantitative was performed. The level of digital mastery of the organization was determined using quantitative techniques through a self-assessment questionnaire. Meanwhile, digital mastery at the individual level was measured by a qualitative method using an open-ended (essay format) survey questions. Findings: The findings show a stark difference between the organization and individual regarding their digital mastery level. At the end of the paper, the authors suggest some remedies that will help those companies narrowing the gap and fulfill the agenda of their digital transformation. Research limitations\/implications: Further research should analyze more industries or companies, conducting case studies to discover more detailed findings as to where the gaps are located or conducting digital readiness and leadership skills at the individual level to discover the direction of development of digital technology in a company. We expect this research can be replicated in other countries, so that wider general insights into the development of digital technology may be obtained. Practical implications: Upper-area companies are indicated by their execution of partial digital initiative in the company which results in the lack of socialization of the ongoing digital activities into the individual level. Companies, especially Top Management, need to develop more knowledge about digital application and transformation to every individual in the company. Meanwhile, lower-area companies should improve their engagement across all organization members. The companies should be able to take advantage of their existing employees who possess knowledge in digital application and transformation and generated various artifacts to motivate other employees to jointly transform the organization into a Digital Master. Originality\/value: Our study compares the perception toward digital mastery at the organization and individual levels. Both levels are different and need to be compared, as suggested by Schuchmann and Seufert (2015) and Hinings et al. (2018). Comparison at both levels does not exist at the time of this study. Accordingly, what problems and challenges are faced by companies undergoing a digital transformation will largely remain unknown. \u00a9 2020, Emerald Publishing Limited.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: Our research objective here is to contribute theoretically and empirically to providing a gap model of digital mastery development in a company. The gap model will be a reference for the companies to develop their digital mastery. Design\/methodology\/approach: To gain deeper insights into the study, a mixed method of qualitative and quantitative was performed. The level of digital mastery of the organization was determined using quantitative techniques through a self-assessment questionnaire. Meanwhile, digital mastery at the individual level was measured by a qualitative method using an open-ended (essay format) survey questions. Findings: The findings show a stark difference between the organization and individual regarding their digital mastery level. At the end of the paper, the authors suggest some remedies that will help those companies narrowing the gap and fulfill the agenda of their digital transformation. Research limitations\/implications: Further research should analyze more industries or companies, conducting case studies to discover more detailed findings as to where the gaps are located or conducting digital readiness and leadership skills at the individual level to discover the direction of development of digital technology in a company. We expect this research can be replicated in other countries, so that wider general insights into the development of digital technology may be obtained. Practical implications: Upper-area companies are indicated by their execution of partial digital initiative in the company which results in the lack of socialization of the ongoing digital activities into the individual level. Companies, especially Top Management, need to develop more knowledge about digital application and transformation to every individual in the company. Meanwhile, lower-area companies should improve their engagement across all organization members. The companies should be able to take advantage of their existing employees who possess knowledge in digital application and transformation and generated various artifacts to motivate other employees to jointly transform the organization into a Digital Master. Originality\/value: Our study compares the perception toward digital mastery at the organization and individual levels. Both levels are different and need to be compared, as suggested by Schuchmann and Seufert (2015) and Hinings et al. (2018). Comparison at both levels does not exist at the time of this study. Accordingly, what problems and challenges are faced by companies undergoing a digital transformation will largely remain unknown. \u00a9 2020, Emerald Publishing Limited."
        ]
    },
    {
        "judul":[
            "PSO-Learned Artificial Neural Networks for Activity Recognition"
        ],
        "penulis":"Ekaniza, Raki Anwar;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of Activity Recognition (AR) is to recognize human activity using a sensor to get the data needed. Then, a machine learning approach is used to determine the type of activity performed. A machine learning technique often used in the classification problem is Artificial Neural Network (ANN), which is trained using a backpropagation algorithm. Although this technique has been significantly developed, it still has a few disadvantages compared to others. One of the disadvantages of the ANN is that the result is not always optimum because of randomized initialization and epoch limit. In this paper, a Particle Swarm Optimization (PSO) is proposed to train the ANN. Some experiments on a dataset of 10 k activities with six imbalanced classes show that the PSO-based ANN produces effectiveness of 100% and an F1 score micro of 0.88, which are much higher than the back propagation-based ANN that gives the effectiveness of 75% and an F1 score micro of 0.87.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of Activity Recognition (AR) is to recognize human activity using a sensor to get the data needed. Then, a machine learning approach is used to determine the type of activity performed. A machine learning technique often used in the classification problem is Artificial Neural Network (ANN), which is trained using a backpropagation algorithm. Although this technique has been significantly developed, it still has a few disadvantages compared to others. One of the disadvantages of the ANN is that the result is not always optimum because of randomized initialization and epoch limit. In this paper, a Particle Swarm Optimization (PSO) is proposed to train the ANN. Some experiments on a dataset of 10 k activities with six imbalanced classes show that the PSO-based ANN produces effectiveness of 100% and an F1 score micro of 0.88, which are much higher than the back propagation-based ANN that gives the effectiveness of 75% and an F1 score micro of 0.87.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Leveraging Textural Features for Mammogram Classification"
        ],
        "penulis":"Akbarisena, Sri Frenzilino Mahayyu;Rachmawati, Ema;Utama, Dody Qori;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Cancer is the body' s tissue cells that continue to grow beyond normal and out of control so that cancer cells push normal cells and cause death in normal cells. One type of cancer is cancer that attacks breast tissue or is called breast cancer. The sooner breast cancer is detected, it will increase the chance the patient will survive. One of the techniques in the early detection of breast cancer is mammography screening. To minimize human error in checking the results of mammography, a CAD system is needed in checking the results of mammography. Therefore, in this research, a system that can classify breast tissue from mammogram into three classes, namely normal, benign, and malignant has been built. The performance of the system reaches F1-Score 74.02%, Recall 76.15% and Precision 74.02%. The system achieves this performance by combining the Uniform Local Binary Pattern and GLCM features and the Random Forest classification method.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is the body' s tissue cells that continue to grow beyond normal and out of control so that cancer cells push normal cells and cause death in normal cells. One type of cancer is cancer that attacks breast tissue or is called breast cancer. The sooner breast cancer is detected, it will increase the chance the patient will survive. One of the techniques in the early detection of breast cancer is mammography screening. To minimize human error in checking the results of mammography, a CAD system is needed in checking the results of mammography. Therefore, in this research, a system that can classify breast tissue from mammogram into three classes, namely normal, benign, and malignant has been built. The performance of the system reaches F1-Score 74.02%, Recall 76.15% and Precision 74.02%. The system achieves this performance by combining the Uniform Local Binary Pattern and GLCM features and the Random Forest classification method.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Character education based on digital comic media"
        ],
        "penulis":"Rina, Nofha;Suminar, Jenny Ratna;Damayani, Ninis Agustini;Hafiar, Hanny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Reading is one of the cultures in society that tends to be abandoned along with the rapid development of information technology as children nowadays tend to choose something practical as a medium for finding information. Therefore, to improve the latest learning methods through digital media, character-based literacy comics become the main choice in building positive educational values among elementary school students. This study aims to produce character-based comic media, determine the feasibility and effectiveness of character-based comic media on the development of character education for fourth grade elementary school students. This research used a development research consisting of some stages, namely: research and data collection, planning, product draft development, expert validation, expert-based revision, limited trials, improvement of the product of limited trial results, field trials, improvement of the final product, and product dissemination. The comparison test method in the field test uses Gain Analysis and Wilcoxon t-test. The subjects of this study were the fourth-grade students of the Quran Elementary School (SDQu) i.e. 26 students consisting of 6 students for limited trials and 20 students for field trials. The results of this study show that: (1) character-based comic media was produced in thematic-integrative learning, (2) the developed comic media were viewed in terms of the quality aspects of media aspects and material aspects from the experts, the teacher, and the results of students' responses were categorized very well, and (3) comic media developed effectively increased the value of student character in the learning process. \u00a9 2020.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Reading is one of the cultures in society that tends to be abandoned along with the rapid development of information technology as children nowadays tend to choose something practical as a medium for finding information. Therefore, to improve the latest learning methods through digital media, character-based literacy comics become the main choice in building positive educational values among elementary school students. This study aims to produce character-based comic media, determine the feasibility and effectiveness of character-based comic media on the development of character education for fourth grade elementary school students. This research used a development research consisting of some stages, namely: research and data collection, planning, product draft development, expert validation, expert-based revision, limited trials, improvement of the product of limited trial results, field trials, improvement of the final product, and product dissemination. The comparison test method in the field test uses Gain Analysis and Wilcoxon t-test. The subjects of this study were the fourth-grade students of the Quran Elementary School (SDQu) i.e. 26 students consisting of 6 students for limited trials and 20 students for field trials. The results of this study show that: (1) character-based comic media was produced in thematic-integrative learning, (2) the developed comic media were viewed in terms of the quality aspects of media aspects and material aspects from the experts, the teacher, and the results of students' responses were categorized very well, and (3) comic media developed effectively increased the value of student character in the learning process. \u00a9 2020."
        ]
    },
    {
        "judul":[
            "Prediction of Sea Level by Using Autoregressive Integrated Moving Average (ARIMA): Case Study in Tanjung Intan Harbour Cilacap, Indonesia"
        ],
        "penulis":"Purba, Yehezkiel K. A.;Saepudin, Deni;Adytia, Didit;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Sea Level forecasting is vital for shores engineering applications such as for engineering construction plan in the shore or in offshore, and routing of ships at harbor. Researchers have been conducting many methods to predict sea levels, such as Artificial Neural Network, SARIMA, and ARIMA. In this paper, we will use a model of Autoregressive Integrated Moving Average (ARIMA) to predict sea level in Cilacap, Indonesia. The ARIMA parameters are obtained by conducting parameter tuning so that the model gives the lowest root mean square error value (RMSE) and the highest correlation coefficient.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sea Level forecasting is vital for shores engineering applications such as for engineering construction plan in the shore or in offshore, and routing of ships at harbor. Researchers have been conducting many methods to predict sea levels, such as Artificial Neural Network, SARIMA, and ARIMA. In this paper, we will use a model of Autoregressive Integrated Moving Average (ARIMA) to predict sea level in Cilacap, Indonesia. The ARIMA parameters are obtained by conducting parameter tuning so that the model gives the lowest root mean square error value (RMSE) and the highest correlation coefficient.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Management of outdoor learning models for environmental education courses"
        ],
        "penulis":"Siswoyo, Andika Adinanda;Setyawan, Agung;Citrawati, Tyasmiarni;Bendriyanti, Rita Prima;Dewi, Citra;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study is to describe the management of outdoor learning models in environmental education courses. The method used is descriptive qualitative, in which the researcher analyzes the results of the interview management model of outdoor learning based on the needs of the course. This activity takes place from December 2019 to February 2020. The sample of this study was 5 lecturers (3 women and 2 men) in the age range of 32-40 years. The sample selection technique was carried out intentionally by evaluating the teaching experience of environmental education courses for a minimum of 4 years. The results of this study were obtained from the management of outdoor learning models in environmental education courses divided into 5 stages, namely analyzing curriculum structure, study the potential and needs of courses, planning, implementation, and evaluation. The conclusion from this study is that outdoor learning models have various positive impacts on their application. The outdoor learning model will be implemented well if it is accompanied by good management. 5 stages in the management of the outdoor learning model are connected. Hope can be applied to other subjects. A finding in this study is outdoor learning models still require face-to-face class, but more time for activities outside the classroom. Activities in the class are in the form of initial coordination, delivery of product designs, and delivery of results. The management of the outdoor learning model needs to be tried in other subjects. \u00a9 2020 Horizon Research Publishing. All rights reserved.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to describe the management of outdoor learning models in environmental education courses. The method used is descriptive qualitative, in which the researcher analyzes the results of the interview management model of outdoor learning based on the needs of the course. This activity takes place from December 2019 to February 2020. The sample of this study was 5 lecturers (3 women and 2 men) in the age range of 32-40 years. The sample selection technique was carried out intentionally by evaluating the teaching experience of environmental education courses for a minimum of 4 years. The results of this study were obtained from the management of outdoor learning models in environmental education courses divided into 5 stages, namely analyzing curriculum structure, study the potential and needs of courses, planning, implementation, and evaluation. The conclusion from this study is that outdoor learning models have various positive impacts on their application. The outdoor learning model will be implemented well if it is accompanied by good management. 5 stages in the management of the outdoor learning model are connected. Hope can be applied to other subjects. A finding in this study is outdoor learning models still require face-to-face class, but more time for activities outside the classroom. Activities in the class are in the form of initial coordination, delivery of product designs, and delivery of results. The management of the outdoor learning model needs to be tried in other subjects. \u00a9 2020 Horizon Research Publishing. All rights reserved."
        ]
    },
    {
        "judul":[
            "Analysis of Overall Effectiveness on Hall Separator Punching Machine at PT. DNIA"
        ],
        "penulis":"Sriwana, Iphov Kumala;Syauqillah, Nadya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT. DNIA is a company engaged in manufacture of automotive parts, one of which is condenser. Manufacture of condenser components requires small parts produced using a hole separator punching machine. However, it deals with high downtime of the machine, resulting in low production performance. This research aimed to identify the extent of hole separator punching machine performance using analysis of Overall Equipment Effectiveness (OEE) and to analyse six big loses which impact on machine downtime. Calculation results show that OEE value obtained, 48.54%, was still below the standard, and therefore continuous improvement attempt is essential to perform. The low OEE value was a result of low performance efficiency which was caused by idling and minor stoppages of 24.54%. In order to improve the performance and carry out idling and minor stoppages loss, it is important to perform improvement attempt in a number of aspects, such as man aspect by training operators to carry machine-related works, machine aspect by repairing abnormal ups and downs of dies, and material aspect by fixing inappropriate position of header tank (material). \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. DNIA is a company engaged in manufacture of automotive parts, one of which is condenser. Manufacture of condenser components requires small parts produced using a hole separator punching machine. However, it deals with high downtime of the machine, resulting in low production performance. This research aimed to identify the extent of hole separator punching machine performance using analysis of Overall Equipment Effectiveness (OEE) and to analyse six big loses which impact on machine downtime. Calculation results show that OEE value obtained, 48.54%, was still below the standard, and therefore continuous improvement attempt is essential to perform. The low OEE value was a result of low performance efficiency which was caused by idling and minor stoppages of 24.54%. In order to improve the performance and carry out idling and minor stoppages loss, it is important to perform improvement attempt in a number of aspects, such as man aspect by training operators to carry machine-related works, machine aspect by repairing abnormal ups and downs of dies, and material aspect by fixing inappropriate position of header tank (material). \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Personality prediction using indonesian twitter data with modified stacking method"
        ],
        "penulis":"Sopianti, Yuli;Kaburuan, Emil R.;Suryani, Arie Ardiyanti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Person's personality can be predicted from Twitter data by building a model using machine learning. In personality prediction areas the use of Stacking as learning algorithm has the best performance compared other learning algorithms. Stacking has a structure consisting of two-level learners making it possible to use several different classifiers to improve the performance of system. However, Stacking has weakness. It performs worse in multi-class dataset than two class datasets. Previous study has shown that adding level learners in the original Stacking structure can improve the performance of system in either multi-class or two class datasets. This study proposes a method called Modified Stacking, which adds one level learner in the original Stacking structure so that it becomes three level learners and adds grammatical features to improve the performance of Personality prediction system. The evaluation results using 10-Fold cross validation indicate that the system obtained average prediction accuracy of 99.62% for Modified Stacking and 99.24% for Stacking. It can be concluded that Modified Stacking has better performance in terms of accuracy than Stacking. In addition, the additions of level learners and grammatical features have an effect to improve accuracy. However, the execution time increased significantly over the addition of level learner in the Stacking structure. \u00a9 2020 SERSC.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Person's personality can be predicted from Twitter data by building a model using machine learning. In personality prediction areas the use of Stacking as learning algorithm has the best performance compared other learning algorithms. Stacking has a structure consisting of two-level learners making it possible to use several different classifiers to improve the performance of system. However, Stacking has weakness. It performs worse in multi-class dataset than two class datasets. Previous study has shown that adding level learners in the original Stacking structure can improve the performance of system in either multi-class or two class datasets. This study proposes a method called Modified Stacking, which adds one level learner in the original Stacking structure so that it becomes three level learners and adds grammatical features to improve the performance of Personality prediction system. The evaluation results using 10-Fold cross validation indicate that the system obtained average prediction accuracy of 99.62% for Modified Stacking and 99.24% for Stacking. It can be concluded that Modified Stacking has better performance in terms of accuracy than Stacking. In addition, the additions of level learners and grammatical features have an effect to improve accuracy. However, the execution time increased significantly over the addition of level learner in the Stacking structure. \u00a9 2020 SERSC."
        ]
    },
    {
        "judul":[
            "Speaker Recognition for Device Controlling using MFCC and GMM Algorithm"
        ],
        "penulis":"Malik, Ridwan Abdul;Setianingsih, Casi;Nasrun, Muhammad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Biometric technology is widely used to identify a smart home device controller with access control to the system. Sound Abstract is one of the biometric technologies used because human speech is different and unique. Generally, a smart home device controller based on sound can be controlled by everyone so that a speaker who should not have access rights to the system will still execute his voice command. The solution to this problem is a sound control system that can identify one speaker's voice with other speakers registered on the system to control smart home devices and reject commands from foreign speakers who are not registered on the system to secure a voice control system is formed. The Mel-Frequency Cepstrum Coefficient (MFCC) method, capable of capturing the characteristics of different human voices and is unique; the output of the MFCC is modeled and classified using GMM (Gaussian Mixture Model) on each cepstrum subject so that the modeling results can identify the voice of the speaker registered on the system listed or the voice of foreign speakers not registered with the system. The accuracy of the system built can identify the voice of the speaker registered on the system by 98.1% and reject the voice of the speaker who is not registered on the system by 91.6%. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Biometric technology is widely used to identify a smart home device controller with access control to the system. Sound Abstract is one of the biometric technologies used because human speech is different and unique. Generally, a smart home device controller based on sound can be controlled by everyone so that a speaker who should not have access rights to the system will still execute his voice command. The solution to this problem is a sound control system that can identify one speaker's voice with other speakers registered on the system to control smart home devices and reject commands from foreign speakers who are not registered on the system to secure a voice control system is formed. The Mel-Frequency Cepstrum Coefficient (MFCC) method, capable of capturing the characteristics of different human voices and is unique; the output of the MFCC is modeled and classified using GMM (Gaussian Mixture Model) on each cepstrum subject so that the modeling results can identify the voice of the speaker registered on the system listed or the voice of foreign speakers not registered with the system. The accuracy of the system built can identify the voice of the speaker registered on the system by 98.1% and reject the voice of the speaker who is not registered on the system by 91.6%. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Analysis of Modulation Performance of Underwater Visible Light Communication with Variable Wavelength"
        ],
        "penulis":"Ibrahimy, Arya Maulana;Fadilah, Budi Ikhwan;Pamukti, Brian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper evaluates the performance of Underwater Visible Light Communication (UVLC) with various modulation and wavelength. The first scenario will analyze the Signalto-Noise Ratio (SNR) of the UVLC with 450, 480, and 500 nm wavelength. The second scenario will compare the performance of Bit Error Rate (BER) with various modulation from Onoff Keying No-Return Zero (OOK-NRZ), On-Off Keying Return Zero (OOK-RZ), 8 Pulse Position Modulation (8-PPM), and 8 Pulse Amplitude Modulation (8-PAM). Same as the first scenario the comparison of BER use 450, 480, and 500 nm wavelength. From thesimulation of the first scenario, the used of 500 nm wavelength get the result 13.1147, which is the best result of SNR in this simulation. Meanwhile, in the second scenario, the combination of 8-PPM with 500 nm wavelength get the result 1.8922 $\\times 10^{-10}$, which is the best result and the value is smaller from Optical Wireless Communication (OWC) BER which is $10^{-9}$ \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper evaluates the performance of Underwater Visible Light Communication (UVLC) with various modulation and wavelength. The first scenario will analyze the Signalto-Noise Ratio (SNR) of the UVLC with 450, 480, and 500 nm wavelength. The second scenario will compare the performance of Bit Error Rate (BER) with various modulation from Onoff Keying No-Return Zero (OOK-NRZ), On-Off Keying Return Zero (OOK-RZ), 8 Pulse Position Modulation (8-PPM), and 8 Pulse Amplitude Modulation (8-PAM). Same as the first scenario the comparison of BER use 450, 480, and 500 nm wavelength. From thesimulation of the first scenario, the used of 500 nm wavelength get the result 13.1147, which is the best result of SNR in this simulation. Meanwhile, in the second scenario, the combination of 8-PPM with 500 nm wavelength get the result 1.8922 $\\times 10^{-10}$, which is the best result and the value is smaller from Optical Wireless Communication (OWC) BER which is $10^{-9}$ \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A Method for Microservices Handover in A Local Area Network"
        ],
        "penulis":"Afshari, Reza;Pusparini, Rimba Frida;Utomo, Muhammad Helmi;Dewanta, Favian;Negara, Ridha Muldina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The trend of internet of things (IoT) makes the cloud less effective because networked control systems need low latency while cloud have high latency for processing data from sensors and devices. In that kind of situation, fog computing is introduced as the complement of cloud computing. However, unlike cloud services, fog services are limited to certain geographical area. As a consequence, fog services handover is needed in order to accommodate user's mobility. This paper is focusing on microservices handover that follows user's movement. The microservices installed in the current fog node are sent to another service coverage of a new fog node for continuing the same service to the users. Fog node contains a docker that runs MySQL, python script, and busybox services. When it comes to handover, docker will freeze current session and convert it to a checkpoint file. The file is created by taking a snapshot of the container, which consists of processes in memory, volume or image. The file will be sent by using secure shell (SSH) or file transfer protocol (FTP). At the destination fog node, the file will be processed in order to resume the service. The results show that delay of SSH is always higher than FTP in all experiments, in which the largest delays are 484.026 seconds for SSH protocol and 146.41 seconds for FTP protocols. As for checkpoint and restore process, those delays tend to be similar with respect to both SSH and FTP protocols but they are still affected by the size of snapshot and checkpoint file.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The trend of internet of things (IoT) makes the cloud less effective because networked control systems need low latency while cloud have high latency for processing data from sensors and devices. In that kind of situation, fog computing is introduced as the complement of cloud computing. However, unlike cloud services, fog services are limited to certain geographical area. As a consequence, fog services handover is needed in order to accommodate user's mobility. This paper is focusing on microservices handover that follows user's movement. The microservices installed in the current fog node are sent to another service coverage of a new fog node for continuing the same service to the users. Fog node contains a docker that runs MySQL, python script, and busybox services. When it comes to handover, docker will freeze current session and convert it to a checkpoint file. The file is created by taking a snapshot of the container, which consists of processes in memory, volume or image. The file will be sent by using secure shell (SSH) or file transfer protocol (FTP). At the destination fog node, the file will be processed in order to resume the service. The results show that delay of SSH is always higher than FTP in all experiments, in which the largest delays are 484.026 seconds for SSH protocol and 146.41 seconds for FTP protocols. As for checkpoint and restore process, those delays tend to be similar with respect to both SSH and FTP protocols but they are still affected by the size of snapshot and checkpoint file.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Optimizing BTS Placement Using Hybrid Evolutionary Firefly Algorithm"
        ],
        "penulis":"Afuzagani, Dzakyta;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The internet has become one of the basic needs of today's society. Increasing internet users causes the addition of Base Transceiver Station (BTS) for each region. The construction of BTS certainly requires many costs if the placement is not optimum and leads to the futile placement of BTS. Therefore, it must be optimized for placement. In this research, a Hybrid Evolutionary Firefly Algorithm (HEFA) is implemented and compared to the original Firefly Algorithm (FA) in tackling this problem. Some computer simulations show that the HEFA gives an average fitness value up to 98.62%, which is slightly higher than the FA that produces 97.73%. It optimizes the BTS up to half of the initial generation.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The internet has become one of the basic needs of today's society. Increasing internet users causes the addition of Base Transceiver Station (BTS) for each region. The construction of BTS certainly requires many costs if the placement is not optimum and leads to the futile placement of BTS. Therefore, it must be optimized for placement. In this research, a Hybrid Evolutionary Firefly Algorithm (HEFA) is implemented and compared to the original Firefly Algorithm (FA) in tackling this problem. Some computer simulations show that the HEFA gives an average fitness value up to 98.62%, which is slightly higher than the FA that produces 97.73%. It optimizes the BTS up to half of the initial generation.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Character education based on digital comic media"
        ],
        "penulis":"Rina, Nofha;Suminar, Jenny Ratna;Damayani, Ninis Agustini;Hafiar, Hanny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Reading is one of the cultures in society that tends to be abandoned along with the rapid development of information technology as children nowadays tend to choose something practical as a medium for finding information. Therefore, to improve the latest learning methods through digital media, character-based literacy comics become the main choice in building positive educational values among elementary school students. This study aims to produce character-based comic media, determine the feasibility and effectiveness of character-based comic media on the development of character education for fourth grade elementary school students. This research used a development research consisting of some stages, namely: research and data collection, planning, product draft development, expert validation, expert-based revision, limited trials, improvement of the product of limited trial results, field trials, improvement of the final product, and product dissemination. The comparison test method in the field test uses Gain Analysis and Wilcoxon t-test. The subjects of this study were the fourth-grade students of the Quran Elementary School (SDQu) i.e. 26 students consisting of 6 students for limited trials and 20 students for field trials. The results of this study show that: (1) character-based comic media was produced in thematic-integrative learning, (2) the developed comic media were viewed in terms of the quality aspects of media aspects and material aspects from the experts, the teacher, and the results of students' responses were categorized very well, and (3) comic media developed effectively increased the value of student character in the learning process. \u00a9 2020.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Reading is one of the cultures in society that tends to be abandoned along with the rapid development of information technology as children nowadays tend to choose something practical as a medium for finding information. Therefore, to improve the latest learning methods through digital media, character-based literacy comics become the main choice in building positive educational values among elementary school students. This study aims to produce character-based comic media, determine the feasibility and effectiveness of character-based comic media on the development of character education for fourth grade elementary school students. This research used a development research consisting of some stages, namely: research and data collection, planning, product draft development, expert validation, expert-based revision, limited trials, improvement of the product of limited trial results, field trials, improvement of the final product, and product dissemination. The comparison test method in the field test uses Gain Analysis and Wilcoxon t-test. The subjects of this study were the fourth-grade students of the Quran Elementary School (SDQu) i.e. 26 students consisting of 6 students for limited trials and 20 students for field trials. The results of this study show that: (1) character-based comic media was produced in thematic-integrative learning, (2) the developed comic media were viewed in terms of the quality aspects of media aspects and material aspects from the experts, the teacher, and the results of students' responses were categorized very well, and (3) comic media developed effectively increased the value of student character in the learning process. \u00a9 2020."
        ]
    },
    {
        "judul":[
            "Competitive advantage improvement of publishing industry in Indonesia: A Case of PT. Gramedia digital nusantara"
        ],
        "penulis":"Diar, Alifiannisa Lawami;Tantra, Ruchi Intan;Setiadi, Farisya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The changes in the business environment influenced by the growth of the global information system and technology development does not exclude changes mandated in book retail and publishing industry business model. Research on business model innovation emerge since the 2000s, but the research that analyzes its relation to how value chain and strategy may utilize one firm's competitive advantage is rare. Hence, this research fulfills the knowledge gaps, uses PT. Gramedia Digital Nusantara as a case study to analyze its business model and value chain. This research adopted the Osterwalder business model canvas, Porter's value chain model, and Porter's Generic Strategy to categorize the firm's competitive advantage improvement. Data collection research was conducted by converges in-depth interviews, data analysis for quantitative support, and observation results to answer the lack of in the firm's document. Then, the data were processed by using conventional qualitative data analysis techniques, open and axial coding. From the research, it can be concluded that the firm's competitive advantage is concerned about the efficiency resulted from internal key partners' collaboration, the utilization of advanced technology in marketing and production activities. Also, strengthen the customer segments with the firm through customer relationships supported by technology operations and research and insights activities. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The changes in the business environment influenced by the growth of the global information system and technology development does not exclude changes mandated in book retail and publishing industry business model. Research on business model innovation emerge since the 2000s, but the research that analyzes its relation to how value chain and strategy may utilize one firm's competitive advantage is rare. Hence, this research fulfills the knowledge gaps, uses PT. Gramedia Digital Nusantara as a case study to analyze its business model and value chain. This research adopted the Osterwalder business model canvas, Porter's value chain model, and Porter's Generic Strategy to categorize the firm's competitive advantage improvement. Data collection research was conducted by converges in-depth interviews, data analysis for quantitative support, and observation results to answer the lack of in the firm's document. Then, the data were processed by using conventional qualitative data analysis techniques, open and axial coding. From the research, it can be concluded that the firm's competitive advantage is concerned about the efficiency resulted from internal key partners' collaboration, the utilization of advanced technology in marketing and production activities. Also, strengthen the customer segments with the firm through customer relationships supported by technology operations and research and insights activities. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Mobile application for identification of coffee fruit maturity using digital image processing"
        ],
        "penulis":"Sudana, Oka;Witarsyah, Deden;Putra, Adhitya;Raharja, Sunia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia is an agricultural country that relies on the agricultural sector and is well known in producing various plantation commodities, one of which is coffee. Coffee is a leading export commodity developed in Indonesia. Community coffee plantations play an important role because most of the coffee production comes from community plantations. However, the condition of community coffee plantations can be said to be still hampered, due to the quality of coffee is still relatively low. It is caused by coffee fruit sorting, which is still done conventionally. The conventional sorting process of coffee fruits is still carried out with the help of operator knowledge, so the level of operator knowledge dramatically influences the results of sorting. The ease of sorting coffee ripeness can be done by implementing a mobile application using digital image processing. Techniques used in digital image processing are the HSV color space to get color features of coffee fruit and the K-Nearest Neighbor (KNN) classification method to classify coffee fruit ripeness. The results of the identification are in the form of ripe, half-ripe, or unripe fruits. The mobile application of this research has two main features, namely training data feature and non real-time identification feature. The results of the testing conducted resulted in an accuracy rate of 95.56% with the best membership value (k) of 3. \u00a9 2020, Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is an agricultural country that relies on the agricultural sector and is well known in producing various plantation commodities, one of which is coffee. Coffee is a leading export commodity developed in Indonesia. Community coffee plantations play an important role because most of the coffee production comes from community plantations. However, the condition of community coffee plantations can be said to be still hampered, due to the quality of coffee is still relatively low. It is caused by coffee fruit sorting, which is still done conventionally. The conventional sorting process of coffee fruits is still carried out with the help of operator knowledge, so the level of operator knowledge dramatically influences the results of sorting. The ease of sorting coffee ripeness can be done by implementing a mobile application using digital image processing. Techniques used in digital image processing are the HSV color space to get color features of coffee fruit and the K-Nearest Neighbor (KNN) classification method to classify coffee fruit ripeness. The results of the identification are in the form of ripe, half-ripe, or unripe fruits. The mobile application of this research has two main features, namely training data feature and non real-time identification feature. The results of the testing conducted resulted in an accuracy rate of 95.56% with the best membership value (k) of 3. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[
            "Management of outdoor learning models for environmental education courses"
        ],
        "penulis":"Siswoyo, Andika Adinanda;Setyawan, Agung;Citrawati, Tyasmiarni;Bendriyanti, Rita Prima;Dewi, Citra;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study is to describe the management of outdoor learning models in environmental education courses. The method used is descriptive qualitative, in which the researcher analyzes the results of the interview management model of outdoor learning based on the needs of the course. This activity takes place from December 2019 to February 2020. The sample of this study was 5 lecturers (3 women and 2 men) in the age range of 32-40 years. The sample selection technique was carried out intentionally by evaluating the teaching experience of environmental education courses for a minimum of 4 years. The results of this study were obtained from the management of outdoor learning models in environmental education courses divided into 5 stages, namely analyzing curriculum structure, study the potential and needs of courses, planning, implementation, and evaluation. The conclusion from this study is that outdoor learning models have various positive impacts on their application. The outdoor learning model will be implemented well if it is accompanied by good management. 5 stages in the management of the outdoor learning model are connected. Hope can be applied to other subjects. A finding in this study is outdoor learning models still require face-to-face class, but more time for activities outside the classroom. Activities in the class are in the form of initial coordination, delivery of product designs, and delivery of results. The management of the outdoor learning model needs to be tried in other subjects. \u00a9 2020 Horizon Research Publishing. All rights reserved.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to describe the management of outdoor learning models in environmental education courses. The method used is descriptive qualitative, in which the researcher analyzes the results of the interview management model of outdoor learning based on the needs of the course. This activity takes place from December 2019 to February 2020. The sample of this study was 5 lecturers (3 women and 2 men) in the age range of 32-40 years. The sample selection technique was carried out intentionally by evaluating the teaching experience of environmental education courses for a minimum of 4 years. The results of this study were obtained from the management of outdoor learning models in environmental education courses divided into 5 stages, namely analyzing curriculum structure, study the potential and needs of courses, planning, implementation, and evaluation. The conclusion from this study is that outdoor learning models have various positive impacts on their application. The outdoor learning model will be implemented well if it is accompanied by good management. 5 stages in the management of the outdoor learning model are connected. Hope can be applied to other subjects. A finding in this study is outdoor learning models still require face-to-face class, but more time for activities outside the classroom. Activities in the class are in the form of initial coordination, delivery of product designs, and delivery of results. The management of the outdoor learning model needs to be tried in other subjects. \u00a9 2020 Horizon Research Publishing. All rights reserved."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Simulation of transport problem with clustering velocity-density function"
        ],
        "penulis":"Daniswara, Ferdian Akbar;Gunawan P.H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper discusses the use of K-Means clustering method in finding an estimate of the velocity-density function in the traffic flow model. Two clusters will be obtained using KMeans clustering process, which are jammed and light cluster. These two clusters will have different velocity-density functions based on clustering result. Here, velocity-density function is obtained from linear regression of each data cluster. For measuring the velocity-density function, then this paper will provide the value of RMSE and R-Squared. The results show that RMSE is 2.3396 and R-squared is 0.3591 when no cluster is implemented in numerical simulation. Meanwhile, for the light cluster, the RMSE is found 1.1795 and R-squared 0.1388. Moreover, for the jammed cluster, RMSE is 0.8723 and R-squared is 0.1357. Finally, the process of identifying traffic conditions in the numerical simulation is done by computing Euclidean distance from centroid of clusters.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper discusses the use of K-Means clustering method in finding an estimate of the velocity-density function in the traffic flow model. Two clusters will be obtained using KMeans clustering process, which are jammed and light cluster. These two clusters will have different velocity-density functions based on clustering result. Here, velocity-density function is obtained from linear regression of each data cluster. For measuring the velocity-density function, then this paper will provide the value of RMSE and R-Squared. The results show that RMSE is 2.3396 and R-squared is 0.3591 when no cluster is implemented in numerical simulation. Meanwhile, for the light cluster, the RMSE is found 1.1795 and R-squared 0.1388. Moreover, for the jammed cluster, RMSE is 0.8723 and R-squared is 0.1357. Finally, the process of identifying traffic conditions in the numerical simulation is done by computing Euclidean distance from centroid of clusters.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Fast and Accurate Fish Classification from Underwater Video using You only Look Once"
        ],
        "penulis":"Lathifah, Hasna Maudi;Novamizanti, Ledya;Rizal, Syamsul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia is a maritime country and one of the largest archipelago countries in the world. Indonesian fisheries have many types of fish in stock, this causes difficulties in introducing fish species directly. This study designed a fish species classification system using the You Only Look Once (YOLO) architecture. YOLO is an object detection method using a convolutional network that will only be just once. Unlike the convolutional networks in general that spend thousands of networks to obtain an image with computing that is long enough. The architecture of this work using YOLO9000. The dataset consists of 6 classes, that is banded butterflyfish, blue tang surgeonfish, barred hamlet, black side hawkfish, Arabian Picasso triggerfish, dan black margate grunt. System testing produces an accuracy of 92%, IoS 0.75, and 2.223 FPS using Adam optimizer. The proposed system model has good accuracy and fast detection time.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is a maritime country and one of the largest archipelago countries in the world. Indonesian fisheries have many types of fish in stock, this causes difficulties in introducing fish species directly. This study designed a fish species classification system using the You Only Look Once (YOLO) architecture. YOLO is an object detection method using a convolutional network that will only be just once. Unlike the convolutional networks in general that spend thousands of networks to obtain an image with computing that is long enough. The architecture of this work using YOLO9000. The dataset consists of 6 classes, that is banded butterflyfish, blue tang surgeonfish, barred hamlet, black side hawkfish, Arabian Picasso triggerfish, dan black margate grunt. System testing produces an accuracy of 92%, IoS 0.75, and 2.223 FPS using Adam optimizer. The proposed system model has good accuracy and fast detection time.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "End-to-End Speech Recognition Models for a Low-Resourced Indonesian Language"
        ],
        "penulis":"Suyanto, Suyanto;Arifianto, Anditya;Sirwan, Anis;Rizaendra, Angga P.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Recent automatic speech recognition (ASR) is commonly developed using deep learning (DL), instead of the Hidden Markov Model (HMM). Many researchers show that DL is much better than HMM in noisy environments. However, DL needs a huge speech corpus but does not require any dictionary as well as the concept of either phonemes or syllables. Many DL-based tools are developed and claimed as a language-independent ASR, such as Mozma DeepSpeech (MDS) and Kaituoxu SpeechTransformer (KST). Both MDS and KST are classified as End-to-End ASR (E2EASR), but MDS uses a Recurrent Neural Network (RNN) while KST exploits a Transformer Network. In this paper, two Indonesian ASR (INASR) are developed using both MDS and KST to see their performances to handle a low-resourced language. Evaluation using a small speech corpus of Bahasa Indonesia containing 40 k utterances shows that KST is slightly better than MDS, where it gives a word error rate (WER) of 22.00% while MDS produces a WER of 23.10%.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recent automatic speech recognition (ASR) is commonly developed using deep learning (DL), instead of the Hidden Markov Model (HMM). Many researchers show that DL is much better than HMM in noisy environments. However, DL needs a huge speech corpus but does not require any dictionary as well as the concept of either phonemes or syllables. Many DL-based tools are developed and claimed as a language-independent ASR, such as Mozma DeepSpeech (MDS) and Kaituoxu SpeechTransformer (KST). Both MDS and KST are classified as End-to-End ASR (E2EASR), but MDS uses a Recurrent Neural Network (RNN) while KST exploits a Transformer Network. In this paper, two Indonesian ASR (INASR) are developed using both MDS and KST to see their performances to handle a low-resourced language. Evaluation using a small speech corpus of Bahasa Indonesia containing 40 k utterances shows that KST is slightly better than MDS, where it gives a word error rate (WER) of 22.00% while MDS produces a WER of 23.10%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Attribute-aware loss function for accurate semantic segmentation considering the pedestrian orientations"
        ],
        "penulis":"Sulistiyo, Mahmud Dwi;Kawanishi, Yasutomo;Deguchi, Daisuke;Ide, Ichiro;Hirayama, Takatsugu;Zheng, Jiang-Yu;Murase, Hiroshi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Numerous applications such as autonomous driving, satellite imagery sensing, and biomedical imaging use computer vision as an important tool for perception tasks. For Intelligent Transportation Systems (ITS), it is required to precisely recognize and locate scenes in sensor data. Semantic segmentation is one of computer vision methods intended to perform such tasks. However, the existing semantic segmentation tasks label each pixel with a single object\u2019s class. Recognizing object attributes, e.g., pedestrian orientation, will be more informative and help for a better scene understanding. Thus, we propose a method to perform semantic segmentation with pedestrian attribute recognition simultaneously. We introduce an attribute-aware loss function that can be applied to an arbitrary base model. Furthermore, a re-annotation to the existing Cityscapes dataset enriches the ground-truth labels by annotating the attributes of pedestrian orientation. We implement the proposed method and compare the experimental results with others. The attribute-aware semantic segmentation shows the ability to outperform baseline methods both in the traditional object segmentation task and the expanded attribute detection task. Copyright \u00a9 2020 The Institute of Electronics, Information and Communication Engineers",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Numerous applications such as autonomous driving, satellite imagery sensing, and biomedical imaging use computer vision as an important tool for perception tasks. For Intelligent Transportation Systems (ITS), it is required to precisely recognize and locate scenes in sensor data. Semantic segmentation is one of computer vision methods intended to perform such tasks. However, the existing semantic segmentation tasks label each pixel with a single object\u2019s class. Recognizing object attributes, e.g., pedestrian orientation, will be more informative and help for a better scene understanding. Thus, we propose a method to perform semantic segmentation with pedestrian attribute recognition simultaneously. We introduce an attribute-aware loss function that can be applied to an arbitrary base model. Furthermore, a re-annotation to the existing Cityscapes dataset enriches the ground-truth labels by annotating the attributes of pedestrian orientation. We implement the proposed method and compare the experimental results with others. The attribute-aware semantic segmentation shows the ability to outperform baseline methods both in the traditional object segmentation task and the expanded attribute detection task. Copyright \u00a9 2020 The Institute of Electronics, Information and Communication Engineers"
        ]
    },
    {
        "judul":[
            "Applied Internet of Things (IoT): The Prototype Bus Passenger Monitoring System Using PIR Sensor"
        ],
        "penulis":"Rahmatulloh, Alam;Nursuwars, Firmansyah M S;Darmawan, Irfan;Febrizki, Galih;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Monitoring passenger data in bus transportation fleets using the IoT concept. Factors that influence passenger monitoring are human counting errors and the accuracy of objects detected by sensors. The IoT system uses PIR (passive infrared) sensors and monitoring with mobile apps is a solution to overcome this, because the use of PIR sensors in the IoT system can only detect movements made by humans alone. The developed IoT system also implements a GPS module to be able to find out the location of the bus. Wemos D1 R2 will automatically send data collected from the results of detection by the PIR sensor and coordinates obtained by the GPS module to the Firebase database via the internet network. The monitoring application will display data stored on firebase on a mobile device. So that monitoring of bus passengers can be done quickly. Experiments on the research show that when the object's motion approaches the PIR sensor, it will not consistently detect the presence of passengers.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Monitoring passenger data in bus transportation fleets using the IoT concept. Factors that influence passenger monitoring are human counting errors and the accuracy of objects detected by sensors. The IoT system uses PIR (passive infrared) sensors and monitoring with mobile apps is a solution to overcome this, because the use of PIR sensors in the IoT system can only detect movements made by humans alone. The developed IoT system also implements a GPS module to be able to find out the location of the bus. Wemos D1 R2 will automatically send data collected from the results of detection by the PIR sensor and coordinates obtained by the GPS module to the Firebase database via the internet network. The monitoring application will display data stored on firebase on a mobile device. So that monitoring of bus passengers can be done quickly. Experiments on the research show that when the object's motion approaches the PIR sensor, it will not consistently detect the presence of passengers.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Caustic Analysis of Reflected Rays from a Spherical Reflector Antenna"
        ],
        "penulis":"Quzwain, Kamelia;Arjunaidi, Ayuni Afiqah;Yamada, Yoshihide;Kamardin, Kamilia;Rahman, Nurul Huda Abd;Ismail, Alyani;Dinh, Nguyen Quoc;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Now, 5G mobile system is developing to increase user capacity and reduce connection latency. At radio wave technology, new challenges such as millimeter wave (28GHz), small cell size and multi beam base station are introduced. At millimeter wave, where antenna size becomes small size of almost 30cm, a reflector antenna becomes promising. In order to use a reflector antenna for multi beam application, a spherical reflector is suitable. However, a spherical reflector has a problem of distributed caustics. In designing antenna, to clarify caustic positions is important. In this paper, the caustic position equation is derived. Accuracy of the equation is ensured by comparing with MATLAB simulation results. Finally, useful data for dual spherical reflector designing is obtained. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Now, 5G mobile system is developing to increase user capacity and reduce connection latency. At radio wave technology, new challenges such as millimeter wave (28GHz), small cell size and multi beam base station are introduced. At millimeter wave, where antenna size becomes small size of almost 30cm, a reflector antenna becomes promising. In order to use a reflector antenna for multi beam application, a spherical reflector is suitable. However, a spherical reflector has a problem of distributed caustics. In designing antenna, to clarify caustic positions is important. In this paper, the caustic position equation is derived. Accuracy of the equation is ensured by comparing with MATLAB simulation results. Finally, useful data for dual spherical reflector designing is obtained. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Proposed assembly line balancing using mixed integer programming to minimize idle time of union fuselage"
        ],
        "penulis":"Dewi, Ni Putu Cynthia Sasmita;Damayanti, Dida Diah;Astuti, Murni Dwi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study is aimed to help the company doing an assembly line balancing to minimize station time as not to exceed takt time and minimize idle time between workstation, using Mixed Integer Programming (MIP) method with Multi-manned Assembly Line Balancing (MmALBP) approach using two mathematical model, which 1stmodel aimed to minimize the cycle time of all workstation, then those cycle time being a parameter in 2ndMathematical model to specified the optimal number of workers also balancing workload between operators. Result from this research were able to minimize station time from 218.56 hour to 166.3 hour so it didn't exceed the takt time and also could reduce total idle time until 45% from 905.2 hour in actual condition become 499.49 hour with decreased number of operator from 52 to 22 person, and increase the efficiency of assembly line from 54% in previous to 67% in the proposed line. \u00a9 2020 IOP Conference Series: Materials Science and Engineering.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study is aimed to help the company doing an assembly line balancing to minimize station time as not to exceed takt time and minimize idle time between workstation, using Mixed Integer Programming (MIP) method with Multi-manned Assembly Line Balancing (MmALBP) approach using two mathematical model, which 1stmodel aimed to minimize the cycle time of all workstation, then those cycle time being a parameter in 2ndMathematical model to specified the optimal number of workers also balancing workload between operators. Result from this research were able to minimize station time from 218.56 hour to 166.3 hour so it didn't exceed the takt time and also could reduce total idle time until 45% from 905.2 hour in actual condition become 499.49 hour with decreased number of operator from 52 to 22 person, and increase the efficiency of assembly line from 54% in previous to 67% in the proposed line. \u00a9 2020 IOP Conference Series: Materials Science and Engineering."
        ]
    },
    {
        "judul":[
            "Business Design and Risk Analysis of Sonja Coffee Shop with the Concept of Coworking Space"
        ],
        "penulis":"Rahmawati F.;Chumaidiyah E.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Sonja Coffee Shop is a business development with the innovative concept of coworking space in Depok City. In this paper, the market aspect is derived from the spread of questionnaires to 100 respondents in Depok City with the age range of 15-34 years. Gained a potential market of 96%, the market is available at 97% and a target market of 0.18% of the market is available. Analysis of technical and operational design is done to know the production and income that occurred in the business for 5 years to come. The calculation of financial aspects acquired by NPV amounted to IDR 192.905.472, IRR value of 21% and PBP for 4.5 years. The value of IRR > MARR is 12% and NPV > 0, so this business is feasible to run. There is sensitivity to the increase in direct raw material costs by 14%, an increase in direct labour costs by 12%, a decrease in demand by 16% and a decrease in sales prices by 3%. There are business risks, market risks due to more and more emerging competitors, operational risks due to damage to machinery and facilities and financial risk due to inflation which is calculated at 7.03%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sonja Coffee Shop is a business development with the innovative concept of coworking space in Depok City. In this paper, the market aspect is derived from the spread of questionnaires to 100 respondents in Depok City with the age range of 15-34 years. Gained a potential market of 96%, the market is available at 97% and a target market of 0.18% of the market is available. Analysis of technical and operational design is done to know the production and income that occurred in the business for 5 years to come. The calculation of financial aspects acquired by NPV amounted to IDR 192.905.472, IRR value of 21% and PBP for 4.5 years. The value of IRR > MARR is 12% and NPV > 0, so this business is feasible to run. There is sensitivity to the increase in direct raw material costs by 14%, an increase in direct labour costs by 12%, a decrease in demand by 16% and a decrease in sales prices by 3%. There are business risks, market risks due to more and more emerging competitors, operational risks due to damage to machinery and facilities and financial risk due to inflation which is calculated at 7.03%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Implementation of Convolutional Neural Network (CNN) Algorithm for Classification of Human Facial Expression in Indonesia"
        ],
        "penulis":"Jala, Aqil Bayu;Purboyo, Tito Waluyo;Nugrahaeni, Ratna Astuti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Emotional expression is an effort made by someone to communicate the status of feelings or emotions in response to certain situations both internal and external as seen from biological changes, physiological and a series of actions like attitudes and behaviors oriented toward goal-oriented. Although humans can recognize expressions very well, facial recognition research is continuing to improve the quality of expression recognition in human and computer interactions. In this study discusses the detection of human facial expressions using the Convolution Neural Network (CNN) method with the Indonesian Mixed Emotion Dataset (IMED), in this algorithm there are two methods in a series namely convolution as feature extraction and neural network as classification. To facilitate the extraction of features, the researcher does preprocessing. The preprocessing stage is face detection, cropping, resizing and grayscaling. To overcome overfitting, in this study, data augmentation was performed on training data and also test data. The results of experiments in this study that the Convolution Neural Network (CNN) algorithm can recognize human facial expressions with an accuracy rate of 93.63% of the 110 expressions tested.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Emotional expression is an effort made by someone to communicate the status of feelings or emotions in response to certain situations both internal and external as seen from biological changes, physiological and a series of actions like attitudes and behaviors oriented toward goal-oriented. Although humans can recognize expressions very well, facial recognition research is continuing to improve the quality of expression recognition in human and computer interactions. In this study discusses the detection of human facial expressions using the Convolution Neural Network (CNN) method with the Indonesian Mixed Emotion Dataset (IMED), in this algorithm there are two methods in a series namely convolution as feature extraction and neural network as classification. To facilitate the extraction of features, the researcher does preprocessing. The preprocessing stage is face detection, cropping, resizing and grayscaling. To overcome overfitting, in this study, data augmentation was performed on training data and also test data. The results of experiments in this study that the Convolution Neural Network (CNN) algorithm can recognize human facial expressions with an accuracy rate of 93.63% of the 110 expressions tested.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Ability to Adapt jBatik Software Technology for Traditional Batik Craftsmen"
        ],
        "penulis":"Ciptandi, Fajar;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study is to find out the adaptability of traditional batik craftsmen in using jBatik software technology to create motif development. The traditional batik industry in Tuban, East Java was choosen as an example of case because it is considered to represent other traditional batik industries in Java. In previous studies, the use of jBatik software has been tested and resulted in the development of several designs of traditional Tuban batik motifs. This study was conducted to analyze the factors driving as well as inhibiting traditional batik craftsmen in adapting jBatik software technology through an experimental approach by referring to the diffusion of innovation theory. This is useful as one of the solutions today as an effort to measure the readiness level of traditional batik craftsmen to adapt technology, as well as being a way of self-evaluation for the technology to adapt to the needs of traditional batik craftsmen in Indonesia.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to find out the adaptability of traditional batik craftsmen in using jBatik software technology to create motif development. The traditional batik industry in Tuban, East Java was choosen as an example of case because it is considered to represent other traditional batik industries in Java. In previous studies, the use of jBatik software has been tested and resulted in the development of several designs of traditional Tuban batik motifs. This study was conducted to analyze the factors driving as well as inhibiting traditional batik craftsmen in adapting jBatik software technology through an experimental approach by referring to the diffusion of innovation theory. This is useful as one of the solutions today as an effort to measure the readiness level of traditional batik craftsmen to adapt technology, as well as being a way of self-evaluation for the technology to adapt to the needs of traditional batik craftsmen in Indonesia.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A technical and economic analysis of solar PV with local tariff policy in Indonesia"
        ],
        "penulis":"Adam K.B.;Ramdhani M.;Suhartono E.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia is still struggling to attract investors in developing the solar photovoltaic (PV) project. The government issued the first regulation on solar PV, announced in 2016. A revision on the local tariff regulation is conducted to reduce the rapid development of the solar PV investment. The major revision is made to change the contract scheme from a build-operate-own (BOO) to a build-operate-own-transfer (BOOT) scheme. This paper investigates how the new local tariff will drive investors and developers to invest in solar PV. This analysis is conducted to know the effectiveness of the policy and the risk of PV investment in Indonesia. Local tariff policy regulation targets PV developers to invest in the solar PV system areas. In the local tariff policy, each area has its PV energy tariff determined by the government. This research proposes a method for deciding demand by considering population data in selected regions to calculate the maximum PV demand of each area. The Levelized Cost of Energy LCOE is used to calculate the economic viability of the PV projects in selected areas in Indonesia. The results show that more than half of the selected areas are profitable for the PV project. The average profit of the projects of the selected areas is 3.21 cent USD per kWh. Most of the areas that have high PV demand have lower local tariffs. Therefore, these areas may not be profitable for developers. The new regulation also cuts the revenue significantly due to the new scheme contract. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is still struggling to attract investors in developing the solar photovoltaic (PV) project. The government issued the first regulation on solar PV, announced in 2016. A revision on the local tariff regulation is conducted to reduce the rapid development of the solar PV investment. The major revision is made to change the contract scheme from a build-operate-own (BOO) to a build-operate-own-transfer (BOOT) scheme. This paper investigates how the new local tariff will drive investors and developers to invest in solar PV. This analysis is conducted to know the effectiveness of the policy and the risk of PV investment in Indonesia. Local tariff policy regulation targets PV developers to invest in the solar PV system areas. In the local tariff policy, each area has its PV energy tariff determined by the government. This research proposes a method for deciding demand by considering population data in selected regions to calculate the maximum PV demand of each area. The Levelized Cost of Energy LCOE is used to calculate the economic viability of the PV projects in selected areas in Indonesia. The results show that more than half of the selected areas are profitable for the PV project. The average profit of the projects of the selected areas is 3.21 cent USD per kWh. Most of the areas that have high PV demand have lower local tariffs. Therefore, these areas may not be profitable for developers. The new regulation also cuts the revenue significantly due to the new scheme contract. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Wheeled Robot Control with Hand Gesture based on Image Processing"
        ],
        "penulis":"Waskito, Theodore Bismo;Sumaryo, Sony;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Computer vision based on shape recognition has a lot of potential in human and computer interaction. Hand gestures can be used as symbols of human interaction with computers which are preferred in the use of various hand gestures in sign language. Various tasks can be used to set remote control functions, control robots, and so on. The process of processing images or hand drawings using computer vision is called image processing. In this paper, a wheeled robot control system can be moved according to the given hand gesture commands. There are 6 forms of hand gestures that are made as input, and each hand gesture gives one command for the movement of a wheeled robot. The method used to classify each hand gesture, namely Convolutional Neural Network (CNN). CNN is a branch of the Artificial Neural Network (ANN) that can perform extraction features and create desired categories. The results of the classification will be carried out and sent to a wireless robot to run a movement. The result of this system is the movement of the wheeled robot following the given hand gestures. Variables that affect this system are training parameters and environmental parameters which include the amount of light intensity, distance, and tilt angle. The accuracy of the entire system obtained is 91.33%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Computer vision based on shape recognition has a lot of potential in human and computer interaction. Hand gestures can be used as symbols of human interaction with computers which are preferred in the use of various hand gestures in sign language. Various tasks can be used to set remote control functions, control robots, and so on. The process of processing images or hand drawings using computer vision is called image processing. In this paper, a wheeled robot control system can be moved according to the given hand gesture commands. There are 6 forms of hand gestures that are made as input, and each hand gesture gives one command for the movement of a wheeled robot. The method used to classify each hand gesture, namely Convolutional Neural Network (CNN). CNN is a branch of the Artificial Neural Network (ANN) that can perform extraction features and create desired categories. The results of the classification will be carried out and sent to a wireless robot to run a movement. The result of this system is the movement of the wheeled robot following the given hand gestures. Variables that affect this system are training parameters and environmental parameters which include the amount of light intensity, distance, and tilt angle. The accuracy of the entire system obtained is 91.33%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Culturable gut bacteria of ikan batak (Neolissochilus sumatranus weber & de beaufort, 1916) collected in toba samosir, indonesia"
        ],
        "penulis":"Dinoto, Achmad;Handayani, Rini;Setianingrum, Ninu;Julistiono, Heddy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Ikan Batak (Neolissochilus sumatranus Weber & de Beaufort, 1916) is one of the fish species that is rarely found in water and have the status of endangered species. In consequence, the loss of endemic fish may contribute to the loss of microorganisms that inhabits the fish as a host. The studies on microorganisms associated with N. sumatranus are very limited. Therefore, the purpose of this study was to isolate and identify the culturable bacteria isolated from the gut of N. sumatranus. Sampling of N. sumatranus was carried out in a river within Toba Samosir area which flows to Lake Toba. Fish gut content was collected for isolating microorganisms using three media, including MRS, 10X diluted MRS, and MRS supplemented with 1% bile salt. Thirteen isolates were successfully isolated and identified based on 16S rRNA. This study revealed various species of gut bacteria recovered from N. sumatranus based on BLAST analysis. The isolates showed closest relationship to species Bacillus subtilis (3 isolates), Bacillus tequilensis (2 isolates), Tumebacillus ginsengisoli (6 isolates), Klebsiella pneumoniae (1 isolate), and Lactobacillus pentosus (1 isolate) with the similarity ranging at 98.7 to 100%. All 16S rRNA gene nucleotides of isolates have been submitted to GenBank. This study also described the isolates that have a very close relationship with Bacillus tequilla and Bacillus subtilis. Further identification is challenged to obtain a big picture of the diversity of microorganisms and the functionality in the digestive ecosystem of N. sumatranus for their conservation and bioprospecting of microbial-based aquaculture. \u00a9 2020, Society for Indonesian Biodiversity. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Clean water and sanitationGoal 6Life below waterGoal 14Life on landGoal 15",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ikan Batak (Neolissochilus sumatranus Weber & de Beaufort, 1916) is one of the fish species that is rarely found in water and have the status of endangered species. In consequence, the loss of endemic fish may contribute to the loss of microorganisms that inhabits the fish as a host. The studies on microorganisms associated with N. sumatranus are very limited. Therefore, the purpose of this study was to isolate and identify the culturable bacteria isolated from the gut of N. sumatranus. Sampling of N. sumatranus was carried out in a river within Toba Samosir area which flows to Lake Toba. Fish gut content was collected for isolating microorganisms using three media, including MRS, 10X diluted MRS, and MRS supplemented with 1% bile salt. Thirteen isolates were successfully isolated and identified based on 16S rRNA. This study revealed various species of gut bacteria recovered from N. sumatranus based on BLAST analysis. The isolates showed closest relationship to species Bacillus subtilis (3 isolates), Bacillus tequilensis (2 isolates), Tumebacillus ginsengisoli (6 isolates), Klebsiella pneumoniae (1 isolate), and Lactobacillus pentosus (1 isolate) with the similarity ranging at 98.7 to 100%. All 16S rRNA gene nucleotides of isolates have been submitted to GenBank. This study also described the isolates that have a very close relationship with Bacillus tequilla and Bacillus subtilis. Further identification is challenged to obtain a big picture of the diversity of microorganisms and the functionality in the digestive ecosystem of N. sumatranus for their conservation and bioprospecting of microbial-based aquaculture. \u00a9 2020, Society for Indonesian Biodiversity. All rights reserved."
        ]
    },
    {
        "judul":[
            "Variable range hopping resistivity in la2-xsrxcuo4nanoparticles evaluated by four point probe method"
        ],
        "penulis":"Winarsih, Suci;Budiman, Faisal;Tanaka, Hirofumi;Adachi, Tadashi;Goto, Takayuki;Soegijono, Bambang;Kurniawan, Budhy;Watanabe, Isao;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We report the results of the resistivity measurement on La2-xSrxCuO4 nanoparticles with x = 0, 0.05, and 0.20 evaluated by the four-point probe method. The high resistivity value shows the predominance of the inter-grain part. The temperature dependence of the conductivity can be analyzed by variable range hopping model showing the charge carriers are formed by thermal activation. There is no superconducting behavior that could be observed in La2-xSrxCuO4 nanoparticles with x = 0.05 and 0.20. \u00a9 2020 Trans Tech Publications Ltd, Switzerland.",
            "InView detailsExpand Substance indium",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We report the results of the resistivity measurement on La2-xSrxCuO4 nanoparticles with x = 0, 0.05, and 0.20 evaluated by the four-point probe method. The high resistivity value shows the predominance of the inter-grain part. The temperature dependence of the conductivity can be analyzed by variable range hopping model showing the charge carriers are formed by thermal activation. There is no superconducting behavior that could be observed in La2-xSrxCuO4 nanoparticles with x = 0.05 and 0.20. \u00a9 2020 Trans Tech Publications Ltd, Switzerland."
        ]
    },
    {
        "judul":[
            "Information security awareness (ISA) towards the intention to comply and demographic factors: Statistical correspondence analysis"
        ],
        "penulis":"Lubis, Muharman;Fauzi, Rokhman;Liandani, Pipit;Lubis, Arif Ridho;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Evidence from the literature and observation conducted from various practice in managing project or developing product within the organization suggested that human factors in term of control and direction can be the greatest threats to the organization to ensure the high quality of information security. Therefore, fewer research was conducted towards assessing the level of end-user awareness in a practical way to extract the relationship of demographic factor with user compliance in order to understand the working mechanism. Thus, this study prepares a literature review with the PRISMA model to implement a systematic process in an integrated manner in order to reveal representative information on the subject. Subsequently, a correspondence analysis (CA) was conducted to discover the hidden meaning of the relevant demographic factors that might affect the intention to comply with the organization's policy to protect confidential, sensitive and confidential information. One interesting result stated that ethnicity provides a stronger association by providing a total variation of 0.121, singular value of 0.248, chi-square of 26.208 and standard deviation of 0.063. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Evidence from the literature and observation conducted from various practice in managing project or developing product within the organization suggested that human factors in term of control and direction can be the greatest threats to the organization to ensure the high quality of information security. Therefore, fewer research was conducted towards assessing the level of end-user awareness in a practical way to extract the relationship of demographic factor with user compliance in order to understand the working mechanism. Thus, this study prepares a literature review with the PRISMA model to implement a systematic process in an integrated manner in order to reveal representative information on the subject. Subsequently, a correspondence analysis (CA) was conducted to discover the hidden meaning of the relevant demographic factors that might affect the intention to comply with the organization's policy to protect confidential, sensitive and confidential information. One interesting result stated that ethnicity provides a stronger association by providing a total variation of 0.121, singular value of 0.248, chi-square of 26.208 and standard deviation of 0.063. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Univariate Time Series Data Forecasting of Air Pollution using LSTM Neural Network"
        ],
        "penulis":"Hamami, Faqih;Dahlan, Iqbal Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Air pollution is an important issue around the world. It can threaten the human life environment and affect illness or even death. Internet of Things (IoT) is a technology that can monitor air quality. It can transmit data in real time and with good latency. Some pollutants in the air can be dangerous at high concentrations. The prediction of time series data from pollutants transmitted by IoT is one step for preventing unwanted conditions in future such as unhealthy environments or becoming uninhabitable due to dangerous air pollution. This paper proposes to build a neural network model using LSTM to forecast air pollution concentrations in the air. The model predicts five air pollution indicators including PM10, SO2, CO, O3, and NO2. The results reveal that the Root Mean Square Error of LSTM model is 5.58. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Air pollution is an important issue around the world. It can threaten the human life environment and affect illness or even death. Internet of Things (IoT) is a technology that can monitor air quality. It can transmit data in real time and with good latency. Some pollutants in the air can be dangerous at high concentrations. The prediction of time series data from pollutants transmitted by IoT is one step for preventing unwanted conditions in future such as unhealthy environments or becoming uninhabitable due to dangerous air pollution. This paper proposes to build a neural network model using LSTM to forecast air pollution concentrations in the air. The model predicts five air pollution indicators including PM10, SO2, CO, O3, and NO2. The results reveal that the Root Mean Square Error of LSTM model is 5.58. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Combination of extraction features based on texture and colour feature for beef and pork classification"
        ],
        "penulis":"Priyatno A.M.;Putra F.M.;Cholidhazia P.;Ningsih L.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Behaviour of traders mixing beef and pork is very detrimental to consumers, especially followers of Islam because it is related to legal or forbidden food. So, consumers must be protected from these rogue traders. However, differentiating beef and pork is not easy for ordinary people, especially if you only see from one information that is the colour or texture. In this paper, we proposed a new combination of extraction features based on texture and colour features for the classification of beef and pork. The feature of the texture is to see the local information optimally by using a local optimal-oriented pattern (LOOP) so that it can provide better texture information. The colour features that will be used are hue, saturation, and value (HSV). Texture and colour features are combined into one, so that more enrich the information used. The combination of optimal local-oriented pattern features and hue saturation value gives increased accuracy for the classification of pork and beef. The results of tests that have been done show that the success rate of calcification by using a combination of features has increased. accuracy obtained is equal to 99.16 percent, recall 100 percent and precision 98.36 percent. this shows that by utilizing the colour features and texture features can provide improved classification due to increased information that can be used to do the classification. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Behaviour of traders mixing beef and pork is very detrimental to consumers, especially followers of Islam because it is related to legal or forbidden food. So, consumers must be protected from these rogue traders. However, differentiating beef and pork is not easy for ordinary people, especially if you only see from one information that is the colour or texture. In this paper, we proposed a new combination of extraction features based on texture and colour features for the classification of beef and pork. The feature of the texture is to see the local information optimally by using a local optimal-oriented pattern (LOOP) so that it can provide better texture information. The colour features that will be used are hue, saturation, and value (HSV). Texture and colour features are combined into one, so that more enrich the information used. The combination of optimal local-oriented pattern features and hue saturation value gives increased accuracy for the classification of pork and beef. The results of tests that have been done show that the success rate of calcification by using a combination of features has increased. accuracy obtained is equal to 99.16 percent, recall 100 percent and precision 98.36 percent. this shows that by utilizing the colour features and texture features can provide improved classification due to increased information that can be used to do the classification. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Green Warehouse Performance Measurement Model for 3PL Warehousing"
        ],
        "penulis":"Margareta, Whendy;Ridwan, Ari Yanuar;Muttaqin, Prafajar Suksessanno;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The usage level of outsourcing logistics services in Indonesia from year to year was grow continuously. It makes logistics service outsourcing companies have to compete in terms of improving services to consumers by evaluating the performance level of logistics services offered. By evaluating the performance level of the logistics service outsourcing company (3PL Warehouse), it is expected that the warehouse performance level will achieve the target. In addition, evaluating the level of performance of logistics services is expected to make outsourcing companies get advantages. Therefore, this study integrated two models that were used to measure the Warehouse KPI, namely Supply Chain Operation Reference (SCOR) and Analytical Hierarchy Process (AHP) by considering green warehousing criteria. By using these two models, the result was in the form of performance metrics that functioned as a scale to evaluate and measure the performance of the warehouse.  \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The usage level of outsourcing logistics services in Indonesia from year to year was grow continuously. It makes logistics service outsourcing companies have to compete in terms of improving services to consumers by evaluating the performance level of logistics services offered. By evaluating the performance level of the logistics service outsourcing company (3PL Warehouse), it is expected that the warehouse performance level will achieve the target. In addition, evaluating the level of performance of logistics services is expected to make outsourcing companies get advantages. Therefore, this study integrated two models that were used to measure the Warehouse KPI, namely Supply Chain Operation Reference (SCOR) and Analytical Hierarchy Process (AHP) by considering green warehousing criteria. By using these two models, the result was in the form of performance metrics that functioned as a scale to evaluate and measure the performance of the warehouse.  \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Wavelet-based hybrid audio watermarking using statistical mean manipulation and spread spectrum"
        ],
        "penulis":"Budiman, Gelar;Suksmono, Andriyan Bayu;Danudirdjo, Donny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, we propose a Discrete Wavelet Transform (DWT) - based hybrid audio watermarking using Statistical Mean Manipulation (SMM) and Spread Spectrum (SS) technique. The host audio is decomposed by DWT to produce the signal in low frequency subband and high frequency subband, where SMM embeds the watermark into low frequency in the first subband, and SS embeds the watermark into high frequency in the selected subband. The embedding process using the SMM technique is the insertion process by modifying the average of the audio signal in one frame according to the watermark, thus it modifies the audio in the low-frequency subband. The SS technique modulates the watermark before it is embedded into the host audio in the higher selected frequency subband. This combination technique produces the robust watermarking method to the signal processing attack, such as Low Pas Filter (LPF), resampling and audio compression while maintaining high watermarked audio quality and watermark payload. \u00a9 2020 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we propose a Discrete Wavelet Transform (DWT) - based hybrid audio watermarking using Statistical Mean Manipulation (SMM) and Spread Spectrum (SS) technique. The host audio is decomposed by DWT to produce the signal in low frequency subband and high frequency subband, where SMM embeds the watermark into low frequency in the first subband, and SS embeds the watermark into high frequency in the selected subband. The embedding process using the SMM technique is the insertion process by modifying the average of the audio signal in one frame according to the watermark, thus it modifies the audio in the low-frequency subband. The SS technique modulates the watermark before it is embedded into the host audio in the higher selected frequency subband. This combination technique produces the robust watermarking method to the signal processing attack, such as Low Pas Filter (LPF), resampling and audio compression while maintaining high watermarked audio quality and watermark payload. \u00a9 2020 IEEE"
        ]
    },
    {
        "judul":[
            "Anatomy of magnetic anisotropy and voltage-controlled magnetic anisotropy in metal oxide heterostructure from first principles"
        ],
        "penulis":"Pardede, Indra;Yoshikawa, Daiki;Kanagawa, Tomosato;Ikhsan, Nurul;Obata, Masao;Oda, Tatsuki;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Voltage control of magnetic anisotropy (VCMA) is one of the promising approaches for magnetoelectric control of magnetic tunnel junction (MTJ). Here, we systematically calculated the magnetic anisotropy (MA) and the VCMA energies in the well-known MTJ structure consisting of Fe\/MgO interface with Cr buffer layer. In this calculation, we investigated an alloying between Fe and Cr and a strain effect. We used a spin density functional approach which includes both contributions from magnetocrystalline anisotropy energy (MCAE) originating from spin\u2013orbit coupling and shape magnetic anisotropy energy from spin dipole\u2013dipole interaction. In the present approach, the MCAE part, in addition to a common scheme of total energy, was evaluated using a grand canonical force theorem scheme. In the latter scheme, atom-resolved and k-resolved analyses for MA and VCMA can be performed. At first, we found that, as the alloying is introduced, the perpendicular MCAE increases by a factor of two. Next, as the strain is introduced, we found that the MCAE increases with increasing compressive strain with the maximum value of 2.2 mJ\/m2. For the VCMA coefficient, as the compressive strain increases, the sign becomes negative and the absolute value becomes enhanced to the number of 170 fJ\/Vm. By using the atom-resolved and k-resolved analyses, we clarified that these enhancements of MCAE and VCMA mainly originates from the Fe interface with MgO (Fe1) and are located at certain lines in the two dimensional Brillouin zone. The findings on MCAE and VCMA are fully explained by the spin-orbit couplings between the certain d-orbital states in the second-order perturbation theory. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Voltage control of magnetic anisotropy (VCMA) is one of the promising approaches for magnetoelectric control of magnetic tunnel junction (MTJ). Here, we systematically calculated the magnetic anisotropy (MA) and the VCMA energies in the well-known MTJ structure consisting of Fe\/MgO interface with Cr buffer layer. In this calculation, we investigated an alloying between Fe and Cr and a strain effect. We used a spin density functional approach which includes both contributions from magnetocrystalline anisotropy energy (MCAE) originating from spin\u2013orbit coupling and shape magnetic anisotropy energy from spin dipole\u2013dipole interaction. In the present approach, the MCAE part, in addition to a common scheme of total energy, was evaluated using a grand canonical force theorem scheme. In the latter scheme, atom-resolved and k-resolved analyses for MA and VCMA can be performed. At first, we found that, as the alloying is introduced, the perpendicular MCAE increases by a factor of two. Next, as the strain is introduced, we found that the MCAE increases with increasing compressive strain with the maximum value of 2.2 mJ\/m2. For the VCMA coefficient, as the compressive strain increases, the sign becomes negative and the absolute value becomes enhanced to the number of 170 fJ\/Vm. By using the atom-resolved and k-resolved analyses, we clarified that these enhancements of MCAE and VCMA mainly originates from the Fe interface with MgO (Fe1) and are located at certain lines in the two dimensional Brillouin zone. The findings on MCAE and VCMA are fully explained by the spin-orbit couplings between the certain d-orbital states in the second-order perturbation theory. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Network Security Analysis Using HTTPS with SSL on General Election Quick Count Website"
        ],
        "penulis":"Wibowo, Faiq;Nuha, Hilal Hudan;Wibowo, Sidik;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The general election is a democratic event held every five years to elect the candidate who will lead the country during the period. There are several pilot websites for data processing by the quick count survey institution. However, in terms of security, the sites are still lacking because of the applicability have not implemented security systems for the anticipation of the attacks were not responsible. In this proposal, the authors designed a security application quick count based crowd-sourcing. HTTPS and SSL is a security protocol that is commonly used to secure web or internet transactions. The use of HTTPS and SSL on a quick count of applications is expected to be able to anticipate and secure communications between the client and the server of the intruder's attack or unauthorized access. A simple implementation of SSL installation is shown to be able to reduce the vulnerability level and prevent the SQL injection attack. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The general election is a democratic event held every five years to elect the candidate who will lead the country during the period. There are several pilot websites for data processing by the quick count survey institution. However, in terms of security, the sites are still lacking because of the applicability have not implemented security systems for the anticipation of the attacks were not responsible. In this proposal, the authors designed a security application quick count based crowd-sourcing. HTTPS and SSL is a security protocol that is commonly used to secure web or internet transactions. The use of HTTPS and SSL on a quick count of applications is expected to be able to anticipate and secure communications between the client and the server of the intruder's attack or unauthorized access. A simple implementation of SSL installation is shown to be able to reduce the vulnerability level and prevent the SQL injection attack. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Crackle detection in lung sound using statistical feature of variogram"
        ],
        "penulis":"Pramudita, Brahmantya Aji;Istiqomah;Rizal, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Pulmonary crackle sound is an adventitious lung sound that occurs due to several types of lung diseases such as pneumonia, pulmonary fibrosis, or chronic bronchitis. Crackle has distinctive sound patterns such as discontinuous, non-musical, and relatively short duration. Various methods were used to detect crackles in lung sounds such as entropy, wavelet-based methods, or spectral analysis. In this study, normal lung sound and pulmonary crackle sound classification were performed using the variogram as a feature extraction method. Modified variogram was applied to the pulmonary sound signal, and its statistical parameters were measured to distinguish crackle lung sound from normal lung sound. The experimental result produced the highest accuracy of 95.3% using Quadratic S V M as a classifier. These results indicated that the variogram could capture differences in signal dynamics in normal and pulmonary crackle sounds. \u00a9 2020 American Institute of Physics Inc.. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Pulmonary crackle sound is an adventitious lung sound that occurs due to several types of lung diseases such as pneumonia, pulmonary fibrosis, or chronic bronchitis. Crackle has distinctive sound patterns such as discontinuous, non-musical, and relatively short duration. Various methods were used to detect crackles in lung sounds such as entropy, wavelet-based methods, or spectral analysis. In this study, normal lung sound and pulmonary crackle sound classification were performed using the variogram as a feature extraction method. Modified variogram was applied to the pulmonary sound signal, and its statistical parameters were measured to distinguish crackle lung sound from normal lung sound. The experimental result produced the highest accuracy of 95.3% using Quadratic S V M as a classifier. These results indicated that the variogram could capture differences in signal dynamics in normal and pulmonary crackle sounds. \u00a9 2020 American Institute of Physics Inc.. All rights reserved."
        ]
    },
    {
        "judul":[
            "Design of Automatic Switch System of Residential Load from Solar Cell and Power Plant Resources using Neural Network"
        ],
        "penulis":"Silalahi D.K.;Aprilia B.S.;Priharti W.;Kumillayly K.;Saidah S.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Residential loads are electronic equipment that is often used at home. Residential loads are supplied from two sources, they are solar panel and the State Power plant. Selecting the supply load source, so an automatic switch system is needed from the load. Optimizing residential load resources and avoiding overloading, load balancing techniques are needed. The switch system uses a relay, determined by the solar panel power output. This research discusses the design of automatic load switch systems for residential loads from solar panels and State Power plant using Artificial Neural Networks (ANN). ANN control system that is arranged using ANN Backpropagation consists of 4 inputs, four hidden layers, each consisting of 4 neurons and one neuron in the output layer. In this research, to determine the network that has been formed to provide changes of load. The results of testing that the parameters used to get the smallest error rate in the process of setting an automatic power load switch is best to use a number of repetitions of 2000 times with an error percentage 5.3%. Artificial Neural Networks can experience convergent failure or not close to output because the initial guess is not good. Initial experiments with actual solar panel data with as many as 98 data produced non-convergent output values. The solution to improving the initial experiment is to simplify learning data 40 data produces convergent output. \u00a9 2020 IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Residential loads are electronic equipment that is often used at home. Residential loads are supplied from two sources, they are solar panel and the State Power plant. Selecting the supply load source, so an automatic switch system is needed from the load. Optimizing residential load resources and avoiding overloading, load balancing techniques are needed. The switch system uses a relay, determined by the solar panel power output. This research discusses the design of automatic load switch systems for residential loads from solar panels and State Power plant using Artificial Neural Networks (ANN). ANN control system that is arranged using ANN Backpropagation consists of 4 inputs, four hidden layers, each consisting of 4 neurons and one neuron in the output layer. In this research, to determine the network that has been formed to provide changes of load. The results of testing that the parameters used to get the smallest error rate in the process of setting an automatic power load switch is best to use a number of repetitions of 2000 times with an error percentage 5.3%. Artificial Neural Networks can experience convergent failure or not close to output because the initial guess is not good. Initial experiments with actual solar panel data with as many as 98 data produced non-convergent output values. The solution to improving the initial experiment is to simplify learning data 40 data produces convergent output. \u00a9 2020 IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Development of Budgeting Module on Android based on Backpacker BackInd Applications: Sorting and Filtering Features"
        ],
        "penulis":"Tampubolon, Yoel F.;Andreswari, Rachmadita;Lubis, Muharman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Decision making problems often occur in tourists to determine the activity within the tourist destinations or location. For tourists, information about attractions also is needed to allow their planning to be precise and meaningful. The BackInd (Backpacker Management System) have been developed as an application to help and support tourists by providing comprehensive information about tourist attractions through filtering and sorting mechanism. In addition to provide those type of information, tourists also allowed to buy tickets directly without much more burden to wait physically in that attractions counter. The development of this application is expected to help tourists get recommendations based on their preferences that are in accordance with the budget of the travellers. Thus, this study uses the Rapid Application Development (RAD) method, which the results focused on the featured added to the application in term of sorting, filtering and budgeting features so the homestay that tourist want will match accordingly with their plan. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Decision making problems often occur in tourists to determine the activity within the tourist destinations or location. For tourists, information about attractions also is needed to allow their planning to be precise and meaningful. The BackInd (Backpacker Management System) have been developed as an application to help and support tourists by providing comprehensive information about tourist attractions through filtering and sorting mechanism. In addition to provide those type of information, tourists also allowed to buy tickets directly without much more burden to wait physically in that attractions counter. The development of this application is expected to help tourists get recommendations based on their preferences that are in accordance with the budget of the travellers. Thus, this study uses the Rapid Application Development (RAD) method, which the results focused on the featured added to the application in term of sorting, filtering and budgeting features so the homestay that tourist want will match accordingly with their plan. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Organizational competency and innovation capability: The influence of knowledge management on business performance"
        ],
        "penulis":"Deni, Asep;Priansa, Donni Juni;Darmo, Ika Suhartanti;Saribanon, Euis;Riswanto, Ari;Sumaryadi, Sumaryadi;Ramdan, Asep Muhamad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study seeks to analyze the relationship of organizational competence and innovation ability by exploring the effect of knowledge management on business performance. This study aims to determine whether organizational competence and innovation capacity can mediate the influence of knowledge management with firm performance. The quantitative descriptive method approach through simple linear regression analysis with SPSS is used in this study while for analytical analysis using Structural Equation Modeling (SEM) starting from the Confirmatory Factor Analysis (CFA) model to validate the instruments simultaneously to the analysis of Product Coefficient Strategy Products using Single Mediation Model, with a sample of 226 respondents, namely the culinary industry in West Java Province, Indonesia. The results show that organizational competence and innovation ability have the ability to mediate the influence between knowledge management and business performance. \u00a9 2020, SAGE Publications Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study seeks to analyze the relationship of organizational competence and innovation ability by exploring the effect of knowledge management on business performance. This study aims to determine whether organizational competence and innovation capacity can mediate the influence of knowledge management with firm performance. The quantitative descriptive method approach through simple linear regression analysis with SPSS is used in this study while for analytical analysis using Structural Equation Modeling (SEM) starting from the Confirmatory Factor Analysis (CFA) model to validate the instruments simultaneously to the analysis of Product Coefficient Strategy Products using Single Mediation Model, with a sample of 226 respondents, namely the culinary industry in West Java Province, Indonesia. The results show that organizational competence and innovation ability have the ability to mediate the influence between knowledge management and business performance. \u00a9 2020, SAGE Publications Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Performance analysis of multi services on container Docker, LXC, and LXD"
        ],
        "penulis":"Putri, Adinda Riztia;Munadi, Rendy;Negara, Ridha Muldina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The emergence of the container in various cloud platforms from Open Stack to Google Cloud Platform has marked the industry interest in opting for container as their cloud service solution. However, the cloud users should aware of performance overheads of different virtualization solutions in order to avoid quality of service degradation because different container platforms delivered different performances. This research evaluated how different container platforms (Docker, LXC, and LXD) impacted in running different TCP services and also measured system performance of each container compared to the native system without any container solution based on overall performance metrics. This research focuses on the three most used PaaS: FTP Server, Web Server, and Mail Server. Related to previous works, our evaluation results show that performance could vary between containers. In terms of system performance, LXD shows better performance while server performance result varies depending on what service is being evaluated. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The emergence of the container in various cloud platforms from Open Stack to Google Cloud Platform has marked the industry interest in opting for container as their cloud service solution. However, the cloud users should aware of performance overheads of different virtualization solutions in order to avoid quality of service degradation because different container platforms delivered different performances. This research evaluated how different container platforms (Docker, LXC, and LXD) impacted in running different TCP services and also measured system performance of each container compared to the native system without any container solution based on overall performance metrics. This research focuses on the three most used PaaS: FTP Server, Web Server, and Mail Server. Related to previous works, our evaluation results show that performance could vary between containers. In terms of system performance, LXD shows better performance while server performance result varies depending on what service is being evaluated. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Student Activities Recommendations to Achieve First Job Waiting Time Target of Graduates in Telkom University: Decision Tree Approach"
        ],
        "penulis":"Rifansyah, Muhammad;Kurniawati, Amelia;Supratman,, Nurdinitya Athari;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The first job search time is one of the measurement values of a university, an \"A\"accredited university if the average time for a student's job search is less than three months. According to the Telkom University tracer study in 2016-2018, there was a significant increase of students who experience the first job search time for more than three months from 18% up to 54%. The purpose of this study is to classify which students will have the potential to experience the first job search time for more than three months based on tracer study, history of organization type, position, Grade Point Average (GPA), and remaining semester credit units. With the results of using the classification process with decision tree C5.0 algorithm, the model has accuracy 54.7% with three attributes that are considered, GPA, study period, and participating in educational\/reasoning\/arts organizations. This helps Telkom University in monitoring students who are indicated to be experiencing a short or long first job waiting time. Therefore, Telkom University can provide specific activity recommendations for students, based on their GPA, remaining semester credits, and organizational activities. For further research, it can be more variables can be added to develop a model with higher accuracy. \u00a9 2020 Association for Computing Machinery.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The first job search time is one of the measurement values of a university, an \"A\"accredited university if the average time for a student's job search is less than three months. According to the Telkom University tracer study in 2016-2018, there was a significant increase of students who experience the first job search time for more than three months from 18% up to 54%. The purpose of this study is to classify which students will have the potential to experience the first job search time for more than three months based on tracer study, history of organization type, position, Grade Point Average (GPA), and remaining semester credit units. With the results of using the classification process with decision tree C5.0 algorithm, the model has accuracy 54.7% with three attributes that are considered, GPA, study period, and participating in educational\/reasoning\/arts organizations. This helps Telkom University in monitoring students who are indicated to be experiencing a short or long first job waiting time. Therefore, Telkom University can provide specific activity recommendations for students, based on their GPA, remaining semester credits, and organizational activities. For further research, it can be more variables can be added to develop a model with higher accuracy. \u00a9 2020 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Classification of Road Surface Quality Based on SVM Method"
        ],
        "penulis":"Afenika, Adhelinia;Gunawan P.H.;Tarwidi D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Damaged and potholes roads can occur due to rain puddles, too many heavy vehicles, poor asphalt quality, or maybe long road life. Damaged roads can hamper activities and endanger the safety of road users. It is necessary to monitor road quality periodically which is conducted by government, so that roads improvement can be done quick as possible. The aim of this study is to build a systemthat can classify roads surface quality. Support Vector Machine (SVM) classifications method is used to classify roads based on roadworthiness. In this study, 300 road surface data which contains good\/smooth and damage quality of road are used. The simulation results show that SVM model can classify road surface data into two classes with average accuracy of 93%. The results can be a recommendation for government to prioritize which roads need to be improved. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Damaged and potholes roads can occur due to rain puddles, too many heavy vehicles, poor asphalt quality, or maybe long road life. Damaged roads can hamper activities and endanger the safety of road users. It is necessary to monitor road quality periodically which is conducted by government, so that roads improvement can be done quick as possible. The aim of this study is to build a systemthat can classify roads surface quality. Support Vector Machine (SVM) classifications method is used to classify roads based on roadworthiness. In this study, 300 road surface data which contains good\/smooth and damage quality of road are used. The simulation results show that SVM model can classify road surface data into two classes with average accuracy of 93%. The results can be a recommendation for government to prioritize which roads need to be improved. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Aspect-based Opinion Mining on Beauty Product Reviews"
        ],
        "penulis":"Mahfiz, Syiti Liviani;Romadhony, Ade;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Product reviews play an important role in consumer decision making. Nowadays, they can be found on most of the marketplaces and online forums. Among Indonesian women, beauty product is the most discussed topic, which leads to an increasing number of reviews. Considering the number, extracting aspect-based information from unstructured review text is a challenging task for consumers. Therefore, providing automatic aspect-based opinion mining will be a very valuable service for the consumers. In this study, we performed aspect-based opinion extraction and polarity classification by using Na\u00efve Bayes. We applied Synthetic Minority Oversampling Technique (SMOTE) and obtained 50.55% for overall aspect F1-Score. We also used 10 different preprocessing settings that combine filtering and stemming for Indonesian and English language. The result shows that setting with filtering and stemming for the Indonesian language achieved the highest score of 53.04% for F1-Score.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGender equalityGoal 5",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Product reviews play an important role in consumer decision making. Nowadays, they can be found on most of the marketplaces and online forums. Among Indonesian women, beauty product is the most discussed topic, which leads to an increasing number of reviews. Considering the number, extracting aspect-based information from unstructured review text is a challenging task for consumers. Therefore, providing automatic aspect-based opinion mining will be a very valuable service for the consumers. In this study, we performed aspect-based opinion extraction and polarity classification by using Na\u00efve Bayes. We applied Synthetic Minority Oversampling Technique (SMOTE) and obtained 50.55% for overall aspect F1-Score. We also used 10 different preprocessing settings that combine filtering and stemming for Indonesian and English language. The result shows that setting with filtering and stemming for the Indonesian language achieved the highest score of 53.04% for F1-Score.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Sentiment Analysis Website of Online Hotel Booking Application Reviews Using the Naive Bayes Algorithm"
        ],
        "penulis":"Azzahra, Zalina Fatima;Andreswari, Rachmadita;Hasibuan, Muhammad Azani;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Today, there are many applications available on the Google Play Store, especially the online hotel booking application. In Indonesia, 2 out of 3 people book hotels online and users also rely on digital reviews for travel inspiration as well as research and bookings. Users can find out user satisfaction by looking at reviews from previous users, but it is very problematic if we read the reviews of this application one by one because it takes a very long time. Measuring the level of user satisfaction of an application can be done by knowing how the sentiment from the public. This paper provides an approach to analyzing sentiments for online hotel booking applications based on user reviews on the Google Play Store using the Naive Bayes algorithm. The process starts with data collection using web-scraping, text preprocessing using python, data labeling using SentiStrength, classification with the Naive Bayes algorithm, and website development using Django Web Framework. This website provides information support for users in choosing an online hotel booking application. From this study, the highest accuracy value obtained was 94%. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Today, there are many applications available on the Google Play Store, especially the online hotel booking application. In Indonesia, 2 out of 3 people book hotels online and users also rely on digital reviews for travel inspiration as well as research and bookings. Users can find out user satisfaction by looking at reviews from previous users, but it is very problematic if we read the reviews of this application one by one because it takes a very long time. Measuring the level of user satisfaction of an application can be done by knowing how the sentiment from the public. This paper provides an approach to analyzing sentiments for online hotel booking applications based on user reviews on the Google Play Store using the Naive Bayes algorithm. The process starts with data collection using web-scraping, text preprocessing using python, data labeling using SentiStrength, classification with the Naive Bayes algorithm, and website development using Django Web Framework. This website provides information support for users in choosing an online hotel booking application. From this study, the highest accuracy value obtained was 94%. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Wavelet-based hybrid audio watermarking using statistical mean manipulation and spread spectrum"
        ],
        "penulis":"Budiman, Gelar;Suksmono, Andriyan Bayu;Danudirdjo, Donny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, we propose a Discrete Wavelet Transform (DWT) - based hybrid audio watermarking using Statistical Mean Manipulation (SMM) and Spread Spectrum (SS) technique. The host audio is decomposed by DWT to produce the signal in low frequency subband and high frequency subband, where SMM embeds the watermark into low frequency in the first subband, and SS embeds the watermark into high frequency in the selected subband. The embedding process using the SMM technique is the insertion process by modifying the average of the audio signal in one frame according to the watermark, thus it modifies the audio in the low-frequency subband. The SS technique modulates the watermark before it is embedded into the host audio in the higher selected frequency subband. This combination technique produces the robust watermarking method to the signal processing attack, such as Low Pas Filter (LPF), resampling and audio compression while maintaining high watermarked audio quality and watermark payload. \u00a9 2020 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we propose a Discrete Wavelet Transform (DWT) - based hybrid audio watermarking using Statistical Mean Manipulation (SMM) and Spread Spectrum (SS) technique. The host audio is decomposed by DWT to produce the signal in low frequency subband and high frequency subband, where SMM embeds the watermark into low frequency in the first subband, and SS embeds the watermark into high frequency in the selected subband. The embedding process using the SMM technique is the insertion process by modifying the average of the audio signal in one frame according to the watermark, thus it modifies the audio in the low-frequency subband. The SS technique modulates the watermark before it is embedded into the host audio in the higher selected frequency subband. This combination technique produces the robust watermarking method to the signal processing attack, such as Low Pas Filter (LPF), resampling and audio compression while maintaining high watermarked audio quality and watermark payload. \u00a9 2020 IEEE"
        ]
    },
    {
        "judul":[
            "Network Security Analysis Using HTTPS with SSL on General Election Quick Count Website"
        ],
        "penulis":"Wibowo, Faiq;Nuha, Hilal Hudan;Wibowo, Sidik;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The general election is a democratic event held every five years to elect the candidate who will lead the country during the period. There are several pilot websites for data processing by the quick count survey institution. However, in terms of security, the sites are still lacking because of the applicability have not implemented security systems for the anticipation of the attacks were not responsible. In this proposal, the authors designed a security application quick count based crowd-sourcing. HTTPS and SSL is a security protocol that is commonly used to secure web or internet transactions. The use of HTTPS and SSL on a quick count of applications is expected to be able to anticipate and secure communications between the client and the server of the intruder's attack or unauthorized access. A simple implementation of SSL installation is shown to be able to reduce the vulnerability level and prevent the SQL injection attack. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The general election is a democratic event held every five years to elect the candidate who will lead the country during the period. There are several pilot websites for data processing by the quick count survey institution. However, in terms of security, the sites are still lacking because of the applicability have not implemented security systems for the anticipation of the attacks were not responsible. In this proposal, the authors designed a security application quick count based crowd-sourcing. HTTPS and SSL is a security protocol that is commonly used to secure web or internet transactions. The use of HTTPS and SSL on a quick count of applications is expected to be able to anticipate and secure communications between the client and the server of the intruder's attack or unauthorized access. A simple implementation of SSL installation is shown to be able to reduce the vulnerability level and prevent the SQL injection attack. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Facial Recognition-Based Automatic Door Access System Using Extreme Learning Machine"
        ],
        "penulis":"Rahmat R.F.;Zai E.N.;Fawwaz I.;Aulia I.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Facial recognition is one of the best forms of security since it is biometric-based security that uses biological features of the face. One of the artificial neural networks that can be implemented in the face recognition case is Extreme Learning Machine with the assistance of Local Binary Pattern in obtaining the facial features. The testing process in this study used 150 face images for training data and 60 face images for test data. The test was carried out using several three parameters of the hidden neuron numbers, namely 10, 30, and 50, and also five parameters of the image condition, namely feature, expression, face direction, lighting, and webcam distance. The system achieved the highest accuracy of 90% using 50 hidden neurons. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Facial recognition is one of the best forms of security since it is biometric-based security that uses biological features of the face. One of the artificial neural networks that can be implemented in the face recognition case is Extreme Learning Machine with the assistance of Local Binary Pattern in obtaining the facial features. The testing process in this study used 150 face images for training data and 60 face images for test data. The test was carried out using several three parameters of the hidden neuron numbers, namely 10, 30, and 50, and also five parameters of the image condition, namely feature, expression, face direction, lighting, and webcam distance. The system achieved the highest accuracy of 90% using 50 hidden neurons. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Design of Automatic Switch System of Residential Load from Solar Cell and Power Plant Resources using Neural Network"
        ],
        "penulis":"Silalahi D.K.;Aprilia B.S.;Priharti W.;Kumillayly K.;Saidah S.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Residential loads are electronic equipment that is often used at home. Residential loads are supplied from two sources, they are solar panel and the State Power plant. Selecting the supply load source, so an automatic switch system is needed from the load. Optimizing residential load resources and avoiding overloading, load balancing techniques are needed. The switch system uses a relay, determined by the solar panel power output. This research discusses the design of automatic load switch systems for residential loads from solar panels and State Power plant using Artificial Neural Networks (ANN). ANN control system that is arranged using ANN Backpropagation consists of 4 inputs, four hidden layers, each consisting of 4 neurons and one neuron in the output layer. In this research, to determine the network that has been formed to provide changes of load. The results of testing that the parameters used to get the smallest error rate in the process of setting an automatic power load switch is best to use a number of repetitions of 2000 times with an error percentage 5.3%. Artificial Neural Networks can experience convergent failure or not close to output because the initial guess is not good. Initial experiments with actual solar panel data with as many as 98 data produced non-convergent output values. The solution to improving the initial experiment is to simplify learning data 40 data produces convergent output. \u00a9 2020 IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Residential loads are electronic equipment that is often used at home. Residential loads are supplied from two sources, they are solar panel and the State Power plant. Selecting the supply load source, so an automatic switch system is needed from the load. Optimizing residential load resources and avoiding overloading, load balancing techniques are needed. The switch system uses a relay, determined by the solar panel power output. This research discusses the design of automatic load switch systems for residential loads from solar panels and State Power plant using Artificial Neural Networks (ANN). ANN control system that is arranged using ANN Backpropagation consists of 4 inputs, four hidden layers, each consisting of 4 neurons and one neuron in the output layer. In this research, to determine the network that has been formed to provide changes of load. The results of testing that the parameters used to get the smallest error rate in the process of setting an automatic power load switch is best to use a number of repetitions of 2000 times with an error percentage 5.3%. Artificial Neural Networks can experience convergent failure or not close to output because the initial guess is not good. Initial experiments with actual solar panel data with as many as 98 data produced non-convergent output values. The solution to improving the initial experiment is to simplify learning data 40 data produces convergent output. \u00a9 2020 IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Implementation of meander line structure for size miniaturization of 4x4 butler matrix"
        ],
        "penulis":"Zulfi;Dewantari, Aulia;Munir, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One method to overcome the problem of co-channel interference in wireless communication systems is by employing a switched-beam antenna system. A Butler matrix is commonly utilized as a beam-forming network for some reasonable factors, e.g. low complexity, low loss, and simply fabrication. However, the bulky size of Butler matrix affects an incompatibility in developing compact devices. In this paper, a meander Une structure which is an approach to reduce the physical dimension of radio frequency components is implemented to miniaturize the size of conventional 4x4 Bulter matrix. Some key parameters of Butler matrix including the amplitude and phase responses are characterized and investigated through several simulations. The characterization results demonstrate that the proposed Butler matrix takes the size of 57.5 mm by 136.4 mm shows good amplitude and phase performances. \u041b phase difference of -46.98\" \u00b1 6.72\" with an imbalance amplitude less than 5.97 dB was achieved at the operating frequency of 2.4 GHz. Meanwhile, a 10 dB return loss fractional bandwidth of 18.75% could be attained at the frequency range of 2.29 GHz to 2.74 GHz. Here, the use of meander line stmcture could exhibit a size miniaturization of 34.29% to the footprint of conventional 4x4 Butler matrix. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One method to overcome the problem of co-channel interference in wireless communication systems is by employing a switched-beam antenna system. A Butler matrix is commonly utilized as a beam-forming network for some reasonable factors, e.g. low complexity, low loss, and simply fabrication. However, the bulky size of Butler matrix affects an incompatibility in developing compact devices. In this paper, a meander Une structure which is an approach to reduce the physical dimension of radio frequency components is implemented to miniaturize the size of conventional 4x4 Bulter matrix. Some key parameters of Butler matrix including the amplitude and phase responses are characterized and investigated through several simulations. The characterization results demonstrate that the proposed Butler matrix takes the size of 57.5 mm by 136.4 mm shows good amplitude and phase performances. \u041b phase difference of -46.98\" \u00b1 6.72\" with an imbalance amplitude less than 5.97 dB was achieved at the operating frequency of 2.4 GHz. Meanwhile, a 10 dB return loss fractional bandwidth of 18.75% could be attained at the frequency range of 2.29 GHz to 2.74 GHz. Here, the use of meander line stmcture could exhibit a size miniaturization of 34.29% to the footprint of conventional 4x4 Butler matrix. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Detection of Multi-Class Glaucoma Using Active Contour Snakes and Support Vector Machine"
        ],
        "penulis":"Zulfira, Fakhira Zahra;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "There are several ways to detect glaucoma, one of the most accurate is the presence of peripapillary atrophy (PPA). PPA is located outside the optic disc around the optic nerve head (ONH) and sometimes looks vague which can cause misclassification, so other parameters that can detect glaucoma are needed. The calculation of the optic cup to disc ratio (CDR) is mostly done for glaucoma detection so that CDR can be considered in addition to the presence of PPA to improve classification results. In this paper, a multi-class glaucoma detection is developed using an active contour snake to get the value of the optic cup and optic disc to measure CDR and a support vector machine (SVM) for classification. Glaucoma is categorized into three classes: non-glaucoma, mild-glaucoma, and severe-glaucoma. Hence, the model can detect its severity which determines further treatment. Evaluation using two datasets of 210 retinal fundus images (165 train and 45 test) informs that the model reaches high accuracies of 95%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "There are several ways to detect glaucoma, one of the most accurate is the presence of peripapillary atrophy (PPA). PPA is located outside the optic disc around the optic nerve head (ONH) and sometimes looks vague which can cause misclassification, so other parameters that can detect glaucoma are needed. The calculation of the optic cup to disc ratio (CDR) is mostly done for glaucoma detection so that CDR can be considered in addition to the presence of PPA to improve classification results. In this paper, a multi-class glaucoma detection is developed using an active contour snake to get the value of the optic cup and optic disc to measure CDR and a support vector machine (SVM) for classification. Glaucoma is categorized into three classes: non-glaucoma, mild-glaucoma, and severe-glaucoma. Hence, the model can detect its severity which determines further treatment. Evaluation using two datasets of 210 retinal fundus images (165 train and 45 test) informs that the model reaches high accuracies of 95%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Ability to Adapt jBatik Software Technology for Traditional Batik Craftsmen"
        ],
        "penulis":"Ciptandi, Fajar;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study is to find out the adaptability of traditional batik craftsmen in using jBatik software technology to create motif development. The traditional batik industry in Tuban, East Java was choosen as an example of case because it is considered to represent other traditional batik industries in Java. In previous studies, the use of jBatik software has been tested and resulted in the development of several designs of traditional Tuban batik motifs. This study was conducted to analyze the factors driving as well as inhibiting traditional batik craftsmen in adapting jBatik software technology through an experimental approach by referring to the diffusion of innovation theory. This is useful as one of the solutions today as an effort to measure the readiness level of traditional batik craftsmen to adapt technology, as well as being a way of self-evaluation for the technology to adapt to the needs of traditional batik craftsmen in Indonesia.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to find out the adaptability of traditional batik craftsmen in using jBatik software technology to create motif development. The traditional batik industry in Tuban, East Java was choosen as an example of case because it is considered to represent other traditional batik industries in Java. In previous studies, the use of jBatik software has been tested and resulted in the development of several designs of traditional Tuban batik motifs. This study was conducted to analyze the factors driving as well as inhibiting traditional batik craftsmen in adapting jBatik software technology through an experimental approach by referring to the diffusion of innovation theory. This is useful as one of the solutions today as an effort to measure the readiness level of traditional batik craftsmen to adapt technology, as well as being a way of self-evaluation for the technology to adapt to the needs of traditional batik craftsmen in Indonesia.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Inversion of Tsunami by Using Artificial Neural Network: Study Case the 2018 Palu's Tsunami"
        ],
        "penulis":"Bakti, Audi Cipta;Adytia, Didit;Subasita, Nugrahinggil;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The earthquake that occurred in Palu City in September 2018 caused an avalanche of marine sediments in Palu Bay that leads to a tsunami generation which impacted the Palu City and its surrounding areas. Nevertheless, there is no information regarding the location, precise shape, and mechanism of the landslide event that generated the tsunami in Palu Bay. In this study, the initial condition of water elevation which is generated by the landslide in Palu Bay is estimated by using a machine learning approach, i.e. Artificial Neural Network (ANN). To apply this approach, sets of training data are needed for the ANN model. Here, we use numerical wave simulations with various initial conditions that are performed to build the training data. We use the SWASH model as the wave model to perform numerical simulation. The obtained training data are then used for tsunami inversion by using ANN. Although there is only one measured water elevation in Palu Bay during the 2018 tsunami, i.e. in Pantoloan port, in this paper, we use four signals at different locations that are used as input for the ANN inversion model, in order to estimate the initial shape and location of the tsunami. We observe that by using four points of observation for tsunami inversion give best result compared to results by using 1 to 3 observation points. Using four points, we obtain R2 score of 0.98347 and RMSE score of 0.115345.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The earthquake that occurred in Palu City in September 2018 caused an avalanche of marine sediments in Palu Bay that leads to a tsunami generation which impacted the Palu City and its surrounding areas. Nevertheless, there is no information regarding the location, precise shape, and mechanism of the landslide event that generated the tsunami in Palu Bay. In this study, the initial condition of water elevation which is generated by the landslide in Palu Bay is estimated by using a machine learning approach, i.e. Artificial Neural Network (ANN). To apply this approach, sets of training data are needed for the ANN model. Here, we use numerical wave simulations with various initial conditions that are performed to build the training data. We use the SWASH model as the wave model to perform numerical simulation. The obtained training data are then used for tsunami inversion by using ANN. Although there is only one measured water elevation in Palu Bay during the 2018 tsunami, i.e. in Pantoloan port, in this paper, we use four signals at different locations that are used as input for the ANN inversion model, in order to estimate the initial shape and location of the tsunami. We observe that by using four points of observation for tsunami inversion give best result compared to results by using 1 to 3 observation points. Using four points, we obtain R2 score of 0.98347 and RMSE score of 0.115345.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Royale Heroes: A Unique RTS Game Using Deep Reinforcement Learning-based Autonomous Movement"
        ],
        "penulis":"Ramadhan, Firdiansyah;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A game, a set of rules or policies by one or more people to carry out an action that will generate excitement for those who do it, can be developed using one of two types of playing methods: turn-based and real-time. In real-time strategic (RTS) games with many characters like Warcraft and Chess, it is fun to play. However, fun decreases since the players have to focus on many points in the playing area. Hence, autonomous movement (AM), an assistant to move the character, can be one solution. An AM can be implemented using deep reinforcement learning (DRL), a new method that can continue to learn without erasing previously learned memory that makes AM better since it can adapt to the playing style. This paper describes the Royale Heroes, a unique RTS game that implements a DRL-based AM. First, a base model is created using a rule-based model based on conventional artificial intelligence (AI). Next, a DRL model is trained to imitate the behavior of previously created AI. Evaluation of six matches shows that the DRL provides high accuracy of up to 98% to copy a behavior. Hence, it can be used as an AM to help players make choices in playing the game. When the player plays this game, the model will continue learning to imitate the player behavior.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A game, a set of rules or policies by one or more people to carry out an action that will generate excitement for those who do it, can be developed using one of two types of playing methods: turn-based and real-time. In real-time strategic (RTS) games with many characters like Warcraft and Chess, it is fun to play. However, fun decreases since the players have to focus on many points in the playing area. Hence, autonomous movement (AM), an assistant to move the character, can be one solution. An AM can be implemented using deep reinforcement learning (DRL), a new method that can continue to learn without erasing previously learned memory that makes AM better since it can adapt to the playing style. This paper describes the Royale Heroes, a unique RTS game that implements a DRL-based AM. First, a base model is created using a rule-based model based on conventional artificial intelligence (AI). Next, a DRL model is trained to imitate the behavior of previously created AI. Evaluation of six matches shows that the DRL provides high accuracy of up to 98% to copy a behavior. Hence, it can be used as an AM to help players make choices in playing the game. When the player plays this game, the model will continue learning to imitate the player behavior.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Driving transformation performance through innovation and experience model"
        ],
        "penulis":"Bawono, Marindra;Mihardjo, Leonardus W.W.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Innovation on business model is not only describing the bundle of products and services but also it is integrated with the input of customer experience. Customer experience should become a key role in developing business model innovation in driving transformational performance. This paper argues that the transformational performance is derived from business model innovation and focuses on customer experience. We use telecommunication firms as our unit analysis with sample of 195 Indonesian ICT firms out of 542 units. The analytical approach and solution technique that is used for analysis is Partial Least Square (PLS). The findings demonstrate that business model played significant role on supporting contribution of customer experience in driving transformational performance. The finding has implication that by synergizing the value proposition of customer experience in a business model innovation, the transformational performance can be maintained through focus on customer experience driven business model innovation. Further study can be explored through additional variable, sample and further study on longitudinal on digital transformation firms. \u00a9 2020 by the authors.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Innovation on business model is not only describing the bundle of products and services but also it is integrated with the input of customer experience. Customer experience should become a key role in developing business model innovation in driving transformational performance. This paper argues that the transformational performance is derived from business model innovation and focuses on customer experience. We use telecommunication firms as our unit analysis with sample of 195 Indonesian ICT firms out of 542 units. The analytical approach and solution technique that is used for analysis is Partial Least Square (PLS). The findings demonstrate that business model played significant role on supporting contribution of customer experience in driving transformational performance. The finding has implication that by synergizing the value proposition of customer experience in a business model innovation, the transformational performance can be maintained through focus on customer experience driven business model innovation. Further study can be explored through additional variable, sample and further study on longitudinal on digital transformation firms. \u00a9 2020 by the authors."
        ]
    },
    {
        "judul":[
            "Passive node-assisted wireless networks forming raptor codes with random access"
        ],
        "penulis":"Hendraningrat, Denny Kusuma;Ramatryana, I. Nyoman Apraz;Narottama, Bhaskara;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, wireless networks with passive nodes forming a pre-code of Raptor codes, also known as Raptor code-structured wireless networks (RCS-WN), are considered. In RCS-WN, the passive nodes utilize a decode-and-forward (DF) scheme and send the decoded data to the destination by using a scheduling scheme. We propose to deploy random access (RA) in passive nodes, to achieve a solution referred to as an RA-based RCS-WN (RAR-WN), and attempt to compare it with conventional wireless networks applying irregular repetition slotted ALOHA (IRSA). We investigate regular and irregular degree distributions for repetition codes to test the capacity of the proposed RAR-WN, using the extrinsic information transfer (EXIT) chart. This paper also examines the capabilities of the stopping set (both with regular and irregular degree distribution) in RAR-WN. Performance of the proposed system is evaluated in terms of EXIT chart, packet loss rate (PLR), and throughput. The results show that the proposed system is capable of achieving non-dropped throughput performance. \u00a9 2020 National Institute of Telecommunications. All rights reserved.",
            "ONHOOView detailsExpand Substance 1,3-benzoxazine-2,4-dione",
            "Powered by"
        ],
        "abstrak":[
            "In this paper, wireless networks with passive nodes forming a pre-code of Raptor codes, also known as Raptor code-structured wireless networks (RCS-WN), are considered. In RCS-WN, the passive nodes utilize a decode-and-forward (DF) scheme and send the decoded data to the destination by using a scheduling scheme. We propose to deploy random access (RA) in passive nodes, to achieve a solution referred to as an RA-based RCS-WN (RAR-WN), and attempt to compare it with conventional wireless networks applying irregular repetition slotted ALOHA (IRSA). We investigate regular and irregular degree distributions for repetition codes to test the capacity of the proposed RAR-WN, using the extrinsic information transfer (EXIT) chart. This paper also examines the capabilities of the stopping set (both with regular and irregular degree distribution) in RAR-WN. Performance of the proposed system is evaluated in terms of EXIT chart, packet loss rate (PLR), and throughput. The results show that the proposed system is capable of achieving non-dropped throughput performance. \u00a9 2020 National Institute of Telecommunications. All rights reserved."
        ]
    },
    {
        "judul":[
            "Prediction of Gross Domestic Product (GDP) in Indonesia Using Deep Learning Algorithm"
        ],
        "penulis":"Sa'adah, Siti;Wibowo, Muhammad Satrio;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Growth Domestic Product (GDP) is the important factor to know the stability of financial condition in a country. Regarding into GDP value could be known the economic condition per capita. Especially, during this pandemic situation, GDP need study further about its sudden fluctuation. The solution can be covered using the prediction approach. Deep learning as new method from machine learning schema had been observed in this research to cope the prediction of GDP problem. Two methods of deep learning techniques that were used, LSTM and RNN, shown that the prediction could fit the data actual very well. The accuracy at around 80% until 90% emerge from LSTM architecture 2 and RNN architecture 2. Based on this result, it could bring new perspective to use this model to know the GDP fluctuation in a country even in catastrophe of Covid-19.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Growth Domestic Product (GDP) is the important factor to know the stability of financial condition in a country. Regarding into GDP value could be known the economic condition per capita. Especially, during this pandemic situation, GDP need study further about its sudden fluctuation. The solution can be covered using the prediction approach. Deep learning as new method from machine learning schema had been observed in this research to cope the prediction of GDP problem. Two methods of deep learning techniques that were used, LSTM and RNN, shown that the prediction could fit the data actual very well. The accuracy at around 80% until 90% emerge from LSTM architecture 2 and RNN architecture 2. Based on this result, it could bring new perspective to use this model to know the GDP fluctuation in a country even in catastrophe of Covid-19.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A technical and economic analysis of solar PV with local tariff policy in Indonesia"
        ],
        "penulis":"Adam K.B.;Ramdhani M.;Suhartono E.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia is still struggling to attract investors in developing the solar photovoltaic (PV) project. The government issued the first regulation on solar PV, announced in 2016. A revision on the local tariff regulation is conducted to reduce the rapid development of the solar PV investment. The major revision is made to change the contract scheme from a build-operate-own (BOO) to a build-operate-own-transfer (BOOT) scheme. This paper investigates how the new local tariff will drive investors and developers to invest in solar PV. This analysis is conducted to know the effectiveness of the policy and the risk of PV investment in Indonesia. Local tariff policy regulation targets PV developers to invest in the solar PV system areas. In the local tariff policy, each area has its PV energy tariff determined by the government. This research proposes a method for deciding demand by considering population data in selected regions to calculate the maximum PV demand of each area. The Levelized Cost of Energy LCOE is used to calculate the economic viability of the PV projects in selected areas in Indonesia. The results show that more than half of the selected areas are profitable for the PV project. The average profit of the projects of the selected areas is 3.21 cent USD per kWh. Most of the areas that have high PV demand have lower local tariffs. Therefore, these areas may not be profitable for developers. The new regulation also cuts the revenue significantly due to the new scheme contract. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is still struggling to attract investors in developing the solar photovoltaic (PV) project. The government issued the first regulation on solar PV, announced in 2016. A revision on the local tariff regulation is conducted to reduce the rapid development of the solar PV investment. The major revision is made to change the contract scheme from a build-operate-own (BOO) to a build-operate-own-transfer (BOOT) scheme. This paper investigates how the new local tariff will drive investors and developers to invest in solar PV. This analysis is conducted to know the effectiveness of the policy and the risk of PV investment in Indonesia. Local tariff policy regulation targets PV developers to invest in the solar PV system areas. In the local tariff policy, each area has its PV energy tariff determined by the government. This research proposes a method for deciding demand by considering population data in selected regions to calculate the maximum PV demand of each area. The Levelized Cost of Energy LCOE is used to calculate the economic viability of the PV projects in selected areas in Indonesia. The results show that more than half of the selected areas are profitable for the PV project. The average profit of the projects of the selected areas is 3.21 cent USD per kWh. Most of the areas that have high PV demand have lower local tariffs. Therefore, these areas may not be profitable for developers. The new regulation also cuts the revenue significantly due to the new scheme contract. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Household energy usage pattern in 2200 VA"
        ],
        "penulis":"Abdurohman K.O.;Ekaputri C.;Aprillia B.S.;Nurfaidah Y.;Reza M.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Household energy usage is important for us to know because we can use the data for energy saving and prototyping solar system installation. We could see what the maximum usage is and reduce it. In this research, power data logger is made to see the total energy usage and will get result discrete graph. The result for household energy usage for 2200 VA will get 9,82kWh\/day. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Household energy usage is important for us to know because we can use the data for energy saving and prototyping solar system installation. We could see what the maximum usage is and reduce it. In this research, power data logger is made to see the total energy usage and will get result discrete graph. The result for household energy usage for 2200 VA will get 9,82kWh\/day. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Waiting Time Estimation of Hydrogen-Fuel Vehicles with YOLO Real-Time Object Detection"
        ],
        "penulis":"Fikri, Rifqi Muhammad;Kim, Byungwook;Hwang, Mintae;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Widespread use of fossil fuels as a source of energy leads to automobile emissions of CO2and other greenhouse gases (GHG) that plays a significant role in environmental pollution. A transition from fossil fuel to cleaner and more energy-efficient alternative fuel vehicles such as hydrogen fuel cell vehicles (FCVs), is a vital step in reducing the automobile emission. However, the insufficient charging stations and the long charging time compared to the conventional vehicles have to be overcome before hydrogen fuel-based vehicles can be fully adopted on a mass scale. This paper proposes a method that can count the approximate waiting time by using YOLO real-time object detection to detect how many hydrogen fuel-based vehicles are charging or queueing in the charging station. Therefore, the driver can choose the charging station that has minimal waiting time so that the insufficient charging stations and the long charging time can be managed. \u00a9 Springer Nature Singapore Pte Ltd 2020.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Widespread use of fossil fuels as a source of energy leads to automobile emissions of CO2and other greenhouse gases (GHG) that plays a significant role in environmental pollution. A transition from fossil fuel to cleaner and more energy-efficient alternative fuel vehicles such as hydrogen fuel cell vehicles (FCVs), is a vital step in reducing the automobile emission. However, the insufficient charging stations and the long charging time compared to the conventional vehicles have to be overcome before hydrogen fuel-based vehicles can be fully adopted on a mass scale. This paper proposes a method that can count the approximate waiting time by using YOLO real-time object detection to detect how many hydrogen fuel-based vehicles are charging or queueing in the charging station. Therefore, the driver can choose the charging station that has minimal waiting time so that the insufficient charging stations and the long charging time can be managed. \u00a9 Springer Nature Singapore Pte Ltd 2020."
        ]
    },
    {
        "judul":[
            "Performance assessment analysis of UHF machines using Reliability, Availability, Maintainability and Safety (RAMS) analysis methods"
        ],
        "penulis":"Nurrahman F.;Atmaji F.T.D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "XYZ Company is manufacturing engaged in the rubber industry located in the city of Bandung, because economic growth and demand from consumers are increasing, making companies demanded to meet the target orders promptly. One way to minimize losses and the possibilities that must be borne by the company is to increase Reliability, Availability, Maintainability of the production and the safety value. Data in the form of Mean Downtime, Mean Time to Failure, Mean Time to Repair is useful for system performance that works. MTTF data can be used to assess safety systems found in PT XYZ with the safety standards of IEC 61508 using Safety Integrity Level. From the results of processing RAMS data using Reliability Block Diagram modeling based on the analytical approach, for 120 hours, the system has a Reliability value (91.12%). The average value of system Maintainability at t = 2 hours is 100%. The Inherent Availability value is 99,981% and the Operational Availability value is 99,980%. Based on the world-class maintenance Key Performace Indicator, leading and lagging availability indicators have reached the indicator target standard. Safety Integrity Level values from calculations based on PFD and RRF values of each system are in SIL 1. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "XYZ Company is manufacturing engaged in the rubber industry located in the city of Bandung, because economic growth and demand from consumers are increasing, making companies demanded to meet the target orders promptly. One way to minimize losses and the possibilities that must be borne by the company is to increase Reliability, Availability, Maintainability of the production and the safety value. Data in the form of Mean Downtime, Mean Time to Failure, Mean Time to Repair is useful for system performance that works. MTTF data can be used to assess safety systems found in PT XYZ with the safety standards of IEC 61508 using Safety Integrity Level. From the results of processing RAMS data using Reliability Block Diagram modeling based on the analytical approach, for 120 hours, the system has a Reliability value (91.12%). The average value of system Maintainability at t = 2 hours is 100%. The Inherent Availability value is 99,981% and the Operational Availability value is 99,980%. Based on the world-class maintenance Key Performace Indicator, leading and lagging availability indicators have reached the indicator target standard. Safety Integrity Level values from calculations based on PFD and RRF values of each system are in SIL 1. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "NB-IoT Network Planning for Advanced Metering Infrastructure in Surabaya, Sidoarjo, and Gresik"
        ],
        "penulis":"Nashiruddin, Muhammad Imam;Purnama, Arrizky Ayu Faradila;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Narrow Band Internet of Things (NB-IoT) technology is one of the Low Power Wide Area (LPWA) technologies with low cost, low power consumption, and wide range connectivity. NB-IoT is supported by cellular networks or Long-Term Evolution (LTE) with 3GPP Release 13 standard, making NB-IoT becomes an appropriate technology for the development and needs of the Internet of Things (IoT). Connectivity is needed to guarantee the service connection, in which one of the technologies is Narrow Band Internet of Things (NB-IoT). As an example of the NB-IoT rollout in urban areas, the study conducted the network design and analysis for AMI (Advanced Metering Infrastructure) in cities of Surabaya, Sidoarjo, and Gresik. The study result indicates that both coverage and capacity of the gateway requirements for Internet of Things (IoT) network planning using NB-IoT are 20 sites for the Surabaya area, 7 sites for the Sidoarjo area, and 5 sites for the Gresik area. Based on the simulations undertaken, the average acceptable signal levels are -57.9dBm for Surabaya, 59.62 dBm for Sidoarjo, and -58.71dBm for Gresik. And for Received Signal Strength Indicator (RSSI) value or sensitivity at the receiver for the three regions, the above standard sensitivity value for NB-IoT is -141dBm, while the minimum sensitivity value for the Surabaya, Sidoarjo and Gresik areas are -100dBm, -104dBm, and -105dBm. The study results also show different network planning parameters although it was planned in the same urban area and using the same capacity per cell approach model. It is possible to happen because of different environmental conditions, different number of users and different coverage areas in each urban city.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Narrow Band Internet of Things (NB-IoT) technology is one of the Low Power Wide Area (LPWA) technologies with low cost, low power consumption, and wide range connectivity. NB-IoT is supported by cellular networks or Long-Term Evolution (LTE) with 3GPP Release 13 standard, making NB-IoT becomes an appropriate technology for the development and needs of the Internet of Things (IoT). Connectivity is needed to guarantee the service connection, in which one of the technologies is Narrow Band Internet of Things (NB-IoT). As an example of the NB-IoT rollout in urban areas, the study conducted the network design and analysis for AMI (Advanced Metering Infrastructure) in cities of Surabaya, Sidoarjo, and Gresik. The study result indicates that both coverage and capacity of the gateway requirements for Internet of Things (IoT) network planning using NB-IoT are 20 sites for the Surabaya area, 7 sites for the Sidoarjo area, and 5 sites for the Gresik area. Based on the simulations undertaken, the average acceptable signal levels are -57.9dBm for Surabaya, 59.62 dBm for Sidoarjo, and -58.71dBm for Gresik. And for Received Signal Strength Indicator (RSSI) value or sensitivity at the receiver for the three regions, the above standard sensitivity value for NB-IoT is -141dBm, while the minimum sensitivity value for the Surabaya, Sidoarjo and Gresik areas are -100dBm, -104dBm, and -105dBm. The study results also show different network planning parameters although it was planned in the same urban area and using the same capacity per cell approach model. It is possible to happen because of different environmental conditions, different number of users and different coverage areas in each urban city.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Data-Driven of Time Series Decomposition on Estimating Geodetic Secular Motion around Palu- Koro Fault Zone"
        ],
        "penulis":"Pratama, Cecep;Meilano, Irwan;Sunarti, Euis;Haksama, Setya;Sulistiyo, Mahmud Dwi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The 2018 Mw 7.5 Palu earthquake occurred along the Palu-Koro segment devastated Central Sulawesi, Indonesia. The Palu-Koro fault is considered as a plate boundaries between of three major tectonic plates. Couples space geodesy measurement has been conducted to characterize the crustal activity of the Palu-Koro fault based on secular velocities pattern. However, several non-secular deformation observed and need to be considered to obtained actual secular deformation. Here, we conducted data-driven time series decomposition of Global Positioning System (GPS) observation. We used earthquake catalogue data to drive decomposition recognize the co-seismic offset and respective post-seismic deformation. We obtained precise secular motion on WATP, P14P, PALP, and TOBP sites where the direction changing from eastward toward northeast.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The 2018 Mw 7.5 Palu earthquake occurred along the Palu-Koro segment devastated Central Sulawesi, Indonesia. The Palu-Koro fault is considered as a plate boundaries between of three major tectonic plates. Couples space geodesy measurement has been conducted to characterize the crustal activity of the Palu-Koro fault based on secular velocities pattern. However, several non-secular deformation observed and need to be considered to obtained actual secular deformation. Here, we conducted data-driven time series decomposition of Global Positioning System (GPS) observation. We used earthquake catalogue data to drive decomposition recognize the co-seismic offset and respective post-seismic deformation. We obtained precise secular motion on WATP, P14P, PALP, and TOBP sites where the direction changing from eastward toward northeast.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Developing a quality metric in controlling the project task"
        ],
        "penulis":"Novitiara, Indriana;Pratami, Devi;Fuad Bay, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In several telecommunication projects, during the monitoring and controlling phases, the quality control and validate scope processes only rely on the receipt test form and handover minutes. Whereas quality errors, in general, can only be seen in the final project phase. If the project deliverables do not meet the customer requirement, the rework must be done or the worst possibility is that the project must be stopped. A quality metric using the internal control method is a project document that can be used to prevent possible problems. There is a quality metric template from previous research proposed for telecommunication projects, but the factors used as variable critical success criteria have not included other important factors that support project success. Therefore, this study will discuss the development of an existing quality metric template and what processes will be affected by the use of this quality metric in a project. It was found that procedures and human factors are critical success factors that can support project success, and quality metrics have an impact on the quality control process and validate scope. It can be concluded that this study produces a quality metric template that has been developed and this quality metric can be used as a template for other projects such as construction projects or IT projects. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In several telecommunication projects, during the monitoring and controlling phases, the quality control and validate scope processes only rely on the receipt test form and handover minutes. Whereas quality errors, in general, can only be seen in the final project phase. If the project deliverables do not meet the customer requirement, the rework must be done or the worst possibility is that the project must be stopped. A quality metric using the internal control method is a project document that can be used to prevent possible problems. There is a quality metric template from previous research proposed for telecommunication projects, but the factors used as variable critical success criteria have not included other important factors that support project success. Therefore, this study will discuss the development of an existing quality metric template and what processes will be affected by the use of this quality metric in a project. It was found that procedures and human factors are critical success factors that can support project success, and quality metrics have an impact on the quality control process and validate scope. It can be concluded that this study produces a quality metric template that has been developed and this quality metric can be used as a template for other projects such as construction projects or IT projects. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Simulated Annealing-Support Vector Machine on QSAR Study of Fusidic Acid Derivatives as Anti-Malarial Agent"
        ],
        "penulis":"Rahman, Farisi;Lhaksmana, Kemas Muslim;Kurniawan, Isman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Malaria is a disease caused by the Plasmodium falciparum parasite and leads to many cases of deaths. Recently, the combination of several drugs has been used to treat this disease. However, the parasite is known to be resistant to the anti-malarial agent. Hence, a new candidate for an anti-malarial drug is required to solve the resistance problem. One compound that is promising as an anti-malarial agent is fusidic acid derivatives. Fusidic acid is an antibiotic that is work by preventing parasite growth. Besides, fusidic acid is known to have antiplasmodial activity although the IC50 is still poor. However, the activity can be improved by optimizing the structure through its derivatives. In this study, we developed a QSAR model to predict the activity of fusidic acid derivatives as anti-malarial agent. The model was developed by using Simulated Annealing (SA) for feature selection and Support Vector Machine (SVM) for model development. The results show that SA produces a satisfying combination of features that are indicated by the trend of MSE value during the selection process. Regarding the performance, SVM with RBF kernel produces the best result of the validation parameter. This indicates that the model is valid to be used to predict a compound with unknown activity values for anti-malarial agents.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Malaria is a disease caused by the Plasmodium falciparum parasite and leads to many cases of deaths. Recently, the combination of several drugs has been used to treat this disease. However, the parasite is known to be resistant to the anti-malarial agent. Hence, a new candidate for an anti-malarial drug is required to solve the resistance problem. One compound that is promising as an anti-malarial agent is fusidic acid derivatives. Fusidic acid is an antibiotic that is work by preventing parasite growth. Besides, fusidic acid is known to have antiplasmodial activity although the IC50 is still poor. However, the activity can be improved by optimizing the structure through its derivatives. In this study, we developed a QSAR model to predict the activity of fusidic acid derivatives as anti-malarial agent. The model was developed by using Simulated Annealing (SA) for feature selection and Support Vector Machine (SVM) for model development. The results show that SA produces a satisfying combination of features that are indicated by the trend of MSE value during the selection process. Regarding the performance, SVM with RBF kernel produces the best result of the validation parameter. This indicates that the model is valid to be used to predict a compound with unknown activity values for anti-malarial agents.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Bandwidth limit and synthesis approach for single resonance ultrathin metasurfaces"
        ],
        "penulis":"Fathnan, Ashif A.;Olk, Andreas E.;Powell, David A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Metasurfaces have emerged as a promising technology for the manipulation of electromagnetic waves within a thin layer. In planar ultrathin metasurfaces, there exist rigorous design methods, based on the equivalent surface impedance of patterned metallic layers on dielectric substrates. In this work, we derive a limit on bandwidth achievable in these metasurfaces, based on constraints that their meta-atoms should be passive, causal and lossless and that they should obey the time-bandwidth product rules of a single resonance structure. The results show that in addition to elementary design parameters involving variation of the surface impedance, the bandwidth is critically limited by the dielectric substrate thickness and permittivity. We then propose a synthesis method for broadband ultrathin metasurfaces, based on an LC resonance fit of the required surface impedance and experimentally verify a broadband dispersive structure at millimeter-wave frequencies. This results in a bandwidth enhancement of over 90%, relative to a reference metasurface created with the narrowband design process. \u00a9 2020 IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Metasurfaces have emerged as a promising technology for the manipulation of electromagnetic waves within a thin layer. In planar ultrathin metasurfaces, there exist rigorous design methods, based on the equivalent surface impedance of patterned metallic layers on dielectric substrates. In this work, we derive a limit on bandwidth achievable in these metasurfaces, based on constraints that their meta-atoms should be passive, causal and lossless and that they should obey the time-bandwidth product rules of a single resonance structure. The results show that in addition to elementary design parameters involving variation of the surface impedance, the bandwidth is critically limited by the dielectric substrate thickness and permittivity. We then propose a synthesis method for broadband ultrathin metasurfaces, based on an LC resonance fit of the required surface impedance and experimentally verify a broadband dispersive structure at millimeter-wave frequencies. This results in a bandwidth enhancement of over 90%, relative to a reference metasurface created with the narrowband design process. \u00a9 2020 IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Ethnomedicinal study of medicinal plants used against infectious disease by muna tribe of South-East Sulawesi, Indonesia"
        ],
        "penulis":"Himaniarwati;Saleh, Ahmad;Yuliastri, Wa Ode;Isrul, Muhammad;Pusmarani, Jastria;Juliansyah, Risky;Dewi, Citra;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The Aim of the present study was to document ethnomedicinal plants used to treat Infectious diseases by Muna Tribe in South-East Sulawesi, Indonesia. Ethnomedicinal data was collected by participant observation and open and semi-structured interviews to collect information from local healers who are native in the study area. Ten male key informants described 26 plant species belong to 20 Families, which are used as herbal medicine for Infections. The medicinal plants have been reported for their antibacterial, antiviral, and antifungal properties. The families of Cucurbitaceae, Fabaceae, Malvaceae, Meliaceae, and Moraceae comprised of 46 % of all the plants documented. For the majoririty of the plants, the were commonly used part were leaves (55%), followed by fruits (16%), stems (13%), rhizomes and roots (6%), and flowers (3%). The data could be used as a basis for further studies on medicinal plants for future phytochemical and pharmacological studies. \u00a9 RJPT All right reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Aim of the present study was to document ethnomedicinal plants used to treat Infectious diseases by Muna Tribe in South-East Sulawesi, Indonesia. Ethnomedicinal data was collected by participant observation and open and semi-structured interviews to collect information from local healers who are native in the study area. Ten male key informants described 26 plant species belong to 20 Families, which are used as herbal medicine for Infections. The medicinal plants have been reported for their antibacterial, antiviral, and antifungal properties. The families of Cucurbitaceae, Fabaceae, Malvaceae, Meliaceae, and Moraceae comprised of 46 % of all the plants documented. For the majoririty of the plants, the were commonly used part were leaves (55%), followed by fruits (16%), stems (13%), rhizomes and roots (6%), and flowers (3%). The data could be used as a basis for further studies on medicinal plants for future phytochemical and pharmacological studies. \u00a9 RJPT All right reserved."
        ]
    },
    {
        "judul":[
            "Brand analysis study of international women university and the implementation strategy to the social media communication"
        ],
        "penulis":"Narimawati, Umi;Gracia, Amanda Bunga;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The IWU brand value analysis was carried out using a qualitative method and a quantitative method applied to observe the basic information about the type of social networks they use most, time consumption and their attitude towards the support of celebrities. Three series of questions were asked about the consumption of digital media. 3 different groups were chosen to survey, such as potential students (high school students), parents and alumni, with a total of 30 people. These 3 different groups of respondents have similarities in perceiving that IWU is distinctive and unique and also recognized the international program offered by IWU. \u00a9 2020, Universidad del Zulia. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The IWU brand value analysis was carried out using a qualitative method and a quantitative method applied to observe the basic information about the type of social networks they use most, time consumption and their attitude towards the support of celebrities. Three series of questions were asked about the consumption of digital media. 3 different groups were chosen to survey, such as potential students (high school students), parents and alumni, with a total of 30 people. These 3 different groups of respondents have similarities in perceiving that IWU is distinctive and unique and also recognized the international program offered by IWU. \u00a9 2020, Universidad del Zulia. All rights reserved."
        ]
    },
    {
        "judul":[
            "Preliminary Study for identifying Rice Plant Disease Based on Thermal Images"
        ],
        "penulis":"Silvi Lydia, Maya;Aulia, Indra;Jaya, Ivan;Sofiah Hanafiah, Diana;Hakim Lubis, Rizky;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Accurate and timely identification of plant disease can help stakeholders and farmers to mitigate losses due to pests and diseases. One of the identification techniques is indirect detection using thermal imaging technology. This technology has been considered a fast way without damaging the profile of a plant. In this paper, we describe the preliminary study of the thermal images gathering, so that the rice plant disease on the leaf canopy can be identified by using a thermal imaging camera. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Accurate and timely identification of plant disease can help stakeholders and farmers to mitigate losses due to pests and diseases. One of the identification techniques is indirect detection using thermal imaging technology. This technology has been considered a fast way without damaging the profile of a plant. In this paper, we describe the preliminary study of the thermal images gathering, so that the rice plant disease on the leaf canopy can be identified by using a thermal imaging camera. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Monitoring floating solar tracker based on axis coordinates using lora network"
        ],
        "penulis":"Fernandez, Abyan Arief;Rakhmatsyah, Andrian;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research aimed to build a solar tracker for a floating solar panel and used long\u2013range (LoRa) communication to harvest energy and monitor its process. With the rising demand for renewable energy in these recent years especially for solar energy, it needs to meet this demand to remain relevant for the upcoming years where it will have an even larger impact as we shift into clean energy. Monitoring single\u2013axis solar trackers on rural areas difficult and cost\u2013intensive. The purpose of a floating solar farm is to reduce the cost from buying\/renting land. Floating solar panels cannot be monitored using wired because they are moving nodes in the water, it makes wired installation complicated. Hence, using wireless sensor network is a solution that allows remote monitoring of floating solar panels in rural areas and makes moving nodes mentioned above possible. Testing was performed by sending 100 packets from the node to its gateway using LoRa modulation, and the gateway successfully received about 90% of the packets sent by the node. The vertical single-axis solar tracker used in floating solar managed to get 17% more energy than the fixed solar with a more stable income for the whole duration of sending 100 packets. \u00a9 2020. CBIORE-IJRED. All rights reserved.",
            "ClOClOSOOONaView detailsExpand Substance sodium 2-(2,4-dichlorophenoxy)ethyl sulfate",
            "Powered by",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research aimed to build a solar tracker for a floating solar panel and used long\u2013range (LoRa) communication to harvest energy and monitor its process. With the rising demand for renewable energy in these recent years especially for solar energy, it needs to meet this demand to remain relevant for the upcoming years where it will have an even larger impact as we shift into clean energy. Monitoring single\u2013axis solar trackers on rural areas difficult and cost\u2013intensive. The purpose of a floating solar farm is to reduce the cost from buying\/renting land. Floating solar panels cannot be monitored using wired because they are moving nodes in the water, it makes wired installation complicated. Hence, using wireless sensor network is a solution that allows remote monitoring of floating solar panels in rural areas and makes moving nodes mentioned above possible. Testing was performed by sending 100 packets from the node to its gateway using LoRa modulation, and the gateway successfully received about 90% of the packets sent by the node. The vertical single-axis solar tracker used in floating solar managed to get 17% more energy than the fixed solar with a more stable income for the whole duration of sending 100 packets. \u00a9 2020. CBIORE-IJRED. All rights reserved."
        ]
    },
    {
        "judul":[
            "Attendance system using machine learning-based face detection for meeting room application"
        ],
        "penulis":"Muttaqin, Rahmat;Nopendri;Fuada, Syifaul;Mulyana, Eueung;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In a modern meeting room, a smart system to make attendance quickly is mandatory. Most of the existing systems perform manual attendance, such as registration and fingerprint. Despite the fingerprint method can reject the Unknown person and give the grant access to the Known person, it will take time to register first a person one-by-one. Moreover, it is possible to create long queues for fingerprint checking before entering the meeting room. Machine learning, along with the Internet of Things (IoT) technology is the best solution; it offers many advantages when applied in the meeting rooms. Generally, the method used is to create a presence by detecting faces. In this paper, we present a facial recognition authentication based on machine learning technology for connection to the meeting rooms. Furthermore, specific website to display the detection result and data storage design testing is developed. The method uses 1) the Dlib library for deep learning purposes, 2) OpenCV for video camera processing, and 3) Face Recognition for Dlib processing. The proposed system allows placing the multiple cameras in a meeting room as needed. However, in this work, we only used one camera as the main system. Tests conducted include identification of one Known person, identification of one Unknown person, identification of two people, and three people. The parameter to be focused is the required time in detecting the number of faces recorded by the camera. The results reveal that the face can be recognized or not recognized, then it will be displayed on the website. \u00a9 2020, Science and Information Organization.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a modern meeting room, a smart system to make attendance quickly is mandatory. Most of the existing systems perform manual attendance, such as registration and fingerprint. Despite the fingerprint method can reject the Unknown person and give the grant access to the Known person, it will take time to register first a person one-by-one. Moreover, it is possible to create long queues for fingerprint checking before entering the meeting room. Machine learning, along with the Internet of Things (IoT) technology is the best solution; it offers many advantages when applied in the meeting rooms. Generally, the method used is to create a presence by detecting faces. In this paper, we present a facial recognition authentication based on machine learning technology for connection to the meeting rooms. Furthermore, specific website to display the detection result and data storage design testing is developed. The method uses 1) the Dlib library for deep learning purposes, 2) OpenCV for video camera processing, and 3) Face Recognition for Dlib processing. The proposed system allows placing the multiple cameras in a meeting room as needed. However, in this work, we only used one camera as the main system. Tests conducted include identification of one Known person, identification of one Unknown person, identification of two people, and three people. The parameter to be focused is the required time in detecting the number of faces recorded by the camera. The results reveal that the face can be recognized or not recognized, then it will be displayed on the website. \u00a9 2020, Science and Information Organization."
        ]
    },
    {
        "judul":[
            "Smart Safe Prototype Based Internet of Things (IoT) with Face and Fingerprint Recognition"
        ],
        "penulis":"Setyadi, Ramadhan Rizki;Istikmal;Irawan, Arif Indra;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The safe box is currently considered safe but is not truly safe. That is because safe storage has a security method using PINs that can be seen by others. Therefore, a more secure safe box security system is needed. This paper purpose a safe box prototype with an added security system using a two-way verification system and an integrated Internet of Things (IoT) system. The face recognition system and fingerprint system used in this system. The face recognition system developed an LBP (Local Binary Pattern) clarification and embedded Haar cascade program in raspberry Pi. For real-time monitoring, the safe box has been designed to provide violation alerts via notifications on android apps. Two-way verification smart safe box has a good face recognition system especially when the conditions are bright and also the best way to identify fingerprints on a flat position. In LOS conditions, the best distance is at 4 meters with a delay value of 0.373 s and throughput of 3680.533 bps. In non-LOS condition, the best distance is 2 meters with a delay value of 0.380 seconds and throughput of 4055.73 bytes\/s.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The safe box is currently considered safe but is not truly safe. That is because safe storage has a security method using PINs that can be seen by others. Therefore, a more secure safe box security system is needed. This paper purpose a safe box prototype with an added security system using a two-way verification system and an integrated Internet of Things (IoT) system. The face recognition system and fingerprint system used in this system. The face recognition system developed an LBP (Local Binary Pattern) clarification and embedded Haar cascade program in raspberry Pi. For real-time monitoring, the safe box has been designed to provide violation alerts via notifications on android apps. Two-way verification smart safe box has a good face recognition system especially when the conditions are bright and also the best way to identify fingerprints on a flat position. In LOS conditions, the best distance is at 4 meters with a delay value of 0.373 s and throughput of 3680.533 bps. In non-LOS condition, the best distance is 2 meters with a delay value of 0.380 seconds and throughput of 4055.73 bytes\/s.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design of green ERP system reverse logistic module based on odoo in leather tanning industry"
        ],
        "penulis":"Arifin, Hennry Syahreza;Ridwan, Ari Yanuar;Saputra, Muhardi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Rise of the leather industry in Indonesia since 2018 makes this industry more visible to the market. Along with the increasing development of leather industry, waste that generated will naturally increase. PT. ELCO Indonesia Sejahtera as a company engaged in leather tanning industry (sheep and goat skin) experienced an increase of waste, from the production process and returned products. Currently PT. ELCO Indonesia Sejahtera still input returned products data manually and still have no system integration to manage business process in company. This condition causes company to view asynchronous data for returned products in inventory and company still have no monitoring process for type of products and routing that often occurs error. To solve those problems, management for returned products needs to be done through system due to view data in real-time and have a more optimal monitoring process. The system based on Green Enterprise Resource Planning (ERP) with Odoo application by applying reverse logistics concept which aims to manage waste from returned products. This research uses SAP Activate methodology for designing system. The results in this study is system can integrate repair module with other modules such as inventory and manufacturing. And to improve business workflow in the company, reverse logistic module produces monitoring reports in the form of transaction document and graph. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rise of the leather industry in Indonesia since 2018 makes this industry more visible to the market. Along with the increasing development of leather industry, waste that generated will naturally increase. PT. ELCO Indonesia Sejahtera as a company engaged in leather tanning industry (sheep and goat skin) experienced an increase of waste, from the production process and returned products. Currently PT. ELCO Indonesia Sejahtera still input returned products data manually and still have no system integration to manage business process in company. This condition causes company to view asynchronous data for returned products in inventory and company still have no monitoring process for type of products and routing that often occurs error. To solve those problems, management for returned products needs to be done through system due to view data in real-time and have a more optimal monitoring process. The system based on Green Enterprise Resource Planning (ERP) with Odoo application by applying reverse logistics concept which aims to manage waste from returned products. This research uses SAP Activate methodology for designing system. The results in this study is system can integrate repair module with other modules such as inventory and manufacturing. And to improve business workflow in the company, reverse logistic module produces monitoring reports in the form of transaction document and graph. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Optimization of Phishing Website Classification Based on Synthetic Minority Oversampling Technique and Feature Selection"
        ],
        "penulis":"Prayogo, Rizal Dwi;Karimah, Siti Amatullah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents a new approach for optimizing phishing website classification based on Synthetic Minority Oversampling Technique (SMOTE) together with feature selection. Classification is a kind of supervised machine learning technique that learns based on the features to identify the class. However, not all features are relevant to identify phishing websites and the class imbalance problem leads to suboptimal performances. Therefore, we propose SMOTE for handling the class imbalance problem by generating new synthetic instances for the minority class. Filter-based feature selection using Information Gain and Correlation are proposed for reducing irrelevant features. The classification performances are evaluated using K-Nearest Neighbor (KNN) classifier. The results demonstrate that SMOTE effectively increases the classification performances in terms of accuracy, precision, recall, and F-measure with more time-efficient. The performance of SMOTE combined with feature selection is validated and benchmarked with different techniques both on full features and reduced features. The results demonstrate that our proposed technique presents the highest accuracy, i.e. 97.47% on full features and 94.87% on reduced features. Hence, our proposed technique is promising in optimizing phishing website classification.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents a new approach for optimizing phishing website classification based on Synthetic Minority Oversampling Technique (SMOTE) together with feature selection. Classification is a kind of supervised machine learning technique that learns based on the features to identify the class. However, not all features are relevant to identify phishing websites and the class imbalance problem leads to suboptimal performances. Therefore, we propose SMOTE for handling the class imbalance problem by generating new synthetic instances for the minority class. Filter-based feature selection using Information Gain and Correlation are proposed for reducing irrelevant features. The classification performances are evaluated using K-Nearest Neighbor (KNN) classifier. The results demonstrate that SMOTE effectively increases the classification performances in terms of accuracy, precision, recall, and F-measure with more time-efficient. The performance of SMOTE combined with feature selection is validated and benchmarked with different techniques both on full features and reduced features. The results demonstrate that our proposed technique presents the highest accuracy, i.e. 97.47% on full features and 94.87% on reduced features. Hence, our proposed technique is promising in optimizing phishing website classification.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Assembly line balancing using genetic algorithm method to minimize number of working stations: A case study in car manufacturing"
        ],
        "penulis":"Damayanti, Dida Diah;Astuti, Murni Dwi;Setyawan, Erlangga Bayu;Ramdani, Arif Faisal;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this competitive era, there are no more manufacturing organizations that want to produce products in large volumes with low variations. The company is now shifting toward the idea of producing more variations that are of interest to consumers. Increased demand and production targets cannot be avoided. however, the increase must be adjusted to the worker's resources according to their function. If it is not balanced, it will cause a bottleneck on the production flow caused by the operating time at a workstation exceeding the takt time. then we need to balance the assembly line to get optimum and efficient results. Assembly line balancing (ALB) is used to flatten workload on all processes in a cell or value stream to eliminate bottlenecks and excess capacity, with a limitation of slowing down process time and excess capacity. The completion of this case study uses a combination of Priority Rule-Based\/heuristic methods and Genetic Algorithm methods. \u00a9 2020 IOP Conference Series: Materials Science and Engineering.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this competitive era, there are no more manufacturing organizations that want to produce products in large volumes with low variations. The company is now shifting toward the idea of producing more variations that are of interest to consumers. Increased demand and production targets cannot be avoided. however, the increase must be adjusted to the worker's resources according to their function. If it is not balanced, it will cause a bottleneck on the production flow caused by the operating time at a workstation exceeding the takt time. then we need to balance the assembly line to get optimum and efficient results. Assembly line balancing (ALB) is used to flatten workload on all processes in a cell or value stream to eliminate bottlenecks and excess capacity, with a limitation of slowing down process time and excess capacity. The completion of this case study uses a combination of Priority Rule-Based\/heuristic methods and Genetic Algorithm methods. \u00a9 2020 IOP Conference Series: Materials Science and Engineering."
        ]
    },
    {
        "judul":[
            "Semi-ensemble learning using neural network for classifying traffic condition"
        ],
        "penulis":"Nasution, Surya Michrandi;Husni, Emir;Yusuf, Rahadian;Kuspriyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The growth of technology aims to help human's activity. One of human's activity which could use technology is in the transportation area by implementing machine learning. This paper discusses the semi-ensemble method for classifying traffic condition, which could be used to classify the traffic condition for shorten travel time in the road. Semi-ensemble that applied is using voting system which consists of several neural networks. The proposed method in this paper gives better performance result than single neural network Even though the performance result is not increased significantly, enhancement in semi-ensemble with voting system which comes from best-5 performance neural networks also give better result than voting system using 10 neural networks. The performance increased from 82.58% to 82.81% for its accuracy and the rests of performance value increased from 65.09% to 65.62%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The growth of technology aims to help human's activity. One of human's activity which could use technology is in the transportation area by implementing machine learning. This paper discusses the semi-ensemble method for classifying traffic condition, which could be used to classify the traffic condition for shorten travel time in the road. Semi-ensemble that applied is using voting system which consists of several neural networks. The proposed method in this paper gives better performance result than single neural network Even though the performance result is not increased significantly, enhancement in semi-ensemble with voting system which comes from best-5 performance neural networks also give better result than voting system using 10 neural networks. The performance increased from 82.58% to 82.81% for its accuracy and the rests of performance value increased from 65.09% to 65.62%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Optimization of rice husk ash (Rha) as partial replacement of cementing material in structural ceramic composite concrete using response surface methodology (rsm) statistical experimental design"
        ],
        "penulis":"Fazli, Aliff Akhmal Mohd;Zakaria, Siti Koriah;Rahman, Nur Iman Najwa Abd;Salleh, Siti Zuliana;Yusoff, Abdul Hafidz;Salleh, Nurul Azita;Taib, Mustaffa Ali Azhar;Budiman, Faisal;Ali, Arlina;Teo, Pao Ter;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Rapid development in the concrete industry leads to a higher demand for cement consumption worldwide. Due to this, the production of cement has become very crucial, resulting in a high carbon footprint and pollution along the process. Therefore, the utilization of agricultural by-products as cement replacement will help to reduce pollution caused by conventional cement production and therefore reduce the unsystematic waste management. Rice husk ash contains high silica content that makes it a potential material to partially replace cement in concrete production. This is because, the reaction between rice husk ash and cement can improve the compressive strength of the concrete. With the aid of response surface methodology, the optimization of utilizing rice husk ash as a partial replacement of cement in concrete can be achieved. Therefore, concrete incorporated with rice husk ash with high and optimum compressive strength can be produced. \u00a9 2020, Hanyang University. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rapid development in the concrete industry leads to a higher demand for cement consumption worldwide. Due to this, the production of cement has become very crucial, resulting in a high carbon footprint and pollution along the process. Therefore, the utilization of agricultural by-products as cement replacement will help to reduce pollution caused by conventional cement production and therefore reduce the unsystematic waste management. Rice husk ash contains high silica content that makes it a potential material to partially replace cement in concrete production. This is because, the reaction between rice husk ash and cement can improve the compressive strength of the concrete. With the aid of response surface methodology, the optimization of utilizing rice husk ash as a partial replacement of cement in concrete can be achieved. Therefore, concrete incorporated with rice husk ash with high and optimum compressive strength can be produced. \u00a9 2020, Hanyang University. All rights reserved."
        ]
    },
    {
        "judul":[
            "Indonesian Phonemicization Model Using N-Gram-Based Bidirectional Long Short-Term Memory"
        ],
        "penulis":"Ramadhelza, Ari Wilyan;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Building a phonemic model of words is a description of a function in mapping the spelling of words to a series of phonetic symbols that represent the pronunciation of the word. The conversion of spelled symbols (grapheme) into pronunciation symbols (phoneme) is very dependent on the characteristics of the language being reviewed. Basically, the word phonemicization is the same as a grapheme-to-phoneme (G2P) conversion. A language in general has a grapheme-to-phoneme conversion system that is different from other languages. The speech synthesis system from text needs to be done in the process of converting graphemes into phonemes, so a G2P is needed here. A widely used implementation of the grapheme-to-phoneme conversion system is a rule-based conversion system. Rule-based can be established through a variety of techniques and methods. The conversion of graphemes into phonemes will represent the mapping of each grapheme or spelling symbol in any word to the phonemic representation or pronunciation symbol. One of the method that can be used is deep learning algorithm. In this paper, a word phonemicization model is developed using a bidirectional long short-term memory (BLSTM). A rule-based re-optimization procedure is proposed to enhance the model. An evaluation of a dataset of 50 k Indonesian formal words shows that the proposed model gives a word error rate (WER) of 0.73%, which is much lower than all previous models. The errors are mostly caused by converting grapheme [removed].  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Building a phonemic model of words is a description of a function in mapping the spelling of words to a series of phonetic symbols that represent the pronunciation of the word. The conversion of spelled symbols (grapheme) into pronunciation symbols (phoneme) is very dependent on the characteristics of the language being reviewed. Basically, the word phonemicization is the same as a grapheme-to-phoneme (G2P) conversion. A language in general has a grapheme-to-phoneme conversion system that is different from other languages. The speech synthesis system from text needs to be done in the process of converting graphemes into phonemes, so a G2P is needed here. A widely used implementation of the grapheme-to-phoneme conversion system is a rule-based conversion system. Rule-based can be established through a variety of techniques and methods. The conversion of graphemes into phonemes will represent the mapping of each grapheme or spelling symbol in any word to the phonemic representation or pronunciation symbol. One of the method that can be used is deep learning algorithm. In this paper, a word phonemicization model is developed using a bidirectional long short-term memory (BLSTM). A rule-based re-optimization procedure is proposed to enhance the model. An evaluation of a dataset of 50 k Indonesian formal words shows that the proposed model gives a word error rate (WER) of 0.73%, which is much lower than all previous models. The errors are mostly caused by converting grapheme [removed].  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Digital learning challenge in Indonesia"
        ],
        "penulis":"Prasetio, Adhi;Anggadwita, Grisna;Pasaribu, Rina D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Industry Education Reform 4.0 was launched by the Indonesian government as one of nine priority agendas called Nawa Cita. The reform consists of two main programs: first, to improve the quality of life of Indonesian people through improving the quality of education and training and, second, to revolutionize the nation's character through the policy of restructuring the national education curriculum. There are challenges though to implement those programs including Indonesian geographic, gap to access different level of education, and the gap to achieve the Industrial Revolution 4.0 skills. The aims of this chapter are to explore alternatives and solutions for access to education in Indonesia by utilizing technological advancements including the skills needed to face the current digital era. Education 4.0 is a good approach to answer those challenges. The use of internet technology for digital learning can provide access to students spread across the country. This approach requires skills set that are appropriate to Industry 4.0 by providing a flexible curriculum and online certification. \u00a9 2021, IGI Global.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Industry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industry Education Reform 4.0 was launched by the Indonesian government as one of nine priority agendas called Nawa Cita. The reform consists of two main programs: first, to improve the quality of life of Indonesian people through improving the quality of education and training and, second, to revolutionize the nation's character through the policy of restructuring the national education curriculum. There are challenges though to implement those programs including Indonesian geographic, gap to access different level of education, and the gap to achieve the Industrial Revolution 4.0 skills. The aims of this chapter are to explore alternatives and solutions for access to education in Indonesia by utilizing technological advancements including the skills needed to face the current digital era. Education 4.0 is a good approach to answer those challenges. The use of internet technology for digital learning can provide access to students spread across the country. This approach requires skills set that are appropriate to Industry 4.0 by providing a flexible curriculum and online certification. \u00a9 2021, IGI Global."
        ]
    },
    {
        "judul":[
            "Improving the Performance of Blockchain Based Digital Contract Using Niederreiter Method"
        ],
        "penulis":"Santoso, Edy;Barmawi, Ari Moesriami;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays the use of internet in daily life is increasing such that data exchange is frequently conducted. Especially in the case of business transactions, data communication security (such as for banking transaction, contract) is necessary. Sony, et al. [1] proposed a method for securing a contract by introducing ECDSA for signing a contract based on blockchain. However, Sony's method requires high time complexity and not resistant against quantum computing attacks. Therefore, this research proposed a method to reduce the time complexity and resistant against quantum computing attack. To overcome the quantum attack and reduce the time complexity of digital signing based on blockchain, McElliece Cryptosystem and digital signature based on Niederreiter are introduced for signing the contract. Since McElliece Cryptosystem and Niederreiter based signature uses scalar multiplication then the processing time is less than ECDSA. Based on the experiment result, it is proven that the execution time for signing process using the proposed method may reach up to 51.1% less than signing execution time of Sony's method, and for verification process up to 77.8% less than verification execution time of Sony's method. It is also proven that the proposed method is resistant against quantum attack.  \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays the use of internet in daily life is increasing such that data exchange is frequently conducted. Especially in the case of business transactions, data communication security (such as for banking transaction, contract) is necessary. Sony, et al. [1] proposed a method for securing a contract by introducing ECDSA for signing a contract based on blockchain. However, Sony's method requires high time complexity and not resistant against quantum computing attacks. Therefore, this research proposed a method to reduce the time complexity and resistant against quantum computing attack. To overcome the quantum attack and reduce the time complexity of digital signing based on blockchain, McElliece Cryptosystem and digital signature based on Niederreiter are introduced for signing the contract. Since McElliece Cryptosystem and Niederreiter based signature uses scalar multiplication then the processing time is less than ECDSA. Based on the experiment result, it is proven that the execution time for signing process using the proposed method may reach up to 51.1% less than signing execution time of Sony's method, and for verification process up to 77.8% less than verification execution time of Sony's method. It is also proven that the proposed method is resistant against quantum attack.  \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Bypassing MRI Pre-processing in Alzheimer's Disease Diagnosis using Deep Learning Detection Network"
        ],
        "penulis":"Fong, Jia Xian;Shapiai, Mohd Ibrahim;Tiew, Yuan You;Batool, Uzma;Fauzi, Hilman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Although promising results have been achieved in the area of Alzheimer's Disease diagnosis via hippocampal atrophy analysis, most of these solutions are heavily dependent on various MRI pre-processing techniques to obtain a good result. Besides, most recent works using deep learning methods such as Convolutional Neural Network (CNN) solve Alzheimer's Disease diagnosis based on a classification problem, leaving a research gap to use deep learning object detection method on Alzheimer's Disease diagnosis. In this study, we make two contributions to solve this problem. Firstly, we are the first group to propose an Alzheimer's Disease diagnosis solution without requiring any MRI pre-processing technique. Secondly, we introduce recent deep learning object detection architectures such as Faster R-CNN, SSD and YOLOv3 into the area of Alzheimer's Disease diagnosis. As a side product of our research, we provide a new Deep Learning Alzheimer's Disease\/Normal Control (AD\/NC) object detection benchmark dataset which includes 500 raw, unprocessed screening instances per class from Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset for future object detection research. This dataset consists of a collection of T1 weighted sagittal MRI dicom slices in MP-Rage series in DICOM 16-bit and PNG 16-bit image format, annotated with their respective class label and bounding box in Pascal VOC format. We call this benchmark dataset UTM-ADNI-RA W\u2217. In this study, without using any MRI preprocessing technique, we managed to obtain a detection accuracy of 0.998 for YOLOv3, 0.982 for SSD and 0.988 for Faster R-CNN in AD\/NC territory while surpassing 0.75 IoU threshold across all three deep learning architectures. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Although promising results have been achieved in the area of Alzheimer's Disease diagnosis via hippocampal atrophy analysis, most of these solutions are heavily dependent on various MRI pre-processing techniques to obtain a good result. Besides, most recent works using deep learning methods such as Convolutional Neural Network (CNN) solve Alzheimer's Disease diagnosis based on a classification problem, leaving a research gap to use deep learning object detection method on Alzheimer's Disease diagnosis. In this study, we make two contributions to solve this problem. Firstly, we are the first group to propose an Alzheimer's Disease diagnosis solution without requiring any MRI pre-processing technique. Secondly, we introduce recent deep learning object detection architectures such as Faster R-CNN, SSD and YOLOv3 into the area of Alzheimer's Disease diagnosis. As a side product of our research, we provide a new Deep Learning Alzheimer's Disease\/Normal Control (AD\/NC) object detection benchmark dataset which includes 500 raw, unprocessed screening instances per class from Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset for future object detection research. This dataset consists of a collection of T1 weighted sagittal MRI dicom slices in MP-Rage series in DICOM 16-bit and PNG 16-bit image format, annotated with their respective class label and bounding box in Pascal VOC format. We call this benchmark dataset UTM-ADNI-RA W\u2217. In this study, without using any MRI preprocessing technique, we managed to obtain a detection accuracy of 0.998 for YOLOv3, 0.982 for SSD and 0.988 for Faster R-CNN in AD\/NC territory while surpassing 0.75 IoU threshold across all three deep learning architectures. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "SMART VEST AND MONITORING SYSTEM FOR AIRSOFT SPORT-GAMES USING VIBRATION SENSOR"
        ],
        "penulis":"Mutiara, Giva Andriana;Periyadi;Agnas, Andry Dupti;Darma, Velly;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Airsoft gun is a replica of weapons used for airsoft sports-games activities. These sport-games are usually equipped with ball bullet type, vest protector, helmet and sunglasses. Rules of the game are defined by prioritizing the honesty of each player if hit by a shot. This becomes a weakness and is misused by the player. To reduce these two impacts, this paper proposed an innovation by developing vest that can detect laser light and the bullet. Those hits then connected to the database and also monitoring system. This system is constructed using Light Dependent Resistor, Raspberry Pi 3, motor vibration sensor, piezoelectric, LED lamp, and buzzer. By utilizing the MAC Address of Raspberry Pi 3, the player can be recognized and the counter of the remaining lives of the player will be displayed. The player's life can be determined by a shoot, if point 25 is set for one shoot, then the player declares the game is over after four hits. Based on the testing results, this research can help to do these sport-games informative, efficient and fairly.\u00a9 2020 Research Institute for Intelligent Computer Systems. All rights reserved."
        ],
        "abstrak":[
            "Airsoft gun is a replica of weapons used for airsoft sports-games activities. These sport-games are usually equipped with ball bullet type, vest protector, helmet and sunglasses. Rules of the game are defined by prioritizing the honesty of each player if hit by a shot. This becomes a weakness and is misused by the player. To reduce these two impacts, this paper proposed an innovation by developing vest that can detect laser light and the bullet. Those hits then connected to the database and also monitoring system. This system is constructed using Light Dependent Resistor, Raspberry Pi 3, motor vibration sensor, piezoelectric, LED lamp, and buzzer. By utilizing the MAC Address of Raspberry Pi 3, the player can be recognized and the counter of the remaining lives of the player will be displayed. The player's life can be determined by a shoot, if point 25 is set for one shoot, then the player declares the game is over after four hits. Based on the testing results, this research can help to do these sport-games informative, efficient and fairly.\u00a9 2020 Research Institute for Intelligent Computer Systems. All rights reserved."
        ]
    },
    {
        "judul":[
            "Implementation of Automatic First Arrival Picking on P-Wave Seismic Signal Using Logistic Regression Method"
        ],
        "penulis":"Sya'bani, Yusuf Azam;Novianty, Astri;Prasasti, Anggunmeka Luhur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The development of automation technology is currently very fast and helps human work, one of them is used by the Badan Meteorologi, Klimatologi dan Geotisika (BMKG) to detect earthquakes. Automatic First Arrival Picking is a system that can detect primary waves at the first arrival or P-Wave that occurs in an earthquake seismic signal. This study aims to create an Automatic First Arrival Picking system and test the performance of the Logistic Regression method to classify this Automatic First Arrival Picking system in detecting primary waves at the first arrival or P-Wave. In this Automatic First Arrival Picking study, data samples taken on the IRIS (Incorporated Research Institutions for Seismology) website with 100 earthquake events taken from the three closest stations with magnitude 5-8 SR. Data samples will be processed using four Feature Extraction: Recursive STA\/LTA, Classic STA\/LTA, Carl STA\/ LTA and Delayed STA\/LTA.Furthermore, the results of Feature Extraction that will be used as a dataset will be classified by the Logistic Regression method. From the test results of the Automatic First Arrival Picking system it is known that several parameters can produce the best system performance, that is 50 seconds for time windowing, 55%: 45% for a ratio training and testing, and a value of 100 for Inverse of Regularization. The results of the research conducted using the Logistic Regression method to detect P-waves in the Automatic First Arrival Picking system with a calibration scheme that carried out that obtained accuracy of 83%, Precision by 75%, Recall of 64% and F1-Score of 67%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of automation technology is currently very fast and helps human work, one of them is used by the Badan Meteorologi, Klimatologi dan Geotisika (BMKG) to detect earthquakes. Automatic First Arrival Picking is a system that can detect primary waves at the first arrival or P-Wave that occurs in an earthquake seismic signal. This study aims to create an Automatic First Arrival Picking system and test the performance of the Logistic Regression method to classify this Automatic First Arrival Picking system in detecting primary waves at the first arrival or P-Wave. In this Automatic First Arrival Picking study, data samples taken on the IRIS (Incorporated Research Institutions for Seismology) website with 100 earthquake events taken from the three closest stations with magnitude 5-8 SR. Data samples will be processed using four Feature Extraction: Recursive STA\/LTA, Classic STA\/LTA, Carl STA\/ LTA and Delayed STA\/LTA.Furthermore, the results of Feature Extraction that will be used as a dataset will be classified by the Logistic Regression method. From the test results of the Automatic First Arrival Picking system it is known that several parameters can produce the best system performance, that is 50 seconds for time windowing, 55%: 45% for a ratio training and testing, and a value of 100 for Inverse of Regularization. The results of the research conducted using the Logistic Regression method to detect P-waves in the Automatic First Arrival Picking system with a calibration scheme that carried out that obtained accuracy of 83%, Precision by 75%, Recall of 64% and F1-Score of 67%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Determinant Factors in Utilizing Electronic Signature Using the TAM and TOE Framework"
        ],
        "penulis":"Haryanto, Budi;Gandhi, Arfive;Giri Sucahyo, Yudho;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Electronic signature should accelerate and protect the electronic transactions in government agencies and non-governmental organizations, but its adoption is slow. Until the beginning of 2020, the number of organizations that utilize electronic signature is still very small compared to the number of organizations that have online service. This study aims to identify factors that determine employees in the organization to continue or are interested in utilizing electronic signature. The electronic signature referred to in this study is a certified electronic signature or digital signature. The survey was conducted on users and prospective users in government agencies and non-government organizations. The research uses an integrated framework Technology Acceptance Model (TAM) and Technology-Organization-Environment (TOE) in the information systems discipline. Based on 192 responses, the research framework is validated. Seven driving factors were successfully identified. The seven driving factors are security protection, internal need, training and education, government policy, vendor support, perceived ease of use, and perceived usefulness. The results of this study expand research on the adoption of electronic signature, and broaden research on technology acceptance models, specifically the TAM-TOE integration model. The findings of this study can be input for the government, electronic signature vendors, and organizations to increase the utilization of electronic signature. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electronic signature should accelerate and protect the electronic transactions in government agencies and non-governmental organizations, but its adoption is slow. Until the beginning of 2020, the number of organizations that utilize electronic signature is still very small compared to the number of organizations that have online service. This study aims to identify factors that determine employees in the organization to continue or are interested in utilizing electronic signature. The electronic signature referred to in this study is a certified electronic signature or digital signature. The survey was conducted on users and prospective users in government agencies and non-government organizations. The research uses an integrated framework Technology Acceptance Model (TAM) and Technology-Organization-Environment (TOE) in the information systems discipline. Based on 192 responses, the research framework is validated. Seven driving factors were successfully identified. The seven driving factors are security protection, internal need, training and education, government policy, vendor support, perceived ease of use, and perceived usefulness. The results of this study expand research on the adoption of electronic signature, and broaden research on technology acceptance models, specifically the TAM-TOE integration model. The findings of this study can be input for the government, electronic signature vendors, and organizations to increase the utilization of electronic signature. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Overall Effectiveness on Hall Separator Punching Machine at PT. DNIA"
        ],
        "penulis":"Sriwana, Iphov Kumala;Syauqillah, Nadya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT. DNIA is a company engaged in manufacture of automotive parts, one of which is condenser. Manufacture of condenser components requires small parts produced using a hole separator punching machine. However, it deals with high downtime of the machine, resulting in low production performance. This research aimed to identify the extent of hole separator punching machine performance using analysis of Overall Equipment Effectiveness (OEE) and to analyse six big loses which impact on machine downtime. Calculation results show that OEE value obtained, 48.54%, was still below the standard, and therefore continuous improvement attempt is essential to perform. The low OEE value was a result of low performance efficiency which was caused by idling and minor stoppages of 24.54%. In order to improve the performance and carry out idling and minor stoppages loss, it is important to perform improvement attempt in a number of aspects, such as man aspect by training operators to carry machine-related works, machine aspect by repairing abnormal ups and downs of dies, and material aspect by fixing inappropriate position of header tank (material). \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. DNIA is a company engaged in manufacture of automotive parts, one of which is condenser. Manufacture of condenser components requires small parts produced using a hole separator punching machine. However, it deals with high downtime of the machine, resulting in low production performance. This research aimed to identify the extent of hole separator punching machine performance using analysis of Overall Equipment Effectiveness (OEE) and to analyse six big loses which impact on machine downtime. Calculation results show that OEE value obtained, 48.54%, was still below the standard, and therefore continuous improvement attempt is essential to perform. The low OEE value was a result of low performance efficiency which was caused by idling and minor stoppages of 24.54%. In order to improve the performance and carry out idling and minor stoppages loss, it is important to perform improvement attempt in a number of aspects, such as man aspect by training operators to carry machine-related works, machine aspect by repairing abnormal ups and downs of dies, and material aspect by fixing inappropriate position of header tank (material). \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "University Strategic System Engineering based on BAN PT Accreditation Criteria One using SysML and Semantic Approach"
        ],
        "penulis":"Aurachman, Rio;Putri, Ericha Mutia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "An organizations business processes need to be precisely defined so that the organization does what it should do. Some quality standards such as BAN-PT and ISO 9001 Accreditation require organizations to carry out some process. Sometimes organizations find a difficulty to understand what processes need to be applied based on the standards. This study proposes a SysML and semantic method for analysing standard sentences and providing guidance on what needs to be applied to organizations. The trial was conducted on the Study Program Accreditation standard specifically criterion 1 on strategic management.. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An organizations business processes need to be precisely defined so that the organization does what it should do. Some quality standards such as BAN-PT and ISO 9001 Accreditation require organizations to carry out some process. Sometimes organizations find a difficulty to understand what processes need to be applied based on the standards. This study proposes a SysML and semantic method for analysing standard sentences and providing guidance on what needs to be applied to organizations. The trial was conducted on the Study Program Accreditation standard specifically criterion 1 on strategic management.. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Performance Evaluation for Class Center-Based Missing Data Imputation Algorithm"
        ],
        "penulis":"Nugroho, Heru;Utama, Nugraha Priya;Surendro, Kridanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The imputation method should be able to reproduce the actual values in the data or Predictive Accuracy (PAC) and maintaining the distribution of these values or Distributional Accuracy (DAC). However, in most studies, evaluation of imputation performance was measured based on classification accuracy. On classification issues, class center-based methods for missing data imputation are developed and outperform other methods for numeric and mixed data types. This paper will be evaluated the accuracy of class center-based methods for missing data imputation, which has been modified by considering the correlation between attributes. A class center-based method for missing data imputation produces an average value of r is 0.96, with the lowest average value for MSE and DKS is 0.04 and 0.03. This result shows that the imputation method is more efficient and can maintain the actual data value distribution. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The imputation method should be able to reproduce the actual values in the data or Predictive Accuracy (PAC) and maintaining the distribution of these values or Distributional Accuracy (DAC). However, in most studies, evaluation of imputation performance was measured based on classification accuracy. On classification issues, class center-based methods for missing data imputation are developed and outperform other methods for numeric and mixed data types. This paper will be evaluated the accuracy of class center-based methods for missing data imputation, which has been modified by considering the correlation between attributes. A class center-based method for missing data imputation produces an average value of r is 0.96, with the lowest average value for MSE and DKS is 0.04 and 0.03. This result shows that the imputation method is more efficient and can maintain the actual data value distribution. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Fermentation of coffee pulp using indigenous lactic acid bacteria with simultaneous aeration to produce cascara with a high antioxidant activity"
        ],
        "penulis":"Oktaviani, Lina;Astuti, Dea Indriani;Rosmiati, Mia;Abduh, Muhammad Yusuf;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Coffee pulp which is a by-product of coffee production contains considerable amounts of phenolic compounds that can be valorised to produce cascara as an antioxidant beverage. The fermentation and drying conditions of the coffee pulp have a great influence on the bioactive compounds in the cascara. This study aimed to investigate the effect of natural fermentation with simultaneous aeration on the phenolic content and antioxidant activity of cascara. A systematic study was carried out using a response surface methodology with a face-centered central composite design to determine the effect of fermentation time (0\u20138 h) and temperature (27\u201337 \u00b0C) on the number of bacteria in the coffee pulp after natural fermentation with simultaneous aeration (an air flowrate of 4 m\/s) as well as phenolic content and antioxidant activity of cascara. The experimental dataset was modelled with an empirical model using multi-variable non-linear regression. A good agreement between model and experimental data was obtained. At the optimum conditions (4.2 h, 31.8 \u00b0C), the phenolic content was 6.72% whereas the antioxidant activity was 27.6%. Indigenous lactic acid bacteria were also isolated from the coffee pulp and determined as Leuconostoc pseudomesenteroides. The isolated bacteria can be used as a starter for controlled fermentation of coffee pulp as it increased the antioxidant activity up to 15% higher than the antioxidant activity of cascara obtained at the optimum conditions for natural fermentation with simultaneous aeration and 30% higher from the fresh coffee pulp. \u00a9 2020 The Author(s)Food science, Food technology, Aeration, Antioxidant activity, Cascara, Coffee pulp, Lactic acid bacteria. \u00a9 2020 The Author(s)",
            "OHOHOOOHHOOHOHOView detailsExpand Substance 3-caffeoylquinic acidOHOHHOOView detailsExpand Substance caffeic acidOHOCH3OHOView detailsExpand Substance (E)-3-(4-hydroxy-3-methoxyphenyl)acrylic acidHOH3COHOView detailsExpand Substance LACTIC ACIDOOHHOOHOHOHView detailsExpand Substance catechinTanninView detailsExpand Substance tannin",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Coffee pulp which is a by-product of coffee production contains considerable amounts of phenolic compounds that can be valorised to produce cascara as an antioxidant beverage. The fermentation and drying conditions of the coffee pulp have a great influence on the bioactive compounds in the cascara. This study aimed to investigate the effect of natural fermentation with simultaneous aeration on the phenolic content and antioxidant activity of cascara. A systematic study was carried out using a response surface methodology with a face-centered central composite design to determine the effect of fermentation time (0\u20138 h) and temperature (27\u201337 \u00b0C) on the number of bacteria in the coffee pulp after natural fermentation with simultaneous aeration (an air flowrate of 4 m\/s) as well as phenolic content and antioxidant activity of cascara. The experimental dataset was modelled with an empirical model using multi-variable non-linear regression. A good agreement between model and experimental data was obtained. At the optimum conditions (4.2 h, 31.8 \u00b0C), the phenolic content was 6.72% whereas the antioxidant activity was 27.6%. Indigenous lactic acid bacteria were also isolated from the coffee pulp and determined as Leuconostoc pseudomesenteroides. The isolated bacteria can be used as a starter for controlled fermentation of coffee pulp as it increased the antioxidant activity up to 15% higher than the antioxidant activity of cascara obtained at the optimum conditions for natural fermentation with simultaneous aeration and 30% higher from the fresh coffee pulp. \u00a9 2020 The Author(s)",
            "Food science, Food technology, Aeration, Antioxidant activity, Cascara, Coffee pulp, Lactic acid bacteria. \u00a9 2020 The Author(s)"
        ]
    },
    {
        "judul":[
            "Parallel Algorithm for K-Means Clustering in Wood Species Classification"
        ],
        "penulis":"Gunawan P.H.;Fathurahman, Taufik;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Wood is one of the commodities that are often traded for industrial materials such as furniture, crafts, building raw materials, etc. Therefore identification system of wood species is needed to find out how the condition of the wood which can be seen from the vessel structure and its diameter. To do this identification, a large enough dataset of wood image is needed so that the data can be validated. From large datasets of wood image, the grouping of wooden vessels can be carried out using computing method which is called K-means clustering. However, using large wood image datasets will increase the computational cost. In this research, K-means clustering method will be implemented in serial and parallel programs to see the use of parallel program to handle computational cost. Here speedup and efficiency measurements will be elaborated to see the benefit of parallel program. The experiment result show that speedup using parallel computing is increasingly 4 times faster then serial computing. Moreover the efficiency using parallel architecture is observed 96.04%. Therefore it can be concluded that implementing the K-means clustering method in parallel programs can obtain optimal computational cost and produce high-efficiency values using the same workload as the serial program. \u00a9 2020, Springer Nature Switzerland AG.",
            "NONHSH2CCH3H3CView detailsExpand Substance Albutoin",
            "Powered by"
        ],
        "abstrak":[
            "Wood is one of the commodities that are often traded for industrial materials such as furniture, crafts, building raw materials, etc. Therefore identification system of wood species is needed to find out how the condition of the wood which can be seen from the vessel structure and its diameter. To do this identification, a large enough dataset of wood image is needed so that the data can be validated. From large datasets of wood image, the grouping of wooden vessels can be carried out using computing method which is called K-means clustering. However, using large wood image datasets will increase the computational cost. In this research, K-means clustering method will be implemented in serial and parallel programs to see the use of parallel program to handle computational cost. Here speedup and efficiency measurements will be elaborated to see the benefit of parallel program. The experiment result show that speedup using parallel computing is increasingly 4 times faster then serial computing. Moreover the efficiency using parallel architecture is observed 96.04%. Therefore it can be concluded that implementing the K-means clustering method in parallel programs can obtain optimal computational cost and produce high-efficiency values using the same workload as the serial program. \u00a9 2020, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Characterization of EM wave absorber configured by axially symmetrical C-shaped planar structure"
        ],
        "penulis":"Mulyadi, Rasheed Abdurrahman;Nur, Levy Olivia;Syihabuddin, Budi;Prasetyo, Agus Dwi;Nugroho, Bambang Setia;Munir, Achinad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper deals with the characterization of electromagnetics (EM) wave absorber configured by axially symmetrical C-shaped planar structure. The proposed absorber which is intended to work at C-band frequency with the center frequency of 5,8GHz is designed on a 0.8mm thick FR4 epoxy dielectric substrate. A unit cell of axially symmetrical C-shaped structure is configured with proper boundary conditions to form a double periodic array planar structure of absorber in infinite extent Some physical parameters of unit cell are investigated to evaluate the performance of proposed EM wave absorber in terms of bandwidth characteristic and frequency response. The characterization results show that the resonator length of axially symmetrical C-shaped planar structure affects significantly the frequency response of the absorber with the widest bandwidth achievement of 80MHz. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper deals with the characterization of electromagnetics (EM) wave absorber configured by axially symmetrical C-shaped planar structure. The proposed absorber which is intended to work at C-band frequency with the center frequency of 5,8GHz is designed on a 0.8mm thick FR4 epoxy dielectric substrate. A unit cell of axially symmetrical C-shaped structure is configured with proper boundary conditions to form a double periodic array planar structure of absorber in infinite extent Some physical parameters of unit cell are investigated to evaluate the performance of proposed EM wave absorber in terms of bandwidth characteristic and frequency response. The characterization results show that the resonator length of axially symmetrical C-shaped planar structure affects significantly the frequency response of the absorber with the widest bandwidth achievement of 80MHz. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Triple-chromosome genetic algorithm for unrelated parallel machine scheduling under time-of-use tariffs"
        ],
        "penulis":"Kurniawan, Bobby;Chandramitasari, Widyaning;Gozali, Alfian Akbar;Weng, Wei;Fujimura, Shigeru;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Energy demand is increasing as the population and economy grow. Many countries have implemented time-of-use (TOU) tariffs to meet such demand so that the demand during peak periods could be reduced by shifting its usage from peak periods to off-peak periods. This paper addresses the unrelated parallel machine scheduling under TOU to minimize the sum of weighted makespan and electricity cost. Because the problem has nonregular performance measure, delaying the starting time of the job can produce a better solution. Hence, not only do we determine the job sequencing and the job assignment, but also we determine the starting time of the job. We propose a triple-chromosome genetic algorithm that represents the job sequencing, the job assignment and the optimal starting time of the job simultaneously. A self-adaptive algorithm is developed to determine the value of the third chromosome after crossover and mutation process. Numerical experiment and statistical analysis are conducted to show the appropriateness and efficacy of the proposed approach. \u00a9 2019 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons, Inc. \u00a9 2019 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons, Inc.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Energy demand is increasing as the population and economy grow. Many countries have implemented time-of-use (TOU) tariffs to meet such demand so that the demand during peak periods could be reduced by shifting its usage from peak periods to off-peak periods. This paper addresses the unrelated parallel machine scheduling under TOU to minimize the sum of weighted makespan and electricity cost. Because the problem has nonregular performance measure, delaying the starting time of the job can produce a better solution. Hence, not only do we determine the job sequencing and the job assignment, but also we determine the starting time of the job. We propose a triple-chromosome genetic algorithm that represents the job sequencing, the job assignment and the optimal starting time of the job simultaneously. A self-adaptive algorithm is developed to determine the value of the third chromosome after crossover and mutation process. Numerical experiment and statistical analysis are conducted to show the appropriateness and efficacy of the proposed approach. \u00a9 2019 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons, Inc. \u00a9 2019 Institute of Electrical Engineers of Japan. Published by John Wiley & Sons, Inc."
        ]
    },
    {
        "judul":[
            "Tracking, Arrival Time Estimator, and Passenger Information System on Bus Rapid Transit (BRT)"
        ],
        "penulis":"Hafiizh Nur M.A.;Hadiyoso, Sugondo;Belladina, Fefa Bianca;Ramadan, Dadan Nur;Wijayanto, Inung;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Trans Metro Bandung is a new Bus Rapid Transit in Bandung, Indonesia. As a new mode of transportation, it proposes comfort, safety, and give an affordable price. However, information systems related to buses are still lacking and far from expectations. That includes the uncertainty of the bus departures and arrivals times at bus stops. Therefore, in this study, an integrated online system is designed to provide information, including bus arrival time, bus position, and the number of passengers on the bus. This information system is a website application that is connected to the Firebase real-time database so that all data can be accessed in real-time and then displayed at the bus stop. The hardware system consists of an infrared detector to count the number of passengers and a GPS module for bus tracking. From the bus position information, the system can estimate the arrival time at the nearest bus stop.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Trans Metro Bandung is a new Bus Rapid Transit in Bandung, Indonesia. As a new mode of transportation, it proposes comfort, safety, and give an affordable price. However, information systems related to buses are still lacking and far from expectations. That includes the uncertainty of the bus departures and arrivals times at bus stops. Therefore, in this study, an integrated online system is designed to provide information, including bus arrival time, bus position, and the number of passengers on the bus. This information system is a website application that is connected to the Firebase real-time database so that all data can be accessed in real-time and then displayed at the bus stop. The hardware system consists of an infrared detector to count the number of passengers and a GPS module for bus tracking. From the bus position information, the system can estimate the arrival time at the nearest bus stop.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Cholesterol detection based on eyelid recognition using convolutional neural network method"
        ],
        "penulis":"Pratama, Rizki Mulia;Novianty, Astri;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Lack of public awareness of health will cause serious problems. A small example, people now tend to always consume fatty foods without thinking about the risk of cholesterol levels in the body. Information on the level of cholesterol suffered by humans can be seen on the human eyelids. The eyelids, one part of the eye, can be known as a person's cholesterol level by observing the eyelids' shape and condition, but many people do not know about this. This application is an application made to detect cholesterol based on the shape of the eyelids. This can determine whether a person is exposed to cholesterol or not, using the Convolutional Neural Network (CNN) method in the classification process. This study provides an output in the form of early detection of cholesterol and prevention so that users can minimize the possibility of illness that will be suffered. This research was conducted to detect cholesterol one eyelid based on digital images. For detecting a cholesterol level, this system got 95.83% of accuracy. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "CH3CH3CH3HOCH3CH3HHHHHView detailsExpand Substance cholesterol",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Lack of public awareness of health will cause serious problems. A small example, people now tend to always consume fatty foods without thinking about the risk of cholesterol levels in the body. Information on the level of cholesterol suffered by humans can be seen on the human eyelids. The eyelids, one part of the eye, can be known as a person's cholesterol level by observing the eyelids' shape and condition, but many people do not know about this. This application is an application made to detect cholesterol based on the shape of the eyelids. This can determine whether a person is exposed to cholesterol or not, using the Convolutional Neural Network (CNN) method in the classification process. This study provides an output in the form of early detection of cholesterol and prevention so that users can minimize the possibility of illness that will be suffered. This research was conducted to detect cholesterol one eyelid based on digital images. For detecting a cholesterol level, this system got 95.83% of accuracy. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Bridging the.id domain purchase intention with website channels: Factors analysis approach"
        ],
        "penulis":"Aditya, Wahyu;Sucahyo, Yudho Giri;Gandhi, Arfive;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Domain is a unique name used to identify the IP address of a computer server. It had a function to facilitate visitors in accessing and remembering the addresses of the website. Organized by PANDI, Indonesia has.id as country code Top Level Domain (ccTLD). Unfortunately, the.id domain in Indonesia penetration was relatively low, with a ratio of 1:855 and the high gap among registrars. This research identified and analyzed factors influencing.id domain purchasing through website channels to fix that situation effectively. This research aimed to determine which factors influence users in purchasing a.id domain through website channels by using a combined research model from Website Quality, Theory of Planned Behavior, Brand Equity Website, and Social Website Interactivity. By involving 143 respondents in an online questionnaire, this research employed 11 hypotheses, nine of them were accepted while two others were rejected. It was using Partial List Square-Structural Equation Modeling (PLS-SEM). They proved factors that influence the.id domains purchasing through the website were: trust, brand experience, and brand choice. They were supported by website quality and social website interactivity while attitude and social response did not. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Domain is a unique name used to identify the IP address of a computer server. It had a function to facilitate visitors in accessing and remembering the addresses of the website. Organized by PANDI, Indonesia has.id as country code Top Level Domain (ccTLD). Unfortunately, the.id domain in Indonesia penetration was relatively low, with a ratio of 1:855 and the high gap among registrars. This research identified and analyzed factors influencing.id domain purchasing through website channels to fix that situation effectively. This research aimed to determine which factors influence users in purchasing a.id domain through website channels by using a combined research model from Website Quality, Theory of Planned Behavior, Brand Equity Website, and Social Website Interactivity. By involving 143 respondents in an online questionnaire, this research employed 11 hypotheses, nine of them were accepted while two others were rejected. It was using Partial List Square-Structural Equation Modeling (PLS-SEM). They proved factors that influence the.id domains purchasing through the website were: trust, brand experience, and brand choice. They were supported by website quality and social website interactivity while attitude and social response did not. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Global competition strategies for Indonesian SMEs"
        ],
        "penulis":"Aryani, Sinta;Wiryono, Sudarso Kaderi;Koesrindartoto, Deddy P.;Anggahegari, Prameshwara;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Given the limitations of SMEs and the rigid requirements of financial institutions, this paper evaluates the bridge which connects those ends. The purpose of the paper is to find smooth connections between SMEs and financial institutions in order to enhance the quality credits given to SMEs. The literature came from qualified international academic journals and papers, reports from prominent global institutions, and reports from the Indonesian government which are related to their policies towards SMEs and financial institutions. Comparisons were made among countries around the world regarding the policies applied to their SMEs and financial institutions. This paper looks specifically at the global challenges related to Indonesian SMEs to reach sustainable growth. Collaborations between the government, financial institutions, and SMEs are needed. The roles of financial inclusion, financial literacy, innovation lending, and the government are important measures to support SMEs' developments. Copyright \u00a9 2020 Inderscience Enterprises Ltd.",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1Decent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Given the limitations of SMEs and the rigid requirements of financial institutions, this paper evaluates the bridge which connects those ends. The purpose of the paper is to find smooth connections between SMEs and financial institutions in order to enhance the quality credits given to SMEs. The literature came from qualified international academic journals and papers, reports from prominent global institutions, and reports from the Indonesian government which are related to their policies towards SMEs and financial institutions. Comparisons were made among countries around the world regarding the policies applied to their SMEs and financial institutions. This paper looks specifically at the global challenges related to Indonesian SMEs to reach sustainable growth. Collaborations between the government, financial institutions, and SMEs are needed. The roles of financial inclusion, financial literacy, innovation lending, and the government are important measures to support SMEs' developments. Copyright \u00a9 2020 Inderscience Enterprises Ltd."
        ]
    },
    {
        "judul":[
            "Mask Classification and Head Temperature Detection Combined with Deep Learning Networks"
        ],
        "penulis":"Farady, Isack;Lin, Chih-Yang;Rojanasarit, Amornthep;Prompol, Kanatip;Akhyar, Fityanul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Due to the COVID-19 pandemic, wearing a mask is mandatory in public spaces, as properly wearing a mask offers a maximum preventive effect against viral transmission. Body temperature has also become an important consideration in determining whether an individual is healthy. In this work, we design a real-Time deep learning model to meet current demand to detect the mask-wearing position and head temperature of a person before he or she enters a public space. In this experiment, we use a deep learning object detection method to create a mask position and head temperature detector using a popular one-stage object detection, RetinaNet. We build two modules for the RetinaNet model to detect three categories of mask-wearing positions and the temperature of the head. We implement an RGB camera and thermal camera to generate input images and capture a person's temperature respectively. The output of these experiments is a live video that carries accurate information about whether a person is wearing a mask properly and what his or her head temperature is. Our model is light and fast, achieving a confidence score of 81.31% for the prediction object and a prediction speed below 0. 1s\/image. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Due to the COVID-19 pandemic, wearing a mask is mandatory in public spaces, as properly wearing a mask offers a maximum preventive effect against viral transmission. Body temperature has also become an important consideration in determining whether an individual is healthy. In this work, we design a real-Time deep learning model to meet current demand to detect the mask-wearing position and head temperature of a person before he or she enters a public space. In this experiment, we use a deep learning object detection method to create a mask position and head temperature detector using a popular one-stage object detection, RetinaNet. We build two modules for the RetinaNet model to detect three categories of mask-wearing positions and the temperature of the head. We implement an RGB camera and thermal camera to generate input images and capture a person's temperature respectively. The output of these experiments is a live video that carries accurate information about whether a person is wearing a mask properly and what his or her head temperature is. Our model is light and fast, achieving a confidence score of 81.31% for the prediction object and a prediction speed below 0. 1s\/image. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Developing an LSTM-based Classification Model of IndiHome Customer Feedbacks"
        ],
        "penulis":"Arifianto, Anditya;Suyanto, Suyanto;Sirwan, Anis;Desrul, Dhamir Raniah Kiasati;Prakoso, Irfan D.;Guntara, Fedy Fahron;Hidayati, Dian Chusnul;Murti, Rani Sari;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The development of companies in the service sector is inseparable from problems with the customer service process. The latest trends show that customers are more comfortable using social media and chat services as feedback delivery media compared to sending emails. In this study, we classify user feedback from an Internet Service Provider (ISP) in Indonesia named IndiHome. In this study, there are two test scenarios carried out to classify, the first scenario uses Short Term Memory combined with Word Embedding, and the second scenario uses Naive Bayes combined with TF-IDF. based on the test results, obtained accuracy on the LSTM method combined with Word Embedding with an f1 score of 87.98 % and accuracy obtained at Naive Bayes combined with TF-IDF with an f1 score of 76.77 %. From the tests that have been done, different results are obtained and have a big difference, which is 11.21%. The difference in the results of this classification is influenced by several factors, namely the first factor is the extraction of features used and the second is the data used. In feature selection, TF-IDF is more ideal for data that has a large or long document size because the representation seen from the whole document, in contrast to Word Embedding that is not affected by the data size because the representation is seen from words. so this is what causes the method of using LSTM combined with Word Embedding to produce higher results.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of companies in the service sector is inseparable from problems with the customer service process. The latest trends show that customers are more comfortable using social media and chat services as feedback delivery media compared to sending emails. In this study, we classify user feedback from an Internet Service Provider (ISP) in Indonesia named IndiHome. In this study, there are two test scenarios carried out to classify, the first scenario uses Short Term Memory combined with Word Embedding, and the second scenario uses Naive Bayes combined with TF-IDF. based on the test results, obtained accuracy on the LSTM method combined with Word Embedding with an f1 score of 87.98 % and accuracy obtained at Naive Bayes combined with TF-IDF with an f1 score of 76.77 %. From the tests that have been done, different results are obtained and have a big difference, which is 11.21%. The difference in the results of this classification is influenced by several factors, namely the first factor is the extraction of features used and the second is the data used. In feature selection, TF-IDF is more ideal for data that has a large or long document size because the representation seen from the whole document, in contrast to Word Embedding that is not affected by the data size because the representation is seen from words. so this is what causes the method of using LSTM combined with Word Embedding to produce higher results.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "On the design of optimal soft demapper for 5G NR wireless communication systems"
        ],
        "penulis":"Syukra, Alhamdi;Anwar, Khoirul;Saputri, Desti Madya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The fifth telecommunication generation new radio (5G NR) modulations enable transmissions to have high data rates although in the environments having large channel distortions and noise. However, the third generation partnership project (3GPP) only standardized the mapper of 5G NR, but left the design of demapper for the industries. This paper proposes an optimal soft demapper for all 5G NR modulations for better performances and practical implementations. The proposed soft demapper is optimized in terms of minimum bit-error rate (BER) subject to the limited practical soft values required by the hardware. We conduct a series of computer simulations to evaluate the performances of the proposed soft demapper without and with soft decoder. The simulation results confirmed that the proposed 5G NR demappers provide excellent performances without error-floor as expected by the theoretical BER curve performances for the case of without channel coding and more than 5 dB gain without error-floor for the case of decoding using soft decoders of convolutional and repetition codes. These results are expected to provide contribution to the development of practical 5G NR receivers. \u00a9 2020 IEEE."
        ],
        "abstrak":[
            "The fifth telecommunication generation new radio (5G NR) modulations enable transmissions to have high data rates although in the environments having large channel distortions and noise. However, the third generation partnership project (3GPP) only standardized the mapper of 5G NR, but left the design of demapper for the industries. This paper proposes an optimal soft demapper for all 5G NR modulations for better performances and practical implementations. The proposed soft demapper is optimized in terms of minimum bit-error rate (BER) subject to the limited practical soft values required by the hardware. We conduct a series of computer simulations to evaluate the performances of the proposed soft demapper without and with soft decoder. The simulation results confirmed that the proposed 5G NR demappers provide excellent performances without error-floor as expected by the theoretical BER curve performances for the case of without channel coding and more than 5 dB gain without error-floor for the case of decoding using soft decoders of convolutional and repetition codes. These results are expected to provide contribution to the development of practical 5G NR receivers. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The P1- P1NCFinite Element Method for 1D wave simulation using Shallow Water Equations"
        ],
        "penulis":"Swastika P.V.;Pudjaprasetya S.R.;Adytia D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We study a simple numerical scheme based on a new type of Finite Element Method (FEM) to solve the 1D Shallow Water Equations. In the new scheme, the surface elevation variable is approximated by a linear continuous basis function (P 1) and the velocity potential variable is approximated by the one-dimensional discontinuous linear non-conforming basis function (P1NC). Here, we implement the P 1 - P1NC finite element pair to solve the 1D Shallow Water Equations on a structured grid, whereas the Runge Kutta method is adopted for time integration. We verified the resulting scheme by conducting several simulations such as a standing wave simulation, and propagation of an initial hump over sloping bathymetry. The resulting scheme free from numerical damping error, conservative and both standing wave and shoaling phenomena are well simulated.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We study a simple numerical scheme based on a new type of Finite Element Method (FEM) to solve the 1D Shallow Water Equations. In the new scheme, the surface elevation variable is approximated by a linear continuous basis function (P 1) and the velocity potential variable is approximated by the one-dimensional discontinuous linear non-conforming basis function (P1NC). Here, we implement the P 1 - P1NC finite element pair to solve the 1D Shallow Water Equations on a structured grid, whereas the Runge Kutta method is adopted for time integration. We verified the resulting scheme by conducting several simulations such as a standing wave simulation, and propagation of an initial hump over sloping bathymetry. The resulting scheme free from numerical damping error, conservative and both standing wave and shoaling phenomena are well simulated.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Robust audio watermarking based on transform domain and SVD with compressive sampling framework"
        ],
        "penulis":"Novamizanti, Ledya;Budiman, Gelar;Astuti, Elsa Nur Fitri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The growth of the internet and digital data has resulted forgery, modification and sharing of digital data without property rights. Audio watermarking is one of a solution to protect the copyright of an audio from copyright infringement. This paper proposes an audio watermarking method which is robust against attacks and high capacity. First, a synchronization bit is added to the audio host. After the audio host is decomposed by Lifting Wavelet Transform (LWT), then choose a subband from the output of LWT to be transformed by discrete cosine transform (DCT). Next, the matrix of the signal from DCT is selected for the singular value decomposition (SVD) process, so that is obtained U, S and V matrix. S matrix is embedded with the watermark. Before the embedding process, the watermark image is compressed by Compressive Sampling. The results show that the proposed watermarking system is highly robust against a kind attack of LPF, resampling, and linear speed change which is proven by its BER is zero. \u00a9 2020, Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The growth of the internet and digital data has resulted forgery, modification and sharing of digital data without property rights. Audio watermarking is one of a solution to protect the copyright of an audio from copyright infringement. This paper proposes an audio watermarking method which is robust against attacks and high capacity. First, a synchronization bit is added to the audio host. After the audio host is decomposed by Lifting Wavelet Transform (LWT), then choose a subband from the output of LWT to be transformed by discrete cosine transform (DCT). Next, the matrix of the signal from DCT is selected for the singular value decomposition (SVD) process, so that is obtained U, S and V matrix. S matrix is embedded with the watermark. Before the embedding process, the watermark image is compressed by Compressive Sampling. The results show that the proposed watermarking system is highly robust against a kind attack of LPF, resampling, and linear speed change which is proven by its BER is zero. \u00a9 2020, Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Implementation of ensemble methods on QSAR Study of NS3 inhibitor activity as anti-dengue agent"
        ],
        "penulis":"Kurniawan I.;Rosalinda M.;Ikhsan N.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Dengue fever is a disease transmitted by infected mosquitoes. This disease spreads in several countries, especially those with a tropical climate. To date, there is no specific drug that can be used to treat dengue. Use of clinically investigated drugs, such as Balapiravir, is still not effective in inhibiting the activity of virus replication. The design of a drug candidate can be performed by using the non-structural protein 3 (NS3) as target. This study aimed to develop QSAR models to predict the inhibitory activity class of NS3 inhibitors. The classification was performed by using feature importance analysis for selecting the descriptors and three ensemble methods, i.e. random forest (RF), adaptive boosting (AdaBoost), and extremely randomized trees (ERT), for model design and prediction. Hyperparameter tuning was performed to improve the performance of the models. Based on the results, we found that model 9, developed from ERT produced the best performance with values of accuracy and AUC equal to 0.73 and 0.82, respectively. Use of y-scrambling method allowed us to confirm that the model was not related to the chance correlation. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Dengue fever is a disease transmitted by infected mosquitoes. This disease spreads in several countries, especially those with a tropical climate. To date, there is no specific drug that can be used to treat dengue. Use of clinically investigated drugs, such as Balapiravir, is still not effective in inhibiting the activity of virus replication. The design of a drug candidate can be performed by using the non-structural protein 3 (NS3) as target. This study aimed to develop QSAR models to predict the inhibitory activity class of NS3 inhibitors. The classification was performed by using feature importance analysis for selecting the descriptors and three ensemble methods, i.e. random forest (RF), adaptive boosting (AdaBoost), and extremely randomized trees (ERT), for model design and prediction. Hyperparameter tuning was performed to improve the performance of the models. Based on the results, we found that model 9, developed from ERT produced the best performance with values of accuracy and AUC equal to 0.73 and 0.82, respectively. Use of y-scrambling method allowed us to confirm that the model was not related to the chance correlation. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group."
        ]
    },
    {
        "judul":[
            "Knowing Opposing Arguments in Persuasive Essays Using Random Forest Classifier"
        ],
        "penulis":"Rachmanto, Daulat;Asror, Ibnu;Herdiani, Anisa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Argumentation mining is a relatively new field of research in the perspective of computational linguistics. It can be used to improve the quality of arguments in persuasive essays by detecting whether in a persuasive essay there are opposing arguments or not. This is because the importance of opposing arguments in persuasive essays that can improve the quality of arguments, precision and author's claims. This research adapted the research conducted by Stab and Gurevych who used the SVM classification method with an accuracy 75,6% and macro F1-score 0,734. While in this research used the Random Forest method and get accuracy of 85,125% and macro F1-score of 0,841 by using three features, namely unigram, production rules, and adversative transitions.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Argumentation mining is a relatively new field of research in the perspective of computational linguistics. It can be used to improve the quality of arguments in persuasive essays by detecting whether in a persuasive essay there are opposing arguments or not. This is because the importance of opposing arguments in persuasive essays that can improve the quality of arguments, precision and author's claims. This research adapted the research conducted by Stab and Gurevych who used the SVM classification method with an accuracy 75,6% and macro F1-score 0,734. While in this research used the Random Forest method and get accuracy of 85,125% and macro F1-score of 0,841 by using three features, namely unigram, production rules, and adversative transitions.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Reduction of number of empty-truck trips in inter-terminal transportation using multi-agent Q-learning"
        ],
        "penulis":"Adi, Taufik Nur;Iskandar, Yelita Anggiane;Bae, Hyerim;Choi, Yulim;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In a port consisting of multiple container terminals, the demand for transportation of containers and cargo among port facilities is high. Almost all transshipment containers bound for a vessel generally are transported from one terminal to another within a short period, which process is known as inter-terminal transportation (ITT). Adequate ITT planning is required in order to reduce ITT-related costs. Minimization of the number of Empty-Truck trips has gained attention, as the ITT problem incurs ITT-related costs. A single Q-Learning-based technique developed in a previous study for minimization of the number of empty-truck trips required high computational time while learning from a considerable amount of orders data. This paper proposes multi-agent Q-Learning to improve the performance offered by the previous single-agent-based model. Our results show that multi-agent Q-Learning performs better than the single-agent alternative in terms of computation time and, therefore too, the quality of its results. \u00a9 Interconnected Supply Chains in an Era of Innovation - Proceedings of the 8th International Conference on Information Systems, Logistics and Supply Chain, ILS 2020. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a port consisting of multiple container terminals, the demand for transportation of containers and cargo among port facilities is high. Almost all transshipment containers bound for a vessel generally are transported from one terminal to another within a short period, which process is known as inter-terminal transportation (ITT). Adequate ITT planning is required in order to reduce ITT-related costs. Minimization of the number of Empty-Truck trips has gained attention, as the ITT problem incurs ITT-related costs. A single Q-Learning-based technique developed in a previous study for minimization of the number of empty-truck trips required high computational time while learning from a considerable amount of orders data. This paper proposes multi-agent Q-Learning to improve the performance offered by the previous single-agent-based model. Our results show that multi-agent Q-Learning performs better than the single-agent alternative in terms of computation time and, therefore too, the quality of its results. \u00a9 Interconnected Supply Chains in an Era of Innovation - Proceedings of the 8th International Conference on Information Systems, Logistics and Supply Chain, ILS 2020. All rights reserved."
        ]
    },
    {
        "judul":[
            "A Method for Microservices Handover in A Local Area Network"
        ],
        "penulis":"Afshari, Reza;Pusparini, Rimba Frida;Utomo, Muhammad Helmi;Dewanta, Favian;Negara, Ridha Muldina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The trend of internet of things (IoT) makes the cloud less effective because networked control systems need low latency while cloud have high latency for processing data from sensors and devices. In that kind of situation, fog computing is introduced as the complement of cloud computing. However, unlike cloud services, fog services are limited to certain geographical area. As a consequence, fog services handover is needed in order to accommodate user's mobility. This paper is focusing on microservices handover that follows user's movement. The microservices installed in the current fog node are sent to another service coverage of a new fog node for continuing the same service to the users. Fog node contains a docker that runs MySQL, python script, and busybox services. When it comes to handover, docker will freeze current session and convert it to a checkpoint file. The file is created by taking a snapshot of the container, which consists of processes in memory, volume or image. The file will be sent by using secure shell (SSH) or file transfer protocol (FTP). At the destination fog node, the file will be processed in order to resume the service. The results show that delay of SSH is always higher than FTP in all experiments, in which the largest delays are 484.026 seconds for SSH protocol and 146.41 seconds for FTP protocols. As for checkpoint and restore process, those delays tend to be similar with respect to both SSH and FTP protocols but they are still affected by the size of snapshot and checkpoint file.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The trend of internet of things (IoT) makes the cloud less effective because networked control systems need low latency while cloud have high latency for processing data from sensors and devices. In that kind of situation, fog computing is introduced as the complement of cloud computing. However, unlike cloud services, fog services are limited to certain geographical area. As a consequence, fog services handover is needed in order to accommodate user's mobility. This paper is focusing on microservices handover that follows user's movement. The microservices installed in the current fog node are sent to another service coverage of a new fog node for continuing the same service to the users. Fog node contains a docker that runs MySQL, python script, and busybox services. When it comes to handover, docker will freeze current session and convert it to a checkpoint file. The file is created by taking a snapshot of the container, which consists of processes in memory, volume or image. The file will be sent by using secure shell (SSH) or file transfer protocol (FTP). At the destination fog node, the file will be processed in order to resume the service. The results show that delay of SSH is always higher than FTP in all experiments, in which the largest delays are 484.026 seconds for SSH protocol and 146.41 seconds for FTP protocols. As for checkpoint and restore process, those delays tend to be similar with respect to both SSH and FTP protocols but they are still affected by the size of snapshot and checkpoint file.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "NGBoost Interpretation Using LIME for Alcoholic EEG Signal Based on GLDM Feature Extraction"
        ],
        "penulis":"Barus, Dandi Trianta;Masri, Fikhri;Rizal, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "NGBoost is a boosting algorithm that predicts probability distribution. In its application to alcoholic EEG signals which features have been extracted using GLDM, the resulting model is difficult to explain due to its black box. In this study, the NGBoost implementation and its interpretation of the alcoholic EEG dataset were investigated using LIME. The LIME technique is used because it proves reliable in interpreting other black-box models such as Neural Network and Support Vector Machine. From the experiments conducted on 3 test data, the results show that LIME can explain how NGBoost works when used in alcoholic EEG datasets. Furthermore, the three results obtained show that the Inverse Difference Moment feature at rotation 0\u2218and 90\u2218are features that most influence the NGBoost model in predicting the probability of \u201calcoholic\u201d or \u201ccontrol\u201d (non-alcoholic). \u00a9 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "NGBoost is a boosting algorithm that predicts probability distribution. In its application to alcoholic EEG signals which features have been extracted using GLDM, the resulting model is difficult to explain due to its black box. In this study, the NGBoost implementation and its interpretation of the alcoholic EEG dataset were investigated using LIME. The LIME technique is used because it proves reliable in interpreting other black-box models such as Neural Network and Support Vector Machine. From the experiments conducted on 3 test data, the results show that LIME can explain how NGBoost works when used in alcoholic EEG datasets. Furthermore, the three results obtained show that the Inverse Difference Moment feature at rotation 0\u2218and 90\u2218are features that most influence the NGBoost model in predicting the probability of \u201calcoholic\u201d or \u201ccontrol\u201d (non-alcoholic). \u00a9 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Integrated Virtual Communities into User Group Management System (UGMS) for Smart Cities"
        ],
        "penulis":"Adam Prasetyo, Yuli;Lubis, Muharman;Azani Hasibuan, Muhammad;Fauzi, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Society as a collection of people who are connected together based on certain understanding and bind by the regulation is adapted to perform multiple functions that for the sake of engaging technology advancement to improve the quality of life. Thus, there are some opportunities for application development to cater to the needs in the complexity of interaction between the individual in the society, one of them is user group management. This study is aimed to design the business canvas and mobile application by integrating virtual communities based on national identity in the form of e-KTP through Scrum method. Therefore, there are some challenges should be considered in the process of identification such as the right resource to implement the smart platform and the alignment between project objective and the readiness in the society. This study present APLICOT API as the framework for UGMS together with business model canvas, use case diagram and prototype. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Society as a collection of people who are connected together based on certain understanding and bind by the regulation is adapted to perform multiple functions that for the sake of engaging technology advancement to improve the quality of life. Thus, there are some opportunities for application development to cater to the needs in the complexity of interaction between the individual in the society, one of them is user group management. This study is aimed to design the business canvas and mobile application by integrating virtual communities based on national identity in the form of e-KTP through Scrum method. Therefore, there are some challenges should be considered in the process of identification such as the right resource to implement the smart platform and the alignment between project objective and the readiness in the society. This study present APLICOT API as the framework for UGMS together with business model canvas, use case diagram and prototype. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Deep salient wood image-based quality assessment"
        ],
        "penulis":"Risnandar;Prakasa, Esa;Erwin, Iwan Muhammad;Gojali, Elli Ahmad;Herlan;Lestari, Puji;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We introduce a novelty in the method of the deep salient wood image quality assessment (DS-WIQA) for no-reference image quality assessment (NR-IQA). We exploit a five-layer deep convolutional neural network (DCNN) for the salient wood image map. DS-WIQA also employs the n-convex-concave model. The outcomes obviously prove that our DCNN and DS-WIQA architectures can deliver a superior achievement on Zenodo and Lignoindo datasets, respectively. We compute a salient wood image map of each wood image in small wood image patches. Our exploratory outcomes evince that the proposed DCNN and DS-WIQA methods are superior to other the advanced methods on Zenodo and Lignoindo datasets, respectively. Our proposed DCNN for NR-IQA also obtains a better result compared with the other NR-IQA methods in the five distortion types of JP2K, JPEG, white noise Gaussian, blocking artifact, and the fast fading and also in the undistorted wood images. Our DCNN outruns the recent most sophisticated methods in terms of SROCC and LCC evaluation, respectively. DS-WIQA outpaces other the advanced methods by 0.38 % and 0.22 % greater than our proposed DCNN, and 34.84 % and 30.15 % greater than other methods with respect to SROCC and LCC, respectively. In computational complexity of our proposed DCNN and DS-WIQA cut down the shift\u00a0add operation in exponential, logarithmic, and trigonometric functions. DS-WIQA shows up to be more significant than our proposed DCNN and the other DCNN methods. \u00a9 2020, Springer Nature Switzerland AG.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We introduce a novelty in the method of the deep salient wood image quality assessment (DS-WIQA) for no-reference image quality assessment (NR-IQA). We exploit a five-layer deep convolutional neural network (DCNN) for the salient wood image map. DS-WIQA also employs the n-convex-concave model. The outcomes obviously prove that our DCNN and DS-WIQA architectures can deliver a superior achievement on Zenodo and Lignoindo datasets, respectively. We compute a salient wood image map of each wood image in small wood image patches. Our exploratory outcomes evince that the proposed DCNN and DS-WIQA methods are superior to other the advanced methods on Zenodo and Lignoindo datasets, respectively. Our proposed DCNN for NR-IQA also obtains a better result compared with the other NR-IQA methods in the five distortion types of JP2K, JPEG, white noise Gaussian, blocking artifact, and the fast fading and also in the undistorted wood images. Our DCNN outruns the recent most sophisticated methods in terms of SROCC and LCC evaluation, respectively. DS-WIQA outpaces other the advanced methods by 0.38 % and 0.22 % greater than our proposed DCNN, and 34.84 % and 30.15 % greater than other methods with respect to SROCC and LCC, respectively. In computational complexity of our proposed DCNN and DS-WIQA cut down the shift\u00a0add operation in exponential, logarithmic, and trigonometric functions. DS-WIQA shows up to be more significant than our proposed DCNN and the other DCNN methods. \u00a9 2020, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "A Cluster-Based Method for Improving Water Depth Estimation from Satellite Derived Bathymetry"
        ],
        "penulis":"Meliala, Litany;Juliansah, Tabah;Adytia, Didit;Sidiq, Teguh Purnama;Windupranata, Wiwin;Poerbandono;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this presented paper, an effort to improve the accuracy of the bathymetric model derived from optical satellite imagery is discussed. According to the previous study, the accuracy approximately measures in 2 m for depth up to 10 m by means of the Global Bathymetric Inversion Methods. Therefore, the improvement is done based on the so-called Cluster-Based Method applied to the analytical and log-ratio methods. The Cluster-Based Method partitions the working area on the by classifying the errors between the known depths and the predicted ones. The data for the known and predicted depths are acquired from the in-situ survey and the Sentinel-2 imagery. Improvement by one-third to the accuracy of the resulting bathymetry is obtained.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this presented paper, an effort to improve the accuracy of the bathymetric model derived from optical satellite imagery is discussed. According to the previous study, the accuracy approximately measures in 2 m for depth up to 10 m by means of the Global Bathymetric Inversion Methods. Therefore, the improvement is done based on the so-called Cluster-Based Method applied to the analytical and log-ratio methods. The Cluster-Based Method partitions the working area on the by classifying the errors between the known depths and the predicted ones. The data for the known and predicted depths are acquired from the in-situ survey and the Sentinel-2 imagery. Improvement by one-third to the accuracy of the resulting bathymetry is obtained.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Linkages of financial efficacy, demographics, risks preference and consumption behavior in Malaysia"
        ],
        "penulis":"Kusairi, Suhal;Sanusi, Nur Azura;Muhamad, Suriyani;Shukri, Madihah;Zamri, Nadia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Financial literacy is one of the sustainable development goals of huge concern of governments. Governments explore solutions addressing policies to improve financial literacy. Nevertheless, financial management has such a broad scope and is not just limited to knowledge. As human nature, individuals are born with different confidence levels that include various financial abilities. This study aims to investigate the household-financial efficacy through the application of psychometric instruments, risk preference, and demographic characteristics toward consumption decision behavior. The research is based on a survey 479 households in the peninsular Malaysia, and utilizes the structural equation model, cluster proportional and systematic random sampling, and two measurements-composite reliability and average variance extracted. Results show that households' financial efficacy is one of the critical factors that explain the households' consumption decision behavior. Also, risk preference, gender and area location (rural or urban) of the household determined the consumption decision behavior of the household. The effectiveness of consumption decision is not only determined by financial literacy, but also financial efficacy. The implications of this paper may help to design policies in narrowing the broad gap between the rural and urban level of financial efficacy. The government needs to take appropriate actions to fix it. \u00a9 The Author(s).",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Financial literacy is one of the sustainable development goals of huge concern of governments. Governments explore solutions addressing policies to improve financial literacy. Nevertheless, financial management has such a broad scope and is not just limited to knowledge. As human nature, individuals are born with different confidence levels that include various financial abilities. This study aims to investigate the household-financial efficacy through the application of psychometric instruments, risk preference, and demographic characteristics toward consumption decision behavior. The research is based on a survey 479 households in the peninsular Malaysia, and utilizes the structural equation model, cluster proportional and systematic random sampling, and two measurements-composite reliability and average variance extracted. Results show that households' financial efficacy is one of the critical factors that explain the households' consumption decision behavior. Also, risk preference, gender and area location (rural or urban) of the household determined the consumption decision behavior of the household. The effectiveness of consumption decision is not only determined by financial literacy, but also financial efficacy. The implications of this paper may help to design policies in narrowing the broad gap between the rural and urban level of financial efficacy. The government needs to take appropriate actions to fix it. \u00a9 The Author(s)."
        ]
    },
    {
        "judul":[
            "Analysis of critical success factors (CSF) in enterprise resource planning (ERP) implementation using extended technology acceptance model (TAM) at trading and distribution company"
        ],
        "penulis":"Putri, Aprilianti Dwi;Lubis, Muharman;Azizah, Anik Hanifatul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Enterprise Resource Planning (ERP) is an integrated system that has been used in several companies, including this Trading and Distribution Company. The company has implemented an ERP system at a certain time. The implementation of the ERP system not only broken off until the testing phase of the deployment process but also required some periodical analysis to improve the effectiveness. Lack of human resource skills and the business process of the company could be several major problems. Consequently, a specified analysis is needed n terms of improving the implementation of ERP in a company. The purpose of this research is to analyze the critical success factors (CSF) on ERP implementation in the company with the aim of identifying success factors that can be used to improve the performance system implementation, especially the human resource. Extended Technology Acceptance Model (TAM) was adopted to run the analysis. The research used quantitative data analysis in seeking core problems. Several variables defining CSF of ERP has built based on the TAM model. The result indicates that each variable in the model is a critical factor determining the success of the system's implementation. The result of the study could be exemplary guidance to find the CSF on ERP implementation. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Enterprise Resource Planning (ERP) is an integrated system that has been used in several companies, including this Trading and Distribution Company. The company has implemented an ERP system at a certain time. The implementation of the ERP system not only broken off until the testing phase of the deployment process but also required some periodical analysis to improve the effectiveness. Lack of human resource skills and the business process of the company could be several major problems. Consequently, a specified analysis is needed n terms of improving the implementation of ERP in a company. The purpose of this research is to analyze the critical success factors (CSF) on ERP implementation in the company with the aim of identifying success factors that can be used to improve the performance system implementation, especially the human resource. Extended Technology Acceptance Model (TAM) was adopted to run the analysis. The research used quantitative data analysis in seeking core problems. Several variables defining CSF of ERP has built based on the TAM model. The result indicates that each variable in the model is a critical factor determining the success of the system's implementation. The result of the study could be exemplary guidance to find the CSF on ERP implementation. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Wavelet-based hybrid audio watermarking using statistical mean manipulation and spread spectrum"
        ],
        "penulis":"Budiman, Gelar;Suksmono, Andriyan Bayu;Danudirdjo, Donny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, we propose a Discrete Wavelet Transform (DWT) - based hybrid audio watermarking using Statistical Mean Manipulation (SMM) and Spread Spectrum (SS) technique. The host audio is decomposed by DWT to produce the signal in low frequency subband and high frequency subband, where SMM embeds the watermark into low frequency in the first subband, and SS embeds the watermark into high frequency in the selected subband. The embedding process using the SMM technique is the insertion process by modifying the average of the audio signal in one frame according to the watermark, thus it modifies the audio in the low-frequency subband. The SS technique modulates the watermark before it is embedded into the host audio in the higher selected frequency subband. This combination technique produces the robust watermarking method to the signal processing attack, such as Low Pas Filter (LPF), resampling and audio compression while maintaining high watermarked audio quality and watermark payload. \u00a9 2020 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we propose a Discrete Wavelet Transform (DWT) - based hybrid audio watermarking using Statistical Mean Manipulation (SMM) and Spread Spectrum (SS) technique. The host audio is decomposed by DWT to produce the signal in low frequency subband and high frequency subband, where SMM embeds the watermark into low frequency in the first subband, and SS embeds the watermark into high frequency in the selected subband. The embedding process using the SMM technique is the insertion process by modifying the average of the audio signal in one frame according to the watermark, thus it modifies the audio in the low-frequency subband. The SS technique modulates the watermark before it is embedded into the host audio in the higher selected frequency subband. This combination technique produces the robust watermarking method to the signal processing attack, such as Low Pas Filter (LPF), resampling and audio compression while maintaining high watermarked audio quality and watermark payload. \u00a9 2020 IEEE"
        ]
    },
    {
        "judul":[
            "Road information collector using smartphone for measuring road width based on object and lane detection"
        ],
        "penulis":"Nasution, Surya Michrandi;Husni, Emir;Kuspriyanto K.;Yusuf, Rahadian;Mulyawan, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Change in traffic condition is unpredictable. This increases the need for alternate routes to avoid congestions and other conditions. The high variance of vehicle types in Indonesia complicates routing, rendering alternative routes sometimes become unavailable for a specific condition of vehicles. Our research is to develop an application for Android smartphone to collect road information and to offer alternative routes for motorcycles; this paper focuses on the first part of the task. The needed information to acquire is road width, so the drivers could use proper alternative routes for their vehicles (e.g. small car or motorcycles). This research uses both object detection and lane detection methods for obtaining road width, and it is quite simple when lane boundaries are detected in road image. When the lane boundaries are not detected, road width is obtained using a vanishing point method. The average error rate for road width measurement using object and lane detection is 19.71%. Meanwhile, the average error rate when there is no lane boundary is in the range of 10-15%, 8-18%, and 10-19% for various capturing sides. Reclassification of the road is done when the error rate of road width is set. Accuracy of road category reclassification is in the range of 70-75% in various sides. \u00a9 2020 International Association of Online Engineering.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Change in traffic condition is unpredictable. This increases the need for alternate routes to avoid congestions and other conditions. The high variance of vehicle types in Indonesia complicates routing, rendering alternative routes sometimes become unavailable for a specific condition of vehicles. Our research is to develop an application for Android smartphone to collect road information and to offer alternative routes for motorcycles; this paper focuses on the first part of the task. The needed information to acquire is road width, so the drivers could use proper alternative routes for their vehicles (e.g. small car or motorcycles). This research uses both object detection and lane detection methods for obtaining road width, and it is quite simple when lane boundaries are detected in road image. When the lane boundaries are not detected, road width is obtained using a vanishing point method. The average error rate for road width measurement using object and lane detection is 19.71%. Meanwhile, the average error rate when there is no lane boundary is in the range of 10-15%, 8-18%, and 10-19% for various capturing sides. Reclassification of the road is done when the error rate of road width is set. Accuracy of road category reclassification is in the range of 70-75% in various sides. \u00a9 2020 International Association of Online Engineering."
        ]
    },
    {
        "judul":[
            "The Development of Information System Security Operation Centre (SOC): Case Study of Auto Repair Company"
        ],
        "penulis":"Lubis, Muharman;Wardana, Chandra;Widjajarto, Adityas;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Auto repair is a series of activities that engage in the field of body repair and painting services of car and motorcycle. The ultimate goal is to provide the best service and quality standards to customers by running the proper response processes, which lead the increased customer satisfaction to be achieved. Importantly, every company required the security system and mechanism to maintain the existing system as an effort to protect and overcome problems related to data privacy, transactions and communication. This study explores the problem and challenges faced by the respected company to generate an access control matrix for logical and physical assets as well as service operation procedure. The focus primarily in the development of Security Operation Center (SOC) as the front gate of the company to offer various services to the customers. SOC is a key enabler for operators who aspire to differentiate themselves based on customer experience and demand. A successful SOC application can help operators to reduce the pressure and improve operational efficiency.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Auto repair is a series of activities that engage in the field of body repair and painting services of car and motorcycle. The ultimate goal is to provide the best service and quality standards to customers by running the proper response processes, which lead the increased customer satisfaction to be achieved. Importantly, every company required the security system and mechanism to maintain the existing system as an effort to protect and overcome problems related to data privacy, transactions and communication. This study explores the problem and challenges faced by the respected company to generate an access control matrix for logical and physical assets as well as service operation procedure. The focus primarily in the development of Security Operation Center (SOC) as the front gate of the company to offer various services to the customers. SOC is a key enabler for operators who aspire to differentiate themselves based on customer experience and demand. A successful SOC application can help operators to reduce the pressure and improve operational efficiency.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Feature Correlation for Music Genre Classification"
        ],
        "penulis":"Leleuly, Manuel Theodore;Gunawan P.H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Music genre classification has been widely discussed by some researcher. There are various methods used to classify many types of music genres, however only a small part of them considered the importance of feature correlation. This feature correlation is to select features to increase the accuracy of classification process. In this paper, we investigate the big role of features correlation where features are obtained from entropy of root mean square and frequency. Moreover, we use probabilistic neural network (PNN) as the classifier. In this paper, results showed that accuracy using all feature (without considering feature correlation) is obtained 70%, meanwhile using selected features from correlation score, accuracy is conducted 90%. The selected features from this high accuracy are minimum and average RMS entropy of all RMS entropies in each music frame, and minimum and average frequency entropy of all entropies in each music frame.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Music genre classification has been widely discussed by some researcher. There are various methods used to classify many types of music genres, however only a small part of them considered the importance of feature correlation. This feature correlation is to select features to increase the accuracy of classification process. In this paper, we investigate the big role of features correlation where features are obtained from entropy of root mean square and frequency. Moreover, we use probabilistic neural network (PNN) as the classifier. In this paper, results showed that accuracy using all feature (without considering feature correlation) is obtained 70%, meanwhile using selected features from correlation score, accuracy is conducted 90%. The selected features from this high accuracy are minimum and average RMS entropy of all RMS entropies in each music frame, and minimum and average frequency entropy of all entropies in each music frame.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Seismic data compression using deep neural network predictors"
        ],
        "penulis":"Nuha H.;Balghonaim A.;Mohandes M.;Liu, Bo;Fekri, Faramarz;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Seismic data compression is highly demanded to reduce the cost for transmission and storage due to an enormous volume of collected data. This paper presents a prediction based compression for seismic data using deep neural networks (DNN) and entropy encoding. First, a DNN with multiple hidden layers is pre-trained using restricted Boltzmann machines (RBMs) to obtain good initial weights. The DNN is then fine-tuned in a supervised fashion to achieve a better prediction precision. The residual between actual and predicted samples are quantized to achieve smaller data representation. The quantized residuals are further encoded using the Huffman coding. Our experiments with a real data set show that the DNN significantly outperforms the Linear Predictive Compression (LPC) in term of reconstruction quality. \u00a9 2019 SEG",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Seismic data compression is highly demanded to reduce the cost for transmission and storage due to an enormous volume of collected data. This paper presents a prediction based compression for seismic data using deep neural networks (DNN) and entropy encoding. First, a DNN with multiple hidden layers is pre-trained using restricted Boltzmann machines (RBMs) to obtain good initial weights. The DNN is then fine-tuned in a supervised fashion to achieve a better prediction precision. The residual between actual and predicted samples are quantized to achieve smaller data representation. The quantized residuals are further encoded using the Huffman coding. Our experiments with a real data set show that the DNN significantly outperforms the Linear Predictive Compression (LPC) in term of reconstruction quality. \u00a9 2019 SEG"
        ]
    },
    {
        "judul":[
            "Research on a Project Schedule of Factory Renovation for Manufacturing Plants in Bandung"
        ],
        "penulis":"Tripiawan W.;Miranda S.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Renovating a plant facility is an example of a project. It is a complex process that the project needs to complete all the task while ensuring the operations without disruption. In project management, scheduling and cost optimization are two main operation problems. These correlate with each other and have proven mathematical solutions for the basics. In this study, the case study faced was to prepare a schedule plan in the process of renovating factory facilities. The facilities to be renovated are based on 2 main facilities, namely Production office facilities and Fabrication plant facilities. The implementation of the renovation of the 2 facilities has constraints in the time available. With the CCPM approach, this study proposes a schedule for implementing renovation projects with limited availability of time. The results obtained; this factory facility renovation project is scheduled to be completed less than 40 calendar days. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Renovating a plant facility is an example of a project. It is a complex process that the project needs to complete all the task while ensuring the operations without disruption. In project management, scheduling and cost optimization are two main operation problems. These correlate with each other and have proven mathematical solutions for the basics. In this study, the case study faced was to prepare a schedule plan in the process of renovating factory facilities. The facilities to be renovated are based on 2 main facilities, namely Production office facilities and Fabrication plant facilities. The implementation of the renovation of the 2 facilities has constraints in the time available. With the CCPM approach, this study proposes a schedule for implementing renovation projects with limited availability of time. The results obtained; this factory facility renovation project is scheduled to be completed less than 40 calendar days. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Nonlinear SWE and Experimental Observation for Wave Simulation due to Bottom Motion"
        ],
        "penulis":"Themba, Astrid Velia;Gunawan P.H.;Aditsania, Annisa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Natural disasters can occur everywhere, causing geological and complex problems. One of the devastating natural disasters is the water wave disaster. Several factors can form a water wave disaster, one of them is due to the bottom motion of the water surface. This paper presents the simulation of numerical modeling waves due to the bottom motion using the 1D nonlinear SWE. Here, the staggered grid is used to help to discretize the model. Experiments are carried out eleven times to produce data for making wave simulations. The results of experiments and simulation results are compared and analyzed using the formula Root Mean Square Error (RMSE). This study aims to prove whether the nonlinear SWE model can simulate experimental waves accurately. The results showed that the shallow water equations model could represent the experimental results well with an error value of 0.000058.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Natural disasters can occur everywhere, causing geological and complex problems. One of the devastating natural disasters is the water wave disaster. Several factors can form a water wave disaster, one of them is due to the bottom motion of the water surface. This paper presents the simulation of numerical modeling waves due to the bottom motion using the 1D nonlinear SWE. Here, the staggered grid is used to help to discretize the model. Experiments are carried out eleven times to produce data for making wave simulations. The results of experiments and simulation results are compared and analyzed using the formula Root Mean Square Error (RMSE). This study aims to prove whether the nonlinear SWE model can simulate experimental waves accurately. The results showed that the shallow water equations model could represent the experimental results well with an error value of 0.000058.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Social Media Technology Adoption for Improving MSMEs Performance in Bandung: A Technology-Organization-Environment (TOE) Framework"
        ],
        "penulis":"Wulandari, Astri;Suryawardani, Bethani;Marcelino, Dandy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The use of the internet in business activities is a common thing to do in business world. Likewise, with MSMEs, many of them have already used the internet in their business activities. City and Regency of Bandung are the two regions that experience the best MSMEs growth in West Java. This is because these two regions are included in the position of three regions with the largest number of MSMEs in West Java. In addition, the two regions consistently won the achievement as five regions in West Java with the best financial performance measured by the ratio of cost to income. This study is expected to provide several implications related to social media technology adoption with determinant factors of TOE (technology, organization, environment) to improve the business performance of MSMEs. Researchers used quantitative research methods namely causal, with SEM (Structural Equation Model) analysis techniques by SMART PLS 2.0 software. The sampling technique chosen is accidental with a total of 400 respondents. Finding from this research which technology, organization, and environment are the factors that encourage MSMEs in adopting social media, then will impact the performance of MSMEs which include customer services, sales, marketing, and internal operations. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of the internet in business activities is a common thing to do in business world. Likewise, with MSMEs, many of them have already used the internet in their business activities. City and Regency of Bandung are the two regions that experience the best MSMEs growth in West Java. This is because these two regions are included in the position of three regions with the largest number of MSMEs in West Java. In addition, the two regions consistently won the achievement as five regions in West Java with the best financial performance measured by the ratio of cost to income. This study is expected to provide several implications related to social media technology adoption with determinant factors of TOE (technology, organization, environment) to improve the business performance of MSMEs. Researchers used quantitative research methods namely causal, with SEM (Structural Equation Model) analysis techniques by SMART PLS 2.0 software. The sampling technique chosen is accidental with a total of 400 respondents. Finding from this research which technology, organization, and environment are the factors that encourage MSMEs in adopting social media, then will impact the performance of MSMEs which include customer services, sales, marketing, and internal operations. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis and Design of Master Data Monitoring Application using Open Source Tools: A Case Study at Government Agency"
        ],
        "penulis":"Naufal, Muhammad Ariq;Kusumasari, Tien Fabrianti;Alam, Ekky Novriza;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Master data management is a process to integrate several data sources into one for good, consistent, and evenly standardized data. Several companies have been successful in creating a good quality data source for their data. However, some companies yet to have this system. A government agency in Indonesia finds difficulties in managing their data source. The problem lies in data duplication, lack of control on data reference, and the lack of application to monitor all data sources. This paper is carried out to fix the MDM monitoring dashboard that has been created in advance. The monitoring dashboard is created with the pureshare method. This paper designed a monitoring dashboardthat can monitor the process and quality of master data. The benefit of this research is to get good quality and consistent master data, which can be used in all organizations, and its authenticity can be guaranteed. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Master data management is a process to integrate several data sources into one for good, consistent, and evenly standardized data. Several companies have been successful in creating a good quality data source for their data. However, some companies yet to have this system. A government agency in Indonesia finds difficulties in managing their data source. The problem lies in data duplication, lack of control on data reference, and the lack of application to monitor all data sources. This paper is carried out to fix the MDM monitoring dashboard that has been created in advance. The monitoring dashboard is created with the pureshare method. This paper designed a monitoring dashboardthat can monitor the process and quality of master data. The benefit of this research is to get good quality and consistent master data, which can be used in all organizations, and its authenticity can be guaranteed. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A Qualitative Study of Teenagers Viewpoint in Dealing with Parents\u2019 Divorce in Indonesia"
        ],
        "penulis":"Supratman, Lucy Pujasari;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Divorce in Indonesia has considered to be a stigma. The stigma does not only affect the spouses, but also their kids. This qualitative study explored the viewpoint of Indonesia teenagers in dealing with parents\u2019 divorce. There were 20 teenagers between 18 to 19 years old who were interviewed. The findings shown that they felt self-pity, blaming the parents, and disappointed as the result of their parent\u2019s divorce decision. During the teenager\u2019s acceptance process, their single parent had done the interpersonal communication to explain the reasons for divorce simultaneously. Their interpersonal communication messages about being whole-hearted, accepting God's destiny, respecting the elder and upholding harmonization among family members, helped them to deal with parents\u2019 divorce. \u00a9 2019, \u00a9 2019 Taylor & Francis Group, LLC.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Divorce in Indonesia has considered to be a stigma. The stigma does not only affect the spouses, but also their kids. This qualitative study explored the viewpoint of Indonesia teenagers in dealing with parents\u2019 divorce. There were 20 teenagers between 18 to 19 years old who were interviewed. The findings shown that they felt self-pity, blaming the parents, and disappointed as the result of their parent\u2019s divorce decision. During the teenager\u2019s acceptance process, their single parent had done the interpersonal communication to explain the reasons for divorce simultaneously. Their interpersonal communication messages about being whole-hearted, accepting God's destiny, respecting the elder and upholding harmonization among family members, helped them to deal with parents\u2019 divorce. \u00a9 2019, \u00a9 2019 Taylor & Francis Group, LLC."
        ]
    },
    {
        "judul":[
            "The influence of children's playroom interior aspect in regard to parental safety perception. Case study: Children's playroom at 23 Paskal Bandung, Indonesia"
        ],
        "penulis":"Rachmawati, Rizka;Hanom, Imtihan;Salayanti, Santi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Children's playrooms in public spaces need to consider the safety of their interior elements. Previous studies also discussed about things that need to be taken into account to assure the children's safety while playing. However, some parents join their children playing in public spaces due to the cautiousness of playground safety level. This study was conducted to understand how far the interior aspects of children's playgrounds can affect parents' safety perception to let their children play by themselves in public spaces, for example, the children's playroom in 23 Paskal Bandung, West Java, Indonesia. The result shows that sufficient light, interior finishes, and noise or sound intensity in the children's playground at 23 Paskal Bandung, Indonesia can make parents feel safe to let their children spend time there. \u00a9 Malaysian Public Health Physicians Association.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Children's playrooms in public spaces need to consider the safety of their interior elements. Previous studies also discussed about things that need to be taken into account to assure the children's safety while playing. However, some parents join their children playing in public spaces due to the cautiousness of playground safety level. This study was conducted to understand how far the interior aspects of children's playgrounds can affect parents' safety perception to let their children play by themselves in public spaces, for example, the children's playroom in 23 Paskal Bandung, West Java, Indonesia. The result shows that sufficient light, interior finishes, and noise or sound intensity in the children's playground at 23 Paskal Bandung, Indonesia can make parents feel safe to let their children spend time there. \u00a9 Malaysian Public Health Physicians Association."
        ]
    },
    {
        "judul":[
            "Blood glucose prediction model for type 1 diabetes based on artificial neural network with time-domain features"
        ],
        "penulis":"Alfian, Ganjar;Syafrudin, Muhammad;Anshari, Muhammad;Benes, Filip;Atmaji, Fransiskus Tatas Dwi;Fahrurrozi, Imam;Hidayatullah, Ahmad Fathan;Rhee, Jongtae;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Predicting future blood glucose (BG) levels for diabetic patients will help them avoid potentially critical health issues. We demonstrate the use of machine learning models to predict future blood glucose levels given a history of blood glucose values as the single input parameter. We propose an Artificial Neural Network (ANN) model with time-domain attributes to predict blood glucose levels 15, 30, 45 and 60 min in the future. Initially, the model's features are selected based on the previous 30 min of BG measurements before a trained model is generated for each patient. These features are combined with time-domain attributes to give additional inputs to the proposed ANN. The prediction model was tested on 12 patients with Type 1 diabetes (T1D) and the results were compared with other data-driven models including the Support Vector Regression (SVR), K-Nearest Neighbor (KNN), C4.5 Decision Tree (DT), Random Forest (RF), Adaptive Boosting (AdaBoost) and eXtreme Gradient Boosting (XGBoost) models. Our results show that the proposed BG prediction model that is based on an ANN outperformed all other models with an average Root Mean Square Error (RMSE) of 2.82, 6.31, 10.65 and 15.33 mg\/dL for Prediction Horizons (PHs) of 15, 30, 45 and 60 min, respectively. Our testing showed that combining time-domain attributes into the input data resulted in enhanced performance of majority of prediction models. The implementation of proposed prediction model allows patients to obtain future blood glucose levels, so that the preventive alerts can be generated before critical hypoglycemic\/ hyperglycemic events occur. \u00a9 2020 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Predicting future blood glucose (BG) levels for diabetic patients will help them avoid potentially critical health issues. We demonstrate the use of machine learning models to predict future blood glucose levels given a history of blood glucose values as the single input parameter. We propose an Artificial Neural Network (ANN) model with time-domain attributes to predict blood glucose levels 15, 30, 45 and 60 min in the future. Initially, the model's features are selected based on the previous 30 min of BG measurements before a trained model is generated for each patient. These features are combined with time-domain attributes to give additional inputs to the proposed ANN. The prediction model was tested on 12 patients with Type 1 diabetes (T1D) and the results were compared with other data-driven models including the Support Vector Regression (SVR), K-Nearest Neighbor (KNN), C4.5 Decision Tree (DT), Random Forest (RF), Adaptive Boosting (AdaBoost) and eXtreme Gradient Boosting (XGBoost) models. Our results show that the proposed BG prediction model that is based on an ANN outperformed all other models with an average Root Mean Square Error (RMSE) of 2.82, 6.31, 10.65 and 15.33 mg\/dL for Prediction Horizons (PHs) of 15, 30, 45 and 60 min, respectively. Our testing showed that combining time-domain attributes into the input data resulted in enhanced performance of majority of prediction models. The implementation of proposed prediction model allows patients to obtain future blood glucose levels, so that the preventive alerts can be generated before critical hypoglycemic\/ hyperglycemic events occur. \u00a9 2020 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences"
        ]
    },
    {
        "judul":[
            "Sequential Dual Attention Network for Rain Streak Removal in a Single Image"
        ],
        "penulis":"Lin, Chih-Yang;Tao, Zhuang;Xu, Ai-Sheng;Kang, Li-Wei;Akhyar, Fityanul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Various weather conditions, such as rain, haze, or snow, can degrade visual quality in images\/videos, which may significantly degrade the performance of related applications. In this paper, a novel framework based on sequential dual attention deep network is proposed for removing rain streaks (deraining) in a single image, called by SSDRNet (Sequential dual attention-based Single image DeRaining deep Network). Since the inherent correlation among rain steaks within an image should be stronger than that between the rain streaks and the background (non-rain) pixels, a two-stage learning strategy is implemented to better capture the distribution of rain streaks within a rainy image. The two-stage deep neural network primarily involves three blocks: residual dense blocks (RDBs), sequential dual attention blocks (SDABs), and multi-scale feature aggregation modules (MAMs), which are all delicately and specifically designed for rain removal. The two-stage strategy successfully learns very fine details of the rain steaks of the image and then clearly removes them. Extensive experimental results have shown that the proposed deep framework achieves the best performance on qualitative and quantitative metrics compared with state-of-the-art methods. The corresponding code and the trained model of the proposed SSDRNet have been available online at https:\/\/github.com\/fityanul\/SDAN-for-Rain-Removal. \u00a9 1992-2012 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Various weather conditions, such as rain, haze, or snow, can degrade visual quality in images\/videos, which may significantly degrade the performance of related applications. In this paper, a novel framework based on sequential dual attention deep network is proposed for removing rain streaks (deraining) in a single image, called by SSDRNet (Sequential dual attention-based Single image DeRaining deep Network). Since the inherent correlation among rain steaks within an image should be stronger than that between the rain streaks and the background (non-rain) pixels, a two-stage learning strategy is implemented to better capture the distribution of rain streaks within a rainy image. The two-stage deep neural network primarily involves three blocks: residual dense blocks (RDBs), sequential dual attention blocks (SDABs), and multi-scale feature aggregation modules (MAMs), which are all delicately and specifically designed for rain removal. The two-stage strategy successfully learns very fine details of the rain steaks of the image and then clearly removes them. Extensive experimental results have shown that the proposed deep framework achieves the best performance on qualitative and quantitative metrics compared with state-of-the-art methods. The corresponding code and the trained model of the proposed SSDRNet have been available online at https:\/\/github.com\/fityanul\/SDAN-for-Rain-Removal. \u00a9 1992-2012 IEEE."
        ]
    },
    {
        "judul":[
            "Soft set theory based decision support system for mining electronic government dataset"
        ],
        "penulis":"Witarsyah, Deden;Md Fudzee, Mohd Farhan;Salamat, Mohamad Aizi;Riyadi Yanto, Iwan Tri;Abawajy, Jemal;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Electronic government (e-gov) is applied to support performance and create more efficient and effective public services. Grouping data in soft-set theory can be considered as a decision-making technique for determining the maturity level of e-government use. So far, the uncertainty of the data obtained through the questionnaire has not been maximally used as an appropriate reference for the government in determining the direction of future e-gov development policy. This study presents the maximum attribute relative (MAR) based on soft set theory to classify attribute options. The results show that facilitation conditions (FC) are the highest variable in influencing people to use e-government, followed by performance expectancy (PE) and system quality (SQ). The results provide useful information for decision makers to make policies about their citizens and potentially provide recommendations on how to design and develop e-government systems in improving public services. Copyright \u00a9 2020, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electronic government (e-gov) is applied to support performance and create more efficient and effective public services. Grouping data in soft-set theory can be considered as a decision-making technique for determining the maturity level of e-government use. So far, the uncertainty of the data obtained through the questionnaire has not been maximally used as an appropriate reference for the government in determining the direction of future e-gov development policy. This study presents the maximum attribute relative (MAR) based on soft set theory to classify attribute options. The results show that facilitation conditions (FC) are the highest variable in influencing people to use e-government, followed by performance expectancy (PE) and system quality (SQ). The results provide useful information for decision makers to make policies about their citizens and potentially provide recommendations on how to design and develop e-government systems in improving public services. Copyright \u00a9 2020, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited."
        ]
    },
    {
        "judul":[
            "Single camera depth control in micro class ROV"
        ],
        "penulis":"Siregar, Simon;Sani, Muhammad Ikhsan;Parlindungan Silalahi, Sintong Tua;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Navigation is one of the main challenges in an underwater vehicle. To measure and sustain the depth in the micro class remotely operated vehicle (ROV) robot is one of the main demands in the underwater robot competition. There are many sensors that can be used to measure the depth; one of the sensors is using a single camera sensor. In this works, camera-based depth control is developed and evaluated for micro class ROV, namely as fitoplankton SAS ROV. Fitoplankton SAS ROV is a micro ROV prototype with six thrusters. To maintain the depth position, a PID control system with a camera-based depth sensor as the input of the setpoint is used. Moreover, the method for the camera to measure the distance is using the triangle similarity method. In this paper, the experimental scenario is using the rectangular marker to measure the distance, and the value of the depth is processing in the ground control station (GCS). The GCS will send the thruster value to control the depth, which depends on the PID control system. The experiment results show an average of depth accuracy of 95.74% to the depth setpoint. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Navigation is one of the main challenges in an underwater vehicle. To measure and sustain the depth in the micro class remotely operated vehicle (ROV) robot is one of the main demands in the underwater robot competition. There are many sensors that can be used to measure the depth; one of the sensors is using a single camera sensor. In this works, camera-based depth control is developed and evaluated for micro class ROV, namely as fitoplankton SAS ROV. Fitoplankton SAS ROV is a micro ROV prototype with six thrusters. To maintain the depth position, a PID control system with a camera-based depth sensor as the input of the setpoint is used. Moreover, the method for the camera to measure the distance is using the triangle similarity method. In this paper, the experimental scenario is using the rectangular marker to measure the distance, and the value of the depth is processing in the ground control station (GCS). The GCS will send the thruster value to control the depth, which depends on the PID control system. The experiment results show an average of depth accuracy of 95.74% to the depth setpoint. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Stock price modeling using localized multiple kernel learning support vector machine"
        ],
        "penulis":"Yasin, Hasbi;Caraka, Rezzy Eko;Hoyyi, Abdul;Sugito;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Effectively and efficiently learning an optimal kernel is of great importance to the success of kernel method. Along with this line of research, many pioneering kernel learning algorithms have been proposed, developed and combined in many ways. This paper aims to explain the application of Localized Multiple Kernel Learning Support Vector Machine (LMKL-SVM) to predict the daily stock price of PT.XL Axiata Tbk (EXCL), PT.Indofood SuksesMakmur Tbk (INDF) and PT.Unilever Indonesia Tbk (UNVR) from January 2014 to May 2016. It can be concluded that LMKL-SVM has good performance to predict daily stock price with Mean Absolute Percentage Error (MAPE) produced all less than 2%. \u00a9 2020 ICIC International.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Effectively and efficiently learning an optimal kernel is of great importance to the success of kernel method. Along with this line of research, many pioneering kernel learning algorithms have been proposed, developed and combined in many ways. This paper aims to explain the application of Localized Multiple Kernel Learning Support Vector Machine (LMKL-SVM) to predict the daily stock price of PT.XL Axiata Tbk (EXCL), PT.Indofood SuksesMakmur Tbk (INDF) and PT.Unilever Indonesia Tbk (UNVR) from January 2014 to May 2016. It can be concluded that LMKL-SVM has good performance to predict daily stock price with Mean Absolute Percentage Error (MAPE) produced all less than 2%. \u00a9 2020 ICIC International."
        ]
    },
    {
        "judul":[
            "Intrusion Detection System using Genetic Algorithm and K-NN Algorithm on Dos Attack"
        ],
        "penulis":"Fauzi, Muhammad Akmal;Hanuranto, Ahmad Tri;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Intrusion Detection is the process of monitoring and identifying activity on a host or network to prove whether the host or network has been successfully attacked or is still an attempt at aggression. Intrusion Detection System (IDS) helps monitor the network based on various anomalies (unusual events) that can indicate threats of hacker aggression, malware, or vulnerabilities in a system. IDS will monitor and provide a warning of whether an activity is classified as malicious or not. Furthermore, IDS will organize it into several strata levels of risk. This is very helpful for prioritizing any activity anomalies that require more attention and handling. This study analyzed the IDS process with a selection feature using genetic algorithms and classification using the KNN algorithm and KDD99 as the dataset. By selecting the best features from 41 to 18, the scenario in this study gets an average training data accuracy of 99.98% and testing data of 97.52% in the parameters K = 5 and K = 7. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Intrusion Detection is the process of monitoring and identifying activity on a host or network to prove whether the host or network has been successfully attacked or is still an attempt at aggression. Intrusion Detection System (IDS) helps monitor the network based on various anomalies (unusual events) that can indicate threats of hacker aggression, malware, or vulnerabilities in a system. IDS will monitor and provide a warning of whether an activity is classified as malicious or not. Furthermore, IDS will organize it into several strata levels of risk. This is very helpful for prioritizing any activity anomalies that require more attention and handling. This study analyzed the IDS process with a selection feature using genetic algorithms and classification using the KNN algorithm and KDD99 as the dataset. By selecting the best features from 41 to 18, the scenario in this study gets an average training data accuracy of 99.98% and testing data of 97.52% in the parameters K = 5 and K = 7. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Forensic malware identification using naive bayes method"
        ],
        "penulis":"Ramadhan, Beno;Purwanto, Yudha;Ruriawan, Muhammad Faris;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Malware is a kind of software that, if installed on a malware victim's device, might carry malicious actions. The malicious actions might be data theft, system failure, or denial of service. Malware analysis is a process to identify whether a piece of software is a malware or not. However, with the advancement of malware technologies, there are several evasion techniques that could be implemented by malware developers to prevent analysis, such as polymorphic and oligomorphic. Therefore, this research proposes an automatic malware detection system. In the system, the malware characteristics data were obtained through both static and dynamic analysis processes. Data from the analysis process were classified using Naive Bayes algorithm to identify whether the software is a malware or not. The process of identifying malware and benign files using the Naive Bayes machine learning method has an accuracy value of 93 percent for the detection process using static characteristics and 85 percent for detection through dynamic characteristics.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Malware is a kind of software that, if installed on a malware victim's device, might carry malicious actions. The malicious actions might be data theft, system failure, or denial of service. Malware analysis is a process to identify whether a piece of software is a malware or not. However, with the advancement of malware technologies, there are several evasion techniques that could be implemented by malware developers to prevent analysis, such as polymorphic and oligomorphic. Therefore, this research proposes an automatic malware detection system. In the system, the malware characteristics data were obtained through both static and dynamic analysis processes. Data from the analysis process were classified using Naive Bayes algorithm to identify whether the software is a malware or not. The process of identifying malware and benign files using the Naive Bayes machine learning method has an accuracy value of 93 percent for the detection process using static characteristics and 85 percent for detection through dynamic characteristics.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A method for estimating technical losses in primary feeder conductors"
        ],
        "penulis":"Zein, Hermagasantos;Raharjo, Jangkung;Wachjoe, Conny K.;Mulyadi, Ahmad Deni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One of the engineers\u2019 concerns is the loss of energy in the electric power system. Actually, most of the energy losses occur in the distribution system, i.e., about 4-8%. Therefore, efforts should be made in order to improve the performance of the distribution networks. Evaluating losses in the distribution networks should be done in order to reduce losses. The problem is that there are many nodes, several lateral feeders, and the un-uniform current flowing in the feeder so that calculating the losses becomes very difficult. In addition, the big distribution system has so many feeders, generally more than 1000 feeders, with various types. Thus, the calculation of the losses in the distribution system will face very complex and large-scale problems. Therefore, calculating losses for large scale distributed systems that use load flow or measurement methods is not possible. This paper proposes an effective method that uses a lump load model for technical losses in distribution systems. By approaching, the current is proportional to power, the input current into the feeder can be distributed to each lateral feeder. Thus, the current flow in each segment of the feeder can be determined. For typical feeder with the load currents changed linearly by linearity factor, then-current flows of each segment feeder can be easily determined as c function. This function is created as a calculation model of losses with a clear derivative of the mathematical formulations. The results of numerical studies show that this method is accurate enough with the error of 1.26% when compared to the load flow method using an 8-node feeder. The calculation result is based on the IEEE 13-node test feeder; its loss is smaller than 3.86% compared to the load flow method. \u00a9 2020 Praise Worthy Prize S.r.l. - All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the engineers\u2019 concerns is the loss of energy in the electric power system. Actually, most of the energy losses occur in the distribution system, i.e., about 4-8%. Therefore, efforts should be made in order to improve the performance of the distribution networks. Evaluating losses in the distribution networks should be done in order to reduce losses. The problem is that there are many nodes, several lateral feeders, and the un-uniform current flowing in the feeder so that calculating the losses becomes very difficult. In addition, the big distribution system has so many feeders, generally more than 1000 feeders, with various types. Thus, the calculation of the losses in the distribution system will face very complex and large-scale problems. Therefore, calculating losses for large scale distributed systems that use load flow or measurement methods is not possible. This paper proposes an effective method that uses a lump load model for technical losses in distribution systems. By approaching, the current is proportional to power, the input current into the feeder can be distributed to each lateral feeder. Thus, the current flow in each segment of the feeder can be determined. For typical feeder with the load currents changed linearly by linearity factor, then-current flows of each segment feeder can be easily determined as c function. This function is created as a calculation model of losses with a clear derivative of the mathematical formulations. The results of numerical studies show that this method is accurate enough with the error of 1.26% when compared to the load flow method using an 8-node feeder. The calculation result is based on the IEEE 13-node test feeder; its loss is smaller than 3.86% compared to the load flow method. \u00a9 2020 Praise Worthy Prize S.r.l. - All rights reserved."
        ]
    },
    {
        "judul":[
            "Technical specification for effective next generation network interconnection in Indonesia"
        ],
        "penulis":"Abdurohman, Maman;Nugroho, Bambang Setia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper proposes technical specifications for effectively implementing the interconnection of Next Generation Network (NGN) in Indonesia. NGN is one of the current telecommunication infrastructure network technology trends. It provides a simpler concept with only two layers of service and transport. The NGN IP-based transport system can connect with various types of networks, which leads to low management costs by offering different kinds of services. Meanwhile, there are currently various types of telecommunication networks depending on the services provided, such as Public Switched Telephone Network (PSTN), IPv4 Internet as well as Public Switched Data Network (PSDN). PSTN is a circuit-switched voice communications network, and PSDN is a network for data-based communications with International Telecommunication Union (ITU)-T X.121 standards. Another type is a packet-switched based network that uses IPv4 addressing systems. Each network has its customers. One of the problems that arise, however, is how to transform the current network system to the NGN network effectively. The effectiveness of network transformation in the service provision for users is determined by the technical aspects used. Some of the technical aspects issues on implementation of NGN networks in Indonesia are the use of a protocol for signaling, coding standards, Quality of Service (QoS), numbering and addressing, and security. This paper proposes technical specifications for the effectiveness of NGN network implementation in Indonesia. Through the technical specification model, we propose, the risks that will arise in the implementation of NGN networks in Indonesia can be managed. Appropriate technical specifications have an essential role in the effectiveness of NGN network implementation in Indonesia. \u00a9 2020, Insight Society.",
            "OH3CCH3SHSView detailsExpand Substance isopropylxanthic acid",
            "Powered by",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes technical specifications for effectively implementing the interconnection of Next Generation Network (NGN) in Indonesia. NGN is one of the current telecommunication infrastructure network technology trends. It provides a simpler concept with only two layers of service and transport. The NGN IP-based transport system can connect with various types of networks, which leads to low management costs by offering different kinds of services. Meanwhile, there are currently various types of telecommunication networks depending on the services provided, such as Public Switched Telephone Network (PSTN), IPv4 Internet as well as Public Switched Data Network (PSDN). PSTN is a circuit-switched voice communications network, and PSDN is a network for data-based communications with International Telecommunication Union (ITU)-T X.121 standards. Another type is a packet-switched based network that uses IPv4 addressing systems. Each network has its customers. One of the problems that arise, however, is how to transform the current network system to the NGN network effectively. The effectiveness of network transformation in the service provision for users is determined by the technical aspects used. Some of the technical aspects issues on implementation of NGN networks in Indonesia are the use of a protocol for signaling, coding standards, Quality of Service (QoS), numbering and addressing, and security. This paper proposes technical specifications for the effectiveness of NGN network implementation in Indonesia. Through the technical specification model, we propose, the risks that will arise in the implementation of NGN networks in Indonesia can be managed. Appropriate technical specifications have an essential role in the effectiveness of NGN network implementation in Indonesia. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[
            "Microarray Data Classification to Detect Cancer Cells by Using Discrete Wavelet Transform and Combining Classifiers Methods"
        ],
        "penulis":"Gusman, Hanafi Abdullah;Adiwijaya;Astuti, Widi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Cancer has become a disease with the highest worldwide mortality rate, reaching 9.6 million occurrences in the year 2018. Researchers are using microarray data to observe the level of cancer expression gene. However, microarray data have huge data attribute and it causes curse of dimensionality. Thus, data processing takes a longer time. Dimensional reduction technique by using Discrete Wavelet Transform is being used in this research to solve these problems. The dimensional reduction process is utilizing the family daubechies4. Then, a method between K-nearest Neighbor and Support Vector Machines is chosen based on the neighbor similarity during the data classification process. Therefore, the created system could produce 95% classification accuracy for colon cancer's data, 88.88% for breast cancer's data, 87.16% for lung cancer's data, and 100% for ovarian cancer's data.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer has become a disease with the highest worldwide mortality rate, reaching 9.6 million occurrences in the year 2018. Researchers are using microarray data to observe the level of cancer expression gene. However, microarray data have huge data attribute and it causes curse of dimensionality. Thus, data processing takes a longer time. Dimensional reduction technique by using Discrete Wavelet Transform is being used in this research to solve these problems. The dimensional reduction process is utilizing the family daubechies4. Then, a method between K-nearest Neighbor and Support Vector Machines is chosen based on the neighbor similarity during the data classification process. Therefore, the created system could produce 95% classification accuracy for colon cancer's data, 88.88% for breast cancer's data, 87.16% for lung cancer's data, and 100% for ovarian cancer's data.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Wi-fi Communication Methods for Internet of Things-based Sensor Telemetry with a Visual Basic-based User Interface"
        ],
        "penulis":"Iswanto;Megantoro, Prisma;Pramudita, Brahmantya Aji;Winarno, Hendra Ari;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Ineffectiveness in sending remote measurement data causes data transmission to be slow and not real-time. That is because the communication media still use conventional methods. In this paper, IoT is used to overcome the problem of the ineffectiveness of sending data from remote measurements, and using IoT remote measurements can increase the practicality and reliability of measurements. The proposed method is successfully sending several analog data from NodeMCU to computer wirelessly via WiFi and it can manage the communication and not only process the data effectively but also real-time by a visual-based application.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ineffectiveness in sending remote measurement data causes data transmission to be slow and not real-time. That is because the communication media still use conventional methods. In this paper, IoT is used to overcome the problem of the ineffectiveness of sending data from remote measurements, and using IoT remote measurements can increase the practicality and reliability of measurements. The proposed method is successfully sending several analog data from NodeMCU to computer wirelessly via WiFi and it can manage the communication and not only process the data effectively but also real-time by a visual-based application.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Smart Controlling System for Green Centralized Air Conditioner based on System Engineering Approach"
        ],
        "penulis":"Saputra, Muhardi;Sutoyo, Edi;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "System monitoring and remote control is a necessity in order to achieve maximum service for service users. Because of shortcomings in the movement and control of Air Conditioner (AC), which still relies on manual systems, resulting in waste for AC energy released, in addition, there is no system that can monitor and control air conditioners remotely or centrally. Author tries to make the process of monitoring and controlling being centralized through the control room that can be used more easily for officers, specifically related to the AC control unit. In the other hand, energy from the AC can be more monitored. The temperature of the room will be monitored and controlled through a computer in the control room. That will make efficiency of energy used and become Green Air Conditioner, specifically in the use of centralized AC in office buildings. The concept of system that designed based on service-oriented by using the system engineering method as a benchmark in system design. Workflow of the system that created is temperature of the room will be taken by the sensor that installed in each room. Data from the sensor will be processed in the microcontroller and sent to the computer via the internet network, which will be showed in real time by using an internet connection, it will necessary to set the AC temperature from the control room automatically. In addition, web service programs are also used to monitor, control, and schedule centralized AC systems, it will m create more efficiency in the use of AC energy.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "System monitoring and remote control is a necessity in order to achieve maximum service for service users. Because of shortcomings in the movement and control of Air Conditioner (AC), which still relies on manual systems, resulting in waste for AC energy released, in addition, there is no system that can monitor and control air conditioners remotely or centrally. Author tries to make the process of monitoring and controlling being centralized through the control room that can be used more easily for officers, specifically related to the AC control unit. In the other hand, energy from the AC can be more monitored. The temperature of the room will be monitored and controlled through a computer in the control room. That will make efficiency of energy used and become Green Air Conditioner, specifically in the use of centralized AC in office buildings. The concept of system that designed based on service-oriented by using the system engineering method as a benchmark in system design. Workflow of the system that created is temperature of the room will be taken by the sensor that installed in each room. Data from the sensor will be processed in the microcontroller and sent to the computer via the internet network, which will be showed in real time by using an internet connection, it will necessary to set the AC temperature from the control room automatically. In addition, web service programs are also used to monitor, control, and schedule centralized AC systems, it will m create more efficiency in the use of AC energy.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Macroscopic Wood Blurred Image Analysis to Determine the Factors of Causing Blur"
        ],
        "penulis":"Barus, Dandi T.;Gunawan P.H.;Prakasa, Esa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents an analysis of what factors cause blur on an image, especially macroscopic images of wood. The image is divided into 6x6 sub-images (blocks), which will then be determined factors causing blur based on patterns and variations of Laplacian calculated from each block. Validation is conducted using two different datasets. The first dataset is Wood Species Dataset that is given a median blur, and testing is performed to validate the proposed algorithm. The second dataset is a dataset collected directly using a smartphone camera, and testing is carried out to determine what factors influence the occurrence of blur in wood macroscopic images. The test results show the proposed algorithm produces a pattern that can determine the factors causing blur.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents an analysis of what factors cause blur on an image, especially macroscopic images of wood. The image is divided into 6x6 sub-images (blocks), which will then be determined factors causing blur based on patterns and variations of Laplacian calculated from each block. Validation is conducted using two different datasets. The first dataset is Wood Species Dataset that is given a median blur, and testing is performed to validate the proposed algorithm. The second dataset is a dataset collected directly using a smartphone camera, and testing is carried out to determine what factors influence the occurrence of blur in wood macroscopic images. The test results show the proposed algorithm produces a pattern that can determine the factors causing blur.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "PSO-Learned Artificial Neural Networks for Activity Recognition"
        ],
        "penulis":"Ekaniza, Raki Anwar;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of Activity Recognition (AR) is to recognize human activity using a sensor to get the data needed. Then, a machine learning approach is used to determine the type of activity performed. A machine learning technique often used in the classification problem is Artificial Neural Network (ANN), which is trained using a backpropagation algorithm. Although this technique has been significantly developed, it still has a few disadvantages compared to others. One of the disadvantages of the ANN is that the result is not always optimum because of randomized initialization and epoch limit. In this paper, a Particle Swarm Optimization (PSO) is proposed to train the ANN. Some experiments on a dataset of 10 k activities with six imbalanced classes show that the PSO-based ANN produces effectiveness of 100% and an F1 score micro of 0.88, which are much higher than the back propagation-based ANN that gives the effectiveness of 75% and an F1 score micro of 0.87.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of Activity Recognition (AR) is to recognize human activity using a sensor to get the data needed. Then, a machine learning approach is used to determine the type of activity performed. A machine learning technique often used in the classification problem is Artificial Neural Network (ANN), which is trained using a backpropagation algorithm. Although this technique has been significantly developed, it still has a few disadvantages compared to others. One of the disadvantages of the ANN is that the result is not always optimum because of randomized initialization and epoch limit. In this paper, a Particle Swarm Optimization (PSO) is proposed to train the ANN. Some experiments on a dataset of 10 k activities with six imbalanced classes show that the PSO-based ANN produces effectiveness of 100% and an F1 score micro of 0.88, which are much higher than the back propagation-based ANN that gives the effectiveness of 75% and an F1 score micro of 0.87.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Leveraging Textural Features for Mammogram Classification"
        ],
        "penulis":"Akbarisena, Sri Frenzilino Mahayyu;Rachmawati, Ema;Utama, Dody Qori;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Cancer is the body' s tissue cells that continue to grow beyond normal and out of control so that cancer cells push normal cells and cause death in normal cells. One type of cancer is cancer that attacks breast tissue or is called breast cancer. The sooner breast cancer is detected, it will increase the chance the patient will survive. One of the techniques in the early detection of breast cancer is mammography screening. To minimize human error in checking the results of mammography, a CAD system is needed in checking the results of mammography. Therefore, in this research, a system that can classify breast tissue from mammogram into three classes, namely normal, benign, and malignant has been built. The performance of the system reaches F1-Score 74.02%, Recall 76.15% and Precision 74.02%. The system achieves this performance by combining the Uniform Local Binary Pattern and GLCM features and the Random Forest classification method.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is the body' s tissue cells that continue to grow beyond normal and out of control so that cancer cells push normal cells and cause death in normal cells. One type of cancer is cancer that attacks breast tissue or is called breast cancer. The sooner breast cancer is detected, it will increase the chance the patient will survive. One of the techniques in the early detection of breast cancer is mammography screening. To minimize human error in checking the results of mammography, a CAD system is needed in checking the results of mammography. Therefore, in this research, a system that can classify breast tissue from mammogram into three classes, namely normal, benign, and malignant has been built. The performance of the system reaches F1-Score 74.02%, Recall 76.15% and Precision 74.02%. The system achieves this performance by combining the Uniform Local Binary Pattern and GLCM features and the Random Forest classification method.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation and Analysis of USB based Password Stealer using PowerShell in Google Chrome and Mozilla Firefox"
        ],
        "penulis":"Muslim, Abdul Azies;Budiono, Avon;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Along with the development of the Windows operating system, browser applications to surf the internet are also growing rapidly. The most widely used browsers today are Google Chrome and Mozilla Firefox. Both browsers have a username and password management feature that makes users login to a website easily, but saving usernames and passwords in the browser is quite dangerous because the stored data can be hacked using brute force attacks or read through a program. One way to get a username and password in the browser is to use a program that can read Google Chrome and Mozilla Firefox login data from the computer's internal storage and then show those data. In this study, an attack will be carried out by implementing Rubber Ducky using BadUSB to run the ChromePass and PasswordFox program and the PowerShell script using the Arduino Pro Micro Leonardo device as a USB Password Stealer. The results obtained from this study are the username and password on Google Chrome and Mozilla Firefox successfully obtained when the USB is connected to the target device, the average time of the attack is 14 seconds then sending it to the author's email.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Along with the development of the Windows operating system, browser applications to surf the internet are also growing rapidly. The most widely used browsers today are Google Chrome and Mozilla Firefox. Both browsers have a username and password management feature that makes users login to a website easily, but saving usernames and passwords in the browser is quite dangerous because the stored data can be hacked using brute force attacks or read through a program. One way to get a username and password in the browser is to use a program that can read Google Chrome and Mozilla Firefox login data from the computer's internal storage and then show those data. In this study, an attack will be carried out by implementing Rubber Ducky using BadUSB to run the ChromePass and PasswordFox program and the PowerShell script using the Arduino Pro Micro Leonardo device as a USB Password Stealer. The results obtained from this study are the username and password on Google Chrome and Mozilla Firefox successfully obtained when the USB is connected to the target device, the average time of the attack is 14 seconds then sending it to the author's email.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Characterization of Electromagnetics Wave Absorber Composed of Ring Resonator Structure"
        ],
        "penulis":"Nusobri, Ichsan;Nur, Levy Olivia;Munir, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In absorbent applications, the technology of surface textured is often used to reduce the material thickness thus allowing the realization of thinner materials. In order to obtain high absorption rate of electromagnetics (EM) wave absorber at the desired frequency, a metal patch upon the wave absorber can be made in a specific shape. In this paper, a characterization of EM wave absorber composed of ring resonator structure is carried out by incorporating resistors between the ring resonator structures on two types of boundary condition, namely perfect electric conductor (PEC) and perfect magnetic conductor (PMC) to represent an infinite double periodic arrangement, and the radiation boundary to analyze the performance of proposed EM wave absorber in an actual condition. By using an FR4 epoxy dielectric substrate with the thickness of 1.6 mm, the proposed EM wave absorber is constructed by two-dimensional array of unit cells. Meanwhile, each unit cell has the dimension of 22 mm \u00d7 22 mm and is composed of a couple of ring resonator structures in a symmetrical configuration. Based on parametric studies, the resistor value required to be incorporated into the structure is in the range of 1 k to 6 k. The characterization result shows that the absorption rate of proposed EM wave absorber is-23.41 dB on the PEC and PMC boundaries with the resistor value of 6 k, and-18.3 dB on the radiation boundary with the resistor value of 5.6 k at the frequency of 2.45 GHz. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In absorbent applications, the technology of surface textured is often used to reduce the material thickness thus allowing the realization of thinner materials. In order to obtain high absorption rate of electromagnetics (EM) wave absorber at the desired frequency, a metal patch upon the wave absorber can be made in a specific shape. In this paper, a characterization of EM wave absorber composed of ring resonator structure is carried out by incorporating resistors between the ring resonator structures on two types of boundary condition, namely perfect electric conductor (PEC) and perfect magnetic conductor (PMC) to represent an infinite double periodic arrangement, and the radiation boundary to analyze the performance of proposed EM wave absorber in an actual condition. By using an FR4 epoxy dielectric substrate with the thickness of 1.6 mm, the proposed EM wave absorber is constructed by two-dimensional array of unit cells. Meanwhile, each unit cell has the dimension of 22 mm \u00d7 22 mm and is composed of a couple of ring resonator structures in a symmetrical configuration. Based on parametric studies, the resistor value required to be incorporated into the structure is in the range of 1 k to 6 k. The characterization result shows that the absorption rate of proposed EM wave absorber is-23.41 dB on the PEC and PMC boundaries with the resistor value of 6 k, and-18.3 dB on the radiation boundary with the resistor value of 5.6 k at the frequency of 2.45 GHz. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Stress and Deformation of Optimally Shaped Silicon Microneedles for Transdermal Drug Delivery"
        ],
        "penulis":"Zainal Abidin, Hafzaliza Erny;Ooi, Poh Choon;Tiong, Teck Yaw;Marsi, Noraini;Ismardi, Abrar;Mohd Noor, Mimiwaty;Nik Zaini Fathi, Nik Amni Fathi;Abd Aziz, Norazreen;Sahari, Siti Kudnie;Sugandi, Gandi;Yunas, Jumril;Dee, Chang Fu;Yeop Majlis, Burhanuddin;Hamzah, Azrul Azlan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this study, we demonstrated the fabrication of the concave conic shape microneedle with the aid of COMSOL Multiphysics simulation. The stress and buckling of the microneedle structure were simulated by applying various loads ranging from 50 to 800 g perpendiculars to the tip in order to predict the occurrence of microneedles structure deformation. The simulation study indicated that the surface buckling deformation does not occur to the microneedle structure with the increment of the load. The microneedles with dimensions of height and diameter tip ranging from 60 to 100 \u03bcm and 1 to 4 \u03bcm, respectively had been fabricated via an etching process in a mixture of hydrofluoric acid, nitric acid, and acetic acid. Three optimized microneedles but different in the structures were fabricated via the acidic etching process. The reproducibility of 3 different microneedle structures was 15, 20, and 60%, respectively. Stress and buckling analyses of the fabricated microneedles were further carried out on the rat skin. The obtained experimental results show promising applications for the deep dermis, stratum corneum to epidermis layer penetration. \u00a9 2020 American Pharmacists Association\u00ae",
            "SiNView detailsExpand Substance silicon nitride",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this study, we demonstrated the fabrication of the concave conic shape microneedle with the aid of COMSOL Multiphysics simulation. The stress and buckling of the microneedle structure were simulated by applying various loads ranging from 50 to 800 g perpendiculars to the tip in order to predict the occurrence of microneedles structure deformation. The simulation study indicated that the surface buckling deformation does not occur to the microneedle structure with the increment of the load. The microneedles with dimensions of height and diameter tip ranging from 60 to 100 \u03bcm and 1 to 4 \u03bcm, respectively had been fabricated via an etching process in a mixture of hydrofluoric acid, nitric acid, and acetic acid. Three optimized microneedles but different in the structures were fabricated via the acidic etching process. The reproducibility of 3 different microneedle structures was 15, 20, and 60%, respectively. Stress and buckling analyses of the fabricated microneedles were further carried out on the rat skin. The obtained experimental results show promising applications for the deep dermis, stratum corneum to epidermis layer penetration. \u00a9 2020 American Pharmacists Association\u00ae"
        ]
    },
    {
        "judul":[
            "Using long-range wireless sensor network to track the illegal cutting log"
        ],
        "penulis":"Mutiara, Giva Andriana;Herman, Nanna Suryana;Mohd, Othman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, the need for wireless sensing applications is increasing. Along with the increased illegal cutting of logs in the forest, however, it requires the integration application to tackle the illegal logging and forest preservation. The wireless sensor network is a suitable network architecture for remotely monitoring or tracking applications in the environment. This paper proposed an integrated system that can identify and track the position of a moving cutting log. An Arduino Uno, Raspberry Pi 3 B+, sound sensor, accelerometer sensor, LoRa GPS HAT Shield, and Outdoor LoRa Gateway OLG01 performed the hardware monitoring and tracking of the proposed system. The network of STAR topology configuration between master and slaves is represented by the LoRa Network embedded with the sensors, as an architecture of the wireless sensor network. The system was examined the performance of the network and the tracking process. The result determined that the LoRa can detect and identify the occurrence of the illegal cutting of logs in real-time. Meanwhile, in terms of the tracking performance, a duration of 5\u201346 s was required to track the new position of the moving cutting log. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "Sustainable Development Goals mapped to this documentLife on landGoal 15",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, the need for wireless sensing applications is increasing. Along with the increased illegal cutting of logs in the forest, however, it requires the integration application to tackle the illegal logging and forest preservation. The wireless sensor network is a suitable network architecture for remotely monitoring or tracking applications in the environment. This paper proposed an integrated system that can identify and track the position of a moving cutting log. An Arduino Uno, Raspberry Pi 3 B+, sound sensor, accelerometer sensor, LoRa GPS HAT Shield, and Outdoor LoRa Gateway OLG01 performed the hardware monitoring and tracking of the proposed system. The network of STAR topology configuration between master and slaves is represented by the LoRa Network embedded with the sensors, as an architecture of the wireless sensor network. The system was examined the performance of the network and the tracking process. The result determined that the LoRa can detect and identify the occurrence of the illegal cutting of logs in real-time. Meanwhile, in terms of the tracking performance, a duration of 5\u201346 s was required to track the new position of the moving cutting log. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Prosthetic finger movement controller based on emg signals using statistical feature and K-nearest neighbors"
        ],
        "penulis":"Puspitasari, Attika;Rizal, Achmad;Mukhtar, Husneni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Electromyography (EMG) is a technique used to acquire electrical activity from muscles called electromyogram (EMG). EMG signals can be used to detect either abnormalities or movements in muscles. This muscle movement can be used to control a prosthetic finger. Previous research focused on how to develop a high-functional prosthetic fingers system. This initial system due to many actuators needed a high-performance processor. The main problem was on the complicated mechanism, leading to the price of prosthetic fingers system became expensive, heavy, and difficult to maintain. In this research, we developed a low-cost prototype of a prosthetic finger that works based on EMG signals produced by human arm muscles. The EMG signal obtained was processed by the signal processing to move the servo motor. An appropriate response was received between the movement of the hand and the prosthetic finger. The proposed prosthetic finger system was managed to recognize the type of motion by 100%. The result showed that the prosthetic finger could follow the movements of the hand precisely. \u00a9 2020 IJSTR.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electromyography (EMG) is a technique used to acquire electrical activity from muscles called electromyogram (EMG). EMG signals can be used to detect either abnormalities or movements in muscles. This muscle movement can be used to control a prosthetic finger. Previous research focused on how to develop a high-functional prosthetic fingers system. This initial system due to many actuators needed a high-performance processor. The main problem was on the complicated mechanism, leading to the price of prosthetic fingers system became expensive, heavy, and difficult to maintain. In this research, we developed a low-cost prototype of a prosthetic finger that works based on EMG signals produced by human arm muscles. The EMG signal obtained was processed by the signal processing to move the servo motor. An appropriate response was received between the movement of the hand and the prosthetic finger. The proposed prosthetic finger system was managed to recognize the type of motion by 100%. The result showed that the prosthetic finger could follow the movements of the hand precisely. \u00a9 2020 IJSTR."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Foot Plantar Pressure to Detect Obesity"
        ],
        "penulis":"Nursida, Yulistia Elsa;Erfianto, Bayu;Rakhmatsyah, Andrian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Physically we can see that there is a difference between obese and non-obese people, it's seen from a fatter body posture. Then we can categorize the person into obese or not by calculating the Body Mass Index (BMI). But this still must be done manually because we have to check weight and height first, then calculated BMI according to the BMI formula. Therefore we need a system that can be used to detect obesity automatically. In this study, we created a system that can detect obesity automatically based on foot plantar pressure. On foot plantar pressure there is a significant change between foot pressure in obese and non-obese people. In obese people the pressure will be further increased in the metatarsal foot, heel, and midfoot. This is because the heel is part of the foot which is the main support of the body and in the midfoot there are different levels of leg curvature between obese and non-obese people. The system is built using Fuzzy Inference System based on Fuzzy Logic Concept. So, the system can provide an automatic output whether the person is categorized as thin, normal, or obese.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Physically we can see that there is a difference between obese and non-obese people, it's seen from a fatter body posture. Then we can categorize the person into obese or not by calculating the Body Mass Index (BMI). But this still must be done manually because we have to check weight and height first, then calculated BMI according to the BMI formula. Therefore we need a system that can be used to detect obesity automatically. In this study, we created a system that can detect obesity automatically based on foot plantar pressure. On foot plantar pressure there is a significant change between foot pressure in obese and non-obese people. In obese people the pressure will be further increased in the metatarsal foot, heel, and midfoot. This is because the heel is part of the foot which is the main support of the body and in the midfoot there are different levels of leg curvature between obese and non-obese people. The system is built using Fuzzy Inference System based on Fuzzy Logic Concept. So, the system can provide an automatic output whether the person is categorized as thin, normal, or obese.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Innovation as the key to gain performance from absorptive capacity and human capital"
        ],
        "penulis":"Pradana, Mahir;P\u00e9rez-Lu\u00f1o, Ana;Fuentes-Blasco, Maria;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study aims to investigate how firms can achieve high levels of organisational performance through innovation, absorptive capacity (ACAP) and human capital (HC). Using a sample of 138 Spanish companies from the wine industry, our findings show that ACAP and HC allow businesses to fully capture the benefits of innovation. These results contribute to the literature of ACAP, human resources management (HRM) innovation and resource-based view (RBV) of the firm by showing that a number of resources and capabilities (ACAP, HC, and innovation) can be seen as good drivers of performance and, by extension, of competitive advantage. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to investigate how firms can achieve high levels of organisational performance through innovation, absorptive capacity (ACAP) and human capital (HC). Using a sample of 138 Spanish companies from the wine industry, our findings show that ACAP and HC allow businesses to fully capture the benefits of innovation. These results contribute to the literature of ACAP, human resources management (HRM) innovation and resource-based view (RBV) of the firm by showing that a number of resources and capabilities (ACAP, HC, and innovation) can be seen as good drivers of performance and, by extension, of competitive advantage. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group."
        ]
    },
    {
        "judul":[
            "Data of innovation ambidexterity as a mediator in the absorptive capacity effect on sustainable competitive advantage"
        ],
        "penulis":"Pangarso, Astadi;Astuti, Endang Siti;Raharjo, Kusdi;Afrianty, Tri Wulida;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This data article shows the nexus between absorptive capacity (X), innovation ambidexterity (Y1) and sustainable competitive advantage (Y2). There are three nexus points between the constructs, namely the direct nexuses of X to Y1, X to Y2 and the indirect nexus from X to Y2 through Y1. The raw data of 530 self-administrated questionnaires were obtained from 64 non-vocational private higher education institutions in the Bandung area of West Java, Indonesia. Data analyzing were conducted using SPPS and Smart PLS. The data are useful as the data can be reproduced, reused and reanalysed. This data article also opens up better research opportunities going forward through collaboration with other researchers. \u00a9 2020 The Author(s)",
            "HNNH3CView detailsExpand Substance harmane",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This data article shows the nexus between absorptive capacity (X), innovation ambidexterity (Y1) and sustainable competitive advantage (Y2). There are three nexus points between the constructs, namely the direct nexuses of X to Y1, X to Y2 and the indirect nexus from X to Y2 through Y1. The raw data of 530 self-administrated questionnaires were obtained from 64 non-vocational private higher education institutions in the Bandung area of West Java, Indonesia. Data analyzing were conducted using SPPS and Smart PLS. The data are useful as the data can be reproduced, reused and reanalysed. This data article also opens up better research opportunities going forward through collaboration with other researchers. \u00a9 2020 The Author(s)"
        ]
    },
    {
        "judul":[
            "A PROPOSED MODIFIED TEXT STEGANOGRAPHY TECHNIQUE USING UNISPACH WITH XOR ENCRYPTION AND SHIFT CIPHER"
        ],
        "penulis":"Adinugraha, Raka;Purboyo, Tito Waluyo;Saputra, Randy Erfa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, security on communication was a necessity. However, sending an encrypted message can draw a suspicion from unintended parties. So, sometimes cryptography doesn\u2019t guarantee a full security because it could attract attempts to break and reveal the encrypted message. Steganography was introduced as a method to secure a secret message by hiding it inside an unsuspicious message. The message can be plain text or other data that can be represented as streams of bits. Many of steganography techniques are being proposed from time to time, means steganography is a promising method to secure a communication line beside cryptography. In this paper, an experiment is conducted by comparing two text steganography techniques, which is UniSpaCh and a steganography technique by altering the foreground color of an invisible character. \u00a9 2006\u20132020. Asian Research Publishing Network (ARPN). All rights reserved.",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, security on communication was a necessity. However, sending an encrypted message can draw a suspicion from unintended parties. So, sometimes cryptography doesn\u2019t guarantee a full security because it could attract attempts to break and reveal the encrypted message. Steganography was introduced as a method to secure a secret message by hiding it inside an unsuspicious message. The message can be plain text or other data that can be represented as streams of bits. Many of steganography techniques are being proposed from time to time, means steganography is a promising method to secure a communication line beside cryptography. In this paper, an experiment is conducted by comparing two text steganography techniques, which is UniSpaCh and a steganography technique by altering the foreground color of an invisible character. \u00a9 2006\u20132020. Asian Research Publishing Network (ARPN). All rights reserved."
        ]
    },
    {
        "judul":[
            "Time and frequency domain feature extraction method of doppler radar for hand gesture based human to machine interface"
        ],
        "penulis":"Pramudita, Aloysius Adya;Lukas;Edwar;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the development of hand gesture based Human to Machine Interface, Doppler response feature extraction method plays an important role in translating hand gesture of certain information. The Doppler response feature extraction method from hand gesture sign was proposed and designed by combining time and frequency domain analysis. The extraction of the Doppler response features at time domain is developed by using cross correlation, and the time domain feature is represented by using peak value of cross correlation result and its time shift. The Doppler response feature of frequency domain is extracted by employing a discriminator filter determined by the frequency spectrum observation of Doppler response. The proposed method was employed as a preprocessing for Continuous Wave (CW) radar output signals, which is able to relieve the pattern classification of Doppler response associated with each hand gesture. The simulation and laboratory experiment using HB 100 Doppler radar were performed to investigate the proposed method. The results show that the combination of all three features was capable of differentiating every type of hand gestures movement. \u00a9 2020, Electromagnetics Academy. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the development of hand gesture based Human to Machine Interface, Doppler response feature extraction method plays an important role in translating hand gesture of certain information. The Doppler response feature extraction method from hand gesture sign was proposed and designed by combining time and frequency domain analysis. The extraction of the Doppler response features at time domain is developed by using cross correlation, and the time domain feature is represented by using peak value of cross correlation result and its time shift. The Doppler response feature of frequency domain is extracted by employing a discriminator filter determined by the frequency spectrum observation of Doppler response. The proposed method was employed as a preprocessing for Continuous Wave (CW) radar output signals, which is able to relieve the pattern classification of Doppler response associated with each hand gesture. The simulation and laboratory experiment using HB 100 Doppler radar were performed to investigate the proposed method. The results show that the combination of all three features was capable of differentiating every type of hand gestures movement. \u00a9 2020, Electromagnetics Academy. All rights reserved."
        ]
    },
    {
        "judul":[
            "Extraction Dependency Based on Evolutionary Requirement Using Natural Language Processing"
        ],
        "penulis":"Asyrofi, Rakha;Siahaan, Daniel Oranova;Priyadi, Yudi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Changes in requirements are one of the critical problems that occur during requirement specification. A change in a requirement could trigger changes in other requirements. Thus the identification process requirement to respond and correct the truth, realistic, require, specific, measurable aspects. Previous work has focused on building a model of interdependency between the requirements. This study proposes a method to identify dependencies among requirements. The dependency relations refer to evolutionary requirements. The technique uses natural language processing to extract dependency relations. This research analyzes how to obtain feature extractions by including the following: 1) Gathering requirements statement from the SRS document, 2) Identifying dependencies between requirements, 3) Developing interdependency extraction methods and, 4) Modeling of the interdependency requirement. The expectation of this experiment indicates the interdependency graph model. This graph defines the interdependency in the (Software Requirement Specification) SRS document. This method gathers interdependency between SRS document requirements such as PART OF, AND, OR, XOR. Therefore, getting the feature extraction to identify the interdependency requirement will be useful for solving specified requirements changing.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Changes in requirements are one of the critical problems that occur during requirement specification. A change in a requirement could trigger changes in other requirements. Thus the identification process requirement to respond and correct the truth, realistic, require, specific, measurable aspects. Previous work has focused on building a model of interdependency between the requirements. This study proposes a method to identify dependencies among requirements. The dependency relations refer to evolutionary requirements. The technique uses natural language processing to extract dependency relations. This research analyzes how to obtain feature extractions by including the following: 1) Gathering requirements statement from the SRS document, 2) Identifying dependencies between requirements, 3) Developing interdependency extraction methods and, 4) Modeling of the interdependency requirement. The expectation of this experiment indicates the interdependency graph model. This graph defines the interdependency in the (Software Requirement Specification) SRS document. This method gathers interdependency between SRS document requirements such as PART OF, AND, OR, XOR. Therefore, getting the feature extraction to identify the interdependency requirement will be useful for solving specified requirements changing.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Open innovation practices and sustainability performance in small and medium industries"
        ],
        "penulis":"Kurniawati, Amelia;Ajidarma, Praditya;Wiratmadja, Iwan Inrawan;Sunaryo, Indryati;Ari Samadhi T.M.A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Sustainability performance is the achievement of an organization in economic, environmental, and social dimensions by considering the interests of stakeholders. Achieving a high sustainability performance is a challenge for not only large industries but also Small and Medium Industries (SMIs). In order to achieve high sustainability performance, an organization needs to innovate in its operations, especially in activities related to the environment, employees, society, and ethics. Conducting innovation needs resources, both financial and nonfinancial, which are very limited in the SMIs. To overcome the problem of limited resources, SMIs can implement open innovation that utilizes both internal and external resources. Open innovation has three types of practices which are inbound, outbound, and coupled. This study aims to identify the relationship between the three open innovation practices and sustainability performance in the SMIs. The respondents of this study are 125 SMIs which produce batik in Indonesia. The model is tested using the partial least square. The result shows a significant relationship between inbound open innovation and economic and environmental performance; outbound open innovation and environmental and social performance; and coupled open innovation and social performance. \u00a9 Springer Nature Singapore Pte Ltd. 2020.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sustainability performance is the achievement of an organization in economic, environmental, and social dimensions by considering the interests of stakeholders. Achieving a high sustainability performance is a challenge for not only large industries but also Small and Medium Industries (SMIs). In order to achieve high sustainability performance, an organization needs to innovate in its operations, especially in activities related to the environment, employees, society, and ethics. Conducting innovation needs resources, both financial and nonfinancial, which are very limited in the SMIs. To overcome the problem of limited resources, SMIs can implement open innovation that utilizes both internal and external resources. Open innovation has three types of practices which are inbound, outbound, and coupled. This study aims to identify the relationship between the three open innovation practices and sustainability performance in the SMIs. The respondents of this study are 125 SMIs which produce batik in Indonesia. The model is tested using the partial least square. The result shows a significant relationship between inbound open innovation and economic and environmental performance; outbound open innovation and environmental and social performance; and coupled open innovation and social performance. \u00a9 Springer Nature Singapore Pte Ltd. 2020."
        ]
    },
    {
        "judul":[
            "Determination of minimum trucks and routes used in the case of municipal solid waste transportation in Bandung City with greedy algoritm"
        ],
        "penulis":"Habibi, Nur Alim;Ridwan, Ari Yanuar;Setyawan, Erlangga Bayu;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study discusses the determination of the minimum number of trucks and the route of transporting the municipal solid waste, where the trucks provided have the heterogeneous capacity, namely 2 trucks with a capacity of 6 m3, and 2 trucks with a capacity of 10 m3. In this study, the heuristic method uses the greedy algorithm because it is expected that the optimal local will produce a global solution so that the expected total cost can be optimal. Based on trials conducted, obtained 3 solutions that might be used, the solution chosen using 2 trucks with a capacity of 10 m3\u00a9 2020 IOP Conference Series: Materials Science and Engineering.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study discusses the determination of the minimum number of trucks and the route of transporting the municipal solid waste, where the trucks provided have the heterogeneous capacity, namely 2 trucks with a capacity of 6 m3, and 2 trucks with a capacity of 10 m3. In this study, the heuristic method uses the greedy algorithm because it is expected that the optimal local will produce a global solution so that the expected total cost can be optimal. Based on trials conducted, obtained 3 solutions that might be used, the solution chosen using 2 trucks with a capacity of 10 m3\u00a9 2020 IOP Conference Series: Materials Science and Engineering."
        ]
    },
    {
        "judul":[
            "Speech Age-Gender Classification Using Long Short-Term Memory"
        ],
        "penulis":"Nitisara, Galih Rahagi;Suyanto, Suyanto;Ramadhani, Kurniawan Nur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Recognizing the age and gender of a person with certainty from a media has a significant advantage. For example, the perpetrators recorded on a CCTV camera can be easily recognized, or someone used to lie about age on social media or job application applications can be easily detected. However, detecting the exact age of a person is still a tricky thing because of the quality media and the characteristics of the person who seems deceptive. In machine learning, the neural-based methods are commonly used for classification and recognition. However, age and gender classifications stillproduce unsatisfactory results, even age and gender classifications by speech are rarely discussed.Hence, the right approach is needed to create a good age and gender classification model. One of the solutions is using Recurrent Neural Network (RNN), which is made for sequential data like speech.In this paper, a speech age-gender classification model is developed using one of the popular RNN models called Long Short-Term Memory (LSTM). The experimental results show that the proposed model is trapped on the overfitting problem so that the accuracy of the testing set is lower than the training set. Regularization can reduce the difference between the accuracies of both training and testing sets but it cannot increase them. The data augmentation is able to slightly solve the overfitting problem. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recognizing the age and gender of a person with certainty from a media has a significant advantage. For example, the perpetrators recorded on a CCTV camera can be easily recognized, or someone used to lie about age on social media or job application applications can be easily detected. However, detecting the exact age of a person is still a tricky thing because of the quality media and the characteristics of the person who seems deceptive. In machine learning, the neural-based methods are commonly used for classification and recognition. However, age and gender classifications stillproduce unsatisfactory results, even age and gender classifications by speech are rarely discussed.Hence, the right approach is needed to create a good age and gender classification model. One of the solutions is using Recurrent Neural Network (RNN), which is made for sequential data like speech.In this paper, a speech age-gender classification model is developed using one of the popular RNN models called Long Short-Term Memory (LSTM). The experimental results show that the proposed model is trapped on the overfitting problem so that the accuracy of the testing set is lower than the training set. Regularization can reduce the difference between the accuracies of both training and testing sets but it cannot increase them. The data augmentation is able to slightly solve the overfitting problem. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design of intelligent algorithm based air volume control system for central air conditioning"
        ],
        "penulis":"Niu, Min;Le, Quoc Tien;Saedudin, Rd Rohmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research aims to analyze the optimization value of intelligent control algorithm in the design of automatic variable air volume control system of central air conditioning, to improve the technology of central air conditioning and reduce the energy consumption of air conditioning. In this research, starting from analyzing the operation characteristics of variable air volume system of central air conditioning, a controller based on fuzzy intelligent control algorithm is proposed, and a terminal controller model based on intelligent control algorithm is established to design a new variable air volume automatic control system for central air conditioning. Besides, its performance is compared with that of central air conditioning system based on traditional proportion integration differentiation (PID) control algorithm. The results show that the automatic variable air volume control system of central air conditioning designed in this research based on the intelligent control algorithm has better energy saving effect. The application of fuzzy intelligent control algorithm improves the performance of the control system, reduces the power consumption of the central air-conditioning system, and optimizes the energy utilization efficiency. In this study, the intelligent control technology has been expanded to the national call for energy conservation and emission reduction, and the application of intelligent control algorithm to the variable air volume control system of central air conditioning has important practical significance, laying a foundation for the development of follow-up high-performance air conditioning system. \u00a9 2020, Cefin Publishing House. All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document"
        ],
        "abstrak":[
            "This research aims to analyze the optimization value of intelligent control algorithm in the design of automatic variable air volume control system of central air conditioning, to improve the technology of central air conditioning and reduce the energy consumption of air conditioning. In this research, starting from analyzing the operation characteristics of variable air volume system of central air conditioning, a controller based on fuzzy intelligent control algorithm is proposed, and a terminal controller model based on intelligent control algorithm is established to design a new variable air volume automatic control system for central air conditioning. Besides, its performance is compared with that of central air conditioning system based on traditional proportion integration differentiation (PID) control algorithm. The results show that the automatic variable air volume control system of central air conditioning designed in this research based on the intelligent control algorithm has better energy saving effect. The application of fuzzy intelligent control algorithm improves the performance of the control system, reduces the power consumption of the central air-conditioning system, and optimizes the energy utilization efficiency. In this study, the intelligent control technology has been expanded to the national call for energy conservation and emission reduction, and the application of intelligent control algorithm to the variable air volume control system of central air conditioning has important practical significance, laying a foundation for the development of follow-up high-performance air conditioning system. \u00a9 2020, Cefin Publishing House. All rights reserved."
        ]
    },
    {
        "judul":[
            "A Study of Text Steganography Methods"
        ],
        "penulis":"Akbar, Fitra Chairil;Purboyo, Tito Waluyo;Latuconsina, Roswan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Based on the development of information and communication technology, then the security improvement will be more important. One of them is the level of security in inserting data or information. Increased security to insert data and information can be resolved using steganography technique. Steganography itself is a technique to hide messages into a digital medium. The digital media used in this steganography is text, picture, sound and video. In the text media, the methods and techniques used there are various. In this study, we will discuss the methods and techniques as well as comparing of each methods. \u00a9 Medwell Journals, 2020",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Based on the development of information and communication technology, then the security improvement will be more important. One of them is the level of security in inserting data or information. Increased security to insert data and information can be resolved using steganography technique. Steganography itself is a technique to hide messages into a digital medium. The digital media used in this steganography is text, picture, sound and video. In the text media, the methods and techniques used there are various. In this study, we will discuss the methods and techniques as well as comparing of each methods. \u00a9 Medwell Journals, 2020"
        ]
    },
    {
        "judul":[
            "Wave Height Prediction based on Wind Information by using General Regression Neural Network, study case in Jakarta Bay"
        ],
        "penulis":"Juliani, Vita;Adytia, Didit;Adiwijaya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information about ocean wave is very important for naval navigation, port operations, offshore or nearshore activities around the sea waters. Moreover prediction of wave condition is necessary for design of harbour, coastal and offshore structures. Variations in wave heights are caused by wind pressure on free waves which make it random and uncertain, so that become difficult to predict. In previous studies, wave prediction have been carried out by using semi-empirical methods and conventional methods that require high resolution simulations and high computation. In this paper, we propose a method for prediction wave height from wind data by using a variant of Artificial Neural Network (ANN) with single pass associative memory-forward, so called General Regression Neural Network (GRNN). To obtain a set of training data, we perform numerical wave simulation by using SWAN (Simulating Wave Nearshore) model by using wind data obtained from ECMWF ERA-5. As a study area, we choose a rather shallow bathymetry and complex geometry, in Jakarta Bay, Indonesia. Results of prediction by using GRNN show a good agreement with wave data.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information about ocean wave is very important for naval navigation, port operations, offshore or nearshore activities around the sea waters. Moreover prediction of wave condition is necessary for design of harbour, coastal and offshore structures. Variations in wave heights are caused by wind pressure on free waves which make it random and uncertain, so that become difficult to predict. In previous studies, wave prediction have been carried out by using semi-empirical methods and conventional methods that require high resolution simulations and high computation. In this paper, we propose a method for prediction wave height from wind data by using a variant of Artificial Neural Network (ANN) with single pass associative memory-forward, so called General Regression Neural Network (GRNN). To obtain a set of training data, we perform numerical wave simulation by using SWAN (Simulating Wave Nearshore) model by using wind data obtained from ECMWF ERA-5. As a study area, we choose a rather shallow bathymetry and complex geometry, in Jakarta Bay, Indonesia. Results of prediction by using GRNN show a good agreement with wave data.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "NB-IoT Network Planning for Advanced Metering Infrastructure in Surabaya, Sidoarjo, and Gresik"
        ],
        "penulis":"Nashiruddin, Muhammad Imam;Purnama, Arrizky Ayu Faradila;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Narrow Band Internet of Things (NB-IoT) technology is one of the Low Power Wide Area (LPWA) technologies with low cost, low power consumption, and wide range connectivity. NB-IoT is supported by cellular networks or Long-Term Evolution (LTE) with 3GPP Release 13 standard, making NB-IoT becomes an appropriate technology for the development and needs of the Internet of Things (IoT). Connectivity is needed to guarantee the service connection, in which one of the technologies is Narrow Band Internet of Things (NB-IoT). As an example of the NB-IoT rollout in urban areas, the study conducted the network design and analysis for AMI (Advanced Metering Infrastructure) in cities of Surabaya, Sidoarjo, and Gresik. The study result indicates that both coverage and capacity of the gateway requirements for Internet of Things (IoT) network planning using NB-IoT are 20 sites for the Surabaya area, 7 sites for the Sidoarjo area, and 5 sites for the Gresik area. Based on the simulations undertaken, the average acceptable signal levels are -57.9dBm for Surabaya, 59.62 dBm for Sidoarjo, and -58.71dBm for Gresik. And for Received Signal Strength Indicator (RSSI) value or sensitivity at the receiver for the three regions, the above standard sensitivity value for NB-IoT is -141dBm, while the minimum sensitivity value for the Surabaya, Sidoarjo and Gresik areas are -100dBm, -104dBm, and -105dBm. The study results also show different network planning parameters although it was planned in the same urban area and using the same capacity per cell approach model. It is possible to happen because of different environmental conditions, different number of users and different coverage areas in each urban city.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Narrow Band Internet of Things (NB-IoT) technology is one of the Low Power Wide Area (LPWA) technologies with low cost, low power consumption, and wide range connectivity. NB-IoT is supported by cellular networks or Long-Term Evolution (LTE) with 3GPP Release 13 standard, making NB-IoT becomes an appropriate technology for the development and needs of the Internet of Things (IoT). Connectivity is needed to guarantee the service connection, in which one of the technologies is Narrow Band Internet of Things (NB-IoT). As an example of the NB-IoT rollout in urban areas, the study conducted the network design and analysis for AMI (Advanced Metering Infrastructure) in cities of Surabaya, Sidoarjo, and Gresik. The study result indicates that both coverage and capacity of the gateway requirements for Internet of Things (IoT) network planning using NB-IoT are 20 sites for the Surabaya area, 7 sites for the Sidoarjo area, and 5 sites for the Gresik area. Based on the simulations undertaken, the average acceptable signal levels are -57.9dBm for Surabaya, 59.62 dBm for Sidoarjo, and -58.71dBm for Gresik. And for Received Signal Strength Indicator (RSSI) value or sensitivity at the receiver for the three regions, the above standard sensitivity value for NB-IoT is -141dBm, while the minimum sensitivity value for the Surabaya, Sidoarjo and Gresik areas are -100dBm, -104dBm, and -105dBm. The study results also show different network planning parameters although it was planned in the same urban area and using the same capacity per cell approach model. It is possible to happen because of different environmental conditions, different number of users and different coverage areas in each urban city.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Classification of brainwaves for sleep stages by high-dimensional FFT features from EEG signals"
        ],
        "penulis":"Delimayanti, Mera Kartika;Purnama, Bedy;Nguyen, Ngoc Giang;Faisal, Mohammad Reza;Mahmudah, Kunti Robiatul;Indriani, Fatma;Kubo, Mamoru;Satou, Kenji;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Manual classification of sleep stage is a time-consuming but necessary step in the diagnosis and treatment of sleep disorders, and its automation has been an area of active study. The previous works have shown that low dimensional fast Fourier transform (FFT) features and many machine learning algorithms have been applied. In this paper, we demonstrate utilization of features extracted from EEG signals via FFT to improve the performance of automated sleep stage classification through machine learning methods. Unlike previous works using FFT, we incorporated thousands of FFT features in order to classify the sleep stages into 2-6 classes. Using the expanded version of Sleep-EDF dataset with 61 recordings, our method outperformed other state-of-the art methods. This result indicates that high dimensional FFT features in combination with a simple feature selection is effective for the improvement of automated sleep stage classification. \u00a9 2020 by the authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Manual classification of sleep stage is a time-consuming but necessary step in the diagnosis and treatment of sleep disorders, and its automation has been an area of active study. The previous works have shown that low dimensional fast Fourier transform (FFT) features and many machine learning algorithms have been applied. In this paper, we demonstrate utilization of features extracted from EEG signals via FFT to improve the performance of automated sleep stage classification through machine learning methods. Unlike previous works using FFT, we incorporated thousands of FFT features in order to classify the sleep stages into 2-6 classes. Using the expanded version of Sleep-EDF dataset with 61 recordings, our method outperformed other state-of-the art methods. This result indicates that high dimensional FFT features in combination with a simple feature selection is effective for the improvement of automated sleep stage classification. \u00a9 2020 by the authors."
        ]
    },
    {
        "judul":[
            "How Can Fingerprint Improves the Payment Experience of a Drink Vending Machine?"
        ],
        "penulis":"Hutomo, Satria;Sukarno, Parman;Yasirandi, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Many examples of technology on the payment scheme already help and facilitate transactions in Indonesia such as internet banking, ATM or debit cards, e-money, and also mobile banking. Included on drink vending machine, it is a sale that utilizes machines. Today's commonly, drink vending machines still use coins or smart cards, which based on the Legal and Ethical Experience this factor is still have many weaknesses and threats, that can occur in this payment system. So the payment authentication factor is needed to pay more attention to user experience components, some of which are ownership, privacy, and security.So that in this study, the implementation of the fingerprint authentication scheme was made as an epayment factor based on user experience. This study uses a mixed-method in analyzing every pain problem of the research. Where to conduct exploratory studies through literature review and direct observation in the case of the application of the vending machines, especially in developing countries such as Indonesia. This research shows that the payment authentication system can solve the problem of the risk of system attack, the risk of topping up fails, it can harm the user (R1), if the user loses a smart card, the smart card is at risk of being used by not the owner (R2), if the data on the smart card is cloned, it can poses a risk to the system (R3). The conclusion of the proposed payment system can overcomes the existing problems obtained from the system security testing scenario. In addition, user agreement testing (R4 and R5) are also done by providing a questionnaire comparing the level of satisfaction of the existing and proposed payment systems, the results of this test shows that the user feels comfortable with the proposed payment system.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Many examples of technology on the payment scheme already help and facilitate transactions in Indonesia such as internet banking, ATM or debit cards, e-money, and also mobile banking. Included on drink vending machine, it is a sale that utilizes machines. Today's commonly, drink vending machines still use coins or smart cards, which based on the Legal and Ethical Experience this factor is still have many weaknesses and threats, that can occur in this payment system. So the payment authentication factor is needed to pay more attention to user experience components, some of which are ownership, privacy, and security.So that in this study, the implementation of the fingerprint authentication scheme was made as an epayment factor based on user experience. This study uses a mixed-method in analyzing every pain problem of the research. Where to conduct exploratory studies through literature review and direct observation in the case of the application of the vending machines, especially in developing countries such as Indonesia. This research shows that the payment authentication system can solve the problem of the risk of system attack, the risk of topping up fails, it can harm the user (R1), if the user loses a smart card, the smart card is at risk of being used by not the owner (R2), if the data on the smart card is cloned, it can poses a risk to the system (R3). The conclusion of the proposed payment system can overcomes the existing problems obtained from the system security testing scenario. In addition, user agreement testing (R4 and R5) are also done by providing a questionnaire comparing the level of satisfaction of the existing and proposed payment systems, the results of this test shows that the user feels comfortable with the proposed payment system.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Developing a quality metric in controlling the project task"
        ],
        "penulis":"Novitiara, Indriana;Pratami, Devi;Fuad Bay, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In several telecommunication projects, during the monitoring and controlling phases, the quality control and validate scope processes only rely on the receipt test form and handover minutes. Whereas quality errors, in general, can only be seen in the final project phase. If the project deliverables do not meet the customer requirement, the rework must be done or the worst possibility is that the project must be stopped. A quality metric using the internal control method is a project document that can be used to prevent possible problems. There is a quality metric template from previous research proposed for telecommunication projects, but the factors used as variable critical success criteria have not included other important factors that support project success. Therefore, this study will discuss the development of an existing quality metric template and what processes will be affected by the use of this quality metric in a project. It was found that procedures and human factors are critical success factors that can support project success, and quality metrics have an impact on the quality control process and validate scope. It can be concluded that this study produces a quality metric template that has been developed and this quality metric can be used as a template for other projects such as construction projects or IT projects. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In several telecommunication projects, during the monitoring and controlling phases, the quality control and validate scope processes only rely on the receipt test form and handover minutes. Whereas quality errors, in general, can only be seen in the final project phase. If the project deliverables do not meet the customer requirement, the rework must be done or the worst possibility is that the project must be stopped. A quality metric using the internal control method is a project document that can be used to prevent possible problems. There is a quality metric template from previous research proposed for telecommunication projects, but the factors used as variable critical success criteria have not included other important factors that support project success. Therefore, this study will discuss the development of an existing quality metric template and what processes will be affected by the use of this quality metric in a project. It was found that procedures and human factors are critical success factors that can support project success, and quality metrics have an impact on the quality control process and validate scope. It can be concluded that this study produces a quality metric template that has been developed and this quality metric can be used as a template for other projects such as construction projects or IT projects. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "In vitro shoot multiplication of curcuma xanthorrhiza with coconut water and banana extract nutrient"
        ],
        "penulis":"Andini, Nur;Samanhudi;Yunus, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Abstract-Curcuma xanthorrhiza is a medicinal plant, commonly used for spices, growth by rhizome, which is as its main product. Its rhizome demand both quantity and quality are increasing every year. Tissue culture techniques can achieve the efforts for providing plant materials massively in the short-term time with free from pest. In vitro, multiplication is an alternative production method. However, it is still limited by high chemical cost and plant growth regulators. Moreover, various natural materials can be used as a substitute for plant growth regulators, such as coconut water extract and various organic materials. The purpose of this study is to assess the response of Curcuma xanthorrhiza explants with coconut water, and Cavendish bananas extract by in vitro. The experiments conducted in February until May 2016 in the Laboratory of Plant Physiology and Biotechnology, Faculty of Agriculture, Sebelas Maret University Surakarta. A completely randomized design was applied with two factors: the first factor was the four concentrations Cavendish banana fruit extract: 0 g\/l, 50 g\/l, 100 g\/l and 150 g\/l. The second factor were the 4 concentrations coconut water: 0 ml\/l, 100 ml\/l, 150 ml\/l, and 200 ml\/l. The observed variables were the period of shoots to appear, the period of leaves to appear and the period of roots to appear, the number of shots, the number of leaves, the number of roots, the height of shoots, the length of leaves and the length of roots. Observed data analyzed by descriptive and variance analysis continued with Duncan Multiple Range Test (DMRT). Research results showed that there were some effects on coconut water and Cavendish banana extract treatment toward the average time of shoots appear, number of shoots, number of leaves and length of leaves. The best treatment for this research is a combination of coconut water at 150 ml\/l and 100 g Cavendish banana extract. \u00a9 2020, Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Abstract-Curcuma xanthorrhiza is a medicinal plant, commonly used for spices, growth by rhizome, which is as its main product. Its rhizome demand both quantity and quality are increasing every year. Tissue culture techniques can achieve the efforts for providing plant materials massively in the short-term time with free from pest. In vitro, multiplication is an alternative production method. However, it is still limited by high chemical cost and plant growth regulators. Moreover, various natural materials can be used as a substitute for plant growth regulators, such as coconut water extract and various organic materials. The purpose of this study is to assess the response of Curcuma xanthorrhiza explants with coconut water, and Cavendish bananas extract by in vitro. The experiments conducted in February until May 2016 in the Laboratory of Plant Physiology and Biotechnology, Faculty of Agriculture, Sebelas Maret University Surakarta. A completely randomized design was applied with two factors: the first factor was the four concentrations Cavendish banana fruit extract: 0 g\/l, 50 g\/l, 100 g\/l and 150 g\/l. The second factor were the 4 concentrations coconut water: 0 ml\/l, 100 ml\/l, 150 ml\/l, and 200 ml\/l. The observed variables were the period of shoots to appear, the period of leaves to appear and the period of roots to appear, the number of shots, the number of leaves, the number of roots, the height of shoots, the length of leaves and the length of roots. Observed data analyzed by descriptive and variance analysis continued with Duncan Multiple Range Test (DMRT). Research results showed that there were some effects on coconut water and Cavendish banana extract treatment toward the average time of shoots appear, number of shoots, number of leaves and length of leaves. The best treatment for this research is a combination of coconut water at 150 ml\/l and 100 g Cavendish banana extract. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[
            "An Interpolation Comparative Analysis for Missing Internet Traffic Data"
        ],
        "penulis":"Irawati, Indrarini Dyah;Suksmono, Andriyan Bayu;Edward, Ian Joseph Matheus;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, we compared interpolation techniques for fixing the missing of internet traffic data. These techniques consist of 2-D interpolation, k-nearest neighbors (KNN), and correlation. We test various types of missing data with missing probability of 0.02 and 0.98. The interpolation technique performance is shown using Normalized Mean Square Error (NMSE) parameters. Simulation results show that all interpolation methods have the ability to recover lost information. 2-D interpolation and KNN suitable for small probability of missing while correlation is suitable for large probability of missing. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we compared interpolation techniques for fixing the missing of internet traffic data. These techniques consist of 2-D interpolation, k-nearest neighbors (KNN), and correlation. We test various types of missing data with missing probability of 0.02 and 0.98. The interpolation technique performance is shown using Normalized Mean Square Error (NMSE) parameters. Simulation results show that all interpolation methods have the ability to recover lost information. 2-D interpolation and KNN suitable for small probability of missing while correlation is suitable for large probability of missing. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Asymmetric impact of textile and clothing manufacturing on carbon-dioxide emissions: Evidence from top Asian economies"
        ],
        "penulis":"Haseeb, Muhammad;Haouas, Ilham;Nasih, Mohammad;Mihardjo, Leonardus WW.;Jermsittiparsert, Kittisak;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The aim of the current investigation is to analyze the impact of textile and clothing (T&C) manufacturing on carbon dioxide emission (CO2) in top Asian economies. In doing so, the study has utilized the quarterly data of percentage of manufacturing covered by T&C sector and CO2per capita from the period of 1990\u20132018. The empirical investigation is carried out by applying the innovative Quantile-on-Quantile (QQ) regression and Granger causality in quantile methods. The findings of the study have identified the significant asymmetric behavior in the quantiles of T&C industry on the quantiles of CO2emission in the considered economies. Precisely, the outcomes have documented the significant positive contribution of T&C manufacturing on CO2emission in China, India, Pakistan, and Indonesia. On the other hand, the effect of T&C on CO2emission is negative in the case of Vietnam. As for causal relationships, the study also confirmed the presence of bi-directional causality between T&C and CO2emission in all countries except Indonesia, where the relationship is uni-directional. The study recommended regulators to introduce some incentives and subsidies for the new investors in T&C industry with higher emphasis on green manufacturing. \u00a9 2020 Elsevier Ltd",
            "OOView detailsExpand Substance carbon dioxideNSOH3CView detailsExpand Substance Molinate",
            "Powered by",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aim of the current investigation is to analyze the impact of textile and clothing (T&C) manufacturing on carbon dioxide emission (CO2) in top Asian economies. In doing so, the study has utilized the quarterly data of percentage of manufacturing covered by T&C sector and CO2per capita from the period of 1990\u20132018. The empirical investigation is carried out by applying the innovative Quantile-on-Quantile (QQ) regression and Granger causality in quantile methods. The findings of the study have identified the significant asymmetric behavior in the quantiles of T&C industry on the quantiles of CO2emission in the considered economies. Precisely, the outcomes have documented the significant positive contribution of T&C manufacturing on CO2emission in China, India, Pakistan, and Indonesia. On the other hand, the effect of T&C on CO2emission is negative in the case of Vietnam. As for causal relationships, the study also confirmed the presence of bi-directional causality between T&C and CO2emission in all countries except Indonesia, where the relationship is uni-directional. The study recommended regulators to introduce some incentives and subsidies for the new investors in T&C industry with higher emphasis on green manufacturing. \u00a9 2020 Elsevier Ltd"
        ]
    },
    {
        "judul":[
            "Nonlinear SWE and Experimental Observation for Wave Simulation due to Bottom Motion"
        ],
        "penulis":"Themba, Astrid Velia;Gunawan P.H.;Aditsania, Annisa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Natural disasters can occur everywhere, causing geological and complex problems. One of the devastating natural disasters is the water wave disaster. Several factors can form a water wave disaster, one of them is due to the bottom motion of the water surface. This paper presents the simulation of numerical modeling waves due to the bottom motion using the 1D nonlinear SWE. Here, the staggered grid is used to help to discretize the model. Experiments are carried out eleven times to produce data for making wave simulations. The results of experiments and simulation results are compared and analyzed using the formula Root Mean Square Error (RMSE). This study aims to prove whether the nonlinear SWE model can simulate experimental waves accurately. The results showed that the shallow water equations model could represent the experimental results well with an error value of 0.000058.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Natural disasters can occur everywhere, causing geological and complex problems. One of the devastating natural disasters is the water wave disaster. Several factors can form a water wave disaster, one of them is due to the bottom motion of the water surface. This paper presents the simulation of numerical modeling waves due to the bottom motion using the 1D nonlinear SWE. Here, the staggered grid is used to help to discretize the model. Experiments are carried out eleven times to produce data for making wave simulations. The results of experiments and simulation results are compared and analyzed using the formula Root Mean Square Error (RMSE). This study aims to prove whether the nonlinear SWE model can simulate experimental waves accurately. The results showed that the shallow water equations model could represent the experimental results well with an error value of 0.000058.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Bipolar disorder classification based on electrocardiogram signal using support vector machine"
        ],
        "penulis":"Ainunhusna, Izzatunnisa;Rizal, Achmad;Sumaryo, Sony;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Bipolar Disorder (BD) is one of kinds of mental disease that is quite common found in Indonesia. Those suffering from this disease will drastically experience a shift in mood in a certain period of time. This shift in mood, in turn, can cause many undesired things. The detection of Bipolar Disorder can be done through various diagnosing methods, one of which is by using EEG (Electroencephalogram) signal or ECG (electrocardiogram). One of the methods to detect BD using the ECG signal is by assessing the heart-rate variability (HRV) in which HRV in the patients of Bipolar Disorder tends to be lower than that of normal persons. In this research, an analysis method of HRV was developed to detect Bipolar Disorder using the ECG signal. The method proposed consisted of notch filter, wavelet decomposition, R-R detection, and HRV analysis using Mean Heart Rate (MHR), Standard Deviation of Normal to Normal (SDNN) and Root Mean Square of successive RR interval differences (RMSSD), and SVM for classification. From the experiment, it was found the highest accuracy of 93.8% using three features and quadratic SVM. This showed that the ability of method designed to differentiate HRV with the high accuracy. Here, the verification using the larger dataset was required to test the consistency of the proposed method. \u00a9 2020 IJSTR.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Bipolar Disorder (BD) is one of kinds of mental disease that is quite common found in Indonesia. Those suffering from this disease will drastically experience a shift in mood in a certain period of time. This shift in mood, in turn, can cause many undesired things. The detection of Bipolar Disorder can be done through various diagnosing methods, one of which is by using EEG (Electroencephalogram) signal or ECG (electrocardiogram). One of the methods to detect BD using the ECG signal is by assessing the heart-rate variability (HRV) in which HRV in the patients of Bipolar Disorder tends to be lower than that of normal persons. In this research, an analysis method of HRV was developed to detect Bipolar Disorder using the ECG signal. The method proposed consisted of notch filter, wavelet decomposition, R-R detection, and HRV analysis using Mean Heart Rate (MHR), Standard Deviation of Normal to Normal (SDNN) and Root Mean Square of successive RR interval differences (RMSSD), and SVM for classification. From the experiment, it was found the highest accuracy of 93.8% using three features and quadratic SVM. This showed that the ability of method designed to differentiate HRV with the high accuracy. Here, the verification using the larger dataset was required to test the consistency of the proposed method. \u00a9 2020 IJSTR."
        ]
    },
    {
        "judul":[
            "Social Media Technology Adoption for Improving MSMEs Performance in Bandung: A Technology-Organization-Environment (TOE) Framework"
        ],
        "penulis":"Wulandari, Astri;Suryawardani, Bethani;Marcelino, Dandy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The use of the internet in business activities is a common thing to do in business world. Likewise, with MSMEs, many of them have already used the internet in their business activities. City and Regency of Bandung are the two regions that experience the best MSMEs growth in West Java. This is because these two regions are included in the position of three regions with the largest number of MSMEs in West Java. In addition, the two regions consistently won the achievement as five regions in West Java with the best financial performance measured by the ratio of cost to income. This study is expected to provide several implications related to social media technology adoption with determinant factors of TOE (technology, organization, environment) to improve the business performance of MSMEs. Researchers used quantitative research methods namely causal, with SEM (Structural Equation Model) analysis techniques by SMART PLS 2.0 software. The sampling technique chosen is accidental with a total of 400 respondents. Finding from this research which technology, organization, and environment are the factors that encourage MSMEs in adopting social media, then will impact the performance of MSMEs which include customer services, sales, marketing, and internal operations. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of the internet in business activities is a common thing to do in business world. Likewise, with MSMEs, many of them have already used the internet in their business activities. City and Regency of Bandung are the two regions that experience the best MSMEs growth in West Java. This is because these two regions are included in the position of three regions with the largest number of MSMEs in West Java. In addition, the two regions consistently won the achievement as five regions in West Java with the best financial performance measured by the ratio of cost to income. This study is expected to provide several implications related to social media technology adoption with determinant factors of TOE (technology, organization, environment) to improve the business performance of MSMEs. Researchers used quantitative research methods namely causal, with SEM (Structural Equation Model) analysis techniques by SMART PLS 2.0 software. The sampling technique chosen is accidental with a total of 400 respondents. Finding from this research which technology, organization, and environment are the factors that encourage MSMEs in adopting social media, then will impact the performance of MSMEs which include customer services, sales, marketing, and internal operations. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Automatic Segmented-Syllable and Deep Learning-Based Indonesian Audiovisual Speech Recognition"
        ],
        "penulis":"Suyanto, Suyanto;Ramadhani, Kurniawan Nur;Mandala, Satria;Kurniawan, Adriana;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Many studies proved that the audiovisual speech recognition system was better than the audio-only or visual-only ones. Nevertheless, three crucial issues should be carefully designed: The combination of both audio and visual, the acoustic model, and the feature extraction. In this paper, a deep learning-based Indonesian audiovisual speech recognition (INAVSR) system is developed. It is a combination of two models: Indonesian audio speech recognition (INASR) and Indonesian visual speech recognition (INVSR). The INASR is built using the Mel frequency cepstral coefficient (MFCC) as well as Mozilla DeepSpeech (MDS) and Kaituoxu Speech-Transformer (KST). Whereas the INVSR is implemented using the LipNet. A simple procedure of automatic syllable segmentation in the visual data is proposed. It functions to solve the out of vocabulary (OOV) words problem in recognizing speech in a sentence-level video. Evaluation of a small dataset shows that the developed deep speech-based INASR produces a relatively low word error rate (WER) of 22.0%. Meanwhile, the developed LipNet-based INVSR gives a bit higher WER of 30.8%. The proposed automatic syllable segmentation is able to tackle the problem of OOV words. Finally, an evaluation of the dataset of videos informs that the INAVSR system is capable of recognizing audiovisual speech in a sentence-level video. Compared to the INASR, the INAVSR provides slightly higher performance. It is able to give an absolute reduction of the WER by up to 2.0%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Many studies proved that the audiovisual speech recognition system was better than the audio-only or visual-only ones. Nevertheless, three crucial issues should be carefully designed: The combination of both audio and visual, the acoustic model, and the feature extraction. In this paper, a deep learning-based Indonesian audiovisual speech recognition (INAVSR) system is developed. It is a combination of two models: Indonesian audio speech recognition (INASR) and Indonesian visual speech recognition (INVSR). The INASR is built using the Mel frequency cepstral coefficient (MFCC) as well as Mozilla DeepSpeech (MDS) and Kaituoxu Speech-Transformer (KST). Whereas the INVSR is implemented using the LipNet. A simple procedure of automatic syllable segmentation in the visual data is proposed. It functions to solve the out of vocabulary (OOV) words problem in recognizing speech in a sentence-level video. Evaluation of a small dataset shows that the developed deep speech-based INASR produces a relatively low word error rate (WER) of 22.0%. Meanwhile, the developed LipNet-based INVSR gives a bit higher WER of 30.8%. The proposed automatic syllable segmentation is able to tackle the problem of OOV words. Finally, an evaluation of the dataset of videos informs that the INAVSR system is capable of recognizing audiovisual speech in a sentence-level video. Compared to the INASR, the INAVSR provides slightly higher performance. It is able to give an absolute reduction of the WER by up to 2.0%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Japanese language conjunction and Indonesian language conjunction: Review of contrastive analysis as seen from the use and teaching method"
        ],
        "penulis":"Aditiawarman, Mac;Kartika, Diana;Prajana, Andika;Yuhendra;Mardius, Ali;Fauzi, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Language is the most important part in meeting socially and getting together to wherever and whenever you live. Language becomes very important because without language human can not interact and understand one to another culture. Nowadays Japanese language becomes one of foreign languages which is preferred by most Indonesia people either high school and university students or anyone who is interested in learning Japanese. Furthermore, Japanese language is learned as linguistics which is used to study in Japan or as introductory language at Japanese corporate outside their own country. As mentioned in the introductory chapter, the purpose of this research is to find out the form of conjunctions in Indonesian, the form of conjunctions in Japanese and what are the differences and similarities between forms of conjunctions between the two languages. The research method used by the writer is descriptive analysis method. The author uses research sources derived from written works such as books, theses, journals and the internet. First of all the writer will gather theories and select them according to their level of relevance to the topic under study. Furthermore, the writer will describe and analyse conjunctions contained in Indonesian and Japanese sentences. After being analysed, the writer found 4 conjunctions in Japanese, namely; \u201csoshite\u201d,\u201d kara\u201d, \u201cdemo\u201d and \u201cdesukara\u201d. Whereas in Indonesian the writer found; \u201cdan\u201d, \u201ctetapi\u201d, \u201coleh karena\u201d, \u201cbiarpun\u201d. \u00a9 2020 Asian E F L Journal Press. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Language is the most important part in meeting socially and getting together to wherever and whenever you live. Language becomes very important because without language human can not interact and understand one to another culture. Nowadays Japanese language becomes one of foreign languages which is preferred by most Indonesia people either high school and university students or anyone who is interested in learning Japanese. Furthermore, Japanese language is learned as linguistics which is used to study in Japan or as introductory language at Japanese corporate outside their own country. As mentioned in the introductory chapter, the purpose of this research is to find out the form of conjunctions in Indonesian, the form of conjunctions in Japanese and what are the differences and similarities between forms of conjunctions between the two languages. The research method used by the writer is descriptive analysis method. The author uses research sources derived from written works such as books, theses, journals and the internet. First of all the writer will gather theories and select them according to their level of relevance to the topic under study. Furthermore, the writer will describe and analyse conjunctions contained in Indonesian and Japanese sentences. After being analysed, the writer found 4 conjunctions in Japanese, namely; \u201csoshite\u201d,\u201d kara\u201d, \u201cdemo\u201d and \u201cdesukara\u201d. Whereas in Indonesian the writer found; \u201cdan\u201d, \u201ctetapi\u201d, \u201coleh karena\u201d, \u201cbiarpun\u201d. \u00a9 2020 Asian E F L Journal Press. All rights reserved."
        ]
    },
    {
        "judul":[
            "Sigfox-based internet of things network planning for advanced metering infrastructure services in urban scenario"
        ],
        "penulis":"Purnama, Arrizky Ayu Faradila;Nashiruddin, Muhammad Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "SigFox is a Low Power Wide Area Network (LPWAN) technology using unlicensed frequency bands with Ultra Narrow Band technology. It has advantages in terms of very low power consumption, high receiver sensitivity, and the cheap cost of end devices. SigFox technology is based on Link Quality Control (LQI). One parameter is the division of zones is based on radio configuration, where Indonesia included in zone 2 with radio configuration RC4. SigFox is very suitable as a solution in terms of radio connectivity. In this study, an analysis of the Internet of Thing (IoT) network design was carried out in the East Java province of Indonesia, particularly in the cities of Surabaya, Sidoarjo, and Gresik as Urban Scenario. The Advanced Metering Infrastructure services include electricity, water, gas, and fuel. From the simulations that have been carried out, the optimal number of gateways obtained respectively 34 sites for the Surabaya area with the average signal level received was -78 dBm, and SNR value was 17.27 dB. While five gateways need for the Sidoarjo area with the average signal level received was -89.68 dBm, and SNR value was -1.06 dB, and eight sites for the Gresik area with the average signal level received was -89.14 dBm, and SNR value was -1.12 dB.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SigFox is a Low Power Wide Area Network (LPWAN) technology using unlicensed frequency bands with Ultra Narrow Band technology. It has advantages in terms of very low power consumption, high receiver sensitivity, and the cheap cost of end devices. SigFox technology is based on Link Quality Control (LQI). One parameter is the division of zones is based on radio configuration, where Indonesia included in zone 2 with radio configuration RC4. SigFox is very suitable as a solution in terms of radio connectivity. In this study, an analysis of the Internet of Thing (IoT) network design was carried out in the East Java province of Indonesia, particularly in the cities of Surabaya, Sidoarjo, and Gresik as Urban Scenario. The Advanced Metering Infrastructure services include electricity, water, gas, and fuel. From the simulations that have been carried out, the optimal number of gateways obtained respectively 34 sites for the Surabaya area with the average signal level received was -78 dBm, and SNR value was 17.27 dB. While five gateways need for the Sidoarjo area with the average signal level received was -89.68 dBm, and SNR value was -1.06 dB, and eight sites for the Gresik area with the average signal level received was -89.14 dBm, and SNR value was -1.12 dB.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The base station application of ERSOW team for communication between robots"
        ],
        "penulis":"Haq, Muhammad Abdul;Wibowo, Iwan Kurnianta;Dewantara, Bima Sena Bayu;Bachtiar, Mochamad Mobed;Anwar, Khoirul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Robot soccer is an application of swarm robots that require excellent communication and coordination when performing tasks, like localization, mapping, looking for ball and goal position, dribbling the hall, passing the hall to the teammate robot and shooting the ball to the goal. However, the rule prohibits the direct exchange of data communication and coordination. All communication and coordination in the base station must be carried out via local connection supplied by the competition organizer. In this paper, we deliver our base station specific ally provided for our wheeled type robot soccer called ERSOW. From each robot, the base station gets robot position and ball position information. These data are then processed as the base station system input to output actions that each robot must perform. Furthermore, our base station system can also be used as a debugging tool during play by visualizing the Information obtained by the robot to identify errors. We used unicast and multicast UDP protocol in creating communication between robot and base station (one to one) and base station to robots (one to many). \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Robot soccer is an application of swarm robots that require excellent communication and coordination when performing tasks, like localization, mapping, looking for ball and goal position, dribbling the hall, passing the hall to the teammate robot and shooting the ball to the goal. However, the rule prohibits the direct exchange of data communication and coordination. All communication and coordination in the base station must be carried out via local connection supplied by the competition organizer. In this paper, we deliver our base station specific ally provided for our wheeled type robot soccer called ERSOW. From each robot, the base station gets robot position and ball position information. These data are then processed as the base station system input to output actions that each robot must perform. Furthermore, our base station system can also be used as a debugging tool during play by visualizing the Information obtained by the robot to identify errors. We used unicast and multicast UDP protocol in creating communication between robot and base station (one to one) and base station to robots (one to many). \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Feasibility Study of the IoT-Connectivity Deployment for AMI Service: A Case Study in Surabaya City"
        ],
        "penulis":"Purnama, Arrizky Ayu Faradila;Nashiruddin, Muhammad Imam;Murti, Muhammad Ary;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The manual reading of electricity, water, gas, and fuel tank meters requires increased fieldwork efficiency and improved measurement accuracy and monitoring related to service users and reducing fraud potential. The implementation of measurement services needs to be supported by communication technology, which has low cost and reliability characteristics.AMI (Advanced Meter Infrastructure) is an integrated smart meter system, communication network, and data management system that enables two-way communication between utilities and customers. With AMI's application, it is expected to increase efficiency in monitoring and detecting leaks to overcome losses. IoT is a concept where particular objects can transfer data over the network without requiring human-to-human or human-to-computer interaction. There is technology standardization, namely LPWAN.Planning is done by comparing LoRaWAN, Sigfox, and NB-IoT with the main topic of discussion regarding network connectivity for AMI service needs. Based on the planning results, LoRaWAN requires at least 31 gateways with an average signal level of -83.11 dBm, an average throughput of 21.88 kbps, and an average SNR -0.13 dB. Sigfox requires at least 32 gateways with an intermediate signal level of -81.28 dBm, an average throughput of 0.6 kbps, and an average SNR of 14.79 dB. NB-IoT requires at least 31 gateways with an average signal level of -57.38 dBm, an average throughput of 220.36 kbps, and an average SNR of 8.87 dB. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The manual reading of electricity, water, gas, and fuel tank meters requires increased fieldwork efficiency and improved measurement accuracy and monitoring related to service users and reducing fraud potential. The implementation of measurement services needs to be supported by communication technology, which has low cost and reliability characteristics.AMI (Advanced Meter Infrastructure) is an integrated smart meter system, communication network, and data management system that enables two-way communication between utilities and customers. With AMI's application, it is expected to increase efficiency in monitoring and detecting leaks to overcome losses. IoT is a concept where particular objects can transfer data over the network without requiring human-to-human or human-to-computer interaction. There is technology standardization, namely LPWAN.Planning is done by comparing LoRaWAN, Sigfox, and NB-IoT with the main topic of discussion regarding network connectivity for AMI service needs. Based on the planning results, LoRaWAN requires at least 31 gateways with an average signal level of -83.11 dBm, an average throughput of 21.88 kbps, and an average SNR -0.13 dB. Sigfox requires at least 32 gateways with an intermediate signal level of -81.28 dBm, an average throughput of 0.6 kbps, and an average SNR of 14.79 dB. NB-IoT requires at least 31 gateways with an average signal level of -57.38 dBm, an average throughput of 220.36 kbps, and an average SNR of 8.87 dB. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Broadband Achromatic Printed-Circuit Metasurfaces"
        ],
        "penulis":"Fathnan, Ashif. A.;Powell, David A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We develop broadband achromatic metasurfaces suited for microwave frequencies, by tailoring LC resonances in series and parallel configurations. We present a synthesis method for a transmissive metasurface and discuss limits on their realizable bandwidth. \u00a9 2020 IEEE."
        ],
        "abstrak":[
            "We develop broadband achromatic metasurfaces suited for microwave frequencies, by tailoring LC resonances in series and parallel configurations. We present a synthesis method for a transmissive metasurface and discuss limits on their realizable bandwidth. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "EDGAN: Disguising Text as Image using Generative Adversarial Network"
        ],
        "penulis":"Arifianto, Anditya;Maulana, Malik Anhar;Mahadi, Made Raharja Surya;Jamaluddin, Triwidyastuti;Subhi, Rajabandanu;Rendragraha, Adriansyah Dwi;Satya, Muhammad Ferianda;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the concept of data hiding, image is often used as a cover to hide sensitive data inside it. This approach is considered a good addition in securing information to cryptography which only hides the information and not the presence of the message itself. The combination of Deep Learning with Steganography and Cryptography is rarely done. By utilizing Deep Neural Networks to encrypt and hide the messages, it will be increasingly difficult to decrypt and track.In this study, we developed an encryption mechanism to not only conceal messages, but transforming them into images. The image containing the hidden messages can later be decrypted and converted back into the original message. We use Generative Adversarial Network to develop the encryption and decryption models. Text data is converted into a word vector using word2vec model which then used as input for the encryption model to produce the word images. We use the MNIST dataset to train models which are able to produce images that encrypt 1000 word variations. Based on our experiments, we were able to produce robust encrypted images with 98% accuracy of reversible words. We also show that our model is resistant to various minor image attacks such as scaling, noise addition, and image rotation.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the concept of data hiding, image is often used as a cover to hide sensitive data inside it. This approach is considered a good addition in securing information to cryptography which only hides the information and not the presence of the message itself. The combination of Deep Learning with Steganography and Cryptography is rarely done. By utilizing Deep Neural Networks to encrypt and hide the messages, it will be increasingly difficult to decrypt and track.In this study, we developed an encryption mechanism to not only conceal messages, but transforming them into images. The image containing the hidden messages can later be decrypted and converted back into the original message. We use Generative Adversarial Network to develop the encryption and decryption models. Text data is converted into a word vector using word2vec model which then used as input for the encryption model to produce the word images. We use the MNIST dataset to train models which are able to produce images that encrypt 1000 word variations. Based on our experiments, we were able to produce robust encrypted images with 98% accuracy of reversible words. We also show that our model is resistant to various minor image attacks such as scaling, noise addition, and image rotation.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Experimental and Simulation Approach for Water Bed Movements"
        ],
        "penulis":"Jaya, Alya Alifia Anwar;Gunawan P.H.;Aditsania, Annisa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper examines the simulation of a 1D half nonlinear shallow water model using a staggered grid scheme for comparing with experiment results. Here, the experiment of the moving bottom problem in one-directional horizontal is given. The experiment was built in a glass basin with an obstacle as the moving bottom. Indeed, the impact of moving the bottom in shallow water can generate surface waves with various elevation values. The results showed that numerical simulation using nonlinear shallow water equations is close enough with the experimental data. The comparison of water elevation from simulation results and experimental data is observed in three gauge which are shown as G 1, G 2, and G 3. Using the initial condition of water elevation 0.1 m, then the error measurement of each gauge are obtained less than 10 {-3}.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper examines the simulation of a 1D half nonlinear shallow water model using a staggered grid scheme for comparing with experiment results. Here, the experiment of the moving bottom problem in one-directional horizontal is given. The experiment was built in a glass basin with an obstacle as the moving bottom. Indeed, the impact of moving the bottom in shallow water can generate surface waves with various elevation values. The results showed that numerical simulation using nonlinear shallow water equations is close enough with the experimental data. The comparison of water elevation from simulation results and experimental data is observed in three gauge which are shown as G 1, G 2, and G 3. Using the initial condition of water elevation 0.1 m, then the error measurement of each gauge are obtained less than 10 {-3}.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Wavelet-based hybrid audio watermarking using statistical mean manipulation and spread spectrum"
        ],
        "penulis":"Budiman, Gelar;Suksmono, Andriyan Bayu;Danudirdjo, Donny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, we propose a Discrete Wavelet Transform (DWT) - based hybrid audio watermarking using Statistical Mean Manipulation (SMM) and Spread Spectrum (SS) technique. The host audio is decomposed by DWT to produce the signal in low frequency subband and high frequency subband, where SMM embeds the watermark into low frequency in the first subband, and SS embeds the watermark into high frequency in the selected subband. The embedding process using the SMM technique is the insertion process by modifying the average of the audio signal in one frame according to the watermark, thus it modifies the audio in the low-frequency subband. The SS technique modulates the watermark before it is embedded into the host audio in the higher selected frequency subband. This combination technique produces the robust watermarking method to the signal processing attack, such as Low Pas Filter (LPF), resampling and audio compression while maintaining high watermarked audio quality and watermark payload. \u00a9 2020 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we propose a Discrete Wavelet Transform (DWT) - based hybrid audio watermarking using Statistical Mean Manipulation (SMM) and Spread Spectrum (SS) technique. The host audio is decomposed by DWT to produce the signal in low frequency subband and high frequency subband, where SMM embeds the watermark into low frequency in the first subband, and SS embeds the watermark into high frequency in the selected subband. The embedding process using the SMM technique is the insertion process by modifying the average of the audio signal in one frame according to the watermark, thus it modifies the audio in the low-frequency subband. The SS technique modulates the watermark before it is embedded into the host audio in the higher selected frequency subband. This combination technique produces the robust watermarking method to the signal processing attack, such as Low Pas Filter (LPF), resampling and audio compression while maintaining high watermarked audio quality and watermark payload. \u00a9 2020 IEEE"
        ]
    },
    {
        "judul":[
            "Road information collector using smartphone for measuring road width based on object and lane detection"
        ],
        "penulis":"Nasution, Surya Michrandi;Husni, Emir;Kuspriyanto K.;Yusuf, Rahadian;Mulyawan, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Change in traffic condition is unpredictable. This increases the need for alternate routes to avoid congestions and other conditions. The high variance of vehicle types in Indonesia complicates routing, rendering alternative routes sometimes become unavailable for a specific condition of vehicles. Our research is to develop an application for Android smartphone to collect road information and to offer alternative routes for motorcycles; this paper focuses on the first part of the task. The needed information to acquire is road width, so the drivers could use proper alternative routes for their vehicles (e.g. small car or motorcycles). This research uses both object detection and lane detection methods for obtaining road width, and it is quite simple when lane boundaries are detected in road image. When the lane boundaries are not detected, road width is obtained using a vanishing point method. The average error rate for road width measurement using object and lane detection is 19.71%. Meanwhile, the average error rate when there is no lane boundary is in the range of 10-15%, 8-18%, and 10-19% for various capturing sides. Reclassification of the road is done when the error rate of road width is set. Accuracy of road category reclassification is in the range of 70-75% in various sides. \u00a9 2020 International Association of Online Engineering.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Change in traffic condition is unpredictable. This increases the need for alternate routes to avoid congestions and other conditions. The high variance of vehicle types in Indonesia complicates routing, rendering alternative routes sometimes become unavailable for a specific condition of vehicles. Our research is to develop an application for Android smartphone to collect road information and to offer alternative routes for motorcycles; this paper focuses on the first part of the task. The needed information to acquire is road width, so the drivers could use proper alternative routes for their vehicles (e.g. small car or motorcycles). This research uses both object detection and lane detection methods for obtaining road width, and it is quite simple when lane boundaries are detected in road image. When the lane boundaries are not detected, road width is obtained using a vanishing point method. The average error rate for road width measurement using object and lane detection is 19.71%. Meanwhile, the average error rate when there is no lane boundary is in the range of 10-15%, 8-18%, and 10-19% for various capturing sides. Reclassification of the road is done when the error rate of road width is set. Accuracy of road category reclassification is in the range of 70-75% in various sides. \u00a9 2020 International Association of Online Engineering."
        ]
    },
    {
        "judul":[
            "Recycling of Pineapple (Ananas comosus) Leaf Agro-waste as One of the Raw Materials for Production of Eco-friendly New Paper"
        ],
        "penulis":"Teo, Pao Ter;Zakaria, Siti Koriah;Azhar Taib, Mustaffa Ali;Budiman, Faisal;Mohamed, Mazlan;Yusoff, Abdul Hafidz;Ahmad Sobri, Sharizal;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This project aimed to recycle pineapple (Ananas comosus) leaf agro-waste and wastepaper into new paper using simple processing routes that involve pulping, mixing, sieving, compaction and drying. Subsequently, physical and mechanical properties, as well as the morphology of the pineapple leaf fiber (PALF)-based paper were investigated accordingly. Two different samples were prepared whereby the first sample is pineapple leaf fiber mixed with wastepaper, and another sample is pure pineapple leaf fiber paper. The samples were tested for tensile properties by using the universal testing machine, morphological analysis using scanning electron microscopy, and density measurement using a densitometer. It was found that the sample consist of pineapple leaf and wastepaper shows a higher tensile strength than the sample containing only PALF. Moreover, the density of paper with pineapple leaf fiber and wastepaper mix was higher than the paper with only pineapple leaf fiber. In the future, further modification of body formulation is necessary to further improve the properties of the pineapple leaf fiber-based paper. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This project aimed to recycle pineapple (Ananas comosus) leaf agro-waste and wastepaper into new paper using simple processing routes that involve pulping, mixing, sieving, compaction and drying. Subsequently, physical and mechanical properties, as well as the morphology of the pineapple leaf fiber (PALF)-based paper were investigated accordingly. Two different samples were prepared whereby the first sample is pineapple leaf fiber mixed with wastepaper, and another sample is pure pineapple leaf fiber paper. The samples were tested for tensile properties by using the universal testing machine, morphological analysis using scanning electron microscopy, and density measurement using a densitometer. It was found that the sample consist of pineapple leaf and wastepaper shows a higher tensile strength than the sample containing only PALF. Moreover, the density of paper with pineapple leaf fiber and wastepaper mix was higher than the paper with only pineapple leaf fiber. In the future, further modification of body formulation is necessary to further improve the properties of the pineapple leaf fiber-based paper. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Detection of Multi-Class Glaucoma Using Active Contour Snakes and Support Vector Machine"
        ],
        "penulis":"Zulfira, Fakhira Zahra;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "There are several ways to detect glaucoma, one of the most accurate is the presence of peripapillary atrophy (PPA). PPA is located outside the optic disc around the optic nerve head (ONH) and sometimes looks vague which can cause misclassification, so other parameters that can detect glaucoma are needed. The calculation of the optic cup to disc ratio (CDR) is mostly done for glaucoma detection so that CDR can be considered in addition to the presence of PPA to improve classification results. In this paper, a multi-class glaucoma detection is developed using an active contour snake to get the value of the optic cup and optic disc to measure CDR and a support vector machine (SVM) for classification. Glaucoma is categorized into three classes: non-glaucoma, mild-glaucoma, and severe-glaucoma. Hence, the model can detect its severity which determines further treatment. Evaluation using two datasets of 210 retinal fundus images (165 train and 45 test) informs that the model reaches high accuracies of 95%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "There are several ways to detect glaucoma, one of the most accurate is the presence of peripapillary atrophy (PPA). PPA is located outside the optic disc around the optic nerve head (ONH) and sometimes looks vague which can cause misclassification, so other parameters that can detect glaucoma are needed. The calculation of the optic cup to disc ratio (CDR) is mostly done for glaucoma detection so that CDR can be considered in addition to the presence of PPA to improve classification results. In this paper, a multi-class glaucoma detection is developed using an active contour snake to get the value of the optic cup and optic disc to measure CDR and a support vector machine (SVM) for classification. Glaucoma is categorized into three classes: non-glaucoma, mild-glaucoma, and severe-glaucoma. Hence, the model can detect its severity which determines further treatment. Evaluation using two datasets of 210 retinal fundus images (165 train and 45 test) informs that the model reaches high accuracies of 95%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Sigfox Based Network Planning Analysis for Public Internet of Things Services in Metropolitan Area"
        ],
        "penulis":"Febriyandi, Fenta;Arifin, Ajib Setyo;Nashiruddin, Muhammad Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Sigfox is a radio protocol Low Power Wide Area Network (LPWAN) technology that has a characteristic global reach, cost-effective, energy efficiency, and simplicity. Sigfox operates in the unlicensed spectrum frequency band, during transmitting and receiving messages, Sigfox uses ultra-narrow band (UNB) modulation technique. This paper analyzes Sigfox based network planning for public Internet of Things (IoT) services in a metropolitan area that has 10.37 million population and 662.3 km2. The result of the study stated that 33 access points are needed to cover the entire city. The simulation result shows that 99.9% of the area has a Reference Signal Received Power (RSRP) Downlink level above -134 dBm. The mean values of RSRP Downlink and Signal to Interference and Noise Ratio (SINR) Downlink are -91.81 dBm and 7.98 dB, respectively. Meanwhile, for the Received Signal Strength Indicator (RSSI) Downlink parameter, 98.7% metropolitan area is covered and has a mean value of -87.91 dBm. Okumura-Hata radio propagation model is used and gives results that allowed propagation loss and shadow fading margin are 152.5 dB and 7.5 dB, respectively, thus cell range for one access point reaches 3.28 km.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sigfox is a radio protocol Low Power Wide Area Network (LPWAN) technology that has a characteristic global reach, cost-effective, energy efficiency, and simplicity. Sigfox operates in the unlicensed spectrum frequency band, during transmitting and receiving messages, Sigfox uses ultra-narrow band (UNB) modulation technique. This paper analyzes Sigfox based network planning for public Internet of Things (IoT) services in a metropolitan area that has 10.37 million population and 662.3 km2. The result of the study stated that 33 access points are needed to cover the entire city. The simulation result shows that 99.9% of the area has a Reference Signal Received Power (RSRP) Downlink level above -134 dBm. The mean values of RSRP Downlink and Signal to Interference and Noise Ratio (SINR) Downlink are -91.81 dBm and 7.98 dB, respectively. Meanwhile, for the Received Signal Strength Indicator (RSSI) Downlink parameter, 98.7% metropolitan area is covered and has a mean value of -87.91 dBm. Okumura-Hata radio propagation model is used and gives results that allowed propagation loss and shadow fading margin are 152.5 dB and 7.5 dB, respectively, thus cell range for one access point reaches 3.28 km.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "LoRaWAN Internet of Things Network Planning for Smart City in Bandung Areas"
        ],
        "penulis":"Baja Sihotang, Maruli Tua;Nashiruddin, Muhammad Imam;Murti, Muhammad Ary;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The Smart Cities Framework is the basis for developing the Smart Cities model. This consideration must take into account the possibility of increasing the number of subscribers who require operators to provide appropriate access services. This study provides solutions and optimization of LoRaWAN-based Internet of Things (IoT) network connectivity to determine the needfor the number of gateways. LoRaWAN-based IoT optimization has critical design parameters, namely bandwidth, Spreading Factor (SF), and Coding Rate (CR). For this reason, analytic models and simulation tools are applied based on the scope and range that canbe transmitted. The results showed that the mean of best receivedsignal level for all areas of Bandung City was-81.17 dBm based oncapacity analysis and 82.31 dBm based on coverage analysis. Basedon the analysis of LoRaWAN capacity and coverage planning thatthe gateway needs in Bandung are 40 and 30 sites. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Smart Cities Framework is the basis for developing the Smart Cities model. This consideration must take into account the possibility of increasing the number of subscribers who require operators to provide appropriate access services. This study provides solutions and optimization of LoRaWAN-based Internet of Things (IoT) network connectivity to determine the needfor the number of gateways. LoRaWAN-based IoT optimization has critical design parameters, namely bandwidth, Spreading Factor (SF), and Coding Rate (CR). For this reason, analytic models and simulation tools are applied based on the scope and range that canbe transmitted. The results showed that the mean of best receivedsignal level for all areas of Bandung City was-81.17 dBm based oncapacity analysis and 82.31 dBm based on coverage analysis. Basedon the analysis of LoRaWAN capacity and coverage planning thatthe gateway needs in Bandung are 40 and 30 sites. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Competitive advantage improvement of publishing industry in Indonesia: A Case of PT. Gramedia digital nusantara"
        ],
        "penulis":"Diar, Alifiannisa Lawami;Tantra, Ruchi Intan;Setiadi, Farisya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The changes in the business environment influenced by the growth of the global information system and technology development does not exclude changes mandated in book retail and publishing industry business model. Research on business model innovation emerge since the 2000s, but the research that analyzes its relation to how value chain and strategy may utilize one firm's competitive advantage is rare. Hence, this research fulfills the knowledge gaps, uses PT. Gramedia Digital Nusantara as a case study to analyze its business model and value chain. This research adopted the Osterwalder business model canvas, Porter's value chain model, and Porter's Generic Strategy to categorize the firm's competitive advantage improvement. Data collection research was conducted by converges in-depth interviews, data analysis for quantitative support, and observation results to answer the lack of in the firm's document. Then, the data were processed by using conventional qualitative data analysis techniques, open and axial coding. From the research, it can be concluded that the firm's competitive advantage is concerned about the efficiency resulted from internal key partners' collaboration, the utilization of advanced technology in marketing and production activities. Also, strengthen the customer segments with the firm through customer relationships supported by technology operations and research and insights activities. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The changes in the business environment influenced by the growth of the global information system and technology development does not exclude changes mandated in book retail and publishing industry business model. Research on business model innovation emerge since the 2000s, but the research that analyzes its relation to how value chain and strategy may utilize one firm's competitive advantage is rare. Hence, this research fulfills the knowledge gaps, uses PT. Gramedia Digital Nusantara as a case study to analyze its business model and value chain. This research adopted the Osterwalder business model canvas, Porter's value chain model, and Porter's Generic Strategy to categorize the firm's competitive advantage improvement. Data collection research was conducted by converges in-depth interviews, data analysis for quantitative support, and observation results to answer the lack of in the firm's document. Then, the data were processed by using conventional qualitative data analysis techniques, open and axial coding. From the research, it can be concluded that the firm's competitive advantage is concerned about the efficiency resulted from internal key partners' collaboration, the utilization of advanced technology in marketing and production activities. Also, strengthen the customer segments with the firm through customer relationships supported by technology operations and research and insights activities. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Preventive maintenance model for heating ventilation air conditioning in pharmacy manufacturing sector"
        ],
        "penulis":"Chin, Jacky;Herlina;Lin, Shu-Chiang;Persada, Satria Fadil;Jaqin, Choesnul;Mufidah, Ilma;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One of the most important factors for the success of maintenance system in heating, ventilation, and air conditioning (HVAC) implementation is satisfaction rate of preventive maintenance. However, there is only few research available regarding the factors influence in the success of maintenance system in manufacturing facilities, including HVAC. The study unearths the complexity link by using the Preventive Maintenance Satisfaction Model, specifically constructed for this study by combining four external factors and two internal factors to evaluate the implementation of the preventive maintenance system in the pharmacy manufacturing industries. The Indonesia pharmacy manufacturing is selected as a case study. The Structural Equation Modeling approach is applied in the analysis phase. Four factors are explored in this evaluation, tools, duration, rate of skill competency, and rate of machine complexity. The analysis results indicated that all factors positively influenced the rate of preventive maintenance satisfaction through facilitating conditions (\u03b2 = 0.566, p < 0.001). The significant contribution of this research is to develop methodologically factors of the satisfaction rate of preventive maintenance in terms of HVAC maintenance system in manufacturing, supporting company sustainability programs. This study gives valuable insights to decision-makers involved in the implementation and development of maintenance system. \u00a9 2019, The Society for Reliability Engineering, Quality and Operations Management (SREQOM), India and The Division of Operation and Maintenance, Lulea University of Technology, Sweden.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the most important factors for the success of maintenance system in heating, ventilation, and air conditioning (HVAC) implementation is satisfaction rate of preventive maintenance. However, there is only few research available regarding the factors influence in the success of maintenance system in manufacturing facilities, including HVAC. The study unearths the complexity link by using the Preventive Maintenance Satisfaction Model, specifically constructed for this study by combining four external factors and two internal factors to evaluate the implementation of the preventive maintenance system in the pharmacy manufacturing industries. The Indonesia pharmacy manufacturing is selected as a case study. The Structural Equation Modeling approach is applied in the analysis phase. Four factors are explored in this evaluation, tools, duration, rate of skill competency, and rate of machine complexity. The analysis results indicated that all factors positively influenced the rate of preventive maintenance satisfaction through facilitating conditions (\u03b2 = 0.566, p < 0.001). The significant contribution of this research is to develop methodologically factors of the satisfaction rate of preventive maintenance in terms of HVAC maintenance system in manufacturing, supporting company sustainability programs. This study gives valuable insights to decision-makers involved in the implementation and development of maintenance system. \u00a9 2019, The Society for Reliability Engineering, Quality and Operations Management (SREQOM), India and The Division of Operation and Maintenance, Lulea University of Technology, Sweden."
        ]
    },
    {
        "judul":[
            "Simultaneous Gradient Descent-Ascent for GANs Minimax Optimization using Sinkhorn Divergence"
        ],
        "penulis":"Adnan, Risman;Adi Saputra, Muchlisin;Fadlil, Junaidillah;Iqbal, Muhamad;Basaruddin, Tjan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The Sinkhorn divergence, a smooth and symmetric normalization version of entropy-regularized optimal transport (EOT) is a promising tool for Generative Adversarial Networks (GANs). However, understanding the dynamic of gradient algorithms for Sinkhorn-based GANs remains a big challenge. In this work, we consider the GANs minimax optimization problem using Sinkhorn divergence, in which smoothness and convexity properties of the objective function are critical factors for convergence and stability. We prove that GANs with convex-concave Sinkhorn divergence can converge to local Nash equilibrium using first-order simultaneous stochastic gradient descent-ascent (SimSGDA) algorithm under certain approximations. We further present a nonasymptotic analysis for the convergence rate of the SimSGDA using structural similarity index measure (SSIM). Our experiments suggest a convergence rate proportional to the inverse number of SGDA iterations tested on tiny-colored datasets (Cats and CelebA) and advanced neural architectures (DCGAN and ResNet). We demonstrate that SSIM is potential tool to measure convergence rate of the SimSGDA algorithm empirically. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Sinkhorn divergence, a smooth and symmetric normalization version of entropy-regularized optimal transport (EOT) is a promising tool for Generative Adversarial Networks (GANs). However, understanding the dynamic of gradient algorithms for Sinkhorn-based GANs remains a big challenge. In this work, we consider the GANs minimax optimization problem using Sinkhorn divergence, in which smoothness and convexity properties of the objective function are critical factors for convergence and stability. We prove that GANs with convex-concave Sinkhorn divergence can converge to local Nash equilibrium using first-order simultaneous stochastic gradient descent-ascent (SimSGDA) algorithm under certain approximations. We further present a nonasymptotic analysis for the convergence rate of the SimSGDA using structural similarity index measure (SSIM). Our experiments suggest a convergence rate proportional to the inverse number of SGDA iterations tested on tiny-colored datasets (Cats and CelebA) and advanced neural architectures (DCGAN and ResNet). We demonstrate that SSIM is potential tool to measure convergence rate of the SimSGDA algorithm empirically. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Non invasive anemia detection in pregnant women based on digital image processing and K-nearest neighbor"
        ],
        "penulis":"Fuadah, Yunendah Nur;Sa'Idah, Sofia;Wijayanto, Inung;Patmasari, Raditiana;Magdalena, Rita;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Anemia is a disease caused by low levels of hemoglobin in the blood. In general, the detection process of anemia is carried out invasively through an examination of hemoglobin levels in the blood. Another method can be done non-invasively by clinical examination of the conjunctiva of the eyes, tongue, palms, and nails. Early detection of anemia is a solution to prevent severe consequences of lack of hemoglobin levels in the blood, especially in pregnant women who are at higher risk of the mother and fetus's safety. This study proposes a non-invasive computer-aided diagnose system for detecting anemia based on digital image processing. The method is by analyzing the conjunctival image of the eye. This study uses the first-order statistic feature extraction method and K-Nearest Neighbor (K-NN) for classifying the conjunctival image into two conditions, anemia and non-anemia conditions. The feature extraction method is performed on RGB, Hue, Saturation, and Value (HSV), and grayscale color space. The system achieved 71.25% of accuracy by using the most optimal parameters on the Green layer of RGB with K = 5 and Euclidean distance equation. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Anemia is a disease caused by low levels of hemoglobin in the blood. In general, the detection process of anemia is carried out invasively through an examination of hemoglobin levels in the blood. Another method can be done non-invasively by clinical examination of the conjunctiva of the eyes, tongue, palms, and nails. Early detection of anemia is a solution to prevent severe consequences of lack of hemoglobin levels in the blood, especially in pregnant women who are at higher risk of the mother and fetus's safety. This study proposes a non-invasive computer-aided diagnose system for detecting anemia based on digital image processing. The method is by analyzing the conjunctival image of the eye. This study uses the first-order statistic feature extraction method and K-Nearest Neighbor (K-NN) for classifying the conjunctival image into two conditions, anemia and non-anemia conditions. The feature extraction method is performed on RGB, Hue, Saturation, and Value (HSV), and grayscale color space. The system achieved 71.25% of accuracy by using the most optimal parameters on the Green layer of RGB with K = 5 and Euclidean distance equation. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Analysis of User Intention Detection Related to Conventional Poster Advertisement by Using the Features of Face and Eye(s)"
        ],
        "penulis":"Modesty, Yolanda;Sudiharto, Dodi Wisaksono;Wijiutomo, Catur Wirawan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "There are official media to display conventional advertisements such as posters and billboards. However, those cannot tell to the owner related to the effectiveness of the advertisements directly. It can be recognized after the product items have been sold. Based on that problem, there is a requirement related to the media demonstrate an ability to instantly detect user intention. That function explained, generally, is held by a smart advertisement display. On that one, smart components can instantly detect the user intention, are attached to the monitor. Unfortunately, for some companies, the monitor is still expensive to be performed. This condition makes a potential desire to modify the existing smart advertisement system by gently moving the smart components (as an embedded system and a sensor) to other conventional displayed media such as posters. There is an underline state that has to be proven then that the smart modules attached on has to act similarly, likes when they are attached on the monitor. This study observes the ability of the smart components if they are attached to the posters to detect user intention directly. This study uses the previous observation result for elaborating user intention detection by using face and eye(s) features. The result gives a proven fact that smart parts attached to the posters produce the scoring which is relatively the same as the scoring by the smart display system in an arrangement, related to the effectiveness of the advertisement.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "There are official media to display conventional advertisements such as posters and billboards. However, those cannot tell to the owner related to the effectiveness of the advertisements directly. It can be recognized after the product items have been sold. Based on that problem, there is a requirement related to the media demonstrate an ability to instantly detect user intention. That function explained, generally, is held by a smart advertisement display. On that one, smart components can instantly detect the user intention, are attached to the monitor. Unfortunately, for some companies, the monitor is still expensive to be performed. This condition makes a potential desire to modify the existing smart advertisement system by gently moving the smart components (as an embedded system and a sensor) to other conventional displayed media such as posters. There is an underline state that has to be proven then that the smart modules attached on has to act similarly, likes when they are attached on the monitor. This study observes the ability of the smart components if they are attached to the posters to detect user intention directly. This study uses the previous observation result for elaborating user intention detection by using face and eye(s) features. The result gives a proven fact that smart parts attached to the posters produce the scoring which is relatively the same as the scoring by the smart display system in an arrangement, related to the effectiveness of the advertisement.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Parallel Algorithm for K-Means Clustering in Wood Species Classification"
        ],
        "penulis":"Gunawan P.H.;Fathurahman, Taufik;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Wood is one of the commodities that are often traded for industrial materials such as furniture, crafts, building raw materials, etc. Therefore identification system of wood species is needed to find out how the condition of the wood which can be seen from the vessel structure and its diameter. To do this identification, a large enough dataset of wood image is needed so that the data can be validated. From large datasets of wood image, the grouping of wooden vessels can be carried out using computing method which is called K-means clustering. However, using large wood image datasets will increase the computational cost. In this research, K-means clustering method will be implemented in serial and parallel programs to see the use of parallel program to handle computational cost. Here speedup and efficiency measurements will be elaborated to see the benefit of parallel program. The experiment result show that speedup using parallel computing is increasingly 4 times faster then serial computing. Moreover the efficiency using parallel architecture is observed 96.04%. Therefore it can be concluded that implementing the K-means clustering method in parallel programs can obtain optimal computational cost and produce high-efficiency values using the same workload as the serial program. \u00a9 2020, Springer Nature Switzerland AG.",
            "NONHSH2CCH3H3CView detailsExpand Substance Albutoin",
            "Powered by"
        ],
        "abstrak":[
            "Wood is one of the commodities that are often traded for industrial materials such as furniture, crafts, building raw materials, etc. Therefore identification system of wood species is needed to find out how the condition of the wood which can be seen from the vessel structure and its diameter. To do this identification, a large enough dataset of wood image is needed so that the data can be validated. From large datasets of wood image, the grouping of wooden vessels can be carried out using computing method which is called K-means clustering. However, using large wood image datasets will increase the computational cost. In this research, K-means clustering method will be implemented in serial and parallel programs to see the use of parallel program to handle computational cost. Here speedup and efficiency measurements will be elaborated to see the benefit of parallel program. The experiment result show that speedup using parallel computing is increasingly 4 times faster then serial computing. Moreover the efficiency using parallel architecture is observed 96.04%. Therefore it can be concluded that implementing the K-means clustering method in parallel programs can obtain optimal computational cost and produce high-efficiency values using the same workload as the serial program. \u00a9 2020, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Single camera depth control in micro class ROV"
        ],
        "penulis":"Siregar, Simon;Sani, Muhammad Ikhsan;Parlindungan Silalahi, Sintong Tua;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Navigation is one of the main challenges in an underwater vehicle. To measure and sustain the depth in the micro class remotely operated vehicle (ROV) robot is one of the main demands in the underwater robot competition. There are many sensors that can be used to measure the depth; one of the sensors is using a single camera sensor. In this works, camera-based depth control is developed and evaluated for micro class ROV, namely as fitoplankton SAS ROV. Fitoplankton SAS ROV is a micro ROV prototype with six thrusters. To maintain the depth position, a PID control system with a camera-based depth sensor as the input of the setpoint is used. Moreover, the method for the camera to measure the distance is using the triangle similarity method. In this paper, the experimental scenario is using the rectangular marker to measure the distance, and the value of the depth is processing in the ground control station (GCS). The GCS will send the thruster value to control the depth, which depends on the PID control system. The experiment results show an average of depth accuracy of 95.74% to the depth setpoint. \u00a9 2019 Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Navigation is one of the main challenges in an underwater vehicle. To measure and sustain the depth in the micro class remotely operated vehicle (ROV) robot is one of the main demands in the underwater robot competition. There are many sensors that can be used to measure the depth; one of the sensors is using a single camera sensor. In this works, camera-based depth control is developed and evaluated for micro class ROV, namely as fitoplankton SAS ROV. Fitoplankton SAS ROV is a micro ROV prototype with six thrusters. To maintain the depth position, a PID control system with a camera-based depth sensor as the input of the setpoint is used. Moreover, the method for the camera to measure the distance is using the triangle similarity method. In this paper, the experimental scenario is using the rectangular marker to measure the distance, and the value of the depth is processing in the ground control station (GCS). The GCS will send the thruster value to control the depth, which depends on the PID control system. The experiment results show an average of depth accuracy of 95.74% to the depth setpoint. \u00a9 2019 Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Topic-Based Tweet Clustering for Public Figures Using Ant Clustering"
        ],
        "penulis":"Firdaus, Diaz Harizky;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The aspects of life on a public figure, discussed by the community, are often exploited by the news media as topic information to create an article that can attract the attention of the reader. Efficiently, the media only needs to pay attention to social media to get some of the information. The more information needed leads to a vast amount of data involved, so the process becomes hard. In this paper, a tweet clustering system to determine topics from many documents in the form of text through text mining method using an ant clustering (AC) technique. AC is one of swarm intelligence algorithms inspired by the behavior of the ant colony in sorting corpses. Evaluation of a small dataset of text documents shows that four topics are successfully concluded: economy, social, politics, and government. The developed AC-based tweet clustering system produces an average cluster quality of the Dunn Index up to 0,3455.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aspects of life on a public figure, discussed by the community, are often exploited by the news media as topic information to create an article that can attract the attention of the reader. Efficiently, the media only needs to pay attention to social media to get some of the information. The more information needed leads to a vast amount of data involved, so the process becomes hard. In this paper, a tweet clustering system to determine topics from many documents in the form of text through text mining method using an ant clustering (AC) technique. AC is one of swarm intelligence algorithms inspired by the behavior of the ant colony in sorting corpses. Evaluation of a small dataset of text documents shows that four topics are successfully concluded: economy, social, politics, and government. The developed AC-based tweet clustering system produces an average cluster quality of the Dunn Index up to 0,3455.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Indonesian Ethnicity Recognition Based on Face Image Using Uniform Local Binary Pattern (ULBP) and Color Histogram"
        ],
        "penulis":"Putri, Tiani Tiara;Rachmawati, Ema;Sthevanie, Febryanti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Ethnicity is one of identity every human has and can be used to categorize individuals in populations or large groups. We presented an Indonesian ethnicity recognition based on facial images using Uniform Local Binary Pattern (ULBP) and Color Histogram as a feature extraction method. We used the five largest ethnic groups in Indonesia, namely Sundanese, Javanese, Banjar, Buginese, and Malay. In the experiment, we used Random Forest as a classification method. The research obtained a performance accuracy of 98.25% using 2290 facial images. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ethnicity is one of identity every human has and can be used to categorize individuals in populations or large groups. We presented an Indonesian ethnicity recognition based on facial images using Uniform Local Binary Pattern (ULBP) and Color Histogram as a feature extraction method. We used the five largest ethnic groups in Indonesia, namely Sundanese, Javanese, Banjar, Buginese, and Malay. In the experiment, we used Random Forest as a classification method. The research obtained a performance accuracy of 98.25% using 2290 facial images. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Tracking, Arrival Time Estimator, and Passenger Information System on Bus Rapid Transit (BRT)"
        ],
        "penulis":"Hafiizh Nur M.A.;Hadiyoso, Sugondo;Belladina, Fefa Bianca;Ramadan, Dadan Nur;Wijayanto, Inung;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Trans Metro Bandung is a new Bus Rapid Transit in Bandung, Indonesia. As a new mode of transportation, it proposes comfort, safety, and give an affordable price. However, information systems related to buses are still lacking and far from expectations. That includes the uncertainty of the bus departures and arrivals times at bus stops. Therefore, in this study, an integrated online system is designed to provide information, including bus arrival time, bus position, and the number of passengers on the bus. This information system is a website application that is connected to the Firebase real-time database so that all data can be accessed in real-time and then displayed at the bus stop. The hardware system consists of an infrared detector to count the number of passengers and a GPS module for bus tracking. From the bus position information, the system can estimate the arrival time at the nearest bus stop.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Trans Metro Bandung is a new Bus Rapid Transit in Bandung, Indonesia. As a new mode of transportation, it proposes comfort, safety, and give an affordable price. However, information systems related to buses are still lacking and far from expectations. That includes the uncertainty of the bus departures and arrivals times at bus stops. Therefore, in this study, an integrated online system is designed to provide information, including bus arrival time, bus position, and the number of passengers on the bus. This information system is a website application that is connected to the Firebase real-time database so that all data can be accessed in real-time and then displayed at the bus stop. The hardware system consists of an infrared detector to count the number of passengers and a GPS module for bus tracking. From the bus position information, the system can estimate the arrival time at the nearest bus stop.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Experimental Security Analysis for Fake eNodeB Attack on LTE Network"
        ],
        "penulis":"Fardan;Istikmal;Mawaldi, Ikbal;Anugraha, Tides;Ginting, Ishak;Karna, Nyoman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The Long Term Evolution (LTE) user network is the largest population used nowadays compared to 2G and 3G in mobile telecom landscape. It is declared that LTE has provided a strong security standard in term of protecting its user for security attack on mobile communication. Fake Base Station is one of attack scheme in mobile communication infrastructure. The paper showcases the experimental analysis of the vulnerability of the LTE network which is impact to the user if we perform Fake eNodeB attack. In this experiment, we use OpenAirInterface5G, an opensource cellular platform that supports the full stack of LTE including 5G standard as the Fake eNodeB. The attack is performed by impersonating a real 4G network Operator. The result of this attack is IMSI number of users is obtained which lead the users is traceable as well as it is possible to force the target unable to be served back by the legitimate base station which leads to Denial of Service (DOS) attack. We also point out on describing the flaws of the LTE protocol that lead into this possibility of attacking and its implication especially on user identity and user connection with the operator that possibly harmed. We describe also several options to overcome the issue in the future.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Long Term Evolution (LTE) user network is the largest population used nowadays compared to 2G and 3G in mobile telecom landscape. It is declared that LTE has provided a strong security standard in term of protecting its user for security attack on mobile communication. Fake Base Station is one of attack scheme in mobile communication infrastructure. The paper showcases the experimental analysis of the vulnerability of the LTE network which is impact to the user if we perform Fake eNodeB attack. In this experiment, we use OpenAirInterface5G, an opensource cellular platform that supports the full stack of LTE including 5G standard as the Fake eNodeB. The attack is performed by impersonating a real 4G network Operator. The result of this attack is IMSI number of users is obtained which lead the users is traceable as well as it is possible to force the target unable to be served back by the legitimate base station which leads to Denial of Service (DOS) attack. We also point out on describing the flaws of the LTE protocol that lead into this possibility of attacking and its implication especially on user identity and user connection with the operator that possibly harmed. We describe also several options to overcome the issue in the future.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "University Management System Engineering based on BAN PT Accreditation Criteria Two using SysML and Semantic Approach"
        ],
        "penulis":"Aurachman, Rio;Putri, Ericha Mutia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Higher education organizations need to implement a management system. However, there has not been a study that designed the management system based on the latest BAN PT Accreditation Criteria, specifically criterion number 2. The design uses the Model Based System Engineering approach with SysML Language. Translation of accreditation standard sentences is done using the Semantic approach. Trough this research, obtained a design that can be applied at the University in order to maintain the quality of education. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Higher education organizations need to implement a management system. However, there has not been a study that designed the management system based on the latest BAN PT Accreditation Criteria, specifically criterion number 2. The design uses the Model Based System Engineering approach with SysML Language. Translation of accreditation standard sentences is done using the Semantic approach. Trough this research, obtained a design that can be applied at the University in order to maintain the quality of education. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Exploratory factor analysis (Efa) to measure entrepreneur satisfaction"
        ],
        "penulis":"Iskamto, Dedi;Ghazali, Puspa Liza;Aftanorhan, Asyraf ;Jenita;Sukono;Bon, Abdul Talib;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper reports on developing a conceptualization for measuring the satisfaction of entrepreneurs. The paper, in doing so, first establishes a theoretical framework by defining constructs of entrepreneur satisfaction from the literature. Secondly, the identification of evaluating requirements from the literature for these constructs, and thirdly, the validation of the theoretical model for measuring the satisfaction of entrepreneurs in Indonesia. The theoretical model consists of 9 entrepreneur satisfaction. The empirical process of validation employed data collected from 100 respondents of pilot test what Micro and Small Enterprises in Pekanbaru Indonesia. The validation method aimed at validating the parameters which measure each of the constructs by statistically determining that the sample used is adequate, using the Bartlett test to ensuring the usefulness of the data for multivariate statistical analysis, validating the measurement requirements as applicable to entrepreneur satisfaction and determining the reliability of each entrepreneur satisfaction. All those goals were accomplished. This coincided in the end result, perhaps even an adjusted statistical model to measure the satisfaction of entrepreneurs in Indonesia. The design has been statistically tested to become a valid and reliable design. \u00a9 IEOM Society International.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper reports on developing a conceptualization for measuring the satisfaction of entrepreneurs. The paper, in doing so, first establishes a theoretical framework by defining constructs of entrepreneur satisfaction from the literature. Secondly, the identification of evaluating requirements from the literature for these constructs, and thirdly, the validation of the theoretical model for measuring the satisfaction of entrepreneurs in Indonesia. The theoretical model consists of 9 entrepreneur satisfaction. The empirical process of validation employed data collected from 100 respondents of pilot test what Micro and Small Enterprises in Pekanbaru Indonesia. The validation method aimed at validating the parameters which measure each of the constructs by statistically determining that the sample used is adequate, using the Bartlett test to ensuring the usefulness of the data for multivariate statistical analysis, validating the measurement requirements as applicable to entrepreneur satisfaction and determining the reliability of each entrepreneur satisfaction. All those goals were accomplished. This coincided in the end result, perhaps even an adjusted statistical model to measure the satisfaction of entrepreneurs in Indonesia. The design has been statistically tested to become a valid and reliable design. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "The Development of Information System Security Operation Centre (SOC): Case Study of Auto Repair Company"
        ],
        "penulis":"Lubis, Muharman;Wardana, Chandra;Widjajarto, Adityas;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Auto repair is a series of activities that engage in the field of body repair and painting services of car and motorcycle. The ultimate goal is to provide the best service and quality standards to customers by running the proper response processes, which lead the increased customer satisfaction to be achieved. Importantly, every company required the security system and mechanism to maintain the existing system as an effort to protect and overcome problems related to data privacy, transactions and communication. This study explores the problem and challenges faced by the respected company to generate an access control matrix for logical and physical assets as well as service operation procedure. The focus primarily in the development of Security Operation Center (SOC) as the front gate of the company to offer various services to the customers. SOC is a key enabler for operators who aspire to differentiate themselves based on customer experience and demand. A successful SOC application can help operators to reduce the pressure and improve operational efficiency.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Auto repair is a series of activities that engage in the field of body repair and painting services of car and motorcycle. The ultimate goal is to provide the best service and quality standards to customers by running the proper response processes, which lead the increased customer satisfaction to be achieved. Importantly, every company required the security system and mechanism to maintain the existing system as an effort to protect and overcome problems related to data privacy, transactions and communication. This study explores the problem and challenges faced by the respected company to generate an access control matrix for logical and physical assets as well as service operation procedure. The focus primarily in the development of Security Operation Center (SOC) as the front gate of the company to offer various services to the customers. SOC is a key enabler for operators who aspire to differentiate themselves based on customer experience and demand. A successful SOC application can help operators to reduce the pressure and improve operational efficiency.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Gradient-Based Edge Effects on Lane Marking Detection using a Deep Learning-Based Approach"
        ],
        "penulis":"Zakaria, Noor Jannah;Shapiai, Mohd Ibrahim;Fauzi, Hilman;Elhawary, Hossamelden Mohamed Amin;Yahya, Wira Jazair;Abdul Rahman, Mohd Azizi;Abu Kassim, Khairil Anwar;Bahiuddin, Irfan;Mohammed Ariff, Mohd Hatta;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Lane detection is part of the advanced driver assistance system (ADAS) equipped in intelligent vehicles. The system provides the driver with significant geometric information of the road ahead. Numerous deep learning techniques have been employed in lane detection because of the simplicity, ease, and efficiency of these techniques in learning discriminative features from RGB (red, green, and blue) images. However, existing works have rarely considered detecting lane markings during bad weather conditions, which could reduce lane detection performance. Hence, this paper proposed a Fully Convolutional Network (FCN) model with RGB and Canny edge detection used as the model\u2019s spatial input. The proposed platform was developed using two scenarios: FCN-RGB-edge and FCN-edge. The model development was divided into three stages, namely data acquisition, platform development, and benchmarking against existing methods and data. Both scenarios using the proposed method yielded a 4% improvement compared to the original FCN-RGB images (i.e., the previous method). The Canny edge detection method successfully extracted necessary information from the images and neglected the water drops in rainy conditions by treating them as noise. In summary, the proposed method has the potential to boost the performance of the ADAS system in detecting lane markings in rainy conditions. \u00a9 2020, King Fahd University of Petroleum & Minerals.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Lane detection is part of the advanced driver assistance system (ADAS) equipped in intelligent vehicles. The system provides the driver with significant geometric information of the road ahead. Numerous deep learning techniques have been employed in lane detection because of the simplicity, ease, and efficiency of these techniques in learning discriminative features from RGB (red, green, and blue) images. However, existing works have rarely considered detecting lane markings during bad weather conditions, which could reduce lane detection performance. Hence, this paper proposed a Fully Convolutional Network (FCN) model with RGB and Canny edge detection used as the model\u2019s spatial input. The proposed platform was developed using two scenarios: FCN-RGB-edge and FCN-edge. The model development was divided into three stages, namely data acquisition, platform development, and benchmarking against existing methods and data. Both scenarios using the proposed method yielded a 4% improvement compared to the original FCN-RGB images (i.e., the previous method). The Canny edge detection method successfully extracted necessary information from the images and neglected the water drops in rainy conditions by treating them as noise. In summary, the proposed method has the potential to boost the performance of the ADAS system in detecting lane markings in rainy conditions. \u00a9 2020, King Fahd University of Petroleum & Minerals."
        ]
    },
    {
        "judul":[
            "A PROPOSED MODIFIED TEXT STEGANOGRAPHY TECHNIQUE USING UNISPACH WITH XOR ENCRYPTION AND SHIFT CIPHER"
        ],
        "penulis":"Adinugraha, Raka;Purboyo, Tito Waluyo;Saputra, Randy Erfa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, security on communication was a necessity. However, sending an encrypted message can draw a suspicion from unintended parties. So, sometimes cryptography doesn\u2019t guarantee a full security because it could attract attempts to break and reveal the encrypted message. Steganography was introduced as a method to secure a secret message by hiding it inside an unsuspicious message. The message can be plain text or other data that can be represented as streams of bits. Many of steganography techniques are being proposed from time to time, means steganography is a promising method to secure a communication line beside cryptography. In this paper, an experiment is conducted by comparing two text steganography techniques, which is UniSpaCh and a steganography technique by altering the foreground color of an invisible character. \u00a9 2006\u20132020. Asian Research Publishing Network (ARPN). All rights reserved.",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, security on communication was a necessity. However, sending an encrypted message can draw a suspicion from unintended parties. So, sometimes cryptography doesn\u2019t guarantee a full security because it could attract attempts to break and reveal the encrypted message. Steganography was introduced as a method to secure a secret message by hiding it inside an unsuspicious message. The message can be plain text or other data that can be represented as streams of bits. Many of steganography techniques are being proposed from time to time, means steganography is a promising method to secure a communication line beside cryptography. In this paper, an experiment is conducted by comparing two text steganography techniques, which is UniSpaCh and a steganography technique by altering the foreground color of an invisible character. \u00a9 2006\u20132020. Asian Research Publishing Network (ARPN). All rights reserved."
        ]
    },
    {
        "judul":[
            "Design of disaster recovery plan: State university in indonesia"
        ],
        "penulis":"Setyawan, Andri;Giri Sucahyo, Yudho;Gandhi, Arfive;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "University X is a state university in Indonesia that can independently manage its assets. In carrying out its business processes, University X uses many information systems managed by the Directorate of Information Systems and Technology (DIST). The management of IS\/IT at the State University has not yet reached risk management implementation under IT governance. This research criticized the absence of an IS\/IT recovery plan as the root cause. In this regard, University X must have a Disaster Recovery Plan (DRP) to guide risk management implementation. This research used qualitative methods, a combination of case study methods, and action research. Data collection was carried out by interviews with the university's management, literature study, documentation, and observation of business processes of IS\/IT assets and data center. The DRP document was designed based on NIST SP 800-34 Rev.1. The stages of this research consisted of the analysis of business processes, identification of IS\/IT assets, policymaking of an IS\/IT disaster recovery plan, business impact analysis, prevention control analysis on data center based on ANSI \/ TIA 942-A, and designing DRP documents. The validation process of the DRP document involved the management of DIST. This research delivered a DRP document draft that suits University X's needs as a state university in Indonesia. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "University X is a state university in Indonesia that can independently manage its assets. In carrying out its business processes, University X uses many information systems managed by the Directorate of Information Systems and Technology (DIST). The management of IS\/IT at the State University has not yet reached risk management implementation under IT governance. This research criticized the absence of an IS\/IT recovery plan as the root cause. In this regard, University X must have a Disaster Recovery Plan (DRP) to guide risk management implementation. This research used qualitative methods, a combination of case study methods, and action research. Data collection was carried out by interviews with the university's management, literature study, documentation, and observation of business processes of IS\/IT assets and data center. The DRP document was designed based on NIST SP 800-34 Rev.1. The stages of this research consisted of the analysis of business processes, identification of IS\/IT assets, policymaking of an IS\/IT disaster recovery plan, business impact analysis, prevention control analysis on data center based on ANSI \/ TIA 942-A, and designing DRP documents. The validation process of the DRP document involved the management of DIST. This research delivered a DRP document draft that suits University X's needs as a state university in Indonesia. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "An efficient implementation of NTRU encryption in post-quantum internet of things"
        ],
        "penulis":"Agus Y.M.;Murti M.A.;Kurniawan F.;Cahyani N.D.W.;Satrya G.B.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The Internet of Things (IoT) or the Internet of Everything (IoE) goes even further beyond, not only it affects the way of exchanging data but also touches the physical lives. On the other side, security challenges of end-to-end device communication need to be addressed i.e., compliance & regulation, protocols, remediation, impacts & risks, threat diversities, and new applications. This research demonstrates impacts, risks, and threat diversities on IoT devices that use either conventional cryptography or post-quantum cryptography. This research also provides proof of concepts of security infrastructure for end-to-end communication among the IoT devices. Moreover, this research proposes and implements lightweight post-quantum cryptography for communication between the publisher to the subscriber in Raspberry Pi3 B+ e.g., Nthdegree Truncated Polynomial Ring (NTRU) lattice-based cryptography. The experimentation compares NTRU with AES, Fernet, and RSA respectively on encryption time analysis, decryption time analysis, and network layer analysis. The results suggest some critical points that should be considered for the future development of smart homes, smart factories, smart cities, smart health, etc. \u00a9 2020 IEEE",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Internet of Things (IoT) or the Internet of Everything (IoE) goes even further beyond, not only it affects the way of exchanging data but also touches the physical lives. On the other side, security challenges of end-to-end device communication need to be addressed i.e., compliance & regulation, protocols, remediation, impacts & risks, threat diversities, and new applications. This research demonstrates impacts, risks, and threat diversities on IoT devices that use either conventional cryptography or post-quantum cryptography. This research also provides proof of concepts of security infrastructure for end-to-end communication among the IoT devices. Moreover, this research proposes and implements lightweight post-quantum cryptography for communication between the publisher to the subscriber in Raspberry Pi3 B+ e.g., Nthdegree Truncated Polynomial Ring (NTRU) lattice-based cryptography. The experimentation compares NTRU with AES, Fernet, and RSA respectively on encryption time analysis, decryption time analysis, and network layer analysis. The results suggest some critical points that should be considered for the future development of smart homes, smart factories, smart cities, smart health, etc. \u00a9 2020 IEEE"
        ]
    },
    {
        "judul":[
            "Prediction of Gross Domestic Product (GDP) in Indonesia Using Deep Learning Algorithm"
        ],
        "penulis":"Sa'adah, Siti;Wibowo, Muhammad Satrio;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Growth Domestic Product (GDP) is the important factor to know the stability of financial condition in a country. Regarding into GDP value could be known the economic condition per capita. Especially, during this pandemic situation, GDP need study further about its sudden fluctuation. The solution can be covered using the prediction approach. Deep learning as new method from machine learning schema had been observed in this research to cope the prediction of GDP problem. Two methods of deep learning techniques that were used, LSTM and RNN, shown that the prediction could fit the data actual very well. The accuracy at around 80% until 90% emerge from LSTM architecture 2 and RNN architecture 2. Based on this result, it could bring new perspective to use this model to know the GDP fluctuation in a country even in catastrophe of Covid-19.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Growth Domestic Product (GDP) is the important factor to know the stability of financial condition in a country. Regarding into GDP value could be known the economic condition per capita. Especially, during this pandemic situation, GDP need study further about its sudden fluctuation. The solution can be covered using the prediction approach. Deep learning as new method from machine learning schema had been observed in this research to cope the prediction of GDP problem. Two methods of deep learning techniques that were used, LSTM and RNN, shown that the prediction could fit the data actual very well. The accuracy at around 80% until 90% emerge from LSTM architecture 2 and RNN architecture 2. Based on this result, it could bring new perspective to use this model to know the GDP fluctuation in a country even in catastrophe of Covid-19.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Extraction Dependency Based on Evolutionary Requirement Using Natural Language Processing"
        ],
        "penulis":"Asyrofi, Rakha;Siahaan, Daniel Oranova;Priyadi, Yudi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Changes in requirements are one of the critical problems that occur during requirement specification. A change in a requirement could trigger changes in other requirements. Thus the identification process requirement to respond and correct the truth, realistic, require, specific, measurable aspects. Previous work has focused on building a model of interdependency between the requirements. This study proposes a method to identify dependencies among requirements. The dependency relations refer to evolutionary requirements. The technique uses natural language processing to extract dependency relations. This research analyzes how to obtain feature extractions by including the following: 1) Gathering requirements statement from the SRS document, 2) Identifying dependencies between requirements, 3) Developing interdependency extraction methods and, 4) Modeling of the interdependency requirement. The expectation of this experiment indicates the interdependency graph model. This graph defines the interdependency in the (Software Requirement Specification) SRS document. This method gathers interdependency between SRS document requirements such as PART OF, AND, OR, XOR. Therefore, getting the feature extraction to identify the interdependency requirement will be useful for solving specified requirements changing.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Changes in requirements are one of the critical problems that occur during requirement specification. A change in a requirement could trigger changes in other requirements. Thus the identification process requirement to respond and correct the truth, realistic, require, specific, measurable aspects. Previous work has focused on building a model of interdependency between the requirements. This study proposes a method to identify dependencies among requirements. The dependency relations refer to evolutionary requirements. The technique uses natural language processing to extract dependency relations. This research analyzes how to obtain feature extractions by including the following: 1) Gathering requirements statement from the SRS document, 2) Identifying dependencies between requirements, 3) Developing interdependency extraction methods and, 4) Modeling of the interdependency requirement. The expectation of this experiment indicates the interdependency graph model. This graph defines the interdependency in the (Software Requirement Specification) SRS document. This method gathers interdependency between SRS document requirements such as PART OF, AND, OR, XOR. Therefore, getting the feature extraction to identify the interdependency requirement will be useful for solving specified requirements changing.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Household energy usage pattern in 2200 VA"
        ],
        "penulis":"Abdurohman K.O.;Ekaputri C.;Aprillia B.S.;Nurfaidah Y.;Reza M.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Household energy usage is important for us to know because we can use the data for energy saving and prototyping solar system installation. We could see what the maximum usage is and reduce it. In this research, power data logger is made to see the total energy usage and will get result discrete graph. The result for household energy usage for 2200 VA will get 9,82kWh\/day. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Household energy usage is important for us to know because we can use the data for energy saving and prototyping solar system installation. We could see what the maximum usage is and reduce it. In this research, power data logger is made to see the total energy usage and will get result discrete graph. The result for household energy usage for 2200 VA will get 9,82kWh\/day. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Passive node-assisted wireless networks forming raptor codes with random access"
        ],
        "penulis":"Hendraningrat, Denny Kusuma;Ramatryana, I. Nyoman Apraz;Narottama, Bhaskara;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, wireless networks with passive nodes forming a pre-code of Raptor codes, also known as Raptor code-structured wireless networks (RCS-WN), are considered. In RCS-WN, the passive nodes utilize a decode-and-forward (DF) scheme and send the decoded data to the destination by using a scheduling scheme. We propose to deploy random access (RA) in passive nodes, to achieve a solution referred to as an RA-based RCS-WN (RAR-WN), and attempt to compare it with conventional wireless networks applying irregular repetition slotted ALOHA (IRSA). We investigate regular and irregular degree distributions for repetition codes to test the capacity of the proposed RAR-WN, using the extrinsic information transfer (EXIT) chart. This paper also examines the capabilities of the stopping set (both with regular and irregular degree distribution) in RAR-WN. Performance of the proposed system is evaluated in terms of EXIT chart, packet loss rate (PLR), and throughput. The results show that the proposed system is capable of achieving non-dropped throughput performance. \u00a9 2020 National Institute of Telecommunications. All rights reserved.",
            "ONHOOView detailsExpand Substance 1,3-benzoxazine-2,4-dione",
            "Powered by"
        ],
        "abstrak":[
            "In this paper, wireless networks with passive nodes forming a pre-code of Raptor codes, also known as Raptor code-structured wireless networks (RCS-WN), are considered. In RCS-WN, the passive nodes utilize a decode-and-forward (DF) scheme and send the decoded data to the destination by using a scheduling scheme. We propose to deploy random access (RA) in passive nodes, to achieve a solution referred to as an RA-based RCS-WN (RAR-WN), and attempt to compare it with conventional wireless networks applying irregular repetition slotted ALOHA (IRSA). We investigate regular and irregular degree distributions for repetition codes to test the capacity of the proposed RAR-WN, using the extrinsic information transfer (EXIT) chart. This paper also examines the capabilities of the stopping set (both with regular and irregular degree distribution) in RAR-WN. Performance of the proposed system is evaluated in terms of EXIT chart, packet loss rate (PLR), and throughput. The results show that the proposed system is capable of achieving non-dropped throughput performance. \u00a9 2020 National Institute of Telecommunications. All rights reserved."
        ]
    },
    {
        "judul":[
            "Waiting Time Estimation of Hydrogen-Fuel Vehicles with YOLO Real-Time Object Detection"
        ],
        "penulis":"Fikri, Rifqi Muhammad;Kim, Byungwook;Hwang, Mintae;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Widespread use of fossil fuels as a source of energy leads to automobile emissions of CO2and other greenhouse gases (GHG) that plays a significant role in environmental pollution. A transition from fossil fuel to cleaner and more energy-efficient alternative fuel vehicles such as hydrogen fuel cell vehicles (FCVs), is a vital step in reducing the automobile emission. However, the insufficient charging stations and the long charging time compared to the conventional vehicles have to be overcome before hydrogen fuel-based vehicles can be fully adopted on a mass scale. This paper proposes a method that can count the approximate waiting time by using YOLO real-time object detection to detect how many hydrogen fuel-based vehicles are charging or queueing in the charging station. Therefore, the driver can choose the charging station that has minimal waiting time so that the insufficient charging stations and the long charging time can be managed. \u00a9 Springer Nature Singapore Pte Ltd 2020.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Widespread use of fossil fuels as a source of energy leads to automobile emissions of CO2and other greenhouse gases (GHG) that plays a significant role in environmental pollution. A transition from fossil fuel to cleaner and more energy-efficient alternative fuel vehicles such as hydrogen fuel cell vehicles (FCVs), is a vital step in reducing the automobile emission. However, the insufficient charging stations and the long charging time compared to the conventional vehicles have to be overcome before hydrogen fuel-based vehicles can be fully adopted on a mass scale. This paper proposes a method that can count the approximate waiting time by using YOLO real-time object detection to detect how many hydrogen fuel-based vehicles are charging or queueing in the charging station. Therefore, the driver can choose the charging station that has minimal waiting time so that the insufficient charging stations and the long charging time can be managed. \u00a9 Springer Nature Singapore Pte Ltd 2020."
        ]
    },
    {
        "judul":[
            "Recycling of Pineapple (Ananas comosus) Leaf Agro-waste as One of the Raw Materials for Production of Eco-friendly New Paper"
        ],
        "penulis":"Teo, Pao Ter;Zakaria, Siti Koriah;Azhar Taib, Mustaffa Ali;Budiman, Faisal;Mohamed, Mazlan;Yusoff, Abdul Hafidz;Ahmad Sobri, Sharizal;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This project aimed to recycle pineapple (Ananas comosus) leaf agro-waste and wastepaper into new paper using simple processing routes that involve pulping, mixing, sieving, compaction and drying. Subsequently, physical and mechanical properties, as well as the morphology of the pineapple leaf fiber (PALF)-based paper were investigated accordingly. Two different samples were prepared whereby the first sample is pineapple leaf fiber mixed with wastepaper, and another sample is pure pineapple leaf fiber paper. The samples were tested for tensile properties by using the universal testing machine, morphological analysis using scanning electron microscopy, and density measurement using a densitometer. It was found that the sample consist of pineapple leaf and wastepaper shows a higher tensile strength than the sample containing only PALF. Moreover, the density of paper with pineapple leaf fiber and wastepaper mix was higher than the paper with only pineapple leaf fiber. In the future, further modification of body formulation is necessary to further improve the properties of the pineapple leaf fiber-based paper. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This project aimed to recycle pineapple (Ananas comosus) leaf agro-waste and wastepaper into new paper using simple processing routes that involve pulping, mixing, sieving, compaction and drying. Subsequently, physical and mechanical properties, as well as the morphology of the pineapple leaf fiber (PALF)-based paper were investigated accordingly. Two different samples were prepared whereby the first sample is pineapple leaf fiber mixed with wastepaper, and another sample is pure pineapple leaf fiber paper. The samples were tested for tensile properties by using the universal testing machine, morphological analysis using scanning electron microscopy, and density measurement using a densitometer. It was found that the sample consist of pineapple leaf and wastepaper shows a higher tensile strength than the sample containing only PALF. Moreover, the density of paper with pineapple leaf fiber and wastepaper mix was higher than the paper with only pineapple leaf fiber. In the future, further modification of body formulation is necessary to further improve the properties of the pineapple leaf fiber-based paper. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Developing an LSTM-based Classification Model of IndiHome Customer Feedbacks"
        ],
        "penulis":"Arifianto, Anditya;Suyanto, Suyanto;Sirwan, Anis;Desrul, Dhamir Raniah Kiasati;Prakoso, Irfan D.;Guntara, Fedy Fahron;Hidayati, Dian Chusnul;Murti, Rani Sari;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The development of companies in the service sector is inseparable from problems with the customer service process. The latest trends show that customers are more comfortable using social media and chat services as feedback delivery media compared to sending emails. In this study, we classify user feedback from an Internet Service Provider (ISP) in Indonesia named IndiHome. In this study, there are two test scenarios carried out to classify, the first scenario uses Short Term Memory combined with Word Embedding, and the second scenario uses Naive Bayes combined with TF-IDF. based on the test results, obtained accuracy on the LSTM method combined with Word Embedding with an f1 score of 87.98 % and accuracy obtained at Naive Bayes combined with TF-IDF with an f1 score of 76.77 %. From the tests that have been done, different results are obtained and have a big difference, which is 11.21%. The difference in the results of this classification is influenced by several factors, namely the first factor is the extraction of features used and the second is the data used. In feature selection, TF-IDF is more ideal for data that has a large or long document size because the representation seen from the whole document, in contrast to Word Embedding that is not affected by the data size because the representation is seen from words. so this is what causes the method of using LSTM combined with Word Embedding to produce higher results.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of companies in the service sector is inseparable from problems with the customer service process. The latest trends show that customers are more comfortable using social media and chat services as feedback delivery media compared to sending emails. In this study, we classify user feedback from an Internet Service Provider (ISP) in Indonesia named IndiHome. In this study, there are two test scenarios carried out to classify, the first scenario uses Short Term Memory combined with Word Embedding, and the second scenario uses Naive Bayes combined with TF-IDF. based on the test results, obtained accuracy on the LSTM method combined with Word Embedding with an f1 score of 87.98 % and accuracy obtained at Naive Bayes combined with TF-IDF with an f1 score of 76.77 %. From the tests that have been done, different results are obtained and have a big difference, which is 11.21%. The difference in the results of this classification is influenced by several factors, namely the first factor is the extraction of features used and the second is the data used. In feature selection, TF-IDF is more ideal for data that has a large or long document size because the representation seen from the whole document, in contrast to Word Embedding that is not affected by the data size because the representation is seen from words. so this is what causes the method of using LSTM combined with Word Embedding to produce higher results.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Designing IT Service Management at Indonesia Internet Domain Names Registry Association's Helpdesk Function"
        ],
        "penulis":"Hermita, Evelyn Sevina;Sucahyo, Yudho Giri;Gandhi, Arfive;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia Internet Domain Names Registry Association (PANDI) hosts helpdesk function as a part of .id domain management. It is a one-stop facility for all registrants and the public to submit questions and complaints regarding .id domain names. Previously, helpdesk function had poor performance since its business processes were manual and slow. This research aimed to design Information Technology Service Management (ITSM) implementation as guidelines for PANDI helpdesk. It demonstrated case study research using qualitative approach by involving helpdesk officers, and c-level in depth interview. This research relied on ITIL V3 2011 framework to generate ITSM design: service catalog, Service Level Agreement, and Standard Operating Procedures. It resulted in tracking status, priority label, reporting feature, and service categories can be added on the application side. Those artifacts guided helpdesk to improve the quality of services provided by PANDI. They consisted of a service catalog that includes 11 Customer Facing Service (CFS) and Resource Facing Service (RFS), five SLAs for helpdesk business process services, and three SOPs for account changes request service.  \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia Internet Domain Names Registry Association (PANDI) hosts helpdesk function as a part of .id domain management. It is a one-stop facility for all registrants and the public to submit questions and complaints regarding .id domain names. Previously, helpdesk function had poor performance since its business processes were manual and slow. This research aimed to design Information Technology Service Management (ITSM) implementation as guidelines for PANDI helpdesk. It demonstrated case study research using qualitative approach by involving helpdesk officers, and c-level in depth interview. This research relied on ITIL V3 2011 framework to generate ITSM design: service catalog, Service Level Agreement, and Standard Operating Procedures. It resulted in tracking status, priority label, reporting feature, and service categories can be added on the application side. Those artifacts guided helpdesk to improve the quality of services provided by PANDI. They consisted of a service catalog that includes 11 Customer Facing Service (CFS) and Resource Facing Service (RFS), five SLAs for helpdesk business process services, and three SOPs for account changes request service.  \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "The Prototype of In-Store Visitor and People Passing Counters using Single Shot Detector Performed by OpenCV"
        ],
        "penulis":"Herviana, Andes;Sudiharto, Dodi Wisaksono;Yulianto, Fazmah Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information related to the power hours of a mall or store is important. By typically knowing it, the manager of the store or the mall can wisely determine the staff planning decision. Without the right decision, it potentially decreases customer satisfaction. The decision can be defined by utilizing in-store visitors and people passing traffic patterns. The other problem also arises when the calculation of in-store visitors and people passing are executed manually, so it requires much effort. This study proposes a prototype design of the system which can automatically calculate visitors by utilizing Single Shot Detector (SSD) method. This method is performed by operating OpenCV library. It is used to detect a human object marked as in-store visitor or people passing. The embedded computer is conducted to process images captured by Pi Camera. Based on the study, the result accuracy is 65.08% for the system counts in-store visitors, and 66.12% for the system marks objects as people pass around in front of the store. Although the accuracy values obtained is not high, but all patterns show that the highest average values of in-store visitors and people passing occur on the days nearing weekend and also on the weekend, such as Friday, Saturday and Sunday. The peak time of in-store visitors (e.g. power hour) on Friday is between 12 PM and 1 PM. The peak time of in-store visitors on Saturday is between 3 PM and 4 PM, and on Monday, it is between 4 PM and 5 PM.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information related to the power hours of a mall or store is important. By typically knowing it, the manager of the store or the mall can wisely determine the staff planning decision. Without the right decision, it potentially decreases customer satisfaction. The decision can be defined by utilizing in-store visitors and people passing traffic patterns. The other problem also arises when the calculation of in-store visitors and people passing are executed manually, so it requires much effort. This study proposes a prototype design of the system which can automatically calculate visitors by utilizing Single Shot Detector (SSD) method. This method is performed by operating OpenCV library. It is used to detect a human object marked as in-store visitor or people passing. The embedded computer is conducted to process images captured by Pi Camera. Based on the study, the result accuracy is 65.08% for the system counts in-store visitors, and 66.12% for the system marks objects as people pass around in front of the store. Although the accuracy values obtained is not high, but all patterns show that the highest average values of in-store visitors and people passing occur on the days nearing weekend and also on the weekend, such as Friday, Saturday and Sunday. The peak time of in-store visitors (e.g. power hour) on Friday is between 12 PM and 1 PM. The peak time of in-store visitors on Saturday is between 3 PM and 4 PM, and on Monday, it is between 4 PM and 5 PM.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The effectiveness of online calculus 2 learning during the Covid-19 pandemic"
        ],
        "penulis":"Susilawati T.;Darmawan I.;Desiasni R.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study aims to analyze the effectiveness of online learning in calculus 2 during the Covid-19 pandemic. The study was conducted in a civil engineering study program at a private tertiary institution on Sumbawa Island. This research is a quasi-experimental research design model non-equivalent control group design. The number of subjects in this study was 71 people. Data analysis used a paired sample t-test analysis with the help of SPSS software. Based on the results of data analysis, online learning is not effective in calculus 2 subjects in the pandemic covid-19 period, there is a significant relationship between conventional learning and online learning and there is a significant difference between conventional learning and online learning. The average value of student learning outcomes is decreased when the online learning system is applied. From these results it can be concluded the online learning system in the 2nd calculus course during the Covid-19 pandemic has not been effective. \u00a9 2020 Institute of Physics Publishing. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Quality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to analyze the effectiveness of online learning in calculus 2 during the Covid-19 pandemic. The study was conducted in a civil engineering study program at a private tertiary institution on Sumbawa Island. This research is a quasi-experimental research design model non-equivalent control group design. The number of subjects in this study was 71 people. Data analysis used a paired sample t-test analysis with the help of SPSS software. Based on the results of data analysis, online learning is not effective in calculus 2 subjects in the pandemic covid-19 period, there is a significant relationship between conventional learning and online learning and there is a significant difference between conventional learning and online learning. The average value of student learning outcomes is decreased when the online learning system is applied. From these results it can be concluded the online learning system in the 2nd calculus course during the Covid-19 pandemic has not been effective. \u00a9 2020 Institute of Physics Publishing. All rights reserved."
        ]
    },
    {
        "judul":[
            "Measurement of Criterion Weight to Determine Industrial Area Location Using AHP for Economic Growth"
        ],
        "penulis":"Chumaidiyah E.;Dewantoro M.D.R.;Hakimah D.A.;Arffan Z.;Robbi R.M.N.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Industrial area is an infrastructure for the process of industrialization as a source that can trigger economic growth. Industrial areas that are structured and can support production operations are an appeal to foreign investors. However, the development of industrial areas requires careful planning because it impacts on the environmental carrying capacity and land loss. Therefore, industrial area development needs attention to a variety of important criteria as considerations in determining the location of an industrial area. This study aims to determine the criteria and measure the importance of each relative criterion to other criteria. The method used is Analytical Hierarchy Process (AHP). The results show that there are four important factors that need to be considered with each of the importance level, namely Infrastructure by 33.97%, Distance to Access by 31.74%, Land Soil by 19.57%, and Production Factors by 14.72%. The four factors have ten important criteria that need to be considered in making decisions to determine the location of an industrial area where the two highest criteria are electricity infrastructure with a significance level of 19.05% and telecommunications infrastructure with an importance level of 14.92%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industrial area is an infrastructure for the process of industrialization as a source that can trigger economic growth. Industrial areas that are structured and can support production operations are an appeal to foreign investors. However, the development of industrial areas requires careful planning because it impacts on the environmental carrying capacity and land loss. Therefore, industrial area development needs attention to a variety of important criteria as considerations in determining the location of an industrial area. This study aims to determine the criteria and measure the importance of each relative criterion to other criteria. The method used is Analytical Hierarchy Process (AHP). The results show that there are four important factors that need to be considered with each of the importance level, namely Infrastructure by 33.97%, Distance to Access by 31.74%, Land Soil by 19.57%, and Production Factors by 14.72%. The four factors have ten important criteria that need to be considered in making decisions to determine the location of an industrial area where the two highest criteria are electricity infrastructure with a significance level of 19.05% and telecommunications infrastructure with an importance level of 14.92%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Analysis of IEEE 802.11p MAC Protocol for Safety Message Broadcast in V2V Communication"
        ],
        "penulis":"Bin Ali Wael, Chaeriah;Armi, Nasrullah;Mitayani, Arumjeni;Kurniawan, Dayat;Suryadi Satyawan, Arief;Subekti, Agus;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "V2X communication technology is expected to improve road safety and optimize transportation efficiency. Safety message broadcasting is in need of high reliability and requires real-time communications between vehicles under adverse environments. In this study, we evaluate IEEE 802.11p MAC protocol performance in terms of packet delivery ratio (PDR), by means of simulation and analysis. Analytical expression of PDR is derived for packets with exponential and deterministic inter-arrival time by taking hidden terminal problem into account as the major cause of performance degradation. Furthermore, the effects of various data rate, packet arrival rate, and packet size towards PDR performance are evaluated. Numerical and simulation results show how packet delivery ratio (PDR) drops dramatically in cases with hidden problem nodes. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "V2X communication technology is expected to improve road safety and optimize transportation efficiency. Safety message broadcasting is in need of high reliability and requires real-time communications between vehicles under adverse environments. In this study, we evaluate IEEE 802.11p MAC protocol performance in terms of packet delivery ratio (PDR), by means of simulation and analysis. Analytical expression of PDR is derived for packets with exponential and deterministic inter-arrival time by taking hidden terminal problem into account as the major cause of performance degradation. Furthermore, the effects of various data rate, packet arrival rate, and packet size towards PDR performance are evaluated. Numerical and simulation results show how packet delivery ratio (PDR) drops dramatically in cases with hidden problem nodes. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Asymmetric impact of textile and clothing manufacturing on carbon-dioxide emissions: Evidence from top Asian economies"
        ],
        "penulis":"Haseeb, Muhammad;Haouas, Ilham;Nasih, Mohammad;Mihardjo, Leonardus WW.;Jermsittiparsert, Kittisak;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The aim of the current investigation is to analyze the impact of textile and clothing (T&C) manufacturing on carbon dioxide emission (CO2) in top Asian economies. In doing so, the study has utilized the quarterly data of percentage of manufacturing covered by T&C sector and CO2per capita from the period of 1990\u20132018. The empirical investigation is carried out by applying the innovative Quantile-on-Quantile (QQ) regression and Granger causality in quantile methods. The findings of the study have identified the significant asymmetric behavior in the quantiles of T&C industry on the quantiles of CO2emission in the considered economies. Precisely, the outcomes have documented the significant positive contribution of T&C manufacturing on CO2emission in China, India, Pakistan, and Indonesia. On the other hand, the effect of T&C on CO2emission is negative in the case of Vietnam. As for causal relationships, the study also confirmed the presence of bi-directional causality between T&C and CO2emission in all countries except Indonesia, where the relationship is uni-directional. The study recommended regulators to introduce some incentives and subsidies for the new investors in T&C industry with higher emphasis on green manufacturing. \u00a9 2020 Elsevier Ltd",
            "OOView detailsExpand Substance carbon dioxideNSOH3CView detailsExpand Substance Molinate",
            "Powered by",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aim of the current investigation is to analyze the impact of textile and clothing (T&C) manufacturing on carbon dioxide emission (CO2) in top Asian economies. In doing so, the study has utilized the quarterly data of percentage of manufacturing covered by T&C sector and CO2per capita from the period of 1990\u20132018. The empirical investigation is carried out by applying the innovative Quantile-on-Quantile (QQ) regression and Granger causality in quantile methods. The findings of the study have identified the significant asymmetric behavior in the quantiles of T&C industry on the quantiles of CO2emission in the considered economies. Precisely, the outcomes have documented the significant positive contribution of T&C manufacturing on CO2emission in China, India, Pakistan, and Indonesia. On the other hand, the effect of T&C on CO2emission is negative in the case of Vietnam. As for causal relationships, the study also confirmed the presence of bi-directional causality between T&C and CO2emission in all countries except Indonesia, where the relationship is uni-directional. The study recommended regulators to introduce some incentives and subsidies for the new investors in T&C industry with higher emphasis on green manufacturing. \u00a9 2020 Elsevier Ltd"
        ]
    },
    {
        "judul":[
            "Modeling Traffic Flow on Buah Batu Exit Toll Gate Using Cellular Automata"
        ],
        "penulis":"Ketaren, Raymondo Fitrah;Danufane, Fadil Habibi;Kurniawan, Isman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the last decade, Bandung has become one of the tourism destination places in Indonesia. It is reported that almost 6.7 million visitors come to Bandung in 2018, and the number increased by almost 4% per year since 2014. This rise in the number of visitors leads to the establishment of several toll gates as main access points throughout the city. As one of the busiest ones, Buah Batu toll gate is frequently congested because of the location that is close to the southern part of Bandung. To overcome this problem, a traffic regulation based on computer simulation is urgently required. In this study, we simulate the traffic system on the Buah Batu toll gate by using a combination of Nagel-Schreckenberg (NaSch) and Daoudia and Moussa (DM) models. NaSch model was used to defined vehicle movement, while the DM model was used to allow a vehicle to change lane. We defined three scenarios to evaluate the effectivity of the closing gate scheme. We found that the closing of gate 5 is more effective than the closing of gate 1. We also investigated the contribution of traffic density and driver's behavior, e.g., stopping behavior and lane-changing behavior, to the average velocity of the vehicles.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the last decade, Bandung has become one of the tourism destination places in Indonesia. It is reported that almost 6.7 million visitors come to Bandung in 2018, and the number increased by almost 4% per year since 2014. This rise in the number of visitors leads to the establishment of several toll gates as main access points throughout the city. As one of the busiest ones, Buah Batu toll gate is frequently congested because of the location that is close to the southern part of Bandung. To overcome this problem, a traffic regulation based on computer simulation is urgently required. In this study, we simulate the traffic system on the Buah Batu toll gate by using a combination of Nagel-Schreckenberg (NaSch) and Daoudia and Moussa (DM) models. NaSch model was used to defined vehicle movement, while the DM model was used to allow a vehicle to change lane. We defined three scenarios to evaluate the effectivity of the closing gate scheme. We found that the closing of gate 5 is more effective than the closing of gate 1. We also investigated the contribution of traffic density and driver's behavior, e.g., stopping behavior and lane-changing behavior, to the average velocity of the vehicles.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Hand gesture recognition using discrete wavelet transform and hidden Markov models"
        ],
        "penulis":"Candrasari, Erizka Banuwati;Novamizanti, Ledya;Aulia, Suci;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Gesture recognition based on computer-vision is an important part of human-computer interaction. But it lacks in several points, that was image brightness, recognition time, and accuracy. Because of that goal of this research was to create a hand gesture recognition system that had good performances using discrete wavelet transform and hidden Markov models. The first process was pre-processing, which done by resizing the image to 128x128 pixels and then segmented the skin color. The second process was feature extraction using the discrete wavelet transform. The result was the feature value in the form of a feature vector from the image. The last process was gesture classification using hidden Markov models to calculate the highest probability of feature matrix which had obtained from the feature extraction process. The result of the system had 72% of accuracy using 150 training and 100 test data images that consist five gestures. The newness thing found in this experiment were the effect of acquisition and pre-processing. The accuracy had been escalated by 14% compared to Sebastien's dataset at 58%. The increment effect propped by brightness and contrast value. \u00a9 2020, Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Gesture recognition based on computer-vision is an important part of human-computer interaction. But it lacks in several points, that was image brightness, recognition time, and accuracy. Because of that goal of this research was to create a hand gesture recognition system that had good performances using discrete wavelet transform and hidden Markov models. The first process was pre-processing, which done by resizing the image to 128x128 pixels and then segmented the skin color. The second process was feature extraction using the discrete wavelet transform. The result was the feature value in the form of a feature vector from the image. The last process was gesture classification using hidden Markov models to calculate the highest probability of feature matrix which had obtained from the feature extraction process. The result of the system had 72% of accuracy using 150 training and 100 test data images that consist five gestures. The newness thing found in this experiment were the effect of acquisition and pre-processing. The accuracy had been escalated by 14% compared to Sebastien's dataset at 58%. The increment effect propped by brightness and contrast value. \u00a9 2020, Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Correspondence between bats population and terrestrial cave-dwelling arthropods community in tasikmalaya karst area"
        ],
        "penulis":"Kurniawan, Isma Dwi;Rahmadi, Cahyo;Caraka, Rezzy Eko;Rahman, Iman Aulia;Kinasih, Ida;Toharudin, Toni;Chen, Rung Ching;Lee, Youngjo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Trogloxenes particularly bats play an important role in subterranean habitat. They provide organic material and induce cave microclimate that influence cave-dwelling biota, including arthropods. This study aimed to learn how bats population influences cave-dwelling arthropods community. Data collections were performed in three caves which had different bats species in Tasikmalaya karst area namely Liang Boeh, Liang Seungit and Sarongge. We recorded bats population, guano production, physicochemical condition of caves passage, and arthropods community in each cave. All samplings were only conducted in the specific sites of the dark zone where bat populations were aggregated. Data indicated that Liang Boeh was inhibited by Hipposideros sp (\u00b1472 individuals), Liang Seungit by Pteripodidae and Miniopterus sp. (\u00b1188 individuals), and Sarongge by Rhinolophus sp. (\u00b11194 individuals). Guano production was positively correlated with bats population. Chemical compositions of soil were varying among bats species. Bats population strongly induced caves physicochemical condition. A total 15986 individuals of cave-dwelling arthropods belonging to 5 Classes and 18 Orders were recorded. Our result revealed that bats population determined arthropods community. Caves with greater bats population size and dominated by insectivorous species would potentially have greater diversity and abundance of cave-dwelling arthropods. \u00a9 2020 the author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Trogloxenes particularly bats play an important role in subterranean habitat. They provide organic material and induce cave microclimate that influence cave-dwelling biota, including arthropods. This study aimed to learn how bats population influences cave-dwelling arthropods community. Data collections were performed in three caves which had different bats species in Tasikmalaya karst area namely Liang Boeh, Liang Seungit and Sarongge. We recorded bats population, guano production, physicochemical condition of caves passage, and arthropods community in each cave. All samplings were only conducted in the specific sites of the dark zone where bat populations were aggregated. Data indicated that Liang Boeh was inhibited by Hipposideros sp (\u00b1472 individuals), Liang Seungit by Pteripodidae and Miniopterus sp. (\u00b1188 individuals), and Sarongge by Rhinolophus sp. (\u00b11194 individuals). Guano production was positively correlated with bats population. Chemical compositions of soil were varying among bats species. Bats population strongly induced caves physicochemical condition. A total 15986 individuals of cave-dwelling arthropods belonging to 5 Classes and 18 Orders were recorded. Our result revealed that bats population determined arthropods community. Caves with greater bats population size and dominated by insectivorous species would potentially have greater diversity and abundance of cave-dwelling arthropods. \u00a9 2020 the author(s)."
        ]
    },
    {
        "judul":[
            "Exploration-Exploitation Balanced Krill Herd Algorithm for Thesis Examination Timetabling"
        ],
        "penulis":"Tawakkal, M. Iqbal;Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The thesis examination is one of the many events that matter to student graduation. Making a schedule for the session by the coordinator at a related instance is time-consuming. Besides, the balance between intensiveness and fairness should be one concern so that examiners do not have a tight schedule, but the total duration does not take too long. A Krill Herd (KH) algorithm, one of the nature-inspired algorithms, is examined. The basic KH is used for local search. Both genetic operators and elitism are added to balance its explorative-exploitative movements of krill individuals to find the global solution. The explorative movement randomly searches the global solution in all directions, while the exploitative movement just finds it in a potential area. A dataset collected from the Faculty of Informatics, Telkom University in 2017-2018, which contains 25 students and 110 lecturers, is used to evaluate the model. By carefully tuning two parameters, the KH-based model produces a schedule with a few violated constraints with the effectiveness of 92%, which can be acceptable to be used in the real application. This result shows that continuous-type of solving algorithms can solve the discrete-type problem with some adjustments. In the future, a procedure of premature convergence avoidance can be introduced to improve the model.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The thesis examination is one of the many events that matter to student graduation. Making a schedule for the session by the coordinator at a related instance is time-consuming. Besides, the balance between intensiveness and fairness should be one concern so that examiners do not have a tight schedule, but the total duration does not take too long. A Krill Herd (KH) algorithm, one of the nature-inspired algorithms, is examined. The basic KH is used for local search. Both genetic operators and elitism are added to balance its explorative-exploitative movements of krill individuals to find the global solution. The explorative movement randomly searches the global solution in all directions, while the exploitative movement just finds it in a potential area. A dataset collected from the Faculty of Informatics, Telkom University in 2017-2018, which contains 25 students and 110 lecturers, is used to evaluate the model. By carefully tuning two parameters, the KH-based model produces a schedule with a few violated constraints with the effectiveness of 92%, which can be acceptable to be used in the real application. This result shows that continuous-type of solving algorithms can solve the discrete-type problem with some adjustments. In the future, a procedure of premature convergence avoidance can be introduced to improve the model.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of USB Based Spying Method Using Arduino and Metasploit Framework in Windows Operating System"
        ],
        "penulis":"Ferryansa;Budiono, Avon;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The use of a very wide windows operating system is undeniably also followed by increasing attacks on the operating system. Universal Serial Bus (USB) is one of the mechanisms used by many people with plug and play functionality that is very easy to use, making data transfers fast and easy compared to other hardware. Some research shows that the Windows operating system has weaknesses so that it is often exploited by using various attacks and malware. There are various methods used to exploit the Windows operating system, one of them by using a USB device. By using a USB device, a criminal can plant a backdoor reverse shell to exploit the victim's computer just by connecting the USB device to the victim's computer without being noticed. This research was conducted by planting a reverse shell backdoor through a USB device to exploit the victim's device, especially the webcam and microphone device on the target computer. From 35 experiments that have been carried out, it was found that 83% of spying attacks using USB devices on the Windows operating system were successfully carried out.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of a very wide windows operating system is undeniably also followed by increasing attacks on the operating system. Universal Serial Bus (USB) is one of the mechanisms used by many people with plug and play functionality that is very easy to use, making data transfers fast and easy compared to other hardware. Some research shows that the Windows operating system has weaknesses so that it is often exploited by using various attacks and malware. There are various methods used to exploit the Windows operating system, one of them by using a USB device. By using a USB device, a criminal can plant a backdoor reverse shell to exploit the victim's computer just by connecting the USB device to the victim's computer without being noticed. This research was conducted by planting a reverse shell backdoor through a USB device to exploit the victim's device, especially the webcam and microphone device on the target computer. From 35 experiments that have been carried out, it was found that 83% of spying attacks using USB devices on the Windows operating system were successfully carried out.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design of River Monitoring Device with the Internet of Things Using LPWAN Based"
        ],
        "penulis":"Jumhana, Satria Ramadhan;Azmi, Fairuz;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays. The amount of development causes less air absorption. It was affected by floods. Flooding is a natural disaster that can damage significantly and harm many people. To minimize the impact of flooding, we need a system that can predict flood expenditure. It is necessary to design a tool to get data to predict the flooding of river water, air discharge, and rainfall.The sensor needed an ultrasonic sensor to measure the river water level and an independent variable to get the river air flow using Manning and a rain gauge sensor with a tipping bucket system to get high water level data. The course will be controlled using Arduino Uno and data sent to the Antares platform using the LoRa network. The power supply uses 2 lions of 3000Mah with each voltage with a total voltage of 8.4 V. The system will be at the river's edge with an ultrasonic sensor back to the riverbed and a rain gauge placed on the device.Based on the measurement results, all sensors run properly by the capabilities of each sensor. Ultrasonic sensors can measure a minimum of 2 cm and a maximum of 380 cm. Discharge measurements using Manning can be applied. The test results tested the 4.09 m of cistern water with river water discharge calculated using the Manning calculation of 51,539 m3\/sec and comparing with the BBWS (technical implementing unit in charge of water resources for river basins across provinces in Indonesia) measurement results of 51,087 m3\/sec. Error is valued at 1%, and the biggest error is valued at 13%. For the results of the rainfall sensor, one tip can be 1.27 mm. LoRa network performance for urban areas with a maximum mileage of 2 km is more than that of a 100% Loss package. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays. The amount of development causes less air absorption. It was affected by floods. Flooding is a natural disaster that can damage significantly and harm many people. To minimize the impact of flooding, we need a system that can predict flood expenditure. It is necessary to design a tool to get data to predict the flooding of river water, air discharge, and rainfall.The sensor needed an ultrasonic sensor to measure the river water level and an independent variable to get the river air flow using Manning and a rain gauge sensor with a tipping bucket system to get high water level data. The course will be controlled using Arduino Uno and data sent to the Antares platform using the LoRa network. The power supply uses 2 lions of 3000Mah with each voltage with a total voltage of 8.4 V. The system will be at the river's edge with an ultrasonic sensor back to the riverbed and a rain gauge placed on the device.Based on the measurement results, all sensors run properly by the capabilities of each sensor. Ultrasonic sensors can measure a minimum of 2 cm and a maximum of 380 cm. Discharge measurements using Manning can be applied. The test results tested the 4.09 m of cistern water with river water discharge calculated using the Manning calculation of 51,539 m3\/sec and comparing with the BBWS (technical implementing unit in charge of water resources for river basins across provinces in Indonesia) measurement results of 51,087 m3\/sec. Error is valued at 1%, and the biggest error is valued at 13%. For the results of the rainfall sensor, one tip can be 1.27 mm. LoRa network performance for urban areas with a maximum mileage of 2 km is more than that of a 100% Loss package. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Micro-Climate Control for Hydroponics in Greenhouses"
        ],
        "penulis":"Erfianto, Bayu;Rakhmatsyah, Andrian;Ariyanto, Endro;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Greenhouse is a building which one of them functions for cultivation. Greenhouse can help the plant growth process, but there can be differences climate that affect plant growth. By knowing the distribution of temperature and humidity, it can help the cultivation process. The next problem is how to control greenhouse conditions or commonly called micro-climate so that temperature and humidity can be maintained. To solve these problems, a system is used to determine the temperature and humidity distribution in a greenhouse and generate it in the form of a two-dimensional distribution map in the form of heatmap so that users can know the spread of temperature and humidity through the image. Based on temperature and humidity data can be used to control the micro-climate in a greenhouse so that the temperature and humidity of the greenhouse are maintained according to the needs of the plant. This system is built using a sprinkler to reduce the temperature and increase the humidity in the greenhouse, where the micro-climate control uses Fuzzy logic controller. The main results of this experiment are the temperature and humidity of the greenhouse can be controlled according to the needs of the plant.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Greenhouse is a building which one of them functions for cultivation. Greenhouse can help the plant growth process, but there can be differences climate that affect plant growth. By knowing the distribution of temperature and humidity, it can help the cultivation process. The next problem is how to control greenhouse conditions or commonly called micro-climate so that temperature and humidity can be maintained. To solve these problems, a system is used to determine the temperature and humidity distribution in a greenhouse and generate it in the form of a two-dimensional distribution map in the form of heatmap so that users can know the spread of temperature and humidity through the image. Based on temperature and humidity data can be used to control the micro-climate in a greenhouse so that the temperature and humidity of the greenhouse are maintained according to the needs of the plant. This system is built using a sprinkler to reduce the temperature and increase the humidity in the greenhouse, where the micro-climate control uses Fuzzy logic controller. The main results of this experiment are the temperature and humidity of the greenhouse can be controlled according to the needs of the plant.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Hate Speech Detection using Global Vector and Deep Belief Network Algorithm"
        ],
        "penulis":"Muhammad, Iqbal Zulfikar;Nasrun, Muhammad;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Hate speeches are words, behaviors, and actions prohibited because they lead to acts that trigger violence and anarchist attitudes towards other individuals or groups. Since the 2014 presidential election, the term 'hater' has been widely known, marking people with a tendency to practice speech utterances in certain people and groups. Thus, the internet's ethics need to be emphasized, considering that the internet is a necessity for today's society. Nevertheless, more and more users are also many parties who abuse the internet to spread information about speech utterances such as ethnicity, race, and religion. In this project, a system will be created to detect hate speech in the form of tweets on twitter. The author's method is the Deep Belief Network method by weighing the Global Vector feature to increase accuracy before classification. The making of this system is expected to be able to find out and detect hate speech from the text previously in the form of tweets. By using the Deep Belief Network method, the results of this study were obtained with an accuracy =86,00%, precision =82,00%, recall =89,13% and Fl-Score =85,42%. After doing this research, it is expected that the computer can find out and classify the existence of hate speech in the text. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hate speeches are words, behaviors, and actions prohibited because they lead to acts that trigger violence and anarchist attitudes towards other individuals or groups. Since the 2014 presidential election, the term 'hater' has been widely known, marking people with a tendency to practice speech utterances in certain people and groups. Thus, the internet's ethics need to be emphasized, considering that the internet is a necessity for today's society. Nevertheless, more and more users are also many parties who abuse the internet to spread information about speech utterances such as ethnicity, race, and religion. In this project, a system will be created to detect hate speech in the form of tweets on twitter. The author's method is the Deep Belief Network method by weighing the Global Vector feature to increase accuracy before classification. The making of this system is expected to be able to find out and detect hate speech from the text previously in the form of tweets. By using the Deep Belief Network method, the results of this study were obtained with an accuracy =86,00%, precision =82,00%, recall =89,13% and Fl-Score =85,42%. After doing this research, it is expected that the computer can find out and classify the existence of hate speech in the text. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Classification of Tomato Plants Diseases Using Convolutional Neural Network"
        ],
        "penulis":"Darma Putra, I Ketut Gede;Jayantha Putra, I Putu Deva;Fauzi, Rahmat;Witarsyah, Deden;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Tomato plants are many cultivated by farmers to get their fruit. Several obstacles in the cultivation process result in the process of producing products that require maximization. Constraints faced by farmers are diseases that attack plants. Farmers in dealing with the disease simply recognize the disease with their naked eyes and take action without knowing how to deal with it. Several approaches have been made in the recognition process that can be handled by using deep learning. The results shown using this process produce a good performance. Therefore, this paper has the aim of making and evaluating recognition of the diseases in plants seen on tomato leaves automatically using a deep learning approach. Convolutional Neural Network (CNN) is one of the deep learning methods used in handling object recognition processes. Recognition process tomato plants disease used a data set consisting of 6 different types of disease. Recognition process used 100 image data for each type of disease as training data, while as many as 60 image data are used as testing. This study used three different types of data sets that are used differently, consisting of original image RGB, blending images, and a mixture of RGB images and blending images. The classification results using a mixture of RGB images and blending images have a better performance than others by producing a Genuine Acceptance Rate (GAR) of 96.7% following by the percentage of False Acceptance Rate (FAR) values of 3.3% and False Rejection Rate (FRR) of 3.3%. \u00a9",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Tomato plants are many cultivated by farmers to get their fruit. Several obstacles in the cultivation process result in the process of producing products that require maximization. Constraints faced by farmers are diseases that attack plants. Farmers in dealing with the disease simply recognize the disease with their naked eyes and take action without knowing how to deal with it. Several approaches have been made in the recognition process that can be handled by using deep learning. The results shown using this process produce a good performance. Therefore, this paper has the aim of making and evaluating recognition of the diseases in plants seen on tomato leaves automatically using a deep learning approach. Convolutional Neural Network (CNN) is one of the deep learning methods used in handling object recognition processes. Recognition process tomato plants disease used a data set consisting of 6 different types of disease. Recognition process used 100 image data for each type of disease as training data, while as many as 60 image data are used as testing. This study used three different types of data sets that are used differently, consisting of original image RGB, blending images, and a mixture of RGB images and blending images. The classification results using a mixture of RGB images and blending images have a better performance than others by producing a Genuine Acceptance Rate (GAR) of 96.7% following by the percentage of False Acceptance Rate (FAR) values of 3.3% and False Rejection Rate (FRR) of 3.3%. \u00a9"
        ]
    },
    {
        "judul":[
            "Automatic whole-body bone scan image segmentation based on constrained local model"
        ],
        "penulis":"Rachmawati, Ema;Jondri;Ramadhani, Kurniawan Nur;Kartamihardja, Achmad Hussein Sundawa;Achmad, Arifudin;Shintawati, Rini;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In Indonesia, cancer is very burdensome financially for sufferers as well as for the country. Increasing the access to early detection of cancer can be a solution to prevent the situation from worsening. Regarding the problem of cancer lesion detection, a whole-body bone scan image is the primary modality of nuclear medicine for the detection of cancer lesions on a bone. Therefore, high segmentation accuracy of the whole-body bone scan image is a crucial step in building the shape model of some predefined regions in the bone scan image where metastasis was predicted to appear frequently. In this article, we proposed an automatic whole-body bone scan image segmentation based on constrained local model (CLM). We determine 111 landmark points on the bone scan image as the input for the model building step. The resulting shape and texture model are further used in the fitting step to estimate the landmark points of predefined regions. We use the CLM-based approach using regularized landmark mean-shift (RLMS) to lessen the effect of ambiguity, which was struggled by the CLM-based approach. From the experimental result, we successfully show that our proposed image segmentation system achieves higher performance than the general CLM-based approach. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In Indonesia, cancer is very burdensome financially for sufferers as well as for the country. Increasing the access to early detection of cancer can be a solution to prevent the situation from worsening. Regarding the problem of cancer lesion detection, a whole-body bone scan image is the primary modality of nuclear medicine for the detection of cancer lesions on a bone. Therefore, high segmentation accuracy of the whole-body bone scan image is a crucial step in building the shape model of some predefined regions in the bone scan image where metastasis was predicted to appear frequently. In this article, we proposed an automatic whole-body bone scan image segmentation based on constrained local model (CLM). We determine 111 landmark points on the bone scan image as the input for the model building step. The resulting shape and texture model are further used in the fitting step to estimate the landmark points of predefined regions. We use the CLM-based approach using regularized landmark mean-shift (RLMS) to lessen the effect of ambiguity, which was struggled by the CLM-based approach. From the experimental result, we successfully show that our proposed image segmentation system achieves higher performance than the general CLM-based approach. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Removing Noise, Reducing dimension, and Weighting Distance to Enhance k-Nearest Neighbors for Diabetes Classification"
        ],
        "penulis":"Khairunnisa, Syifa;Suyanto, Suyanto;Eko Yunanto, Prasti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Various methods of machine learning have been implemented in the medical field to classify various diseases, such as diabetes. The k-nearest neighbors (KNN) is one of the most known approaches for predicting diabetes. Many researchers have found by combining KNN with one or more other algorithms may provide a better result. In this paper, a combination of three procedures, removing noise, reducing the dimension, and weighting distance, is proposed to improve a standard voting-based KNN to classify Pima Indians Diabetes Dataset (PIDD) into two classes. First, the noises in the training set are removed using k-means clustering (KMC) to make the voter data in both classes more competent. Second, its dimensional is then reduced to decrease the intra-class data distances but increase the inter-class ones. Two methods of dimensional reduction: principal component analysis (PCA) and autoencoder (AE), are applied to investigate the linearity of the dataset. Since there is an imbalance on the dataset, a proportional weight is incorporated into the distance formula to get the fairness of the voting. A 5-fold cross validation-based evaluation shows that each proposed procedure works very well in enhancing the KNN. KMC is capable of increasing the accuracy of KNN from 81.6% to 86.7%. Combining KMC and PCA improves the KNN accuracy to be 90.9%. Next, a combination of KMC and AE enhances the KNN to gives an accuracy of 97.8%. Combining three proposed procedures of KMC, PCA, and Weighted KNN (WKNN) increases the accuracy to be 94.5%. Finally, the combination of KMC, AE, and WKNN reaches the highest accuracy of 98.3%. The facts that AE produces higher accuracies than PCA inform that the features in the dataset have a high non-linearity.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Various methods of machine learning have been implemented in the medical field to classify various diseases, such as diabetes. The k-nearest neighbors (KNN) is one of the most known approaches for predicting diabetes. Many researchers have found by combining KNN with one or more other algorithms may provide a better result. In this paper, a combination of three procedures, removing noise, reducing the dimension, and weighting distance, is proposed to improve a standard voting-based KNN to classify Pima Indians Diabetes Dataset (PIDD) into two classes. First, the noises in the training set are removed using k-means clustering (KMC) to make the voter data in both classes more competent. Second, its dimensional is then reduced to decrease the intra-class data distances but increase the inter-class ones. Two methods of dimensional reduction: principal component analysis (PCA) and autoencoder (AE), are applied to investigate the linearity of the dataset. Since there is an imbalance on the dataset, a proportional weight is incorporated into the distance formula to get the fairness of the voting. A 5-fold cross validation-based evaluation shows that each proposed procedure works very well in enhancing the KNN. KMC is capable of increasing the accuracy of KNN from 81.6% to 86.7%. Combining KMC and PCA improves the KNN accuracy to be 90.9%. Next, a combination of KMC and AE enhances the KNN to gives an accuracy of 97.8%. Combining three proposed procedures of KMC, PCA, and Weighted KNN (WKNN) increases the accuracy to be 94.5%. Finally, the combination of KMC, AE, and WKNN reaches the highest accuracy of 98.3%. The facts that AE produces higher accuracies than PCA inform that the features in the dataset have a high non-linearity.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Evaluation of XGS-PON Optical Network Termination for Enterprise Customer"
        ],
        "penulis":"Nashiruddin, Muhammad Imam;Solihah, Nomarhinta;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Digital economy development requires enterprises to seek solutions to cater increasing demand for internet bandwidth. Enterprise customer require a reliable connection for delivering their business solution with the symmetric speed between upload and download, such as XGS-PON technology (10 Gigabit Capable Symmetric Passive Optical Network). However, standards and regulations for using XGS-PON ONT (Optical Network Terminal) equipment intended for enterprise customers do not exist. This research aims to determine the XGS-PON ONT capabilities for enterprise customers to ensure its service quality. XGS-PON ONT's performance evaluates optical interface capability parameters such as nominal line rate, operating wavelength, mean launch power, sensitivity, and overload. Also, data function capability parameters testing includes the VLAN ID, VLAN translate, and jumbo frame. Optical interface test results show that the XGS-PON ONT enterprise has an upstream nominal line rate capability of 9.81221 Gbps and supports an upstream operating wavelength of 1269,509 nm. The XGS-PON ONT results of mean launch power, sensitivity, and overload comply with the Optical Distribution Network (ODN) class requirements of N1 and N2. The test results of data function capability show that the XGS-PON ONT for enterprise customers can deliver 4000 Virtual Local Area Network Identifiers (VLAN IDs), supports the VLAN translate function jumbo frames from 2000 to 9000 bytes. The optical interface and data function capability of XGS-PON ONT shows the results following ITU-T G.9807, IEEE 802.1q, and Broadband Forum technical reports.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Digital economy development requires enterprises to seek solutions to cater increasing demand for internet bandwidth. Enterprise customer require a reliable connection for delivering their business solution with the symmetric speed between upload and download, such as XGS-PON technology (10 Gigabit Capable Symmetric Passive Optical Network). However, standards and regulations for using XGS-PON ONT (Optical Network Terminal) equipment intended for enterprise customers do not exist. This research aims to determine the XGS-PON ONT capabilities for enterprise customers to ensure its service quality. XGS-PON ONT's performance evaluates optical interface capability parameters such as nominal line rate, operating wavelength, mean launch power, sensitivity, and overload. Also, data function capability parameters testing includes the VLAN ID, VLAN translate, and jumbo frame. Optical interface test results show that the XGS-PON ONT enterprise has an upstream nominal line rate capability of 9.81221 Gbps and supports an upstream operating wavelength of 1269,509 nm. The XGS-PON ONT results of mean launch power, sensitivity, and overload comply with the Optical Distribution Network (ODN) class requirements of N1 and N2. The test results of data function capability show that the XGS-PON ONT for enterprise customers can deliver 4000 Virtual Local Area Network Identifiers (VLAN IDs), supports the VLAN translate function jumbo frames from 2000 to 9000 bytes. The optical interface and data function capability of XGS-PON ONT shows the results following ITU-T G.9807, IEEE 802.1q, and Broadband Forum technical reports.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Thermal performance, parametric analysis, and multi-objective optimization of a direct-expansion solar-assisted heat pump water heater using NSGA-II and decision makings"
        ],
        "penulis":"Cao, Yan;Mihardjo, Leonardus W.W.;Parikhani, Towhid;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Direct-expansion solar-assisted heat pump water heaters (DX-SAHPWHs) are conducive to the environment due to the use of ambient energy and solar radiation. This paper aims to design and develop a thermodynamic model and a multi-criteria optimization of thermal performance for a DX-SAHPWH using R-134a as the working refrigerant that supplies domestic hot water for a typical building throughout the whole year. The thermodynamic model of the DX-SAHPWH is developed so that the performance of the system is solved through the try and error technique with the least initial data of the thermodynamic cycle of DX-SAHPWH. After the validation of the thermodynamic model, the performance of the DX-SAHPWH is analyzed for a typical building located at the temperate climate of Iran. Then, a parametric study is conducted to identify how various design parameters may affect the performance of the DX-SAHPWH system. In the current investigation, the effects of design parameters including solar radiation intensity, ambient air temperature, outlet water temperature of the condenser, solar collector area, compressor speed, length of tube in the condenser, external diameter of the tube in collector plate, fin thickness, and thermal conductivity of collector plate on the performance of the DX-SAHPWH are investigated. Besides, single and bi-criteria optimizations are carried out using genetic algorithm (GA) to obtain the optimal solutions of design parameters, where the coefficient of performance (COP) and the solar collector efficiency (SCE) are selected as two fitness functions. The optimal solutions achieved from the bi-criteria optimization process will be given as Pareto frontier. The final optimum solution from the available solutions on the Pareto optimal frontier is selected using decision-making methods, such as LINMAP, TOPSIS, and Shannon's Entropy. The comparison of single and bi-criteria optimization results illustrate that the bi-criteria optimization method yields more proper results than single ones, mainly because of the lower deviation index from the ideal solution. The results of bi-criteria optimization show that SCE decreases 1.6% compared to the initial model while the COP increases close to 20% that makes the optimum solution more desirable compared to the single ones. Moreover, the performance of the optimized DX-SAHPWH system is compared with the initial model in each month of the year. The results indicate that the performance of the optimized DX-SAHPWH is highly improved so that the working hours of the system decrease close to 109 h compared to the initial model during the whole year. \u00a9 2020",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Direct-expansion solar-assisted heat pump water heaters (DX-SAHPWHs) are conducive to the environment due to the use of ambient energy and solar radiation. This paper aims to design and develop a thermodynamic model and a multi-criteria optimization of thermal performance for a DX-SAHPWH using R-134a as the working refrigerant that supplies domestic hot water for a typical building throughout the whole year. The thermodynamic model of the DX-SAHPWH is developed so that the performance of the system is solved through the try and error technique with the least initial data of the thermodynamic cycle of DX-SAHPWH. After the validation of the thermodynamic model, the performance of the DX-SAHPWH is analyzed for a typical building located at the temperate climate of Iran. Then, a parametric study is conducted to identify how various design parameters may affect the performance of the DX-SAHPWH system. In the current investigation, the effects of design parameters including solar radiation intensity, ambient air temperature, outlet water temperature of the condenser, solar collector area, compressor speed, length of tube in the condenser, external diameter of the tube in collector plate, fin thickness, and thermal conductivity of collector plate on the performance of the DX-SAHPWH are investigated. Besides, single and bi-criteria optimizations are carried out using genetic algorithm (GA) to obtain the optimal solutions of design parameters, where the coefficient of performance (COP) and the solar collector efficiency (SCE) are selected as two fitness functions. The optimal solutions achieved from the bi-criteria optimization process will be given as Pareto frontier. The final optimum solution from the available solutions on the Pareto optimal frontier is selected using decision-making methods, such as LINMAP, TOPSIS, and Shannon's Entropy. The comparison of single and bi-criteria optimization results illustrate that the bi-criteria optimization method yields more proper results than single ones, mainly because of the lower deviation index from the ideal solution. The results of bi-criteria optimization show that SCE decreases 1.6% compared to the initial model while the COP increases close to 20% that makes the optimum solution more desirable compared to the single ones. Moreover, the performance of the optimized DX-SAHPWH system is compared with the initial model in each month of the year. The results indicate that the performance of the optimized DX-SAHPWH is highly improved so that the working hours of the system decrease close to 109 h compared to the initial model during the whole year. \u00a9 2020"
        ]
    },
    {
        "judul":[
            "A method for estimating technical losses in primary feeder conductors"
        ],
        "penulis":"Zein, Hermagasantos;Raharjo, Jangkung;Wachjoe, Conny K.;Mulyadi, Ahmad Deni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One of the engineers\u2019 concerns is the loss of energy in the electric power system. Actually, most of the energy losses occur in the distribution system, i.e., about 4-8%. Therefore, efforts should be made in order to improve the performance of the distribution networks. Evaluating losses in the distribution networks should be done in order to reduce losses. The problem is that there are many nodes, several lateral feeders, and the un-uniform current flowing in the feeder so that calculating the losses becomes very difficult. In addition, the big distribution system has so many feeders, generally more than 1000 feeders, with various types. Thus, the calculation of the losses in the distribution system will face very complex and large-scale problems. Therefore, calculating losses for large scale distributed systems that use load flow or measurement methods is not possible. This paper proposes an effective method that uses a lump load model for technical losses in distribution systems. By approaching, the current is proportional to power, the input current into the feeder can be distributed to each lateral feeder. Thus, the current flow in each segment of the feeder can be determined. For typical feeder with the load currents changed linearly by linearity factor, then-current flows of each segment feeder can be easily determined as c function. This function is created as a calculation model of losses with a clear derivative of the mathematical formulations. The results of numerical studies show that this method is accurate enough with the error of 1.26% when compared to the load flow method using an 8-node feeder. The calculation result is based on the IEEE 13-node test feeder; its loss is smaller than 3.86% compared to the load flow method. \u00a9 2020 Praise Worthy Prize S.r.l. - All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "One of the engineers\u2019 concerns is the loss of energy in the electric power system. Actually, most of the energy losses occur in the distribution system, i.e., about 4-8%. Therefore, efforts should be made in order to improve the performance of the distribution networks. Evaluating losses in the distribution networks should be done in order to reduce losses. The problem is that there are many nodes, several lateral feeders, and the un-uniform current flowing in the feeder so that calculating the losses becomes very difficult. In addition, the big distribution system has so many feeders, generally more than 1000 feeders, with various types. Thus, the calculation of the losses in the distribution system will face very complex and large-scale problems. Therefore, calculating losses for large scale distributed systems that use load flow or measurement methods is not possible. This paper proposes an effective method that uses a lump load model for technical losses in distribution systems. By approaching, the current is proportional to power, the input current into the feeder can be distributed to each lateral feeder. Thus, the current flow in each segment of the feeder can be determined. For typical feeder with the load currents changed linearly by linearity factor, then-current flows of each segment feeder can be easily determined as c function. This function is created as a calculation model of losses with a clear derivative of the mathematical formulations. The results of numerical studies show that this method is accurate enough with the error of 1.26% when compared to the load flow method using an 8-node feeder. The calculation result is based on the IEEE 13-node test feeder; its loss is smaller than 3.86% compared to the load flow method. \u00a9 2020 Praise Worthy Prize S.r.l. - All rights reserved."
        ]
    },
    {
        "judul":[
            "Technical specification for effective next generation network interconnection in Indonesia"
        ],
        "penulis":"Abdurohman, Maman;Nugroho, Bambang Setia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper proposes technical specifications for effectively implementing the interconnection of Next Generation Network (NGN) in Indonesia. NGN is one of the current telecommunication infrastructure network technology trends. It provides a simpler concept with only two layers of service and transport. The NGN IP-based transport system can connect with various types of networks, which leads to low management costs by offering different kinds of services. Meanwhile, there are currently various types of telecommunication networks depending on the services provided, such as Public Switched Telephone Network (PSTN), IPv4 Internet as well as Public Switched Data Network (PSDN). PSTN is a circuit-switched voice communications network, and PSDN is a network for data-based communications with International Telecommunication Union (ITU)-T X.121 standards. Another type is a packet-switched based network that uses IPv4 addressing systems. Each network has its customers. One of the problems that arise, however, is how to transform the current network system to the NGN network effectively. The effectiveness of network transformation in the service provision for users is determined by the technical aspects used. Some of the technical aspects issues on implementation of NGN networks in Indonesia are the use of a protocol for signaling, coding standards, Quality of Service (QoS), numbering and addressing, and security. This paper proposes technical specifications for the effectiveness of NGN network implementation in Indonesia. Through the technical specification model, we propose, the risks that will arise in the implementation of NGN networks in Indonesia can be managed. Appropriate technical specifications have an essential role in the effectiveness of NGN network implementation in Indonesia. \u00a9 2020, Insight Society.",
            "OH3CCH3SHSView detailsExpand Substance isopropylxanthic acid",
            "Powered by",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes technical specifications for effectively implementing the interconnection of Next Generation Network (NGN) in Indonesia. NGN is one of the current telecommunication infrastructure network technology trends. It provides a simpler concept with only two layers of service and transport. The NGN IP-based transport system can connect with various types of networks, which leads to low management costs by offering different kinds of services. Meanwhile, there are currently various types of telecommunication networks depending on the services provided, such as Public Switched Telephone Network (PSTN), IPv4 Internet as well as Public Switched Data Network (PSDN). PSTN is a circuit-switched voice communications network, and PSDN is a network for data-based communications with International Telecommunication Union (ITU)-T X.121 standards. Another type is a packet-switched based network that uses IPv4 addressing systems. Each network has its customers. One of the problems that arise, however, is how to transform the current network system to the NGN network effectively. The effectiveness of network transformation in the service provision for users is determined by the technical aspects used. Some of the technical aspects issues on implementation of NGN networks in Indonesia are the use of a protocol for signaling, coding standards, Quality of Service (QoS), numbering and addressing, and security. This paper proposes technical specifications for the effectiveness of NGN network implementation in Indonesia. Through the technical specification model, we propose, the risks that will arise in the implementation of NGN networks in Indonesia can be managed. Appropriate technical specifications have an essential role in the effectiveness of NGN network implementation in Indonesia. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Microarray Data Classification to Detect Cancer Cells by Using Discrete Wavelet Transform and Combining Classifiers Methods"
        ],
        "penulis":"Gusman, Hanafi Abdullah;Adiwijaya;Astuti, Widi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Cancer has become a disease with the highest worldwide mortality rate, reaching 9.6 million occurrences in the year 2018. Researchers are using microarray data to observe the level of cancer expression gene. However, microarray data have huge data attribute and it causes curse of dimensionality. Thus, data processing takes a longer time. Dimensional reduction technique by using Discrete Wavelet Transform is being used in this research to solve these problems. The dimensional reduction process is utilizing the family daubechies4. Then, a method between K-nearest Neighbor and Support Vector Machines is chosen based on the neighbor similarity during the data classification process. Therefore, the created system could produce 95% classification accuracy for colon cancer's data, 88.88% for breast cancer's data, 87.16% for lung cancer's data, and 100% for ovarian cancer's data.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer has become a disease with the highest worldwide mortality rate, reaching 9.6 million occurrences in the year 2018. Researchers are using microarray data to observe the level of cancer expression gene. However, microarray data have huge data attribute and it causes curse of dimensionality. Thus, data processing takes a longer time. Dimensional reduction technique by using Discrete Wavelet Transform is being used in this research to solve these problems. The dimensional reduction process is utilizing the family daubechies4. Then, a method between K-nearest Neighbor and Support Vector Machines is chosen based on the neighbor similarity during the data classification process. Therefore, the created system could produce 95% classification accuracy for colon cancer's data, 88.88% for breast cancer's data, 87.16% for lung cancer's data, and 100% for ovarian cancer's data.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Towards a wellbeing-driven system design for intergenerational collaborative innovation: A literature review"
        ],
        "penulis":"Nurhas, Irawan;Geisler, Stefan;Ojala, Arto;Pawlowski, Jan M.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Researchers have previously utilized the advantages of a design driven by well-being and intergenerational collaboration (IGC) for successful innovation. Unfortunately, scant information exists regarding barrier dimensions and correlated design solutions in the information systems (IS) domain, which can serve as a starting point for a design oriented toward well-being in an IGC system. Therefore, in this study, we applied the positive computing approach to guide our analysis in a systematic literature review and developed a framework oriented toward well-being for a system with a multi-generational team. Our study contributes to the IS community by providing five dimensions of barriers to IGC and the corresponding well-being determinants for positive system design. In addition, we propose further research directions to close the research gap based on the review outcomes. \u00a9 2020 IEEE Computer Society. All rights reserved."
        ],
        "abstrak":[
            "Researchers have previously utilized the advantages of a design driven by well-being and intergenerational collaboration (IGC) for successful innovation. Unfortunately, scant information exists regarding barrier dimensions and correlated design solutions in the information systems (IS) domain, which can serve as a starting point for a design oriented toward well-being in an IGC system. Therefore, in this study, we applied the positive computing approach to guide our analysis in a systematic literature review and developed a framework oriented toward well-being for a system with a multi-generational team. Our study contributes to the IS community by providing five dimensions of barriers to IGC and the corresponding well-being determinants for positive system design. In addition, we propose further research directions to close the research gap based on the review outcomes. \u00a9 2020 IEEE Computer Society. All rights reserved."
        ]
    },
    {
        "judul":[
            "A Hybrid of Seasonal Autoregressive Integrated Moving Average (SARIMA) and Decision Tree for Drought Forecasting"
        ],
        "penulis":"Yasnita;Sutoyo, Edi;Musnansyah, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Drought is one of the triggers for forest fires due to depletion of surface water reserves. Along with the frequent drought, the incidence of forest fires has also increased. Therefore, it is important to know or forecast drought to take precautions. In this study, drought forecasting was carried out by applying the concept of data mining classification methods and forecasting methods. This classification uses the decision tree (CART) method, which is a method that aims to see the rules resulting from the classification of existing data. While forecasting uses the SARIMA method, this method is used to predict the factors that cause drought (temperature, humidity, and rainfall). Furthermore, the rule of the classification results is used to classify the results of forecasts. Based on the implementation of the CART algorithm which is evaluated using a confusion matrix is able to achieve an accuracy of 91.33%. Based on the implementation of the SARIMA method, a model is obtained for each variable to build forecasting. Each model was selected based on AIC criteria, and evaluated using MSE. The optimal model for temperature (Tx) is SARIMA (1, 1, 0) x (0, 1, 1, 12) with the MSE value of 0.15. While the selected model for humidity (RH_avg) is SARIMA (0, 1, 1) x (1, 1, 1, 12) with the MSE value of 3.85, and the optimal model for rainfall (RR) is SARIMA (0, 1, 1) x (0, 1, 1, 12) with the MSE value of 8.61. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Drought is one of the triggers for forest fires due to depletion of surface water reserves. Along with the frequent drought, the incidence of forest fires has also increased. Therefore, it is important to know or forecast drought to take precautions. In this study, drought forecasting was carried out by applying the concept of data mining classification methods and forecasting methods. This classification uses the decision tree (CART) method, which is a method that aims to see the rules resulting from the classification of existing data. While forecasting uses the SARIMA method, this method is used to predict the factors that cause drought (temperature, humidity, and rainfall). Furthermore, the rule of the classification results is used to classify the results of forecasts. Based on the implementation of the CART algorithm which is evaluated using a confusion matrix is able to achieve an accuracy of 91.33%. Based on the implementation of the SARIMA method, a model is obtained for each variable to build forecasting. Each model was selected based on AIC criteria, and evaluated using MSE. The optimal model for temperature (Tx) is SARIMA (1, 1, 0) x (0, 1, 1, 12) with the MSE value of 0.15. While the selected model for humidity (RH_avg) is SARIMA (0, 1, 1) x (1, 1, 1, 12) with the MSE value of 3.85, and the optimal model for rainfall (RR) is SARIMA (0, 1, 1) x (0, 1, 1, 12) with the MSE value of 8.61. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "A multi tone modeling for seismic data compression"
        ],
        "penulis":"Liu, Bo;Mohandes M.;Nuha H.;Deriche M.;Iqbal, Naveed;Fekri, Faramarz;McClellan, James H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG"
        ]
    },
    {
        "judul":[
            "Anatomy of magnetic anisotropy and voltage-controlled magnetic anisotropy in metal oxide heterostructure from first principles"
        ],
        "penulis":"Pardede, Indra;Yoshikawa, Daiki;Kanagawa, Tomosato;Ikhsan, Nurul;Obata, Masao;Oda, Tatsuki;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Voltage control of magnetic anisotropy (VCMA) is one of the promising approaches for magnetoelectric control of magnetic tunnel junction (MTJ). Here, we systematically calculated the magnetic anisotropy (MA) and the VCMA energies in the well-known MTJ structure consisting of Fe\/MgO interface with Cr buffer layer. In this calculation, we investigated an alloying between Fe and Cr and a strain effect. We used a spin density functional approach which includes both contributions from magnetocrystalline anisotropy energy (MCAE) originating from spin\u2013orbit coupling and shape magnetic anisotropy energy from spin dipole\u2013dipole interaction. In the present approach, the MCAE part, in addition to a common scheme of total energy, was evaluated using a grand canonical force theorem scheme. In the latter scheme, atom-resolved and k-resolved analyses for MA and VCMA can be performed. At first, we found that, as the alloying is introduced, the perpendicular MCAE increases by a factor of two. Next, as the strain is introduced, we found that the MCAE increases with increasing compressive strain with the maximum value of 2.2 mJ\/m2. For the VCMA coefficient, as the compressive strain increases, the sign becomes negative and the absolute value becomes enhanced to the number of 170 fJ\/Vm. By using the atom-resolved and k-resolved analyses, we clarified that these enhancements of MCAE and VCMA mainly originates from the Fe interface with MgO (Fe1) and are located at certain lines in the two dimensional Brillouin zone. The findings on MCAE and VCMA are fully explained by the spin-orbit couplings between the certain d-orbital states in the second-order perturbation theory. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Voltage control of magnetic anisotropy (VCMA) is one of the promising approaches for magnetoelectric control of magnetic tunnel junction (MTJ). Here, we systematically calculated the magnetic anisotropy (MA) and the VCMA energies in the well-known MTJ structure consisting of Fe\/MgO interface with Cr buffer layer. In this calculation, we investigated an alloying between Fe and Cr and a strain effect. We used a spin density functional approach which includes both contributions from magnetocrystalline anisotropy energy (MCAE) originating from spin\u2013orbit coupling and shape magnetic anisotropy energy from spin dipole\u2013dipole interaction. In the present approach, the MCAE part, in addition to a common scheme of total energy, was evaluated using a grand canonical force theorem scheme. In the latter scheme, atom-resolved and k-resolved analyses for MA and VCMA can be performed. At first, we found that, as the alloying is introduced, the perpendicular MCAE increases by a factor of two. Next, as the strain is introduced, we found that the MCAE increases with increasing compressive strain with the maximum value of 2.2 mJ\/m2. For the VCMA coefficient, as the compressive strain increases, the sign becomes negative and the absolute value becomes enhanced to the number of 170 fJ\/Vm. By using the atom-resolved and k-resolved analyses, we clarified that these enhancements of MCAE and VCMA mainly originates from the Fe interface with MgO (Fe1) and are located at certain lines in the two dimensional Brillouin zone. The findings on MCAE and VCMA are fully explained by the spin-orbit couplings between the certain d-orbital states in the second-order perturbation theory. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "High availability storage server with kubernetes"
        ],
        "penulis":"Khatami, Ali Akbar;Purwanto, Yudha;Ruriawan, Muhammad Faris;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "High availability server (HAS) is a concept in which the server resources continuously available through any interference of the virtual and physical server. HAS is widely used for various purposes such as online trading services, business and Big Data needs. To optimize storage, it needs a special way to minimize costs incurred and be able to optimize the existing server. This research has implemented a system of high availability server using Kubernetes and distributed storage. The system was capable of meeting the resource requests even though one instance was interrupted. And if an instance was down, the services stored in the cluster could still be accessed through other instances. Based on the reliability and availability testing, the system was capable of meeting the high availability criteria, by reaching an uptime rate of 100%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "High availability server (HAS) is a concept in which the server resources continuously available through any interference of the virtual and physical server. HAS is widely used for various purposes such as online trading services, business and Big Data needs. To optimize storage, it needs a special way to minimize costs incurred and be able to optimize the existing server. This research has implemented a system of high availability server using Kubernetes and distributed storage. The system was capable of meeting the resource requests even though one instance was interrupted. And if an instance was down, the services stored in the cluster could still be accessed through other instances. Based on the reliability and availability testing, the system was capable of meeting the high availability criteria, by reaching an uptime rate of 100%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "A survey on malware detection technology and future trends"
        ],
        "penulis":"Irzal Ismail, Setia Juli;Hendrawan;Rahardjo, Budi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Malware has become a serious threat to the internet. Their numbers are constantly increasing, and the level of complexity is rising. This paper aims to conduct a systematic survey on the development of malware detection technology. The main contributions of this paper are: 1) Describing in detail the state-of-the-art of malware detection methods, 2) Exploring the challenges and limitations of machine learning implementation on malware detection, 3) Providing new trends and developments in malware detection technology. This survey is expected to help researchers to understand the malware detection technology and the direction of its research development.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Malware has become a serious threat to the internet. Their numbers are constantly increasing, and the level of complexity is rising. This paper aims to conduct a systematic survey on the development of malware detection technology. The main contributions of this paper are: 1) Describing in detail the state-of-the-art of malware detection methods, 2) Exploring the challenges and limitations of machine learning implementation on malware detection, 3) Providing new trends and developments in malware detection technology. This survey is expected to help researchers to understand the malware detection technology and the direction of its research development.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Deep Neural Networks with Extreme Learning Machine for Seismic Data Compression"
        ],
        "penulis":"Nuha, Hilal H.;Balghonaim, Adil;Liu, Bo;Mohandes, Mohamed;Deriche, Mohamed;Fekri, Faramarz;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Advances on seismic survey techniques require a large number of geophones. This leads to an exponential growth in the size of data and prohibitive demands on storage and network communication resources. Therefore, it is desirable to compress the seismic data to the minimum possible, without losing important information. In this paper, a stacked auto-encoder extreme learning machine (AE-ELM) for seismic data compression is proposed. First, a deep asymmetric auto-encoder is constructed, in which nonlinear activation functions are used in the encoder hidden layers and linear activation functions are utilized in the decoder layers. Second, the encoder hidden layers are connected in a cascade way, so that outputs of a hidden layer are considered as the inputs to the succeeding hidden layer. Third, the optimal weights of connections between the layers of the decoder are solved analytically. Lastly, the AE-ELMs are stacked to create the complete encoder\/decoder. The extreme learning machine (ELM) is selected due to its analytical calculation of weights efficient training that is suitable for practical implementation. In this neural network, data compression is achieved by transforming the original data through the encoder layers where the size of outputs from the last encoder hidden layer is smaller than the original data size. The proposed method exhibits a comparable reconstruction quality on a real dataset but with a much shorter training duration than other deep neural networks methods. This neural network with more than 8000 hidden units achieved 1.28 \u00d7 10- 3of normalized mean-squared error for 10:1 of compression ratio with only 8.23\u00a0s of training time. \u00a9 2019, King Fahd University of Petroleum & Minerals.",
            "ClClNView detailsExpand Substance 2,6-dichloro-benzonitrile",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Advances on seismic survey techniques require a large number of geophones. This leads to an exponential growth in the size of data and prohibitive demands on storage and network communication resources. Therefore, it is desirable to compress the seismic data to the minimum possible, without losing important information. In this paper, a stacked auto-encoder extreme learning machine (AE-ELM) for seismic data compression is proposed. First, a deep asymmetric auto-encoder is constructed, in which nonlinear activation functions are used in the encoder hidden layers and linear activation functions are utilized in the decoder layers. Second, the encoder hidden layers are connected in a cascade way, so that outputs of a hidden layer are considered as the inputs to the succeeding hidden layer. Third, the optimal weights of connections between the layers of the decoder are solved analytically. Lastly, the AE-ELMs are stacked to create the complete encoder\/decoder. The extreme learning machine (ELM) is selected due to its analytical calculation of weights efficient training that is suitable for practical implementation. In this neural network, data compression is achieved by transforming the original data through the encoder layers where the size of outputs from the last encoder hidden layer is smaller than the original data size. The proposed method exhibits a comparable reconstruction quality on a real dataset but with a much shorter training duration than other deep neural networks methods. This neural network with more than 8000 hidden units achieved 1.28 \u00d7 10- 3of normalized mean-squared error for 10:1 of compression ratio with only 8.23\u00a0s of training time. \u00a9 2019, King Fahd University of Petroleum & Minerals."
        ]
    },
    {
        "judul":[
            "Reporting system design for family planning field officers in DPPKB using business process improvement (BPI)"
        ],
        "penulis":"Alifah, Fakhirah Nur;Triwibisono, Christanto;Suwarsono, Litasari Widyastuti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Family Planning (FP) field officers are the people actively working in the field to encourage people to get involved in the family planning program that supports the government in controlling the population of the country. However, many of the officers have stated that their recruits often make mistakes during the process of inputting data along, added with the long manual validation process. The available digital reporting application called Sistem Informasi Keluarga (SIGA) is also not used at its maximum capability, causing the decrease of data validity collected through the process. Using business process improvement (BPI), valueadded analysis, and gap analysis are performed to find the issues in the system that will become the base of the reporting system redesign. This research was done to provide a proper business process design that is needed to ensure maximum comprehension and reduction of data invalidity with the help of the existing application. The result of this research shows that the new business process design required the digitalization of the data input process using an information system and the reduction of the use of offline forms to increase the validity of data in the reporting system.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Family Planning (FP) field officers are the people actively working in the field to encourage people to get involved in the family planning program that supports the government in controlling the population of the country. However, many of the officers have stated that their recruits often make mistakes during the process of inputting data along, added with the long manual validation process. The available digital reporting application called Sistem Informasi Keluarga (SIGA) is also not used at its maximum capability, causing the decrease of data validity collected through the process. Using business process improvement (BPI), valueadded analysis, and gap analysis are performed to find the issues in the system that will become the base of the reporting system redesign. This research was done to provide a proper business process design that is needed to ensure maximum comprehension and reduction of data invalidity with the help of the existing application. The result of this research shows that the new business process design required the digitalization of the data input process using an information system and the reduction of the use of offline forms to increase the validity of data in the reporting system.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "FFT-based data hiding on audio in LWT-domain using spread spectrum technique"
        ],
        "penulis":"Budiman, Gelar;Suksmono, Andriyan Bayu;Danudirdjo, Donny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Audio watermarking is a process to hide digital data without being seen or heard by the sense of sight or hearing. Watermaking is applied to insert the copyright on digital media, such as an image file, an audio file or a video file. In this paper, we propose watermarking procedure to embed spread spectrum watermark into frequency domain of adaptive selected subband from host audio. Lifting Wavelet Transform (LWT) is used to decompose the host audio into several subbands, and then Fast Fourier Transform (FFT) transforms selected several subbands with lowest energy. The watermark image is converted into one-dimensional signal, then it is modulated by imperceptible pseudo-noise (PN) code with controlled gain. Next, the frequency domain of audio is added by modulated and imperceptible watermark prior to transforming it to time domain by Inverse FFT (IFFT) obtaining watermarked subbands. Finally, the watermarked subbands are combined with other unused subbands by inverse LWT (ILWT) becoming the perfect version of watermarked audio. The result of this method has good robustness against most attacks from stirmark benchmark experiments, good imperceptibility with Signal to Noise Ratio (SNR) more than 30 dB and payload 172.66 bps. \u00a9 2020 Kauno Technologijos Universitetas. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Audio watermarking is a process to hide digital data without being seen or heard by the sense of sight or hearing. Watermaking is applied to insert the copyright on digital media, such as an image file, an audio file or a video file. In this paper, we propose watermarking procedure to embed spread spectrum watermark into frequency domain of adaptive selected subband from host audio. Lifting Wavelet Transform (LWT) is used to decompose the host audio into several subbands, and then Fast Fourier Transform (FFT) transforms selected several subbands with lowest energy. The watermark image is converted into one-dimensional signal, then it is modulated by imperceptible pseudo-noise (PN) code with controlled gain. Next, the frequency domain of audio is added by modulated and imperceptible watermark prior to transforming it to time domain by Inverse FFT (IFFT) obtaining watermarked subbands. Finally, the watermarked subbands are combined with other unused subbands by inverse LWT (ILWT) becoming the perfect version of watermarked audio. The result of this method has good robustness against most attacks from stirmark benchmark experiments, good imperceptibility with Signal to Noise Ratio (SNR) more than 30 dB and payload 172.66 bps. \u00a9 2020 Kauno Technologijos Universitetas. All rights reserved."
        ]
    },
    {
        "judul":[
            "Short communication: COVID-19 pandemic and attitude of citizens in bandung City Indonesia (Case Study in Cibiru Subdistrict)"
        ],
        "penulis":"Sumaryana, Asep;Toharudin, Toni;Caraka, Rezzy Eko;Pontoh, Resa Septiani;Chen, Rung Ching;Pardamean, Bens;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the beginning, the pandemic panicked the people of Cibiru. Over time, the case fell in line with the increasing number of patients recovering. In addition, different views between elements of government make people surrender and believe in the power of nature's creator. Under these conditions, the researchers were interested in learning more. The study was conducted using a descriptive analysis of a number of parties regarding economic and social activities. The results show that there are three important components: First, trust builds the creator and reduces to the government component, communication that a number of parties do not work consistently when responding to COVID-19, and enforcement of unclear rules. In a nutshell. The citizens, grouped into two groups, agree that a pandemic is dangerous and urge them to follow values in the form of existing rules. Also,The pandemic communication competes in a short time and therefore cannot be carried out interactively.The government\u2019s assertiveness of forcing residents to be at home becomes difficult as compensation can be granted for lost opportunities to seek family income Lastly, due to the preparation of the strategy that precedes the arrival of a pandemic, it cannot be face wisely. \u00a9 2020 Lifescience Global",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the beginning, the pandemic panicked the people of Cibiru. Over time, the case fell in line with the increasing number of patients recovering. In addition, different views between elements of government make people surrender and believe in the power of nature's creator. Under these conditions, the researchers were interested in learning more. The study was conducted using a descriptive analysis of a number of parties regarding economic and social activities. The results show that there are three important components: First, trust builds the creator and reduces to the government component, communication that a number of parties do not work consistently when responding to COVID-19, and enforcement of unclear rules. In a nutshell. The citizens, grouped into two groups, agree that a pandemic is dangerous and urge them to follow values in the form of existing rules. Also,The pandemic communication competes in a short time and therefore cannot be carried out interactively.The government\u2019s assertiveness of forcing residents to be at home becomes difficult as compensation can be granted for lost opportunities to seek family income Lastly, due to the preparation of the strategy that precedes the arrival of a pandemic, it cannot be face wisely. \u00a9 2020 Lifescience Global"
        ]
    },
    {
        "judul":[
            "A study of coping stress strategies on psychological well-being during the COVID-19 pandemic in Jabodetabek Area"
        ],
        "penulis":"Sofa, Gagar Asmara;Findez Shidiq Anugrah, Ananda;Nugraha, Yudhistira;Al Rasyid, Salman Haydar;Aghinasuci, Vicka;Hidayat, Wahyu Nur;Wibowo, Ibnu;Suherman, Alex L.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Large-Scale Social Limitations-related policies enacted by the Provincial Government of the Special Capital Region of Jakarta evoked an adaptation process to changes in their usual life patterns. Such adaptation processes are suspected to create new problems, which might become stressors. This research aims to perceive the effect of coping strategies on the psychological being of Jabodetabek (Jakarta, Bogor, Depok, Tangerang, Bekasi) citizens during the Large- Scale Social Limitations period. Results showed that there was a significant relationship between coping strategies and psychological well-being (p=0.000<0.005). Research also found that most respondents cope by employing the emotion-focused coping system. It was strongly suspected that citizens were able to cope and manage stressors during the pandemic by doing self-improvement activities and trying to connect with their social network (friendship or work-related) with existing technological platforms. On the other hand, it was also suspected that the high number of respondents with emotion-focused coping was a result of feelings of helplessness in controlling problems arising during the pandemic, such as local government policies and socioeconomic impacts. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Large-Scale Social Limitations-related policies enacted by the Provincial Government of the Special Capital Region of Jakarta evoked an adaptation process to changes in their usual life patterns. Such adaptation processes are suspected to create new problems, which might become stressors. This research aims to perceive the effect of coping strategies on the psychological being of Jabodetabek (Jakarta, Bogor, Depok, Tangerang, Bekasi) citizens during the Large- Scale Social Limitations period. Results showed that there was a significant relationship between coping strategies and psychological well-being (p=0.000<0.005). Research also found that most respondents cope by employing the emotion-focused coping system. It was strongly suspected that citizens were able to cope and manage stressors during the pandemic by doing self-improvement activities and trying to connect with their social network (friendship or work-related) with existing technological platforms. On the other hand, it was also suspected that the high number of respondents with emotion-focused coping was a result of feelings of helplessness in controlling problems arising during the pandemic, such as local government policies and socioeconomic impacts. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A Review of Batik Pattern Generations Methods"
        ],
        "penulis":"Laitupa, Dyah Rizky Hujairha;Purboyo, Tito Waluyo;Kusuma, Purba Daru;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The art of coloring the cloth with the coloring blocking technique using the night is one of the ancient art forms. And batik is one of the art of coloring cloth that has developed in Indonesia, since, Majapahit kingdom. The process of making batik traditionally takes a long time. From the length of the process of making batik there are stages that usually takes quite a long time called scratching is to draw a motive either on paper or directly on the cloth. This is because at the stage of scraping batik should think of ideas after getting new ideas batik will apply it. The process of getting this idea make the process longer in making batik. With the development of technology and science today, it can shorten making the pattern by using an algorithm or computation method. \u00a9 2020. Medwell Journals",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The art of coloring the cloth with the coloring blocking technique using the night is one of the ancient art forms. And batik is one of the art of coloring cloth that has developed in Indonesia, since, Majapahit kingdom. The process of making batik traditionally takes a long time. From the length of the process of making batik there are stages that usually takes quite a long time called scratching is to draw a motive either on paper or directly on the cloth. This is because at the stage of scraping batik should think of ideas after getting new ideas batik will apply it. The process of getting this idea make the process longer in making batik. With the development of technology and science today, it can shorten making the pattern by using an algorithm or computation method. \u00a9 2020. Medwell Journals"
        ]
    },
    {
        "judul":[
            "Classification of premature ventricular contraction (Pvc) based on ecg signal using convolutional neural network (cnn)"
        ],
        "penulis":"Jondri;Rizal, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study observes one of the ECG signal abnormalities, which is the Premature Ventricular Contraction (PVC). Many studies applied a machine learning technique to develop a computer-aided diagnosis to classify normal and PVC conditions of ECG signals. The common process to obtain information from the ECG signal is by performing a feature extraction process. Since the ECG signal is a complex signal, there is a need to reduce the signal dimension to produce an optimal feature set. However, these processes can remove the information contained in the signal. Therefore, this study process the original ECG signal using a Convolutional Neural Network to avoid losing information. The input data were in the form of both one beat of normal ECG signal or PVC with size 1x200. The classification used four layers of convolutional neural network (CNN). There were eight 1x1 filters used in the input. Simultaneously, 16 and 32 of 1x1 filters were used in the second and the fourth convolutional layers, respectively. Thus the system produced a fully connected layer consisted of 512 neurons, while the output layer consisted of 2 neurons. The system is tested using 11361 beats of ECG data and achieved the highest accuracy of 99.59%, with the 10-fold cross-validation. This study emphasizes an opportunity to develop a wearable device to detect PVC since CNN can be implemented into an embedded system or an IoT based system. \u00a9 2020 Institute of Advanced Engineering and Science.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study observes one of the ECG signal abnormalities, which is the Premature Ventricular Contraction (PVC). Many studies applied a machine learning technique to develop a computer-aided diagnosis to classify normal and PVC conditions of ECG signals. The common process to obtain information from the ECG signal is by performing a feature extraction process. Since the ECG signal is a complex signal, there is a need to reduce the signal dimension to produce an optimal feature set. However, these processes can remove the information contained in the signal. Therefore, this study process the original ECG signal using a Convolutional Neural Network to avoid losing information. The input data were in the form of both one beat of normal ECG signal or PVC with size 1x200. The classification used four layers of convolutional neural network (CNN). There were eight 1x1 filters used in the input. Simultaneously, 16 and 32 of 1x1 filters were used in the second and the fourth convolutional layers, respectively. Thus the system produced a fully connected layer consisted of 512 neurons, while the output layer consisted of 2 neurons. The system is tested using 11361 beats of ECG data and achieved the highest accuracy of 99.59%, with the 10-fold cross-validation. This study emphasizes an opportunity to develop a wearable device to detect PVC since CNN can be implemented into an embedded system or an IoT based system. \u00a9 2020 Institute of Advanced Engineering and Science."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Sequential Dual Attention Network for Rain Streak Removal in a Single Image"
        ],
        "penulis":"Lin, Chih-Yang;Tao, Zhuang;Xu, Ai-Sheng;Kang, Li-Wei;Akhyar, Fityanul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Various weather conditions, such as rain, haze, or snow, can degrade visual quality in images\/videos, which may significantly degrade the performance of related applications. In this paper, a novel framework based on sequential dual attention deep network is proposed for removing rain streaks (deraining) in a single image, called by SSDRNet (Sequential dual attention-based Single image DeRaining deep Network). Since the inherent correlation among rain steaks within an image should be stronger than that between the rain streaks and the background (non-rain) pixels, a two-stage learning strategy is implemented to better capture the distribution of rain streaks within a rainy image. The two-stage deep neural network primarily involves three blocks: residual dense blocks (RDBs), sequential dual attention blocks (SDABs), and multi-scale feature aggregation modules (MAMs), which are all delicately and specifically designed for rain removal. The two-stage strategy successfully learns very fine details of the rain steaks of the image and then clearly removes them. Extensive experimental results have shown that the proposed deep framework achieves the best performance on qualitative and quantitative metrics compared with state-of-the-art methods. The corresponding code and the trained model of the proposed SSDRNet have been available online at https:\/\/github.com\/fityanul\/SDAN-for-Rain-Removal. \u00a9 1992-2012 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Various weather conditions, such as rain, haze, or snow, can degrade visual quality in images\/videos, which may significantly degrade the performance of related applications. In this paper, a novel framework based on sequential dual attention deep network is proposed for removing rain streaks (deraining) in a single image, called by SSDRNet (Sequential dual attention-based Single image DeRaining deep Network). Since the inherent correlation among rain steaks within an image should be stronger than that between the rain streaks and the background (non-rain) pixels, a two-stage learning strategy is implemented to better capture the distribution of rain streaks within a rainy image. The two-stage deep neural network primarily involves three blocks: residual dense blocks (RDBs), sequential dual attention blocks (SDABs), and multi-scale feature aggregation modules (MAMs), which are all delicately and specifically designed for rain removal. The two-stage strategy successfully learns very fine details of the rain steaks of the image and then clearly removes them. Extensive experimental results have shown that the proposed deep framework achieves the best performance on qualitative and quantitative metrics compared with state-of-the-art methods. The corresponding code and the trained model of the proposed SSDRNet have been available online at https:\/\/github.com\/fityanul\/SDAN-for-Rain-Removal. \u00a9 1992-2012 IEEE."
        ]
    },
    {
        "judul":[
            "ITSM Analysis using ITIL V3 in Service Operation in PT.Inovasi Tjaraka Buana"
        ],
        "penulis":"Lubis, Muharman;Annisyah, Rizky Cherthio;Lyvia Winiyanti L.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT. Inovasi Tjaraka Buana is a company in ISP (Internet Service Provider) sector that uses information technology to sustain activities the company. At this time the company is experiencing scaling-up, which is a drastic increase in the number of user of internet services, and coverage areas that make companies have to develop for various aspects of the company. The problem is that companies cannot at this time balancing service operations when handling an incident that occurs with drastic addition of the number of users and the amount of coverage area. To solve the problem, it is necessary to implement Information Technology Service Management (ITSM). The method used in this research is data collection by interview and observation techniques. This research will produce Incident Management Flow and Problem Management Flow. ITIL, which is a framework that illustrates best practices that focus on managing IT services, IT development and operations, which can help companies to overcome problems, so the company can apply it in order to balance service operations when handling incidents that occur. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. Inovasi Tjaraka Buana is a company in ISP (Internet Service Provider) sector that uses information technology to sustain activities the company. At this time the company is experiencing scaling-up, which is a drastic increase in the number of user of internet services, and coverage areas that make companies have to develop for various aspects of the company. The problem is that companies cannot at this time balancing service operations when handling an incident that occurs with drastic addition of the number of users and the amount of coverage area. To solve the problem, it is necessary to implement Information Technology Service Management (ITSM). The method used in this research is data collection by interview and observation techniques. This research will produce Incident Management Flow and Problem Management Flow. ITIL, which is a framework that illustrates best practices that focus on managing IT services, IT development and operations, which can help companies to overcome problems, so the company can apply it in order to balance service operations when handling incidents that occur. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Preparation & Characterization of Microcrystalline Cellulose from Agriculture Waste"
        ],
        "penulis":"Senusi, Nur Aiman;Mohd Shohaimi, Norshahidatul Akmar;Halim, Ahmad Zamani Ab;Shukr, Nurasmat Mohd;Abdul Razab, Mohammad Khairul Azhar;Mohamed, Mazlan;Mohd Amin, Mohamad Asyraf;Mokhtar, Wan Nur Aini Wan;Ismardi, Abrar;Mohamed Noor, An'Amt Bin;Abdullah, Nor Hakimin;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this work, microcrystalline cellulose was prepared from oil palm trunk by water treated fibre process and alkali bleaching. The prepared samples were characterized by using Fourier-transform infrared spectroscopy attenuated total reflectance (FTIR-ATR), Scanning Electron Microscopy (SEM) and X-ray diffraction (XRD). FTIR-ATR spectra analysis indicates the presence of the hydroxyl group, alcohol, alkane\/alkene and imine group. XRD patterns revealed the amorphous nature of the samples and the crystallinity index for extracted cellulose is 48.7 %. SEM images showed the fibrous structure of the microcrystalline cellulose with a size of 50 \u03bcm. This research proved that the synthesized microcrystalline cellulose could be potentially used as reinforcement in bio composite for better performance and ductility. \u00a9 Published under licence by IOP Publishing Ltd.",
            "ClOONaView detailsExpand Substance sodium chloriteMicrocrystalline celluloseView detailsExpand Substance microcrystalline cellulose",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this work, microcrystalline cellulose was prepared from oil palm trunk by water treated fibre process and alkali bleaching. The prepared samples were characterized by using Fourier-transform infrared spectroscopy attenuated total reflectance (FTIR-ATR), Scanning Electron Microscopy (SEM) and X-ray diffraction (XRD). FTIR-ATR spectra analysis indicates the presence of the hydroxyl group, alcohol, alkane\/alkene and imine group. XRD patterns revealed the amorphous nature of the samples and the crystallinity index for extracted cellulose is 48.7 %. SEM images showed the fibrous structure of the microcrystalline cellulose with a size of 50 \u03bcm. This research proved that the synthesized microcrystalline cellulose could be potentially used as reinforcement in bio composite for better performance and ductility. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Implementation of electronic stethoscope for online remote monitoring with mobile application"
        ],
        "penulis":"Hadiyoso, Sugondo;Mardiyah, Dieny Rofiatul;Ramadan, Dadan Nur;Ibrahim, Asril;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The stethoscope is a piece of medical standard equipment that isused by a physician for an initial examination of the patient. Generally, the stethoscope is used for auscultating sounds which are generated by the workings of organ systems such as cardiac, lung or digestive. In the present condition with the growing number of the patient population, it has an impact on the burden of hospitals and medical practitioners. So that treatment is not optimal, especially patients who need continuous monitoring. Thus it needs a system that can work dynamically, flexibly and remotely based. This paper focuses on the implementation of the electronic stethoscope which is integrated with a mobile phone as the modality of online data transmission through the internet network. The prototype of an electronic stethoscope uses condenser mic, pre-amplifier, wide bandpass filter (20 Hz-1 KHz) and audio amplifier. The maximum gain is 28.63 dB in the 20 Hz-690 Hz frequency range. The signal output can be connected to the android mobile through the jacked phone to be stored in MP3 format and then sent to the cloud server for further monitoring and analysis. The application called \u201cSteder\u201d supports realtime communication between patient and physician for medical check-up, consultation, and discussion activities. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The stethoscope is a piece of medical standard equipment that isused by a physician for an initial examination of the patient. Generally, the stethoscope is used for auscultating sounds which are generated by the workings of organ systems such as cardiac, lung or digestive. In the present condition with the growing number of the patient population, it has an impact on the burden of hospitals and medical practitioners. So that treatment is not optimal, especially patients who need continuous monitoring. Thus it needs a system that can work dynamically, flexibly and remotely based. This paper focuses on the implementation of the electronic stethoscope which is integrated with a mobile phone as the modality of online data transmission through the internet network. The prototype of an electronic stethoscope uses condenser mic, pre-amplifier, wide bandpass filter (20 Hz-1 KHz) and audio amplifier. The maximum gain is 28.63 dB in the 20 Hz-690 Hz frequency range. The signal output can be connected to the android mobile through the jacked phone to be stored in MP3 format and then sent to the cloud server for further monitoring and analysis. The application called \u201cSteder\u201d supports realtime communication between patient and physician for medical check-up, consultation, and discussion activities. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Performance Analysis of On-Off Keying Modulation on Underwater Visible Light Communication"
        ],
        "penulis":"Amalia, Annisa Izmi;Hambali, Akhmad;Pamukti, Brian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research evaluates the performance of On-Off Keying (OOK) Modulation on the Underwater Visible Light Communication (UVLC) system. This research analyses the performance of two types of OOK signal formats, Non-Return to Zero (OOK-NRZ) and Return to Zero (OOK-RZ). This signal formats tested on distance, acceptability, Signal to Noise Ratio (SNR), Q-factor and Bit Error Rate (BER) parameters. From extensive simulations that have been done, the results show that the received power decreased 21.7249 % at the maximum distance. In this condition, the UVLC system produced the BER value of the NRZ format 3.28 \u00d7 smaller than the RZ format. The SNR minimum that produced BER value less than the threshold for NRZ format is 17.925% smaller than the RZ format. Meanwhile, the minimum Q-factor that produced BER value less than 10-3for NRZ modulation is 6 \u00d7 smaller than the RZ modulation format. From the results, we take the conclusion that the OOK-NRZ better than OOK-RZ on the UVLC system. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research evaluates the performance of On-Off Keying (OOK) Modulation on the Underwater Visible Light Communication (UVLC) system. This research analyses the performance of two types of OOK signal formats, Non-Return to Zero (OOK-NRZ) and Return to Zero (OOK-RZ). This signal formats tested on distance, acceptability, Signal to Noise Ratio (SNR), Q-factor and Bit Error Rate (BER) parameters. From extensive simulations that have been done, the results show that the received power decreased 21.7249 % at the maximum distance. In this condition, the UVLC system produced the BER value of the NRZ format 3.28 \u00d7 smaller than the RZ format. The SNR minimum that produced BER value less than the threshold for NRZ format is 17.925% smaller than the RZ format. Meanwhile, the minimum Q-factor that produced BER value less than 10-3for NRZ modulation is 6 \u00d7 smaller than the RZ modulation format. From the results, we take the conclusion that the OOK-NRZ better than OOK-RZ on the UVLC system. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "High Throughput Satellite using Ka-Band for Government Multifunctional Services in Indonesia: Study of Link Budget and Capacity Analysis"
        ],
        "penulis":"Kristiadi, Ignatius Daru;Nashiruddin, Muhammad Imam;Sudjai, Miftadi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Satellite infrastructure has a vital role in delivering communication services throughout Indonesia as one of the biggest archipelagic countries in the world. The high throughput satellite (HTS) can be the best choice considering the uneven distribution of terrestrial infrastructure networks, especially in the corners and isolated areas of Indonesia. In this paper, a study is conducted related to link budget and capacity analysis on the high throughput satellite using the proposed Ka-band frequency plan. The purpose of this study is to find out how far the link capability and capacity can be provided by HTS if it is operating in the proposed Ka-band frequency plan associated with Indonesia's environmental conditions. The result of this study on link budget analysis shows that using its Ka-Band frequency plan as the proposed assigned frequency is suitable and feasible to be implemented in the near future of the HTS system for government multifunctional services over Indonesia. It is indicated by the positive value of C\/N obtained from link budget analysis for each link of each scenario in this research. Besides that, the estimation for capacity analysis of communication that is able to be provided by its HTS is enormous enough to handle the data services needs over Indonesia, which is 38.41-93.54 Gbps depends on environment condition. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Satellite infrastructure has a vital role in delivering communication services throughout Indonesia as one of the biggest archipelagic countries in the world. The high throughput satellite (HTS) can be the best choice considering the uneven distribution of terrestrial infrastructure networks, especially in the corners and isolated areas of Indonesia. In this paper, a study is conducted related to link budget and capacity analysis on the high throughput satellite using the proposed Ka-band frequency plan. The purpose of this study is to find out how far the link capability and capacity can be provided by HTS if it is operating in the proposed Ka-band frequency plan associated with Indonesia's environmental conditions. The result of this study on link budget analysis shows that using its Ka-Band frequency plan as the proposed assigned frequency is suitable and feasible to be implemented in the near future of the HTS system for government multifunctional services over Indonesia. It is indicated by the positive value of C\/N obtained from link budget analysis for each link of each scenario in this research. Besides that, the estimation for capacity analysis of communication that is able to be provided by its HTS is enormous enough to handle the data services needs over Indonesia, which is 38.41-93.54 Gbps depends on environment condition. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Life Cycle Cost Analysis in Construction of Green Building Concept, A Case Study"
        ],
        "penulis":"Kamaralo M.K.;Alhilman J.;Atmaji F.T.D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Based on data from the Green Building Council of Indonesia, more than one-third of CO2gas emissions worldwide are generated by buildings, it has an impact on the environment such as global warming, ozone layer depletion, and accumulation of waste. The concept of Green Building is considered very necessary to overcome global warming and improve energy and resource efficiency. In the process of building a building that is Green Building requires a relatively high cost when compared to conventional buildings. Therefore, the Life Cycle Cost (LCC) method is used to determine the total cost needed, the optimal cost of the building, the economic age of the building, the number of crew maintenance and the level of energy efficiency. The analysis using the Life Cycle Cost method requires several related costs such as Initial Costs, Maintenance Costs, Energy Costs, Replacement Costs, and Utility Costs. The analysis was conducted using the Present Worth method within a period of 8 years from the start of building construction. Based on data processing using the Life Cycle Cost method, the optimal cost of a green building concept building is IDR 232, 296, 615, 337 with the economic life of the building being 8 years, the optimal number of maintenance crews is 1 person and the level of energy consumption intensity is very efficient. \u00a9 Published under licence by IOP Publishing Ltd.",
            "OOOView detailsExpand Substance ozone",
            "Powered by",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Decent work and economic growthGoal 8Responsible consumption and productionGoal 12Climate actionGoal 13Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Based on data from the Green Building Council of Indonesia, more than one-third of CO2gas emissions worldwide are generated by buildings, it has an impact on the environment such as global warming, ozone layer depletion, and accumulation of waste. The concept of Green Building is considered very necessary to overcome global warming and improve energy and resource efficiency. In the process of building a building that is Green Building requires a relatively high cost when compared to conventional buildings. Therefore, the Life Cycle Cost (LCC) method is used to determine the total cost needed, the optimal cost of the building, the economic age of the building, the number of crew maintenance and the level of energy efficiency. The analysis using the Life Cycle Cost method requires several related costs such as Initial Costs, Maintenance Costs, Energy Costs, Replacement Costs, and Utility Costs. The analysis was conducted using the Present Worth method within a period of 8 years from the start of building construction. Based on data processing using the Life Cycle Cost method, the optimal cost of a green building concept building is IDR 232, 296, 615, 337 with the economic life of the building being 8 years, the optimal number of maintenance crews is 1 person and the level of energy consumption intensity is very efficient. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Real Time Video Analytics Based on Deep Learning and Big Data for Smart Station"
        ],
        "penulis":"Hidayat F.;Hamami F.;Dahlan I.A.;Supangkat S.H.;Fadillah A.;Hidayatuloh A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "CCTV is a sophisticated tool for monitoring and surveillance. It was chosen because of the low price and ease of use. CCTV creates issues in monitoring because officers must always supervise every CCTV monitor to look for abnormal conditions. This research proposes the implementation of smart CCTV for surveillance in Bandung Station. It applied deep learning algorithm to create smart CCTV for sensing and understanding station environment such as passengers' flow, crowded area, prohibited location and others. Big data technologies are also carried out to solve the complexity of data. The objective of this research is to improve the quality of services in Bandung Station and make the station safer, more secure and more convenient. \u00a9 2020 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "CCTV is a sophisticated tool for monitoring and surveillance. It was chosen because of the low price and ease of use. CCTV creates issues in monitoring because officers must always supervise every CCTV monitor to look for abnormal conditions. This research proposes the implementation of smart CCTV for surveillance in Bandung Station. It applied deep learning algorithm to create smart CCTV for sensing and understanding station environment such as passengers' flow, crowded area, prohibited location and others. Big data technologies are also carried out to solve the complexity of data. The objective of this research is to improve the quality of services in Bandung Station and make the station safer, more secure and more convenient. \u00a9 2020 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Identification of the changing air temperature and rainfall in Bogor"
        ],
        "penulis":"Hidayat, Rahmat;Farihah, Alfi Wardah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Climate datasets were analyzed to identify the changing climatic parameters and extreme events in Bogor, West Java. This study aims to analyze the characteristic of observational datasets in Baranangsiang and Dramaga, namely, air temperature and rainfall, and to identify the changing structure of those climate parameters. The analysis has been conducted using RClimdex to understand the long-term changing air temperature and rainfall based on 10 indices for air temperature and 8 indices for temperature and rainfall. Results show that the rainfall in Baranangsiang has a daily mean of 10 mm\/day and in Dramaga of 8 mm\/day. The daily mean air temperature in Baranangsiang and Dramaga is 27\u02daC and 25.5\u02daC, respectively. Generally, the declined slopes of the temperature indices in Barangsiang, namely, TN90p, TNx, TX10p, TNn, TXn, TR20, and SU25, indicate cooler temperature. In Dramaga, the increased temperature indices, namely, TN90p, TX90p, TXx, SU25, and TXn, indicate the warmer temperature. The rainfall indices generally decline, except for consecutive dry days (CDD), which indicate the increased consecutive dry days in Baranangsiang. \u00a9 2020, Pusat Penelitian Lingkungan Hidup - Lembaga Penelitian dan Pengabdian Kepada Masyarakat Institut Pertanian Bogor (PPLH-LPPM IPB). All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Climate datasets were analyzed to identify the changing climatic parameters and extreme events in Bogor, West Java. This study aims to analyze the characteristic of observational datasets in Baranangsiang and Dramaga, namely, air temperature and rainfall, and to identify the changing structure of those climate parameters. The analysis has been conducted using RClimdex to understand the long-term changing air temperature and rainfall based on 10 indices for air temperature and 8 indices for temperature and rainfall. Results show that the rainfall in Baranangsiang has a daily mean of 10 mm\/day and in Dramaga of 8 mm\/day. The daily mean air temperature in Baranangsiang and Dramaga is 27\u02daC and 25.5\u02daC, respectively. Generally, the declined slopes of the temperature indices in Barangsiang, namely, TN90p, TNx, TX10p, TNn, TXn, TR20, and SU25, indicate cooler temperature. In Dramaga, the increased temperature indices, namely, TN90p, TX90p, TXx, SU25, and TXn, indicate the warmer temperature. The rainfall indices generally decline, except for consecutive dry days (CDD), which indicate the increased consecutive dry days in Baranangsiang. \u00a9 2020, Pusat Penelitian Lingkungan Hidup - Lembaga Penelitian dan Pengabdian Kepada Masyarakat Institut Pertanian Bogor (PPLH-LPPM IPB). All rights reserved."
        ]
    },
    {
        "judul":[
            "Digital Literacy Education In The Industrial Revolution 4.0 In Alquran Primary School Students"
        ],
        "penulis":"RINA, NOFHA;SUMINAR, JENNY RATNA;DAMAYANI, NINIS AGUSTINI;HAFIAR, HANNY;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The development of the world at this time has entered the era of the industrial revolution 4.0 and has an effect on human life based on information. Elementary school students as alpha generation or internet generation are users who are familiar and very dependent on technology especially with social media. Research on digital literacy is still rare, especially in Indonesia. The subjects of this study are students aged 11-12 years who are active users of social media. This research uses a qualitative approach with a case study method. The informants used as the sample of the study were five people and one key informant from a media literacy expert. The findings in this study indicate the importance of digital literacy education which has a positive impact on knowledge, understanding and skills in using social media that is currently used as a source of information and entertainment by the public, especially among the alpha generation that can bring about awareness in using social media. In this study, not all participants had the skills to use social media properly. So digital literacy education is a solution that can be done by the government and elements of society and academics who care about the progress of the nation. \u00a9 2020. All Rights Reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of the world at this time has entered the era of the industrial revolution 4.0 and has an effect on human life based on information. Elementary school students as alpha generation or internet generation are users who are familiar and very dependent on technology especially with social media. Research on digital literacy is still rare, especially in Indonesia. The subjects of this study are students aged 11-12 years who are active users of social media. This research uses a qualitative approach with a case study method. The informants used as the sample of the study were five people and one key informant from a media literacy expert. The findings in this study indicate the importance of digital literacy education which has a positive impact on knowledge, understanding and skills in using social media that is currently used as a source of information and entertainment by the public, especially among the alpha generation that can bring about awareness in using social media. In this study, not all participants had the skills to use social media properly. So digital literacy education is a solution that can be done by the government and elements of society and academics who care about the progress of the nation. \u00a9 2020. All Rights Reserved."
        ]
    },
    {
        "judul":[
            "Impact of employee satisfaction on work discipline in government office in indonesia"
        ],
        "penulis":"Iskamto, Dedi;Karim, Kurniati;Sukono;Bon, Abdul Talib;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study was to determine the effect of job satisfaction on the work discipline of government employees in the district office. The population in this study were all employees at the Pangkalan Kerinci sub-district office Riau Province, Indonesia. This study is a quantitative study, data analysis using SPSS 23. The results of research with the t-test, t-value (8.297) is greater than t-table (2.021). So it was concluded that Ha was accepted and H0 was rejected, so the hypothesis that there was a significant relationship between job satisfaction and employee work discipline at the Pangkalan Kerinci sub-district office was acceptable. While the R2test was 61.6%, while 38.4% was influenced by other factors not examined in this study. This means that job satisfaction has a significant influence on the work discipline of government employees. \u00a9 IEOM Society International.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study was to determine the effect of job satisfaction on the work discipline of government employees in the district office. The population in this study were all employees at the Pangkalan Kerinci sub-district office Riau Province, Indonesia. This study is a quantitative study, data analysis using SPSS 23. The results of research with the t-test, t-value (8.297) is greater than t-table (2.021). So it was concluded that Ha was accepted and H0 was rejected, so the hypothesis that there was a significant relationship between job satisfaction and employee work discipline at the Pangkalan Kerinci sub-district office was acceptable. While the R2test was 61.6%, while 38.4% was influenced by other factors not examined in this study. This means that job satisfaction has a significant influence on the work discipline of government employees. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "Design of intelligent algorithm based air volume control system for central air conditioning"
        ],
        "penulis":"Niu, Min;Le, Quoc Tien;Saedudin, Rd Rohmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research aims to analyze the optimization value of intelligent control algorithm in the design of automatic variable air volume control system of central air conditioning, to improve the technology of central air conditioning and reduce the energy consumption of air conditioning. In this research, starting from analyzing the operation characteristics of variable air volume system of central air conditioning, a controller based on fuzzy intelligent control algorithm is proposed, and a terminal controller model based on intelligent control algorithm is established to design a new variable air volume automatic control system for central air conditioning. Besides, its performance is compared with that of central air conditioning system based on traditional proportion integration differentiation (PID) control algorithm. The results show that the automatic variable air volume control system of central air conditioning designed in this research based on the intelligent control algorithm has better energy saving effect. The application of fuzzy intelligent control algorithm improves the performance of the control system, reduces the power consumption of the central air-conditioning system, and optimizes the energy utilization efficiency. In this study, the intelligent control technology has been expanded to the national call for energy conservation and emission reduction, and the application of intelligent control algorithm to the variable air volume control system of central air conditioning has important practical significance, laying a foundation for the development of follow-up high-performance air conditioning system. \u00a9 2020, Cefin Publishing House. All rights reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document"
        ],
        "abstrak":[
            "This research aims to analyze the optimization value of intelligent control algorithm in the design of automatic variable air volume control system of central air conditioning, to improve the technology of central air conditioning and reduce the energy consumption of air conditioning. In this research, starting from analyzing the operation characteristics of variable air volume system of central air conditioning, a controller based on fuzzy intelligent control algorithm is proposed, and a terminal controller model based on intelligent control algorithm is established to design a new variable air volume automatic control system for central air conditioning. Besides, its performance is compared with that of central air conditioning system based on traditional proportion integration differentiation (PID) control algorithm. The results show that the automatic variable air volume control system of central air conditioning designed in this research based on the intelligent control algorithm has better energy saving effect. The application of fuzzy intelligent control algorithm improves the performance of the control system, reduces the power consumption of the central air-conditioning system, and optimizes the energy utilization efficiency. In this study, the intelligent control technology has been expanded to the national call for energy conservation and emission reduction, and the application of intelligent control algorithm to the variable air volume control system of central air conditioning has important practical significance, laying a foundation for the development of follow-up high-performance air conditioning system. \u00a9 2020, Cefin Publishing House. All rights reserved."
        ]
    },
    {
        "judul":[
            "Throughput-Maximum Energy-Aware Rate Adaptation in W-NCSs over Quasi-Static Fading Channels"
        ],
        "penulis":"Royyan, Muhammad;Vehkapera, Mikko;Charalambous, Themistoklis;Wichman, Risto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, we consider a wireless networked control system (W-NCS) and seek to optimize the performance of the system by adapting the transmission throughput of the communication link, which is assumed to be a quasi-static fading channel. Towards this end, an optimization problem is formulated and solved, herein called Maximum Throughput with Energy Constraints (MaxTEC), in which the optimal achievable throughput is selected subject to the limited available energy per transmission. It is demonstrated that the larger the available energy, the higher the throughput, and, subsequently, the better the control performance. The performance of our proposed scheme is illustrated via simulations of an inverted pendulum on a cart. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we consider a wireless networked control system (W-NCS) and seek to optimize the performance of the system by adapting the transmission throughput of the communication link, which is assumed to be a quasi-static fading channel. Towards this end, an optimization problem is formulated and solved, herein called Maximum Throughput with Energy Constraints (MaxTEC), in which the optimal achievable throughput is selected subject to the limited available energy per transmission. It is demonstrated that the larger the available energy, the higher the throughput, and, subsequently, the better the control performance. The performance of our proposed scheme is illustrated via simulations of an inverted pendulum on a cart. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Social Media Technology Adoption for Improving MSMEs Performance in Bandung: A Technology-Organization-Environment (TOE) Framework"
        ],
        "penulis":"Wulandari, Astri;Suryawardani, Bethani;Marcelino, Dandy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The use of the internet in business activities is a common thing to do in business world. Likewise, with MSMEs, many of them have already used the internet in their business activities. City and Regency of Bandung are the two regions that experience the best MSMEs growth in West Java. This is because these two regions are included in the position of three regions with the largest number of MSMEs in West Java. In addition, the two regions consistently won the achievement as five regions in West Java with the best financial performance measured by the ratio of cost to income. This study is expected to provide several implications related to social media technology adoption with determinant factors of TOE (technology, organization, environment) to improve the business performance of MSMEs. Researchers used quantitative research methods namely causal, with SEM (Structural Equation Model) analysis techniques by SMART PLS 2.0 software. The sampling technique chosen is accidental with a total of 400 respondents. Finding from this research which technology, organization, and environment are the factors that encourage MSMEs in adopting social media, then will impact the performance of MSMEs which include customer services, sales, marketing, and internal operations. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of the internet in business activities is a common thing to do in business world. Likewise, with MSMEs, many of them have already used the internet in their business activities. City and Regency of Bandung are the two regions that experience the best MSMEs growth in West Java. This is because these two regions are included in the position of three regions with the largest number of MSMEs in West Java. In addition, the two regions consistently won the achievement as five regions in West Java with the best financial performance measured by the ratio of cost to income. This study is expected to provide several implications related to social media technology adoption with determinant factors of TOE (technology, organization, environment) to improve the business performance of MSMEs. Researchers used quantitative research methods namely causal, with SEM (Structural Equation Model) analysis techniques by SMART PLS 2.0 software. The sampling technique chosen is accidental with a total of 400 respondents. Finding from this research which technology, organization, and environment are the factors that encourage MSMEs in adopting social media, then will impact the performance of MSMEs which include customer services, sales, marketing, and internal operations. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Utilization of Internet of Thing and Social Media in Designing a Smart System for Identification Pollution Quality of Air, Water, and Temperature"
        ],
        "penulis":"Saputra, Muhardi;Witjaksono, R. Wahjoe;Puspitasari, Warih;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The problem of pollution in big cities is one form of social issues. Natural sources and human activities can cause air pollution. Classification of air pollutants is divided into two, the first is a primary pollutant that is a pollutant which is generated directly from the source of air pollution, and the second is a secondary pollutant that is a pollutant that occurs from primary reactions in the atmosphere. The nature of air causes the effects of air pollution can be direct and local, regional, and global. Air pollution can endanger the health of humans, animals, and plants, disrupt aesthetics and comfort, or damage property. To overcome this social problem, the Government has regulated in Government Regulation Number 41 of 1999 concerning Air Pollution Control. Cooperation is needed for all relevant stakeholders and the community to overcome these social problems. Current conditions both the Government and the public are difficult to find out information about air quality in the surrounding environment, so the role of community functions is very limited in anticipating and overcoming the problem of air pollution. Based on these problems, Machine-to-Machine (M2M) technology and social media networks Twitter can be used as a medium for disseminating information about air quality to trigger public awareness of the condition of air pollution in the surrounding environment and increase the role of community functions in tackling the problem of air pollution.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The problem of pollution in big cities is one form of social issues. Natural sources and human activities can cause air pollution. Classification of air pollutants is divided into two, the first is a primary pollutant that is a pollutant which is generated directly from the source of air pollution, and the second is a secondary pollutant that is a pollutant that occurs from primary reactions in the atmosphere. The nature of air causes the effects of air pollution can be direct and local, regional, and global. Air pollution can endanger the health of humans, animals, and plants, disrupt aesthetics and comfort, or damage property. To overcome this social problem, the Government has regulated in Government Regulation Number 41 of 1999 concerning Air Pollution Control. Cooperation is needed for all relevant stakeholders and the community to overcome these social problems. Current conditions both the Government and the public are difficult to find out information about air quality in the surrounding environment, so the role of community functions is very limited in anticipating and overcoming the problem of air pollution. Based on these problems, Machine-to-Machine (M2M) technology and social media networks Twitter can be used as a medium for disseminating information about air quality to trigger public awareness of the condition of air pollution in the surrounding environment and increase the role of community functions in tackling the problem of air pollution.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Stock price modeling using localized multiple kernel learning support vector machine"
        ],
        "penulis":"Yasin, Hasbi;Caraka, Rezzy Eko;Hoyyi, Abdul;Sugito;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Effectively and efficiently learning an optimal kernel is of great importance to the success of kernel method. Along with this line of research, many pioneering kernel learning algorithms have been proposed, developed and combined in many ways. This paper aims to explain the application of Localized Multiple Kernel Learning Support Vector Machine (LMKL-SVM) to predict the daily stock price of PT.XL Axiata Tbk (EXCL), PT.Indofood SuksesMakmur Tbk (INDF) and PT.Unilever Indonesia Tbk (UNVR) from January 2014 to May 2016. It can be concluded that LMKL-SVM has good performance to predict daily stock price with Mean Absolute Percentage Error (MAPE) produced all less than 2%. \u00a9 2020 ICIC International.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Effectively and efficiently learning an optimal kernel is of great importance to the success of kernel method. Along with this line of research, many pioneering kernel learning algorithms have been proposed, developed and combined in many ways. This paper aims to explain the application of Localized Multiple Kernel Learning Support Vector Machine (LMKL-SVM) to predict the daily stock price of PT.XL Axiata Tbk (EXCL), PT.Indofood SuksesMakmur Tbk (INDF) and PT.Unilever Indonesia Tbk (UNVR) from January 2014 to May 2016. It can be concluded that LMKL-SVM has good performance to predict daily stock price with Mean Absolute Percentage Error (MAPE) produced all less than 2%. \u00a9 2020 ICIC International."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "What Users Want for Gig Economy Platforms: Sentiment Analysis Approach"
        ],
        "penulis":"Indrawan, Nadina Adelia;Sucahyo, Yudho Giri;Ruldeviyani, Yova;Gandhi, Arfive;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Gig economy-based mobile applications are increasingly in demand by the public. An increment in the number of users rises the number of downloads and reviews. However, the number of reviews makes it difficult for developers to understand the information contained in reviews. Besides, one review can have a variety of information. This study proposes a model that can categorize content and sentiment reviews using Support Vector Machine (SVM), Multinomial Na\u00efve Bayes, Complement Na\u00efve Bayes classifier, and Binary Relevance, Classifier Chain, and Label Power Sets as the data transformation method. This study used the reviews contained in the Gojek, Sampingan, and Ruang Guru applications, with 10, 123 reviews. This study found the review text's length influenced accuracy based on the evaluation of Gojek application. Generally, this study results showed that the SVM algorithm (both in the classification of sentiment reviews and review categorization) and Label Power Sets as the transformation method, yielded the best accuracy. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Gig economy-based mobile applications are increasingly in demand by the public. An increment in the number of users rises the number of downloads and reviews. However, the number of reviews makes it difficult for developers to understand the information contained in reviews. Besides, one review can have a variety of information. This study proposes a model that can categorize content and sentiment reviews using Support Vector Machine (SVM), Multinomial Na\u00efve Bayes, Complement Na\u00efve Bayes classifier, and Binary Relevance, Classifier Chain, and Label Power Sets as the data transformation method. This study used the reviews contained in the Gojek, Sampingan, and Ruang Guru applications, with 10, 123 reviews. This study found the review text's length influenced accuracy based on the evaluation of Gojek application. Generally, this study results showed that the SVM algorithm (both in the classification of sentiment reviews and review categorization) and Label Power Sets as the transformation method, yielded the best accuracy. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design of Defect Classification on Clay Tiles using Support Vector Machine (SVM)"
        ],
        "penulis":"Prasetio, Murman Dwi;Rifai, Mohammad Husain;Xavierullah, Rais Yufli;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The current industry has been developing rapidly which make the company must have high competitiveness by maintaining the product's quality and quantity produced by the company. PT. XYZ is one of the companies in the clay tile industry. There are classifications of PT. XYZ products: Good tile, white stone tile, and cracked tile in quality control. During its classification, PT XYZ still uses the traditional method of vision. The traditional detection of errors or defects only using human vision can slow down the process and increase the error rate. With the rapid development of automation can overcome this by the discovery of artificial visual detectors that use measurement methods, image preprocessing, and algorithms in detecting these defects. In this study using the Support Vector Machine (SVM) method for classifying defects and Local Binary Pattern (LBP) method for extracting the feature on tiles. Direct image taking in this study use raspberry pi and create the algorithm system using python software. The results of this study concluded that the highest level of accuracy was 87.5% using linear kernels. While the required time for direct classification is 10.63 seconds.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The current industry has been developing rapidly which make the company must have high competitiveness by maintaining the product's quality and quantity produced by the company. PT. XYZ is one of the companies in the clay tile industry. There are classifications of PT. XYZ products: Good tile, white stone tile, and cracked tile in quality control. During its classification, PT XYZ still uses the traditional method of vision. The traditional detection of errors or defects only using human vision can slow down the process and increase the error rate. With the rapid development of automation can overcome this by the discovery of artificial visual detectors that use measurement methods, image preprocessing, and algorithms in detecting these defects. In this study using the Support Vector Machine (SVM) method for classifying defects and Local Binary Pattern (LBP) method for extracting the feature on tiles. Direct image taking in this study use raspberry pi and create the algorithm system using python software. The results of this study concluded that the highest level of accuracy was 87.5% using linear kernels. While the required time for direct classification is 10.63 seconds.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Comparison between client-side and server-side rendering in the web development"
        ],
        "penulis":"Fadhilah Iskandar, Taufan;Lubis, Muharman;Fabrianti Kusumasari, Tien;Ridho Lubis, Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Mandatory servers for universal applications that is accessible to number of users may be a deterrent for the corporation and excessive for small applications even though it could bring the compatibility advantages. Knowing that demand of web application increases to provide convenience and ease of use to the users, client side rendering comes to create software more fast and efficient. It has been done by redirecting the request towards an HTML file then the server will give messages without any content or a loading screen until the device takes all JavaScript to allow the browser compiling everything before displaying the content. Therefore, the purpose of this paper is to analyse the comparison between client side and server side method in the respect of technical aspects in term of first content paint, speed index, time to interactive, first meaningful paint, first idle CPU and estimated input latency that present better performance with 2.1s, 2.0s, 2.2s, 2.1s, 2.2s and 20ms respectively on server side. It also provide better result based on Google Audit with 100% performance, 48% accessibility, 93% best practice and 89% of search engine optimization (SEO). \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Mandatory servers for universal applications that is accessible to number of users may be a deterrent for the corporation and excessive for small applications even though it could bring the compatibility advantages. Knowing that demand of web application increases to provide convenience and ease of use to the users, client side rendering comes to create software more fast and efficient. It has been done by redirecting the request towards an HTML file then the server will give messages without any content or a loading screen until the device takes all JavaScript to allow the browser compiling everything before displaying the content. Therefore, the purpose of this paper is to analyse the comparison between client side and server side method in the respect of technical aspects in term of first content paint, speed index, time to interactive, first meaningful paint, first idle CPU and estimated input latency that present better performance with 2.1s, 2.0s, 2.2s, 2.1s, 2.2s and 20ms respectively on server side. It also provide better result based on Google Audit with 100% performance, 48% accessibility, 93% best practice and 89% of search engine optimization (SEO). \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Development of XGS-PON Optical Line Termination Equipment Standardization for Broadband Fiber Access Networks in Indonesia"
        ],
        "penulis":"Solihah, Nomarhinta;Nashiruddin, Muhammad Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "XGS-PON is the promising technology for broadband fiber access network provider due to the capability of sending 10 Gbps for downstream and upstream directions and can be implemented along with existing PON networks. Another advantage is meeting the high bandwidth demand for services such as HDTV, M2M, and the Internet of Everything. Although it has begun to be widely implemented, the regulation of telecommunications equipment standards in Indonesia for Passive Optical Networks (PON) is currently limited to G-PON and E-PON technology. This study aims to provide a reference to the technical specifications of the OLT XGS-PON for improving existing PON regulations. This study's technical requirements are the capability of nominal rate, wavelength range, and IGMP multicast group from the OLT XGS-PON device. The research obtained a reference to the nominal rate of XGS-PON with FEC at 8.5 Gbps for bidirectional service, the upstream wavelength range at 1260-1280 nm, the downstream wavelength range at 1575-1580 nm, and IGMP multicast group capability was 4096 groups in IPv4 network. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "XGS-PON is the promising technology for broadband fiber access network provider due to the capability of sending 10 Gbps for downstream and upstream directions and can be implemented along with existing PON networks. Another advantage is meeting the high bandwidth demand for services such as HDTV, M2M, and the Internet of Everything. Although it has begun to be widely implemented, the regulation of telecommunications equipment standards in Indonesia for Passive Optical Networks (PON) is currently limited to G-PON and E-PON technology. This study aims to provide a reference to the technical specifications of the OLT XGS-PON for improving existing PON regulations. This study's technical requirements are the capability of nominal rate, wavelength range, and IGMP multicast group from the OLT XGS-PON device. The research obtained a reference to the nominal rate of XGS-PON with FEC at 8.5 Gbps for bidirectional service, the upstream wavelength range at 1260-1280 nm, the downstream wavelength range at 1575-1580 nm, and IGMP multicast group capability was 4096 groups in IPv4 network. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance assessment analysis of UHF machines using Reliability, Availability, Maintainability and Safety (RAMS) analysis methods"
        ],
        "penulis":"Nurrahman F.;Atmaji F.T.D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "XYZ Company is manufacturing engaged in the rubber industry located in the city of Bandung, because economic growth and demand from consumers are increasing, making companies demanded to meet the target orders promptly. One way to minimize losses and the possibilities that must be borne by the company is to increase Reliability, Availability, Maintainability of the production and the safety value. Data in the form of Mean Downtime, Mean Time to Failure, Mean Time to Repair is useful for system performance that works. MTTF data can be used to assess safety systems found in PT XYZ with the safety standards of IEC 61508 using Safety Integrity Level. From the results of processing RAMS data using Reliability Block Diagram modeling based on the analytical approach, for 120 hours, the system has a Reliability value (91.12%). The average value of system Maintainability at t = 2 hours is 100%. The Inherent Availability value is 99,981% and the Operational Availability value is 99,980%. Based on the world-class maintenance Key Performace Indicator, leading and lagging availability indicators have reached the indicator target standard. Safety Integrity Level values from calculations based on PFD and RRF values of each system are in SIL 1. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "XYZ Company is manufacturing engaged in the rubber industry located in the city of Bandung, because economic growth and demand from consumers are increasing, making companies demanded to meet the target orders promptly. One way to minimize losses and the possibilities that must be borne by the company is to increase Reliability, Availability, Maintainability of the production and the safety value. Data in the form of Mean Downtime, Mean Time to Failure, Mean Time to Repair is useful for system performance that works. MTTF data can be used to assess safety systems found in PT XYZ with the safety standards of IEC 61508 using Safety Integrity Level. From the results of processing RAMS data using Reliability Block Diagram modeling based on the analytical approach, for 120 hours, the system has a Reliability value (91.12%). The average value of system Maintainability at t = 2 hours is 100%. The Inherent Availability value is 99,981% and the Operational Availability value is 99,980%. Based on the world-class maintenance Key Performace Indicator, leading and lagging availability indicators have reached the indicator target standard. Safety Integrity Level values from calculations based on PFD and RRF values of each system are in SIL 1. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Web-Based Application of Reliability Availability Maintainability and Cost of Unreliability Method to Analyze Performance of the Machine"
        ],
        "penulis":"Alhilman, Judi;Habibie, Muhammad Fadhil;Tripiawan, Wawan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Maintenance is important to do in order to maintain or improve the function of the equipment to work optimally. One factor that support the maintenance activities is machine reliability. Higher reliability can reduces process costs. Conversely, engine failure can reduce production output also the business benefits for the community. In business terms, the problem of controlling the Cost of Unreliability (COUR) of equipment and process failure is just a waste of money. Unreliable index costs are simple and practical reliability tools for converting failure data into costs. A long stage in manual calculation of COUR and RAM analysis with more than one applications used as work tool, therefore designed a web-based application with more complete features that can be used to analyze COUR and RAM. This application will simplify the calculation process, analysis, and results management, so it will helps maintenance analysts in doing their work. This application can determine the maintenance policy, predict the performance of machine's reliability, availability and maintenance capabilities. As well as calculating costs from reliability issues. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Maintenance is important to do in order to maintain or improve the function of the equipment to work optimally. One factor that support the maintenance activities is machine reliability. Higher reliability can reduces process costs. Conversely, engine failure can reduce production output also the business benefits for the community. In business terms, the problem of controlling the Cost of Unreliability (COUR) of equipment and process failure is just a waste of money. Unreliable index costs are simple and practical reliability tools for converting failure data into costs. A long stage in manual calculation of COUR and RAM analysis with more than one applications used as work tool, therefore designed a web-based application with more complete features that can be used to analyze COUR and RAM. This application will simplify the calculation process, analysis, and results management, so it will helps maintenance analysts in doing their work. This application can determine the maintenance policy, predict the performance of machine's reliability, availability and maintenance capabilities. As well as calculating costs from reliability issues. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Lip Motion Recognition for Indonesian Vowel Phonemes Using 3D Convolutional Neural Networks"
        ],
        "penulis":"Maxalmina;Kahfi, Satria;Ramadhani, Kurniawan Nur;Arifianto, Anditya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Lip motion recognition is a technique for interpreting visual data that focuses on the mouth area and aims to recognize lip movement. The development of lip motion recognition is expected to be used to develop communication tools with deaf people and to automate the speech-to-text process visually. In the Indonesian language, the existence of vowel phonemes is needed to produce sounds so that words and sentences in the Indonesian language can be formed. This paper proposes a model that can recognize Indonesian vowel phonemes (\/a\/,\/i\/,\/u\/,\/e\/, and\/o\/) in lip movements. We proposed a model that uses 3D Convolutional Neural Networks. The data in this paper were processed by resizing into 112x56 pixel resolution then, proceed to the data augmentation by reversing the data horizontally and add blur to the data. The results of the testing of the vowel phoneme recognition model on lip motion show the highest accuracy rate of 84%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Lip motion recognition is a technique for interpreting visual data that focuses on the mouth area and aims to recognize lip movement. The development of lip motion recognition is expected to be used to develop communication tools with deaf people and to automate the speech-to-text process visually. In the Indonesian language, the existence of vowel phonemes is needed to produce sounds so that words and sentences in the Indonesian language can be formed. This paper proposes a model that can recognize Indonesian vowel phonemes (\/a\/,\/i\/,\/u\/,\/e\/, and\/o\/) in lip movements. We proposed a model that uses 3D Convolutional Neural Networks. The data in this paper were processed by resizing into 112x56 pixel resolution then, proceed to the data augmentation by reversing the data horizontally and add blur to the data. The results of the testing of the vowel phoneme recognition model on lip motion show the highest accuracy rate of 84%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Speech recognition implementation using MFCC and DTW algorithm for home automation"
        ],
        "penulis":"Haq, Abdulloh Salahul;Nasrun, Muhammad;Setianingsih, Casi;Murti, Muhammad Ary;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The use of speech recognition as part of home automation, especially for smart homes, is an exciting thing that is still being developed. That is because of human needs for comfort, convenience, quality of life, and better safety. Speech recognition built in this study is used as a device to control smart home devices by identifying the commands spoken by users, especially in a state of clean speech. The command used is a predetermined consecutive word. For the extraction of voice commands, the MFCC algorithm is used to match spoken words with templates using the Dynamic Time Warping (DTW) algorithm. DTW algorithm can find the difference between 2-time series that have different lengths of time. The results of the accuracy of this system by using these algorithms were successfully carried out by 86.67%, with an average time required to identify the commands of 5.28 seconds. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The use of speech recognition as part of home automation, especially for smart homes, is an exciting thing that is still being developed. That is because of human needs for comfort, convenience, quality of life, and better safety. Speech recognition built in this study is used as a device to control smart home devices by identifying the commands spoken by users, especially in a state of clean speech. The command used is a predetermined consecutive word. For the extraction of voice commands, the MFCC algorithm is used to match spoken words with templates using the Dynamic Time Warping (DTW) algorithm. DTW algorithm can find the difference between 2-time series that have different lengths of time. The results of the accuracy of this system by using these algorithms were successfully carried out by 86.67%, with an average time required to identify the commands of 5.28 seconds. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Computer-Aided Detection (CAD) for COVID-19 based on Chest X-Ray Images using Convolutional Neural Network"
        ],
        "penulis":"Pratiwi, Nk Caecar;Ibrahim, Nur;Fu'adah, Yunendah Nur;Masykuroh, Kholidiyah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Covid-19 has spread throughout the world and has been declared as a pandemic by the World Health Organization (WHO). The disease was discovered by the end of 2019 in Wuhan-China. The number of deaths continues to surge sharply and spread to many countries. Covid-19 has sent billions of people on earth into lock-down when health services struggle to cope. A swift and reliable Covid-19 diagnosis system is needed, to direct the patient to the appropriate treatment and prevent the disease dissemination. During this time, we are familiar with rapid tests and Real-Time Polymerase Chain Reaction (RT-PCR) as the procedure of Covid-19 detection. Both of these procedures tend to be impractical and require specialized laboratories that are arranged in such away. It can also take several hours to wait for the amplification process until the results are known. In this study, we introduce a Covid-19 detection system based on Chest C-Ray images using Convolutional Neural Network (CNN). The dataset consists of 1000 images, 500 images each for positive Covid-19, and Pneumonia. The CNN model that was designed consisted of three hidden layers, a fully connected layer with sigmoid activation. The evaluation was conducted to determine the performance of the proposed model using matrices of precision, recall, F1, and accuracy. The experimental results show that the proposed method provides precision, recall, F1 was 1 and 100% accuracy, respectively. This research is expected to be tested in field validation, to help the medical authorities for clinical diagnosis.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Covid-19 has spread throughout the world and has been declared as a pandemic by the World Health Organization (WHO). The disease was discovered by the end of 2019 in Wuhan-China. The number of deaths continues to surge sharply and spread to many countries. Covid-19 has sent billions of people on earth into lock-down when health services struggle to cope. A swift and reliable Covid-19 diagnosis system is needed, to direct the patient to the appropriate treatment and prevent the disease dissemination. During this time, we are familiar with rapid tests and Real-Time Polymerase Chain Reaction (RT-PCR) as the procedure of Covid-19 detection. Both of these procedures tend to be impractical and require specialized laboratories that are arranged in such away. It can also take several hours to wait for the amplification process until the results are known. In this study, we introduce a Covid-19 detection system based on Chest C-Ray images using Convolutional Neural Network (CNN). The dataset consists of 1000 images, 500 images each for positive Covid-19, and Pneumonia. The CNN model that was designed consisted of three hidden layers, a fully connected layer with sigmoid activation. The evaluation was conducted to determine the performance of the proposed model using matrices of precision, recall, F1, and accuracy. The experimental results show that the proposed method provides precision, recall, F1 was 1 and 100% accuracy, respectively. This research is expected to be tested in field validation, to help the medical authorities for clinical diagnosis.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Study of the Barriers to Digital Transformation in Higher Education: A Preliminary Investigation in Indonesia"
        ],
        "penulis":"Aditya, Bayu Rima;Ferdiana, Ridi;Kusumawardani, Sri Suning;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The implementation of digital transformation has been carried out in various industrial sectors, including the higher education sector. Many countries have considered changing their education system by doing digital transformation. Although digital transformation has the potential to improve the education system, developing countries still find it difficult to reap the benefits caused by certain barriers. The purpose of this study is to investigate the barriers faced when implementing digital transformation in higher education, in this case in Indonesia. The results of the questionnaire survey ensured that of the twenty-two barriers identified based on a literature review, eleven barriers significantly affecting the implementation of digital transformation in Indonesian higher education. This study contributes by revealing initial set barriers of digital transformation in the higher education sector. The findings of this study will help identify barriers that influence the direction of decision strategies for implementing digital transformation in higher education institutions in Indonesia. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The implementation of digital transformation has been carried out in various industrial sectors, including the higher education sector. Many countries have considered changing their education system by doing digital transformation. Although digital transformation has the potential to improve the education system, developing countries still find it difficult to reap the benefits caused by certain barriers. The purpose of this study is to investigate the barriers faced when implementing digital transformation in higher education, in this case in Indonesia. The results of the questionnaire survey ensured that of the twenty-two barriers identified based on a literature review, eleven barriers significantly affecting the implementation of digital transformation in Indonesian higher education. This study contributes by revealing initial set barriers of digital transformation in the higher education sector. The findings of this study will help identify barriers that influence the direction of decision strategies for implementing digital transformation in higher education institutions in Indonesia. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation Face Recognition Attendance Monitoring System for Lab Surveillance with Hash Encryption"
        ],
        "penulis":"Hamami F.;Dahlan I.A.;Prakosa S.W.;Somantri K.F.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Face recognition (FR) is becoming popular to identify people. In fact, using the FR scheme, surveillance tasks can be built by recognizing people from their faces. This paper presents the implementation of face recognition as a biometric method for smart attendance as well as we also proposed the integrated scheme from capturing data from edge devices (CCTVs), streaming data to the dedicated server, then presenting the real-time data through android mobile devices. In this scheme, we proposed to employ deep learning algorithms based on the Convolutional Neural Network (CNN). Throughthe CCTV data streaming, faces are captured and matched with the database. Therefore, it is considered as their logging attendance. Furthermore, it is marked and stored into the database. This system prototype is developed by big data technology to tackle this complexity of data. The recognized faces can be monitored in real time monitoring. Eventually, real time reports are delivered through the web and android device with API after the data transmission is secured with hash encryption. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Face recognition (FR) is becoming popular to identify people. In fact, using the FR scheme, surveillance tasks can be built by recognizing people from their faces. This paper presents the implementation of face recognition as a biometric method for smart attendance as well as we also proposed the integrated scheme from capturing data from edge devices (CCTVs), streaming data to the dedicated server, then presenting the real-time data through android mobile devices. In this scheme, we proposed to employ deep learning algorithms based on the Convolutional Neural Network (CNN). Throughthe CCTV data streaming, faces are captured and matched with the database. Therefore, it is considered as their logging attendance. Furthermore, it is marked and stored into the database. This system prototype is developed by big data technology to tackle this complexity of data. The recognized faces can be monitored in real time monitoring. Eventually, real time reports are delivered through the web and android device with API after the data transmission is secured with hash encryption. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Design of River Monitoring Device with the Internet of Things Using LPWAN Based"
        ],
        "penulis":"Jumhana, Satria Ramadhan;Azmi, Fairuz;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays. The amount of development causes less air absorption. It was affected by floods. Flooding is a natural disaster that can damage significantly and harm many people. To minimize the impact of flooding, we need a system that can predict flood expenditure. It is necessary to design a tool to get data to predict the flooding of river water, air discharge, and rainfall.The sensor needed an ultrasonic sensor to measure the river water level and an independent variable to get the river air flow using Manning and a rain gauge sensor with a tipping bucket system to get high water level data. The course will be controlled using Arduino Uno and data sent to the Antares platform using the LoRa network. The power supply uses 2 lions of 3000Mah with each voltage with a total voltage of 8.4 V. The system will be at the river's edge with an ultrasonic sensor back to the riverbed and a rain gauge placed on the device.Based on the measurement results, all sensors run properly by the capabilities of each sensor. Ultrasonic sensors can measure a minimum of 2 cm and a maximum of 380 cm. Discharge measurements using Manning can be applied. The test results tested the 4.09 m of cistern water with river water discharge calculated using the Manning calculation of 51,539 m3\/sec and comparing with the BBWS (technical implementing unit in charge of water resources for river basins across provinces in Indonesia) measurement results of 51,087 m3\/sec. Error is valued at 1%, and the biggest error is valued at 13%. For the results of the rainfall sensor, one tip can be 1.27 mm. LoRa network performance for urban areas with a maximum mileage of 2 km is more than that of a 100% Loss package. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays. The amount of development causes less air absorption. It was affected by floods. Flooding is a natural disaster that can damage significantly and harm many people. To minimize the impact of flooding, we need a system that can predict flood expenditure. It is necessary to design a tool to get data to predict the flooding of river water, air discharge, and rainfall.The sensor needed an ultrasonic sensor to measure the river water level and an independent variable to get the river air flow using Manning and a rain gauge sensor with a tipping bucket system to get high water level data. The course will be controlled using Arduino Uno and data sent to the Antares platform using the LoRa network. The power supply uses 2 lions of 3000Mah with each voltage with a total voltage of 8.4 V. The system will be at the river's edge with an ultrasonic sensor back to the riverbed and a rain gauge placed on the device.Based on the measurement results, all sensors run properly by the capabilities of each sensor. Ultrasonic sensors can measure a minimum of 2 cm and a maximum of 380 cm. Discharge measurements using Manning can be applied. The test results tested the 4.09 m of cistern water with river water discharge calculated using the Manning calculation of 51,539 m3\/sec and comparing with the BBWS (technical implementing unit in charge of water resources for river basins across provinces in Indonesia) measurement results of 51,087 m3\/sec. Error is valued at 1%, and the biggest error is valued at 13%. For the results of the rainfall sensor, one tip can be 1.27 mm. LoRa network performance for urban areas with a maximum mileage of 2 km is more than that of a 100% Loss package. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Measuring the effectiveness of social media owned by local government leaders in communicating smart city programs"
        ],
        "penulis":"Anggadwita, Grisna;Rikumahu, Brady;Hendayani, Ratih;Putra, Rayhan Raka;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Smart city is one of the innovation programs that is now being intensively developed in Indonesia as a step in the modernization and adoption of technology to a broader sector. Leadership in a city is an important factor in the success of a program. The purpose of this study is to measure the effectiveness of Instagram social media owned by Oded Muhammad Danial as mayor of Bandung in communicating government programs that focus on Bandung Smart City. This research method uses descriptive qualitative method with content analysis approach using Oded Muhammad Danial's personal Instagram account data during the period 18 September 2018 to 31 October 2019. The results of this study successfully revealed that each priority area of Bandung Smart City does not have balanced communication intensity. The implications of this study will be discussed further.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Smart city is one of the innovation programs that is now being intensively developed in Indonesia as a step in the modernization and adoption of technology to a broader sector. Leadership in a city is an important factor in the success of a program. The purpose of this study is to measure the effectiveness of Instagram social media owned by Oded Muhammad Danial as mayor of Bandung in communicating government programs that focus on Bandung Smart City. This research method uses descriptive qualitative method with content analysis approach using Oded Muhammad Danial's personal Instagram account data during the period 18 September 2018 to 31 October 2019. The results of this study successfully revealed that each priority area of Bandung Smart City does not have balanced communication intensity. The implications of this study will be discussed further.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Instantaneous Height of Sea Surface: A Comparison between Local Field Observation and the Simulated Level from Global Models"
        ],
        "penulis":"Nusantara, Candida A.D.S.;Hakim, Aradea R.;Adytia, Didit;Poerbandono;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper explores the usability of a global database containing sea surface height. We look at simulated heights of the sea surface at a certain area and compare them with field observation from three stationary stations and one from an ocean cruise. Mean Sea Surface data from the global model and Mean Sea Level (MSL) data from the field observation must be referenced to the same height system. For this reason, a height system in the form of a global ellipsoid model, namely the World Geodetic System 1984 (WGS84) was chosen as the height reference. After being referenced in the same height system, then the MSS and MSL are compared by looking for the difference between the MSS of the ellipsoid hMSS and the MSL of the ellipsoid (hMSS) and the average of these differences. The results show that the differences are in the order of <1m. The simulated tidal waves from the global model is incapable to describe the actual sea level variations, although it is able to capture the general trend. It should be noted that the field observation is incomplete and subject to various uncertainties. Bearing in mind the limitation of the models and uncertainties of the observation, our study confirms that such an order discrepancy in a global sense is tolerable.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper explores the usability of a global database containing sea surface height. We look at simulated heights of the sea surface at a certain area and compare them with field observation from three stationary stations and one from an ocean cruise. Mean Sea Surface data from the global model and Mean Sea Level (MSL) data from the field observation must be referenced to the same height system. For this reason, a height system in the form of a global ellipsoid model, namely the World Geodetic System 1984 (WGS84) was chosen as the height reference. After being referenced in the same height system, then the MSS and MSL are compared by looking for the difference between the MSS of the ellipsoid hMSS and the MSL of the ellipsoid (hMSS) and the average of these differences. The results show that the differences are in the order of <1m. The simulated tidal waves from the global model is incapable to describe the actual sea level variations, although it is able to capture the general trend. It should be noted that the field observation is incomplete and subject to various uncertainties. Bearing in mind the limitation of the models and uncertainties of the observation, our study confirms that such an order discrepancy in a global sense is tolerable.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Authentication system and method for improving security login without typing password"
        ],
        "penulis":"Darmawan, Irfan;Rahmatulloh, Alam;Rianto;Oriza, Ilman Hilmi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Authentication in the login process is an important thing that needs attention. The login process will involve a password that is owned by the user, while the password is private and confidential. If someone uses a weak password, the password is likely to be easily hacked. Authentication security needs to be improved, and hackers will get access to the login system with only a few attack techniques such as SQL Injection or sniffing techniques. Besides, the lack of awareness of users by creating weak passwords is easy to guess. Meanwhile, to create a strong password, consisting of upper-and lower-case letters, a combination of numbers and symbols, it is very difficult to remember. This is a very important problem in the login process. This study discusses the login authentication process that can perform login integration without typing a password, because passwords are generated repeatedly with the One Time Password (OTP) method, and use the Quick Response Code (QR) as its support. To disguise the data in the QR Code, which is applied by the Rivest-Shamir-Adleman (RSA) encryption algorithm, and will be tested on a web-based application. The login integration process, using the QR Code token application that runs on an android phone. Which functions as an OTP token generator, and a web-based application will read information from the QR Code token. The result is that with login authentication, this can increase the security and ease of the authentication process without typing a password. \u00a9 2020 Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Authentication in the login process is an important thing that needs attention. The login process will involve a password that is owned by the user, while the password is private and confidential. If someone uses a weak password, the password is likely to be easily hacked. Authentication security needs to be improved, and hackers will get access to the login system with only a few attack techniques such as SQL Injection or sniffing techniques. Besides, the lack of awareness of users by creating weak passwords is easy to guess. Meanwhile, to create a strong password, consisting of upper-and lower-case letters, a combination of numbers and symbols, it is very difficult to remember. This is a very important problem in the login process. This study discusses the login authentication process that can perform login integration without typing a password, because passwords are generated repeatedly with the One Time Password (OTP) method, and use the Quick Response Code (QR) as its support. To disguise the data in the QR Code, which is applied by the Rivest-Shamir-Adleman (RSA) encryption algorithm, and will be tested on a web-based application. The login integration process, using the QR Code token application that runs on an android phone. Which functions as an OTP token generator, and a web-based application will read information from the QR Code token. The result is that with login authentication, this can increase the security and ease of the authentication process without typing a password. \u00a9 2020 Insight Society."
        ]
    },
    {
        "judul":[
            "Analysis of Choice Shrimp Technology based on Business Process, Productivity, Financial and Risk"
        ],
        "penulis":"Akbar, Wydzka Tasha Aulia;Chumaidiyah, Endang;Rendra, Meldi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The application of new technology in shrimp ponds, autofeeder, has many advantages, but carries a greater risk compared to conventional shrimp ponds, therefore a more structured analysis is needed to decide the best shrimp pond technology. The comparison is seen from business processes, productivity, financial and risk. The results of business process efficiency level with conventional worth 67.19% while for the autofeeder level worth 88.71%. The productivity results show FCR 1.34 (conventional) and 1.34 (autofeeder); SR 79% (conventional) and 90% (autofeeder); and productivity of 13 tons\/ha (conventional) and 25 tons\/ha (autofeeder). The financial shows an NPV of Rp 1, 515, 178.503 (conventional) and Rp 7, 721, 596, 229 (autofeeder); IRR 38.24% (conventional) and 51.23% (autofeeder); payback period 2.68 years (conventional) and 2.17 years (autofeeder); BCR 1, 696 (conventional) and 2, 065 (autofeeder). Furthermore, for the calculation of risk consisting of production risk and revenue risk with a total risk of 6% for conventional and 31% for autofeeder. In the results of technology selection with an assessment of the 15 criteria above, the results obtained 4 criteria are better for conventional technology and 11 criteria are better for autofeeder technology. So between the two technologies, the selected shrimp pond system is the Autofeeder technology. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The application of new technology in shrimp ponds, autofeeder, has many advantages, but carries a greater risk compared to conventional shrimp ponds, therefore a more structured analysis is needed to decide the best shrimp pond technology. The comparison is seen from business processes, productivity, financial and risk. The results of business process efficiency level with conventional worth 67.19% while for the autofeeder level worth 88.71%. The productivity results show FCR 1.34 (conventional) and 1.34 (autofeeder); SR 79% (conventional) and 90% (autofeeder); and productivity of 13 tons\/ha (conventional) and 25 tons\/ha (autofeeder). The financial shows an NPV of Rp 1, 515, 178.503 (conventional) and Rp 7, 721, 596, 229 (autofeeder); IRR 38.24% (conventional) and 51.23% (autofeeder); payback period 2.68 years (conventional) and 2.17 years (autofeeder); BCR 1, 696 (conventional) and 2, 065 (autofeeder). Furthermore, for the calculation of risk consisting of production risk and revenue risk with a total risk of 6% for conventional and 31% for autofeeder. In the results of technology selection with an assessment of the 15 criteria above, the results obtained 4 criteria are better for conventional technology and 11 criteria are better for autofeeder technology. So between the two technologies, the selected shrimp pond system is the Autofeeder technology. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Error rate detection due to primary user emulation attack in cognitive radio networks"
        ],
        "penulis":"Armi N.;Gharibi W.;Khan W.Z.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Security threat is a crucial issue in cognitive radio network (CRN). These threats come from physical layer, data link layer, network layer, transport layer, and application layer. Hence, security system to all layers in CRN has a responsibility to protect the communication between among Secondary User (SU) or to maintain valid detection to the presence of Primary User (PU) signals. Primary User Emulation Attack (PUEA) is a threat on physical layer where malicious user emulates PU signal. This paper studies the effect of exclusive region of PUEA in CRN. We take two setting of exclusive distances, 30m and 50m, where this radius of area is free of malicious users. Probability of false alarm (Pf) and miss detection (Pm) are used to evaluate the performances. The result shows that increasing distance of exclusive region may decrease Pf and Pm. \u00a9 2020 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Security threat is a crucial issue in cognitive radio network (CRN). These threats come from physical layer, data link layer, network layer, transport layer, and application layer. Hence, security system to all layers in CRN has a responsibility to protect the communication between among Secondary User (SU) or to maintain valid detection to the presence of Primary User (PU) signals. Primary User Emulation Attack (PUEA) is a threat on physical layer where malicious user emulates PU signal. This paper studies the effect of exclusive region of PUEA in CRN. We take two setting of exclusive distances, 30m and 50m, where this radius of area is free of malicious users. Probability of false alarm (Pf) and miss detection (Pm) are used to evaluate the performances. The result shows that increasing distance of exclusive region may decrease Pf and Pm. \u00a9 2020 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Biogas Production Volume Measurement and Internet of Things based Monitoring System"
        ],
        "penulis":"Abdurrahman, Arif Haidar;Kirom, Mukhammad Ramdlan;Suhendi, Asep;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Biogas is an alternative energy that utilizes several types of leftover material such as food scraps, garbage and livestock feces. The conversion process of these organic materials takes several weeks in anaerobic conditions by using microbes to overhaul the organic material. In its implementation, biogas reactors are not equipped with appropriate measuring instruments, such as instruments to measure the volume of gas produced by the reactor, so the users do not know the volume of gas produced by the reactor. In this research, an Internet of Things (IoT) biogas production volume monitoring system will be developed. The biogas measurement data is sent to the IoT platform so that data about daily biogas production can be monitored directly form far away. The measurement process carried out by the flowmeter sensor will be received and processed by a microcontroller. The process of sending data to the IoT platform is done using the GSM\/ GPRS communication module with a delivery time of every 15 minutes. GSM\/ GPRS communication module can transmit data with an average time of 36.2 seconds. The accuracy of the flowmeter sensor used on standard measuring devices is 94,84% with an error of + 5.16%. Accuracy of volume accumulation by the microcontroller to the reference volume is 95,75%. with an error of + 4.25%. The accumulated volume of biogas production for the first period was 772.55 liters, the second period was 664.73 liters, and the third period of 695.63 liters. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Biogas is an alternative energy that utilizes several types of leftover material such as food scraps, garbage and livestock feces. The conversion process of these organic materials takes several weeks in anaerobic conditions by using microbes to overhaul the organic material. In its implementation, biogas reactors are not equipped with appropriate measuring instruments, such as instruments to measure the volume of gas produced by the reactor, so the users do not know the volume of gas produced by the reactor. In this research, an Internet of Things (IoT) biogas production volume monitoring system will be developed. The biogas measurement data is sent to the IoT platform so that data about daily biogas production can be monitored directly form far away. The measurement process carried out by the flowmeter sensor will be received and processed by a microcontroller. The process of sending data to the IoT platform is done using the GSM\/ GPRS communication module with a delivery time of every 15 minutes. GSM\/ GPRS communication module can transmit data with an average time of 36.2 seconds. The accuracy of the flowmeter sensor used on standard measuring devices is 94,84% with an error of + 5.16%. Accuracy of volume accumulation by the microcontroller to the reference volume is 95,75%. with an error of + 4.25%. The accumulated volume of biogas production for the first period was 772.55 liters, the second period was 664.73 liters, and the third period of 695.63 liters. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Photostabilization of phycocyanin from Spirulina platensis modified by formaldehyde"
        ],
        "penulis":"Munawaroh, Heli Siti Halimatul;Gumilar, Gun Gun;Alifia, Chindiar Rizka;Marthania, Meganita;Stellasary, Bianca;Yuliani, Galuh;Wulandari, Asri Peni;Kurniawan, Isman;Hidayat, Rahmat;Ningrum, Andriati;Koyande, Apurav Krishna;Show, Pau-Loke;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Spirulina platensis contain variety of pigments, such as chlorophylls, carotenoids, and phycocyanin. Phycocyanin (PC) exists in abundance, but due to its instability, the utilization of this pigment is still very limited. In this study, the PC was modified using formaldehyde crosslinks yielding phycocyanin-formaldehyde (PC-F), and its photostability was evaluated. The PC-F formation was designated by the distinctive alterations of the maximum absorption to 611 nm, which was 10 nm blue-shifted than those of the PC. Additionally, the sharp peaks of FTIR spectra at 1636 nm for [sbnd]C[dbnd]O and at 1019 nm for [sbnd]C[sbnd]O[sbnd]C, suggesting the interaction of phycocyanin with formaldehyde. The PC-F showed stabilization improvement up to 1.53-folds after 300 mins of yellow light exposure than those of PC. Contrary to yellow light irradiation, a severe decrease of PC-F absorbance was observed reach to 4.9-folds under UV-B irradiation. The poor stability of PC-F upon white light and UV-A irradiation were indicated by the decline of PC-F absorbance up to 1.72 and 1.80, respectively. Moreover, the present study suggests that the modification of phycocyanin by formaldehyde crosslink can increase photostability upon yellow light irradiation. \u00a9 2020 Elsevier Ltd",
            "NH4SOOOO2View detailsExpand Substance ammonium sulfateSOOOOH3CNSNH3CH3CCH3CH3View detailsExpand Substance thiazinamium metilsulfateOHOHOOOHHOOHOHOView detailsExpand Substance 3-caffeoylquinic acidOHOHHOOView detailsExpand Substance caffeic acidCH3CH3H3CHOOCH3CH3CH3H3CH3CH3CH3COOHView detailsExpand Substance 3,3'-dihydroxy-\u03b2,\u03b2-carotene-4,4'-dioneNH2CH3HOOCH3View detailsExpand Substance isoleucineHNH3CNHHOOH3CNHHOOHNH3CCH2OCH3OCH2View detailsExpand Substance bilirubinChlorophyllView detailsExpand Substance Chlorophyll",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Spirulina platensis contain variety of pigments, such as chlorophylls, carotenoids, and phycocyanin. Phycocyanin (PC) exists in abundance, but due to its instability, the utilization of this pigment is still very limited. In this study, the PC was modified using formaldehyde crosslinks yielding phycocyanin-formaldehyde (PC-F), and its photostability was evaluated. The PC-F formation was designated by the distinctive alterations of the maximum absorption to 611 nm, which was 10 nm blue-shifted than those of the PC. Additionally, the sharp peaks of FTIR spectra at 1636 nm for [sbnd]C[dbnd]O and at 1019 nm for [sbnd]C[sbnd]O[sbnd]C, suggesting the interaction of phycocyanin with formaldehyde. The PC-F showed stabilization improvement up to 1.53-folds after 300 mins of yellow light exposure than those of PC. Contrary to yellow light irradiation, a severe decrease of PC-F absorbance was observed reach to 4.9-folds under UV-B irradiation. The poor stability of PC-F upon white light and UV-A irradiation were indicated by the decline of PC-F absorbance up to 1.72 and 1.80, respectively. Moreover, the present study suggests that the modification of phycocyanin by formaldehyde crosslink can increase photostability upon yellow light irradiation. \u00a9 2020 Elsevier Ltd"
        ]
    },
    {
        "judul":[
            "QoS Performance of Software Define Network Using Open Network Operating System Controller"
        ],
        "penulis":"Ramadhan, Rafli;Armi, Nasrullah;Magdalena, Rita;Nurkahfi, Galih Nugraha;Dinata, Mochamad Mardi Marta;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The demand of network services implies many provider services on the bandwidth and devices quality, respectively. It causes the high time consumption in the network configuration and construction. We study the software define network (SDN) by using open network operating system (ONOS) controller. This controller separates every controller and data plane which is placed in the same network device. The ONOS supports virtual devices like the router and switch by using mininet. The ONOS also emulates a complete host networks, links, and switches on a single machine. We treat 20 hosts and 10 switches which have the linear and ring topologies to investigate the throughput, packet loss, delay, and jitter performance, respectively. The simulation results show that the linear topology achieves 4.9 kbits, 2.69 ms, 0.7 \u03bcs, and 1.4 % on the throughput, delay, jitter, and packet loss, respectively. Meanwhile, the ring topology accomplishes 4.2 mbps, 1.96 ms, 3.4 \u03bcs, and 1.2 ms, respectively. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The demand of network services implies many provider services on the bandwidth and devices quality, respectively. It causes the high time consumption in the network configuration and construction. We study the software define network (SDN) by using open network operating system (ONOS) controller. This controller separates every controller and data plane which is placed in the same network device. The ONOS supports virtual devices like the router and switch by using mininet. The ONOS also emulates a complete host networks, links, and switches on a single machine. We treat 20 hosts and 10 switches which have the linear and ring topologies to investigate the throughput, packet loss, delay, and jitter performance, respectively. The simulation results show that the linear topology achieves 4.9 kbits, 2.69 ms, 0.7 \u03bcs, and 1.4 % on the throughput, delay, jitter, and packet loss, respectively. Meanwhile, the ring topology accomplishes 4.2 mbps, 1.96 ms, 3.4 \u03bcs, and 1.2 ms, respectively. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Image Retrieval using Modified Multi Texton and Rotation Invariant Local Binary Pattern"
        ],
        "penulis":"Bimantoro, Fitri;Aziz, Ashri Annisaak;Husodo, Ario Yudo;Musnansyah, Ahmad;Minarno, Agus Eko;Kurniawardhani, Arrie;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Image retrieval is a standard method used to search a digital image in large image databases. One of the most critical things in image retrieval is the feature extraction process. Several techniques can be used in the image feature extraction process, one of which is Multi Texton Histogram (MTH). MTH is usually carried out with two main processes, namely color quantization, and texture orientation. Improvement of MTH method performance can be made by adding texton. In our experiment, we test the method by using rotated images. In this paper, we develop the use of an invariant method for rotation, namely the Local Binary Pattern Rotation Invariant (LBPROT) method to improve image retrieval precision. The results of combining these two methods produce features of each image. The features produced by each image are compared using a distance matrix. A query image that has the smallest distance matrix value is an image that has the same class as the compared database image. Based on our experiments on typical images, the use of Modified MTH and LBPROT can improve image retrieval performance by increasing the percentage of precision and recall by 3.63% and 0.62%. However, The Modified MTH is better when compared to the merging of the Modified MTH and LBPROT on 45 \u00b0, 135 \u00b0, 225 \u00b0, and 315 \u00b0 angle rotations with precision values by 24% -27%. Meanwhile, our testing result using rotated images, the combination of Modified MTH and LBPROT produces an increase in precision at angles rotation of 90 \u00b0, 180 \u00b0, and 270 \u00b0 by 2% -3%. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Image retrieval is a standard method used to search a digital image in large image databases. One of the most critical things in image retrieval is the feature extraction process. Several techniques can be used in the image feature extraction process, one of which is Multi Texton Histogram (MTH). MTH is usually carried out with two main processes, namely color quantization, and texture orientation. Improvement of MTH method performance can be made by adding texton. In our experiment, we test the method by using rotated images. In this paper, we develop the use of an invariant method for rotation, namely the Local Binary Pattern Rotation Invariant (LBPROT) method to improve image retrieval precision. The results of combining these two methods produce features of each image. The features produced by each image are compared using a distance matrix. A query image that has the smallest distance matrix value is an image that has the same class as the compared database image. Based on our experiments on typical images, the use of Modified MTH and LBPROT can improve image retrieval performance by increasing the percentage of precision and recall by 3.63% and 0.62%. However, The Modified MTH is better when compared to the merging of the Modified MTH and LBPROT on 45 \u00b0, 135 \u00b0, 225 \u00b0, and 315 \u00b0 angle rotations with precision values by 24% -27%. Meanwhile, our testing result using rotated images, the combination of Modified MTH and LBPROT produces an increase in precision at angles rotation of 90 \u00b0, 180 \u00b0, and 270 \u00b0 by 2% -3%. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Throughput-Maximum Energy-Aware Rate Adaptation in W-NCSs over Quasi-Static Fading Channels"
        ],
        "penulis":"Royyan, Muhammad;Vehkapera, Mikko;Charalambous, Themistoklis;Wichman, Risto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, we consider a wireless networked control system (W-NCS) and seek to optimize the performance of the system by adapting the transmission throughput of the communication link, which is assumed to be a quasi-static fading channel. Towards this end, an optimization problem is formulated and solved, herein called Maximum Throughput with Energy Constraints (MaxTEC), in which the optimal achievable throughput is selected subject to the limited available energy per transmission. It is demonstrated that the larger the available energy, the higher the throughput, and, subsequently, the better the control performance. The performance of our proposed scheme is illustrated via simulations of an inverted pendulum on a cart. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we consider a wireless networked control system (W-NCS) and seek to optimize the performance of the system by adapting the transmission throughput of the communication link, which is assumed to be a quasi-static fading channel. Towards this end, an optimization problem is formulated and solved, herein called Maximum Throughput with Energy Constraints (MaxTEC), in which the optimal achievable throughput is selected subject to the limited available energy per transmission. It is demonstrated that the larger the available energy, the higher the throughput, and, subsequently, the better the control performance. The performance of our proposed scheme is illustrated via simulations of an inverted pendulum on a cart. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design and Characterization of Rectangular Array Microstrip Antenna for Cubesat S-Band Transmitter"
        ],
        "penulis":"Benyamin, Sherin Octavani;Wijanto, Heroe;Edwar;Prabowo, Vinsensius Sigit Widhi;Prananditya, Haris;Oktaviani, Shindi Marlina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Automatic Dependent Surveillance-Broadcast (ADS-B) is an air traffic surveillance technology that automatically and periodically broadcasts onboard aircraft flight information such as identity numbers, positions, speeds, and destinations during all phases of flight to avoid collisions. In the future, the radar system will be equipped or even replaced by the ADS-B ground station. Therefore, the Nano-Satellite Laboratory of Telkom University is developing a satellite technology called Tel-USat which the ADS-B receiver is one of the missions. This work focuses on the design and characterization of the antenna to send all the collected ADS-B data to the ground. This antenna is designed by using an FR-4 substrate material with two rectangular patches, linear array, T-junction powerdivider, and proximity coupled rationing. The results obtained during the measurement are return loss values at 2.4 GHz frequency of -18.5 dB, VSWR of 1.2, antenna bandwidth of 163 MHz, and the gainof 6.08 dB. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Automatic Dependent Surveillance-Broadcast (ADS-B) is an air traffic surveillance technology that automatically and periodically broadcasts onboard aircraft flight information such as identity numbers, positions, speeds, and destinations during all phases of flight to avoid collisions. In the future, the radar system will be equipped or even replaced by the ADS-B ground station. Therefore, the Nano-Satellite Laboratory of Telkom University is developing a satellite technology called Tel-USat which the ADS-B receiver is one of the missions. This work focuses on the design and characterization of the antenna to send all the collected ADS-B data to the ground. This antenna is designed by using an FR-4 substrate material with two rectangular patches, linear array, T-junction powerdivider, and proximity coupled rationing. The results obtained during the measurement are return loss values at 2.4 GHz frequency of -18.5 dB, VSWR of 1.2, antenna bandwidth of 163 MHz, and the gainof 6.08 dB. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Recognizing Personality from Social Media Linguistic Cues: A Case Study of Brand Ambassador Personality"
        ],
        "penulis":"Alamsyah, Andry;Bastikarana, Rafa Syafiq;Ramadhanti, Alya Rysda;Widiyanesti, Sri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The burgeoning need of a brand ambassador (BA) as a company representative begin to rise in recent year. The phenomena followed by the increase of method to select the most suitable BA. The universal way of selecting one appropriate ambassador is by understanding their personality, therefore, measurement of a BA personality considered as one way to characterize a company credibility. This research proposes to design a method of measuring the BA personality from their social media data in Bahasa Indonesia. We enrich the methodology to measure human personality using the ontology modeling approach. The ontology model constructed under the ngram language model which provides a rapid and effective way of measuring a BA personality. The results of a BA personality measurement allow the utilization to portray of how an ambassador represent their brand and interact with their customer.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The burgeoning need of a brand ambassador (BA) as a company representative begin to rise in recent year. The phenomena followed by the increase of method to select the most suitable BA. The universal way of selecting one appropriate ambassador is by understanding their personality, therefore, measurement of a BA personality considered as one way to characterize a company credibility. This research proposes to design a method of measuring the BA personality from their social media data in Bahasa Indonesia. We enrich the methodology to measure human personality using the ontology modeling approach. The ontology model constructed under the ngram language model which provides a rapid and effective way of measuring a BA personality. The results of a BA personality measurement allow the utilization to portray of how an ambassador represent their brand and interact with their customer.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Evaluation performance of SVR genetic algorithm and hybrid PSO in rainfall forecasting"
        ],
        "penulis":"Caraka, Rezzyeko;Chen, Rung Ching;Toharudin, Toni;Tahmid, Muhammad;Pardamean, Bens;Putra, Richard Mahendra;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Climate is an essential natural factor which is dynamic and challenging to predict. The accurate climate prediction is needed. In this paper, we use support vector regression (SVR) with different kernels such as polynomial, sigmoid and RBF. At the same time, we employ genetic algorithm, particle swarm optimization, and hybrid particle swarm optimization. SVR-GA are population-based algorithms that allow for optimization of problems with the search space that is very broad and complex. This property too allows genetic algorithms to jump out of the local area optimum. In contrast with SVR-PSO and SVR-HPSO they do not have the genetic operation. In PSO only use internal velocity and have the memory which is essential to the algorithm. In this paper we compare SVR-PSO, SVR-HPSO and SVR-GA by comparing the input from the correlation and ARIMA in rainfall data. It was found that the input using correlation provides better accuracy than ARIMA. \u00a9 2020, ICIC International. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Climate is an essential natural factor which is dynamic and challenging to predict. The accurate climate prediction is needed. In this paper, we use support vector regression (SVR) with different kernels such as polynomial, sigmoid and RBF. At the same time, we employ genetic algorithm, particle swarm optimization, and hybrid particle swarm optimization. SVR-GA are population-based algorithms that allow for optimization of problems with the search space that is very broad and complex. This property too allows genetic algorithms to jump out of the local area optimum. In contrast with SVR-PSO and SVR-HPSO they do not have the genetic operation. In PSO only use internal velocity and have the memory which is essential to the algorithm. In this paper we compare SVR-PSO, SVR-HPSO and SVR-GA by comparing the input from the correlation and ARIMA in rainfall data. It was found that the input using correlation provides better accuracy than ARIMA. \u00a9 2020, ICIC International. All rights reserved."
        ]
    },
    {
        "judul":[
            "Advanced technologies to support service discovery in service-oriented systems"
        ],
        "penulis":"Azmy, Moh. Roufiq;Suhardi;Muhamad, Wardani;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The development of information technology encourages the service industry to revolutionize service-oriented businesses. Various service industries provide web-services as IT services and register it to several service directories, so other parties can use and integrate these services into existing systems to create more value. Performing service discovery from a collection of services in the service directory is a challenge that must be resolved. Understanding the latest technology to support service discovery could help them determine the technology that can be used. This article presents a review of previous studies related to service discovery methods carried out on service-oriented systems. It summarizes selected previous related studies and categorizes them based on qualitative approaches. The aim is to present some of the latest research and provide a comprehensive vision of designing service discovery engines. This paper provides theoretical contribution and the understanding related to service discovery from previous studies through the systematic literature review. Thirty-eight articles were selected based on search results and then reviewed. It can be used as a guide to build the service discovery engine for service-oriented system.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The development of information technology encourages the service industry to revolutionize service-oriented businesses. Various service industries provide web-services as IT services and register it to several service directories, so other parties can use and integrate these services into existing systems to create more value. Performing service discovery from a collection of services in the service directory is a challenge that must be resolved. Understanding the latest technology to support service discovery could help them determine the technology that can be used. This article presents a review of previous studies related to service discovery methods carried out on service-oriented systems. It summarizes selected previous related studies and categorizes them based on qualitative approaches. The aim is to present some of the latest research and provide a comprehensive vision of designing service discovery engines. This paper provides theoretical contribution and the understanding related to service discovery from previous studies through the systematic literature review. Thirty-eight articles were selected based on search results and then reviewed. It can be used as a guide to build the service discovery engine for service-oriented system.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Innovation as the key to gain performance from absorptive capacity and human capital"
        ],
        "penulis":"Pradana, Mahir;P\u00e9rez-Lu\u00f1o, Ana;Fuentes-Blasco, Maria;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study aims to investigate how firms can achieve high levels of organisational performance through innovation, absorptive capacity (ACAP) and human capital (HC). Using a sample of 138 Spanish companies from the wine industry, our findings show that ACAP and HC allow businesses to fully capture the benefits of innovation. These results contribute to the literature of ACAP, human resources management (HRM) innovation and resource-based view (RBV) of the firm by showing that a number of resources and capabilities (ACAP, HC, and innovation) can be seen as good drivers of performance and, by extension, of competitive advantage. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to investigate how firms can achieve high levels of organisational performance through innovation, absorptive capacity (ACAP) and human capital (HC). Using a sample of 138 Spanish companies from the wine industry, our findings show that ACAP and HC allow businesses to fully capture the benefits of innovation. These results contribute to the literature of ACAP, human resources management (HRM) innovation and resource-based view (RBV) of the firm by showing that a number of resources and capabilities (ACAP, HC, and innovation) can be seen as good drivers of performance and, by extension, of competitive advantage. \u00a9 2020, \u00a9 2020 Informa UK Limited, trading as Taylor & Francis Group."
        ]
    },
    {
        "judul":[
            "Time and frequency domain feature extraction method of doppler radar for hand gesture based human to machine interface"
        ],
        "penulis":"Pramudita, Aloysius Adya;Lukas;Edwar;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the development of hand gesture based Human to Machine Interface, Doppler response feature extraction method plays an important role in translating hand gesture of certain information. The Doppler response feature extraction method from hand gesture sign was proposed and designed by combining time and frequency domain analysis. The extraction of the Doppler response features at time domain is developed by using cross correlation, and the time domain feature is represented by using peak value of cross correlation result and its time shift. The Doppler response feature of frequency domain is extracted by employing a discriminator filter determined by the frequency spectrum observation of Doppler response. The proposed method was employed as a preprocessing for Continuous Wave (CW) radar output signals, which is able to relieve the pattern classification of Doppler response associated with each hand gesture. The simulation and laboratory experiment using HB 100 Doppler radar were performed to investigate the proposed method. The results show that the combination of all three features was capable of differentiating every type of hand gestures movement. \u00a9 2020, Electromagnetics Academy. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the development of hand gesture based Human to Machine Interface, Doppler response feature extraction method plays an important role in translating hand gesture of certain information. The Doppler response feature extraction method from hand gesture sign was proposed and designed by combining time and frequency domain analysis. The extraction of the Doppler response features at time domain is developed by using cross correlation, and the time domain feature is represented by using peak value of cross correlation result and its time shift. The Doppler response feature of frequency domain is extracted by employing a discriminator filter determined by the frequency spectrum observation of Doppler response. The proposed method was employed as a preprocessing for Continuous Wave (CW) radar output signals, which is able to relieve the pattern classification of Doppler response associated with each hand gesture. The simulation and laboratory experiment using HB 100 Doppler radar were performed to investigate the proposed method. The results show that the combination of all three features was capable of differentiating every type of hand gestures movement. \u00a9 2020, Electromagnetics Academy. All rights reserved."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Using LSTM for Context Based Approach of Sarcasm Detection in Twitter"
        ],
        "penulis":"Khotijah, Siti;Tirtawangsa, Jimmy;Suryani, Arie A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this research, we propose a sarcasm detection by taking into consideration its many varying contexts, related to the word or phrase in a tweet. To get the related context, we extract the information with paragraph2vec to simplify the process of finding the contextual meaning. The result paragraph2vec will provide the features to help classification in Long Short Term Memory (LSTM). Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. We applied a sarcasm detection method to identify sarcasm in two different languages: English and Indonesian and classification with balanced and imbalanced data. It aims to measure the reliability of the proposed approach and how effective the method is in detecting sarcasm. The result of the experiment shows that in Indonesian, balanced data has a good accuracy of 88.33 % and imbalanced data of 76.66 %, whereas in English the balanced data has an accuracy of 79% and imbalanced data of 54.5%. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this research, we propose a sarcasm detection by taking into consideration its many varying contexts, related to the word or phrase in a tweet. To get the related context, we extract the information with paragraph2vec to simplify the process of finding the contextual meaning. The result paragraph2vec will provide the features to help classification in Long Short Term Memory (LSTM). Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. We applied a sarcasm detection method to identify sarcasm in two different languages: English and Indonesian and classification with balanced and imbalanced data. It aims to measure the reliability of the proposed approach and how effective the method is in detecting sarcasm. The result of the experiment shows that in Indonesian, balanced data has a good accuracy of 88.33 % and imbalanced data of 76.66 %, whereas in English the balanced data has an accuracy of 79% and imbalanced data of 54.5%. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Smart Safe Prototype Based Internet of Things (IoT) with Face and Fingerprint Recognition"
        ],
        "penulis":"Setyadi, Ramadhan Rizki;Istikmal;Irawan, Arif Indra;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The safe box is currently considered safe but is not truly safe. That is because safe storage has a security method using PINs that can be seen by others. Therefore, a more secure safe box security system is needed. This paper purpose a safe box prototype with an added security system using a two-way verification system and an integrated Internet of Things (IoT) system. The face recognition system and fingerprint system used in this system. The face recognition system developed an LBP (Local Binary Pattern) clarification and embedded Haar cascade program in raspberry Pi. For real-time monitoring, the safe box has been designed to provide violation alerts via notifications on android apps. Two-way verification smart safe box has a good face recognition system especially when the conditions are bright and also the best way to identify fingerprints on a flat position. In LOS conditions, the best distance is at 4 meters with a delay value of 0.373 s and throughput of 3680.533 bps. In non-LOS condition, the best distance is 2 meters with a delay value of 0.380 seconds and throughput of 4055.73 bytes\/s.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The safe box is currently considered safe but is not truly safe. That is because safe storage has a security method using PINs that can be seen by others. Therefore, a more secure safe box security system is needed. This paper purpose a safe box prototype with an added security system using a two-way verification system and an integrated Internet of Things (IoT) system. The face recognition system and fingerprint system used in this system. The face recognition system developed an LBP (Local Binary Pattern) clarification and embedded Haar cascade program in raspberry Pi. For real-time monitoring, the safe box has been designed to provide violation alerts via notifications on android apps. Two-way verification smart safe box has a good face recognition system especially when the conditions are bright and also the best way to identify fingerprints on a flat position. In LOS conditions, the best distance is at 4 meters with a delay value of 0.373 s and throughput of 3680.533 bps. In non-LOS condition, the best distance is 2 meters with a delay value of 0.380 seconds and throughput of 4055.73 bytes\/s.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Consumer Trust to Buy Green Product: Investigation of Green Perceived Value with Green Satisfaction Mediation"
        ],
        "penulis":"Lutfie, Harrie;Marcelino, Dandy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The current level of human awareness of the environment began to grow since the emergence of negative environmental issues like global warming. Global warming causes consumers to be more interested in buying products from companies that care about the environment. One form of consumer concern today is the emergence of green lifestyle trends. Green lifestyle is currently being widely adopted by the community as natural damage caused by that community as well. Consumers who have an environmental concern will make changes by buying products that are proven to be environmentally friendly. This study aims to determine whether the green marketing strategy implemented by Starbucks runs effectively and to find out the role of Green Perceived Value towards Green Trust mediated by Green Satisfaction on Starbucks Bandung consumers. The analysis method employed in this research is quantitative with causal type research, as well as data analysis techniques using path analysis which is divided into two substructures. The results showed the Green Perceived Value and Green Satisfaction variables had a positive and significant effect on the Green Trust variables simultaneously. The total effect of the independent variables studied is equal to 68.68% and the rest 31.32% is influenced by other variables or factors not examined that could increase Green Trust. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The current level of human awareness of the environment began to grow since the emergence of negative environmental issues like global warming. Global warming causes consumers to be more interested in buying products from companies that care about the environment. One form of consumer concern today is the emergence of green lifestyle trends. Green lifestyle is currently being widely adopted by the community as natural damage caused by that community as well. Consumers who have an environmental concern will make changes by buying products that are proven to be environmentally friendly. This study aims to determine whether the green marketing strategy implemented by Starbucks runs effectively and to find out the role of Green Perceived Value towards Green Trust mediated by Green Satisfaction on Starbucks Bandung consumers. The analysis method employed in this research is quantitative with causal type research, as well as data analysis techniques using path analysis which is divided into two substructures. The results showed the Green Perceived Value and Green Satisfaction variables had a positive and significant effect on the Green Trust variables simultaneously. The total effect of the independent variables studied is equal to 68.68% and the rest 31.32% is influenced by other variables or factors not examined that could increase Green Trust. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Analysis of Message Broker for Communication in Fog Computing"
        ],
        "penulis":"Bagaskara, Aditya Eka;Setyorini, Setyorini;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this research, performance testing is performed between the two most popular message brokers, which commonly used in the enterprise, namely RabbitMQ and Apache Kafka in the fog computing environment. REST API is a method that implements the HTTP protocol and commonly used in the Internet of Things as a communication media between devices. Hence the performance will degrade when the amount of request is abundant and less reliable due to its synchronous communication. By using a message broker as the medium of communication between devices in fog computing, each connected device will not rely on each other and will make the message delivery more guaranteed. By reason, this research will implement a message broker for communication between devices in fog computing. Today there are many message brokers developed by various companies or communities. Choosing an unsuitable message broker can cause performance degradation, which results in a chaotic IoT system. The test results show that Apache Kafka has a higher throughput than RabbitMQ when the message size is calculable. However, when the message size is myriad, RabbitMQ is much better because the bottleneck of disk I\/O usage occurred in Kafka. Nevertheless, in latency testing, RabbitMQ is always better even though the difference is not too far. This testing can also be concluded that the use of message broker in fog computing that extends the cloud computing architecture proven effective in implementing the IoT system. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this research, performance testing is performed between the two most popular message brokers, which commonly used in the enterprise, namely RabbitMQ and Apache Kafka in the fog computing environment. REST API is a method that implements the HTTP protocol and commonly used in the Internet of Things as a communication media between devices. Hence the performance will degrade when the amount of request is abundant and less reliable due to its synchronous communication. By using a message broker as the medium of communication between devices in fog computing, each connected device will not rely on each other and will make the message delivery more guaranteed. By reason, this research will implement a message broker for communication between devices in fog computing. Today there are many message brokers developed by various companies or communities. Choosing an unsuitable message broker can cause performance degradation, which results in a chaotic IoT system. The test results show that Apache Kafka has a higher throughput than RabbitMQ when the message size is calculable. However, when the message size is myriad, RabbitMQ is much better because the bottleneck of disk I\/O usage occurred in Kafka. Nevertheless, in latency testing, RabbitMQ is always better even though the difference is not too far. This testing can also be concluded that the use of message broker in fog computing that extends the cloud computing architecture proven effective in implementing the IoT system. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A Comparative Study of Deepfake Video Detection Method"
        ],
        "penulis":"Ramadhani, Kurniawan Nur;Munir, Rinaldi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Deepfake technology allows humans to manipulate images and videos using deep learning technology. The results from deepfakes are very difficult to distinguish using ordinary vision. Many algorithms are built to detect deepfake content in images and videos. There are several approaches in deepfake detection, including a visual feature-based approach, a local feature-based approach, a deep feature-based approach and a temporal feature-based approach. The main challenge in developing deepfake detection algorithms is the variety of existing deepfake models in both images and videos. Another challenge is that deepfake technology is still evolving, making deepfake images and videos look more realistic and harder to detect. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Deepfake technology allows humans to manipulate images and videos using deep learning technology. The results from deepfakes are very difficult to distinguish using ordinary vision. Many algorithms are built to detect deepfake content in images and videos. There are several approaches in deepfake detection, including a visual feature-based approach, a local feature-based approach, a deep feature-based approach and a temporal feature-based approach. The main challenge in developing deepfake detection algorithms is the variety of existing deepfake models in both images and videos. Another challenge is that deepfake technology is still evolving, making deepfake images and videos look more realistic and harder to detect. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Integration the 6th category Business Excellence Framework, the 8th clause ISO 9001:2015 and the 6th category KPKU Indonesia Framework"
        ],
        "penulis":"Widaningrum, Sri;Mohammad, Musli;Ibrahim, Rasidi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "KPKU (Kriteria Penilaian Kinerja Unggul) Indonesia framework 2015 adopted Business Excellence Framework 2013-2014, that is a framework used by the \u201cMinistry of State-Owned Enterprises\u201d of the Republic of Indonesia to assess the performance of SOEs in Indonesia. One of the KPKU criteria is the operation, that is the most dominant criteria in company performance. They are proven by the score in Baldrige Excellence Framework (110 point is the highest score) for product and process results which are influenced by operational criteria in the 6th category of BEF. Currently, Indonesia does not have yet business excellence framework based on companies in Indonesia and does not have yet Indonesia operational excellence model, either in Indonesia or based on previous research. Currently, there is no model that integrates (Baldrige Excellence Framework, ISO 9001: 2015, and KPKU). This research will develop the Indonesia operational excellence model based on the Baldrige Excellence Framework, ISO 9001:2015, and KPKU Indonesia framework. Stage of the research is the literature survey, identifying the 6th Category Baldrige Excellence Framework; KPKU and the 8th Clause ISO 9001:2015, and integration the 6th KPKU framework and the 8th Clause ISO 9001:2015 to the 6th Category Baldrige Excellence framework. The results of the study are the Indonesian operational excellence framework that consists of 5 criteria and 14 sub-criteria, namely Product and Process Design, Process Management, Process Efficiency and Effectiveness, Process Improvement, and Safety and Emergency Preparedness. This model is appropriate for company performance measurement, especially operational performance. \u00a9 2020 Universiti Tun Hussein Onn Malaysia Publisher's Office. All Rights Reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "KPKU (Kriteria Penilaian Kinerja Unggul) Indonesia framework 2015 adopted Business Excellence Framework 2013-2014, that is a framework used by the \u201cMinistry of State-Owned Enterprises\u201d of the Republic of Indonesia to assess the performance of SOEs in Indonesia. One of the KPKU criteria is the operation, that is the most dominant criteria in company performance. They are proven by the score in Baldrige Excellence Framework (110 point is the highest score) for product and process results which are influenced by operational criteria in the 6th category of BEF. Currently, Indonesia does not have yet business excellence framework based on companies in Indonesia and does not have yet Indonesia operational excellence model, either in Indonesia or based on previous research. Currently, there is no model that integrates (Baldrige Excellence Framework, ISO 9001: 2015, and KPKU). This research will develop the Indonesia operational excellence model based on the Baldrige Excellence Framework, ISO 9001:2015, and KPKU Indonesia framework. Stage of the research is the literature survey, identifying the 6th Category Baldrige Excellence Framework; KPKU and the 8th Clause ISO 9001:2015, and integration the 6th KPKU framework and the 8th Clause ISO 9001:2015 to the 6th Category Baldrige Excellence framework. The results of the study are the Indonesian operational excellence framework that consists of 5 criteria and 14 sub-criteria, namely Product and Process Design, Process Management, Process Efficiency and Effectiveness, Process Improvement, and Safety and Emergency Preparedness. This model is appropriate for company performance measurement, especially operational performance. \u00a9 2020 Universiti Tun Hussein Onn Malaysia Publisher's Office. All Rights Reserved."
        ]
    },
    {
        "judul":[
            "Blacklisted IP distribution system to handle DDoS attacks on IPS Snort based on Blockchain"
        ],
        "penulis":"Al'Aziz, Bram Andika Ahmad;Sukarno, Parman;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The mechanism for distributing information on the source of the attack by combining blockchain technology with the Intrusion Prevention System (IPS) can be done so that DDoS attack mitigation becomes more flexible, saves resources and costs. Also, by informing the blacklisted Internet Protocol(IP), each IPS can share attack source information so that attack traffic blocking can be carried out on IPS that are closer to the source of the attack. Therefore, the attack traffic passing through the network can be drastically reduced because the attack traffic has been blocked on the IPS that is closer to the attack source. The blocking of existing DDoS attack traffic is generally carried out on each IPS without a mechanism to share information on the source of the attack so that each IPS cannot cooperate. Also, even though the DDoS attack traffic did not reach the server because it had been blocked by IPS, the attack traffic still flooded the network so that network performance was reduced. Through smart contracts on the Ethereum blockchain, it is possible to inform the source of the attack or blacklisted IP addresses without requiring additional infrastructure. The blacklisted IP address is used by IPS to detect and handle DDoS attacks. Through the blacklisted IP distribution scheme, testing and analysis are carried out to see information on the source of the attack on each IPS and the attack traffic that passes on the network. The result is that each IPS can have the same blacklisted IP so that each IPS can have the same attack source information. The results also showed that the attack traffic through the network infrastructure can be drastically reduced. Initially, the total number of attack packets had an average of 115, 578 reduced to 27, 165.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The mechanism for distributing information on the source of the attack by combining blockchain technology with the Intrusion Prevention System (IPS) can be done so that DDoS attack mitigation becomes more flexible, saves resources and costs. Also, by informing the blacklisted Internet Protocol(IP), each IPS can share attack source information so that attack traffic blocking can be carried out on IPS that are closer to the source of the attack. Therefore, the attack traffic passing through the network can be drastically reduced because the attack traffic has been blocked on the IPS that is closer to the attack source. The blocking of existing DDoS attack traffic is generally carried out on each IPS without a mechanism to share information on the source of the attack so that each IPS cannot cooperate. Also, even though the DDoS attack traffic did not reach the server because it had been blocked by IPS, the attack traffic still flooded the network so that network performance was reduced. Through smart contracts on the Ethereum blockchain, it is possible to inform the source of the attack or blacklisted IP addresses without requiring additional infrastructure. The blacklisted IP address is used by IPS to detect and handle DDoS attacks. Through the blacklisted IP distribution scheme, testing and analysis are carried out to see information on the source of the attack on each IPS and the attack traffic that passes on the network. The result is that each IPS can have the same blacklisted IP so that each IPS can have the same attack source information. The results also showed that the attack traffic through the network infrastructure can be drastically reduced. Initially, the total number of attack packets had an average of 115, 578 reduced to 27, 165.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The routing protocol efficiency of named data network"
        ],
        "penulis":"Wibowo, Tody Ariefianto;Syambas, Nana Rachmana;Hendrawan, Hendrawan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "An efficient routing protocol is needed in transmitting data on the network, especially on Named Data Network. This means that the routing mechanism must be made in such a way that the data transmission rate is close to the transmission link rate. This study investigates the effect of a geographic-based routing protocol compared to the link state from an efficiency point of view. The system model is built to see the effect of link bitrate, path stretch, packet header, and packet size on the efficiency of the routing protocol in sending data. From the mathematical model, Link State routing is outperformed geographic routing protocol for 24% on average.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An efficient routing protocol is needed in transmitting data on the network, especially on Named Data Network. This means that the routing mechanism must be made in such a way that the data transmission rate is close to the transmission link rate. This study investigates the effect of a geographic-based routing protocol compared to the link state from an efficiency point of view. The system model is built to see the effect of link bitrate, path stretch, packet header, and packet size on the efficiency of the routing protocol in sending data. From the mathematical model, Link State routing is outperformed geographic routing protocol for 24% on average.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The effect of drill reamer tool on cutting force and temperature when machining with different parameters and cutting condition"
        ],
        "penulis":"Rachmat H.;Rafai N.H.;Rahim E.A.;Kamdani K.;Adzman M.A.S.;Wong C.K.;Chong Y.L.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Normally in manufacturing process, drilling and reaming are separate processes. However a new tool is developed which combined both processes. In this study, the performance of a new drill reamer is studied in terms of cutting force and temperature under internal cooling, external cooling and minimum quantity lubricant (MQL) condition. Three types of tools are used to machine aluminum; 140\u00b0 twist drill, 140\u00b0 and 180\u00b0 drill reamer. Various values of feed were involved while cutting speed and depth of cut are kept constant. From the result it showed that 140\u00b0 twist drill has produced low cutting (thrust) force and temperature. In addition, low value of cutting force and temperature were also generated when applying low feed and internal cooling condition for all tools. \u00a9 2020 UTHM Publisher.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Normally in manufacturing process, drilling and reaming are separate processes. However a new tool is developed which combined both processes. In this study, the performance of a new drill reamer is studied in terms of cutting force and temperature under internal cooling, external cooling and minimum quantity lubricant (MQL) condition. Three types of tools are used to machine aluminum; 140\u00b0 twist drill, 140\u00b0 and 180\u00b0 drill reamer. Various values of feed were involved while cutting speed and depth of cut are kept constant. From the result it showed that 140\u00b0 twist drill has produced low cutting (thrust) force and temperature. In addition, low value of cutting force and temperature were also generated when applying low feed and internal cooling condition for all tools. \u00a9 2020 UTHM Publisher."
        ]
    },
    {
        "judul":[
            "Characterization of Electromagnetics Wave Absorber Composed of Ring Resonator Structure"
        ],
        "penulis":"Nusobri, Ichsan;Nur, Levy Olivia;Munir, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In absorbent applications, the technology of surface textured is often used to reduce the material thickness thus allowing the realization of thinner materials. In order to obtain high absorption rate of electromagnetics (EM) wave absorber at the desired frequency, a metal patch upon the wave absorber can be made in a specific shape. In this paper, a characterization of EM wave absorber composed of ring resonator structure is carried out by incorporating resistors between the ring resonator structures on two types of boundary condition, namely perfect electric conductor (PEC) and perfect magnetic conductor (PMC) to represent an infinite double periodic arrangement, and the radiation boundary to analyze the performance of proposed EM wave absorber in an actual condition. By using an FR4 epoxy dielectric substrate with the thickness of 1.6 mm, the proposed EM wave absorber is constructed by two-dimensional array of unit cells. Meanwhile, each unit cell has the dimension of 22 mm \u00d7 22 mm and is composed of a couple of ring resonator structures in a symmetrical configuration. Based on parametric studies, the resistor value required to be incorporated into the structure is in the range of 1 k to 6 k. The characterization result shows that the absorption rate of proposed EM wave absorber is-23.41 dB on the PEC and PMC boundaries with the resistor value of 6 k, and-18.3 dB on the radiation boundary with the resistor value of 5.6 k at the frequency of 2.45 GHz. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In absorbent applications, the technology of surface textured is often used to reduce the material thickness thus allowing the realization of thinner materials. In order to obtain high absorption rate of electromagnetics (EM) wave absorber at the desired frequency, a metal patch upon the wave absorber can be made in a specific shape. In this paper, a characterization of EM wave absorber composed of ring resonator structure is carried out by incorporating resistors between the ring resonator structures on two types of boundary condition, namely perfect electric conductor (PEC) and perfect magnetic conductor (PMC) to represent an infinite double periodic arrangement, and the radiation boundary to analyze the performance of proposed EM wave absorber in an actual condition. By using an FR4 epoxy dielectric substrate with the thickness of 1.6 mm, the proposed EM wave absorber is constructed by two-dimensional array of unit cells. Meanwhile, each unit cell has the dimension of 22 mm \u00d7 22 mm and is composed of a couple of ring resonator structures in a symmetrical configuration. Based on parametric studies, the resistor value required to be incorporated into the structure is in the range of 1 k to 6 k. The characterization result shows that the absorption rate of proposed EM wave absorber is-23.41 dB on the PEC and PMC boundaries with the resistor value of 6 k, and-18.3 dB on the radiation boundary with the resistor value of 5.6 k at the frequency of 2.45 GHz. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The effect of management style on accounting information systems"
        ],
        "penulis":"Meiryani;Suzan, Leny;Sudrajat, Jajat;Warganegara, Dezie Leonarda;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Management style is a complex concept. It is identified as a factor that can succeed or thwart the achievement of quality of a financial reporting system. The purpose of this study is to investigate through testing confirmation of management style influence on the quality of financial reporting systems. It was statistically processed using simple regression analysis. The research method used explanatory research method to get basic answers of causation by analysing the causes of the problems on the quality of financial reporting systems. The results of this study show that management style influences the quality of financial reporting systems and the problems of financial reporting systems which has not qualified occur because of the financial reporting systems which are less qualified, less integrated, less efficient and have not achieved optimal access. The financial reporting systems which have not qualified are because the management style does not fully guarantee the implementation of financial reporting systems. \u00a9 2020, Primrose Hall Publishing Group.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Management style is a complex concept. It is identified as a factor that can succeed or thwart the achievement of quality of a financial reporting system. The purpose of this study is to investigate through testing confirmation of management style influence on the quality of financial reporting systems. It was statistically processed using simple regression analysis. The research method used explanatory research method to get basic answers of causation by analysing the causes of the problems on the quality of financial reporting systems. The results of this study show that management style influences the quality of financial reporting systems and the problems of financial reporting systems which has not qualified occur because of the financial reporting systems which are less qualified, less integrated, less efficient and have not achieved optimal access. The financial reporting systems which have not qualified are because the management style does not fully guarantee the implementation of financial reporting systems. \u00a9 2020, Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Computational Parallel of K-Nearest Neighbor on Page Blocks Classification Dataset"
        ],
        "penulis":"Zaky, Damar;Gunawan P.H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "K-Nearest Neighbor (KNN) is considered as one of the simplest machine learning algorithms. While the implementation is quite simple, KNN is actually computationally expensive that makes it take a lot of time when it tries to predict. KNN has been known to be a lazy learning machine learning method that means that this method doesn't generalize the data, instead it has to memorize the training data, even when testing. This paper aims to optimize the KNN classifier to solve page blocks classification by making the algorithm parallel. The part of the KNN algorithm that is changed to become parallel is the outer part where the task for each test data is divided according to the number of processors. In this work, we use parallel KNN to classify page blocks. Page blocks are any blocks of a page layout that are detected by using a segmentation technique, the KNN is trained to classify whether a block is a vertical line, picture, text, horizontal line or graphic. The experiment shows that the KNN classifier obtains an accuracy of 93.51% and by using parallel KNN, a speedup of 4.64 times faster and an efficiency of 57.96% can be obtained by using 8 processors and an increasing number of grids up to 6040 while it obtains the same accuracy as serial.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "K-Nearest Neighbor (KNN) is considered as one of the simplest machine learning algorithms. While the implementation is quite simple, KNN is actually computationally expensive that makes it take a lot of time when it tries to predict. KNN has been known to be a lazy learning machine learning method that means that this method doesn't generalize the data, instead it has to memorize the training data, even when testing. This paper aims to optimize the KNN classifier to solve page blocks classification by making the algorithm parallel. The part of the KNN algorithm that is changed to become parallel is the outer part where the task for each test data is divided according to the number of processors. In this work, we use parallel KNN to classify page blocks. Page blocks are any blocks of a page layout that are detected by using a segmentation technique, the KNN is trained to classify whether a block is a vertical line, picture, text, horizontal line or graphic. The experiment shows that the KNN classifier obtains an accuracy of 93.51% and by using parallel KNN, a speedup of 4.64 times faster and an efficiency of 57.96% can be obtained by using 8 processors and an increasing number of grids up to 6040 while it obtains the same accuracy as serial.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A multi tone modeling for seismic data compression"
        ],
        "penulis":"Liu, Bo;Mohandes M.;Nuha H.;Deriche M.;Iqbal, Naveed;Fekri, Faramarz;McClellan, James H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This work develops a multi tone modeling for seismic data compression. First, seismic traces are described as multitone decaying sinusoidal waves superposition. Each sinusoidal wave is regarded as a model component and is represented by a set of distinct parameters. Secondly, a novel parameter estimation algorithm for this model is proposed accordingly. In this algorithm, the parameters are estimated for each component sequentially. A suitable number of model components is determined by the level of the residuals energy. The proposed model-based compression scheme outperforms the Linear Predictive Coding (LPC) both analytically and experimentally in terms of compression ratio, reconstruction quality and convergence rate. \u00a9 2019 SEG"
        ]
    },
    {
        "judul":[
            "Using long-range wireless sensor network to track the illegal cutting log"
        ],
        "penulis":"Mutiara, Giva Andriana;Herman, Nanna Suryana;Mohd, Othman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, the need for wireless sensing applications is increasing. Along with the increased illegal cutting of logs in the forest, however, it requires the integration application to tackle the illegal logging and forest preservation. The wireless sensor network is a suitable network architecture for remotely monitoring or tracking applications in the environment. This paper proposed an integrated system that can identify and track the position of a moving cutting log. An Arduino Uno, Raspberry Pi 3 B+, sound sensor, accelerometer sensor, LoRa GPS HAT Shield, and Outdoor LoRa Gateway OLG01 performed the hardware monitoring and tracking of the proposed system. The network of STAR topology configuration between master and slaves is represented by the LoRa Network embedded with the sensors, as an architecture of the wireless sensor network. The system was examined the performance of the network and the tracking process. The result determined that the LoRa can detect and identify the occurrence of the illegal cutting of logs in real-time. Meanwhile, in terms of the tracking performance, a duration of 5\u201346 s was required to track the new position of the moving cutting log. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "Sustainable Development Goals mapped to this documentLife on landGoal 15",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, the need for wireless sensing applications is increasing. Along with the increased illegal cutting of logs in the forest, however, it requires the integration application to tackle the illegal logging and forest preservation. The wireless sensor network is a suitable network architecture for remotely monitoring or tracking applications in the environment. This paper proposed an integrated system that can identify and track the position of a moving cutting log. An Arduino Uno, Raspberry Pi 3 B+, sound sensor, accelerometer sensor, LoRa GPS HAT Shield, and Outdoor LoRa Gateway OLG01 performed the hardware monitoring and tracking of the proposed system. The network of STAR topology configuration between master and slaves is represented by the LoRa Network embedded with the sensors, as an architecture of the wireless sensor network. The system was examined the performance of the network and the tracking process. The result determined that the LoRa can detect and identify the occurrence of the illegal cutting of logs in real-time. Meanwhile, in terms of the tracking performance, a duration of 5\u201346 s was required to track the new position of the moving cutting log. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Godunov method for Stefan problems with Neumann and Robin type boundary condition using dimensionless enthalpy formulation"
        ],
        "penulis":"Ihsan A.F.;Tuwankotta J.M.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A Stefan problem is a boundary value problem where the position of one of the boundaries is time-dependent. In this article, we consider one-dimensional phase-change Stefan problems where the fixed boundary is Neumann-type and Robin-type. We solve the problem using a numerical approach by deriving dimensionless enthalpy formulation based on suitable finite difference approximation. Numerical schema is obtained by applying the Godunov method on the formulation. We use several cases of various functions for boundary conditions and small initial conditions. The result obtained provide important information to develop a currently unavailable exact solution or another approximation solution. \u00a9 2020 American Institute of Physics Inc.. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A Stefan problem is a boundary value problem where the position of one of the boundaries is time-dependent. In this article, we consider one-dimensional phase-change Stefan problems where the fixed boundary is Neumann-type and Robin-type. We solve the problem using a numerical approach by deriving dimensionless enthalpy formulation based on suitable finite difference approximation. Numerical schema is obtained by applying the Godunov method on the formulation. We use several cases of various functions for boundary conditions and small initial conditions. The result obtained provide important information to develop a currently unavailable exact solution or another approximation solution. \u00a9 2020 American Institute of Physics Inc.. All rights reserved."
        ]
    },
    {
        "judul":[
            "Pre Cervical Cancer Detection on Visual Inspection of Acetic Acid (VIA) Test Image Using K-Means Clustering Method"
        ],
        "penulis":"Ariyani, Ria;Ramadhani, Kurniawan Nur;Tresna Sania Putra, Hilman Fauzi;Harsono, Ali Budi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We built an approach in early detection of cervical cancer using image recognition of Visual Inspection with Acetic Acid (VIA) image. We used k-Means clustering to segment the expected region of cervical cell in the VIA test image. The positive suspect shown by white lesion which are called acetowhite. We used VIA test image captured from mobile phone as the dataset. From the acetowhite area, we extracted the color moment feature and the Gray Level Co-occurence Matrix (GLCM) feature. The color moment and GLCM feature were then classified as positive or negative using Support Vector Machine (SVM) classifier. The best performance were an accuracy of 72,14%, with sensitivity of 70% and specificity of 74% using k-Means clustering with k=2 and SVM with linear kernel. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We built an approach in early detection of cervical cancer using image recognition of Visual Inspection with Acetic Acid (VIA) image. We used k-Means clustering to segment the expected region of cervical cell in the VIA test image. The positive suspect shown by white lesion which are called acetowhite. We used VIA test image captured from mobile phone as the dataset. From the acetowhite area, we extracted the color moment feature and the Gray Level Co-occurence Matrix (GLCM) feature. The color moment and GLCM feature were then classified as positive or negative using Support Vector Machine (SVM) classifier. The best performance were an accuracy of 72,14%, with sensitivity of 70% and specificity of 74% using k-Means clustering with k=2 and SVM with linear kernel. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Analysis of Message Broker for Communication in Fog Computing"
        ],
        "penulis":"Bagaskara, Aditya Eka;Setyorini, Setyorini;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this research, performance testing is performed between the two most popular message brokers, which commonly used in the enterprise, namely RabbitMQ and Apache Kafka in the fog computing environment. REST API is a method that implements the HTTP protocol and commonly used in the Internet of Things as a communication media between devices. Hence the performance will degrade when the amount of request is abundant and less reliable due to its synchronous communication. By using a message broker as the medium of communication between devices in fog computing, each connected device will not rely on each other and will make the message delivery more guaranteed. By reason, this research will implement a message broker for communication between devices in fog computing. Today there are many message brokers developed by various companies or communities. Choosing an unsuitable message broker can cause performance degradation, which results in a chaotic IoT system. The test results show that Apache Kafka has a higher throughput than RabbitMQ when the message size is calculable. However, when the message size is myriad, RabbitMQ is much better because the bottleneck of disk I\/O usage occurred in Kafka. Nevertheless, in latency testing, RabbitMQ is always better even though the difference is not too far. This testing can also be concluded that the use of message broker in fog computing that extends the cloud computing architecture proven effective in implementing the IoT system. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this research, performance testing is performed between the two most popular message brokers, which commonly used in the enterprise, namely RabbitMQ and Apache Kafka in the fog computing environment. REST API is a method that implements the HTTP protocol and commonly used in the Internet of Things as a communication media between devices. Hence the performance will degrade when the amount of request is abundant and less reliable due to its synchronous communication. By using a message broker as the medium of communication between devices in fog computing, each connected device will not rely on each other and will make the message delivery more guaranteed. By reason, this research will implement a message broker for communication between devices in fog computing. Today there are many message brokers developed by various companies or communities. Choosing an unsuitable message broker can cause performance degradation, which results in a chaotic IoT system. The test results show that Apache Kafka has a higher throughput than RabbitMQ when the message size is calculable. However, when the message size is myriad, RabbitMQ is much better because the bottleneck of disk I\/O usage occurred in Kafka. Nevertheless, in latency testing, RabbitMQ is always better even though the difference is not too far. This testing can also be concluded that the use of message broker in fog computing that extends the cloud computing architecture proven effective in implementing the IoT system. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Experimental and Simulation Approach for Water Bed Movements"
        ],
        "penulis":"Jaya, Alya Alifia Anwar;Gunawan P.H.;Aditsania, Annisa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper examines the simulation of a 1D half nonlinear shallow water model using a staggered grid scheme for comparing with experiment results. Here, the experiment of the moving bottom problem in one-directional horizontal is given. The experiment was built in a glass basin with an obstacle as the moving bottom. Indeed, the impact of moving the bottom in shallow water can generate surface waves with various elevation values. The results showed that numerical simulation using nonlinear shallow water equations is close enough with the experimental data. The comparison of water elevation from simulation results and experimental data is observed in three gauge which are shown as G 1, G 2, and G 3. Using the initial condition of water elevation 0.1 m, then the error measurement of each gauge are obtained less than 10 {-3}.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper examines the simulation of a 1D half nonlinear shallow water model using a staggered grid scheme for comparing with experiment results. Here, the experiment of the moving bottom problem in one-directional horizontal is given. The experiment was built in a glass basin with an obstacle as the moving bottom. Indeed, the impact of moving the bottom in shallow water can generate surface waves with various elevation values. The results showed that numerical simulation using nonlinear shallow water equations is close enough with the experimental data. The comparison of water elevation from simulation results and experimental data is observed in three gauge which are shown as G 1, G 2, and G 3. Using the initial condition of water elevation 0.1 m, then the error measurement of each gauge are obtained less than 10 {-3}.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Analysis of On-Off Keying Modulation on Underwater Visible Light Communication"
        ],
        "penulis":"Amalia, Annisa Izmi;Hambali, Akhmad;Pamukti, Brian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research evaluates the performance of On-Off Keying (OOK) Modulation on the Underwater Visible Light Communication (UVLC) system. This research analyses the performance of two types of OOK signal formats, Non-Return to Zero (OOK-NRZ) and Return to Zero (OOK-RZ). This signal formats tested on distance, acceptability, Signal to Noise Ratio (SNR), Q-factor and Bit Error Rate (BER) parameters. From extensive simulations that have been done, the results show that the received power decreased 21.7249 % at the maximum distance. In this condition, the UVLC system produced the BER value of the NRZ format 3.28 \u00d7 smaller than the RZ format. The SNR minimum that produced BER value less than the threshold for NRZ format is 17.925% smaller than the RZ format. Meanwhile, the minimum Q-factor that produced BER value less than 10-3for NRZ modulation is 6 \u00d7 smaller than the RZ modulation format. From the results, we take the conclusion that the OOK-NRZ better than OOK-RZ on the UVLC system. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research evaluates the performance of On-Off Keying (OOK) Modulation on the Underwater Visible Light Communication (UVLC) system. This research analyses the performance of two types of OOK signal formats, Non-Return to Zero (OOK-NRZ) and Return to Zero (OOK-RZ). This signal formats tested on distance, acceptability, Signal to Noise Ratio (SNR), Q-factor and Bit Error Rate (BER) parameters. From extensive simulations that have been done, the results show that the received power decreased 21.7249 % at the maximum distance. In this condition, the UVLC system produced the BER value of the NRZ format 3.28 \u00d7 smaller than the RZ format. The SNR minimum that produced BER value less than the threshold for NRZ format is 17.925% smaller than the RZ format. Meanwhile, the minimum Q-factor that produced BER value less than 10-3for NRZ modulation is 6 \u00d7 smaller than the RZ modulation format. From the results, we take the conclusion that the OOK-NRZ better than OOK-RZ on the UVLC system. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Design of Landslide Early Warning System Using Fuzzy Method Based on Android"
        ],
        "penulis":"Fatimah, Putri;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In Indonesia, landslides are one of the many natural disasters that often occur during the rainy season. Especially in mountainous areas, cliffs, hills, which cause many losses. Therefore, it is necessary to create a landslide Early Warning System. Slope, vibration, and excessive water content in the soil are the leading causes of landslides. To measure these parameters, an Internet of Things (IoT) based system is used that is connected to various sensors. In this study, the fuzzy value obtained from the measurement of the MPU6050 Accelerometer and Gyroscope sensor, also Soil Moisture sensor sent to the Antares server using LoRa. In research, Fuzzy algorithm is used to analyze the sensor detection results in the form of three final decision rules based on the knowledge of a landslide expert, namely Safe, Alert, and Watch out, which can be seen on an android device with 90% accuracy value and 10% error. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In Indonesia, landslides are one of the many natural disasters that often occur during the rainy season. Especially in mountainous areas, cliffs, hills, which cause many losses. Therefore, it is necessary to create a landslide Early Warning System. Slope, vibration, and excessive water content in the soil are the leading causes of landslides. To measure these parameters, an Internet of Things (IoT) based system is used that is connected to various sensors. In this study, the fuzzy value obtained from the measurement of the MPU6050 Accelerometer and Gyroscope sensor, also Soil Moisture sensor sent to the Antares server using LoRa. In research, Fuzzy algorithm is used to analyze the sensor detection results in the form of three final decision rules based on the knowledge of a landslide expert, namely Safe, Alert, and Watch out, which can be seen on an android device with 90% accuracy value and 10% error. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "ITSM Analysis using ITIL V3 in Service Operation in PT.Inovasi Tjaraka Buana"
        ],
        "penulis":"Lubis, Muharman;Annisyah, Rizky Cherthio;Lyvia Winiyanti L.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT. Inovasi Tjaraka Buana is a company in ISP (Internet Service Provider) sector that uses information technology to sustain activities the company. At this time the company is experiencing scaling-up, which is a drastic increase in the number of user of internet services, and coverage areas that make companies have to develop for various aspects of the company. The problem is that companies cannot at this time balancing service operations when handling an incident that occurs with drastic addition of the number of users and the amount of coverage area. To solve the problem, it is necessary to implement Information Technology Service Management (ITSM). The method used in this research is data collection by interview and observation techniques. This research will produce Incident Management Flow and Problem Management Flow. ITIL, which is a framework that illustrates best practices that focus on managing IT services, IT development and operations, which can help companies to overcome problems, so the company can apply it in order to balance service operations when handling incidents that occur. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. Inovasi Tjaraka Buana is a company in ISP (Internet Service Provider) sector that uses information technology to sustain activities the company. At this time the company is experiencing scaling-up, which is a drastic increase in the number of user of internet services, and coverage areas that make companies have to develop for various aspects of the company. The problem is that companies cannot at this time balancing service operations when handling an incident that occurs with drastic addition of the number of users and the amount of coverage area. To solve the problem, it is necessary to implement Information Technology Service Management (ITSM). The method used in this research is data collection by interview and observation techniques. This research will produce Incident Management Flow and Problem Management Flow. ITIL, which is a framework that illustrates best practices that focus on managing IT services, IT development and operations, which can help companies to overcome problems, so the company can apply it in order to balance service operations when handling incidents that occur. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Effect of fermented feed supplementation in circulated aquaponic system with catfish (Clarias sp.) on growth of lettuce (Lactuca sativa L.)"
        ],
        "penulis":"Handayani R.;Dinoto A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Aquaponic systems of aquatic animal-plant are a model for conversion of waste into plant substrates and its efficacy is estimated depending on the type of feed given. This study aims to investigate the effect of fermented feed in the circulating aquaponics system with catfish (Clarias sp.) on the growth of lettuce (Lactuca sativa L.). The study was carried out in a circulated serial aquaculture tanks containing catfish. Various inputs of fermented fish feed was applied including low concentration (6% of fish weight) and high concentration (9% of fish weight). The growth of lettuce, water quality, and total microorganisms were measured. As results, maximum length and width of lettuce were higher in supplementation of higher feed concentrations (9%), as well as tendency height and weight of plant clumps plant. \u00a9 the author(s)",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Aquaponic systems of aquatic animal-plant are a model for conversion of waste into plant substrates and its efficacy is estimated depending on the type of feed given. This study aims to investigate the effect of fermented feed in the circulating aquaponics system with catfish (Clarias sp.) on the growth of lettuce (Lactuca sativa L.). The study was carried out in a circulated serial aquaculture tanks containing catfish. Various inputs of fermented fish feed was applied including low concentration (6% of fish weight) and high concentration (9% of fish weight). The growth of lettuce, water quality, and total microorganisms were measured. As results, maximum length and width of lettuce were higher in supplementation of higher feed concentrations (9%), as well as tendency height and weight of plant clumps plant. \u00a9 the author(s)"
        ]
    },
    {
        "judul":[
            "Variable range hopping resistivity in la2-xsrxcuo4nanoparticles evaluated by four point probe method"
        ],
        "penulis":"Winarsih, Suci;Budiman, Faisal;Tanaka, Hirofumi;Adachi, Tadashi;Goto, Takayuki;Soegijono, Bambang;Kurniawan, Budhy;Watanabe, Isao;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We report the results of the resistivity measurement on La2-xSrxCuO4 nanoparticles with x = 0, 0.05, and 0.20 evaluated by the four-point probe method. The high resistivity value shows the predominance of the inter-grain part. The temperature dependence of the conductivity can be analyzed by variable range hopping model showing the charge carriers are formed by thermal activation. There is no superconducting behavior that could be observed in La2-xSrxCuO4 nanoparticles with x = 0.05 and 0.20. \u00a9 2020 Trans Tech Publications Ltd, Switzerland.",
            "InView detailsExpand Substance indium",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We report the results of the resistivity measurement on La2-xSrxCuO4 nanoparticles with x = 0, 0.05, and 0.20 evaluated by the four-point probe method. The high resistivity value shows the predominance of the inter-grain part. The temperature dependence of the conductivity can be analyzed by variable range hopping model showing the charge carriers are formed by thermal activation. There is no superconducting behavior that could be observed in La2-xSrxCuO4 nanoparticles with x = 0.05 and 0.20. \u00a9 2020 Trans Tech Publications Ltd, Switzerland."
        ]
    },
    {
        "judul":[
            "Hyperparameter Setting of LSTM-based Language Model using Grey Wolf Optimizer"
        ],
        "penulis":"Aufa, Bilal Zahran;Suyanto, Suyanto;Arifianto, Anditya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Hyperparameters is one of the most essential part of deep learning, because they can give big impact to the performance of the model. Recent works show that if the hyperparameters of a Long Short-Term Memory (LSTM) are carefully adjusted or optimized, its performance can achieve the same performance as the more complex LSTM model. Previously, several methods such as grid search and random search is introduced to solve this hyperparameters optimization problem, but it is still not effective enough. Hence, it opens opportunities for meta-heuristic nature-inspired approach like Swarm Intelligence (SI) method to solve this hyperparameter optimization problem. The main advantage of this method is the behaviour of the algorithm that has exploring-exploiting process in order to find the global optima solution in the search space. Algorithm such as Grey Wolf Optimizer (GWO) are one of the SI algorithms that have a promising performance in optimization problem in various field. The algorithm has balanced exploring-exploiting process, that can make the optimization are more effective. Therefore, in this paper the GWO is exploited to optimize the LSTM hyperparameters for a language modeling task. Evaluation for the Penn Tree Bank dataset shows that GWO is capable of giving an optimum hyperparameters of the LSTM.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hyperparameters is one of the most essential part of deep learning, because they can give big impact to the performance of the model. Recent works show that if the hyperparameters of a Long Short-Term Memory (LSTM) are carefully adjusted or optimized, its performance can achieve the same performance as the more complex LSTM model. Previously, several methods such as grid search and random search is introduced to solve this hyperparameters optimization problem, but it is still not effective enough. Hence, it opens opportunities for meta-heuristic nature-inspired approach like Swarm Intelligence (SI) method to solve this hyperparameter optimization problem. The main advantage of this method is the behaviour of the algorithm that has exploring-exploiting process in order to find the global optima solution in the search space. Algorithm such as Grey Wolf Optimizer (GWO) are one of the SI algorithms that have a promising performance in optimization problem in various field. The algorithm has balanced exploring-exploiting process, that can make the optimization are more effective. Therefore, in this paper the GWO is exploited to optimize the LSTM hyperparameters for a language modeling task. Evaluation for the Penn Tree Bank dataset shows that GWO is capable of giving an optimum hyperparameters of the LSTM.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "High Throughput Satellite using Ka-Band for Government Multifunctional Services in Indonesia: Study of Link Budget and Capacity Analysis"
        ],
        "penulis":"Kristiadi, Ignatius Daru;Nashiruddin, Muhammad Imam;Sudjai, Miftadi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Satellite infrastructure has a vital role in delivering communication services throughout Indonesia as one of the biggest archipelagic countries in the world. The high throughput satellite (HTS) can be the best choice considering the uneven distribution of terrestrial infrastructure networks, especially in the corners and isolated areas of Indonesia. In this paper, a study is conducted related to link budget and capacity analysis on the high throughput satellite using the proposed Ka-band frequency plan. The purpose of this study is to find out how far the link capability and capacity can be provided by HTS if it is operating in the proposed Ka-band frequency plan associated with Indonesia's environmental conditions. The result of this study on link budget analysis shows that using its Ka-Band frequency plan as the proposed assigned frequency is suitable and feasible to be implemented in the near future of the HTS system for government multifunctional services over Indonesia. It is indicated by the positive value of C\/N obtained from link budget analysis for each link of each scenario in this research. Besides that, the estimation for capacity analysis of communication that is able to be provided by its HTS is enormous enough to handle the data services needs over Indonesia, which is 38.41-93.54 Gbps depends on environment condition. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Satellite infrastructure has a vital role in delivering communication services throughout Indonesia as one of the biggest archipelagic countries in the world. The high throughput satellite (HTS) can be the best choice considering the uneven distribution of terrestrial infrastructure networks, especially in the corners and isolated areas of Indonesia. In this paper, a study is conducted related to link budget and capacity analysis on the high throughput satellite using the proposed Ka-band frequency plan. The purpose of this study is to find out how far the link capability and capacity can be provided by HTS if it is operating in the proposed Ka-band frequency plan associated with Indonesia's environmental conditions. The result of this study on link budget analysis shows that using its Ka-Band frequency plan as the proposed assigned frequency is suitable and feasible to be implemented in the near future of the HTS system for government multifunctional services over Indonesia. It is indicated by the positive value of C\/N obtained from link budget analysis for each link of each scenario in this research. Besides that, the estimation for capacity analysis of communication that is able to be provided by its HTS is enormous enough to handle the data services needs over Indonesia, which is 38.41-93.54 Gbps depends on environment condition. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Univariate Time Series Data Forecasting of Air Pollution using LSTM Neural Network"
        ],
        "penulis":"Hamami, Faqih;Dahlan, Iqbal Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Air pollution is an important issue around the world. It can threaten the human life environment and affect illness or even death. Internet of Things (IoT) is a technology that can monitor air quality. It can transmit data in real time and with good latency. Some pollutants in the air can be dangerous at high concentrations. The prediction of time series data from pollutants transmitted by IoT is one step for preventing unwanted conditions in future such as unhealthy environments or becoming uninhabitable due to dangerous air pollution. This paper proposes to build a neural network model using LSTM to forecast air pollution concentrations in the air. The model predicts five air pollution indicators including PM10, SO2, CO, O3, and NO2. The results reveal that the Root Mean Square Error of LSTM model is 5.58. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Air pollution is an important issue around the world. It can threaten the human life environment and affect illness or even death. Internet of Things (IoT) is a technology that can monitor air quality. It can transmit data in real time and with good latency. Some pollutants in the air can be dangerous at high concentrations. The prediction of time series data from pollutants transmitted by IoT is one step for preventing unwanted conditions in future such as unhealthy environments or becoming uninhabitable due to dangerous air pollution. This paper proposes to build a neural network model using LSTM to forecast air pollution concentrations in the air. The model predicts five air pollution indicators including PM10, SO2, CO, O3, and NO2. The results reveal that the Root Mean Square Error of LSTM model is 5.58. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The influence of children's playroom interior aspect in regard to parental safety perception. Case study: Children's playroom at 23 Paskal Bandung, Indonesia"
        ],
        "penulis":"Rachmawati, Rizka;Hanom, Imtihan;Salayanti, Santi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Children's playrooms in public spaces need to consider the safety of their interior elements. Previous studies also discussed about things that need to be taken into account to assure the children's safety while playing. However, some parents join their children playing in public spaces due to the cautiousness of playground safety level. This study was conducted to understand how far the interior aspects of children's playgrounds can affect parents' safety perception to let their children play by themselves in public spaces, for example, the children's playroom in 23 Paskal Bandung, West Java, Indonesia. The result shows that sufficient light, interior finishes, and noise or sound intensity in the children's playground at 23 Paskal Bandung, Indonesia can make parents feel safe to let their children spend time there. \u00a9 Malaysian Public Health Physicians Association.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Children's playrooms in public spaces need to consider the safety of their interior elements. Previous studies also discussed about things that need to be taken into account to assure the children's safety while playing. However, some parents join their children playing in public spaces due to the cautiousness of playground safety level. This study was conducted to understand how far the interior aspects of children's playgrounds can affect parents' safety perception to let their children play by themselves in public spaces, for example, the children's playroom in 23 Paskal Bandung, West Java, Indonesia. The result shows that sufficient light, interior finishes, and noise or sound intensity in the children's playground at 23 Paskal Bandung, Indonesia can make parents feel safe to let their children spend time there. \u00a9 Malaysian Public Health Physicians Association."
        ]
    },
    {
        "judul":[
            "The P1- P1NCFinite Element Method for 1D wave simulation using Shallow Water Equations"
        ],
        "penulis":"Swastika P.V.;Pudjaprasetya S.R.;Adytia D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We study a simple numerical scheme based on a new type of Finite Element Method (FEM) to solve the 1D Shallow Water Equations. In the new scheme, the surface elevation variable is approximated by a linear continuous basis function (P 1) and the velocity potential variable is approximated by the one-dimensional discontinuous linear non-conforming basis function (P1NC). Here, we implement the P 1 - P1NC finite element pair to solve the 1D Shallow Water Equations on a structured grid, whereas the Runge Kutta method is adopted for time integration. We verified the resulting scheme by conducting several simulations such as a standing wave simulation, and propagation of an initial hump over sloping bathymetry. The resulting scheme free from numerical damping error, conservative and both standing wave and shoaling phenomena are well simulated.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We study a simple numerical scheme based on a new type of Finite Element Method (FEM) to solve the 1D Shallow Water Equations. In the new scheme, the surface elevation variable is approximated by a linear continuous basis function (P 1) and the velocity potential variable is approximated by the one-dimensional discontinuous linear non-conforming basis function (P1NC). Here, we implement the P 1 - P1NC finite element pair to solve the 1D Shallow Water Equations on a structured grid, whereas the Runge Kutta method is adopted for time integration. We verified the resulting scheme by conducting several simulations such as a standing wave simulation, and propagation of an initial hump over sloping bathymetry. The resulting scheme free from numerical damping error, conservative and both standing wave and shoaling phenomena are well simulated.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "MSOF-DT Strategy and Its Impact on Real-Time Systems Scheduling"
        ],
        "penulis":"Yulianto, Fazmah Arif;Kuspriyanto;Mengko, Richard Karel Willem;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "When managing Real-Time System execution, dynamic deadlines are problems that are not easy to handle. If a real-time computation is built using the traditional approach (Run-to-Completion), then there is no tolerance for the time of completion of the execution. Using the MSOF-DT computation strategy, the RT task can be more tolerant of the reduced processing time (deadline changes). Besides that, in this paper, we also propose a real-time process scheduling algorithm based on the MSOF-DT strategy, called EDSEF\/MSOF-DT. The schedulability of the schedule produced by EDSEF\/MSOF-DT can be better than the schedule generated by the EDF algorithm and also higher than using (Min-D+ Min-C) policy alone without MSOF-DT, both in cases without interruptions or cases that contain interruptions.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "When managing Real-Time System execution, dynamic deadlines are problems that are not easy to handle. If a real-time computation is built using the traditional approach (Run-to-Completion), then there is no tolerance for the time of completion of the execution. Using the MSOF-DT computation strategy, the RT task can be more tolerant of the reduced processing time (deadline changes). Besides that, in this paper, we also propose a real-time process scheduling algorithm based on the MSOF-DT strategy, called EDSEF\/MSOF-DT. The schedulability of the schedule produced by EDSEF\/MSOF-DT can be better than the schedule generated by the EDF algorithm and also higher than using (Min-D+ Min-C) policy alone without MSOF-DT, both in cases without interruptions or cases that contain interruptions.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Comparison Method for Handling Missing Data in Clinical Studies"
        ],
        "penulis":"Nugroho, Heru;Utama, Nugraha Priya;Surendro, Kridanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Missing data is an issue that cannot be avoided. Most data mining algorithms cannot work with data that consist of missing values. Complete case analysis, single imputation, multiple imputations, and kNN imputation are some methods that can be used to handle the missing data. Each method has is own advantages and disadvantages. This paper compares of these methods using datasets in clinical studies, chronic kidney disease, Indian Pima diabetes, thyroid, and hepatitis. The accuracy of each method was compared using several classifiers. The experimental results show that kNN imputation method provides better accuracy than other methods. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Missing data is an issue that cannot be avoided. Most data mining algorithms cannot work with data that consist of missing values. Complete case analysis, single imputation, multiple imputations, and kNN imputation are some methods that can be used to handle the missing data. Each method has is own advantages and disadvantages. This paper compares of these methods using datasets in clinical studies, chronic kidney disease, Indian Pima diabetes, thyroid, and hepatitis. The accuracy of each method was compared using several classifiers. The experimental results show that kNN imputation method provides better accuracy than other methods. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Estimation and Correlation of Surian Leaves (Toona Sinensis) Weight with the Tree Parameters"
        ],
        "penulis":"Lastini, Tien;Hernawan, Endang;Rosmiati, Mia;Putra, Ramadhani E.;Rahmayunita, Ira;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Leaves of surian tree (Toona sinensis) based on the research, can be used for medications, such as diabetes, cancer, and others. At the present the people is being switched from chemical drugs to herbal medicines. Therefore, surian leaves is one source of herbal medicine to be developed in the future. However, information of leaves biomass in each tree relating to ages and tree parameters is unknown. This study aims to determine the weight of surian leaves on each tree and to examine the relationship of leaves weight with several tree dparameters. The study was conducted on private forests in Sumedang District. The sample of 110 trees were taken purposively. Tree parameters were measured, namely: Diameter Breast Height (DBH), total height, timber height, crown height, crown diameter, age, and leaves weight of each tree. The results of the correlation analysis showed that there was a significant relationship between four parameters of the tree, namely DBH, total height, crown height, and crown diameter with surian leaves weight. The highest correlation with the weight of surian leaves is DBH, amounting to 0.75. Estimated weight of leaves in DBH 10-19 cm is 8-11 kg\/tree. Whereas for DBH above equal to 20 cm is 18-23 kg\/tree. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Leaves of surian tree (Toona sinensis) based on the research, can be used for medications, such as diabetes, cancer, and others. At the present the people is being switched from chemical drugs to herbal medicines. Therefore, surian leaves is one source of herbal medicine to be developed in the future. However, information of leaves biomass in each tree relating to ages and tree parameters is unknown. This study aims to determine the weight of surian leaves on each tree and to examine the relationship of leaves weight with several tree dparameters. The study was conducted on private forests in Sumedang District. The sample of 110 trees were taken purposively. Tree parameters were measured, namely: Diameter Breast Height (DBH), total height, timber height, crown height, crown diameter, age, and leaves weight of each tree. The results of the correlation analysis showed that there was a significant relationship between four parameters of the tree, namely DBH, total height, crown height, and crown diameter with surian leaves weight. The highest correlation with the weight of surian leaves is DBH, amounting to 0.75. Estimated weight of leaves in DBH 10-19 cm is 8-11 kg\/tree. Whereas for DBH above equal to 20 cm is 18-23 kg\/tree. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Developing project schedule in telecommunication projects using critical path method (CPM)"
        ],
        "penulis":"Kusumadarma, Indri Alvi;Pratami, Devi;Yasa, I Putu;Tripiawan, Wawan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Increased public demand for stable internet network services requires companies engaged in telecommunications to always improve their technological capabilities. One way to improve technological capability is to use basic materials or supporting materials, that is fiber optics (FO). PT. XYZ is a company engaged in the field of telecommunications in several years ago. In general, projects in PT. XYZ experience more frequent delays, one of the most influencing factors that they are not applying the method appropriate to the type of project. If the project schedule does not use a method that is appropriate to the type of project being undertaken, then the result is a delay in the implementation of the project. In a project with small or large scopes, processes such as defining activities, sorting activities, estimating duration and making the Schedule Model are so closely tied to each other that they can be viewed as a Single Process that can be done\/done by a person in a relatively short period of time. Therefore, this study focuses on the design of the feeder cabling project schedule in STO Nanjung by using CPM method. The calculation results using the CPM method indicate that the completion time of the Feeder FO cable project is 46 days with 16 critical activities. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Increased public demand for stable internet network services requires companies engaged in telecommunications to always improve their technological capabilities. One way to improve technological capability is to use basic materials or supporting materials, that is fiber optics (FO). PT. XYZ is a company engaged in the field of telecommunications in several years ago. In general, projects in PT. XYZ experience more frequent delays, one of the most influencing factors that they are not applying the method appropriate to the type of project. If the project schedule does not use a method that is appropriate to the type of project being undertaken, then the result is a delay in the implementation of the project. In a project with small or large scopes, processes such as defining activities, sorting activities, estimating duration and making the Schedule Model are so closely tied to each other that they can be viewed as a Single Process that can be done\/done by a person in a relatively short period of time. Therefore, this study focuses on the design of the feeder cabling project schedule in STO Nanjung by using CPM method. The calculation results using the CPM method indicate that the completion time of the Feeder FO cable project is 46 days with 16 critical activities. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office."
        ]
    },
    {
        "judul":[
            "Experimental characterization of AMC-based thin tunable absorber using varactor diode"
        ],
        "penulis":"Hanifah, Muthia;Nur, Levy Olivia;Taufiqqurrachman;Armi, Nasrullah;Sarief, Ivany;Munir, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper deals with the experimental characterization of thin tunable absorber developed based on artificial magnetic conductor (AMC). To produce the tunable frequency response, the varactor diodes with varied reverse DC bias voltage are incorporated into the AMC structure of proposed absorber. By using an equivalent circuit of varactor diode, the performance of AMC-based thin tunable absorber is characterized through a simulation software. To improve the absorptivity, a resistor with the value of 470\u03a9 is also incorporated into the AMC structure in parallel to each varactor diode. A 1.6mm thick FR4 epoxy dielectric substrate with the dimension of 104mm \u00d7 104mm is used for deploying the design as well as for the realization. The experimental characterization which is performed using a horn antenna shows that the realized absorber has a tunable frequency response from the frequency of 2.26GHz with the reflection coefficient (S11) value of -21.5dB at the reverse DC bias voltage of 0V to the frequency of 3.01GHz with the S11 value of -19.75dB at the reverse DC bias voltage of 10V. This performance is comparable to the simulation result for the proposed absorber with the varactor diode and 470\u03a9 resistor incorporation.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper deals with the experimental characterization of thin tunable absorber developed based on artificial magnetic conductor (AMC). To produce the tunable frequency response, the varactor diodes with varied reverse DC bias voltage are incorporated into the AMC structure of proposed absorber. By using an equivalent circuit of varactor diode, the performance of AMC-based thin tunable absorber is characterized through a simulation software. To improve the absorptivity, a resistor with the value of 470\u03a9 is also incorporated into the AMC structure in parallel to each varactor diode. A 1.6mm thick FR4 epoxy dielectric substrate with the dimension of 104mm \u00d7 104mm is used for deploying the design as well as for the realization. The experimental characterization which is performed using a horn antenna shows that the realized absorber has a tunable frequency response from the frequency of 2.26GHz with the reflection coefficient (S11) value of -21.5dB at the reverse DC bias voltage of 0V to the frequency of 3.01GHz with the S11 value of -19.75dB at the reverse DC bias voltage of 10V. This performance is comparable to the simulation result for the proposed absorber with the varactor diode and 470\u03a9 resistor incorporation.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A comprehensive energy efficiency study of segmented annular thermoelectric generator; thermal, exergetic and economic analysis"
        ],
        "penulis":"Tian, Man-Wen;Mihardjo, Leonardus W.W.;Moria, Hazim;Asaadi, Soheil;Sadighi Dizaji, Hamed;Khalilarya, Shahram;Nguyen, Phong Thanh;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Annular thermoelectric generator (ATEG) has not been commercialized yet and many studies are required to identify its characteristics from different viewpoints. Most recently, segmented annular thermoelectric was proposed as an efficient structure for annular thermoelectric in which each leg of thermoelectric (n-type and p-type) is made of two different materials termed low temperature material and high temperature material. Although a few of investigations have reported thermal behavior of segmented annular thermoelectric, no exergetic and economic analysis have been performed yet on segmented annular thermoelectric generators. Exergetic and economic evaluations are significant criteria on marketing area of any industrial product. Hence, in this study, a comparison between segmented and non-segmented annular thermoelectric is first presented and then the impacts of the main parameters of segmented annular thermoelectric generator on energy, exergy and economic factors (including output power, conversion efficiency, exergy efficiency and cost per unit of output power) are comprehensively investigated and presented via validated 3-D numerical simulation method. The results showed that the segmented thermoelectric is more efficient than the non-segmented thermoelectric from the viewpoint of all said criteria. A peak point was observed for the curve behavior of most geometric characteristics of the segmented annular thermoelectric generator which is remarkable and discussed in this paper. \u00a9 2020 Elsevier Ltd",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Annular thermoelectric generator (ATEG) has not been commercialized yet and many studies are required to identify its characteristics from different viewpoints. Most recently, segmented annular thermoelectric was proposed as an efficient structure for annular thermoelectric in which each leg of thermoelectric (n-type and p-type) is made of two different materials termed low temperature material and high temperature material. Although a few of investigations have reported thermal behavior of segmented annular thermoelectric, no exergetic and economic analysis have been performed yet on segmented annular thermoelectric generators. Exergetic and economic evaluations are significant criteria on marketing area of any industrial product. Hence, in this study, a comparison between segmented and non-segmented annular thermoelectric is first presented and then the impacts of the main parameters of segmented annular thermoelectric generator on energy, exergy and economic factors (including output power, conversion efficiency, exergy efficiency and cost per unit of output power) are comprehensively investigated and presented via validated 3-D numerical simulation method. The results showed that the segmented thermoelectric is more efficient than the non-segmented thermoelectric from the viewpoint of all said criteria. A peak point was observed for the curve behavior of most geometric characteristics of the segmented annular thermoelectric generator which is remarkable and discussed in this paper. \u00a9 2020 Elsevier Ltd"
        ]
    },
    {
        "judul":[
            "Stochastic optimization in disaster relief management"
        ],
        "penulis":"Syarah, Fatmah;Mawengkang, Herman;Abdulbasah Kamil, Anton;Sutarman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research develops a two-stage stochastic programming model for planning the distribution of aid to areas affected by disasters during the emergency response. Taking into account 3 network locations of aid goods, namely (main warehouse or supplier, distribution center and disaster area) in the storage of relief goods inventory with standard assistance time or maximum delivery duration and penalty for loss of relief goods. To determine the number and location of suppliers and distribution centers propose a mixed integer programming model. Where demand for relief goods and routes are considered as variables containing uncertainty. \u00a9 2020 SERSC.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research develops a two-stage stochastic programming model for planning the distribution of aid to areas affected by disasters during the emergency response. Taking into account 3 network locations of aid goods, namely (main warehouse or supplier, distribution center and disaster area) in the storage of relief goods inventory with standard assistance time or maximum delivery duration and penalty for loss of relief goods. To determine the number and location of suppliers and distribution centers propose a mixed integer programming model. Where demand for relief goods and routes are considered as variables containing uncertainty. \u00a9 2020 SERSC."
        ]
    },
    {
        "judul":[
            "Detecting Ictal and Interictal Condition of EEG Signal using Higuchi Fractal Dimension and Support Vector Machine"
        ],
        "penulis":"Wijayanto I.;Hadiyoso S.;Aulia S.;Atmojo B.S.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Ictal and interictal periods are the most important condition which needed to find for detecting and predicting seizure condition in epileptic patients. Neurologist spends hours to analyze electroencephalogram (EEG) signals in order to find a certain pattern for diagnosing epilepsy. This manual interpretation has a high chance of error and very time consuming. In order to minimize mistakes, various studies have proposed a computer-based detection system to support the detection of ictal and interictal conditions. In this study, we extract the EEG signal pattern by using the Higuchi fractal dimension to classify the ictal and interictal conditions of EEG signals. The features are extracted from five EEG sub-bands, delta, theta, alpha, beta, and gamma band. Those features are then fed to support vector machine as the classifier using 10-cross folds validation. The experiment shows that the use of HFD and the quadratic kernel is suitable for ictal detection. While the use of cubic kernel and HFD is suitable for detecting interictal conditions. \u00a9 2020 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ictal and interictal periods are the most important condition which needed to find for detecting and predicting seizure condition in epileptic patients. Neurologist spends hours to analyze electroencephalogram (EEG) signals in order to find a certain pattern for diagnosing epilepsy. This manual interpretation has a high chance of error and very time consuming. In order to minimize mistakes, various studies have proposed a computer-based detection system to support the detection of ictal and interictal conditions. In this study, we extract the EEG signal pattern by using the Higuchi fractal dimension to classify the ictal and interictal conditions of EEG signals. The features are extracted from five EEG sub-bands, delta, theta, alpha, beta, and gamma band. Those features are then fed to support vector machine as the classifier using 10-cross folds validation. The experiment shows that the use of HFD and the quadratic kernel is suitable for ictal detection. While the use of cubic kernel and HFD is suitable for detecting interictal conditions. \u00a9 2020 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Copula-Based Robust Landmine Detection in Muti-View Forward-Looking GPR Imagery"
        ],
        "penulis":"Pambudi, Afief D.;Ahmad, Fauzia;Zoubir, Abdelhak M.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We propose a scheme for detecting landmines using forward-looking ground-penetrating radar. The detector is applied to tomographic radar images obtained from multiple viewpoints of the investigation area and is based on a robust version of the likelihood-ratio test. The statistical dependence between multi-view images is incorporated via a copula-based function. The test is designed to maximize the worst-case performance over all feasible target and clutter distribution pairs, thereby eliminating the need for a strong assumption about the clutter distribution. Using numerical radar data of shallow buried targets, we demonstrate the superior performance of the proposed detector over existing approaches.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We propose a scheme for detecting landmines using forward-looking ground-penetrating radar. The detector is applied to tomographic radar images obtained from multiple viewpoints of the investigation area and is based on a robust version of the likelihood-ratio test. The statistical dependence between multi-view images is incorporated via a copula-based function. The test is designed to maximize the worst-case performance over all feasible target and clutter distribution pairs, thereby eliminating the need for a strong assumption about the clutter distribution. Using numerical radar data of shallow buried targets, we demonstrate the superior performance of the proposed detector over existing approaches.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Crackle detection in lung sound using statistical feature of variogram"
        ],
        "penulis":"Pramudita, Brahmantya Aji;Istiqomah;Rizal, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Pulmonary crackle sound is an adventitious lung sound that occurs due to several types of lung diseases such as pneumonia, pulmonary fibrosis, or chronic bronchitis. Crackle has distinctive sound patterns such as discontinuous, non-musical, and relatively short duration. Various methods were used to detect crackles in lung sounds such as entropy, wavelet-based methods, or spectral analysis. In this study, normal lung sound and pulmonary crackle sound classification were performed using the variogram as a feature extraction method. Modified variogram was applied to the pulmonary sound signal, and its statistical parameters were measured to distinguish crackle lung sound from normal lung sound. The experimental result produced the highest accuracy of 95.3% using Quadratic S V M as a classifier. These results indicated that the variogram could capture differences in signal dynamics in normal and pulmonary crackle sounds. \u00a9 2020 American Institute of Physics Inc.. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Pulmonary crackle sound is an adventitious lung sound that occurs due to several types of lung diseases such as pneumonia, pulmonary fibrosis, or chronic bronchitis. Crackle has distinctive sound patterns such as discontinuous, non-musical, and relatively short duration. Various methods were used to detect crackles in lung sounds such as entropy, wavelet-based methods, or spectral analysis. In this study, normal lung sound and pulmonary crackle sound classification were performed using the variogram as a feature extraction method. Modified variogram was applied to the pulmonary sound signal, and its statistical parameters were measured to distinguish crackle lung sound from normal lung sound. The experimental result produced the highest accuracy of 95.3% using Quadratic S V M as a classifier. These results indicated that the variogram could capture differences in signal dynamics in normal and pulmonary crackle sounds. \u00a9 2020 American Institute of Physics Inc.. All rights reserved."
        ]
    },
    {
        "judul":[
            "Performance Analysis of Implementation Model Architecture Reference and Master Data Management using Open Source Platform"
        ],
        "penulis":"Perdana, Immanuela Christiantari;Kusumasari, Tien Fabrianti;Alam, Ekky Novriza;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Data is one of the most valuable assets that an enterprise can own. The data must also be accurate, relevant, and consistent due to it be used as a decision-making process. Data stored in the enterprise is spread on a database that is in the enterprise; to manage that, an enterprise needs a Master Data Management (MDM) to keep the data consistent and maintained. The selection of an appropriate MDM implementation model will support the successful implementation of MDM. This paper aims to improve and measure the performance of the MDM management process that has been made. Applicationperformance in this study was measured using the performance testing method. This study will determine the performance of existing MDM applications with MDM applications after adjustments to find out more effective performance. The advantage of this research to know the importance of application performance in the enterprise and application performance measurement. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data is one of the most valuable assets that an enterprise can own. The data must also be accurate, relevant, and consistent due to it be used as a decision-making process. Data stored in the enterprise is spread on a database that is in the enterprise; to manage that, an enterprise needs a Master Data Management (MDM) to keep the data consistent and maintained. The selection of an appropriate MDM implementation model will support the successful implementation of MDM. This paper aims to improve and measure the performance of the MDM management process that has been made. Applicationperformance in this study was measured using the performance testing method. This study will determine the performance of existing MDM applications with MDM applications after adjustments to find out more effective performance. The advantage of this research to know the importance of application performance in the enterprise and application performance measurement. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "SVD Diagonal Matrix Reconstruction Using OMP"
        ],
        "penulis":"Irawati, Indrarini Dyah;Edward, Ian Joseph Matheus;Suksmono, Andriyan Bayu;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We designed a compression and reconstruction system in internet traffic applications by combining Singular Value Decomposition (SVD) and Orthogonal Matching Pursuit (OMP) techniques. This system aims to obtain all internet traffic information from several measured data samples. The problem occurred due to the reconstruction results of the SVD diagonal matrix using OMP are undefined values. This paper presents a solution to fix it. We applied zero forcing and improved it using interpolation. The optimized interpolation is proposed to replace zero value with optimal solution using minimization algorithm. The result shows that the proposed methods is able to overcome zero value problem and improve the accuracy of reconstruction. \u00a9 Springer Nature Singapore Pte Ltd. 2020."
        ],
        "abstrak":[
            "We designed a compression and reconstruction system in internet traffic applications by combining Singular Value Decomposition (SVD) and Orthogonal Matching Pursuit (OMP) techniques. This system aims to obtain all internet traffic information from several measured data samples. The problem occurred due to the reconstruction results of the SVD diagonal matrix using OMP are undefined values. This paper presents a solution to fix it. We applied zero forcing and improved it using interpolation. The optimized interpolation is proposed to replace zero value with optimal solution using minimization algorithm. The result shows that the proposed methods is able to overcome zero value problem and improve the accuracy of reconstruction. \u00a9 Springer Nature Singapore Pte Ltd. 2020."
        ]
    },
    {
        "judul":[
            "Thermal performance, parametric analysis, and multi-objective optimization of a direct-expansion solar-assisted heat pump water heater using NSGA-II and decision makings"
        ],
        "penulis":"Cao, Yan;Mihardjo, Leonardus W.W.;Parikhani, Towhid;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Direct-expansion solar-assisted heat pump water heaters (DX-SAHPWHs) are conducive to the environment due to the use of ambient energy and solar radiation. This paper aims to design and develop a thermodynamic model and a multi-criteria optimization of thermal performance for a DX-SAHPWH using R-134a as the working refrigerant that supplies domestic hot water for a typical building throughout the whole year. The thermodynamic model of the DX-SAHPWH is developed so that the performance of the system is solved through the try and error technique with the least initial data of the thermodynamic cycle of DX-SAHPWH. After the validation of the thermodynamic model, the performance of the DX-SAHPWH is analyzed for a typical building located at the temperate climate of Iran. Then, a parametric study is conducted to identify how various design parameters may affect the performance of the DX-SAHPWH system. In the current investigation, the effects of design parameters including solar radiation intensity, ambient air temperature, outlet water temperature of the condenser, solar collector area, compressor speed, length of tube in the condenser, external diameter of the tube in collector plate, fin thickness, and thermal conductivity of collector plate on the performance of the DX-SAHPWH are investigated. Besides, single and bi-criteria optimizations are carried out using genetic algorithm (GA) to obtain the optimal solutions of design parameters, where the coefficient of performance (COP) and the solar collector efficiency (SCE) are selected as two fitness functions. The optimal solutions achieved from the bi-criteria optimization process will be given as Pareto frontier. The final optimum solution from the available solutions on the Pareto optimal frontier is selected using decision-making methods, such as LINMAP, TOPSIS, and Shannon's Entropy. The comparison of single and bi-criteria optimization results illustrate that the bi-criteria optimization method yields more proper results than single ones, mainly because of the lower deviation index from the ideal solution. The results of bi-criteria optimization show that SCE decreases 1.6% compared to the initial model while the COP increases close to 20% that makes the optimum solution more desirable compared to the single ones. Moreover, the performance of the optimized DX-SAHPWH system is compared with the initial model in each month of the year. The results indicate that the performance of the optimized DX-SAHPWH is highly improved so that the working hours of the system decrease close to 109 h compared to the initial model during the whole year. \u00a9 2020",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Direct-expansion solar-assisted heat pump water heaters (DX-SAHPWHs) are conducive to the environment due to the use of ambient energy and solar radiation. This paper aims to design and develop a thermodynamic model and a multi-criteria optimization of thermal performance for a DX-SAHPWH using R-134a as the working refrigerant that supplies domestic hot water for a typical building throughout the whole year. The thermodynamic model of the DX-SAHPWH is developed so that the performance of the system is solved through the try and error technique with the least initial data of the thermodynamic cycle of DX-SAHPWH. After the validation of the thermodynamic model, the performance of the DX-SAHPWH is analyzed for a typical building located at the temperate climate of Iran. Then, a parametric study is conducted to identify how various design parameters may affect the performance of the DX-SAHPWH system. In the current investigation, the effects of design parameters including solar radiation intensity, ambient air temperature, outlet water temperature of the condenser, solar collector area, compressor speed, length of tube in the condenser, external diameter of the tube in collector plate, fin thickness, and thermal conductivity of collector plate on the performance of the DX-SAHPWH are investigated. Besides, single and bi-criteria optimizations are carried out using genetic algorithm (GA) to obtain the optimal solutions of design parameters, where the coefficient of performance (COP) and the solar collector efficiency (SCE) are selected as two fitness functions. The optimal solutions achieved from the bi-criteria optimization process will be given as Pareto frontier. The final optimum solution from the available solutions on the Pareto optimal frontier is selected using decision-making methods, such as LINMAP, TOPSIS, and Shannon's Entropy. The comparison of single and bi-criteria optimization results illustrate that the bi-criteria optimization method yields more proper results than single ones, mainly because of the lower deviation index from the ideal solution. The results of bi-criteria optimization show that SCE decreases 1.6% compared to the initial model while the COP increases close to 20% that makes the optimum solution more desirable compared to the single ones. Moreover, the performance of the optimized DX-SAHPWH system is compared with the initial model in each month of the year. The results indicate that the performance of the optimized DX-SAHPWH is highly improved so that the working hours of the system decrease close to 109 h compared to the initial model during the whole year. \u00a9 2020"
        ]
    },
    {
        "judul":[
            "Driving transformation performance through innovation and experience model"
        ],
        "penulis":"Bawono, Marindra;Mihardjo, Leonardus W.W.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Innovation on business model is not only describing the bundle of products and services but also it is integrated with the input of customer experience. Customer experience should become a key role in developing business model innovation in driving transformational performance. This paper argues that the transformational performance is derived from business model innovation and focuses on customer experience. We use telecommunication firms as our unit analysis with sample of 195 Indonesian ICT firms out of 542 units. The analytical approach and solution technique that is used for analysis is Partial Least Square (PLS). The findings demonstrate that business model played significant role on supporting contribution of customer experience in driving transformational performance. The finding has implication that by synergizing the value proposition of customer experience in a business model innovation, the transformational performance can be maintained through focus on customer experience driven business model innovation. Further study can be explored through additional variable, sample and further study on longitudinal on digital transformation firms. \u00a9 2020 by the authors.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Innovation on business model is not only describing the bundle of products and services but also it is integrated with the input of customer experience. Customer experience should become a key role in developing business model innovation in driving transformational performance. This paper argues that the transformational performance is derived from business model innovation and focuses on customer experience. We use telecommunication firms as our unit analysis with sample of 195 Indonesian ICT firms out of 542 units. The analytical approach and solution technique that is used for analysis is Partial Least Square (PLS). The findings demonstrate that business model played significant role on supporting contribution of customer experience in driving transformational performance. The finding has implication that by synergizing the value proposition of customer experience in a business model innovation, the transformational performance can be maintained through focus on customer experience driven business model innovation. Further study can be explored through additional variable, sample and further study on longitudinal on digital transformation firms. \u00a9 2020 by the authors."
        ]
    },
    {
        "judul":[
            "Cultural values and their implications to family business succession: A case study of small Chinese-owned family businesses in Bandung, Indonesia"
        ],
        "penulis":"Anggadwita, Grisna;Profityo, Werda Bagus;Alamanda, Dini Turipanam;Permatasari, Anggraeni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Purpose: The family business is one of the business entities that contribute to the economy of a country. Succession in the family business occupies a strategic position, especially in maintaining the company\u2019s sustainability. The Chinese family business has unique characteristics in maintaining and growing its business with the cultural values that underlie how their business. The purpose of this paper is to discuss the cultural values of Chinese ethnic and their implications in the succession process in small family businesses in Bandung, Indonesia. Design\/methodology\/approach: This research uses a qualitative method with the in-depth interview method as a data collection technique. The sampling technique uses purposive sampling, while to test the validity of research data using a triangulation technique. A total of four small Chinese-owned family businesses participated as informants in this study. The study will identify the stage of succession process in the Chinese family business. Findings: There are several stages identified in the succession planning of small Chinese-owned family business in Bandung which include succession antecedents, succession activities and desired outcomes. The results showed that small Chinese-owned family business in Bandung has not applied the rules and procedures in the succession process. Most of the Chinese family business in this research still holds Confucianism culture; they prioritize boys as business successors, who have a greater responsibility rather than successor with other gender. Practical implications: Several implications are discussed. One of them is the Chinese family business holding cultural values in the process of family business succession. Originality\/value: This research is expected to provide theoretical and practical implications for academics and family companies with similar cases. \u00a9 2019, Emerald Publishing Limited.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: The family business is one of the business entities that contribute to the economy of a country. Succession in the family business occupies a strategic position, especially in maintaining the company\u2019s sustainability. The Chinese family business has unique characteristics in maintaining and growing its business with the cultural values that underlie how their business. The purpose of this paper is to discuss the cultural values of Chinese ethnic and their implications in the succession process in small family businesses in Bandung, Indonesia. Design\/methodology\/approach: This research uses a qualitative method with the in-depth interview method as a data collection technique. The sampling technique uses purposive sampling, while to test the validity of research data using a triangulation technique. A total of four small Chinese-owned family businesses participated as informants in this study. The study will identify the stage of succession process in the Chinese family business. Findings: There are several stages identified in the succession planning of small Chinese-owned family business in Bandung which include succession antecedents, succession activities and desired outcomes. The results showed that small Chinese-owned family business in Bandung has not applied the rules and procedures in the succession process. Most of the Chinese family business in this research still holds Confucianism culture; they prioritize boys as business successors, who have a greater responsibility rather than successor with other gender. Practical implications: Several implications are discussed. One of them is the Chinese family business holding cultural values in the process of family business succession. Originality\/value: This research is expected to provide theoretical and practical implications for academics and family companies with similar cases. \u00a9 2019, Emerald Publishing Limited."
        ]
    },
    {
        "judul":[
            "Sample median approximation on stochastic data envelopment analysis"
        ],
        "penulis":"Nasution, Marah Doly;Mawengkang, Herman;Kamil, Anton Abdulbasah;Efendi, Syahril;Sutarman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper study a new approximation model to solving stochastic data envelopment analysis (SDEA) problem. The proposed approach is based on problems that might occur in everyday life. This paper discusses the approach in determining the efficiency and super efficiency ratings of a decision making unit (DMU) in the DEA model with stochastic data. In determining efficiency, SDEA is first transformed into an equivalent deterministic DEA by changing its chance constraints in such a way that the SDEA problem can be solved easily. The author proposes an approach technique called a sample median approximation (SMA) to change the chance constraints so that it will be easy to get the optimal solution in determining the efficiency of DMUs. In the process, the data to be processed first is determined by the median average which will later be considered to represent the actual sample average. As a numerical example, the author resolves the vendor selection problem as presented by Wu and Olson (2006) in their paper. By taking the same parameter value (a = 0.2 and beta = 0.9), the efficiency score and super efficiency of the problem are obtained. \u00a9 2020 Inderscience Enterprises Ltd.. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper study a new approximation model to solving stochastic data envelopment analysis (SDEA) problem. The proposed approach is based on problems that might occur in everyday life. This paper discusses the approach in determining the efficiency and super efficiency ratings of a decision making unit (DMU) in the DEA model with stochastic data. In determining efficiency, SDEA is first transformed into an equivalent deterministic DEA by changing its chance constraints in such a way that the SDEA problem can be solved easily. The author proposes an approach technique called a sample median approximation (SMA) to change the chance constraints so that it will be easy to get the optimal solution in determining the efficiency of DMUs. In the process, the data to be processed first is determined by the median average which will later be considered to represent the actual sample average. As a numerical example, the author resolves the vendor selection problem as presented by Wu and Olson (2006) in their paper. By taking the same parameter value (a = 0.2 and beta = 0.9), the efficiency score and super efficiency of the problem are obtained. \u00a9 2020 Inderscience Enterprises Ltd.. All rights reserved."
        ]
    },
    {
        "judul":[
            "Hybrid Method for Flower Classification in High Intra-class Variation"
        ],
        "penulis":"Siregar, Faisal Ridwan;Al Maki, Wikky Fawwaz;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, we present an algorithm of flower classification. The image data used in this study was obtained from the Oxford 102 Flowers dataset. We classified 16368 flower images which were obtained by applying a set of augmentation process on each image in the dataset. The images were segmented by using GrabCut method. Then, a hybrid method of feature extraction was employed to the segmented images. The so-called Moment Invariants was used to extract shape features whereas the Color Moments was employed to extract color features. The proposed hybrid method of feature extraction is proven to be good for declaring objects by considering color, shape, and object area. Further, we implemented Random Forest as the classifier. The proposed algorithm of flower classification provided satisfactory results based on stratified k-fold cross-validation tests where an optimal k value was obtained by using the elbow method. Our experimental results shows that the proposed model yields accuracy of 88,74%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, we present an algorithm of flower classification. The image data used in this study was obtained from the Oxford 102 Flowers dataset. We classified 16368 flower images which were obtained by applying a set of augmentation process on each image in the dataset. The images were segmented by using GrabCut method. Then, a hybrid method of feature extraction was employed to the segmented images. The so-called Moment Invariants was used to extract shape features whereas the Color Moments was employed to extract color features. The proposed hybrid method of feature extraction is proven to be good for declaring objects by considering color, shape, and object area. Further, we implemented Random Forest as the classifier. The proposed algorithm of flower classification provided satisfactory results based on stratified k-fold cross-validation tests where an optimal k value was obtained by using the elbow method. Our experimental results shows that the proposed model yields accuracy of 88,74%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Improvement of new product development process by evaluating the existing development approach: Lesson learned from pharmaceutical and ICT companies"
        ],
        "penulis":"Iqbal, Muhammad;Suzianti, Amalia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The article discusses the implementation of the NPD process design method, while at the same time considering the existing product development applied by the company, to have early development improvement ideas. It is involving nationwide companies from two industries: pharmaceutical and ICT-related. The approach is using the PDP Design Method and SWOT analysis (as part of the 'existing design process' analysis). The result shows that using the approach, the improved design ideas are obtained: agility of the process, development time reduction with concurrent approach, lean initiatives, and evaluation of process iterations. Future research can be done related to the analysis of existing product development in the PDP Design Method and the usage of other tools to study the issue. It is also interesting to study this approach for companies that don't have a \"formal\"product development process yet.  \u00a9 2020 Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The article discusses the implementation of the NPD process design method, while at the same time considering the existing product development applied by the company, to have early development improvement ideas. It is involving nationwide companies from two industries: pharmaceutical and ICT-related. The approach is using the PDP Design Method and SWOT analysis (as part of the 'existing design process' analysis). The result shows that using the approach, the improved design ideas are obtained: agility of the process, development time reduction with concurrent approach, lean initiatives, and evaluation of process iterations. Future research can be done related to the analysis of existing product development in the PDP Design Method and the usage of other tools to study the issue. It is also interesting to study this approach for companies that don't have a \"formal\"product development process yet.  \u00a9 2020 Author(s)."
        ]
    },
    {
        "judul":[
            "Design On-Grid Solar Power System for 450 VA Conventional Housing using HOMER Software"
        ],
        "penulis":"Aprillia, Bandiyah Sri;Foury Rigoursyah, Muhammad Agung;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The on-grid solar power system is a solution that can fulfil the ever-increasing demands for electricity. The important role of a solar grid system is to save and reduce the cost of electricity, particularly those with high energy usage in the daytime. This research aims to design a configuration for placing a solar grid system in the housings for the city of Bandung, Indonesia. The research method used is to collect solar radiation data, tool specifications, and other data needed, and then proceed to optimise on these bases. On-grid solar power system design requires the software HOMER. HOMER is used to find the correct system configuration, payback period, and the best NPC technically. Based on the result of optimization, the system configuration can fill the needs of electricity by about 42 % for daily consumption with a total NPC cost of around thirty eighty million one hundred thousand with four years payback period. \u00a9 2020 IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The on-grid solar power system is a solution that can fulfil the ever-increasing demands for electricity. The important role of a solar grid system is to save and reduce the cost of electricity, particularly those with high energy usage in the daytime. This research aims to design a configuration for placing a solar grid system in the housings for the city of Bandung, Indonesia. The research method used is to collect solar radiation data, tool specifications, and other data needed, and then proceed to optimise on these bases. On-grid solar power system design requires the software HOMER. HOMER is used to find the correct system configuration, payback period, and the best NPC technically. Based on the result of optimization, the system configuration can fill the needs of electricity by about 42 % for daily consumption with a total NPC cost of around thirty eighty million one hundred thousand with four years payback period. \u00a9 2020 IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Operational Dashboard Development as A Data Quality Monitoring Tools Using Data Deduplication Profiling Result"
        ],
        "penulis":"Kristyanti, Sesillia Fajar;Kusumasari, Tien Fabrianti;Alam, Ekky Novriza;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Data quality is a crucial thing presently. Poor data quality can lead to business failure and wrong decision making. One problem that arises when merging several databases is the emergence of data duplication. When merging two applications of a government agency first, it causes 39,3% of data duplication. It can cause some business problems such as storage cost, wasted marketing budget, lack of a single customer view, and lost productivity. For this reason, data quality monitoring needed to monitor and control the duplicated data. This study is a follow-up study focusing on developing a data quality monitoring module using data deduplication profiling results. The method used to develop the dashboard in this study is the operational dashboard development methodology that proposed by Suryatiningsih on her research (2011). The methodology consists of six stages, namely requirement identification, plan process, prototype design, review prototype, implementation process, and system testing. By adjusting to the predefined business rule and KPI, the operational dashboard will help the organization to monitor and control their data quality. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data quality is a crucial thing presently. Poor data quality can lead to business failure and wrong decision making. One problem that arises when merging several databases is the emergence of data duplication. When merging two applications of a government agency first, it causes 39,3% of data duplication. It can cause some business problems such as storage cost, wasted marketing budget, lack of a single customer view, and lost productivity. For this reason, data quality monitoring needed to monitor and control the duplicated data. This study is a follow-up study focusing on developing a data quality monitoring module using data deduplication profiling results. The method used to develop the dashboard in this study is the operational dashboard development methodology that proposed by Suryatiningsih on her research (2011). The methodology consists of six stages, namely requirement identification, plan process, prototype design, review prototype, implementation process, and system testing. By adjusting to the predefined business rule and KPI, the operational dashboard will help the organization to monitor and control their data quality. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Correspondence between bats population and terrestrial cave-dwelling arthropods community in tasikmalaya karst area"
        ],
        "penulis":"Kurniawan, Isma Dwi;Rahmadi, Cahyo;Caraka, Rezzy Eko;Rahman, Iman Aulia;Kinasih, Ida;Toharudin, Toni;Chen, Rung Ching;Lee, Youngjo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Trogloxenes particularly bats play an important role in subterranean habitat. They provide organic material and induce cave microclimate that influence cave-dwelling biota, including arthropods. This study aimed to learn how bats population influences cave-dwelling arthropods community. Data collections were performed in three caves which had different bats species in Tasikmalaya karst area namely Liang Boeh, Liang Seungit and Sarongge. We recorded bats population, guano production, physicochemical condition of caves passage, and arthropods community in each cave. All samplings were only conducted in the specific sites of the dark zone where bat populations were aggregated. Data indicated that Liang Boeh was inhibited by Hipposideros sp (\u00b1472 individuals), Liang Seungit by Pteripodidae and Miniopterus sp. (\u00b1188 individuals), and Sarongge by Rhinolophus sp. (\u00b11194 individuals). Guano production was positively correlated with bats population. Chemical compositions of soil were varying among bats species. Bats population strongly induced caves physicochemical condition. A total 15986 individuals of cave-dwelling arthropods belonging to 5 Classes and 18 Orders were recorded. Our result revealed that bats population determined arthropods community. Caves with greater bats population size and dominated by insectivorous species would potentially have greater diversity and abundance of cave-dwelling arthropods. \u00a9 2020 the author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Trogloxenes particularly bats play an important role in subterranean habitat. They provide organic material and induce cave microclimate that influence cave-dwelling biota, including arthropods. This study aimed to learn how bats population influences cave-dwelling arthropods community. Data collections were performed in three caves which had different bats species in Tasikmalaya karst area namely Liang Boeh, Liang Seungit and Sarongge. We recorded bats population, guano production, physicochemical condition of caves passage, and arthropods community in each cave. All samplings were only conducted in the specific sites of the dark zone where bat populations were aggregated. Data indicated that Liang Boeh was inhibited by Hipposideros sp (\u00b1472 individuals), Liang Seungit by Pteripodidae and Miniopterus sp. (\u00b1188 individuals), and Sarongge by Rhinolophus sp. (\u00b11194 individuals). Guano production was positively correlated with bats population. Chemical compositions of soil were varying among bats species. Bats population strongly induced caves physicochemical condition. A total 15986 individuals of cave-dwelling arthropods belonging to 5 Classes and 18 Orders were recorded. Our result revealed that bats population determined arthropods community. Caves with greater bats population size and dominated by insectivorous species would potentially have greater diversity and abundance of cave-dwelling arthropods. \u00a9 2020 the author(s)."
        ]
    },
    {
        "judul":[
            "Optical-loss measurement of a silicon-slab waveguide"
        ],
        "penulis":"Tresna, Wildan Panji;Putra, Alexander William Setiawan;Maruyama, Takeo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A mirror-in-slab waveguide is fabricated on a slab waveguide by using the refractive-index contrast between two materials, with the reflection performance depending on the slab waveguide\u2019s design. In this research, a slab waveguide design consisting of silicon (Si) as the core and SiO2as the substrate was designed and developed to determine the coupling, waveguide, and mirror losses. Based on experimental results, coupling loss is dominant and is affected by the design of the slab waveguide. Furthermore, the mirror loss is affected by the design of the mirror, such as the curvature radius and the size of the mirror. TE and TM polarizations of light are used in the measurements. The experimental results show that mirror losses due to reflection by mirrors are 0.011 dB\/mirror and 0.007 dB\/mirror for TE and TM polarizations respectively. A simulation was performed to confirm whether the size of mirror is sufficient to reflect the input light, and to check the quality of the surfaces of fabricated mirrors. \u00a9 2020 Current Optics and Photonics.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A mirror-in-slab waveguide is fabricated on a slab waveguide by using the refractive-index contrast between two materials, with the reflection performance depending on the slab waveguide\u2019s design. In this research, a slab waveguide design consisting of silicon (Si) as the core and SiO2as the substrate was designed and developed to determine the coupling, waveguide, and mirror losses. Based on experimental results, coupling loss is dominant and is affected by the design of the slab waveguide. Furthermore, the mirror loss is affected by the design of the mirror, such as the curvature radius and the size of the mirror. TE and TM polarizations of light are used in the measurements. The experimental results show that mirror losses due to reflection by mirrors are 0.011 dB\/mirror and 0.007 dB\/mirror for TE and TM polarizations respectively. A simulation was performed to confirm whether the size of mirror is sufficient to reflect the input light, and to check the quality of the surfaces of fabricated mirrors. \u00a9 2020 Current Optics and Photonics."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "A System Dynamics for Financial Strategy Model Assessment in National Health Insurance System"
        ],
        "penulis":"Kurnianingtyas, Diva;Santosa, Budi;Siswanto, Nurhadi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The National Health Insurance System (NHIS) was established by the government to provide health insurance to its people. However, some obstacles will be faced by NHIS. For example, when not having proper financial management, the fiscal budget sector will experience a deficit. The issue is happening in Indonesia. The purpose of this research is to develop and evaluate problem models so it can be used for consideration in determining relevant proposed policies. This research uses NHIS data in Indonesia from 2014 to 2018. The method used is a system dynamics approach. The validation of the SD model uses the mean comparison test and t statistic. Next, the model is tested for sensitivity under extreme conditions of low, basic, and high. Patient variables generate low and high states of 34.34% and 33.24%, respectively, which affect the variable fund inventory about 49.3 trillion and -93.46 trillion, respectively. Otherwise, participant variables affect the supply of funds in low and high conditions were about -19.60 trillion and -26.19 trillion, respectively. It can be concluded variable have a direct influence on the expense variable (patient variable) gives a more dominant effect than the variable gives the overall impact (variable of expense and income) such as participant variables. Therefore, strategies related to patient variables are used as short-term strategies, while those related to participant variables are used as long-term strategies. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The National Health Insurance System (NHIS) was established by the government to provide health insurance to its people. However, some obstacles will be faced by NHIS. For example, when not having proper financial management, the fiscal budget sector will experience a deficit. The issue is happening in Indonesia. The purpose of this research is to develop and evaluate problem models so it can be used for consideration in determining relevant proposed policies. This research uses NHIS data in Indonesia from 2014 to 2018. The method used is a system dynamics approach. The validation of the SD model uses the mean comparison test and t statistic. Next, the model is tested for sensitivity under extreme conditions of low, basic, and high. Patient variables generate low and high states of 34.34% and 33.24%, respectively, which affect the variable fund inventory about 49.3 trillion and -93.46 trillion, respectively. Otherwise, participant variables affect the supply of funds in low and high conditions were about -19.60 trillion and -26.19 trillion, respectively. It can be concluded variable have a direct influence on the expense variable (patient variable) gives a more dominant effect than the variable gives the overall impact (variable of expense and income) such as participant variables. Therefore, strategies related to patient variables are used as short-term strategies, while those related to participant variables are used as long-term strategies. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Machine instruction analysis for DCT algorithm using DLX architecture"
        ],
        "penulis":"Dyanneley, Believa;Karna, Nyoman;Patmasari, Raditiana;Kim, Dong-Seong;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "One of the methods to reduce the size of images is by compressing the images. This research tried to find out the machine instruction set of DLX microprocessor to do image compression, in which the result will be used to design an ASIP microprocessor that has less power consumption compared to a general-purpose microprocessor with dozens of machine instruction. This ASIP microprocessor will become the heart of our next project, which is the autonomous seabed robot scanner that will be installed under the sea which relying on a rechargeable battery to supply the power. That is why this research is very crucial to reduce the power consumption of the microprocessor to save more energy for long term use. This research uses a simulation tool for DLX microprocessor, namely the WinDLX, to implement the algorithm of Discrete Cosine Transform (DCT) for image compression process. The result shows that the program requires a total of 14763 cycles executed with a total of 5920 instructions. The instructions which are often used in this experiment are LF (Load Float) which is used to load the value of matrices before being stored in the memory and multiplied to other matrices.  \u00a9 2020 IEEE."
        ],
        "abstrak":[
            "One of the methods to reduce the size of images is by compressing the images. This research tried to find out the machine instruction set of DLX microprocessor to do image compression, in which the result will be used to design an ASIP microprocessor that has less power consumption compared to a general-purpose microprocessor with dozens of machine instruction. This ASIP microprocessor will become the heart of our next project, which is the autonomous seabed robot scanner that will be installed under the sea which relying on a rechargeable battery to supply the power. That is why this research is very crucial to reduce the power consumption of the microprocessor to save more energy for long term use. This research uses a simulation tool for DLX microprocessor, namely the WinDLX, to implement the algorithm of Discrete Cosine Transform (DCT) for image compression process. The result shows that the program requires a total of 14763 cycles executed with a total of 5920 instructions. The instructions which are often used in this experiment are LF (Load Float) which is used to load the value of matrices before being stored in the memory and multiplied to other matrices.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A framework for factors influencing the implementation of information assurance for e-Government in Indonesia"
        ],
        "penulis":"Utomo, Rio Guntur;Wills, Gary;Walters, Robert;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Electronic government (e-Government) enables outstanding improvements to be made to services for the public by the government. This is achieved through improvements to service quality and availability for which access can be given regardless of place and time. In Indonesia, the implementation of e-Government is still not extensively comprehensive and yet being optimized. To support e-Government implementation, it is essential to implement information assurance (IA). This is intended to reduce the risks to businesses in regard to information and information systems and ensuring the business continuity when incidents occur. Additionally, it is necessary to understand the practices and cultures which exist in the government agencies which are implementing IA. However, so far, there has not been any research that has focused on IA for Indonesian e-Government. Therefore, this paper researches the factors which influence the implementation of IA in Indonesia to support e-Government. A framework is proposed and consists of three categories: Indonesian Context, Implementation Management, and Organizational Management. The framework was developed through the identification of the factors from IA international standards, international publications, and various challenges. Furthermore, the framework was reviewed and confirmed by surveying practitioners, and interviewing experts in the IA, information security, and e-Government fields in various Indonesian institutions. The results were analyzed by conducting the non-parametric test. In addition, Cronbach's alpha test was used for testing the data reliability. The results demonstrate that every proposed factor in the framework is significant. \u00a9 2020, Insight Society.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electronic government (e-Government) enables outstanding improvements to be made to services for the public by the government. This is achieved through improvements to service quality and availability for which access can be given regardless of place and time. In Indonesia, the implementation of e-Government is still not extensively comprehensive and yet being optimized. To support e-Government implementation, it is essential to implement information assurance (IA). This is intended to reduce the risks to businesses in regard to information and information systems and ensuring the business continuity when incidents occur. Additionally, it is necessary to understand the practices and cultures which exist in the government agencies which are implementing IA. However, so far, there has not been any research that has focused on IA for Indonesian e-Government. Therefore, this paper researches the factors which influence the implementation of IA in Indonesia to support e-Government. A framework is proposed and consists of three categories: Indonesian Context, Implementation Management, and Organizational Management. The framework was developed through the identification of the factors from IA international standards, international publications, and various challenges. Furthermore, the framework was reviewed and confirmed by surveying practitioners, and interviewing experts in the IA, information security, and e-Government fields in various Indonesian institutions. The results were analyzed by conducting the non-parametric test. In addition, Cronbach's alpha test was used for testing the data reliability. The results demonstrate that every proposed factor in the framework is significant. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[
            "Energetic requirements of the transition from solitary to group living"
        ],
        "penulis":"Sumaiya, Rahila I.K.;Nii, Momoka;Okabe, Takuya;Ito, Hiromu;Pulungan, Muhammad Almaududi;Morita, Satoru;Kobayashi, Kazuya;Setou, Mitsutoshi;Iwabuchi, Kikuo;Matsuura, Kenji;Yoshimura, Jin;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Synergy is known to be vital for the group collaboration among non-kin individuals. In order to evaluate the condition of synergy that initiates group living, we build a model of food intake based on three types of functional response. We show that type III functional response is prerequisite for synergy to allow group living. The optimal number of gathering individuals can be also evaluated from Type III functional response curve. Type III functional response consists of terms depending linearly and bilinearly on the number of individuals and the bilinear term represents synergy. For a fixed value of the linear coefficient, there are upper and lower boundaries of the bilinear coefficient for synergistic collaboration. The dilution effect can be incorporated into the model through the functional response of the predator. Thus, the functional response of the predator as well as that of the prey contribute to the group living of the prey. Our model shows that group livings can be categorized into three types, namely those due to (1) synergy effect of the own group, (2) dilution effect against predators, and (3) both effects contributing together. The predator's functional response plays a decisive role in the last two types, where the predator response should be of anti-Type III (i.e., Type II). \u00a9 2020 Elsevier B.V.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Synergy is known to be vital for the group collaboration among non-kin individuals. In order to evaluate the condition of synergy that initiates group living, we build a model of food intake based on three types of functional response. We show that type III functional response is prerequisite for synergy to allow group living. The optimal number of gathering individuals can be also evaluated from Type III functional response curve. Type III functional response consists of terms depending linearly and bilinearly on the number of individuals and the bilinear term represents synergy. For a fixed value of the linear coefficient, there are upper and lower boundaries of the bilinear coefficient for synergistic collaboration. The dilution effect can be incorporated into the model through the functional response of the predator. Thus, the functional response of the predator as well as that of the prey contribute to the group living of the prey. Our model shows that group livings can be categorized into three types, namely those due to (1) synergy effect of the own group, (2) dilution effect against predators, and (3) both effects contributing together. The predator's functional response plays a decisive role in the last two types, where the predator response should be of anti-Type III (i.e., Type II). \u00a9 2020 Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Comparison of students\u2019 perception about curriculum design versus employability in Malaysia, Indonesia and Thailand"
        ],
        "penulis":"Md Isa, Filzah;Noor, Shaista;Ahmdon, Muhd Afiq Syazwan;Setiawati, Cut Irna;Tantasuntisakul, Warangkana;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Globalisation and technological developments demand employees be highly skilled. The graduates of Higher Education Institutions are facing problems in getting jobs due to lack of employability skills. Curriculum designing plays an essential role in preparing the student to meet the challenges of employment. The purpose of this paper is to understand the perception of students regarding the followed scheme of studies explicitly focused on perceived quality and applicability of the curriculum for employment. This study is conducted in universities across three countries (Malaysia, Indonesia, and Thailand). Focus group discussion held which comprises of 20 Master\u2019s Program participants from each country. The findings revealed that universities curriculum under Master\u2019s Program needs revision by addition of modules related to skills development, practical work, fieldwork and industrial interaction in the form of internships. A model has been designed to explain the curriculum design effectiveness and employability of the students in the three countries. Copyright \u00a9 2020 Inderscience Enterprises Ltd.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Industry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Globalisation and technological developments demand employees be highly skilled. The graduates of Higher Education Institutions are facing problems in getting jobs due to lack of employability skills. Curriculum designing plays an essential role in preparing the student to meet the challenges of employment. The purpose of this paper is to understand the perception of students regarding the followed scheme of studies explicitly focused on perceived quality and applicability of the curriculum for employment. This study is conducted in universities across three countries (Malaysia, Indonesia, and Thailand). Focus group discussion held which comprises of 20 Master\u2019s Program participants from each country. The findings revealed that universities curriculum under Master\u2019s Program needs revision by addition of modules related to skills development, practical work, fieldwork and industrial interaction in the form of internships. A model has been designed to explain the curriculum design effectiveness and employability of the students in the three countries. Copyright \u00a9 2020 Inderscience Enterprises Ltd."
        ]
    },
    {
        "judul":[
            "Coordinated Beamforming for Multi-Cell Non-Orthogonal Multiple Access-Based Spatial Modulation"
        ],
        "penulis":"Hendraningrat, Denny Kusuma;Satrya, Gandeva Bayu;Ramatryana, I. Nyoman Apraz;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper proposes coordinated beamforming (CB) that works over non-orthogonal multiple access (NOMA) scheme integrated with spatial modulation (SM), termed as CB NOMA-SM, to improve capacity and user fairness. User capacity, ergodic sum capacity (ESC), and user fairness of $K$ number of coordinated base stations (BSs) are simulated and analyzed by comparing them with joint transmission coordinated multi-point based NOMA with SM (JT-CoMP NOMA-SM), NOMA, and orthogonal multiple access (OMA). The results show that the proposed system outperforms the other schemes both in ESC and user fairness due to the enhancing CEU while CCU capacity still can be maintained. \u00a9 2013 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes coordinated beamforming (CB) that works over non-orthogonal multiple access (NOMA) scheme integrated with spatial modulation (SM), termed as CB NOMA-SM, to improve capacity and user fairness. User capacity, ergodic sum capacity (ESC), and user fairness of $K$ number of coordinated base stations (BSs) are simulated and analyzed by comparing them with joint transmission coordinated multi-point based NOMA with SM (JT-CoMP NOMA-SM), NOMA, and orthogonal multiple access (OMA). The results show that the proposed system outperforms the other schemes both in ESC and user fairness due to the enhancing CEU while CCU capacity still can be maintained. \u00a9 2013 IEEE."
        ]
    },
    {
        "judul":[
            "Experimental study on polarization of X-band wave absorber configured by an array of SRR with thin wire"
        ],
        "penulis":"Syihabuddin, Budi;Effendi, Mohammad Ridwan;Munir, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents an experimental study on the polarization of X-band wave absorber which is configured by an array of split ring resonator (SRR) with thin wire. The structure of X-band wave absorber that consists of a doubly periodic array of unit cell is constructed in three layers, that is an SRR on the first layer, 0.2 mm air spacing on the second layer, and a thin wire on the third layer. A 1.6 mm thick FR4 Epoxy dielectric substrate is used to deploy an array of SRR and thin wir\u00ab at the first and third layer, respectively. The dimension of each unit cell is 3.50 mm x 3.50 nun. The polarization is experimentally investigated by performing incident wave in some orientation angles, i.e. 0\u00b0, 45\", and 90\u00b0, upon the surface of X-band wave absorber. The results show that the minimum reflection coefficient occurred at the frequency of 8.26GHz are -24.15 dB, -23.29 dB, and -23.30 dB for the incident waves of 0\u00b0, 45\u00b0, and 90\", respectively. \u00a9 2020 IEEE."
        ],
        "abstrak":[
            "This paper presents an experimental study on the polarization of X-band wave absorber which is configured by an array of split ring resonator (SRR) with thin wire. The structure of X-band wave absorber that consists of a doubly periodic array of unit cell is constructed in three layers, that is an SRR on the first layer, 0.2 mm air spacing on the second layer, and a thin wire on the third layer. A 1.6 mm thick FR4 Epoxy dielectric substrate is used to deploy an array of SRR and thin wir\u00ab at the first and third layer, respectively. The dimension of each unit cell is 3.50 mm x 3.50 nun. The polarization is experimentally investigated by performing incident wave in some orientation angles, i.e. 0\u00b0, 45\", and 90\u00b0, upon the surface of X-band wave absorber. The results show that the minimum reflection coefficient occurred at the frequency of 8.26GHz are -24.15 dB, -23.29 dB, and -23.30 dB for the incident waves of 0\u00b0, 45\u00b0, and 90\", respectively. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Designing A Reading Chair using Kansei Engineering Approach"
        ],
        "penulis":"Rahayu, Mira;Ekananda, Hilman Ardian;Mufidah, Ilma;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Supporting facilities such as reading chair are often used as a scene to read books. However, the existing reading chair has not satisfied the user. This Research uses Kansei Engineering which purpose to design a reading chair that fulfil user needs. Kansei Engineering was chosen in this research because it can translate customer's impression, feeling, and demands on existing products or concepts to design concrete solutions and parameters into product design. This research is done on students in the Bandung area who use reading chair. Using a questionnaire as a tool to collect data that distributed online with google form to 347 respondents. Questionnaire data was processed using KMO statistical test and Barlett test, so from 23 Kansei word that had been obtained there was a reduction to 15 Kansei word would be used into designing reading chair in this research. The results of this research states, the implementation of Kansei Engineering could be done in the design of reading chairs, and there are innovations to meet user needs such as, armrest, headrest and footrest. Also USB port, lights, and book storage area. All of that can be used by users. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Supporting facilities such as reading chair are often used as a scene to read books. However, the existing reading chair has not satisfied the user. This Research uses Kansei Engineering which purpose to design a reading chair that fulfil user needs. Kansei Engineering was chosen in this research because it can translate customer's impression, feeling, and demands on existing products or concepts to design concrete solutions and parameters into product design. This research is done on students in the Bandung area who use reading chair. Using a questionnaire as a tool to collect data that distributed online with google form to 347 respondents. Questionnaire data was processed using KMO statistical test and Barlett test, so from 23 Kansei word that had been obtained there was a reduction to 15 Kansei word would be used into designing reading chair in this research. The results of this research states, the implementation of Kansei Engineering could be done in the design of reading chairs, and there are innovations to meet user needs such as, armrest, headrest and footrest. Also USB port, lights, and book storage area. All of that can be used by users. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Extraction of Website Navigation Label Using A Multiple Web Crawler. A Case Study on 14 University Websites in Indonesia"
        ],
        "penulis":"Luthfiyanto, Arief;Kusumo, Dana Sulistiyo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Labeling system is designed for a website to find information easily. Labeling system in a website is required to represent the information contents. One of methods to design labeling system is to compare a website with its competitors' websites. The benefit of comparing labels is to get common labels therefore it will make users to easily find and use the labeling system. Labels are extracted using a web crawler. To make web crawler, it must consider the structure of targeted website. The problems arise when there are several different target websites that will be compared. That means, it is necessary to create some unique and different web crawler program codes, so it takes a long time. This research proposes and analyzes multiple web crawler. The step to make multiple web crawler is, first, start to collect targeted website based on 14 top Indonesia's University (based on Indonesia Higher Education's University Ranking). Next step is analyzing the pattern of structure navigation labels. Then the results are used to make a multiple web crawler. The result of this research is a multiple web crawler that can extract navigation label of several different target websites automatically without writing another program code of different web crawler for each crawled website.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Labeling system is designed for a website to find information easily. Labeling system in a website is required to represent the information contents. One of methods to design labeling system is to compare a website with its competitors' websites. The benefit of comparing labels is to get common labels therefore it will make users to easily find and use the labeling system. Labels are extracted using a web crawler. To make web crawler, it must consider the structure of targeted website. The problems arise when there are several different target websites that will be compared. That means, it is necessary to create some unique and different web crawler program codes, so it takes a long time. This research proposes and analyzes multiple web crawler. The step to make multiple web crawler is, first, start to collect targeted website based on 14 top Indonesia's University (based on Indonesia Higher Education's University Ranking). Next step is analyzing the pattern of structure navigation labels. Then the results are used to make a multiple web crawler. The result of this research is a multiple web crawler that can extract navigation label of several different target websites automatically without writing another program code of different web crawler for each crawled website.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Predicting traffic conditions using knowledge-growing bayes classifier"
        ],
        "penulis":"Husni, Emir;Nasution, Surya Michrandi;Kuspriyanto;Yusuf, Rahadian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Congestion often hinders human mobility. This problem occurs due to the constant increase in vehicles every year. Reliable predictions of traffic conditions would allow drivers to choose their routes to avoid traffic jams while providing the police with traffic management strategies. Therefore, this paper tests the ability of various machine learning methods to predict traffic conditions. The study assesses Neural Networks, Bayes Classifier, Decision Trees, SVM, Deep Neural Network, and Deep Learning. Of these methods, the Decision Tree, Deep Neural Network, and Bayes Classifier show the highest performance in predicting traffic conditions using static data testing. However, in dynamic testing to assess the growth of knowledge, the performance of the Knowledge-Growing Decision Tree tends to decrease as the training data grows. Its performance decreased 3.89 points (88.24% to 84.35%) in accuracy, and 7.55 points (76.25% to 68.70%) for each precision, recall, and F1 Score. Conversely, the Knowledge-Growing Deep Neural Network and Bayes Classifier had a better performance than Decision Tree. The performances of Knowledge-Growing Deep Neural Network increased slightly by 0.35 points (93.38% to 93.73%) for accuracy and 0.69 points (86.77% to 87.64%) in other measurements. Although its performance increased, the processing time takes very long, namely 139452.76 seconds and 318832.80 seconds for sub-scheme (a) and (b), respectively. Meanwhile, the Knowledge-Growing Bayes Classifier offers a greater performance increase of 2.3 points (80.52% to 82.82%) for the accuracy and 4.6 points (65.63% to 61.03%) for the other performance measurements. In addition, it also scored better for processing time, as predictions only take 3 seconds using sub-scheme (a), and 7 seconds when using sub-scheme (b). Therefore, the paper proposes the Knowledge-Growing Bayes Classifier to predict rapidly changing traffic conditions. This method outperform the others. These can be attributed to its ability to 1) adjust to ever-changing the traffic conditions; 2) predict the result as soon as the data are acquired; and 3) make decentralized predictions. \u00a9 2020 Lippincott Williams and Wilkins. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Congestion often hinders human mobility. This problem occurs due to the constant increase in vehicles every year. Reliable predictions of traffic conditions would allow drivers to choose their routes to avoid traffic jams while providing the police with traffic management strategies. Therefore, this paper tests the ability of various machine learning methods to predict traffic conditions. The study assesses Neural Networks, Bayes Classifier, Decision Trees, SVM, Deep Neural Network, and Deep Learning. Of these methods, the Decision Tree, Deep Neural Network, and Bayes Classifier show the highest performance in predicting traffic conditions using static data testing. However, in dynamic testing to assess the growth of knowledge, the performance of the Knowledge-Growing Decision Tree tends to decrease as the training data grows. Its performance decreased 3.89 points (88.24% to 84.35%) in accuracy, and 7.55 points (76.25% to 68.70%) for each precision, recall, and F1 Score. Conversely, the Knowledge-Growing Deep Neural Network and Bayes Classifier had a better performance than Decision Tree. The performances of Knowledge-Growing Deep Neural Network increased slightly by 0.35 points (93.38% to 93.73%) for accuracy and 0.69 points (86.77% to 87.64%) in other measurements. Although its performance increased, the processing time takes very long, namely 139452.76 seconds and 318832.80 seconds for sub-scheme (a) and (b), respectively. Meanwhile, the Knowledge-Growing Bayes Classifier offers a greater performance increase of 2.3 points (80.52% to 82.82%) for the accuracy and 4.6 points (65.63% to 61.03%) for the other performance measurements. In addition, it also scored better for processing time, as predictions only take 3 seconds using sub-scheme (a), and 7 seconds when using sub-scheme (b). Therefore, the paper proposes the Knowledge-Growing Bayes Classifier to predict rapidly changing traffic conditions. This method outperform the others. These can be attributed to its ability to 1) adjust to ever-changing the traffic conditions; 2) predict the result as soon as the data are acquired; and 3) make decentralized predictions. \u00a9 2020 Lippincott Williams and Wilkins. All rights reserved."
        ]
    },
    {
        "judul":[
            "Classification of Student Academic Performance using Fuzzy Soft Set"
        ],
        "penulis":"Riyadi Yanto, Iwan Tri;Sutoyo, Edi;Rahman, Arif;Hidayat, Rahmat;Ramli, Azizul Azhar;Fudzee, Mohd Farhan Md.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Students are one of the substances that need to be considered in relation to the world of education, because students are translators of the dynamics of science, and carry out the task of exploring that knowledge. As a subject with potential and, at the same time, objects in their activities and creativity, students are expected to be able to develop their qualities. The quality can be seen from the academic achievements achieved, which are evidence of the effort earned by students. Student academic achievement is evaluated at the end of each semester to determine the learning outcomes that have been achieved. If a student cannot meet certain academic criteria to be declared eligible to continue their studies, the student is declared to be not graduating on time or even dropout (DO). The high number of students not graduating on time or dropouts at higher institutions can be minimized by the policies of higher institutions by directing and detecting at-risk students in the early stages of education. Therefore, in this paper, we present the use of Fuzzy Soft Set Classification (FSSC), which is based on the Fuzzy Soft set theory to predict student graduation. The 2068 dataset was taken from the Directorate of Information Systems, Ahmad Dahlan University. The results showed that the FSSC reached up to 0.893292 in terms of accuracy. So, it is expected to be able to detect students at risk in the early stages of education so that higher education can minimize students not graduating on time or dropout by providing appropriate treatment and designing strategic programs. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Students are one of the substances that need to be considered in relation to the world of education, because students are translators of the dynamics of science, and carry out the task of exploring that knowledge. As a subject with potential and, at the same time, objects in their activities and creativity, students are expected to be able to develop their qualities. The quality can be seen from the academic achievements achieved, which are evidence of the effort earned by students. Student academic achievement is evaluated at the end of each semester to determine the learning outcomes that have been achieved. If a student cannot meet certain academic criteria to be declared eligible to continue their studies, the student is declared to be not graduating on time or even dropout (DO). The high number of students not graduating on time or dropouts at higher institutions can be minimized by the policies of higher institutions by directing and detecting at-risk students in the early stages of education. Therefore, in this paper, we present the use of Fuzzy Soft Set Classification (FSSC), which is based on the Fuzzy Soft set theory to predict student graduation. The 2068 dataset was taken from the Directorate of Information Systems, Ahmad Dahlan University. The results showed that the FSSC reached up to 0.893292 in terms of accuracy. So, it is expected to be able to detect students at risk in the early stages of education so that higher education can minimize students not graduating on time or dropout by providing appropriate treatment and designing strategic programs. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Simulation of transport problem with clustering velocity-density function"
        ],
        "penulis":"Daniswara, Ferdian Akbar;Gunawan P.H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper discusses the use of K-Means clustering method in finding an estimate of the velocity-density function in the traffic flow model. Two clusters will be obtained using KMeans clustering process, which are jammed and light cluster. These two clusters will have different velocity-density functions based on clustering result. Here, velocity-density function is obtained from linear regression of each data cluster. For measuring the velocity-density function, then this paper will provide the value of RMSE and R-Squared. The results show that RMSE is 2.3396 and R-squared is 0.3591 when no cluster is implemented in numerical simulation. Meanwhile, for the light cluster, the RMSE is found 1.1795 and R-squared 0.1388. Moreover, for the jammed cluster, RMSE is 0.8723 and R-squared is 0.1357. Finally, the process of identifying traffic conditions in the numerical simulation is done by computing Euclidean distance from centroid of clusters.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper discusses the use of K-Means clustering method in finding an estimate of the velocity-density function in the traffic flow model. Two clusters will be obtained using KMeans clustering process, which are jammed and light cluster. These two clusters will have different velocity-density functions based on clustering result. Here, velocity-density function is obtained from linear regression of each data cluster. For measuring the velocity-density function, then this paper will provide the value of RMSE and R-Squared. The results show that RMSE is 2.3396 and R-squared is 0.3591 when no cluster is implemented in numerical simulation. Meanwhile, for the light cluster, the RMSE is found 1.1795 and R-squared 0.1388. Moreover, for the jammed cluster, RMSE is 0.8723 and R-squared is 0.1357. Finally, the process of identifying traffic conditions in the numerical simulation is done by computing Euclidean distance from centroid of clusters.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Sustainability analysis of dairy-horticulture integrated farming system"
        ],
        "penulis":"Rosmiati M.;Putra R.E.;Lastini T.;Hernawan E.;Pujo;Rahmayunita I.;Maulana F.R.;Liesdiana F.;Nurdiansyah M.A.;Azis A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Purpose: The Integrated farming system offers better opportunities to be implemented in smallholder agriculture because it ensures productivity and profitability for sustainable livelihoods. However, the evaluation of this practice has not been clearly identified. This study is aimed at evaluating the ecological, economic, social, institutional, and technological aspects of sustainability of existing dairy-horticulture farming systems at farm level. Research Method: Data were collected through survey design using questionnaire, observation, and literature review. This research used Multidimensional Scaling, leverage analysis and Monte Carlo called RAP-DHFS (Rapid Appraisal for Dairy-Horticulture Farming System) to analyze the data. Findings: The results showed that the sustainability status of ecological dimension, economic dimension, social dimension, and technological dimension were classified as less sustainable which were 28.07%, 29.52%, 27.37%, and 29.15, respectively while the institutional dimension was considered as unsustainable (21.77%). There were also 10 attributes identified as the most influential attributes on the sustainability status. Limitations: The study was conducted at one village, which is a small scope of area. Value: This study provides a holistic assessment of the integrated farming system and shows the concern and risk for further development in rural areas. \u00a9 2020, Faculty of Agricultural Sciences, Sabaragamuwa University of Sri Lanka. All rights reserved.",
            "Sustainable Development Goals mapped to this documentZero hungerGoal 2Quality educationGoal 4Decent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: The Integrated farming system offers better opportunities to be implemented in smallholder agriculture because it ensures productivity and profitability for sustainable livelihoods. However, the evaluation of this practice has not been clearly identified. This study is aimed at evaluating the ecological, economic, social, institutional, and technological aspects of sustainability of existing dairy-horticulture farming systems at farm level. Research Method: Data were collected through survey design using questionnaire, observation, and literature review. This research used Multidimensional Scaling, leverage analysis and Monte Carlo called RAP-DHFS (Rapid Appraisal for Dairy-Horticulture Farming System) to analyze the data. Findings: The results showed that the sustainability status of ecological dimension, economic dimension, social dimension, and technological dimension were classified as less sustainable which were 28.07%, 29.52%, 27.37%, and 29.15, respectively while the institutional dimension was considered as unsustainable (21.77%). There were also 10 attributes identified as the most influential attributes on the sustainability status. Limitations: The study was conducted at one village, which is a small scope of area. Value: This study provides a holistic assessment of the integrated farming system and shows the concern and risk for further development in rural areas. \u00a9 2020, Faculty of Agricultural Sciences, Sabaragamuwa University of Sri Lanka. All rights reserved."
        ]
    },
    {
        "judul":[
            "Rateless raptor codes for reliable wireless capsule endoscopy (WCE)"
        ],
        "penulis":"Sobiroh, Indriana Fitriotavia Endah;Anwar, Khoirul;Mukhtar, Husneni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Wireless Capsule Endoscopy (WCE) has established as painless endoscopic imaging of the gastrointestinal (GI) tract To improve the performance of video transfer, we propose a rateless Raptor coding scheme with low coding rate to overcome the potential interference from other signals due to the low-power transmission characteristic of the WCE communications. In addition, the proposed Raptor codes with rateless capability can protect the information from error under varying channel conditions between capsule and the receiver outside the body. The proposed Raptor codes are constructed from Low-Density Parity Check (LDPC) and Luby Transform (LT) codes suitable for short block length of WCE applications such that the rateless capability of the codes can adapt to the dynamic GI channel modeled by multipath In-Body-to-On-Body (IB-to-OB) ultra wide band (UWB) channels in the 3.4-4.8 GHz. We also evaluate the performance of the codes under the multipath channel model for WCE using Cyclic-Prefix Orthogonal Frequency Division Multiplexing (CP-OFDM) in terms of average bit error rate (BER) using a series of computer simulations. The results confirmed that the proposed rateless Raptor codes can adapt well to the dynamic changes of channel conditions and are suitable for practical reliable WCE applications. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Wireless Capsule Endoscopy (WCE) has established as painless endoscopic imaging of the gastrointestinal (GI) tract To improve the performance of video transfer, we propose a rateless Raptor coding scheme with low coding rate to overcome the potential interference from other signals due to the low-power transmission characteristic of the WCE communications. In addition, the proposed Raptor codes with rateless capability can protect the information from error under varying channel conditions between capsule and the receiver outside the body. The proposed Raptor codes are constructed from Low-Density Parity Check (LDPC) and Luby Transform (LT) codes suitable for short block length of WCE applications such that the rateless capability of the codes can adapt to the dynamic GI channel modeled by multipath In-Body-to-On-Body (IB-to-OB) ultra wide band (UWB) channels in the 3.4-4.8 GHz. We also evaluate the performance of the codes under the multipath channel model for WCE using Cyclic-Prefix Orthogonal Frequency Division Multiplexing (CP-OFDM) in terms of average bit error rate (BER) using a series of computer simulations. The results confirmed that the proposed rateless Raptor codes can adapt well to the dynamic changes of channel conditions and are suitable for practical reliable WCE applications. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Exploring the Pattern of Voters' Characteristics: Partial Least Square Analysis"
        ],
        "penulis":"Lubis, Muharman;Ridho Lubis, Arif;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Understanding of characteristics can be assessed either by public decision-makers, who have been the primary concern of political actors or by voters themselves, who have participated directly in the process of election. Therefore, this study focused on the voters' self-evaluation to look out on the voter decisions with survey questionnaire have been used as the tools to collect the data independently in relation to create formative measurement model. In addition, major influences to the public also involves the role of emotion, political socialization and tolerance to the diversity of media views. This study investigated gender-based patterns of 790 samples using PLS as a data analysis tool, which found interesting result, which suggested that Social Norm (SNorm) have strongest effect to both PCon and PBen with 0.179 and 0.066 respectively followed by Technology Solution (TSol) with 0.057 and 0.022 as well Legal Regulation (LReg) with 0.043 and 0.020 accordingly. Thus, in the developed model, the researcher recommend that social factors can lead to determination of demand and participation in the voting to have public confidence and good behaviour in the protective manner. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Understanding of characteristics can be assessed either by public decision-makers, who have been the primary concern of political actors or by voters themselves, who have participated directly in the process of election. Therefore, this study focused on the voters' self-evaluation to look out on the voter decisions with survey questionnaire have been used as the tools to collect the data independently in relation to create formative measurement model. In addition, major influences to the public also involves the role of emotion, political socialization and tolerance to the diversity of media views. This study investigated gender-based patterns of 790 samples using PLS as a data analysis tool, which found interesting result, which suggested that Social Norm (SNorm) have strongest effect to both PCon and PBen with 0.179 and 0.066 respectively followed by Technology Solution (TSol) with 0.057 and 0.022 as well Legal Regulation (LReg) with 0.043 and 0.020 accordingly. Thus, in the developed model, the researcher recommend that social factors can lead to determination of demand and participation in the voting to have public confidence and good behaviour in the protective manner. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Analysis the measurement quality system of clearence tappet using measurement system analysis on motorcycle manufacturing company"
        ],
        "penulis":"Doaly, Carla Olyvia;Sriwana, Iphov K.;Salomon, Lithrone;Farrell;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A motorcycle manufacturing company on the K56S engine has a symptom that often occurs called noise tappet. The observations found that Symptom was caused by clearence or tappet gap that was not in accordance with the specified specifications. The gap measurement system uses fuller which usually relies on the experience and feeling of the operator, so it is possible to produce an unsuitable gap measurement. This research will evaluate the measurement system of clearence tappet using Measurement system analysis (MSA) which includes stability, bias, linearity, repeatability & reproducibility. Based on data processing known that the measurement system has a stable process with a linearity level of 2.6% is acceptable. The measurement system has a biased problem with an average bias value of 0.054 mm (not acceptable) and from repeatability & reproducibility with a GRR% of ANOVA method of 49.98% that exceeds the acceptance criteria. \u00a9 2020 Institute of Physics Publishing. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A motorcycle manufacturing company on the K56S engine has a symptom that often occurs called noise tappet. The observations found that Symptom was caused by clearence or tappet gap that was not in accordance with the specified specifications. The gap measurement system uses fuller which usually relies on the experience and feeling of the operator, so it is possible to produce an unsuitable gap measurement. This research will evaluate the measurement system of clearence tappet using Measurement system analysis (MSA) which includes stability, bias, linearity, repeatability & reproducibility. Based on data processing known that the measurement system has a stable process with a linearity level of 2.6% is acceptable. The measurement system has a biased problem with an average bias value of 0.054 mm (not acceptable) and from repeatability & reproducibility with a GRR% of ANOVA method of 49.98% that exceeds the acceptance criteria. \u00a9 2020 Institute of Physics Publishing. All rights reserved."
        ]
    },
    {
        "judul":[
            "The Influence of Blue Light in Maintaining Alertness in Tropical Country: A Preliminary Study"
        ],
        "penulis":"Rahma K.T.;Salma S.A.;Widyanti A.;Suprijanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Several studies have discussed the influence of blue light on cognitive activity. This study aims to determine the effectiveness of blue light in increasing alertness at night in tropical countries. Twelve healthy young males joined in this study. All participants were asked to do a monotonous activity that is reading activity. The experiment was a within-subject design with the independent variable is lighting condition (normal light and blue light) and duration of exposure (30 minutes and 60 minutes). Electroencephalography (EEG) signals were recorded continuously during the experiment. Alertness was measured based on theta, alpha, and beta activity. The result is the light condition not significantly affected the theta (F (1,11) = 0.608, \u03c1 = 0.452), alpha (F (1,11) = 1.561, \u03c1 = 0.237), and beta (F (1,11) = 0.608, \u03c1 = 0.700) activity. This shows that blue light is not effective in increasing alertness at night in the tropical country both in short and long duration of exposure. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Several studies have discussed the influence of blue light on cognitive activity. This study aims to determine the effectiveness of blue light in increasing alertness at night in tropical countries. Twelve healthy young males joined in this study. All participants were asked to do a monotonous activity that is reading activity. The experiment was a within-subject design with the independent variable is lighting condition (normal light and blue light) and duration of exposure (30 minutes and 60 minutes). Electroencephalography (EEG) signals were recorded continuously during the experiment. Alertness was measured based on theta, alpha, and beta activity. The result is the light condition not significantly affected the theta (F (1,11) = 0.608, \u03c1 = 0.452), alpha (F (1,11) = 1.561, \u03c1 = 0.237), and beta (F (1,11) = 0.608, \u03c1 = 0.700) activity. This shows that blue light is not effective in increasing alertness at night in the tropical country both in short and long duration of exposure. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Human factors analysis of online learning process for students on selected indonesian campus (A preliminary study)"
        ],
        "penulis":"Studiyanti, Linda;Aurachman, Rio;Amran, Tiena Gustina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The fourth industrial revolution is impacting the learning industry to become online learning, especially in Indonesia. Online learning provides benefits in that it can be cheaper, takes less time, can be self-paced, and provides an equal quality of education for students in rural areas. A total of 60 Indonesian college students on selected campus (age 20 \u00b1 0,36 years old) who joined the Computer Simulation class in the third grade participated in this study. They are divided into two classes, an online class using Moodle software and a physical class, then observations are made. This study aims to obtain preliminary data to then research what human factors influence Indonesian people that constrain students from successful participation in online learning. The results show that there are three aspects of implementing online lectures in Indonesia: rules, usability and cognitive aspects. Besides, quality of place is an environmental factor that cannot be controlled. \u00a9 Malaysian Public Health Physicians Association.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The fourth industrial revolution is impacting the learning industry to become online learning, especially in Indonesia. Online learning provides benefits in that it can be cheaper, takes less time, can be self-paced, and provides an equal quality of education for students in rural areas. A total of 60 Indonesian college students on selected campus (age 20 \u00b1 0,36 years old) who joined the Computer Simulation class in the third grade participated in this study. They are divided into two classes, an online class using Moodle software and a physical class, then observations are made. This study aims to obtain preliminary data to then research what human factors influence Indonesian people that constrain students from successful participation in online learning. The results show that there are three aspects of implementing online lectures in Indonesia: rules, usability and cognitive aspects. Besides, quality of place is an environmental factor that cannot be controlled. \u00a9 Malaysian Public Health Physicians Association."
        ]
    },
    {
        "judul":[
            "Preliminary Study for identifying Rice Plant Disease Based on Thermal Images"
        ],
        "penulis":"Silvi Lydia, Maya;Aulia, Indra;Jaya, Ivan;Sofiah Hanafiah, Diana;Hakim Lubis, Rizky;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Accurate and timely identification of plant disease can help stakeholders and farmers to mitigate losses due to pests and diseases. One of the identification techniques is indirect detection using thermal imaging technology. This technology has been considered a fast way without damaging the profile of a plant. In this paper, we describe the preliminary study of the thermal images gathering, so that the rice plant disease on the leaf canopy can be identified by using a thermal imaging camera. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Accurate and timely identification of plant disease can help stakeholders and farmers to mitigate losses due to pests and diseases. One of the identification techniques is indirect detection using thermal imaging technology. This technology has been considered a fast way without damaging the profile of a plant. In this paper, we describe the preliminary study of the thermal images gathering, so that the rice plant disease on the leaf canopy can be identified by using a thermal imaging camera. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Building Serverless Website on GitHub Pages"
        ],
        "penulis":"Utomo, Prayudi;Falahah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "GitHub provides the environment for developing and publishing website in integrated environment. By GitHub Pages, we can host the static web easy, fast and free. It helps the developer for integrating development and deployment process, because GitHub Pages is integrating with GitHub environment that support continuous integration and continuous delivery, and also become a content delivery network (CDN), as a part of JAMstack building block. Unfortunately, the usage GitHub as web hosting and JAMstack as an approach for developing web is not very popular among developer in Indonesia. The purpose of this research is to show how implement the JAMstack approach on designing and building website and host it on the GitHub. The website we designed using JAMstack approach by implementing Hugo as static site generator (SSG) and GitHub as content delivery network (CDN). We also insert API for showing the easiness of integrating lots of components on JAMstack approach. We do several tests to check the quality of the website, such as functional test and performance test. The performance test results show that Google PageSpeed score is 97% (A) and YSlow score is 91% (A). It shows that the website can run in good performance although it connected with others services through API.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "GitHub provides the environment for developing and publishing website in integrated environment. By GitHub Pages, we can host the static web easy, fast and free. It helps the developer for integrating development and deployment process, because GitHub Pages is integrating with GitHub environment that support continuous integration and continuous delivery, and also become a content delivery network (CDN), as a part of JAMstack building block. Unfortunately, the usage GitHub as web hosting and JAMstack as an approach for developing web is not very popular among developer in Indonesia. The purpose of this research is to show how implement the JAMstack approach on designing and building website and host it on the GitHub. The website we designed using JAMstack approach by implementing Hugo as static site generator (SSG) and GitHub as content delivery network (CDN). We also insert API for showing the easiness of integrating lots of components on JAMstack approach. We do several tests to check the quality of the website, such as functional test and performance test. The performance test results show that Google PageSpeed score is 97% (A) and YSlow score is 91% (A). It shows that the website can run in good performance although it connected with others services through API.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Utilization magnetic field and radio frequency identification for moving block signalling system prototype to increase line track capacity"
        ],
        "penulis":"Wijaya, Rifki;Siswanto, Rahmat;Prihatmanto, Ary Setijadi;Suwita, Ferry Stephanus;Darmakusuma, Reza;Rosyid, Harits Ar;Satriawan, Ardianto;Sukoco, Agus;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The line capacity of fixed block signaling is reciprocal of the minimum headway and is defined as the maximum number of the train that can pass through a stretch of track per unit time for safety reason. By using the Communication Based Train Control (CBTC) technology all trains continuously communicating their exact position. Therefore, the safety distance was no longer a static entity but an adjustable distance (moving block) based on a real-time calculation of the train speed. There will no longer wasted space so the line capacity will increase. The prototype form implemented in four subsystems, the first one is signal generating system consisting of an oscillator circuit and amplifiers to generate AC signals and flow it to the loop cable produce electromagnetic waves, the signal processing sub-system which serves to read the oscillator signal on the loop cable by using the coil, data processing and communication sub-system processing signal output and send data to the server and the radio frequency identification as the wayside equipment for calibrating the position. The output of this implementation is sequence number of blocks that have been passed by the train and the information of the RFID tags used to calibrate the position of the train. By using that information, we can determine the position of the trains and kept the trains close to each other while maintaining a safety distance. \u00a9 2020 Asian Research Publishing Network.",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The line capacity of fixed block signaling is reciprocal of the minimum headway and is defined as the maximum number of the train that can pass through a stretch of track per unit time for safety reason. By using the Communication Based Train Control (CBTC) technology all trains continuously communicating their exact position. Therefore, the safety distance was no longer a static entity but an adjustable distance (moving block) based on a real-time calculation of the train speed. There will no longer wasted space so the line capacity will increase. The prototype form implemented in four subsystems, the first one is signal generating system consisting of an oscillator circuit and amplifiers to generate AC signals and flow it to the loop cable produce electromagnetic waves, the signal processing sub-system which serves to read the oscillator signal on the loop cable by using the coil, data processing and communication sub-system processing signal output and send data to the server and the radio frequency identification as the wayside equipment for calibrating the position. The output of this implementation is sequence number of blocks that have been passed by the train and the information of the RFID tags used to calibrate the position of the train. By using that information, we can determine the position of the trains and kept the trains close to each other while maintaining a safety distance. \u00a9 2020 Asian Research Publishing Network."
        ]
    },
    {
        "judul":[
            "An Integration of National Identity towards Single Identity Number with Blockchain"
        ],
        "penulis":"Fathiyana, Rana Zaini;Hidayat, Fadhil;Rahardjo, Budi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The lack of coordination in the integration of information systems between government agencies that issue identity numbers causes replication and redundancy of population information data. Another problem is the emergence of citizens' concerns over data integrity and security due to national identification records is also used by the private sector. In this paper, one of the solutions offered to overcome the above problem is to build an integrated national identification database system between government agencies by applying the concept of Single Identity Number (SIN) using blockchain technology. Blockchain is a secure and robust system for keeping a record of the identities of all citizens and also able to facilitate data integration between institutions. This paper uses the strengths of blockchain to possess characteristics of immutability that it is possible to store national identification records. Copyright \u00a9 2020 EAI",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The lack of coordination in the integration of information systems between government agencies that issue identity numbers causes replication and redundancy of population information data. Another problem is the emergence of citizens' concerns over data integrity and security due to national identification records is also used by the private sector. In this paper, one of the solutions offered to overcome the above problem is to build an integrated national identification database system between government agencies by applying the concept of Single Identity Number (SIN) using blockchain technology. Blockchain is a secure and robust system for keeping a record of the identities of all citizens and also able to facilitate data integration between institutions. This paper uses the strengths of blockchain to possess characteristics of immutability that it is possible to store national identification records. Copyright \u00a9 2020 EAI"
        ]
    },
    {
        "judul":[
            "Monitoring floating solar tracker based on axis coordinates using lora network"
        ],
        "penulis":"Fernandez, Abyan Arief;Rakhmatsyah, Andrian;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research aimed to build a solar tracker for a floating solar panel and used long\u2013range (LoRa) communication to harvest energy and monitor its process. With the rising demand for renewable energy in these recent years especially for solar energy, it needs to meet this demand to remain relevant for the upcoming years where it will have an even larger impact as we shift into clean energy. Monitoring single\u2013axis solar trackers on rural areas difficult and cost\u2013intensive. The purpose of a floating solar farm is to reduce the cost from buying\/renting land. Floating solar panels cannot be monitored using wired because they are moving nodes in the water, it makes wired installation complicated. Hence, using wireless sensor network is a solution that allows remote monitoring of floating solar panels in rural areas and makes moving nodes mentioned above possible. Testing was performed by sending 100 packets from the node to its gateway using LoRa modulation, and the gateway successfully received about 90% of the packets sent by the node. The vertical single-axis solar tracker used in floating solar managed to get 17% more energy than the fixed solar with a more stable income for the whole duration of sending 100 packets. \u00a9 2020. CBIORE-IJRED. All rights reserved.",
            "ClOClOSOOONaView detailsExpand Substance sodium 2-(2,4-dichlorophenoxy)ethyl sulfate",
            "Powered by",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research aimed to build a solar tracker for a floating solar panel and used long\u2013range (LoRa) communication to harvest energy and monitor its process. With the rising demand for renewable energy in these recent years especially for solar energy, it needs to meet this demand to remain relevant for the upcoming years where it will have an even larger impact as we shift into clean energy. Monitoring single\u2013axis solar trackers on rural areas difficult and cost\u2013intensive. The purpose of a floating solar farm is to reduce the cost from buying\/renting land. Floating solar panels cannot be monitored using wired because they are moving nodes in the water, it makes wired installation complicated. Hence, using wireless sensor network is a solution that allows remote monitoring of floating solar panels in rural areas and makes moving nodes mentioned above possible. Testing was performed by sending 100 packets from the node to its gateway using LoRa modulation, and the gateway successfully received about 90% of the packets sent by the node. The vertical single-axis solar tracker used in floating solar managed to get 17% more energy than the fixed solar with a more stable income for the whole duration of sending 100 packets. \u00a9 2020. CBIORE-IJRED. All rights reserved."
        ]
    },
    {
        "judul":[
            "Firefly Algorithm-based Hyperparameters Setting of DRNN for Weather Prediction"
        ],
        "penulis":"Ahyar, Laila Fathhiyana;Suyanto, Suyanto;Arifianto, Anditya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A Deep Recurrent Neural Networks (DRNN) is powerful to be used in sequential datasets. Quite hard tasks in DRNN is setting the optimum hyperparameters. There are known to be three types of general methods for searching the optimum DRNN hyperparameters: manual, grid, and random searches. However, these types of methods are not the right choice when a prior experience is insufficient. This paper addresses both the optimization and automation of hyperparameters to build its structure. They are carried out using a Firefly Algorithm (FA), one of the metaheuristic methods. The hyperparameters to be optimized and automated are batch size, dense, and total units in each layer. There are three things to consider in doing FA-based optimization in this test, such as designing FA, determining the initialization of fixed hyperparameters from the DRNN, and determining the range of DRNN hyperparameter values. Evaluation using the dataset of weather history recorded by the Max Planck Biogeochemical Institute, which contains 15 attributes, shows that the FA-based hyperparameters setting of DRNN gives a much lower prediction error of 0.111 than the manual tuning (0.475). Based on that result, when using FA for the optimization of DRNN hyperparameters in weather prediction, it reduces the error value, so the prediction results using DRNN are more accurate.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A Deep Recurrent Neural Networks (DRNN) is powerful to be used in sequential datasets. Quite hard tasks in DRNN is setting the optimum hyperparameters. There are known to be three types of general methods for searching the optimum DRNN hyperparameters: manual, grid, and random searches. However, these types of methods are not the right choice when a prior experience is insufficient. This paper addresses both the optimization and automation of hyperparameters to build its structure. They are carried out using a Firefly Algorithm (FA), one of the metaheuristic methods. The hyperparameters to be optimized and automated are batch size, dense, and total units in each layer. There are three things to consider in doing FA-based optimization in this test, such as designing FA, determining the initialization of fixed hyperparameters from the DRNN, and determining the range of DRNN hyperparameter values. Evaluation using the dataset of weather history recorded by the Max Planck Biogeochemical Institute, which contains 15 attributes, shows that the FA-based hyperparameters setting of DRNN gives a much lower prediction error of 0.111 than the manual tuning (0.475). Based on that result, when using FA for the optimization of DRNN hyperparameters in weather prediction, it reduces the error value, so the prediction results using DRNN are more accurate.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Comparison of File Transfer Protocol Service between Link State and Distance Vector Routing Protocol in Software Defined Network"
        ],
        "penulis":"Tulloh, Rohmat;Amri Ginting, Jafaruddin Gusti;Mulyana, Asep;Lutfi, Muhammad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Software-Defined Network (SDN) is a new concept in computer networks where the network control function is separated from the data forwarding function (data plane). The control plane and data plane which are separated from each other is the answer for faster, more flexible, and secure internet service. File transfer protocol (FTP) is an internet protocol that runs at the application layer that is used to exchange data between server and client. Open Shortest Path First (OSPF) is a routing protocol for internet networks that belongs to the Interior Gateway Protocol (IGP) group and uses the Link State Routing algorithm (LSR). Routing Information Protocol (RIP) is a type of Distance Vector Routing protocol that is still used today. This study aims to compare the performance of FTP services using OSPF and RIP on SDN networks and conventional networks. The research was conducted with direct implementation on the device with a planned topology. The measurement results show that FTP using OSPF routing has better results than using RIP. FTP that runs on SDN also has a better quality of service value compared to conventional networks.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Software-Defined Network (SDN) is a new concept in computer networks where the network control function is separated from the data forwarding function (data plane). The control plane and data plane which are separated from each other is the answer for faster, more flexible, and secure internet service. File transfer protocol (FTP) is an internet protocol that runs at the application layer that is used to exchange data between server and client. Open Shortest Path First (OSPF) is a routing protocol for internet networks that belongs to the Interior Gateway Protocol (IGP) group and uses the Link State Routing algorithm (LSR). Routing Information Protocol (RIP) is a type of Distance Vector Routing protocol that is still used today. This study aims to compare the performance of FTP services using OSPF and RIP on SDN networks and conventional networks. The research was conducted with direct implementation on the device with a planned topology. The measurement results show that FTP using OSPF routing has better results than using RIP. FTP that runs on SDN also has a better quality of service value compared to conventional networks.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Application of Theory Planned Behavior (TPB) and Health Belief Model (HBM) in COVID-19 Prevention: A Literature Review"
        ],
        "penulis":"Yastica, Tiara Verita;Salma, Sheila Amalia;Caesaron, Dino;Safrudin, Yunita Nugrahaini;Pramadya, Afin Rizqi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This preliminary study was conducted to provide a literature review about applications of theory of planned behavior and health belief model. These theories have been widely used to explain and predict a person's health-related intention and behavior. Health belief model as well as theory of planned behavior remain the best known theories in health behavior research. The health belief model suggests people's belief about health problems in order to reduce or prevent the chance of disease whereas the theory of planned behavior is about predicting a person's intention or behavior. In this study, we systematically selected and reviewed articles related to the application of theory of planned behavior and health belief model, particularly to its implementation in observing public health behavior. The aim was to identify the implications of theory of planned behavior and health belief model in behavioral health-related research and identify a potential research gap by using these two theories. Our analysis revealed that in Indonesia there were less studies which integrated extension of theory of planned behavior and health belief model, especially in evaluating factors affecting the public behavior from prevention of COVID-19. This study could be a basis of further studies which integrate extended theory of planned behavior and health belief model in investigating public behavior during the pandemic of COVID-19 in Indonesia.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This preliminary study was conducted to provide a literature review about applications of theory of planned behavior and health belief model. These theories have been widely used to explain and predict a person's health-related intention and behavior. Health belief model as well as theory of planned behavior remain the best known theories in health behavior research. The health belief model suggests people's belief about health problems in order to reduce or prevent the chance of disease whereas the theory of planned behavior is about predicting a person's intention or behavior. In this study, we systematically selected and reviewed articles related to the application of theory of planned behavior and health belief model, particularly to its implementation in observing public health behavior. The aim was to identify the implications of theory of planned behavior and health belief model in behavioral health-related research and identify a potential research gap by using these two theories. Our analysis revealed that in Indonesia there were less studies which integrated extension of theory of planned behavior and health belief model, especially in evaluating factors affecting the public behavior from prevention of COVID-19. This study could be a basis of further studies which integrate extended theory of planned behavior and health belief model in investigating public behavior during the pandemic of COVID-19 in Indonesia.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A PROPOSED MODIFIED TEXT STEGANOGRAPHY TECHNIQUE USING UNISPACH WITH XOR ENCRYPTION AND SHIFT CIPHER"
        ],
        "penulis":"Adinugraha, Raka;Purboyo, Tito Waluyo;Saputra, Randy Erfa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, security on communication was a necessity. However, sending an encrypted message can draw a suspicion from unintended parties. So, sometimes cryptography doesn\u2019t guarantee a full security because it could attract attempts to break and reveal the encrypted message. Steganography was introduced as a method to secure a secret message by hiding it inside an unsuspicious message. The message can be plain text or other data that can be represented as streams of bits. Many of steganography techniques are being proposed from time to time, means steganography is a promising method to secure a communication line beside cryptography. In this paper, an experiment is conducted by comparing two text steganography techniques, which is UniSpaCh and a steganography technique by altering the foreground color of an invisible character. \u00a9 2006\u20132020. Asian Research Publishing Network (ARPN). All rights reserved.",
            "OHH2NView detailsExpand Substance hydroxylamine",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, security on communication was a necessity. However, sending an encrypted message can draw a suspicion from unintended parties. So, sometimes cryptography doesn\u2019t guarantee a full security because it could attract attempts to break and reveal the encrypted message. Steganography was introduced as a method to secure a secret message by hiding it inside an unsuspicious message. The message can be plain text or other data that can be represented as streams of bits. Many of steganography techniques are being proposed from time to time, means steganography is a promising method to secure a communication line beside cryptography. In this paper, an experiment is conducted by comparing two text steganography techniques, which is UniSpaCh and a steganography technique by altering the foreground color of an invisible character. \u00a9 2006\u20132020. Asian Research Publishing Network (ARPN). All rights reserved."
        ]
    },
    {
        "judul":[
            "Leveraging Textural Features for Mammogram Classification"
        ],
        "penulis":"Akbarisena, Sri Frenzilino Mahayyu;Rachmawati, Ema;Utama, Dody Qori;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Cancer is the body' s tissue cells that continue to grow beyond normal and out of control so that cancer cells push normal cells and cause death in normal cells. One type of cancer is cancer that attacks breast tissue or is called breast cancer. The sooner breast cancer is detected, it will increase the chance the patient will survive. One of the techniques in the early detection of breast cancer is mammography screening. To minimize human error in checking the results of mammography, a CAD system is needed in checking the results of mammography. Therefore, in this research, a system that can classify breast tissue from mammogram into three classes, namely normal, benign, and malignant has been built. The performance of the system reaches F1-Score 74.02%, Recall 76.15% and Precision 74.02%. The system achieves this performance by combining the Uniform Local Binary Pattern and GLCM features and the Random Forest classification method.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Cancer is the body' s tissue cells that continue to grow beyond normal and out of control so that cancer cells push normal cells and cause death in normal cells. One type of cancer is cancer that attacks breast tissue or is called breast cancer. The sooner breast cancer is detected, it will increase the chance the patient will survive. One of the techniques in the early detection of breast cancer is mammography screening. To minimize human error in checking the results of mammography, a CAD system is needed in checking the results of mammography. Therefore, in this research, a system that can classify breast tissue from mammogram into three classes, namely normal, benign, and malignant has been built. The performance of the system reaches F1-Score 74.02%, Recall 76.15% and Precision 74.02%. The system achieves this performance by combining the Uniform Local Binary Pattern and GLCM features and the Random Forest classification method.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Identification of upwelling area of the western territorial waters of Indonesia from 2000 to 2017"
        ],
        "penulis":"Supriyadi, Eko;Hidayat, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The Western Waters of Indonesian (WWI) present a diverse interaction of ocean-atmosphere dynamics. One of them represents the event of Indian Ocean Dipole (IOD), El Nino-Southern Oscillation (ENSO), and upwelling. The objective of this study is to determine the dynamics of chlorophyll-a concentration (Chl-a), especially during IOD and ENSO. Also, this study is aimed to examine the temporal and spatial distribution of the upwelling area from 2000 to 2017. The data utilized consisted of Chl-a, wind stress, Sea Level Anomaly (SLA), and Sea Surface Temperature (SST). The technique used to determine the upwelling area was by examining the maximum conditions of Chl-a, the low temperature of SST, and SLA. The results showed the sea surface temperature had a relationship with the concentration of Chl-a. It was obtained if the Directional Movement Index (DMI) and N3.4 (Nino 3.4 Index) moved stably (not too fluctuation) resulting in high concentrations of Chl-a. High standard deviations of SST are recognized around the Sunda Strait (June - October). When the standard deviation of SST is high, there is also a tendency for high Chl-a concentrations, while the results of empirical calculations show that large areas of upwelling occurred in January and September respectively at 12,447.72 km2and 8,146.20 km2. Based on the results of the analysis, it can be concluded that the upwelling does not only occur at the coastal area of Western Sumatra (coastal upwelling), but it also occurs in the eastern territorial waters of the Indian Ocean. In addition, the upwelling area has the same pattern as the Chl-a concentration in January - October. \u00a9 2020 by the authors. Licensee Indonesian Journal of Geography, Indonesia",
            "NNOOOCH3H3CCH3NOONH3CCH3CH3CH2CH3CH3CH3H3CCH3MgView detailsExpand Substance chlorophyll a",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The Western Waters of Indonesian (WWI) present a diverse interaction of ocean-atmosphere dynamics. One of them represents the event of Indian Ocean Dipole (IOD), El Nino-Southern Oscillation (ENSO), and upwelling. The objective of this study is to determine the dynamics of chlorophyll-a concentration (Chl-a), especially during IOD and ENSO. Also, this study is aimed to examine the temporal and spatial distribution of the upwelling area from 2000 to 2017. The data utilized consisted of Chl-a, wind stress, Sea Level Anomaly (SLA), and Sea Surface Temperature (SST). The technique used to determine the upwelling area was by examining the maximum conditions of Chl-a, the low temperature of SST, and SLA. The results showed the sea surface temperature had a relationship with the concentration of Chl-a. It was obtained if the Directional Movement Index (DMI) and N3.4 (Nino 3.4 Index) moved stably (not too fluctuation) resulting in high concentrations of Chl-a. High standard deviations of SST are recognized around the Sunda Strait (June - October). When the standard deviation of SST is high, there is also a tendency for high Chl-a concentrations, while the results of empirical calculations show that large areas of upwelling occurred in January and September respectively at 12,447.72 km2and 8,146.20 km2. Based on the results of the analysis, it can be concluded that the upwelling does not only occur at the coastal area of Western Sumatra (coastal upwelling), but it also occurs in the eastern territorial waters of the Indian Ocean. In addition, the upwelling area has the same pattern as the Chl-a concentration in January - October. \u00a9 2020 by the authors. Licensee Indonesian Journal of Geography, Indonesia"
        ]
    },
    {
        "judul":[
            "Attribute Selection Effect on Tree-Based Classifiers for Letter Recognition"
        ],
        "penulis":"Prayogo, Rizal Dwi;Ikhsan, Nurul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study presents evaluation measures for attribute selection effect on classification performance in classifying the 26 uppercase letters in the English alphabet. Attribute selection is an essential method in the classification phase to measure the attribute significance related to the class label since not all attributes are significant for letter recognition. Therefore, insignificant attributes should be reduced by applying dimensionality reduction. The filter-based attribute selection methods using Information Gain, Gain Ratio, Correlation, and Chi-square are proposed. The performances of attribute selection are evaluated by tree-based classifiers using J48, CART, and Random Forest algorithms with the measures of accuracy, precision, recall, F-measure, and processing time. The results indicate that the use of attribute selection methods provides the increase of classification performances for letter recognition. The reduction of insignificant attributes is discussed in terms of the effect on classification accuracy and the processing time. The optimal number of selected attributes is determined for each attribute selection, it provides better classification accuracy with more time-efficient.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study presents evaluation measures for attribute selection effect on classification performance in classifying the 26 uppercase letters in the English alphabet. Attribute selection is an essential method in the classification phase to measure the attribute significance related to the class label since not all attributes are significant for letter recognition. Therefore, insignificant attributes should be reduced by applying dimensionality reduction. The filter-based attribute selection methods using Information Gain, Gain Ratio, Correlation, and Chi-square are proposed. The performances of attribute selection are evaluated by tree-based classifiers using J48, CART, and Random Forest algorithms with the measures of accuracy, precision, recall, F-measure, and processing time. The results indicate that the use of attribute selection methods provides the increase of classification performances for letter recognition. The reduction of insignificant attributes is discussed in terms of the effect on classification accuracy and the processing time. The optimal number of selected attributes is determined for each attribute selection, it provides better classification accuracy with more time-efficient.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Dashboard information system development as visualization of transaction reports in the application BackInd (backpacker reservation system)"
        ],
        "penulis":"Lubis, Muharman;Dennis, Filhan;Andreswari, Rachmadita;Ridho Lubis, Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The accuracy and clarity of information becomes primary source for decision making process to bring effective and efficient of technology utilization. For this purpose, the 'BackInd' has been developed as reservation system to help travellers obtain complete information regarding the tourist attractions and any relevant information. Therefore, there are several problems that occur in term of presenting information, such as the use of complex tables as a means of detail information about business conditions, information overload in single page that become deterrent in term of identification of relevant data and unintuitive data presentation that bring exhaustive understanding. Thus, the implementation of dashboard can visualize the key performance and metric in real-time to support the executive gain valuable insight lead to quick and accurate decision making. The results of this study related to the process and context analysis by visualizing the data group into various sections such as transactions, finances, testimonials, visits and business performance to bring resourceful and usable information. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The accuracy and clarity of information becomes primary source for decision making process to bring effective and efficient of technology utilization. For this purpose, the 'BackInd' has been developed as reservation system to help travellers obtain complete information regarding the tourist attractions and any relevant information. Therefore, there are several problems that occur in term of presenting information, such as the use of complex tables as a means of detail information about business conditions, information overload in single page that become deterrent in term of identification of relevant data and unintuitive data presentation that bring exhaustive understanding. Thus, the implementation of dashboard can visualize the key performance and metric in real-time to support the executive gain valuable insight lead to quick and accurate decision making. The results of this study related to the process and context analysis by visualizing the data group into various sections such as transactions, finances, testimonials, visits and business performance to bring resourceful and usable information. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The impact of absorptive capacity and innovation ambidexterity on sustainable competitive advantage: The case of Indonesian higher education"
        ],
        "penulis":"Pangarso, Astadi;Astuti, Endang Siti;Raharjo, Kusdi;Afrianty, Tri Wulida;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study is to empirically examine the mediation role of innovation ambidexterity on the impact of absorptive capacity on sustainable competitive advantage from the previous researchers' data article publication. A survey of academic and nonacademic staff from sixty four private higher education institutions (PHEIs) in Bandung, West Java, Indonesia was conducted for the research. A total of five hundred and thirty completed questionnaires from 478 academic and 52 non academic staff were statistically analyzed using SPSS and smart PLS. Investigating sustainable competitive advantage related issues for PHIEs in Indonesia is important for a number of reasons, including supporting the vision of the Golden Indonesia generation 2045. Moreover, the impact of absorptive capacity on sustainable competitive advantage in the literature is remains unclear, thus a new theoretical framework is needed related to the concept of ambidexterity. The finding of this research shows that innovation ambidexterity partially mediates the effect of absorptive capacity on sustainable competitive advantage as proposed in the hypothesis. The implications of this study are discussed. \u00a9 2020 by author(s) and VsI Entrepreneurship and Sustainability Center.",
            "Sustainable Development Goals mapped to this documentResponsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to empirically examine the mediation role of innovation ambidexterity on the impact of absorptive capacity on sustainable competitive advantage from the previous researchers' data article publication. A survey of academic and nonacademic staff from sixty four private higher education institutions (PHEIs) in Bandung, West Java, Indonesia was conducted for the research. A total of five hundred and thirty completed questionnaires from 478 academic and 52 non academic staff were statistically analyzed using SPSS and smart PLS. Investigating sustainable competitive advantage related issues for PHIEs in Indonesia is important for a number of reasons, including supporting the vision of the Golden Indonesia generation 2045. Moreover, the impact of absorptive capacity on sustainable competitive advantage in the literature is remains unclear, thus a new theoretical framework is needed related to the concept of ambidexterity. The finding of this research shows that innovation ambidexterity partially mediates the effect of absorptive capacity on sustainable competitive advantage as proposed in the hypothesis. The implications of this study are discussed. \u00a9 2020 by author(s) and VsI Entrepreneurship and Sustainability Center."
        ]
    },
    {
        "judul":[
            "Hybrid Configuration in Information Technology Value Model"
        ],
        "penulis":"Abdurrahman, Lukman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Thus far, the IT value study model is typically in a serial configuration correlating its subsystems. This article attempts to propose a hybrid configuration merging serial and parallel configurations to be a proposed IT value model. A methodology is the meta-analysis approach to determine the subsystem model and to rationalize the relationships among subsystems. To complete the analysis, the research also puts on the partial adjustment valuation functioning as a valuation method to calculate the numerical magnitude of the operating revenue of each subsystem. The resulted model undergoes a case study using Telkom's data, which is the Indonesian information and communication technology industry provider. It indicates that the variance of the hybrid configuration is extraordinarily insignificant and tolerable, in which the portion of the average deviation to the Telkom's average revenue is only-0.08% during the period 2005-2015. Thus, the hybrid configuration can nearly be acceptable in the IT value study due to its validity theoretically and empirically.  \u00a9 2007-2012 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Thus far, the IT value study model is typically in a serial configuration correlating its subsystems. This article attempts to propose a hybrid configuration merging serial and parallel configurations to be a proposed IT value model. A methodology is the meta-analysis approach to determine the subsystem model and to rationalize the relationships among subsystems. To complete the analysis, the research also puts on the partial adjustment valuation functioning as a valuation method to calculate the numerical magnitude of the operating revenue of each subsystem. The resulted model undergoes a case study using Telkom's data, which is the Indonesian information and communication technology industry provider. It indicates that the variance of the hybrid configuration is extraordinarily insignificant and tolerable, in which the portion of the average deviation to the Telkom's average revenue is only-0.08% during the period 2005-2015. Thus, the hybrid configuration can nearly be acceptable in the IT value study due to its validity theoretically and empirically.  \u00a9 2007-2012 IEEE."
        ]
    },
    {
        "judul":[
            "Comparative Analysis of Load Balancing Dynamic Ratio and Server Ratio Algorithms"
        ],
        "penulis":"Murti, Krisna Wahyu;Riza, Tengku Ahmad;Mulyana, Asep;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Load balancing is a technique for dividing traffic loads and reading the availability of resources on the server. Dividing the traffic load use server hardware such as CPU, memory, and disk. This research designed load balancing using dynamic ratio and ratio algorithms on three types of services namely web server, FTP server, and VoIP server, FTP server, and VoIP server. The highest throughput average value is found in the 3:2 of dynamic ratio algorithm, i.e. 114.18 KB\/s of web server and 118.9 KB\/s of FTP server. The fastest response time average value is the 3:2 ratio algorithm for 8.7 seconds of web server and 32.3 seconds of FTP server. The average results for the least number of request losses are the 1: 1 of ratio algorithm, i.e. web server for 17 request failures, FTP server for 1 file transfer failure, and VoIP server for 0.18% call failure. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Load balancing is a technique for dividing traffic loads and reading the availability of resources on the server. Dividing the traffic load use server hardware such as CPU, memory, and disk. This research designed load balancing using dynamic ratio and ratio algorithms on three types of services namely web server, FTP server, and VoIP server, FTP server, and VoIP server. The highest throughput average value is found in the 3:2 of dynamic ratio algorithm, i.e. 114.18 KB\/s of web server and 118.9 KB\/s of FTP server. The fastest response time average value is the 3:2 ratio algorithm for 8.7 seconds of web server and 32.3 seconds of FTP server. The average results for the least number of request losses are the 1: 1 of ratio algorithm, i.e. web server for 17 request failures, FTP server for 1 file transfer failure, and VoIP server for 0.18% call failure. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "An artificial neural network approach to predict energy consumption and surface roughness of a natural material"
        ],
        "penulis":"Arafat, Mohammad;Sjafrizal, Teddy;Anugraha, Rino Andias;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Constructing a prediction model of machining performance is useful to improve its process efficiency. Artificial neural network (ANN) has been widely used in prediction works, capable of solving complex problems with numerous parameters. The present study aims to describe the application of the ANN technique in predicting the machining performance of a natural material. Bovine horns were the selected natural materials. Bovine horns are sustainable, recyclable, and abundant source for industrial applications. The outputs of the predictive model were surface roughness and energy consumption, whereas the input data were spindle speed, depth of cut and feed rate of a face milling. It was found that the ANN-based prediction model of bovine horns produced a high accuracy prediction (95.4%). The outcome of this study may be referred by similar studies on other natural materials, supporting the global efforts in improving the industrialization of natural materials. \u00a9 2020, Springer Nature Switzerland AG.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Constructing a prediction model of machining performance is useful to improve its process efficiency. Artificial neural network (ANN) has been widely used in prediction works, capable of solving complex problems with numerous parameters. The present study aims to describe the application of the ANN technique in predicting the machining performance of a natural material. Bovine horns were the selected natural materials. Bovine horns are sustainable, recyclable, and abundant source for industrial applications. The outputs of the predictive model were surface roughness and energy consumption, whereas the input data were spindle speed, depth of cut and feed rate of a face milling. It was found that the ANN-based prediction model of bovine horns produced a high accuracy prediction (95.4%). The outcome of this study may be referred by similar studies on other natural materials, supporting the global efforts in improving the industrialization of natural materials. \u00a9 2020, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Enhancing student learning achievement using competency-based modules on basic competencies examining the characteristics of refrigerants and lubricating oils"
        ],
        "penulis":"Suherman A.;Wiyono A.;Yayat Y.;Negara R.M.H.K.;Berman E.T.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study was to determine the increase in student achievement using competency-based modules. The study was conducted on the subject of system and the installation of refrigeration with basic competencies examining the characteristics of refrigerants and lubricating oils. This study uses quasi-experimental research methods. Participants in this study were 60 students from the vocational high school in Bandung. The research instrument used was a test, which consisted of pre-test and post-test. Improved student achievement was analyzed using the concept of normalized gain (N-gain) based on pre test and post test score data. The results showed the use of competency-based modules can improve student learning achievement. The achievement of the post test scores of the experimental class students above the minimum completion criteria with an average post test score of 89.39, while the score of the control class was 72.42. Based on the N-Gain value there are differences between the experimental class and the control class which are 79.5 and 46.94, respectively. The use of competency-based modules has implications for improving student achievement to be more optimal. The content of interesting module materials can increase student motivation and activity in learning in the classroom. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study was to determine the increase in student achievement using competency-based modules. The study was conducted on the subject of system and the installation of refrigeration with basic competencies examining the characteristics of refrigerants and lubricating oils. This study uses quasi-experimental research methods. Participants in this study were 60 students from the vocational high school in Bandung. The research instrument used was a test, which consisted of pre-test and post-test. Improved student achievement was analyzed using the concept of normalized gain (N-gain) based on pre test and post test score data. The results showed the use of competency-based modules can improve student learning achievement. The achievement of the post test scores of the experimental class students above the minimum completion criteria with an average post test score of 89.39, while the score of the control class was 72.42. Based on the N-Gain value there are differences between the experimental class and the control class which are 79.5 and 46.94, respectively. The use of competency-based modules has implications for improving student achievement to be more optimal. The content of interesting module materials can increase student motivation and activity in learning in the classroom. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Language Modeling for Journalistic Robot based on Generative Pretrained Transformer 2"
        ],
        "penulis":"Suraperwata, Raihan Hamid;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The language model is typically represented as an unsupervised distribution estimate from a set of examples, each consisting of symbol sequences, and it could predict over sequences of words. We demonstrate the language model based on Generative Pretrained 2 will have a readable generated article for the journalistic robot. Nowadays, there is some trending of journalistic in Indonesia, freedom of the press, and it enables every journalist to make unprofessional news on the media. The problem affects the raise of journalist numbers who have lack journalistic knowledge and increases the amount of inappropriate news content in Indonesia. Therefore, to improve the quality of news produced by the mass media in Indonesia, a journalistic robot is needed to produce news content by the guidelines and the journalistic code of ethics. This research uses language modeling based on GPT-2 to generate articles. The program has four primary steps: building dataset, fine tuning GPT-2, modeling the trained data, and create articles. Furthermore, this research will add an Indonesian model for GPT-2 since the main purpose of this research is Indonesian articles. This paper proposes GPT-2 to be applied to news contents and calculate the result with BLEU scores to check if the results are readable content. These findings show that the proposed model is capable of generating a readable article after trained by 110 Indonesian articles with an excellent score of BLEU.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The language model is typically represented as an unsupervised distribution estimate from a set of examples, each consisting of symbol sequences, and it could predict over sequences of words. We demonstrate the language model based on Generative Pretrained 2 will have a readable generated article for the journalistic robot. Nowadays, there is some trending of journalistic in Indonesia, freedom of the press, and it enables every journalist to make unprofessional news on the media. The problem affects the raise of journalist numbers who have lack journalistic knowledge and increases the amount of inappropriate news content in Indonesia. Therefore, to improve the quality of news produced by the mass media in Indonesia, a journalistic robot is needed to produce news content by the guidelines and the journalistic code of ethics. This research uses language modeling based on GPT-2 to generate articles. The program has four primary steps: building dataset, fine tuning GPT-2, modeling the trained data, and create articles. Furthermore, this research will add an Indonesian model for GPT-2 since the main purpose of this research is Indonesian articles. This paper proposes GPT-2 to be applied to news contents and calculate the result with BLEU scores to check if the results are readable content. These findings show that the proposed model is capable of generating a readable article after trained by 110 Indonesian articles with an excellent score of BLEU.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Identification of the changing air temperature and rainfall in Bogor"
        ],
        "penulis":"Hidayat, Rahmat;Farihah, Alfi Wardah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Climate datasets were analyzed to identify the changing climatic parameters and extreme events in Bogor, West Java. This study aims to analyze the characteristic of observational datasets in Baranangsiang and Dramaga, namely, air temperature and rainfall, and to identify the changing structure of those climate parameters. The analysis has been conducted using RClimdex to understand the long-term changing air temperature and rainfall based on 10 indices for air temperature and 8 indices for temperature and rainfall. Results show that the rainfall in Baranangsiang has a daily mean of 10 mm\/day and in Dramaga of 8 mm\/day. The daily mean air temperature in Baranangsiang and Dramaga is 27\u02daC and 25.5\u02daC, respectively. Generally, the declined slopes of the temperature indices in Barangsiang, namely, TN90p, TNx, TX10p, TNn, TXn, TR20, and SU25, indicate cooler temperature. In Dramaga, the increased temperature indices, namely, TN90p, TX90p, TXx, SU25, and TXn, indicate the warmer temperature. The rainfall indices generally decline, except for consecutive dry days (CDD), which indicate the increased consecutive dry days in Baranangsiang. \u00a9 2020, Pusat Penelitian Lingkungan Hidup - Lembaga Penelitian dan Pengabdian Kepada Masyarakat Institut Pertanian Bogor (PPLH-LPPM IPB). All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Climate datasets were analyzed to identify the changing climatic parameters and extreme events in Bogor, West Java. This study aims to analyze the characteristic of observational datasets in Baranangsiang and Dramaga, namely, air temperature and rainfall, and to identify the changing structure of those climate parameters. The analysis has been conducted using RClimdex to understand the long-term changing air temperature and rainfall based on 10 indices for air temperature and 8 indices for temperature and rainfall. Results show that the rainfall in Baranangsiang has a daily mean of 10 mm\/day and in Dramaga of 8 mm\/day. The daily mean air temperature in Baranangsiang and Dramaga is 27\u02daC and 25.5\u02daC, respectively. Generally, the declined slopes of the temperature indices in Barangsiang, namely, TN90p, TNx, TX10p, TNn, TXn, TR20, and SU25, indicate cooler temperature. In Dramaga, the increased temperature indices, namely, TN90p, TX90p, TXx, SU25, and TXn, indicate the warmer temperature. The rainfall indices generally decline, except for consecutive dry days (CDD), which indicate the increased consecutive dry days in Baranangsiang. \u00a9 2020, Pusat Penelitian Lingkungan Hidup - Lembaga Penelitian dan Pengabdian Kepada Masyarakat Institut Pertanian Bogor (PPLH-LPPM IPB). All rights reserved."
        ]
    },
    {
        "judul":[
            "E-learning content design using ADDIE and SECI: Case of shelving activity in research organization"
        ],
        "penulis":"Kusumastuti, Dyah;Soesanto, Rayinda Pramuditya;Kurniawati, Amelia;Kurniawan, Mochamad Teguh;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Knowledge sharing considered an important role in an organization, especially in an organization that focused on research activity such as research organization. Research Organization is an organization that focused on providing scientific information in various forms of collection. The collection often used as a reference for many researchers. The collection saved in the organization library service section and displayed by the types and classified to ease the finding process. In the shelving process, some employees take a different way to do the process besides the shelving procedure and gain new knowledge through experience from it in the form of knowledge. The problem occurred when the turnover of the employee is high because of the job role rotation. It is needed a way to preserve the experience from the previous employee of the shelving process, so when rotation occurred, the learning time of new employees can be reduced. E-learning is one of the solutions that can help the learning process. ADDIE is used as the model for the content of e-learning. The purpose of this research is to design the e-learning content for the shelving process by converting previous tacit knowledge using the SECI method. The output of this paper is the best practice for shelving activity that is used as the content of e-Learning. This research contribution can give a reference on how to convert tacit knowledge into e-learning. Future research can be done to develop the present application by evaluating the weakness and enhancing the feature for improvement. \u00a9 2020, Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Knowledge sharing considered an important role in an organization, especially in an organization that focused on research activity such as research organization. Research Organization is an organization that focused on providing scientific information in various forms of collection. The collection often used as a reference for many researchers. The collection saved in the organization library service section and displayed by the types and classified to ease the finding process. In the shelving process, some employees take a different way to do the process besides the shelving procedure and gain new knowledge through experience from it in the form of knowledge. The problem occurred when the turnover of the employee is high because of the job role rotation. It is needed a way to preserve the experience from the previous employee of the shelving process, so when rotation occurred, the learning time of new employees can be reduced. E-learning is one of the solutions that can help the learning process. ADDIE is used as the model for the content of e-learning. The purpose of this research is to design the e-learning content for the shelving process by converting previous tacit knowledge using the SECI method. The output of this paper is the best practice for shelving activity that is used as the content of e-Learning. This research contribution can give a reference on how to convert tacit knowledge into e-learning. Future research can be done to develop the present application by evaluating the weakness and enhancing the feature for improvement. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[
            "Vectorizer Comparison for Sentiment Analysis on Social Media Youtube: A Case Study"
        ],
        "penulis":"Irawaty, Irene;Andreswari, Rachmadita;Pramesti, Dita;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Youtube is a popular social media used by several companies to market their products, both in the form of advertisements and videos. Nokia is one company that uses Youtube as social media to advertise and market its products until now. Nokia was a cellphone company that had fallen in 2013 due to the company's unwillingness to follow the operating system trend at the time. Nokia continues to rise and launch new products that are increasingly sophisticated. In seeing and summarizing public opinion towards the revival of the Nokia company, this research will classify the sentiment given by the public towards latest Nokia products through comments on the videos of Nokia products on Youtube. This research using Support Vector Machine (SVM) and K-Nearest Neighbor (K-NN) algorithm to classify, with comparing performance of three vectorizers, namely CountVectorizer, TFIDFVectorizer and HashingVectorizer. Compared to other algorithms and vectorizers, SVM with TFIDFVectorizer has the highest accuracy with score of 97.5%. The best vectorizer in this research is TFIDFVectorizer because there are almost no errors in predicting negative values, and also has many positive predictive values compared to other vectorizers. So, the best way to do classification is using SVM algorithm with TFIDFVectorizer.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Youtube is a popular social media used by several companies to market their products, both in the form of advertisements and videos. Nokia is one company that uses Youtube as social media to advertise and market its products until now. Nokia was a cellphone company that had fallen in 2013 due to the company's unwillingness to follow the operating system trend at the time. Nokia continues to rise and launch new products that are increasingly sophisticated. In seeing and summarizing public opinion towards the revival of the Nokia company, this research will classify the sentiment given by the public towards latest Nokia products through comments on the videos of Nokia products on Youtube. This research using Support Vector Machine (SVM) and K-Nearest Neighbor (K-NN) algorithm to classify, with comparing performance of three vectorizers, namely CountVectorizer, TFIDFVectorizer and HashingVectorizer. Compared to other algorithms and vectorizers, SVM with TFIDFVectorizer has the highest accuracy with score of 97.5%. The best vectorizer in this research is TFIDFVectorizer because there are almost no errors in predicting negative values, and also has many positive predictive values compared to other vectorizers. So, the best way to do classification is using SVM algorithm with TFIDFVectorizer.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Optimization of distance formula in k-nearest neighbor method"
        ],
        "penulis":"Lubis, Arif Ridho;Lubis, Muharman;Al-Khowarizmi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "K-Nearest Neighbor (KNN) is a method applied in classifying objects based on learning data that is closest to the object based on comparison between previous and current data. In the learning process, KNN calculates the distance of the nearest neighbor by applying the euclidean distance formula, while in other methods, optimization has been done on the distance formula by comparing it with the other similar in order to get optimal results. This study will discuss the calculation of the euclidean distance formula in KNN compared with the normalized euclidean distance, manhattan and normalized manhattan to achieve optimization results or optimal value in finding the distance of the nearest neighbor. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "K-Nearest Neighbor (KNN) is a method applied in classifying objects based on learning data that is closest to the object based on comparison between previous and current data. In the learning process, KNN calculates the distance of the nearest neighbor by applying the euclidean distance formula, while in other methods, optimization has been done on the distance formula by comparing it with the other similar in order to get optimal results. This study will discuss the calculation of the euclidean distance formula in KNN compared with the normalized euclidean distance, manhattan and normalized manhattan to achieve optimization results or optimal value in finding the distance of the nearest neighbor. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Influence of sputtering temperature of TiO2deposited onto reduced graphene oxide nanosheet as efficient photoanodes in dye-sensitized solar cells"
        ],
        "penulis":"Low, Foo Wah;Hock, Goh Chin;Kashif, Muhammad;Samsudin, Nurul Asma;Chau, Chien Fat;Utami, Amaliyah Rohsari Indah;Islam, Mohammad Aminul;Heah, Cheng Yong;Liew, Yun Ming;Lai, Chin Wei;Amin, Nowshad;Tiong, Sieh Kiong;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Renewable solar energy is the key target to reduce fossil fuel consumption, minimize global warming issues, and indirectly minimizes erratic weather patterns. Herein, the authors synthesized an ultrathin reduced graphene oxide (rGO) nanosheet with ~47 nm via an improved Hummer\u2019s method. The TiO2was deposited by RF sputtering onto an rGO nanosheet with a variation of temperature to enhance the photogenerated electron or charge carrier mobility transport for the photoanode component. The morphology, topologies, element composition, crystallinity as well as dye-sensitized solar cells\u2019 (DSSCs) performance were determined accordingly. Based on the results, FTIR spectra revealed presence of Ti-O-C bonds in every rGO-TiO2nanocomposite samples at 800 cm\u20131. Besides, XRD revealed that a broad peak of anatase TiO2was detected at ~25.4\u25e6after incorporation with the rGO. Furthermore, it was discovered that sputtering temperature of 120\u25e6C created a desired power conversion energy (PCE) of 7.27% based on the J-V plot. Further increase of the sputtering temperature to 160\u25e6C and 200\u25e6C led to excessive TiO2growth on the rGO nanosheet, thus resulting in undesirable charge recombination formed at the photoanode in the DSSC device. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Renewable solar energy is the key target to reduce fossil fuel consumption, minimize global warming issues, and indirectly minimizes erratic weather patterns. Herein, the authors synthesized an ultrathin reduced graphene oxide (rGO) nanosheet with ~47 nm via an improved Hummer\u2019s method. The TiO2was deposited by RF sputtering onto an rGO nanosheet with a variation of temperature to enhance the photogenerated electron or charge carrier mobility transport for the photoanode component. The morphology, topologies, element composition, crystallinity as well as dye-sensitized solar cells\u2019 (DSSCs) performance were determined accordingly. Based on the results, FTIR spectra revealed presence of Ti-O-C bonds in every rGO-TiO2nanocomposite samples at 800 cm\u20131. Besides, XRD revealed that a broad peak of anatase TiO2was detected at ~25.4\u25e6after incorporation with the rGO. Furthermore, it was discovered that sputtering temperature of 120\u25e6C created a desired power conversion energy (PCE) of 7.27% based on the J-V plot. Further increase of the sputtering temperature to 160\u25e6C and 200\u25e6C led to excessive TiO2growth on the rGO nanosheet, thus resulting in undesirable charge recombination formed at the photoanode in the DSSC device. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Real time bridge dynamic response: Bridge condition assessment and early warning system"
        ],
        "penulis":"Riyansyah, Muhammad;Wijayanto, Pratama Budi;Trilaksono, Bambang Riyanto;Putra, Seno Adi;Laila, Dina Shona;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The present study investigates the use of wireless sensor networks (WSNs) in the assessment of bridge conditions as well as an early warning system. The WSNs are used to measure the acceleration that occurred on the bridge and the mode shape of the bridge as the excitation loads passing through the bridge. Fast Fourier Transform (FFT) is applied to transform the measured acceleration to get the frequency of the dynamic bridge response. Numerical integration is applied to determine the acceleration to get the displacement of the bridge dynamic response. Implementing the structural dynamics equation, the effective stiffness of the bridge can be determined using the frequency. The effective stiffness and the bridge dynamic response are then used to obtain the bridge condition and load ratings. A scaled model of steel truss bridge and miniature truck with various loads were used to simulate the use of WSNs in bridge assessment, which were also used to validate the finite element model. The finite element model was then used to simulate various scenarios, including the scenarios in which the bridge elements had the various level of damages. The behaviors of bridge with various level of damages can be used to identify the location and the level of damages in the bridge and were found to be useful as early warning system for bridges condition and load ratings. \u00a9 Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The present study investigates the use of wireless sensor networks (WSNs) in the assessment of bridge conditions as well as an early warning system. The WSNs are used to measure the acceleration that occurred on the bridge and the mode shape of the bridge as the excitation loads passing through the bridge. Fast Fourier Transform (FFT) is applied to transform the measured acceleration to get the frequency of the dynamic bridge response. Numerical integration is applied to determine the acceleration to get the displacement of the bridge dynamic response. Implementing the structural dynamics equation, the effective stiffness of the bridge can be determined using the frequency. The effective stiffness and the bridge dynamic response are then used to obtain the bridge condition and load ratings. A scaled model of steel truss bridge and miniature truck with various loads were used to simulate the use of WSNs in bridge assessment, which were also used to validate the finite element model. The finite element model was then used to simulate various scenarios, including the scenarios in which the bridge elements had the various level of damages. The behaviors of bridge with various level of damages can be used to identify the location and the level of damages in the bridge and were found to be useful as early warning system for bridges condition and load ratings. \u00a9 Insight Society."
        ]
    },
    {
        "judul":[
            "The effects of mobile service quality and E-recovery service quality on e-satisfaction in bukalapak application users"
        ],
        "penulis":"Hidayah, Riski Taufik;Tauwli, Muhammad Dzil Fadhli;Saefudin, Nugraha;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study was to find out how much influence the quality of mobile-based services and the recovery of electronic services to the satisfaction of users of the Bukalapak trading application. The research uses descriptive methods and the method of verification with the population are consumers who have shopped with the Bukalapak buy and sell application represented by 200 respondents. The analytical method used is Rank Spearman correlation, coefficient of determination, and t test with a significance level of 5% with the use of IBM Statistics 24 SPSS software. The results showed that mobile service quality contributed to the effect of e-satisfaction by 60.84% and e recovery service quality contributed 43.03% to e-satisfaction. Some aspects that can be of concern are companies need to review and pay attention to speed in responding to complaints from consumers and allowance to users of the Bukalapak application as a sign of apology for the inconvenience of malfunctions of the application. \u00a9 2020, Hampstead Psychological Associates. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study was to find out how much influence the quality of mobile-based services and the recovery of electronic services to the satisfaction of users of the Bukalapak trading application. The research uses descriptive methods and the method of verification with the population are consumers who have shopped with the Bukalapak buy and sell application represented by 200 respondents. The analytical method used is Rank Spearman correlation, coefficient of determination, and t test with a significance level of 5% with the use of IBM Statistics 24 SPSS software. The results showed that mobile service quality contributed to the effect of e-satisfaction by 60.84% and e recovery service quality contributed 43.03% to e-satisfaction. Some aspects that can be of concern are companies need to review and pay attention to speed in responding to complaints from consumers and allowance to users of the Bukalapak application as a sign of apology for the inconvenience of malfunctions of the application. \u00a9 2020, Hampstead Psychological Associates. All rights reserved."
        ]
    },
    {
        "judul":[
            "Optical camera communications: Principles, modulations, potential and challenges"
        ],
        "penulis":"Cahyadi, Willy Anugrah;Chung, Yeon Ho;Ghassemlooy, Zabih;Hassan, Navid Bani;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Optical wireless communications (OWC) are emerging as cost-effective and practical solutions to the congested radio frequency-based wireless technologies. As part of OWC, optical camera communications (OCC) have become very attractive, considering recent developments in cameras and the use of fitted cameras in smart devices. OCC together with visible light communications (VLC) is considered within the framework of the IEEE 802.15.7m standardization. OCCs based on both organic and inorganic light sources as well as cameras are being considered for low-rate transmissions and localization in indoor as well as outdoor short-range applications and within the framework of the IEEE 802.15.7m standardization together with VLC. This paper introduces the underlying principles of OCC and gives a comprehensive overview of this emerging technology with recent standardization activities in OCC. It also outlines the key technical issues such as mobility, coverage, interference, performance enhancement, etc. Future research directions and open issues are also presented. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Optical wireless communications (OWC) are emerging as cost-effective and practical solutions to the congested radio frequency-based wireless technologies. As part of OWC, optical camera communications (OCC) have become very attractive, considering recent developments in cameras and the use of fitted cameras in smart devices. OCC together with visible light communications (VLC) is considered within the framework of the IEEE 802.15.7m standardization. OCCs based on both organic and inorganic light sources as well as cameras are being considered for low-rate transmissions and localization in indoor as well as outdoor short-range applications and within the framework of the IEEE 802.15.7m standardization together with VLC. This paper introduces the underlying principles of OCC and gives a comprehensive overview of this emerging technology with recent standardization activities in OCC. It also outlines the key technical issues such as mobility, coverage, interference, performance enhancement, etc. Future research directions and open issues are also presented. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "Social characters as predictors of sociopreneurs\u2019 motivation"
        ],
        "penulis":"Anggadwita, Grisna;Alamanda, Dini Turipanam;Eshtrefi, Luan;Ramadani, Veland;Permatasari, Anggraeni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Social entrepreneurship is considered as a solution in reducing unemployment and poverty. Social entrepreneurs in this study are called as sociopreneurs. This study aims to identify the social characters as predictors of sociopreneurs\u2019 motivation in Bandung, Indonesia. In addition, this study also explores more deeply how sociopreneurs prioritise social values, and the impact of becoming sociopreneurs. This study attempts to overcome gaps in understanding social entrepreneurship broadly by taking the perspective of social-oriented, using qualitative methods and a case study approach. Empirical data is collected by conducting in-depth semi-structured interviews with sociopreneurs in Bandung as respondents in this study. This study identifies several social entrepreneurship values which include social values, civil society, innovation, economic activities, and social impacts (outcomes). In addition, personal values influence the creation of social enterprises through the values of personal experience, the desire to make changes and the willingness to do something meaningful in one\u2019s life. Copyright \u00a9 2020 Inderscience Enterprises Ltd.",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Social entrepreneurship is considered as a solution in reducing unemployment and poverty. Social entrepreneurs in this study are called as sociopreneurs. This study aims to identify the social characters as predictors of sociopreneurs\u2019 motivation in Bandung, Indonesia. In addition, this study also explores more deeply how sociopreneurs prioritise social values, and the impact of becoming sociopreneurs. This study attempts to overcome gaps in understanding social entrepreneurship broadly by taking the perspective of social-oriented, using qualitative methods and a case study approach. Empirical data is collected by conducting in-depth semi-structured interviews with sociopreneurs in Bandung as respondents in this study. This study identifies several social entrepreneurship values which include social values, civil society, innovation, economic activities, and social impacts (outcomes). In addition, personal values influence the creation of social enterprises through the values of personal experience, the desire to make changes and the willingness to do something meaningful in one\u2019s life. Copyright \u00a9 2020 Inderscience Enterprises Ltd."
        ]
    },
    {
        "judul":[
            "Implementation of Service Platform for Smart City As A Service"
        ],
        "penulis":"Prasetyo, Yuli Adam;Albarda;Suhardi;Arman, Arry Ahmad;Yustianto, Purnomo;Hartanti, Fera Tri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "An ecosystem of digital services requires a service platform to facilitate a dynamic service introduction. As a system of systems and a service-oriented system, Smart City has key characteristics of a service ecosystem. However, a service platform has unique characteristics to become a service platform for the implementation of Smart City. On the other hand, an implementation of a service platform for a Smart City must depart from a proven service platform concept conforming to the characteristics of a Smart City Architecture. This paper elaborates an initial process of a service platform implementation with Smart City characteristics. This initial study takes its form as a descriptive study from a systematic literature review employing a Design Research Methodology (DRM) approach. This paper provides an overview of an application of service platforms concept in the digital service ecosystem and service computing systems to fulfill the need of a Smart City Architecture characteristics.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An ecosystem of digital services requires a service platform to facilitate a dynamic service introduction. As a system of systems and a service-oriented system, Smart City has key characteristics of a service ecosystem. However, a service platform has unique characteristics to become a service platform for the implementation of Smart City. On the other hand, an implementation of a service platform for a Smart City must depart from a proven service platform concept conforming to the characteristics of a Smart City Architecture. This paper elaborates an initial process of a service platform implementation with Smart City characteristics. This initial study takes its form as a descriptive study from a systematic literature review employing a Design Research Methodology (DRM) approach. This paper provides an overview of an application of service platforms concept in the digital service ecosystem and service computing systems to fulfill the need of a Smart City Architecture characteristics.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of public complaint reports during the COVID-19 pandemic: A case study of Jakarta's citizen relations management"
        ],
        "penulis":"Finola, Clarissa Febria;Nugraha, Yudhistira;Suprijono, Samuel Aditya;Larrantuka, Adzan;Kanggrawan, Juan Intan;Suherman, Alex L.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "COVID-19, as a newly discovered disease, has suddenly become a major challenging problem for many cities in the world, including Jakarta. This crisis affects all segments in day to day life. Jakarta citizens can report any problems related to COVID-19 through Citizen Relations Management, later known as CRM. This CRM system consists of 14 official complaint platforms that can be used by the citizens to report their complaints to the government and its working units. As a bridge between people and the government, this system is a form of problem-solving innovation. In this study, Exploratory Data Analysis (EDA) was carried out to analyze the pattern of complaint reports concerning COVID-19. The dataset used is CRM report data and daily COVID-19 positive case data. Through the analysis, a linkage is found between the cumulative number of reports related to COVID-19 and the cumulative number of COVID-19 positive cases. During the crisis period like the unfolding COVID-19 pandemic, transparency of information and citizen feedback can make invaluable contributions to an effective national response. This study is expected to encourage CRM to deal with the impact of COVID-19 effectively through the official platforms managed by Jakarta Smart City. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Peace, justice and strong institutionsGoal 16",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "COVID-19, as a newly discovered disease, has suddenly become a major challenging problem for many cities in the world, including Jakarta. This crisis affects all segments in day to day life. Jakarta citizens can report any problems related to COVID-19 through Citizen Relations Management, later known as CRM. This CRM system consists of 14 official complaint platforms that can be used by the citizens to report their complaints to the government and its working units. As a bridge between people and the government, this system is a form of problem-solving innovation. In this study, Exploratory Data Analysis (EDA) was carried out to analyze the pattern of complaint reports concerning COVID-19. The dataset used is CRM report data and daily COVID-19 positive case data. Through the analysis, a linkage is found between the cumulative number of reports related to COVID-19 and the cumulative number of COVID-19 positive cases. During the crisis period like the unfolding COVID-19 pandemic, transparency of information and citizen feedback can make invaluable contributions to an effective national response. This study is expected to encourage CRM to deal with the impact of COVID-19 effectively through the official platforms managed by Jakarta Smart City. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "High Throughput Satellite using Ka-Band for Government Multifunctional Services in Indonesia: Study of Link Budget and Capacity Analysis"
        ],
        "penulis":"Kristiadi, Ignatius Daru;Nashiruddin, Muhammad Imam;Sudjai, Miftadi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Satellite infrastructure has a vital role in delivering communication services throughout Indonesia as one of the biggest archipelagic countries in the world. The high throughput satellite (HTS) can be the best choice considering the uneven distribution of terrestrial infrastructure networks, especially in the corners and isolated areas of Indonesia. In this paper, a study is conducted related to link budget and capacity analysis on the high throughput satellite using the proposed Ka-band frequency plan. The purpose of this study is to find out how far the link capability and capacity can be provided by HTS if it is operating in the proposed Ka-band frequency plan associated with Indonesia's environmental conditions. The result of this study on link budget analysis shows that using its Ka-Band frequency plan as the proposed assigned frequency is suitable and feasible to be implemented in the near future of the HTS system for government multifunctional services over Indonesia. It is indicated by the positive value of C\/N obtained from link budget analysis for each link of each scenario in this research. Besides that, the estimation for capacity analysis of communication that is able to be provided by its HTS is enormous enough to handle the data services needs over Indonesia, which is 38.41-93.54 Gbps depends on environment condition. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Satellite infrastructure has a vital role in delivering communication services throughout Indonesia as one of the biggest archipelagic countries in the world. The high throughput satellite (HTS) can be the best choice considering the uneven distribution of terrestrial infrastructure networks, especially in the corners and isolated areas of Indonesia. In this paper, a study is conducted related to link budget and capacity analysis on the high throughput satellite using the proposed Ka-band frequency plan. The purpose of this study is to find out how far the link capability and capacity can be provided by HTS if it is operating in the proposed Ka-band frequency plan associated with Indonesia's environmental conditions. The result of this study on link budget analysis shows that using its Ka-Band frequency plan as the proposed assigned frequency is suitable and feasible to be implemented in the near future of the HTS system for government multifunctional services over Indonesia. It is indicated by the positive value of C\/N obtained from link budget analysis for each link of each scenario in this research. Besides that, the estimation for capacity analysis of communication that is able to be provided by its HTS is enormous enough to handle the data services needs over Indonesia, which is 38.41-93.54 Gbps depends on environment condition. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Managing digital marketing communication of coffee shop using instagram"
        ],
        "penulis":"Soedarsono, Dewi K.;Mohamad, Bahtiar;Adamu, Adamu Abbas;Pradita, Kennia Aline;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper focuses on managing the digital marketing communication of coffee shop using the Instagram. The Instagram application offer a great advantage such as quick and cheap marketing communication tools, particularly in promoting the product, disseminating advertisement and brand awareness. Previous study highlighted that managing marketing communication via Instagram is a strategic tool to inform, persuade and remind consumers about what they offer. However, there is limited number of empirical studies on Instagram as a marketing communication tools on how efficiencies of Instagram application in managing digital marketing communication strategies to the customers. Therefore, this paper will enlighten the issues related to the application of Instagram as a marketing tool in the coffee shop business. The content analysis and semi-structured interview has been employed to gain in-depth knowledge from the owner, marketing staffs and marketing consultant who have experiences in managing the digital marketing communication strategy. The findings of the study revealed that Instagram application has become an effective marketing communication tools to disseminate the promotional message to the customers in quick way dan cost efficient as compare to the traditional media. \u00a9 2020 International Association of Online Engineering.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper focuses on managing the digital marketing communication of coffee shop using the Instagram. The Instagram application offer a great advantage such as quick and cheap marketing communication tools, particularly in promoting the product, disseminating advertisement and brand awareness. Previous study highlighted that managing marketing communication via Instagram is a strategic tool to inform, persuade and remind consumers about what they offer. However, there is limited number of empirical studies on Instagram as a marketing communication tools on how efficiencies of Instagram application in managing digital marketing communication strategies to the customers. Therefore, this paper will enlighten the issues related to the application of Instagram as a marketing tool in the coffee shop business. The content analysis and semi-structured interview has been employed to gain in-depth knowledge from the owner, marketing staffs and marketing consultant who have experiences in managing the digital marketing communication strategy. The findings of the study revealed that Instagram application has become an effective marketing communication tools to disseminate the promotional message to the customers in quick way dan cost efficient as compare to the traditional media. \u00a9 2020 International Association of Online Engineering."
        ]
    },
    {
        "judul":[
            "Motion control system of numerical control machine tool under image processing"
        ],
        "penulis":"Zeng, Qi;Luu, Viet Hung;Saedudin, Rd Rohmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper is to study the overall structure of the motion control system of the numerical control machine tool to improve motion control precision. It performs digital image processing on the obtained workpiece image, extracts the coordinate of the tool setting point, and calculates the distance of the tool setting. Comparison of algorithms in image processing accomplished and improved to increase the positioning accuracy and stability of the tool setting system. The results show that to improve the effect of workpiece edge detection, recommended by this study based on the Canny operator, and the morphological processing of the fusion image to detect the edge of the workpiece. In the algorithm of tool setting point coordinate extraction, an improved Hough transform algorithm is used to extract the coordinates of the center of a rectangular workpiece and a circular workpiece respectively, which reduces the complexity of the algorithm. In the algorithm of calculating the distance from the tool tip to the tool setting point, the optimization principle of the distance from the point to the straight line is used to determine the tool tip. Then, the descending distance of the tool is determined in the tool setting, completing the extraction of the three-dimensional machine coordinate of the tool setting point. Based on the camera calibration, the image is processed using a visual positioning software algorithm to extract the machine coordinates of the tool setting point of the workpiece and the tool\u2019s descending distance. The motion information instruction is sent to the motion controller via the host computer. The motion controller controls the movement of the actuator, adjusts the movement distance of the three axes of the machine tool, to complete an automatic tool setting of the workpiece of the numerical control machine tool. It improves the intelligence and automation of the numerical control machine tool setting technology. \u00a9 2020, Cefin Publishing House. All rights reserved."
        ],
        "abstrak":[
            "This paper is to study the overall structure of the motion control system of the numerical control machine tool to improve motion control precision. It performs digital image processing on the obtained workpiece image, extracts the coordinate of the tool setting point, and calculates the distance of the tool setting. Comparison of algorithms in image processing accomplished and improved to increase the positioning accuracy and stability of the tool setting system. The results show that to improve the effect of workpiece edge detection, recommended by this study based on the Canny operator, and the morphological processing of the fusion image to detect the edge of the workpiece. In the algorithm of tool setting point coordinate extraction, an improved Hough transform algorithm is used to extract the coordinates of the center of a rectangular workpiece and a circular workpiece respectively, which reduces the complexity of the algorithm. In the algorithm of calculating the distance from the tool tip to the tool setting point, the optimization principle of the distance from the point to the straight line is used to determine the tool tip. Then, the descending distance of the tool is determined in the tool setting, completing the extraction of the three-dimensional machine coordinate of the tool setting point. Based on the camera calibration, the image is processed using a visual positioning software algorithm to extract the machine coordinates of the tool setting point of the workpiece and the tool\u2019s descending distance. The motion information instruction is sent to the motion controller via the host computer. The motion controller controls the movement of the actuator, adjusts the movement distance of the three axes of the machine tool, to complete an automatic tool setting of the workpiece of the numerical control machine tool. It improves the intelligence and automation of the numerical control machine tool setting technology. \u00a9 2020, Cefin Publishing House. All rights reserved."
        ]
    },
    {
        "judul":[
            "Applied Internet of Things (IoT): The Prototype Bus Passenger Monitoring System Using PIR Sensor"
        ],
        "penulis":"Rahmatulloh, Alam;Nursuwars, Firmansyah M S;Darmawan, Irfan;Febrizki, Galih;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Monitoring passenger data in bus transportation fleets using the IoT concept. Factors that influence passenger monitoring are human counting errors and the accuracy of objects detected by sensors. The IoT system uses PIR (passive infrared) sensors and monitoring with mobile apps is a solution to overcome this, because the use of PIR sensors in the IoT system can only detect movements made by humans alone. The developed IoT system also implements a GPS module to be able to find out the location of the bus. Wemos D1 R2 will automatically send data collected from the results of detection by the PIR sensor and coordinates obtained by the GPS module to the Firebase database via the internet network. The monitoring application will display data stored on firebase on a mobile device. So that monitoring of bus passengers can be done quickly. Experiments on the research show that when the object's motion approaches the PIR sensor, it will not consistently detect the presence of passengers.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Monitoring passenger data in bus transportation fleets using the IoT concept. Factors that influence passenger monitoring are human counting errors and the accuracy of objects detected by sensors. The IoT system uses PIR (passive infrared) sensors and monitoring with mobile apps is a solution to overcome this, because the use of PIR sensors in the IoT system can only detect movements made by humans alone. The developed IoT system also implements a GPS module to be able to find out the location of the bus. Wemos D1 R2 will automatically send data collected from the results of detection by the PIR sensor and coordinates obtained by the GPS module to the Firebase database via the internet network. The monitoring application will display data stored on firebase on a mobile device. So that monitoring of bus passengers can be done quickly. Experiments on the research show that when the object's motion approaches the PIR sensor, it will not consistently detect the presence of passengers.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Home Electrical Energy Management System Using DijCostMin Algorithm"
        ],
        "penulis":"Akbar, Adhiel;Halomoan, Junartho;Silalahi, Desri Kristina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the afternoon until night, an electrical load is increased, it happened because to increase the usage of electrical devices by customers. These conditions in which increased electricity consumption by buyers at the same time with the quantity a large power have not been able to handle properly by PLN as the supplier of electrical energy in Indonesia. The impact is the occurrence of the power outage in rotation, to reduce these all, needs to be setting the use of electric power appropriate, in order to achieve the purpose of balance between demand and supply for electricity energy; especially on the household sectors. One of the tricks is enacting the management of the load on the side of their customers or well known as Demand-Side Management (DSM) and apply dynamic pricing on electricity tariff from the peak time and non-peak time. Home Electrical Energy Management System (HEEMS) is a system for managing electrical energy-based method DSM and apply dynamic pricing. HEEMS allows users to manage and monitor the usage of electricity. HEEMS serves to do scheduling on the use of an electrical device DijCostMin Algorithm based on data planning the use of devices electricity or load forecasting entered by users. The method that proposed is a success and effective to reduce energy demand is about 22.69% when peak time and reduce bills of electricity is about 8.38%. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the afternoon until night, an electrical load is increased, it happened because to increase the usage of electrical devices by customers. These conditions in which increased electricity consumption by buyers at the same time with the quantity a large power have not been able to handle properly by PLN as the supplier of electrical energy in Indonesia. The impact is the occurrence of the power outage in rotation, to reduce these all, needs to be setting the use of electric power appropriate, in order to achieve the purpose of balance between demand and supply for electricity energy; especially on the household sectors. One of the tricks is enacting the management of the load on the side of their customers or well known as Demand-Side Management (DSM) and apply dynamic pricing on electricity tariff from the peak time and non-peak time. Home Electrical Energy Management System (HEEMS) is a system for managing electrical energy-based method DSM and apply dynamic pricing. HEEMS allows users to manage and monitor the usage of electricity. HEEMS serves to do scheduling on the use of an electrical device DijCostMin Algorithm based on data planning the use of devices electricity or load forecasting entered by users. The method that proposed is a success and effective to reduce energy demand is about 22.69% when peak time and reduce bills of electricity is about 8.38%. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Optimal parameters for modified butterfly interpolation scheme inspired configurations as hole-filling method in 3D volume reconstruction"
        ],
        "penulis":"Siang, Chan Vei;Mohamed, Farhan;Idris, Mohd Yazid;Sunar, Mohd Sharizal Bin;Selamat, Ali Bin;Wirasari, Ira;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Three-dimensional volume reconstruction can help physicians to understand the patients' inner anatomy better in a 3D perspective. However, the pixel nearest neighbor method volume reconstruction tended to blur the reconstruction result. This study aims to present the design and configuration of improved modified butterfly interpolation scheme as the hole-filling method in the pixel nearest neighbor. The optimal parameters are also investigated to obtain a high-quality volume reconstruction result using a modified butterfly interpolation scheme. The experiment is designed and conducted on the ultrasound and CT scan data sets, where the artificial holes are created in these ground truth data sets. The proposed method is then used to reconstruct the missing voxels, and its capability is evaluated quantitatively. The results showed that the optimal butterfly interpolation parameter w is equal to 1\/32 and 0 in the 3D reconstruction of ultrasound and CT scan, respectively. Meanwhile, the optimal maximum neighbor interpolation distance n is equal to 2 and 0 in the 3D reconstruction of ultrasound and CT scans, respectively. \u00a9 2020 IEEE",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Three-dimensional volume reconstruction can help physicians to understand the patients' inner anatomy better in a 3D perspective. However, the pixel nearest neighbor method volume reconstruction tended to blur the reconstruction result. This study aims to present the design and configuration of improved modified butterfly interpolation scheme as the hole-filling method in the pixel nearest neighbor. The optimal parameters are also investigated to obtain a high-quality volume reconstruction result using a modified butterfly interpolation scheme. The experiment is designed and conducted on the ultrasound and CT scan data sets, where the artificial holes are created in these ground truth data sets. The proposed method is then used to reconstruct the missing voxels, and its capability is evaluated quantitatively. The results showed that the optimal butterfly interpolation parameter w is equal to 1\/32 and 0 in the 3D reconstruction of ultrasound and CT scan, respectively. Meanwhile, the optimal maximum neighbor interpolation distance n is equal to 2 and 0 in the 3D reconstruction of ultrasound and CT scans, respectively. \u00a9 2020 IEEE"
        ]
    },
    {
        "judul":[
            "Design Mitigation and Monitoring System of Blood Supply Chain Using SCOR (Supply Chain Operational Reference) and HOR (House of Risk)"
        ],
        "penulis":"Raras Dewantari, Maria Francisca;Ridwan, Ari Yanuar;Pambudi, Hardian Kokoh;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Blood supply chain manages the flow of blood product from donors to patients. One of the service provider is PMI which contributes 92% of blood national donation. In fact, demands and supplies of in a blood supply chain are often unpredictable. They contribute to the occurrence of risks which have direct impacts on human life. Thus need a risk management to mitigate such impacts. One way to do so is by using Supply Chain Operational Reference (SCOR) model for mapping the activities of blood chain. Thus, it can facilitate the identification of risk events and risk agents. Further risk events and risk agents are processed using House of Risk (HOR). While the aim of HOR1 is to identify priority of the risk events, the HOR2 arranges necessary mitigation strategies. Moreover, in this work, there are 9 risk agents chosen from HOR1 and 8 preventive actions for the mitigation. Additionally, this research develop a monitoring system that may assist to monitor the occurring risks.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Blood supply chain manages the flow of blood product from donors to patients. One of the service provider is PMI which contributes 92% of blood national donation. In fact, demands and supplies of in a blood supply chain are often unpredictable. They contribute to the occurrence of risks which have direct impacts on human life. Thus need a risk management to mitigate such impacts. One way to do so is by using Supply Chain Operational Reference (SCOR) model for mapping the activities of blood chain. Thus, it can facilitate the identification of risk events and risk agents. Further risk events and risk agents are processed using House of Risk (HOR). While the aim of HOR1 is to identify priority of the risk events, the HOR2 arranges necessary mitigation strategies. Moreover, in this work, there are 9 risk agents chosen from HOR1 and 8 preventive actions for the mitigation. Additionally, this research develop a monitoring system that may assist to monitor the occurring risks.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Developing project schedule in telecommunication projects using critical path method (CPM)"
        ],
        "penulis":"Kusumadarma, Indri Alvi;Pratami, Devi;Yasa, I Putu;Tripiawan, Wawan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Increased public demand for stable internet network services requires companies engaged in telecommunications to always improve their technological capabilities. One way to improve technological capability is to use basic materials or supporting materials, that is fiber optics (FO). PT. XYZ is a company engaged in the field of telecommunications in several years ago. In general, projects in PT. XYZ experience more frequent delays, one of the most influencing factors that they are not applying the method appropriate to the type of project. If the project schedule does not use a method that is appropriate to the type of project being undertaken, then the result is a delay in the implementation of the project. In a project with small or large scopes, processes such as defining activities, sorting activities, estimating duration and making the Schedule Model are so closely tied to each other that they can be viewed as a Single Process that can be done\/done by a person in a relatively short period of time. Therefore, this study focuses on the design of the feeder cabling project schedule in STO Nanjung by using CPM method. The calculation results using the CPM method indicate that the completion time of the Feeder FO cable project is 46 days with 16 critical activities. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Increased public demand for stable internet network services requires companies engaged in telecommunications to always improve their technological capabilities. One way to improve technological capability is to use basic materials or supporting materials, that is fiber optics (FO). PT. XYZ is a company engaged in the field of telecommunications in several years ago. In general, projects in PT. XYZ experience more frequent delays, one of the most influencing factors that they are not applying the method appropriate to the type of project. If the project schedule does not use a method that is appropriate to the type of project being undertaken, then the result is a delay in the implementation of the project. In a project with small or large scopes, processes such as defining activities, sorting activities, estimating duration and making the Schedule Model are so closely tied to each other that they can be viewed as a Single Process that can be done\/done by a person in a relatively short period of time. Therefore, this study focuses on the design of the feeder cabling project schedule in STO Nanjung by using CPM method. The calculation results using the CPM method indicate that the completion time of the Feeder FO cable project is 46 days with 16 critical activities. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher's Office."
        ]
    },
    {
        "judul":[
            "Improving indoor positioning systems accuracy in closed buildings with kalman filter and feedback filter"
        ],
        "penulis":"Andika Satrugna Mahardhika, Muhammad;Gautama Putrada, Aji;Abdurohman, Maman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In recent years, location-based technology has been widely used, one of which is the Indoor Positioning System (IPS). This technology is specifically designed for indoor use. IPS technology can be used for various purposes in various fields, for example to find the location of doctors in hospitals, to help find routes at department stores and exhibitions, or even to find objects in a room. In a closed room, sometimes the signal strength becomes unstable due to several effects called multipath and shadowing. This signal instability can cause a decrease in the position accuracy level. Filtering can be used as a solution. This research compares the performance of several filtering methods in reducing RSSI signal fluctuations so as to improve positioning accuracy. Two different Kalman Filters and the Feedback Filter are used as a comparison. The accuracy performance of each filtering method are compare. In addition the effect of multipath and shadowing are considered. The filtering method delay are also analysed. The results show that a modified Kalman Filter method has the highest accuracy in improving the IPS performance with an MSE value of 1.09. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In recent years, location-based technology has been widely used, one of which is the Indoor Positioning System (IPS). This technology is specifically designed for indoor use. IPS technology can be used for various purposes in various fields, for example to find the location of doctors in hospitals, to help find routes at department stores and exhibitions, or even to find objects in a room. In a closed room, sometimes the signal strength becomes unstable due to several effects called multipath and shadowing. This signal instability can cause a decrease in the position accuracy level. Filtering can be used as a solution. This research compares the performance of several filtering methods in reducing RSSI signal fluctuations so as to improve positioning accuracy. Two different Kalman Filters and the Feedback Filter are used as a comparison. The accuracy performance of each filtering method are compare. In addition the effect of multipath and shadowing are considered. The filtering method delay are also analysed. The results show that a modified Kalman Filter method has the highest accuracy in improving the IPS performance with an MSE value of 1.09. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Distributed gateway-based load balancing in software defined network"
        ],
        "penulis":"Tussyadiah, Halimah;Negara, Ridha Muldina;Sanjoyo, Danu Dwi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "To achieve an internet with high availability and reliability, needs two or more data paths so the process for sending data can be faster. Load balancing is often plays a significant role for this technique to properly utilized every gateway in the network. This research, implemented load balancing in software defined network architecture using floodlight controller. Evaluation is done by measuring QoS (delay, bit rate, packet rate, packet success rate) while sending various traffics through the network such as UDP flow, VoIP, and DNS. Performance of load balancer is work well, because the results after load balancing is better than before. Which is the value of delay after load balancing is decreased about 30-55% compared to before load balancing, also the values of bit rate, packet rate dan packet success rate after load balancing is increased about 10-30% compared to before load balancing. \u00a9 2020, Universitas Ahmad Dahlan.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "To achieve an internet with high availability and reliability, needs two or more data paths so the process for sending data can be faster. Load balancing is often plays a significant role for this technique to properly utilized every gateway in the network. This research, implemented load balancing in software defined network architecture using floodlight controller. Evaluation is done by measuring QoS (delay, bit rate, packet rate, packet success rate) while sending various traffics through the network such as UDP flow, VoIP, and DNS. Performance of load balancer is work well, because the results after load balancing is better than before. Which is the value of delay after load balancing is decreased about 30-55% compared to before load balancing, also the values of bit rate, packet rate dan packet success rate after load balancing is increased about 10-30% compared to before load balancing. \u00a9 2020, Universitas Ahmad Dahlan."
        ]
    },
    {
        "judul":[
            "Music Source Separation Using Generative Adversarial Network and U-Net"
        ],
        "penulis":"Satya, Muhammad Ferianda;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The separation of sound sources in the decomposition of music has become an interesting problem among scientists for the last 50 years. It has the main target of making it difficult for components in the music, such as vocals, bass, drums, and others. The results of sound separation have also been applied on many fields, such as remixing, repanning, and upmixing. In this paper, a new model based on a Generative Adversarial Network (GAN) is proposed to separate the music sources to rebuild the sound sources that exist in the music. The GAN architecture is built using U-net with VGG19 as an encoding block, mirror from VGG19 as an encoder block on the generator, and three times combinations of Convolution, Batch Normalization, and Leaky Rectified Linear Unit (LeakyReLU) blocks. An evaluation using the DSD100 dataset shows that the proposed model gives quite high average source to distortion ratios (SDR): 7.03 dB for bass, 18.72 dB for drums, 20.20 dB for vocal, and 12.73 dB for others.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The separation of sound sources in the decomposition of music has become an interesting problem among scientists for the last 50 years. It has the main target of making it difficult for components in the music, such as vocals, bass, drums, and others. The results of sound separation have also been applied on many fields, such as remixing, repanning, and upmixing. In this paper, a new model based on a Generative Adversarial Network (GAN) is proposed to separate the music sources to rebuild the sound sources that exist in the music. The GAN architecture is built using U-net with VGG19 as an encoding block, mirror from VGG19 as an encoder block on the generator, and three times combinations of Convolution, Batch Normalization, and Leaky Rectified Linear Unit (LeakyReLU) blocks. An evaluation using the DSD100 dataset shows that the proposed model gives quite high average source to distortion ratios (SDR): 7.03 dB for bass, 18.72 dB for drums, 20.20 dB for vocal, and 12.73 dB for others.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Smart City Architecture Development Methodology (SCADM): A Meta-Analysis Using SOA-EA and SoS Approach"
        ],
        "penulis":"Prasetyo, Yuli Adam;Lubis, Muharman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Architecture and methodology development for smart city are still being carried out together in clarifying the scope of smart city. This is because the application of Enterprise Architecture (EA) still does not accommodate its characteristics as a form of System of System. This study discusses the EA research overview on smart city design and the gaps in EA implementation for smart city architecture development. This research is intended to create a smart city architecture development methodology as a System of System for reference architecture with the collaboration of several systems. The system is an element of smart city designed and developed by the leaders of each coordinated system. In the end, this methodology can form the basis for building and coordinating the development of a collaborative smart city by several actors. \u00a9 The Author(s) 2020.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Architecture and methodology development for smart city are still being carried out together in clarifying the scope of smart city. This is because the application of Enterprise Architecture (EA) still does not accommodate its characteristics as a form of System of System. This study discusses the EA research overview on smart city design and the gaps in EA implementation for smart city architecture development. This research is intended to create a smart city architecture development methodology as a System of System for reference architecture with the collaboration of several systems. The system is an element of smart city designed and developed by the leaders of each coordinated system. In the end, this methodology can form the basis for building and coordinating the development of a collaborative smart city by several actors. \u00a9 The Author(s) 2020."
        ]
    },
    {
        "judul":[
            "Numerology Effect on 5G 28 GHz Communication System Performance"
        ],
        "penulis":"Purnomo, Ikhsan;Muayyadi, Achmad Ali;Saputri, Desti Madya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "OFDM Numerology is one of the features that distinguishes between LTE technology and 5G NR technology. OFDM Numerology is a set of parameters used in 5G NR communication systems dependent upon user needs and channel conditions. In addition, 5G NR technology uses Polar Codes as error correction and error detection. Testing is needed to determine the performance characteristics of the 5G NR communication system based on OFDM Numerology provisions by adding Polar Codes, so that the resulting performance is close to real and can be a reference for efficient power requirements in the implementation of 5G NR technology in the future. This paper conducts a test to determine the performance characteristics of the 5G NR communication system based on OFDM Numerology provisions by adding Polar Codes. This paper simulation uses QPSK modulation and uses soft demapper techniques so that the resulting performance is more optimal. This study reviewed the bit error rate (BER) and frame error rate (FER) parameters. This study also calculated outage probability with coding rates R = 1 and R = 1\/2. The results of this paper test showed that numerology 3 had the same performance characteristics as numerology 4, both uncoded and Polar Codes. The performance of the 5G NR communication system using Polar Codes was better than uncoded.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "OFDM Numerology is one of the features that distinguishes between LTE technology and 5G NR technology. OFDM Numerology is a set of parameters used in 5G NR communication systems dependent upon user needs and channel conditions. In addition, 5G NR technology uses Polar Codes as error correction and error detection. Testing is needed to determine the performance characteristics of the 5G NR communication system based on OFDM Numerology provisions by adding Polar Codes, so that the resulting performance is close to real and can be a reference for efficient power requirements in the implementation of 5G NR technology in the future. This paper conducts a test to determine the performance characteristics of the 5G NR communication system based on OFDM Numerology provisions by adding Polar Codes. This paper simulation uses QPSK modulation and uses soft demapper techniques so that the resulting performance is more optimal. This study reviewed the bit error rate (BER) and frame error rate (FER) parameters. This study also calculated outage probability with coding rates R = 1 and R = 1\/2. The results of this paper test showed that numerology 3 had the same performance characteristics as numerology 4, both uncoded and Polar Codes. The performance of the 5G NR communication system using Polar Codes was better than uncoded.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis and Design of Policy and Standard Operating Procedure (SOP) for Information Technology in the Communication and Information Services Department"
        ],
        "penulis":"Lubis, Muharman;Ananza, Hikam Haikal Radya;Suryoputro, Fritasya Dwiputri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "SOP as quality standards to perform the process of the instruction and executing tasks and activities are important for an organization. The communication and information services in West Java Province has developed a service known as Management of West Java province domain emails. SOP for service provided is to support the procedures needed for the continuity of service provided needed for the continuity of service. This research uses an observation and interview as a method to collect data. SOP will divide into 5 categories by the answer of a data interview that has been collected. This paper tries to explain what are necessary and which type of work needs to be done for writing SOPs for service provided in the communication and information services of West Java Province.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SOP as quality standards to perform the process of the instruction and executing tasks and activities are important for an organization. The communication and information services in West Java Province has developed a service known as Management of West Java province domain emails. SOP for service provided is to support the procedures needed for the continuity of service provided needed for the continuity of service. This research uses an observation and interview as a method to collect data. SOP will divide into 5 categories by the answer of a data interview that has been collected. This paper tries to explain what are necessary and which type of work needs to be done for writing SOPs for service provided in the communication and information services of West Java Province.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Prediction of Tide level by using Holtz-Winters Exponential Smoothing: Case study in Cilacap Bay"
        ],
        "penulis":"Wibowo, Dwinov Satrio;Adytia, Didit;Saepudin, Deni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Sea level rise is a phenomenon that causes the sea level to rise to some extent, And the impact from The changes in the tide level can influence flooding in coastal area that can damage the structure of the building around that area and also disturb the health of functionally linked neighboring ecosystems. But now with the development of technology and science it is possible to make some projection of the future tidal level by using a time series data, which is very important for an island country like Indonesia, this forecasted data can be used to make a planning and implementing a projects in port and coastal area. Now, there are many methods to predict the future value of several things. In this paper, the Holt-Winters Exponential Smoothings applied to forecast the tidal level in Cilacap. Then the Holt-Winters forecasting performance compared with the Autoregressive Integrated Moving Average (ARIMA), and Seasonal-Autoregressive Integrated Moving Average (SARIMA), in order to see which one that can produce the best forecast. The method performance measured by using root mean square error (RMSE) and R-Square. The Holt-Winters Exponential smoothing produces RMSE and R-Square that are better than ARIMA and SARIMA. The choice of seasonal period significantly affects the forecasting result produced by the Holt-Winters method.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentLife below waterGoal 14Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sea level rise is a phenomenon that causes the sea level to rise to some extent, And the impact from The changes in the tide level can influence flooding in coastal area that can damage the structure of the building around that area and also disturb the health of functionally linked neighboring ecosystems. But now with the development of technology and science it is possible to make some projection of the future tidal level by using a time series data, which is very important for an island country like Indonesia, this forecasted data can be used to make a planning and implementing a projects in port and coastal area. Now, there are many methods to predict the future value of several things. In this paper, the Holt-Winters Exponential Smoothings applied to forecast the tidal level in Cilacap. Then the Holt-Winters forecasting performance compared with the Autoregressive Integrated Moving Average (ARIMA), and Seasonal-Autoregressive Integrated Moving Average (SARIMA), in order to see which one that can produce the best forecast. The method performance measured by using root mean square error (RMSE) and R-Square. The Holt-Winters Exponential smoothing produces RMSE and R-Square that are better than ARIMA and SARIMA. The choice of seasonal period significantly affects the forecasting result produced by the Holt-Winters method.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Green Innovative Product and Its Effects on Environmental"
        ],
        "penulis":"Widodo, Arry;Wahid, Nabsiah Abdul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The presence of green innovative product (GIP) is observed to influence consumers' purchasing decisions as they become more ecologically aware of the effects caused by conventional products' consumption to the environment. This article reviews the concept behind GIP and its effect on consumer's behavior. The article focuses on the meaning and classification of GIP and on how it affects consumer's behavior in terms of their satisfaction, environmental attitude and also purchase. Several issues that arise for customer when they consume GIP will be raised. The article will also address why the industry such as oil and gas needs to cater to the need for GIP and provide basic guidelines on how this is achieved without too much difficulty. The insights are expected to help build our understanding on the importance of GIP to be researched and on the potential of its commercial value that encourages consumers to repeat purchase after consuming it. In addition, the insights may give an idea for government and the industry in forming and formulating appropriate policies as well as increasing public's environmental sensitivity. The article implies the important connection between GIP and individual's identity as well as their ecological beliefs. \u00a9 2020 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The presence of green innovative product (GIP) is observed to influence consumers' purchasing decisions as they become more ecologically aware of the effects caused by conventional products' consumption to the environment. This article reviews the concept behind GIP and its effect on consumer's behavior. The article focuses on the meaning and classification of GIP and on how it affects consumer's behavior in terms of their satisfaction, environmental attitude and also purchase. Several issues that arise for customer when they consume GIP will be raised. The article will also address why the industry such as oil and gas needs to cater to the need for GIP and provide basic guidelines on how this is achieved without too much difficulty. The insights are expected to help build our understanding on the importance of GIP to be researched and on the potential of its commercial value that encourages consumers to repeat purchase after consuming it. In addition, the insights may give an idea for government and the industry in forming and formulating appropriate policies as well as increasing public's environmental sensitivity. The article implies the important connection between GIP and individual's identity as well as their ecological beliefs. \u00a9 2020 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Industrial internet of things: Recent advances, enabling technologies and open challenges"
        ],
        "penulis":"Khan W.Z.;Rehman M.H.;Zangoti H.M.;Afzal M.K.;Armi N.;Salah K.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The adoption of emerging technological trends and applications of the Internet of Things (IoT) in the industrial systems is leading towards the development of Industrial IoT (IIoT). IIoT serves as a new vision of IoT in the industrial sector by automating smart objects for sensing, collecting, processing and communicating the real-time events in industrial systems. The major objective of IIoT is to achieve high operational efficiency, increased productivity, and better management of industrial assets and processes through product customization, intelligent monitoring applications for production floor shops and machine health, and predictive and preventive maintenance of industrial equipment. In this paper, we present a new and clear definition of IIoT, which can help the readers to understand the concept of IIoT. We have described the state-of-the-art research efforts in IIoT. Finally, we have highlighted the enabling technologies for IIoT and recent challenges faced by IIoT. \u00a9 2019",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The adoption of emerging technological trends and applications of the Internet of Things (IoT) in the industrial systems is leading towards the development of Industrial IoT (IIoT). IIoT serves as a new vision of IoT in the industrial sector by automating smart objects for sensing, collecting, processing and communicating the real-time events in industrial systems. The major objective of IIoT is to achieve high operational efficiency, increased productivity, and better management of industrial assets and processes through product customization, intelligent monitoring applications for production floor shops and machine health, and predictive and preventive maintenance of industrial equipment. In this paper, we present a new and clear definition of IIoT, which can help the readers to understand the concept of IIoT. We have described the state-of-the-art research efforts in IIoT. Finally, we have highlighted the enabling technologies for IIoT and recent challenges faced by IIoT. \u00a9 2019"
        ]
    },
    {
        "judul":[
            "FFT-based data hiding on audio in LWT-domain using spread spectrum technique"
        ],
        "penulis":"Budiman, Gelar;Suksmono, Andriyan Bayu;Danudirdjo, Donny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Audio watermarking is a process to hide digital data without being seen or heard by the sense of sight or hearing. Watermaking is applied to insert the copyright on digital media, such as an image file, an audio file or a video file. In this paper, we propose watermarking procedure to embed spread spectrum watermark into frequency domain of adaptive selected subband from host audio. Lifting Wavelet Transform (LWT) is used to decompose the host audio into several subbands, and then Fast Fourier Transform (FFT) transforms selected several subbands with lowest energy. The watermark image is converted into one-dimensional signal, then it is modulated by imperceptible pseudo-noise (PN) code with controlled gain. Next, the frequency domain of audio is added by modulated and imperceptible watermark prior to transforming it to time domain by Inverse FFT (IFFT) obtaining watermarked subbands. Finally, the watermarked subbands are combined with other unused subbands by inverse LWT (ILWT) becoming the perfect version of watermarked audio. The result of this method has good robustness against most attacks from stirmark benchmark experiments, good imperceptibility with Signal to Noise Ratio (SNR) more than 30 dB and payload 172.66 bps. \u00a9 2020 Kauno Technologijos Universitetas. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Audio watermarking is a process to hide digital data without being seen or heard by the sense of sight or hearing. Watermaking is applied to insert the copyright on digital media, such as an image file, an audio file or a video file. In this paper, we propose watermarking procedure to embed spread spectrum watermark into frequency domain of adaptive selected subband from host audio. Lifting Wavelet Transform (LWT) is used to decompose the host audio into several subbands, and then Fast Fourier Transform (FFT) transforms selected several subbands with lowest energy. The watermark image is converted into one-dimensional signal, then it is modulated by imperceptible pseudo-noise (PN) code with controlled gain. Next, the frequency domain of audio is added by modulated and imperceptible watermark prior to transforming it to time domain by Inverse FFT (IFFT) obtaining watermarked subbands. Finally, the watermarked subbands are combined with other unused subbands by inverse LWT (ILWT) becoming the perfect version of watermarked audio. The result of this method has good robustness against most attacks from stirmark benchmark experiments, good imperceptibility with Signal to Noise Ratio (SNR) more than 30 dB and payload 172.66 bps. \u00a9 2020 Kauno Technologijos Universitetas. All rights reserved."
        ]
    },
    {
        "judul":[
            "The Prototype of In-Store Visitor and People Passing Counters using Single Shot Detector Performed by OpenCV"
        ],
        "penulis":"Herviana, Andes;Sudiharto, Dodi Wisaksono;Yulianto, Fazmah Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information related to the power hours of a mall or store is important. By typically knowing it, the manager of the store or the mall can wisely determine the staff planning decision. Without the right decision, it potentially decreases customer satisfaction. The decision can be defined by utilizing in-store visitors and people passing traffic patterns. The other problem also arises when the calculation of in-store visitors and people passing are executed manually, so it requires much effort. This study proposes a prototype design of the system which can automatically calculate visitors by utilizing Single Shot Detector (SSD) method. This method is performed by operating OpenCV library. It is used to detect a human object marked as in-store visitor or people passing. The embedded computer is conducted to process images captured by Pi Camera. Based on the study, the result accuracy is 65.08% for the system counts in-store visitors, and 66.12% for the system marks objects as people pass around in front of the store. Although the accuracy values obtained is not high, but all patterns show that the highest average values of in-store visitors and people passing occur on the days nearing weekend and also on the weekend, such as Friday, Saturday and Sunday. The peak time of in-store visitors (e.g. power hour) on Friday is between 12 PM and 1 PM. The peak time of in-store visitors on Saturday is between 3 PM and 4 PM, and on Monday, it is between 4 PM and 5 PM.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information related to the power hours of a mall or store is important. By typically knowing it, the manager of the store or the mall can wisely determine the staff planning decision. Without the right decision, it potentially decreases customer satisfaction. The decision can be defined by utilizing in-store visitors and people passing traffic patterns. The other problem also arises when the calculation of in-store visitors and people passing are executed manually, so it requires much effort. This study proposes a prototype design of the system which can automatically calculate visitors by utilizing Single Shot Detector (SSD) method. This method is performed by operating OpenCV library. It is used to detect a human object marked as in-store visitor or people passing. The embedded computer is conducted to process images captured by Pi Camera. Based on the study, the result accuracy is 65.08% for the system counts in-store visitors, and 66.12% for the system marks objects as people pass around in front of the store. Although the accuracy values obtained is not high, but all patterns show that the highest average values of in-store visitors and people passing occur on the days nearing weekend and also on the weekend, such as Friday, Saturday and Sunday. The peak time of in-store visitors (e.g. power hour) on Friday is between 12 PM and 1 PM. The peak time of in-store visitors on Saturday is between 3 PM and 4 PM, and on Monday, it is between 4 PM and 5 PM.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The effectiveness of online calculus 2 learning during the Covid-19 pandemic"
        ],
        "penulis":"Susilawati T.;Darmawan I.;Desiasni R.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study aims to analyze the effectiveness of online learning in calculus 2 during the Covid-19 pandemic. The study was conducted in a civil engineering study program at a private tertiary institution on Sumbawa Island. This research is a quasi-experimental research design model non-equivalent control group design. The number of subjects in this study was 71 people. Data analysis used a paired sample t-test analysis with the help of SPSS software. Based on the results of data analysis, online learning is not effective in calculus 2 subjects in the pandemic covid-19 period, there is a significant relationship between conventional learning and online learning and there is a significant difference between conventional learning and online learning. The average value of student learning outcomes is decreased when the online learning system is applied. From these results it can be concluded the online learning system in the 2nd calculus course during the Covid-19 pandemic has not been effective. \u00a9 2020 Institute of Physics Publishing. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Quality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study aims to analyze the effectiveness of online learning in calculus 2 during the Covid-19 pandemic. The study was conducted in a civil engineering study program at a private tertiary institution on Sumbawa Island. This research is a quasi-experimental research design model non-equivalent control group design. The number of subjects in this study was 71 people. Data analysis used a paired sample t-test analysis with the help of SPSS software. Based on the results of data analysis, online learning is not effective in calculus 2 subjects in the pandemic covid-19 period, there is a significant relationship between conventional learning and online learning and there is a significant difference between conventional learning and online learning. The average value of student learning outcomes is decreased when the online learning system is applied. From these results it can be concluded the online learning system in the 2nd calculus course during the Covid-19 pandemic has not been effective. \u00a9 2020 Institute of Physics Publishing. All rights reserved."
        ]
    },
    {
        "judul":[
            "Measurement of Criterion Weight to Determine Industrial Area Location Using AHP for Economic Growth"
        ],
        "penulis":"Chumaidiyah E.;Dewantoro M.D.R.;Hakimah D.A.;Arffan Z.;Robbi R.M.N.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Industrial area is an infrastructure for the process of industrialization as a source that can trigger economic growth. Industrial areas that are structured and can support production operations are an appeal to foreign investors. However, the development of industrial areas requires careful planning because it impacts on the environmental carrying capacity and land loss. Therefore, industrial area development needs attention to a variety of important criteria as considerations in determining the location of an industrial area. This study aims to determine the criteria and measure the importance of each relative criterion to other criteria. The method used is Analytical Hierarchy Process (AHP). The results show that there are four important factors that need to be considered with each of the importance level, namely Infrastructure by 33.97%, Distance to Access by 31.74%, Land Soil by 19.57%, and Production Factors by 14.72%. The four factors have ten important criteria that need to be considered in making decisions to determine the location of an industrial area where the two highest criteria are electricity infrastructure with a significance level of 19.05% and telecommunications infrastructure with an importance level of 14.92%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industrial area is an infrastructure for the process of industrialization as a source that can trigger economic growth. Industrial areas that are structured and can support production operations are an appeal to foreign investors. However, the development of industrial areas requires careful planning because it impacts on the environmental carrying capacity and land loss. Therefore, industrial area development needs attention to a variety of important criteria as considerations in determining the location of an industrial area. This study aims to determine the criteria and measure the importance of each relative criterion to other criteria. The method used is Analytical Hierarchy Process (AHP). The results show that there are four important factors that need to be considered with each of the importance level, namely Infrastructure by 33.97%, Distance to Access by 31.74%, Land Soil by 19.57%, and Production Factors by 14.72%. The four factors have ten important criteria that need to be considered in making decisions to determine the location of an industrial area where the two highest criteria are electricity infrastructure with a significance level of 19.05% and telecommunications infrastructure with an importance level of 14.92%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Modeling Traffic Flow on Buah Batu Exit Toll Gate Using Cellular Automata"
        ],
        "penulis":"Ketaren, Raymondo Fitrah;Danufane, Fadil Habibi;Kurniawan, Isman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the last decade, Bandung has become one of the tourism destination places in Indonesia. It is reported that almost 6.7 million visitors come to Bandung in 2018, and the number increased by almost 4% per year since 2014. This rise in the number of visitors leads to the establishment of several toll gates as main access points throughout the city. As one of the busiest ones, Buah Batu toll gate is frequently congested because of the location that is close to the southern part of Bandung. To overcome this problem, a traffic regulation based on computer simulation is urgently required. In this study, we simulate the traffic system on the Buah Batu toll gate by using a combination of Nagel-Schreckenberg (NaSch) and Daoudia and Moussa (DM) models. NaSch model was used to defined vehicle movement, while the DM model was used to allow a vehicle to change lane. We defined three scenarios to evaluate the effectivity of the closing gate scheme. We found that the closing of gate 5 is more effective than the closing of gate 1. We also investigated the contribution of traffic density and driver's behavior, e.g., stopping behavior and lane-changing behavior, to the average velocity of the vehicles.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the last decade, Bandung has become one of the tourism destination places in Indonesia. It is reported that almost 6.7 million visitors come to Bandung in 2018, and the number increased by almost 4% per year since 2014. This rise in the number of visitors leads to the establishment of several toll gates as main access points throughout the city. As one of the busiest ones, Buah Batu toll gate is frequently congested because of the location that is close to the southern part of Bandung. To overcome this problem, a traffic regulation based on computer simulation is urgently required. In this study, we simulate the traffic system on the Buah Batu toll gate by using a combination of Nagel-Schreckenberg (NaSch) and Daoudia and Moussa (DM) models. NaSch model was used to defined vehicle movement, while the DM model was used to allow a vehicle to change lane. We defined three scenarios to evaluate the effectivity of the closing gate scheme. We found that the closing of gate 5 is more effective than the closing of gate 1. We also investigated the contribution of traffic density and driver's behavior, e.g., stopping behavior and lane-changing behavior, to the average velocity of the vehicles.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Boost of Attribute-aware Semantic Segmentation via Data Augmentation for Driver Assistance"
        ],
        "penulis":"Sulistiyo, Mahmud Dwi;Kawanishi, Yasutomo;Deguchi, Daisuke;Ide, Ichiro;Hirayama, Takatsugu;Murase, Hiroshi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper is an extension of our work in developing an attribute-aware semantic segmentation method which focuses on pedestrian understanding in a traffic scene. Recently, the trending topic of semantic segmentation has been expanded to be able to collaborate with the object's attributes recognition task; Here, it refers to recognizing a pedestrian's body orientation. The attribute-aware semantic segmentation can be more beneficial for driver assistance compared to the conventional semantic segmentation because it can provide a more informative output to the system. In this paper, we conduct a study of the data augmentation usage as an effort to enhance the performance of the attribute-aware semantic segmentation task. The experiments show that the proposed method in augmenting the training data is able to improve the model's performance. We also demonstrate some of qualitative results and discuss the benefits to a driver assistance system.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper is an extension of our work in developing an attribute-aware semantic segmentation method which focuses on pedestrian understanding in a traffic scene. Recently, the trending topic of semantic segmentation has been expanded to be able to collaborate with the object's attributes recognition task; Here, it refers to recognizing a pedestrian's body orientation. The attribute-aware semantic segmentation can be more beneficial for driver assistance compared to the conventional semantic segmentation because it can provide a more informative output to the system. In this paper, we conduct a study of the data augmentation usage as an effort to enhance the performance of the attribute-aware semantic segmentation task. The experiments show that the proposed method in augmenting the training data is able to improve the model's performance. We also demonstrate some of qualitative results and discuss the benefits to a driver assistance system.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Author Correction: Grazing enhances species diversity in grassland communities (Scientific Reports, (2019), 9, 1, (11201), 10.1038\/s41598-019-47635-1)"
        ],
        "penulis":"Pulungan, Muhammad Almaududi;Suzuki, Shota;Gavina, Maica Krizna Areja;Tubay, Jerrold M.;Ito, Hiromu;Nii, Momoka;Ichinose, Genki;Okabe, Takuya;Ishida, Atsushi;Shiyomi, Masae;Togashi, Tatsuya;Yoshimura, Jin;Morita, Satoru;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This Article contains errors. In the Methods, under the Lattice Model subheading, the sentence, \"In the first (second) case, the grazing intensity is strongest for the weakest (strongest) of 20 species.\u201d should read: \u201cIn the first (second) case, the grazing intensity is strongest for the strongest (weakest) of 20 species.\" In Supplementary Figure 4a, the data for G = 0.5 was not included. In Supplementary Figure 4b, the data was plotted incorrectly at G = 0.5, and error bars were not included. The correct Supplementary Figure 4 appears below as Figure 1. \u00a9 2020, The Author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This Article contains errors. In the Methods, under the Lattice Model subheading, the sentence, \"In the first (second) case, the grazing intensity is strongest for the weakest (strongest) of 20 species.\u201d should read: \u201cIn the first (second) case, the grazing intensity is strongest for the strongest (weakest) of 20 species.\" In Supplementary Figure 4a, the data for G = 0.5 was not included. In Supplementary Figure 4b, the data was plotted incorrectly at G = 0.5, and error bars were not included. The correct Supplementary Figure 4 appears below as Figure 1. \u00a9 2020, The Author(s)."
        ]
    },
    {
        "judul":[
            "Analysis of Overall Effectiveness on Hall Separator Punching Machine at PT. DNIA"
        ],
        "penulis":"Sriwana, Iphov Kumala;Syauqillah, Nadya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT. DNIA is a company engaged in manufacture of automotive parts, one of which is condenser. Manufacture of condenser components requires small parts produced using a hole separator punching machine. However, it deals with high downtime of the machine, resulting in low production performance. This research aimed to identify the extent of hole separator punching machine performance using analysis of Overall Equipment Effectiveness (OEE) and to analyse six big loses which impact on machine downtime. Calculation results show that OEE value obtained, 48.54%, was still below the standard, and therefore continuous improvement attempt is essential to perform. The low OEE value was a result of low performance efficiency which was caused by idling and minor stoppages of 24.54%. In order to improve the performance and carry out idling and minor stoppages loss, it is important to perform improvement attempt in a number of aspects, such as man aspect by training operators to carry machine-related works, machine aspect by repairing abnormal ups and downs of dies, and material aspect by fixing inappropriate position of header tank (material). \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. DNIA is a company engaged in manufacture of automotive parts, one of which is condenser. Manufacture of condenser components requires small parts produced using a hole separator punching machine. However, it deals with high downtime of the machine, resulting in low production performance. This research aimed to identify the extent of hole separator punching machine performance using analysis of Overall Equipment Effectiveness (OEE) and to analyse six big loses which impact on machine downtime. Calculation results show that OEE value obtained, 48.54%, was still below the standard, and therefore continuous improvement attempt is essential to perform. The low OEE value was a result of low performance efficiency which was caused by idling and minor stoppages of 24.54%. In order to improve the performance and carry out idling and minor stoppages loss, it is important to perform improvement attempt in a number of aspects, such as man aspect by training operators to carry machine-related works, machine aspect by repairing abnormal ups and downs of dies, and material aspect by fixing inappropriate position of header tank (material). \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "University Strategic System Engineering based on BAN PT Accreditation Criteria One using SysML and Semantic Approach"
        ],
        "penulis":"Aurachman, Rio;Putri, Ericha Mutia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "An organizations business processes need to be precisely defined so that the organization does what it should do. Some quality standards such as BAN-PT and ISO 9001 Accreditation require organizations to carry out some process. Sometimes organizations find a difficulty to understand what processes need to be applied based on the standards. This study proposes a SysML and semantic method for analysing standard sentences and providing guidance on what needs to be applied to organizations. The trial was conducted on the Study Program Accreditation standard specifically criterion 1 on strategic management.. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An organizations business processes need to be precisely defined so that the organization does what it should do. Some quality standards such as BAN-PT and ISO 9001 Accreditation require organizations to carry out some process. Sometimes organizations find a difficulty to understand what processes need to be applied based on the standards. This study proposes a SysML and semantic method for analysing standard sentences and providing guidance on what needs to be applied to organizations. The trial was conducted on the Study Program Accreditation standard specifically criterion 1 on strategic management.. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Macroscopic Modelling of Pedestrian Flows Based on Conservation Law"
        ],
        "penulis":"Windyani, Finna;Gunawan P.H.;Tarwidi, Dede;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Overcrowded of sidewalks can reduce the level of satisfaction of pedestrians. The large crowd on the sidewalks results in slowing down time of the pedestrian to arrive in their destination. This studt, focuses on pedestrian flows modelling using the macroscopic model. Numerical approximationof the macroscopic model is formulated as scalar hyperbolic conservation laws. The Lax-Wendroff scheme is used to discretize the equation of conservation laws. The simulation results show that the numerical approximation in term of density confirms the exact solution. In this simulation, the velocity function is obtained by curve fitting of observation data using linear regression method. The observation data, which are consist of velocity-density relation, are obtained from observation of pedestrian flows. The study case of this research conducts on the sidewalks of Braga Street, Bandung, Indonesia. There are two velocity functions used in the simulation, i.e. c 1 = 0.58206 + -0.94476? and c 2 = 0.59926 + -0.78052?, respectively. In performing the velocity function c 2, the pedestrian leader position is approximately 1 meter in front of the pedestrian leader using the velocity function c 1 at final time T = 20 seconds and T= 30 seconds. Overall, the numerical experiment shows that the pedestrian leader using the velocityfunctions c 2 is faster than by using c 1. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Overcrowded of sidewalks can reduce the level of satisfaction of pedestrians. The large crowd on the sidewalks results in slowing down time of the pedestrian to arrive in their destination. This studt, focuses on pedestrian flows modelling using the macroscopic model. Numerical approximationof the macroscopic model is formulated as scalar hyperbolic conservation laws. The Lax-Wendroff scheme is used to discretize the equation of conservation laws. The simulation results show that the numerical approximation in term of density confirms the exact solution. In this simulation, the velocity function is obtained by curve fitting of observation data using linear regression method. The observation data, which are consist of velocity-density relation, are obtained from observation of pedestrian flows. The study case of this research conducts on the sidewalks of Braga Street, Bandung, Indonesia. There are two velocity functions used in the simulation, i.e. c 1 = 0.58206 + -0.94476? and c 2 = 0.59926 + -0.78052?, respectively. In performing the velocity function c 2, the pedestrian leader position is approximately 1 meter in front of the pedestrian leader using the velocity function c 1 at final time T = 20 seconds and T= 30 seconds. Overall, the numerical experiment shows that the pedestrian leader using the velocityfunctions c 2 is faster than by using c 1. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The use of quality metric to control quality of telecommunication project (case study: Regional metro junction)"
        ],
        "penulis":"Zaki, Naufal Muhammad;Haryono, Imam;Pratami, Devi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Regional Metro Junction is known as a telecommunication network project which connects one city to another city \/ village. This project has specific quality requirement to be achieved. However, the project executor didn't meet the quality requirement from project owner because there's no quality guideline in the planning process of the project, so it caused several quality problem in the execution process such as 2.700 meters twisted cable, 76 poles wrong location and 35 poles tilted. In addition to that, this paper aimed to design quality metric using internal control method as a guideline to control quality the project in order to minimize the potential of rework. The step of making this quality metric is identifying the possible issue of each activity, creating the critical success criteria of each activity based on requirement documentation then identifying the resources needed of each activity. The result shows that the number of defect is decreasing as much 750 meters for the twisted cable, 44 wrong pole location and 27 tilted pole. At the end, this quality metric guideline is useful to minimize the defect of the project and can be lesson learned for another project. \u00a9 2020 Institute of Physics Publishing. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Regional Metro Junction is known as a telecommunication network project which connects one city to another city \/ village. This project has specific quality requirement to be achieved. However, the project executor didn't meet the quality requirement from project owner because there's no quality guideline in the planning process of the project, so it caused several quality problem in the execution process such as 2.700 meters twisted cable, 76 poles wrong location and 35 poles tilted. In addition to that, this paper aimed to design quality metric using internal control method as a guideline to control quality the project in order to minimize the potential of rework. The step of making this quality metric is identifying the possible issue of each activity, creating the critical success criteria of each activity based on requirement documentation then identifying the resources needed of each activity. The result shows that the number of defect is decreasing as much 750 meters for the twisted cable, 44 wrong pole location and 27 tilted pole. At the end, this quality metric guideline is useful to minimize the defect of the project and can be lesson learned for another project. \u00a9 2020 Institute of Physics Publishing. All rights reserved."
        ]
    },
    {
        "judul":[
            "Determination of Standard Time and Output Production of Spring Frame Mattress Components using Work Sampling Method"
        ],
        "penulis":"Rachman, Taufiqur;Sriwana, Iphov Kumala;Zalukhu, Stefanny Liyanawati;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT.CMAP which is a company that manufactures mattresses with production process starts from making foam (foaming), mattress covers, spring frames and finishing. Based on observations, obtained that the process of spring frame has the lowest percentage of daily production results. The purpose of this research is to determine the percentage of productive activities, cycle time, normal time, standard time and daily output of the spring frame mattress production process at PT.CMAP. The method used in this research is work sampling method that begins with preliminary sampling, data uniformity test, data adequacy test, calculating cycle time, calculating normal time by including performance factors, calculating standard time by including allowance factor and calculating daily output. The results obtained from this research that the standard time for the process of spring frame mattress components at PT.CMAP which consists of the spring round process is 5.04 minutes with the daily output is 90 pcs, the semifinished spring frame process is 10.99 minute with the daily output is 41 pcs, the list frame process is 14.81 minutes with the daily output is 31 pcs and spring frame shooting CL process is 13.40 minutes with the daily output is 34 pcs. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT.CMAP which is a company that manufactures mattresses with production process starts from making foam (foaming), mattress covers, spring frames and finishing. Based on observations, obtained that the process of spring frame has the lowest percentage of daily production results. The purpose of this research is to determine the percentage of productive activities, cycle time, normal time, standard time and daily output of the spring frame mattress production process at PT.CMAP. The method used in this research is work sampling method that begins with preliminary sampling, data uniformity test, data adequacy test, calculating cycle time, calculating normal time by including performance factors, calculating standard time by including allowance factor and calculating daily output. The results obtained from this research that the standard time for the process of spring frame mattress components at PT.CMAP which consists of the spring round process is 5.04 minutes with the daily output is 90 pcs, the semifinished spring frame process is 10.99 minute with the daily output is 41 pcs, the list frame process is 14.81 minutes with the daily output is 31 pcs and spring frame shooting CL process is 13.40 minutes with the daily output is 34 pcs. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Investigating generation Z' intention to use learners' generated content for learning activity: A theory of planned behavior approach"
        ],
        "penulis":"Persada, Satria Fadil;Ivanovski, Jeremy;Miraja, Bobby Ardiansyah;Nadlifatin, Reny;Mufidah, Ilma;Chin, Jacky;Redi, A.A.N Perwira;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, learning media has developed rapidly, opening infinite possibilities for students to access their educational materials. Learner's Generated Content (LGC) is one of the emerging learning media that showed interesting promises. LGC is based on the concept of User Generated Content; many advantages of UGC also existed in LGC: speed, collaboration, and the diversity of contents. Although past researches have already proven that LGC has positive effects on the educational process, mainly, these previous researches focused only on the perspective of the educators. This study questioned how today's students, mostly comprised of Generation Z, see LGC. Employing the Theory of Planned Behaviour (TPB), we revealed several statistical results followed by managerial interpretations. Attitude (AT) was shown to have the highest correlation with Generation Z's students (\u03b2=0.43), educators could utilise this fact; they can be more reassured when implementing LGC in their future curriculum. The Perceived Behavioral Control (PBC) was also significant towards our respondent's behavioural intention (\u03b2=0.34), indicating that there is a little limitation for students to use LGC as part of their learning activity. \u00a9 2020 Kassel University Press GmbH.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, learning media has developed rapidly, opening infinite possibilities for students to access their educational materials. Learner's Generated Content (LGC) is one of the emerging learning media that showed interesting promises. LGC is based on the concept of User Generated Content; many advantages of UGC also existed in LGC: speed, collaboration, and the diversity of contents. Although past researches have already proven that LGC has positive effects on the educational process, mainly, these previous researches focused only on the perspective of the educators. This study questioned how today's students, mostly comprised of Generation Z, see LGC. Employing the Theory of Planned Behaviour (TPB), we revealed several statistical results followed by managerial interpretations. Attitude (AT) was shown to have the highest correlation with Generation Z's students (\u03b2=0.43), educators could utilise this fact; they can be more reassured when implementing LGC in their future curriculum. The Perceived Behavioral Control (PBC) was also significant towards our respondent's behavioural intention (\u03b2=0.34), indicating that there is a little limitation for students to use LGC as part of their learning activity. \u00a9 2020 Kassel University Press GmbH."
        ]
    },
    {
        "judul":[
            "The Function of PMO for successful program-project management in the bank company - A case study"
        ],
        "penulis":"Yana, Rika Rizki;Sasongko, Danarto Tri;Wardhana, Aditya Wisnu;Ilona, Kwee Felicia;Shihab, Muhammad Rifki;Ranti, Benny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this paper is to investigate the specific function of Program Management Office (PMO) to manage multiple Kaizen or improvement projects and how we can implement PMO with more effective and more efficient to deliver value, benefits and achieve business goal in bank company. Research indicate that project management become increasingly difficult to manage when multiple projects are many overlapping projects in a project-oriented company, the goal in a need for enhanced bank company controls to increase success rates. It caused with implementation of a system that help project management, the system named Project Management Office (PMO) that is essential for bank company that are project-oriented and faced many overlapping projects. The PMO with an essential model that will explain to us to have management system of multiple project effectively in a banking company. Using a case study in one of banking industry in Indonesia, to test the method of research found that PMO deliver excellent value for bank company. The survey result of PMO function saw that most of project stakeholders in banking company agreed to 5 (five) categories and 20 (twenty) specified of PMO function implementation to manage several banking projects excellent. based on the results of the questionnaire, stakeholders answered more agreeably with the function of PMO for success project management at bank company and it could answer to the question that the method has deliver benefit and create goals for project management office performance in bank company.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this paper is to investigate the specific function of Program Management Office (PMO) to manage multiple Kaizen or improvement projects and how we can implement PMO with more effective and more efficient to deliver value, benefits and achieve business goal in bank company. Research indicate that project management become increasingly difficult to manage when multiple projects are many overlapping projects in a project-oriented company, the goal in a need for enhanced bank company controls to increase success rates. It caused with implementation of a system that help project management, the system named Project Management Office (PMO) that is essential for bank company that are project-oriented and faced many overlapping projects. The PMO with an essential model that will explain to us to have management system of multiple project effectively in a banking company. Using a case study in one of banking industry in Indonesia, to test the method of research found that PMO deliver excellent value for bank company. The survey result of PMO function saw that most of project stakeholders in banking company agreed to 5 (five) categories and 20 (twenty) specified of PMO function implementation to manage several banking projects excellent. based on the results of the questionnaire, stakeholders answered more agreeably with the function of PMO for success project management at bank company and it could answer to the question that the method has deliver benefit and create goals for project management office performance in bank company.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Ability to Adapt jBatik Software Technology for Traditional Batik Craftsmen"
        ],
        "penulis":"Ciptandi, Fajar;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study is to find out the adaptability of traditional batik craftsmen in using jBatik software technology to create motif development. The traditional batik industry in Tuban, East Java was choosen as an example of case because it is considered to represent other traditional batik industries in Java. In previous studies, the use of jBatik software has been tested and resulted in the development of several designs of traditional Tuban batik motifs. This study was conducted to analyze the factors driving as well as inhibiting traditional batik craftsmen in adapting jBatik software technology through an experimental approach by referring to the diffusion of innovation theory. This is useful as one of the solutions today as an effort to measure the readiness level of traditional batik craftsmen to adapt technology, as well as being a way of self-evaluation for the technology to adapt to the needs of traditional batik craftsmen in Indonesia.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study is to find out the adaptability of traditional batik craftsmen in using jBatik software technology to create motif development. The traditional batik industry in Tuban, East Java was choosen as an example of case because it is considered to represent other traditional batik industries in Java. In previous studies, the use of jBatik software has been tested and resulted in the development of several designs of traditional Tuban batik motifs. This study was conducted to analyze the factors driving as well as inhibiting traditional batik craftsmen in adapting jBatik software technology through an experimental approach by referring to the diffusion of innovation theory. This is useful as one of the solutions today as an effort to measure the readiness level of traditional batik craftsmen to adapt technology, as well as being a way of self-evaluation for the technology to adapt to the needs of traditional batik craftsmen in Indonesia.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Moderating effects of green IS on the relationship between organizational agility, customer experience and digital service innovation to achieve sustainable performance"
        ],
        "penulis":"Mihardjo, Leonardus W. W.;Sasmoko;Alamsjah, Firdaus;Elidjen;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study focuses on the empirical analysis to assess the role of digitalization through Green Information System (GIS) on the relationship between organizational agility (OA), customer experience (CX), and digital service innovation (DSI) to achieve sustainable performance (SP) in the Indonesian Information Communication and Technology (ICT) industry. The authors seek to examine the technological impact as part of digital transformation antecedents of CX and OA in developing DSI. The study also aims to investigate the digital transformation model to attain a more sustainableICT performance in Indonesia. The novelty of this study lies in the identifying and testing the concurrent effects of studied variables in improving the understanding of DSI and SP as part of the Indonesian ICT digital transformation model. The study used a sample of 195 Indonesia ICT firms. The finding from PLS-SEM reveals that GIS has a significant moderating role in accelerating the development ofDSI on the relationship with CX and OA, while SP is positively and significantly influenced by CS, OA and DSI. The implication and the proposed of digital transformation model for Indonesian ICT firms is also discussed in this paper. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study focuses on the empirical analysis to assess the role of digitalization through Green Information System (GIS) on the relationship between organizational agility (OA), customer experience (CX), and digital service innovation (DSI) to achieve sustainable performance (SP) in the Indonesian Information Communication and Technology (ICT) industry. The authors seek to examine the technological impact as part of digital transformation antecedents of CX and OA in developing DSI. The study also aims to investigate the digital transformation model to attain a more sustainableICT performance in Indonesia. The novelty of this study lies in the identifying and testing the concurrent effects of studied variables in improving the understanding of DSI and SP as part of the Indonesian ICT digital transformation model. The study used a sample of 195 Indonesia ICT firms. The finding from PLS-SEM reveals that GIS has a significant moderating role in accelerating the development ofDSI on the relationship with CX and OA, while SP is positively and significantly influenced by CS, OA and DSI. The implication and the proposed of digital transformation model for Indonesian ICT firms is also discussed in this paper. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Leader-follower synchronization of uncertain Euler-Lagrange dynamics with input constraints"
        ],
        "penulis":"Rosa, Muhammad Ridho;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper addresses the problem of leader-follower synchronization of uncertain Euler-Lagrange systems under input constraints. The problem is solved in a distributed model reference adaptive control framework that includes positive m-modification to address input constraints. The proposed design has the distinguishing features of updating the gains to synchronize the uncertain systems and of providing stable adaptation in the presence of input saturation. By using a matching condition assumption, a distributed inverse dynamics architecture is adopted to guarantee convergence to common dynamics. The design is studied analytically, and its performance is validated in simulation using spacecraft dynamics. \u00a9 2020 by the authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper addresses the problem of leader-follower synchronization of uncertain Euler-Lagrange systems under input constraints. The problem is solved in a distributed model reference adaptive control framework that includes positive m-modification to address input constraints. The proposed design has the distinguishing features of updating the gains to synchronize the uncertain systems and of providing stable adaptation in the presence of input saturation. By using a matching condition assumption, a distributed inverse dynamics architecture is adopted to guarantee convergence to common dynamics. The design is studied analytically, and its performance is validated in simulation using spacecraft dynamics. \u00a9 2020 by the authors."
        ]
    },
    {
        "judul":[
            "The Development of Information System Security Operation Centre (SOC): Case Study of Auto Repair Company"
        ],
        "penulis":"Lubis, Muharman;Wardana, Chandra;Widjajarto, Adityas;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Auto repair is a series of activities that engage in the field of body repair and painting services of car and motorcycle. The ultimate goal is to provide the best service and quality standards to customers by running the proper response processes, which lead the increased customer satisfaction to be achieved. Importantly, every company required the security system and mechanism to maintain the existing system as an effort to protect and overcome problems related to data privacy, transactions and communication. This study explores the problem and challenges faced by the respected company to generate an access control matrix for logical and physical assets as well as service operation procedure. The focus primarily in the development of Security Operation Center (SOC) as the front gate of the company to offer various services to the customers. SOC is a key enabler for operators who aspire to differentiate themselves based on customer experience and demand. A successful SOC application can help operators to reduce the pressure and improve operational efficiency.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Auto repair is a series of activities that engage in the field of body repair and painting services of car and motorcycle. The ultimate goal is to provide the best service and quality standards to customers by running the proper response processes, which lead the increased customer satisfaction to be achieved. Importantly, every company required the security system and mechanism to maintain the existing system as an effort to protect and overcome problems related to data privacy, transactions and communication. This study explores the problem and challenges faced by the respected company to generate an access control matrix for logical and physical assets as well as service operation procedure. The focus primarily in the development of Security Operation Center (SOC) as the front gate of the company to offer various services to the customers. SOC is a key enabler for operators who aspire to differentiate themselves based on customer experience and demand. A successful SOC application can help operators to reduce the pressure and improve operational efficiency.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Character education based on digital comic media"
        ],
        "penulis":"Rina, Nofha;Suminar, Jenny Ratna;Damayani, Ninis Agustini;Hafiar, Hanny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Reading is one of the cultures in society that tends to be abandoned along with the rapid development of information technology as children nowadays tend to choose something practical as a medium for finding information. Therefore, to improve the latest learning methods through digital media, character-based literacy comics become the main choice in building positive educational values among elementary school students. This study aims to produce character-based comic media, determine the feasibility and effectiveness of character-based comic media on the development of character education for fourth grade elementary school students. This research used a development research consisting of some stages, namely: research and data collection, planning, product draft development, expert validation, expert-based revision, limited trials, improvement of the product of limited trial results, field trials, improvement of the final product, and product dissemination. The comparison test method in the field test uses Gain Analysis and Wilcoxon t-test. The subjects of this study were the fourth-grade students of the Quran Elementary School (SDQu) i.e. 26 students consisting of 6 students for limited trials and 20 students for field trials. The results of this study show that: (1) character-based comic media was produced in thematic-integrative learning, (2) the developed comic media were viewed in terms of the quality aspects of media aspects and material aspects from the experts, the teacher, and the results of students' responses were categorized very well, and (3) comic media developed effectively increased the value of student character in the learning process. \u00a9 2020.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Reading is one of the cultures in society that tends to be abandoned along with the rapid development of information technology as children nowadays tend to choose something practical as a medium for finding information. Therefore, to improve the latest learning methods through digital media, character-based literacy comics become the main choice in building positive educational values among elementary school students. This study aims to produce character-based comic media, determine the feasibility and effectiveness of character-based comic media on the development of character education for fourth grade elementary school students. This research used a development research consisting of some stages, namely: research and data collection, planning, product draft development, expert validation, expert-based revision, limited trials, improvement of the product of limited trial results, field trials, improvement of the final product, and product dissemination. The comparison test method in the field test uses Gain Analysis and Wilcoxon t-test. The subjects of this study were the fourth-grade students of the Quran Elementary School (SDQu) i.e. 26 students consisting of 6 students for limited trials and 20 students for field trials. The results of this study show that: (1) character-based comic media was produced in thematic-integrative learning, (2) the developed comic media were viewed in terms of the quality aspects of media aspects and material aspects from the experts, the teacher, and the results of students' responses were categorized very well, and (3) comic media developed effectively increased the value of student character in the learning process. \u00a9 2020."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Designing the Smart Health Function towards Puskesmas (Citizen Health Centre) based on Smart City Concept"
        ],
        "penulis":"Jannah, Alif Miftahul;Lubis, Muharman;Saedudin, Rd. Rohmat;Fritasya Dwiputri S.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "According to Regional Regulation No.23 of 2014 Article 386 until 390 which requires all institutions to adopt architectural designs to bring up architectural innovations. A smart city is a concept of the application, development, and implementation of technology that is applied to a region (especially urban area) as a complex interaction between the various systems in it. One important development area to be developed is the health sector. In Indonesian constitution of article 28 H and 28 I that the state must guarantee the lives of all its citizens, include by providing appropriate services such as health services. This study aims to design an enterprise architecture in health functions within Citizen Health Centre management system based on the Smart City based on the TOGAF ADM framework, so that it is expected to help the city government work program in realizing smart city and business activities that currently run can be supported by information systems so as to increase satisfaction Bandung City communities. Based on the results of research on public health functions at the Bandung City Health Office obtained a design or blueprint that focuses on the preliminary phase, architecture vision, business architecture, system architecture, information technology, opportunities and solutions, and migration planning. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "According to Regional Regulation No.23 of 2014 Article 386 until 390 which requires all institutions to adopt architectural designs to bring up architectural innovations. A smart city is a concept of the application, development, and implementation of technology that is applied to a region (especially urban area) as a complex interaction between the various systems in it. One important development area to be developed is the health sector. In Indonesian constitution of article 28 H and 28 I that the state must guarantee the lives of all its citizens, include by providing appropriate services such as health services. This study aims to design an enterprise architecture in health functions within Citizen Health Centre management system based on the Smart City based on the TOGAF ADM framework, so that it is expected to help the city government work program in realizing smart city and business activities that currently run can be supported by information systems so as to increase satisfaction Bandung City communities. Based on the results of research on public health functions at the Bandung City Health Office obtained a design or blueprint that focuses on the preliminary phase, architecture vision, business architecture, system architecture, information technology, opportunities and solutions, and migration planning. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Stress and Deformation of Optimally Shaped Silicon Microneedles for Transdermal Drug Delivery"
        ],
        "penulis":"Zainal Abidin, Hafzaliza Erny;Ooi, Poh Choon;Tiong, Teck Yaw;Marsi, Noraini;Ismardi, Abrar;Mohd Noor, Mimiwaty;Nik Zaini Fathi, Nik Amni Fathi;Abd Aziz, Norazreen;Sahari, Siti Kudnie;Sugandi, Gandi;Yunas, Jumril;Dee, Chang Fu;Yeop Majlis, Burhanuddin;Hamzah, Azrul Azlan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this study, we demonstrated the fabrication of the concave conic shape microneedle with the aid of COMSOL Multiphysics simulation. The stress and buckling of the microneedle structure were simulated by applying various loads ranging from 50 to 800 g perpendiculars to the tip in order to predict the occurrence of microneedles structure deformation. The simulation study indicated that the surface buckling deformation does not occur to the microneedle structure with the increment of the load. The microneedles with dimensions of height and diameter tip ranging from 60 to 100 \u03bcm and 1 to 4 \u03bcm, respectively had been fabricated via an etching process in a mixture of hydrofluoric acid, nitric acid, and acetic acid. Three optimized microneedles but different in the structures were fabricated via the acidic etching process. The reproducibility of 3 different microneedle structures was 15, 20, and 60%, respectively. Stress and buckling analyses of the fabricated microneedles were further carried out on the rat skin. The obtained experimental results show promising applications for the deep dermis, stratum corneum to epidermis layer penetration. \u00a9 2020 American Pharmacists Association\u00ae",
            "SiNView detailsExpand Substance silicon nitride",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this study, we demonstrated the fabrication of the concave conic shape microneedle with the aid of COMSOL Multiphysics simulation. The stress and buckling of the microneedle structure were simulated by applying various loads ranging from 50 to 800 g perpendiculars to the tip in order to predict the occurrence of microneedles structure deformation. The simulation study indicated that the surface buckling deformation does not occur to the microneedle structure with the increment of the load. The microneedles with dimensions of height and diameter tip ranging from 60 to 100 \u03bcm and 1 to 4 \u03bcm, respectively had been fabricated via an etching process in a mixture of hydrofluoric acid, nitric acid, and acetic acid. Three optimized microneedles but different in the structures were fabricated via the acidic etching process. The reproducibility of 3 different microneedle structures was 15, 20, and 60%, respectively. Stress and buckling analyses of the fabricated microneedles were further carried out on the rat skin. The obtained experimental results show promising applications for the deep dermis, stratum corneum to epidermis layer penetration. \u00a9 2020 American Pharmacists Association\u00ae"
        ]
    },
    {
        "judul":[
            "Speaker Recognition for Device Controlling using MFCC and GMM Algorithm"
        ],
        "penulis":"Malik, Ridwan Abdul;Setianingsih, Casi;Nasrun, Muhammad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Biometric technology is widely used to identify a smart home device controller with access control to the system. Sound Abstract is one of the biometric technologies used because human speech is different and unique. Generally, a smart home device controller based on sound can be controlled by everyone so that a speaker who should not have access rights to the system will still execute his voice command. The solution to this problem is a sound control system that can identify one speaker's voice with other speakers registered on the system to control smart home devices and reject commands from foreign speakers who are not registered on the system to secure a voice control system is formed. The Mel-Frequency Cepstrum Coefficient (MFCC) method, capable of capturing the characteristics of different human voices and is unique; the output of the MFCC is modeled and classified using GMM (Gaussian Mixture Model) on each cepstrum subject so that the modeling results can identify the voice of the speaker registered on the system listed or the voice of foreign speakers not registered with the system. The accuracy of the system built can identify the voice of the speaker registered on the system by 98.1% and reject the voice of the speaker who is not registered on the system by 91.6%. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Biometric technology is widely used to identify a smart home device controller with access control to the system. Sound Abstract is one of the biometric technologies used because human speech is different and unique. Generally, a smart home device controller based on sound can be controlled by everyone so that a speaker who should not have access rights to the system will still execute his voice command. The solution to this problem is a sound control system that can identify one speaker's voice with other speakers registered on the system to control smart home devices and reject commands from foreign speakers who are not registered on the system to secure a voice control system is formed. The Mel-Frequency Cepstrum Coefficient (MFCC) method, capable of capturing the characteristics of different human voices and is unique; the output of the MFCC is modeled and classified using GMM (Gaussian Mixture Model) on each cepstrum subject so that the modeling results can identify the voice of the speaker registered on the system listed or the voice of foreign speakers not registered with the system. The accuracy of the system built can identify the voice of the speaker registered on the system by 98.1% and reject the voice of the speaker who is not registered on the system by 91.6%. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Voice Delivery using the Visible Light Communication (VLC) Prototype on Line of Sight (LOS) Channels"
        ],
        "penulis":"Putri, Dewandari Adi Antika;Hambali, Akhmad;Sugesti, Erna Sri;Pamukti, Brian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Visible Light Communication (VLC) is the one of technologies used for 6th generation of telecommunications (6G), because it has a wide frequency spectrum, higher speed and safety. We have conducted an experiment using a prototype to transmit sound. Measurements were made by changing the receiving distance from 30 cm up to 300 cm in increments of 30 cm. We also shift the receiving device, so that it forms an angle 0\u00b0 up to 30\u00b0. This study analyzes the extent of changes in distance and angle to the measurement results. We use a Lux meter measurement of the light intensity received by the receiver. In addition, we also measure the ratio of the sound sent to the received by measuring dB meter. From the results of extensive testing, we got the result that the farther distance, then the sound quality is getting lower. For the 0\u00b0 angle obtained a propagation distance limit of up to 250 cm, 15\u00b0 angle 200 cm away and 30\u00b0 angle up to 150 cm. In addition, we also found that the magnitude of the angle shift decreased the intensity of the received light. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Visible Light Communication (VLC) is the one of technologies used for 6th generation of telecommunications (6G), because it has a wide frequency spectrum, higher speed and safety. We have conducted an experiment using a prototype to transmit sound. Measurements were made by changing the receiving distance from 30 cm up to 300 cm in increments of 30 cm. We also shift the receiving device, so that it forms an angle 0\u00b0 up to 30\u00b0. This study analyzes the extent of changes in distance and angle to the measurement results. We use a Lux meter measurement of the light intensity received by the receiver. In addition, we also measure the ratio of the sound sent to the received by measuring dB meter. From the results of extensive testing, we got the result that the farther distance, then the sound quality is getting lower. For the 0\u00b0 angle obtained a propagation distance limit of up to 250 cm, 15\u00b0 angle 200 cm away and 30\u00b0 angle up to 150 cm. In addition, we also found that the magnitude of the angle shift decreased the intensity of the received light. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Secure Microservices Deployment for Fog Computing Services in a Remote Office"
        ],
        "penulis":"Dewanta, Favian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Microservices deployment remains insecure because it relies on the knowledge of microservices'users against security aspects in some particular fog computing networks. As a consequence, the users need to carefully assess the vulnerability of the micorservices' deployment. In addition, the users have to ensure that transactions between microservices and fog computing server should be verified and protected against any potential attacks. This paper proposes secure microservices deployment for environment of fog computing services by establishing trusted and authenticated communicationchannel prior to engaging any transactions among all entities. The proposed method is lightweight due to employing one-way hash function and XOR operation. Eventually, performance evaluation shows that the method is secure against replay attack, offline guessing attack, impersonation attack, and ephemeral secret leakage attack. Moreover, the proposed scheme is more lightweight in terms of communication and computational cost with respect to the J-PAKE algorithm. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Microservices deployment remains insecure because it relies on the knowledge of microservices'users against security aspects in some particular fog computing networks. As a consequence, the users need to carefully assess the vulnerability of the micorservices' deployment. In addition, the users have to ensure that transactions between microservices and fog computing server should be verified and protected against any potential attacks. This paper proposes secure microservices deployment for environment of fog computing services by establishing trusted and authenticated communicationchannel prior to engaging any transactions among all entities. The proposed method is lightweight due to employing one-way hash function and XOR operation. Eventually, performance evaluation shows that the method is secure against replay attack, offline guessing attack, impersonation attack, and ephemeral secret leakage attack. Moreover, the proposed scheme is more lightweight in terms of communication and computational cost with respect to the J-PAKE algorithm. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Evaluation of Effectiveness and Cost of Machine Losses using Overall Equipment Effectiveness (OEE) and Overall Equipment Cost Loss (OECL) Methods, a case study on Toshiba CNC Machine"
        ],
        "penulis":"Dewi, Sarastya;Alhilman, Judi;Atmaji, Fransiskus Tatas Dwi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In a manufacturing company, the machine is one of the most important elements in their production process because machine failure can stop the production process. Therefore, the initial step to minimizing losses caused by machine failure can be done by evaluating the machine condition. Evaluation of machine performance is carried out by measuring the effectiveness of the machine with the Overall Equipment Effectiveness (OEE) method. Based on the calculation result, the OEE value of the machine is 68.63% and this value still under the Japanese Institute of Plant Maintenance standard. Six big losses analysis is performed to determine the biggest loss that affects the effectiveness of the machine. The result of six big losses calculation shows that the most influential factor for the low OEE value of the machine is Reduced Speed Loss (39.12%). Causal analysis with a fishbone diagram is done to find out the causes of the highly reduced speed loss. To calculate the equipment cost loss use the Overall Equipment Cost Loss (OECL) methods. The total of the overall equipment cost loss is IDR 849, 839, 947.53. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In a manufacturing company, the machine is one of the most important elements in their production process because machine failure can stop the production process. Therefore, the initial step to minimizing losses caused by machine failure can be done by evaluating the machine condition. Evaluation of machine performance is carried out by measuring the effectiveness of the machine with the Overall Equipment Effectiveness (OEE) method. Based on the calculation result, the OEE value of the machine is 68.63% and this value still under the Japanese Institute of Plant Maintenance standard. Six big losses analysis is performed to determine the biggest loss that affects the effectiveness of the machine. The result of six big losses calculation shows that the most influential factor for the low OEE value of the machine is Reduced Speed Loss (39.12%). Causal analysis with a fishbone diagram is done to find out the causes of the highly reduced speed loss. To calculate the equipment cost loss use the Overall Equipment Cost Loss (OECL) methods. The total of the overall equipment cost loss is IDR 849, 839, 947.53. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Classifying the Polarity of Online Media on the Indonesia Presidential Election 2019 Using Artificial Neural Network"
        ],
        "penulis":"Farisi, Muhammad Afif;Lhaksmana, Kemas M.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The 2019 presidential election is one of the mandatory national agendas that is covered by all of the mainstream news media in Indonesia. The function of news media as an information provider reaps criticism because they are suspected of having polarity towards certain candidates. In this paper, the polarity of news media is analyzed by performing sentiment assessment towards every news regarding each candidate. Since manual sentiment analysis is costly and time-consuming, because of the large amount of data that needs to be processed, we adopt a machine learning method to automate the sentiment analysis process. This research employs Artificial Neural Network (ANN) to classify scraped news texts from online media and TF-IDF weighting method for feature extraction. We found that the observed online media kompas.com, liputan tan6.com, republika.co.id, and tempo.co do not have significant polarity toward one of the candidates. In addition to ANN, we also compared other methods to investigate the appropriate methods for our dataset. Our experiment shows that on average, ANN obtains the best accuracy at 84.57%, compares to Decision Tree C4.5 (83.34%), Naive Bayes (SO.42%), and SVM (79.04%).  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The 2019 presidential election is one of the mandatory national agendas that is covered by all of the mainstream news media in Indonesia. The function of news media as an information provider reaps criticism because they are suspected of having polarity towards certain candidates. In this paper, the polarity of news media is analyzed by performing sentiment assessment towards every news regarding each candidate. Since manual sentiment analysis is costly and time-consuming, because of the large amount of data that needs to be processed, we adopt a machine learning method to automate the sentiment analysis process. This research employs Artificial Neural Network (ANN) to classify scraped news texts from online media and TF-IDF weighting method for feature extraction. We found that the observed online media kompas.com, liputan tan6.com, republika.co.id, and tempo.co do not have significant polarity toward one of the candidates. In addition to ANN, we also compared other methods to investigate the appropriate methods for our dataset. Our experiment shows that on average, ANN obtains the best accuracy at 84.57%, compares to Decision Tree C4.5 (83.34%), Naive Bayes (SO.42%), and SVM (79.04%).  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Appraising Personal Data Protection in Startup Companies in Financial Technology: A Case Study of ABC Corp"
        ],
        "penulis":"Rozi, Muhamad Fahru;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Financial Technology (fintech) has been immerged extensively in the last decade. In the realm of disruptive world, there are many areas in which startup companies are developing their business. There is always contradiction when dealing with innovation as core of digital disruption and how privacy remains as hot issues at the edge of everybody's talks. Internet plays important roles to sustain the trends. As rapidly growing country, 68% of Indonesian has access to the Internet. It drives startup companies on financial technology to innovate more and besides that they must comply to regulation in regard with personal data protection. This research aims to appraise how startup company on financial technology protect users' personal data. Personal data protection principles from international organization and Indonesian regulation regarding personal data protection are used to appraise how ABC Corp as a startup company that deliver financial technology service in Indonesian society. To ensure that its service is qualified and trustable, ABC Corp should be appraised using relevant criteria and qualitative approach. The results showed that most of regulations from sectorial supervising agency have been adhered by ABC Corp. The results bring meaningful insight to improve performance on personal data protection. They can became lessons for similar emerging startup companies in financial technology when acquiring their qualifications to protect users' personal data and keep their sustainability. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Financial Technology (fintech) has been immerged extensively in the last decade. In the realm of disruptive world, there are many areas in which startup companies are developing their business. There is always contradiction when dealing with innovation as core of digital disruption and how privacy remains as hot issues at the edge of everybody's talks. Internet plays important roles to sustain the trends. As rapidly growing country, 68% of Indonesian has access to the Internet. It drives startup companies on financial technology to innovate more and besides that they must comply to regulation in regard with personal data protection. This research aims to appraise how startup company on financial technology protect users' personal data. Personal data protection principles from international organization and Indonesian regulation regarding personal data protection are used to appraise how ABC Corp as a startup company that deliver financial technology service in Indonesian society. To ensure that its service is qualified and trustable, ABC Corp should be appraised using relevant criteria and qualitative approach. The results showed that most of regulations from sectorial supervising agency have been adhered by ABC Corp. The results bring meaningful insight to improve performance on personal data protection. They can became lessons for similar emerging startup companies in financial technology when acquiring their qualifications to protect users' personal data and keep their sustainability. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Design of Multicriteria Decision Making Tools for IT Project Selection: A Case from Software House"
        ],
        "penulis":"Soesanto R.P.;Tripiawan W.;Darmawan I.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information Technology as an enabler helps organization to improve business by gaining more competitive advantage, it plays a significant role for organization to compete. Many organizations sense the pressure to leverage their investment towards information system. Selecting the optimal portfolio of IT projects is becoming increasingly important as the dependency on IT for organizational performance increases. The purpose of this research is to design tools for IT project selection tools in the software house. Combination of Delphi, AHP, and Factor rating method is used to gain the prioritize of the projects. Agile method is used to develop the application. The application is built in web platform to help the organization decision. Future research can be done to consider more variables for choosing the right project for the organization. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information Technology as an enabler helps organization to improve business by gaining more competitive advantage, it plays a significant role for organization to compete. Many organizations sense the pressure to leverage their investment towards information system. Selecting the optimal portfolio of IT projects is becoming increasingly important as the dependency on IT for organizational performance increases. The purpose of this research is to design tools for IT project selection tools in the software house. Combination of Delphi, AHP, and Factor rating method is used to gain the prioritize of the projects. Agile method is used to develop the application. The application is built in web platform to help the organization decision. Future research can be done to consider more variables for choosing the right project for the organization. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The role of trust to enhance the recommendation system based on social network"
        ],
        "penulis":"Abd Alkhalec Tharwat, Muhammed E.;Jacob, Deden Witarsyah;Md Fudzee, Mohd Farhan;Kasim, Shahreen;Ramli, Azizul Azhar;Lubis, Muharman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Recommendation systems or recommender system (RSs) is one of the hottest topics nowadays, which is widely utilized to predict an item to the end-user based on his\/her preferences primary. Recommendation systems applied in many areas mainly in commercial applications. This work aims to collect evidence of utilizing social network information between users to enhance the quality of traditional recommendation system. It provides an overview of traditional and modern approaches used by RSs such as collaborative filter (CF) approach, content-based (CB) approach, and hybrid filter approach. CF is one of the most famous traditional approaches in RSs, which is facing many limitations due to the lack of information available during a performance such as Cold start, Sparsity and Shilling attack. Additionally, this content focused on the role of incorporating a trust relationship from the social network to enhance the weaknesses of CF and achieve better quality in the recommendation process. Trust-aware Recommendation Systems (TaRSs) is a modern approach proposed to overcome the limitations of CF recommendation system in a social network. The trust relationship between users can boost and enhance CF limitations. Many researchers are focusing on trust in the recommendation system but fewer works are highlighting the role of trust in the recommendation system. In the end, limitations, and open issues of the current picture of the recommendation system come across. \u00a9 2020, Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recommendation systems or recommender system (RSs) is one of the hottest topics nowadays, which is widely utilized to predict an item to the end-user based on his\/her preferences primary. Recommendation systems applied in many areas mainly in commercial applications. This work aims to collect evidence of utilizing social network information between users to enhance the quality of traditional recommendation system. It provides an overview of traditional and modern approaches used by RSs such as collaborative filter (CF) approach, content-based (CB) approach, and hybrid filter approach. CF is one of the most famous traditional approaches in RSs, which is facing many limitations due to the lack of information available during a performance such as Cold start, Sparsity and Shilling attack. Additionally, this content focused on the role of incorporating a trust relationship from the social network to enhance the weaknesses of CF and achieve better quality in the recommendation process. Trust-aware Recommendation Systems (TaRSs) is a modern approach proposed to overcome the limitations of CF recommendation system in a social network. The trust relationship between users can boost and enhance CF limitations. Many researchers are focusing on trust in the recommendation system but fewer works are highlighting the role of trust in the recommendation system. In the end, limitations, and open issues of the current picture of the recommendation system come across. \u00a9 2020, Insight Society."
        ]
    },
    {
        "judul":[
            "A practical method of accurate troubleshooting mechanism in the decision objective teaching type on the integrated landing system"
        ],
        "penulis":"Ema;Hendrarini N.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "An aircraft is a transportation system that works in conditions according to the standards. When an aircraft technician is aware of a system failure or damage, he must make the right decision to overcome the problems that occur. A relatively high level of accuracy decision making based is a necessary treat. This condition must be anticipated in aircraft vocational education. An integrated landing system is one of the subsystems on an aircraft that requires quick and precise handling if there are problems. A practical method that accommodates various concepts in troubleshooting is proposed to facilitate aircraft technicians' competence. This method performs standardization of troubleshooting steps in a particular algorithm so that it is more systematic. The appropriate validation and verification steps follow this troubleshooting mechanism to ensure that the system is up to standard. \u00a9 2020 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An aircraft is a transportation system that works in conditions according to the standards. When an aircraft technician is aware of a system failure or damage, he must make the right decision to overcome the problems that occur. A relatively high level of accuracy decision making based is a necessary treat. This condition must be anticipated in aircraft vocational education. An integrated landing system is one of the subsystems on an aircraft that requires quick and precise handling if there are problems. A practical method that accommodates various concepts in troubleshooting is proposed to facilitate aircraft technicians' competence. This method performs standardization of troubleshooting steps in a particular algorithm so that it is more systematic. The appropriate validation and verification steps follow this troubleshooting mechanism to ensure that the system is up to standard. \u00a9 2020 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "D-magic strongly regular graphs"
        ],
        "penulis":"Simanjuntak, Rinovia;Anuwiksa, Palton;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "For a set of distances D, a graph G on n vertices is said to be D-magic if there exists a bijection (Formula presented.) and a constant k such that for any vertex x, (Formula presented.) where (Formula presented.) is the D-neighbourhood set of x. In this paper we utilize spectra of graphs to characterize strongly regular graphs which are D-magic, for all possible distance sets D. In addition, we provide necessary conditions for distance regular graphs of diameter 3 to be {1}-magic. \u00a9 2020 The Author(s). Published with license by Taylor & Francis Group, LLC.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "For a set of distances D, a graph G on n vertices is said to be D-magic if there exists a bijection (Formula presented.) and a constant k such that for any vertex x, (Formula presented.) where (Formula presented.) is the D-neighbourhood set of x. In this paper we utilize spectra of graphs to characterize strongly regular graphs which are D-magic, for all possible distance sets D. In addition, we provide necessary conditions for distance regular graphs of diameter 3 to be {1}-magic. \u00a9 2020 The Author(s). Published with license by Taylor & Francis Group, LLC."
        ]
    },
    {
        "judul":[
            "Energy Consumption Performance on IEEE 802.11ah Networks with Station Grouping Scheme"
        ],
        "penulis":"Aminah A.S.;Perdana D.;Wahidah I.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Sending packages from the sender to the recipient at the station requires adequate resources. To ensure messages in the form of text, data, images, and videos are received in real-time, reliably, and flexibly, power performance with low energy consumption is required at the station. IEEE 802.11ah can be one of the wireless technologies to overcome this problem by saving low power consumption, the transmission range of 1 km and access points can reach 8191 stations. The purpose of this study was to determine the performance of energy-saving consumption by station grouping which is regulated in the regulation of the number of RAW slots. From the results of this study, energy savings were obtained by dividing the two groups when the station numbered 900 stations with an energy consumption of 8.105 joules while in one group with a smaller station scale the total energy consumption of 8.124 joules was obtained. The second scheme is by dividing slots (NRawSlot) to reduce energy consumption in large station capacities. The NRawSlot division is divided into seven-slot with energy consumption of 8,105 joules. It is proven that energy consumption is more efficient by grouping with more station capacity.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Sending packages from the sender to the recipient at the station requires adequate resources. To ensure messages in the form of text, data, images, and videos are received in real-time, reliably, and flexibly, power performance with low energy consumption is required at the station. IEEE 802.11ah can be one of the wireless technologies to overcome this problem by saving low power consumption, the transmission range of 1 km and access points can reach 8191 stations. The purpose of this study was to determine the performance of energy-saving consumption by station grouping which is regulated in the regulation of the number of RAW slots. From the results of this study, energy savings were obtained by dividing the two groups when the station numbered 900 stations with an energy consumption of 8.105 joules while in one group with a smaller station scale the total energy consumption of 8.124 joules was obtained. The second scheme is by dividing slots (NRawSlot) to reduce energy consumption in large station capacities. The NRawSlot division is divided into seven-slot with energy consumption of 8,105 joules. It is proven that energy consumption is more efficient by grouping with more station capacity.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Correspondence between bats population and terrestrial cave-dwelling arthropods community in tasikmalaya karst area"
        ],
        "penulis":"Kurniawan, Isma Dwi;Rahmadi, Cahyo;Caraka, Rezzy Eko;Rahman, Iman Aulia;Kinasih, Ida;Toharudin, Toni;Chen, Rung Ching;Lee, Youngjo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Trogloxenes particularly bats play an important role in subterranean habitat. They provide organic material and induce cave microclimate that influence cave-dwelling biota, including arthropods. This study aimed to learn how bats population influences cave-dwelling arthropods community. Data collections were performed in three caves which had different bats species in Tasikmalaya karst area namely Liang Boeh, Liang Seungit and Sarongge. We recorded bats population, guano production, physicochemical condition of caves passage, and arthropods community in each cave. All samplings were only conducted in the specific sites of the dark zone where bat populations were aggregated. Data indicated that Liang Boeh was inhibited by Hipposideros sp (\u00b1472 individuals), Liang Seungit by Pteripodidae and Miniopterus sp. (\u00b1188 individuals), and Sarongge by Rhinolophus sp. (\u00b11194 individuals). Guano production was positively correlated with bats population. Chemical compositions of soil were varying among bats species. Bats population strongly induced caves physicochemical condition. A total 15986 individuals of cave-dwelling arthropods belonging to 5 Classes and 18 Orders were recorded. Our result revealed that bats population determined arthropods community. Caves with greater bats population size and dominated by insectivorous species would potentially have greater diversity and abundance of cave-dwelling arthropods. \u00a9 2020 the author(s).",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Trogloxenes particularly bats play an important role in subterranean habitat. They provide organic material and induce cave microclimate that influence cave-dwelling biota, including arthropods. This study aimed to learn how bats population influences cave-dwelling arthropods community. Data collections were performed in three caves which had different bats species in Tasikmalaya karst area namely Liang Boeh, Liang Seungit and Sarongge. We recorded bats population, guano production, physicochemical condition of caves passage, and arthropods community in each cave. All samplings were only conducted in the specific sites of the dark zone where bat populations were aggregated. Data indicated that Liang Boeh was inhibited by Hipposideros sp (\u00b1472 individuals), Liang Seungit by Pteripodidae and Miniopterus sp. (\u00b1188 individuals), and Sarongge by Rhinolophus sp. (\u00b11194 individuals). Guano production was positively correlated with bats population. Chemical compositions of soil were varying among bats species. Bats population strongly induced caves physicochemical condition. A total 15986 individuals of cave-dwelling arthropods belonging to 5 Classes and 18 Orders were recorded. Our result revealed that bats population determined arthropods community. Caves with greater bats population size and dominated by insectivorous species would potentially have greater diversity and abundance of cave-dwelling arthropods. \u00a9 2020 the author(s)."
        ]
    },
    {
        "judul":[
            "The Function of PMO for successful program-project management in the bank company - A case study"
        ],
        "penulis":"Yana, Rika Rizki;Sasongko, Danarto Tri;Wardhana, Aditya Wisnu;Ilona, Kwee Felicia;Shihab, Muhammad Rifki;Ranti, Benny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this paper is to investigate the specific function of Program Management Office (PMO) to manage multiple Kaizen or improvement projects and how we can implement PMO with more effective and more efficient to deliver value, benefits and achieve business goal in bank company. Research indicate that project management become increasingly difficult to manage when multiple projects are many overlapping projects in a project-oriented company, the goal in a need for enhanced bank company controls to increase success rates. It caused with implementation of a system that help project management, the system named Project Management Office (PMO) that is essential for bank company that are project-oriented and faced many overlapping projects. The PMO with an essential model that will explain to us to have management system of multiple project effectively in a banking company. Using a case study in one of banking industry in Indonesia, to test the method of research found that PMO deliver excellent value for bank company. The survey result of PMO function saw that most of project stakeholders in banking company agreed to 5 (five) categories and 20 (twenty) specified of PMO function implementation to manage several banking projects excellent. based on the results of the questionnaire, stakeholders answered more agreeably with the function of PMO for success project management at bank company and it could answer to the question that the method has deliver benefit and create goals for project management office performance in bank company.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this paper is to investigate the specific function of Program Management Office (PMO) to manage multiple Kaizen or improvement projects and how we can implement PMO with more effective and more efficient to deliver value, benefits and achieve business goal in bank company. Research indicate that project management become increasingly difficult to manage when multiple projects are many overlapping projects in a project-oriented company, the goal in a need for enhanced bank company controls to increase success rates. It caused with implementation of a system that help project management, the system named Project Management Office (PMO) that is essential for bank company that are project-oriented and faced many overlapping projects. The PMO with an essential model that will explain to us to have management system of multiple project effectively in a banking company. Using a case study in one of banking industry in Indonesia, to test the method of research found that PMO deliver excellent value for bank company. The survey result of PMO function saw that most of project stakeholders in banking company agreed to 5 (five) categories and 20 (twenty) specified of PMO function implementation to manage several banking projects excellent. based on the results of the questionnaire, stakeholders answered more agreeably with the function of PMO for success project management at bank company and it could answer to the question that the method has deliver benefit and create goals for project management office performance in bank company.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The effect of easy perception and risk of users of financial technology services in smes of bandung, indonesia"
        ],
        "penulis":"Kartawinata, Budi Rustandi;Pradana, Mahir;Akbar, Aldi;Trenggana, Arlin Ferlina Mochamad;Cahyaningrum, Synthia Dewi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This research aims to the study of Ease and Risk Perceptions of users of Financial Technology services. This objective is motivated by the problems faced by MSME business actors in the City of Bandung who have used or are using Financial Technology services. In its use it is influenced by many factors,, in this study the factors are the Perception of Ease and Risk. Taking these two factors is based on the results of interviews with SMEs in the city of Bandung and is supported by data that has been collected. The method used in this research is to use quantitative methods with data analysis techniques used are descriptive analysis of multiple linear regression analysis. The population in this study amounted to 1.567 business actors, so in this study the sampling was carried out by purposive sampling method, namely obtaining a sample of 100 business actors. Based on the results of the research that has been done that (1) the respondent's response to the Ease of Perception is in the easy-to-use category (score 81.3%), (2) the respondent's response to the risk is in the fairly agreeable category (score 66.1% and (3) the respondent's response It can be concluded that the Ease and Risk Perception has a significant effect on Financial Technology service users with a score of 83%. These results support that Financial Technology can have a significant influence on MSME business actors in Bandung city . \u00a9 IEOM Society International.",
            "BHIPH2View detailsExpand Substance PBI-9393",
            "Powered by",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This research aims to the study of Ease and Risk Perceptions of users of Financial Technology services. This objective is motivated by the problems faced by MSME business actors in the City of Bandung who have used or are using Financial Technology services. In its use it is influenced by many factors,, in this study the factors are the Perception of Ease and Risk. Taking these two factors is based on the results of interviews with SMEs in the city of Bandung and is supported by data that has been collected. The method used in this research is to use quantitative methods with data analysis techniques used are descriptive analysis of multiple linear regression analysis. The population in this study amounted to 1.567 business actors, so in this study the sampling was carried out by purposive sampling method, namely obtaining a sample of 100 business actors. Based on the results of the research that has been done that (1) the respondent's response to the Ease of Perception is in the easy-to-use category (score 81.3%), (2) the respondent's response to the risk is in the fairly agreeable category (score 66.1% and (3) the respondent's response It can be concluded that the Ease and Risk Perception has a significant effect on Financial Technology service users with a score of 83%. These results support that Financial Technology can have a significant influence on MSME business actors in Bandung city . \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "Spanish muslims' halal food purchase intention"
        ],
        "penulis":"Pradana, Mahir;Huertas-Garc\u00eda, Rub\u00e9n;Marimon, Frederic;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this paper is to investigate the factors that influence purchase intention of halal food among Spanish Muslim consumers. Data were obtained from a survey of 228 consumers living in various regions of Spain, then analyzed using the partial least squares technique. Our results showed that product awareness does not have an effect on purchase intention while other constructs do, including the mediating effect of consumers' attitude towards halal label and moderating effect of religious involvement. This study thus contributes to the advancement of knowledge on factors that motivate the purchase intention of halal food. \u00a9 2020 Higuchi et al.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this paper is to investigate the factors that influence purchase intention of halal food among Spanish Muslim consumers. Data were obtained from a survey of 228 consumers living in various regions of Spain, then analyzed using the partial least squares technique. Our results showed that product awareness does not have an effect on purchase intention while other constructs do, including the mediating effect of consumers' attitude towards halal label and moderating effect of religious involvement. This study thus contributes to the advancement of knowledge on factors that motivate the purchase intention of halal food. \u00a9 2020 Higuchi et al."
        ]
    },
    {
        "judul":[
            "Clustering nodes and discretizing movement to increase the effectiveness of HEFA for a CVRP"
        ],
        "penulis":"Abdillah, Ubassy;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A Capacitated Vehicle Routing Problem (CVRP) is an important problem in transportation and industry. It is challenging to be solved using some optimization algorithms. Unfortunately, it is not easy to achieve a global optimum solution. Hence, many researchers use a combination of two or more optimization algorithms, which based on swarm intelligence methods, to overcome the drawbacks of the single algorithm. In this research, a CVRP optimization model, which contains two main processes of clustering and optimization, based on a discrete hybrid evolutionary firefly algorithm (DHEFA), is proposed. Some evaluations on three CVRP cases show that DHEFA produces an averaged effectiveness of 91.74%, which is much more effective than the original FA that gives mean effectiveness of 87.95%. This result shows that clustering nodes into several clusters effectively reduces the problem space, and the DHEFA quickly searches the optimum solution in those partial spaces. \u00a9 2020 Science and Information Organization.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A Capacitated Vehicle Routing Problem (CVRP) is an important problem in transportation and industry. It is challenging to be solved using some optimization algorithms. Unfortunately, it is not easy to achieve a global optimum solution. Hence, many researchers use a combination of two or more optimization algorithms, which based on swarm intelligence methods, to overcome the drawbacks of the single algorithm. In this research, a CVRP optimization model, which contains two main processes of clustering and optimization, based on a discrete hybrid evolutionary firefly algorithm (DHEFA), is proposed. Some evaluations on three CVRP cases show that DHEFA produces an averaged effectiveness of 91.74%, which is much more effective than the original FA that gives mean effectiveness of 87.95%. This result shows that clustering nodes into several clusters effectively reduces the problem space, and the DHEFA quickly searches the optimum solution in those partial spaces. \u00a9 2020 Science and Information Organization."
        ]
    },
    {
        "judul":[
            "Micro-Climate Control for Hydroponics in Greenhouses"
        ],
        "penulis":"Erfianto, Bayu;Rakhmatsyah, Andrian;Ariyanto, Endro;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Greenhouse is a building which one of them functions for cultivation. Greenhouse can help the plant growth process, but there can be differences climate that affect plant growth. By knowing the distribution of temperature and humidity, it can help the cultivation process. The next problem is how to control greenhouse conditions or commonly called micro-climate so that temperature and humidity can be maintained. To solve these problems, a system is used to determine the temperature and humidity distribution in a greenhouse and generate it in the form of a two-dimensional distribution map in the form of heatmap so that users can know the spread of temperature and humidity through the image. Based on temperature and humidity data can be used to control the micro-climate in a greenhouse so that the temperature and humidity of the greenhouse are maintained according to the needs of the plant. This system is built using a sprinkler to reduce the temperature and increase the humidity in the greenhouse, where the micro-climate control uses Fuzzy logic controller. The main results of this experiment are the temperature and humidity of the greenhouse can be controlled according to the needs of the plant.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Greenhouse is a building which one of them functions for cultivation. Greenhouse can help the plant growth process, but there can be differences climate that affect plant growth. By knowing the distribution of temperature and humidity, it can help the cultivation process. The next problem is how to control greenhouse conditions or commonly called micro-climate so that temperature and humidity can be maintained. To solve these problems, a system is used to determine the temperature and humidity distribution in a greenhouse and generate it in the form of a two-dimensional distribution map in the form of heatmap so that users can know the spread of temperature and humidity through the image. Based on temperature and humidity data can be used to control the micro-climate in a greenhouse so that the temperature and humidity of the greenhouse are maintained according to the needs of the plant. This system is built using a sprinkler to reduce the temperature and increase the humidity in the greenhouse, where the micro-climate control uses Fuzzy logic controller. The main results of this experiment are the temperature and humidity of the greenhouse can be controlled according to the needs of the plant.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Correlation of climate variability and burned area in borneo using clustering methods"
        ],
        "penulis":"Hidayati, Ishardina C.;Nalaratih, Novinda;Shabrina, Ayu;Wahyuni, Intan N.;Latifah, Arnida L.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The island of Borneo has faced seasonal forest fires for decades. This phenomenon is worsening during dry seasons, especially when droughts are concurrent with the El Ni\u00f1o-Southern Oscillation (ENSO) phenomenon. Climate is therefore one of the drivers of the fire phenomenon. This paper studies the relationship between climate variables, namely temperature, precipitation, relative humidity, and wind speed, and the occurrence of forest fire using two clustering methods, K-means and Fuzzy C-means (FCM) clustering methods. Borneo is clustered into four areas based on burned area data obtained from Global Fire Emission Data (GFED). It is also clustered according to the combinations of climate variables. Both methods reach the highest correlation between the climate variable and the burned area clusters in September. The K-means method gives a correlation of-0.54 while the FCM gives-0.55. In August until October, relative humidity provides the dominant correlation affecting burned area, even though an additional precipitation or wind variable slightly increases the correlation in the FCM method. In November, temperature largely contributed to the burned area by a positive correlation of 0.31 in K-means and 0.33 in FCM. The evaluation performance of the methods is conducted by an internal validation called the Silhouette index. Both methods have positive index values ranging from 0.39 to 0.69 and the maximum value is influenced by the wind cluster. This indicates that the clustering methods applied in this paper can identify one or a combination of climate variables into dense and well-separated clusters. \u00a9 2020, Hasanuddin University. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The island of Borneo has faced seasonal forest fires for decades. This phenomenon is worsening during dry seasons, especially when droughts are concurrent with the El Ni\u00f1o-Southern Oscillation (ENSO) phenomenon. Climate is therefore one of the drivers of the fire phenomenon. This paper studies the relationship between climate variables, namely temperature, precipitation, relative humidity, and wind speed, and the occurrence of forest fire using two clustering methods, K-means and Fuzzy C-means (FCM) clustering methods. Borneo is clustered into four areas based on burned area data obtained from Global Fire Emission Data (GFED). It is also clustered according to the combinations of climate variables. Both methods reach the highest correlation between the climate variable and the burned area clusters in September. The K-means method gives a correlation of-0.54 while the FCM gives-0.55. In August until October, relative humidity provides the dominant correlation affecting burned area, even though an additional precipitation or wind variable slightly increases the correlation in the FCM method. In November, temperature largely contributed to the burned area by a positive correlation of 0.31 in K-means and 0.33 in FCM. The evaluation performance of the methods is conducted by an internal validation called the Silhouette index. Both methods have positive index values ranging from 0.39 to 0.69 and the maximum value is influenced by the wind cluster. This indicates that the clustering methods applied in this paper can identify one or a combination of climate variables into dense and well-separated clusters. \u00a9 2020, Hasanuddin University. All rights reserved."
        ]
    },
    {
        "judul":[
            "Optimization of distance formula in k-nearest neighbor method"
        ],
        "penulis":"Lubis, Arif Ridho;Lubis, Muharman;Al-Khowarizmi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "K-Nearest Neighbor (KNN) is a method applied in classifying objects based on learning data that is closest to the object based on comparison between previous and current data. In the learning process, KNN calculates the distance of the nearest neighbor by applying the euclidean distance formula, while in other methods, optimization has been done on the distance formula by comparing it with the other similar in order to get optimal results. This study will discuss the calculation of the euclidean distance formula in KNN compared with the normalized euclidean distance, manhattan and normalized manhattan to achieve optimization results or optimal value in finding the distance of the nearest neighbor. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "K-Nearest Neighbor (KNN) is a method applied in classifying objects based on learning data that is closest to the object based on comparison between previous and current data. In the learning process, KNN calculates the distance of the nearest neighbor by applying the euclidean distance formula, while in other methods, optimization has been done on the distance formula by comparing it with the other similar in order to get optimal results. This study will discuss the calculation of the euclidean distance formula in KNN compared with the normalized euclidean distance, manhattan and normalized manhattan to achieve optimization results or optimal value in finding the distance of the nearest neighbor. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Influence of sputtering temperature of TiO2deposited onto reduced graphene oxide nanosheet as efficient photoanodes in dye-sensitized solar cells"
        ],
        "penulis":"Low, Foo Wah;Hock, Goh Chin;Kashif, Muhammad;Samsudin, Nurul Asma;Chau, Chien Fat;Utami, Amaliyah Rohsari Indah;Islam, Mohammad Aminul;Heah, Cheng Yong;Liew, Yun Ming;Lai, Chin Wei;Amin, Nowshad;Tiong, Sieh Kiong;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Renewable solar energy is the key target to reduce fossil fuel consumption, minimize global warming issues, and indirectly minimizes erratic weather patterns. Herein, the authors synthesized an ultrathin reduced graphene oxide (rGO) nanosheet with ~47 nm via an improved Hummer\u2019s method. The TiO2was deposited by RF sputtering onto an rGO nanosheet with a variation of temperature to enhance the photogenerated electron or charge carrier mobility transport for the photoanode component. The morphology, topologies, element composition, crystallinity as well as dye-sensitized solar cells\u2019 (DSSCs) performance were determined accordingly. Based on the results, FTIR spectra revealed presence of Ti-O-C bonds in every rGO-TiO2nanocomposite samples at 800 cm\u20131. Besides, XRD revealed that a broad peak of anatase TiO2was detected at ~25.4\u25e6after incorporation with the rGO. Furthermore, it was discovered that sputtering temperature of 120\u25e6C created a desired power conversion energy (PCE) of 7.27% based on the J-V plot. Further increase of the sputtering temperature to 160\u25e6C and 200\u25e6C led to excessive TiO2growth on the rGO nanosheet, thus resulting in undesirable charge recombination formed at the photoanode in the DSSC device. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Climate actionGoal 13",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Renewable solar energy is the key target to reduce fossil fuel consumption, minimize global warming issues, and indirectly minimizes erratic weather patterns. Herein, the authors synthesized an ultrathin reduced graphene oxide (rGO) nanosheet with ~47 nm via an improved Hummer\u2019s method. The TiO2was deposited by RF sputtering onto an rGO nanosheet with a variation of temperature to enhance the photogenerated electron or charge carrier mobility transport for the photoanode component. The morphology, topologies, element composition, crystallinity as well as dye-sensitized solar cells\u2019 (DSSCs) performance were determined accordingly. Based on the results, FTIR spectra revealed presence of Ti-O-C bonds in every rGO-TiO2nanocomposite samples at 800 cm\u20131. Besides, XRD revealed that a broad peak of anatase TiO2was detected at ~25.4\u25e6after incorporation with the rGO. Furthermore, it was discovered that sputtering temperature of 120\u25e6C created a desired power conversion energy (PCE) of 7.27% based on the J-V plot. Further increase of the sputtering temperature to 160\u25e6C and 200\u25e6C led to excessive TiO2growth on the rGO nanosheet, thus resulting in undesirable charge recombination formed at the photoanode in the DSSC device. \u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland."
        ]
    },
    {
        "judul":[
            "A study on the anxiety level of people related to the COVID-19 pandemic death cases: A case study of Jabodetabek region"
        ],
        "penulis":"Sofa, Gagar Asmara;Anugrah, Ananda F. S.;Nugraha, Yudhistira;Suherman, Alex L.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Since its first case appeared in Depok, West Java, COVID-19 had sent people into panic and anxious apprehension. This paper aims to perceive the anxiety level of people related to the deaths caused by the COVID-19 in Jabodetabek (Jakarta, Bogor, Depok, Tangerang, Bekasi). Factors such as socioeconomic vulnerability and human cognitive level (regarding COVID-19) are also perceived to play important roles in causing such anxiety. A total of 554 respondents have participated in this study. Results showed that respondents had a low level of death anxiety, remembering, and understanding cognitive levels, but had a high level of concern regarding their ability to fulfil their food needs and adequate healthcare access. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Reduced inequalitiesGoal 10",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Since its first case appeared in Depok, West Java, COVID-19 had sent people into panic and anxious apprehension. This paper aims to perceive the anxiety level of people related to the deaths caused by the COVID-19 in Jabodetabek (Jakarta, Bogor, Depok, Tangerang, Bekasi). Factors such as socioeconomic vulnerability and human cognitive level (regarding COVID-19) are also perceived to play important roles in causing such anxiety. A total of 554 respondents have participated in this study. Results showed that respondents had a low level of death anxiety, remembering, and understanding cognitive levels, but had a high level of concern regarding their ability to fulfil their food needs and adequate healthcare access. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The effects of mobile service quality and E-recovery service quality on e-satisfaction in bukalapak application users"
        ],
        "penulis":"Hidayah, Riski Taufik;Tauwli, Muhammad Dzil Fadhli;Saefudin, Nugraha;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this study was to find out how much influence the quality of mobile-based services and the recovery of electronic services to the satisfaction of users of the Bukalapak trading application. The research uses descriptive methods and the method of verification with the population are consumers who have shopped with the Bukalapak buy and sell application represented by 200 respondents. The analytical method used is Rank Spearman correlation, coefficient of determination, and t test with a significance level of 5% with the use of IBM Statistics 24 SPSS software. The results showed that mobile service quality contributed to the effect of e-satisfaction by 60.84% and e recovery service quality contributed 43.03% to e-satisfaction. Some aspects that can be of concern are companies need to review and pay attention to speed in responding to complaints from consumers and allowance to users of the Bukalapak application as a sign of apology for the inconvenience of malfunctions of the application. \u00a9 2020, Hampstead Psychological Associates. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this study was to find out how much influence the quality of mobile-based services and the recovery of electronic services to the satisfaction of users of the Bukalapak trading application. The research uses descriptive methods and the method of verification with the population are consumers who have shopped with the Bukalapak buy and sell application represented by 200 respondents. The analytical method used is Rank Spearman correlation, coefficient of determination, and t test with a significance level of 5% with the use of IBM Statistics 24 SPSS software. The results showed that mobile service quality contributed to the effect of e-satisfaction by 60.84% and e recovery service quality contributed 43.03% to e-satisfaction. Some aspects that can be of concern are companies need to review and pay attention to speed in responding to complaints from consumers and allowance to users of the Bukalapak application as a sign of apology for the inconvenience of malfunctions of the application. \u00a9 2020, Hampstead Psychological Associates. All rights reserved."
        ]
    },
    {
        "judul":[
            "Performance analysis of software defined network using intent monitor and reroute method on ONOS controller"
        ],
        "penulis":"Monika, Putri;Negara, Ridha Muldina;Sanjoyo, Danu Dwi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Software Defined Network (SDN) provides high service flexibility to optimize network configuration based on network traffic. Traffic management able to solve traffic density in SDN. However, it will misuse the network bandwidth and links. One variant of the SDN controller, namely Open Network Operating System (ONOS), provides an Intent Monitor and Reroute (IMR) method that can optimize traffic management based on the description of an object in the ONOS application. This method can optimize the network bandwidth and links of SDN. The IMR can monitor the network and reconfigure the network to restore network connectivity by maximizing the use of each link when transmitting data. This study examines the impact of using IMR with a custom topology on ONOS to find the best scenario by performing traffic management on a data plane consisting of switches totaling 8-12 switches. The parameters measured in this study are bandwidth usage and quality of service (QoS). The results obtained in this study are IMR able to optimize the use of each link and maximize bandwidth usage in a network when distributing data and following TIPHON standards. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Software Defined Network (SDN) provides high service flexibility to optimize network configuration based on network traffic. Traffic management able to solve traffic density in SDN. However, it will misuse the network bandwidth and links. One variant of the SDN controller, namely Open Network Operating System (ONOS), provides an Intent Monitor and Reroute (IMR) method that can optimize traffic management based on the description of an object in the ONOS application. This method can optimize the network bandwidth and links of SDN. The IMR can monitor the network and reconfigure the network to restore network connectivity by maximizing the use of each link when transmitting data. This study examines the impact of using IMR with a custom topology on ONOS to find the best scenario by performing traffic management on a data plane consisting of switches totaling 8-12 switches. The parameters measured in this study are bandwidth usage and quality of service (QoS). The results obtained in this study are IMR able to optimize the use of each link and maximize bandwidth usage in a network when distributing data and following TIPHON standards. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Energy Saving Management with Suggestion Method in Home Automation based on User Habits"
        ],
        "penulis":"Nurfadilah, Muhammad Fahmi;Hariyanto, Nurman;Prihatmanto, Ary Setijadi;Darmakusuma, Reza;Wijaya, Rifki;Pratama, Vitradisa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In designing an automation system to help make it easier for humans to control and monitor household appliances or smart houses often experience problems with the problem of estimating the increasing burden of electric current because it uses additional tools to control the household appliances. To reduce this view, it can be solved by regulating the energy to be consumed from the household appliance by using a smart meter as a monitoring device specifically designed with excess internet to send data taken from the energy meter and then the incoming data can be processed analyzed from the peak current demand of electric current using the User Habits method which will be combined with the energy scheduling method and combined with suggestion turning on or off the household appliances, so that it is expected to provide comfort and effectiveness in using Home Automation. Effectiveness means that all home appliances or intruments must be running properly first, such as KWH meters, the lamp, switches, dispensers, mini server (local saving), and data center (global saving). And then, after the effectiveness has been running good or smooth the author continues his research into efficiency, namely an energy saving mode with an energy management process based on user habits.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In designing an automation system to help make it easier for humans to control and monitor household appliances or smart houses often experience problems with the problem of estimating the increasing burden of electric current because it uses additional tools to control the household appliances. To reduce this view, it can be solved by regulating the energy to be consumed from the household appliance by using a smart meter as a monitoring device specifically designed with excess internet to send data taken from the energy meter and then the incoming data can be processed analyzed from the peak current demand of electric current using the User Habits method which will be combined with the energy scheduling method and combined with suggestion turning on or off the household appliances, so that it is expected to provide comfort and effectiveness in using Home Automation. Effectiveness means that all home appliances or intruments must be running properly first, such as KWH meters, the lamp, switches, dispensers, mini server (local saving), and data center (global saving). And then, after the effectiveness has been running good or smooth the author continues his research into efficiency, namely an energy saving mode with an energy management process based on user habits.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Electronic nose for detecting multilevel diabetes using optimized deep neural network"
        ],
        "penulis":"Sarno, Riyanarto;Izza Sabilla, Shoffi;Rahman Wijaya, Dedy;Hariyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Diabetes is a chronic disease which is still a major issue in the world. The common testing methods generally used to detect diabetes are urine dipstick, laboratory blood tests, and blood glucose monitors. However, those testing procedures are often perceived as painful and inconvenient for the patients. In this context, this study proposes an electronic nose (e-nose) for detecting three classes of diabetes (healthy, prediabetes, and diabetes) based on a patient breath. The proposed e-nose system is called DENS, which utilizes an optimized deep neural network for the classiflcation. DENS also attempts to enhance accuracy and to reduce the error rate from previous studies. Therefore, this paper has three contributions: (i) the optimal gas sensors for capturing patient breaths; (ii) the optimal signal preprocessing; (iii) the fine-tuned parameters of deep neural network (DNN) for classifying multilevel diabetes. The proposed system successfully detected multilevel diabetes with an accuracy of 96.29% and showed a minimum classiflcation error of 0.050. \u00a9 2020, International Association of Engineers. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Diabetes is a chronic disease which is still a major issue in the world. The common testing methods generally used to detect diabetes are urine dipstick, laboratory blood tests, and blood glucose monitors. However, those testing procedures are often perceived as painful and inconvenient for the patients. In this context, this study proposes an electronic nose (e-nose) for detecting three classes of diabetes (healthy, prediabetes, and diabetes) based on a patient breath. The proposed e-nose system is called DENS, which utilizes an optimized deep neural network for the classiflcation. DENS also attempts to enhance accuracy and to reduce the error rate from previous studies. Therefore, this paper has three contributions: (i) the optimal gas sensors for capturing patient breaths; (ii) the optimal signal preprocessing; (iii) the fine-tuned parameters of deep neural network (DNN) for classifying multilevel diabetes. The proposed system successfully detected multilevel diabetes with an accuracy of 96.29% and showed a minimum classiflcation error of 0.050. \u00a9 2020, International Association of Engineers. All rights reserved."
        ]
    },
    {
        "judul":[
            "PowerDoW (Power Digital Offset Weightage): Video ContentAdaptation (VCA) Profiling in Smartphone Devices for Energy Efficiency"
        ],
        "penulis":"Jofri, Muhammad Hanif;Lubis, Muharman;Fudzee, Mohd Farhan Md;Kasim, Shahreen;Ismail, Mohd Norasri;Witarsyah, Deden;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, the rapid enhancement of Internet connectivity and the recent progression of smartphone technologies lead to better smartphones quality towards video streaming activity. With the massive production of smartphone devices today, motivate studies of energy consumption behaviors to extend the smartphone device battery-life. Therefore, existing designs for smartphone devices occasionally lack energy-aware thus it need profiling optimization technique that reduces energy usage. Energy profiling in smartphone devices is one of the practical criteria for saving energy in smartphone devices during video streaming session. Energy efficiency features for smartphone devices, profiling and video content adaptation approach are the most critical parts for the energyefficient while streaming in course. However, the consideration of energy-aware profiling area has not yet been discovered widely. In this case, appointing promising approaches will be used to reduce energy consumption in the smartphone devices during video streaming session. A framework called PowerDoW will be benefited towards adding energy adaptation strategies. PowerDoW framework manage and utilize system profiling status to attain the entire streaming session activity and classify the streaming video format depending on the selective video parameter. Selection of the best quality depending on low energy usage will be determined in the profiling experimentation. The experimentations are based on the Android operating system in smartphone devices\u2014 instrumentation setup testing by using PowerTutor application to measure energy consumption in real-time. The result indicates that PowerDoW framework can reduce a huge energy consumption by selecting suitable video content adaptation during video streaming session. \u00a9 2020. All Rights Reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, the rapid enhancement of Internet connectivity and the recent progression of smartphone technologies lead to better smartphones quality towards video streaming activity. With the massive production of smartphone devices today, motivate studies of energy consumption behaviors to extend the smartphone device battery-life. Therefore, existing designs for smartphone devices occasionally lack energy-aware thus it need profiling optimization technique that reduces energy usage. Energy profiling in smartphone devices is one of the practical criteria for saving energy in smartphone devices during video streaming session. Energy efficiency features for smartphone devices, profiling and video content adaptation approach are the most critical parts for the energyefficient while streaming in course. However, the consideration of energy-aware profiling area has not yet been discovered widely. In this case, appointing promising approaches will be used to reduce energy consumption in the smartphone devices during video streaming session. A framework called PowerDoW will be benefited towards adding energy adaptation strategies. PowerDoW framework manage and utilize system profiling status to attain the entire streaming session activity and classify the streaming video format depending on the selective video parameter. Selection of the best quality depending on low energy usage will be determined in the profiling experimentation. The experimentations are based on the Android operating system in smartphone devices\u2014 instrumentation setup testing by using PowerTutor application to measure energy consumption in real-time. The result indicates that PowerDoW framework can reduce a huge energy consumption by selecting suitable video content adaptation during video streaming session. \u00a9 2020. All Rights Reserved."
        ]
    },
    {
        "judul":[
            "Compressive sampling with multiple bit spread spectrum-based data hiding"
        ],
        "penulis":"Budiman, Gelar;Suksmono, Andriyan Bayu;Danudirdjo, Donny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We propose a novel data hiding method in an audio host with a compressive sampling technique. An over-complete dictionary represents a group of watermarks. Each row of the dictionary is a Hadamard sequence representing multiple bits of the watermark. Then, the singular values of the segment-based host audio in a diagonal matrix are multiplied by the over-complete dictionary, producing a lower size matrix. At the same time, we embed the watermark into the compressed audio. In the detector, we detect the watermark and reconstruct the audio. This proposed method offers not only hiding the information, but also compressing the audio host. The application of the proposed method is broadcast monitoring and biomedical signal recording. We can mark and secure the signal content by hiding the watermark inside the signal while we compress the signal for memory efficiency. We evaluate the performance in terms of payload, compression ratio, audio quality, and watermark quality. The proposed method can hide the data imperceptibly, in the range of 729-5292 bps, with a compression ratio 1.47-4.84, and a perfectly detected watermark. \u00a9 2020 by the authors.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We propose a novel data hiding method in an audio host with a compressive sampling technique. An over-complete dictionary represents a group of watermarks. Each row of the dictionary is a Hadamard sequence representing multiple bits of the watermark. Then, the singular values of the segment-based host audio in a diagonal matrix are multiplied by the over-complete dictionary, producing a lower size matrix. At the same time, we embed the watermark into the compressed audio. In the detector, we detect the watermark and reconstruct the audio. This proposed method offers not only hiding the information, but also compressing the audio host. The application of the proposed method is broadcast monitoring and biomedical signal recording. We can mark and secure the signal content by hiding the watermark inside the signal while we compress the signal for memory efficiency. We evaluate the performance in terms of payload, compression ratio, audio quality, and watermark quality. The proposed method can hide the data imperceptibly, in the range of 729-5292 bps, with a compression ratio 1.47-4.84, and a perfectly detected watermark. \u00a9 2020 by the authors."
        ]
    },
    {
        "judul":[
            "Effect of honey variation on blood glucose level in pregnant wistar rats (Rattus norvegicus)"
        ],
        "penulis":"Syarifuddin, Syarifuddin;Hadju, Veny;Inriasari, Rahayu;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "BACKGROUND: In addition to Moringa one of the food products that are often used as supplements is honey. Honey contains carbohydrates and content of antioxidants and other active substances needed during pregnancy. AIM: This study aimed to look at the effect of the intervention on the blood glucose levels of normal white pregnant Wistar strain of Moringa honey, honey plus Moringa or natural honey interventions. METHODS: This research method uses a quantitative research with experimental lab research type. With a completely randomized pre-test-post-test controlled completely randomized research design. The samples in this study were 24 white Wistar pregnant rats, divided into four groups, the control group, the honey group, the honey plus Moringa group, and the Moringa honey group, each consisting of six animals. The intervention was carried out for 20 days with initial BB measurements pregnancy (pre) and end of pregnancy (post). Data analysis used paired t-test and one-way ANOVA test. RESULTS: GD levels showed a significant decrease in GD levels in all groups at the end of pregnancy with a p < 0.05, but a decrease in GD levels between groups did not show a significant difference at the end of the study, the control group (82.33 \u00b1 8.98), honey (83.83 \u00b1 6.67), plus honey (73.17 \u00b1 10.92), and Moringa honey (73.00 \u00b1 6.45) with a p = 0.065 > 0.05. CONCLUSION: It shows that honey variation has the effect of controlling blood glucose levels during pregnancy. \u00a9 2020 Syarifuddin Syarifuddin, Veny Hadju, Rahayu Inriasari.",
            "OHHOOHOHOHOHHHHView detailsExpand Substance D-glucose",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "BACKGROUND: In addition to Moringa one of the food products that are often used as supplements is honey. Honey contains carbohydrates and content of antioxidants and other active substances needed during pregnancy. AIM: This study aimed to look at the effect of the intervention on the blood glucose levels of normal white pregnant Wistar strain of Moringa honey, honey plus Moringa or natural honey interventions. METHODS: This research method uses a quantitative research with experimental lab research type. With a completely randomized pre-test-post-test controlled completely randomized research design. The samples in this study were 24 white Wistar pregnant rats, divided into four groups, the control group, the honey group, the honey plus Moringa group, and the Moringa honey group, each consisting of six animals. The intervention was carried out for 20 days with initial BB measurements pregnancy (pre) and end of pregnancy (post). Data analysis used paired t-test and one-way ANOVA test. RESULTS: GD levels showed a significant decrease in GD levels in all groups at the end of pregnancy with a p < 0.05, but a decrease in GD levels between groups did not show a significant difference at the end of the study, the control group (82.33 \u00b1 8.98), honey (83.83 \u00b1 6.67), plus honey (73.17 \u00b1 10.92), and Moringa honey (73.00 \u00b1 6.45) with a p = 0.065 > 0.05. CONCLUSION: It shows that honey variation has the effect of controlling blood glucose levels during pregnancy. \u00a9 2020 Syarifuddin Syarifuddin, Veny Hadju, Rahayu Inriasari."
        ]
    },
    {
        "judul":[
            "Enhancing the economic potential of indigenous people in the Jababeka industrial area through corporate social responsibility"
        ],
        "penulis":"Yunus, Ulani;Sumbogo, Tri Adi;Mahestu, Gayes;Zulqarnain, Wajid;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Jababeka is a brand of an industrial area located in Cikarang, Bekasi Regency, West Java Province, Indonesia. The purpose of this study was to find how were the CSR programs of the tenants of Jababeka could enhance the economic potential of indigenous peoples. The methodology used descriptive qualitative research. Data collection technique used were interviews, literature, and observations. The results showed that Jababeka used CSR as continuous improvements in succession planning to support company performance excellent. Jababeka CSR program such as Economic, Fellowship, and Environmental. Economic pillar relates to improving the quality of human resources through entrepreneurship training and micro-finance, as well as community empowerment and economic improvement through the provision of assistance in the form of revolving capital, farm or business equipment, including mentoring. This research concluded that CSR Program of tenants could enhance the economic potential of indigenous peoples through Jababeka CSR program especially in training of entrepreneurship and be mentoring in business. The selection of the program was based on the type of products owned by tenant and the practical way of economic empowerment of local communities such as opening a beauty salon of L'Oreal products. \u00a9 Universiti Putra Malaysia Press",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1Zero hungerGoal 2Decent work and economic growthGoal 8Peace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Jababeka is a brand of an industrial area located in Cikarang, Bekasi Regency, West Java Province, Indonesia. The purpose of this study was to find how were the CSR programs of the tenants of Jababeka could enhance the economic potential of indigenous peoples. The methodology used descriptive qualitative research. Data collection technique used were interviews, literature, and observations. The results showed that Jababeka used CSR as continuous improvements in succession planning to support company performance excellent. Jababeka CSR program such as Economic, Fellowship, and Environmental. Economic pillar relates to improving the quality of human resources through entrepreneurship training and micro-finance, as well as community empowerment and economic improvement through the provision of assistance in the form of revolving capital, farm or business equipment, including mentoring. This research concluded that CSR Program of tenants could enhance the economic potential of indigenous peoples through Jababeka CSR program especially in training of entrepreneurship and be mentoring in business. The selection of the program was based on the type of products owned by tenant and the practical way of economic empowerment of local communities such as opening a beauty salon of L'Oreal products. \u00a9 Universiti Putra Malaysia Press"
        ]
    },
    {
        "judul":[
            "Classification of Tajweed Al-Qur'an on Images Applied Varying Normalized Distance Formulas"
        ],
        "penulis":"Khowarizmi, Al;Akhm;Lubis, Muharman;Lubis, Arif Ridho;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Al-Qur'an is a Muslim holy book which is written originally in Arabic where the way of reading it should be aligned with the pronunciation and spelling of the messenger and companion in the time of revelation. It is very important to follow the rule of its reading to avoid misinterpretation of the verses, which the existence of artificial neural networks and image processing can be used to classify various type of Tajweed as the reading discipline of Al-Quran in order to support the readers in term of pronunciation and interpretation. In this classification, the recitation of Al-Qur'an in the form of a number of normalized distance formulas in order to obtain the right optimization for the classification namely normalized Manhattan distance which is consistent at a value <0.5 and one that is not applied in the case of Tajweed Al-Qur'an is normalized hamming distance because the value generated is 1. \u00a9 2020 ACM.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Al-Qur'an is a Muslim holy book which is written originally in Arabic where the way of reading it should be aligned with the pronunciation and spelling of the messenger and companion in the time of revelation. It is very important to follow the rule of its reading to avoid misinterpretation of the verses, which the existence of artificial neural networks and image processing can be used to classify various type of Tajweed as the reading discipline of Al-Quran in order to support the readers in term of pronunciation and interpretation. In this classification, the recitation of Al-Qur'an in the form of a number of normalized distance formulas in order to obtain the right optimization for the classification namely normalized Manhattan distance which is consistent at a value <0.5 and one that is not applied in the case of Tajweed Al-Qur'an is normalized hamming distance because the value generated is 1. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Extraction Dependency Based on Evolutionary Requirement Using Natural Language Processing"
        ],
        "penulis":"Asyrofi, Rakha;Siahaan, Daniel Oranova;Priyadi, Yudi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Changes in requirements are one of the critical problems that occur during requirement specification. A change in a requirement could trigger changes in other requirements. Thus the identification process requirement to respond and correct the truth, realistic, require, specific, measurable aspects. Previous work has focused on building a model of interdependency between the requirements. This study proposes a method to identify dependencies among requirements. The dependency relations refer to evolutionary requirements. The technique uses natural language processing to extract dependency relations. This research analyzes how to obtain feature extractions by including the following: 1) Gathering requirements statement from the SRS document, 2) Identifying dependencies between requirements, 3) Developing interdependency extraction methods and, 4) Modeling of the interdependency requirement. The expectation of this experiment indicates the interdependency graph model. This graph defines the interdependency in the (Software Requirement Specification) SRS document. This method gathers interdependency between SRS document requirements such as PART OF, AND, OR, XOR. Therefore, getting the feature extraction to identify the interdependency requirement will be useful for solving specified requirements changing.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Changes in requirements are one of the critical problems that occur during requirement specification. A change in a requirement could trigger changes in other requirements. Thus the identification process requirement to respond and correct the truth, realistic, require, specific, measurable aspects. Previous work has focused on building a model of interdependency between the requirements. This study proposes a method to identify dependencies among requirements. The dependency relations refer to evolutionary requirements. The technique uses natural language processing to extract dependency relations. This research analyzes how to obtain feature extractions by including the following: 1) Gathering requirements statement from the SRS document, 2) Identifying dependencies between requirements, 3) Developing interdependency extraction methods and, 4) Modeling of the interdependency requirement. The expectation of this experiment indicates the interdependency graph model. This graph defines the interdependency in the (Software Requirement Specification) SRS document. This method gathers interdependency between SRS document requirements such as PART OF, AND, OR, XOR. Therefore, getting the feature extraction to identify the interdependency requirement will be useful for solving specified requirements changing.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Fast and Accurate Fish Classification from Underwater Video using You only Look Once"
        ],
        "penulis":"Lathifah, Hasna Maudi;Novamizanti, Ledya;Rizal, Syamsul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia is a maritime country and one of the largest archipelago countries in the world. Indonesian fisheries have many types of fish in stock, this causes difficulties in introducing fish species directly. This study designed a fish species classification system using the You Only Look Once (YOLO) architecture. YOLO is an object detection method using a convolutional network that will only be just once. Unlike the convolutional networks in general that spend thousands of networks to obtain an image with computing that is long enough. The architecture of this work using YOLO9000. The dataset consists of 6 classes, that is banded butterflyfish, blue tang surgeonfish, barred hamlet, black side hawkfish, Arabian Picasso triggerfish, dan black margate grunt. System testing produces an accuracy of 92%, IoS 0.75, and 2.223 FPS using Adam optimizer. The proposed system model has good accuracy and fast detection time.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia is a maritime country and one of the largest archipelago countries in the world. Indonesian fisheries have many types of fish in stock, this causes difficulties in introducing fish species directly. This study designed a fish species classification system using the You Only Look Once (YOLO) architecture. YOLO is an object detection method using a convolutional network that will only be just once. Unlike the convolutional networks in general that spend thousands of networks to obtain an image with computing that is long enough. The architecture of this work using YOLO9000. The dataset consists of 6 classes, that is banded butterflyfish, blue tang surgeonfish, barred hamlet, black side hawkfish, Arabian Picasso triggerfish, dan black margate grunt. System testing produces an accuracy of 92%, IoS 0.75, and 2.223 FPS using Adam optimizer. The proposed system model has good accuracy and fast detection time.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Speech Age-Gender Classification Using Long Short-Term Memory"
        ],
        "penulis":"Nitisara, Galih Rahagi;Suyanto, Suyanto;Ramadhani, Kurniawan Nur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Recognizing the age and gender of a person with certainty from a media has a significant advantage. For example, the perpetrators recorded on a CCTV camera can be easily recognized, or someone used to lie about age on social media or job application applications can be easily detected. However, detecting the exact age of a person is still a tricky thing because of the quality media and the characteristics of the person who seems deceptive. In machine learning, the neural-based methods are commonly used for classification and recognition. However, age and gender classifications stillproduce unsatisfactory results, even age and gender classifications by speech are rarely discussed.Hence, the right approach is needed to create a good age and gender classification model. One of the solutions is using Recurrent Neural Network (RNN), which is made for sequential data like speech.In this paper, a speech age-gender classification model is developed using one of the popular RNN models called Long Short-Term Memory (LSTM). The experimental results show that the proposed model is trapped on the overfitting problem so that the accuracy of the testing set is lower than the training set. Regularization can reduce the difference between the accuracies of both training and testing sets but it cannot increase them. The data augmentation is able to slightly solve the overfitting problem. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recognizing the age and gender of a person with certainty from a media has a significant advantage. For example, the perpetrators recorded on a CCTV camera can be easily recognized, or someone used to lie about age on social media or job application applications can be easily detected. However, detecting the exact age of a person is still a tricky thing because of the quality media and the characteristics of the person who seems deceptive. In machine learning, the neural-based methods are commonly used for classification and recognition. However, age and gender classifications stillproduce unsatisfactory results, even age and gender classifications by speech are rarely discussed.Hence, the right approach is needed to create a good age and gender classification model. One of the solutions is using Recurrent Neural Network (RNN), which is made for sequential data like speech.In this paper, a speech age-gender classification model is developed using one of the popular RNN models called Long Short-Term Memory (LSTM). The experimental results show that the proposed model is trapped on the overfitting problem so that the accuracy of the testing set is lower than the training set. Regularization can reduce the difference between the accuracies of both training and testing sets but it cannot increase them. The data augmentation is able to slightly solve the overfitting problem. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "How to Integrate Enterprise Asset Management System for Smart Hospital: A Case Study"
        ],
        "penulis":"Saputra, Muhardi;Hermawan, Ikhsan;Puspitasari, Warih;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "XYZ Regional Public Hospital is one of the government-owned hospitals of Indonesia, XYZ regional public hospital has numerous patient and employee, yet it has not been supported by a good information system, there is no integrated system that helps the exchange of data between each sector in the hospital. Data exchange is done conventionally by using paper as a physical document. The archives of the document would cost a lot and spent wide space that made several rooms are filled with a pile of archives due to lack of space in the hospital. ERP is a concept that integrates all business process activities of an agency or company so that the processes that occur are mutually sustainable in achieving the goals of an organization, ERP provides a solution for managing complex data and information that runs in the hospital. This research is focusing on designing an ERP system in asset management of the warehousing sector in XYZ regional public hospital using Odoo on Asset Maintenance Module with Quickstart methodology. The result of this research is the ERP system that focused on how the asset maintenance is managed in the hospital and how it will be integrated with inventory sector. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "XYZ Regional Public Hospital is one of the government-owned hospitals of Indonesia, XYZ regional public hospital has numerous patient and employee, yet it has not been supported by a good information system, there is no integrated system that helps the exchange of data between each sector in the hospital. Data exchange is done conventionally by using paper as a physical document. The archives of the document would cost a lot and spent wide space that made several rooms are filled with a pile of archives due to lack of space in the hospital. ERP is a concept that integrates all business process activities of an agency or company so that the processes that occur are mutually sustainable in achieving the goals of an organization, ERP provides a solution for managing complex data and information that runs in the hospital. This research is focusing on designing an ERP system in asset management of the warehousing sector in XYZ regional public hospital using Odoo on Asset Maintenance Module with Quickstart methodology. The result of this research is the ERP system that focused on how the asset maintenance is managed in the hospital and how it will be integrated with inventory sector. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Prototype of In-Store Visitor and People Passing Counters using Single Shot Detector Performed by OpenCV"
        ],
        "penulis":"Herviana, Andes;Sudiharto, Dodi Wisaksono;Yulianto, Fazmah Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information related to the power hours of a mall or store is important. By typically knowing it, the manager of the store or the mall can wisely determine the staff planning decision. Without the right decision, it potentially decreases customer satisfaction. The decision can be defined by utilizing in-store visitors and people passing traffic patterns. The other problem also arises when the calculation of in-store visitors and people passing are executed manually, so it requires much effort. This study proposes a prototype design of the system which can automatically calculate visitors by utilizing Single Shot Detector (SSD) method. This method is performed by operating OpenCV library. It is used to detect a human object marked as in-store visitor or people passing. The embedded computer is conducted to process images captured by Pi Camera. Based on the study, the result accuracy is 65.08% for the system counts in-store visitors, and 66.12% for the system marks objects as people pass around in front of the store. Although the accuracy values obtained is not high, but all patterns show that the highest average values of in-store visitors and people passing occur on the days nearing weekend and also on the weekend, such as Friday, Saturday and Sunday. The peak time of in-store visitors (e.g. power hour) on Friday is between 12 PM and 1 PM. The peak time of in-store visitors on Saturday is between 3 PM and 4 PM, and on Monday, it is between 4 PM and 5 PM.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information related to the power hours of a mall or store is important. By typically knowing it, the manager of the store or the mall can wisely determine the staff planning decision. Without the right decision, it potentially decreases customer satisfaction. The decision can be defined by utilizing in-store visitors and people passing traffic patterns. The other problem also arises when the calculation of in-store visitors and people passing are executed manually, so it requires much effort. This study proposes a prototype design of the system which can automatically calculate visitors by utilizing Single Shot Detector (SSD) method. This method is performed by operating OpenCV library. It is used to detect a human object marked as in-store visitor or people passing. The embedded computer is conducted to process images captured by Pi Camera. Based on the study, the result accuracy is 65.08% for the system counts in-store visitors, and 66.12% for the system marks objects as people pass around in front of the store. Although the accuracy values obtained is not high, but all patterns show that the highest average values of in-store visitors and people passing occur on the days nearing weekend and also on the weekend, such as Friday, Saturday and Sunday. The peak time of in-store visitors (e.g. power hour) on Friday is between 12 PM and 1 PM. The peak time of in-store visitors on Saturday is between 3 PM and 4 PM, and on Monday, it is between 4 PM and 5 PM.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Rateless raptor codes for reliable wireless capsule endoscopy (WCE)"
        ],
        "penulis":"Sobiroh, Indriana Fitriotavia Endah;Anwar, Khoirul;Mukhtar, Husneni;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Wireless Capsule Endoscopy (WCE) has established as painless endoscopic imaging of the gastrointestinal (GI) tract To improve the performance of video transfer, we propose a rateless Raptor coding scheme with low coding rate to overcome the potential interference from other signals due to the low-power transmission characteristic of the WCE communications. In addition, the proposed Raptor codes with rateless capability can protect the information from error under varying channel conditions between capsule and the receiver outside the body. The proposed Raptor codes are constructed from Low-Density Parity Check (LDPC) and Luby Transform (LT) codes suitable for short block length of WCE applications such that the rateless capability of the codes can adapt to the dynamic GI channel modeled by multipath In-Body-to-On-Body (IB-to-OB) ultra wide band (UWB) channels in the 3.4-4.8 GHz. We also evaluate the performance of the codes under the multipath channel model for WCE using Cyclic-Prefix Orthogonal Frequency Division Multiplexing (CP-OFDM) in terms of average bit error rate (BER) using a series of computer simulations. The results confirmed that the proposed rateless Raptor codes can adapt well to the dynamic changes of channel conditions and are suitable for practical reliable WCE applications. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Wireless Capsule Endoscopy (WCE) has established as painless endoscopic imaging of the gastrointestinal (GI) tract To improve the performance of video transfer, we propose a rateless Raptor coding scheme with low coding rate to overcome the potential interference from other signals due to the low-power transmission characteristic of the WCE communications. In addition, the proposed Raptor codes with rateless capability can protect the information from error under varying channel conditions between capsule and the receiver outside the body. The proposed Raptor codes are constructed from Low-Density Parity Check (LDPC) and Luby Transform (LT) codes suitable for short block length of WCE applications such that the rateless capability of the codes can adapt to the dynamic GI channel modeled by multipath In-Body-to-On-Body (IB-to-OB) ultra wide band (UWB) channels in the 3.4-4.8 GHz. We also evaluate the performance of the codes under the multipath channel model for WCE using Cyclic-Prefix Orthogonal Frequency Division Multiplexing (CP-OFDM) in terms of average bit error rate (BER) using a series of computer simulations. The results confirmed that the proposed rateless Raptor codes can adapt well to the dynamic changes of channel conditions and are suitable for practical reliable WCE applications. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Measurement of Criterion Weight to Determine Industrial Area Location Using AHP for Economic Growth"
        ],
        "penulis":"Chumaidiyah E.;Dewantoro M.D.R.;Hakimah D.A.;Arffan Z.;Robbi R.M.N.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Industrial area is an infrastructure for the process of industrialization as a source that can trigger economic growth. Industrial areas that are structured and can support production operations are an appeal to foreign investors. However, the development of industrial areas requires careful planning because it impacts on the environmental carrying capacity and land loss. Therefore, industrial area development needs attention to a variety of important criteria as considerations in determining the location of an industrial area. This study aims to determine the criteria and measure the importance of each relative criterion to other criteria. The method used is Analytical Hierarchy Process (AHP). The results show that there are four important factors that need to be considered with each of the importance level, namely Infrastructure by 33.97%, Distance to Access by 31.74%, Land Soil by 19.57%, and Production Factors by 14.72%. The four factors have ten important criteria that need to be considered in making decisions to determine the location of an industrial area where the two highest criteria are electricity infrastructure with a significance level of 19.05% and telecommunications infrastructure with an importance level of 14.92%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industrial area is an infrastructure for the process of industrialization as a source that can trigger economic growth. Industrial areas that are structured and can support production operations are an appeal to foreign investors. However, the development of industrial areas requires careful planning because it impacts on the environmental carrying capacity and land loss. Therefore, industrial area development needs attention to a variety of important criteria as considerations in determining the location of an industrial area. This study aims to determine the criteria and measure the importance of each relative criterion to other criteria. The method used is Analytical Hierarchy Process (AHP). The results show that there are four important factors that need to be considered with each of the importance level, namely Infrastructure by 33.97%, Distance to Access by 31.74%, Land Soil by 19.57%, and Production Factors by 14.72%. The four factors have ten important criteria that need to be considered in making decisions to determine the location of an industrial area where the two highest criteria are electricity infrastructure with a significance level of 19.05% and telecommunications infrastructure with an importance level of 14.92%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Modeling Traffic Flow on Buah Batu Exit Toll Gate Using Cellular Automata"
        ],
        "penulis":"Ketaren, Raymondo Fitrah;Danufane, Fadil Habibi;Kurniawan, Isman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the last decade, Bandung has become one of the tourism destination places in Indonesia. It is reported that almost 6.7 million visitors come to Bandung in 2018, and the number increased by almost 4% per year since 2014. This rise in the number of visitors leads to the establishment of several toll gates as main access points throughout the city. As one of the busiest ones, Buah Batu toll gate is frequently congested because of the location that is close to the southern part of Bandung. To overcome this problem, a traffic regulation based on computer simulation is urgently required. In this study, we simulate the traffic system on the Buah Batu toll gate by using a combination of Nagel-Schreckenberg (NaSch) and Daoudia and Moussa (DM) models. NaSch model was used to defined vehicle movement, while the DM model was used to allow a vehicle to change lane. We defined three scenarios to evaluate the effectivity of the closing gate scheme. We found that the closing of gate 5 is more effective than the closing of gate 1. We also investigated the contribution of traffic density and driver's behavior, e.g., stopping behavior and lane-changing behavior, to the average velocity of the vehicles.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the last decade, Bandung has become one of the tourism destination places in Indonesia. It is reported that almost 6.7 million visitors come to Bandung in 2018, and the number increased by almost 4% per year since 2014. This rise in the number of visitors leads to the establishment of several toll gates as main access points throughout the city. As one of the busiest ones, Buah Batu toll gate is frequently congested because of the location that is close to the southern part of Bandung. To overcome this problem, a traffic regulation based on computer simulation is urgently required. In this study, we simulate the traffic system on the Buah Batu toll gate by using a combination of Nagel-Schreckenberg (NaSch) and Daoudia and Moussa (DM) models. NaSch model was used to defined vehicle movement, while the DM model was used to allow a vehicle to change lane. We defined three scenarios to evaluate the effectivity of the closing gate scheme. We found that the closing of gate 5 is more effective than the closing of gate 1. We also investigated the contribution of traffic density and driver's behavior, e.g., stopping behavior and lane-changing behavior, to the average velocity of the vehicles.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Heuristic based on dynamic weighting to support diagnosis with two minimization focus in alignment incoherence repair"
        ],
        "penulis":"Husein, Inne Gartina;Sitohang, Benhard;Akbar, Saiful;Azizah, Fazat Nur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Ontology alignment is a collection of correspondences or mappings between entities from two ontologies being matched. Alignment is an essential data resource that used as a reference to build interlinking on Linked Data. Since it is produced by an ontology matching system, the good quality of alignment determines the good performance of the ontology matching system. The coherence of alignment is one of the success criteria of the ontology matching system so that some systems implement the alignment repair feature in it. This feature restores the incoherent to coherent by removing some mappings in alignment. Research of alignment incoherence stated that the repair process should have a minimum impact on alignment by minimizing the number of removed mappings and\/or minimizing the confidence value of removed mappings. The study discussed in this paper is alignment repair to restore coherent conditions with two minimization focus of diagnosis. In a repair system, the process of finding and removing a mapping to produce conflict-free alignment is called the diagnosis. We have been proven that conflict-free alignment is coherent alignment. The proposed repair system implements a dynamic weighting heuristic to guide the search for minimum removed mapping with two minimization focus, in order to produce conflict-free alignment. Experiment on 8 alignments shows that the current system which removes more mapping will produce conflict-free alignment, but does not support minimal impact. Conversely, the current system that removes minimal mapping does not support conflict-free alignment. The proposed system excels at producing conflict-free alignment with minimal impact. \u00a9 2020, School of Electrical Engineering and Informatics. All rights reserved.",
            "ONHOOView detailsExpand Substance 1,3-benzoxazine-2,4-dione",
            "Powered by",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ontology alignment is a collection of correspondences or mappings between entities from two ontologies being matched. Alignment is an essential data resource that used as a reference to build interlinking on Linked Data. Since it is produced by an ontology matching system, the good quality of alignment determines the good performance of the ontology matching system. The coherence of alignment is one of the success criteria of the ontology matching system so that some systems implement the alignment repair feature in it. This feature restores the incoherent to coherent by removing some mappings in alignment. Research of alignment incoherence stated that the repair process should have a minimum impact on alignment by minimizing the number of removed mappings and\/or minimizing the confidence value of removed mappings. The study discussed in this paper is alignment repair to restore coherent conditions with two minimization focus of diagnosis. In a repair system, the process of finding and removing a mapping to produce conflict-free alignment is called the diagnosis. We have been proven that conflict-free alignment is coherent alignment. The proposed repair system implements a dynamic weighting heuristic to guide the search for minimum removed mapping with two minimization focus, in order to produce conflict-free alignment. Experiment on 8 alignments shows that the current system which removes more mapping will produce conflict-free alignment, but does not support minimal impact. Conversely, the current system that removes minimal mapping does not support conflict-free alignment. The proposed system excels at producing conflict-free alignment with minimal impact. \u00a9 2020, School of Electrical Engineering and Informatics. All rights reserved."
        ]
    },
    {
        "judul":[
            "The Study of the Barriers to Digital Transformation in Higher Education: A Preliminary Investigation in Indonesia"
        ],
        "penulis":"Aditya, Bayu Rima;Ferdiana, Ridi;Kusumawardani, Sri Suning;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The implementation of digital transformation has been carried out in various industrial sectors, including the higher education sector. Many countries have considered changing their education system by doing digital transformation. Although digital transformation has the potential to improve the education system, developing countries still find it difficult to reap the benefits caused by certain barriers. The purpose of this study is to investigate the barriers faced when implementing digital transformation in higher education, in this case in Indonesia. The results of the questionnaire survey ensured that of the twenty-two barriers identified based on a literature review, eleven barriers significantly affecting the implementation of digital transformation in Indonesian higher education. This study contributes by revealing initial set barriers of digital transformation in the higher education sector. The findings of this study will help identify barriers that influence the direction of decision strategies for implementing digital transformation in higher education institutions in Indonesia. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The implementation of digital transformation has been carried out in various industrial sectors, including the higher education sector. Many countries have considered changing their education system by doing digital transformation. Although digital transformation has the potential to improve the education system, developing countries still find it difficult to reap the benefits caused by certain barriers. The purpose of this study is to investigate the barriers faced when implementing digital transformation in higher education, in this case in Indonesia. The results of the questionnaire survey ensured that of the twenty-two barriers identified based on a literature review, eleven barriers significantly affecting the implementation of digital transformation in Indonesian higher education. This study contributes by revealing initial set barriers of digital transformation in the higher education sector. The findings of this study will help identify barriers that influence the direction of decision strategies for implementing digital transformation in higher education institutions in Indonesia. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation Face Recognition Attendance Monitoring System for Lab Surveillance with Hash Encryption"
        ],
        "penulis":"Hamami F.;Dahlan I.A.;Prakosa S.W.;Somantri K.F.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Face recognition (FR) is becoming popular to identify people. In fact, using the FR scheme, surveillance tasks can be built by recognizing people from their faces. This paper presents the implementation of face recognition as a biometric method for smart attendance as well as we also proposed the integrated scheme from capturing data from edge devices (CCTVs), streaming data to the dedicated server, then presenting the real-time data through android mobile devices. In this scheme, we proposed to employ deep learning algorithms based on the Convolutional Neural Network (CNN). Throughthe CCTV data streaming, faces are captured and matched with the database. Therefore, it is considered as their logging attendance. Furthermore, it is marked and stored into the database. This system prototype is developed by big data technology to tackle this complexity of data. The recognized faces can be monitored in real time monitoring. Eventually, real time reports are delivered through the web and android device with API after the data transmission is secured with hash encryption. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Face recognition (FR) is becoming popular to identify people. In fact, using the FR scheme, surveillance tasks can be built by recognizing people from their faces. This paper presents the implementation of face recognition as a biometric method for smart attendance as well as we also proposed the integrated scheme from capturing data from edge devices (CCTVs), streaming data to the dedicated server, then presenting the real-time data through android mobile devices. In this scheme, we proposed to employ deep learning algorithms based on the Convolutional Neural Network (CNN). Throughthe CCTV data streaming, faces are captured and matched with the database. Therefore, it is considered as their logging attendance. Furthermore, it is marked and stored into the database. This system prototype is developed by big data technology to tackle this complexity of data. The recognized faces can be monitored in real time monitoring. Eventually, real time reports are delivered through the web and android device with API after the data transmission is secured with hash encryption. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Analysis of Overall Effectiveness on Hall Separator Punching Machine at PT. DNIA"
        ],
        "penulis":"Sriwana, Iphov Kumala;Syauqillah, Nadya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "PT. DNIA is a company engaged in manufacture of automotive parts, one of which is condenser. Manufacture of condenser components requires small parts produced using a hole separator punching machine. However, it deals with high downtime of the machine, resulting in low production performance. This research aimed to identify the extent of hole separator punching machine performance using analysis of Overall Equipment Effectiveness (OEE) and to analyse six big loses which impact on machine downtime. Calculation results show that OEE value obtained, 48.54%, was still below the standard, and therefore continuous improvement attempt is essential to perform. The low OEE value was a result of low performance efficiency which was caused by idling and minor stoppages of 24.54%. In order to improve the performance and carry out idling and minor stoppages loss, it is important to perform improvement attempt in a number of aspects, such as man aspect by training operators to carry machine-related works, machine aspect by repairing abnormal ups and downs of dies, and material aspect by fixing inappropriate position of header tank (material). \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "PT. DNIA is a company engaged in manufacture of automotive parts, one of which is condenser. Manufacture of condenser components requires small parts produced using a hole separator punching machine. However, it deals with high downtime of the machine, resulting in low production performance. This research aimed to identify the extent of hole separator punching machine performance using analysis of Overall Equipment Effectiveness (OEE) and to analyse six big loses which impact on machine downtime. Calculation results show that OEE value obtained, 48.54%, was still below the standard, and therefore continuous improvement attempt is essential to perform. The low OEE value was a result of low performance efficiency which was caused by idling and minor stoppages of 24.54%. In order to improve the performance and carry out idling and minor stoppages loss, it is important to perform improvement attempt in a number of aspects, such as man aspect by training operators to carry machine-related works, machine aspect by repairing abnormal ups and downs of dies, and material aspect by fixing inappropriate position of header tank (material). \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Measuring information credibility in social media using combination of user profile and message content dimensions"
        ],
        "penulis":"Setiawan, Erwin B.;Widyantoro, Dwi H.;Surendro, Kridanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information credibility in social media is becoming the most important part of information sharing in the society. The literatures have shown that there is no labeling information credibility based on user competencies and their posted topics. This paper increases the information credibility by adding new 17 features for Twitter and 49 features for Facebook. In the first step, we perform a labeling process based on user competencies and their posted topic to classify the users into two groups, credible and not credible users, regarding their posted topics. These approaches are evaluated over ten thousand samples of real-field data obtained from Twitter and Facebook networks using classification of Naive Bayes (NB), Support Vector Machine (SVM), Logistic Regression (Logit) and J48 Algorithm (J48). With the proposed new features, the credibility of information provided in social media is increasing significantly indicated by better accuracy compared to the existing technique for all classifiers. Copyright \u00a9 2020 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information credibility in social media is becoming the most important part of information sharing in the society. The literatures have shown that there is no labeling information credibility based on user competencies and their posted topics. This paper increases the information credibility by adding new 17 features for Twitter and 49 features for Facebook. In the first step, we perform a labeling process based on user competencies and their posted topic to classify the users into two groups, credible and not credible users, regarding their posted topics. These approaches are evaluated over ten thousand samples of real-field data obtained from Twitter and Facebook networks using classification of Naive Bayes (NB), Support Vector Machine (SVM), Logistic Regression (Logit) and J48 Algorithm (J48). With the proposed new features, the credibility of information provided in social media is increasing significantly indicated by better accuracy compared to the existing technique for all classifiers. Copyright \u00a9 2020 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "University Strategic System Engineering based on BAN PT Accreditation Criteria One using SysML and Semantic Approach"
        ],
        "penulis":"Aurachman, Rio;Putri, Ericha Mutia;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "An organizations business processes need to be precisely defined so that the organization does what it should do. Some quality standards such as BAN-PT and ISO 9001 Accreditation require organizations to carry out some process. Sometimes organizations find a difficulty to understand what processes need to be applied based on the standards. This study proposes a SysML and semantic method for analysing standard sentences and providing guidance on what needs to be applied to organizations. The trial was conducted on the Study Program Accreditation standard specifically criterion 1 on strategic management.. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Industry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An organizations business processes need to be precisely defined so that the organization does what it should do. Some quality standards such as BAN-PT and ISO 9001 Accreditation require organizations to carry out some process. Sometimes organizations find a difficulty to understand what processes need to be applied based on the standards. This study proposes a SysML and semantic method for analysing standard sentences and providing guidance on what needs to be applied to organizations. The trial was conducted on the Study Program Accreditation standard specifically criterion 1 on strategic management.. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Authentication system and method for improving security login without typing password"
        ],
        "penulis":"Darmawan, Irfan;Rahmatulloh, Alam;Rianto;Oriza, Ilman Hilmi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Authentication in the login process is an important thing that needs attention. The login process will involve a password that is owned by the user, while the password is private and confidential. If someone uses a weak password, the password is likely to be easily hacked. Authentication security needs to be improved, and hackers will get access to the login system with only a few attack techniques such as SQL Injection or sniffing techniques. Besides, the lack of awareness of users by creating weak passwords is easy to guess. Meanwhile, to create a strong password, consisting of upper-and lower-case letters, a combination of numbers and symbols, it is very difficult to remember. This is a very important problem in the login process. This study discusses the login authentication process that can perform login integration without typing a password, because passwords are generated repeatedly with the One Time Password (OTP) method, and use the Quick Response Code (QR) as its support. To disguise the data in the QR Code, which is applied by the Rivest-Shamir-Adleman (RSA) encryption algorithm, and will be tested on a web-based application. The login integration process, using the QR Code token application that runs on an android phone. Which functions as an OTP token generator, and a web-based application will read information from the QR Code token. The result is that with login authentication, this can increase the security and ease of the authentication process without typing a password. \u00a9 2020 Insight Society.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Authentication in the login process is an important thing that needs attention. The login process will involve a password that is owned by the user, while the password is private and confidential. If someone uses a weak password, the password is likely to be easily hacked. Authentication security needs to be improved, and hackers will get access to the login system with only a few attack techniques such as SQL Injection or sniffing techniques. Besides, the lack of awareness of users by creating weak passwords is easy to guess. Meanwhile, to create a strong password, consisting of upper-and lower-case letters, a combination of numbers and symbols, it is very difficult to remember. This is a very important problem in the login process. This study discusses the login authentication process that can perform login integration without typing a password, because passwords are generated repeatedly with the One Time Password (OTP) method, and use the Quick Response Code (QR) as its support. To disguise the data in the QR Code, which is applied by the Rivest-Shamir-Adleman (RSA) encryption algorithm, and will be tested on a web-based application. The login integration process, using the QR Code token application that runs on an android phone. Which functions as an OTP token generator, and a web-based application will read information from the QR Code token. The result is that with login authentication, this can increase the security and ease of the authentication process without typing a password. \u00a9 2020 Insight Society."
        ]
    },
    {
        "judul":[
            "Error rate detection due to primary user emulation attack in cognitive radio networks"
        ],
        "penulis":"Armi N.;Gharibi W.;Khan W.Z.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Security threat is a crucial issue in cognitive radio network (CRN). These threats come from physical layer, data link layer, network layer, transport layer, and application layer. Hence, security system to all layers in CRN has a responsibility to protect the communication between among Secondary User (SU) or to maintain valid detection to the presence of Primary User (PU) signals. Primary User Emulation Attack (PUEA) is a threat on physical layer where malicious user emulates PU signal. This paper studies the effect of exclusive region of PUEA in CRN. We take two setting of exclusive distances, 30m and 50m, where this radius of area is free of malicious users. Probability of false alarm (Pf) and miss detection (Pm) are used to evaluate the performances. The result shows that increasing distance of exclusive region may decrease Pf and Pm. \u00a9 2020 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Security threat is a crucial issue in cognitive radio network (CRN). These threats come from physical layer, data link layer, network layer, transport layer, and application layer. Hence, security system to all layers in CRN has a responsibility to protect the communication between among Secondary User (SU) or to maintain valid detection to the presence of Primary User (PU) signals. Primary User Emulation Attack (PUEA) is a threat on physical layer where malicious user emulates PU signal. This paper studies the effect of exclusive region of PUEA in CRN. We take two setting of exclusive distances, 30m and 50m, where this radius of area is free of malicious users. Probability of false alarm (Pf) and miss detection (Pm) are used to evaluate the performances. The result shows that increasing distance of exclusive region may decrease Pf and Pm. \u00a9 2020 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "The new trend for search engine optimization, tools and techniques"
        ],
        "penulis":"Shahzad, Asim;Jacob, Deden Witarsyah;Nawi, Nazri Mohd;Mahdin, Hairulnizam;Saputri, Marheni Eka;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Search Engines are used to search any information on the internet. The primary objective of any website owner is to list their website at the top of all the results in Search Engine Results Pages (SERPs). Search Engine Optimization is the art of increasing visibility of a website in Search Engine Result Pages. This art of improving the visibility of website requires the tools and techniques; This paper is a comprehensive survey of how a Search Engine (SE) works, types and parts of Search Engine and different techniques and tools used for Search Engine Optimization (SEO.) In this paper, we will discuss the current tools and techniques in practice for Search Engine Optimization. Copyright \u00a9 2020 Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Search Engines are used to search any information on the internet. The primary objective of any website owner is to list their website at the top of all the results in Search Engine Results Pages (SERPs). Search Engine Optimization is the art of increasing visibility of a website in Search Engine Result Pages. This art of improving the visibility of website requires the tools and techniques; This paper is a comprehensive survey of how a Search Engine (SE) works, types and parts of Search Engine and different techniques and tools used for Search Engine Optimization (SEO.) In this paper, we will discuss the current tools and techniques in practice for Search Engine Optimization. Copyright \u00a9 2020 Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "RGB Channel Analysis for Glaucoma Detection in Retinal Fundus Image"
        ],
        "penulis":"Satya Nugraha, Gibran;Amelia Riyandari, Baiq;Sutoyo, Edi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The research that used digital image processing to detect glaucoma has been known as one of the popular methods. The beginning step of the research is to choose the best channel among red, green, or blue (RGB) so it can ease the glaucoma segmentation. In choosing the channel, it is important to analyze deeply the used retinal images. Choosing of best component can affect the accuracy of glaucoma diagnosis results. In this research, the most suitable component will be analyzed to detect glaucoma based on the visual, MSE (Mean Square Error) value, and PSNR (Peak Signal to Noise Ratio). In this research, we used 85 images of glaucoma from the DRISTHI-GS database and 101 normal images from the RIM-ONE database. From the visualization, it showed that the red component had high brightness level so it can differ the optic disc and other parts of retinal eyes. The green component still has vessel blood so it will make it more difficult to segment the images. Blue component results in very dark of retinal image. From MSE and PNSR values, it showed that the green component had the smallest MSE value while the blue component has the biggest MSE value. PSNR value was obtained from the green component. Both red and blue components had PSNR value which had a small difference. From these results, it can be concluded that the MSE and PSNR values do not guarantee visual results. So that for further research, it is expected that the MSE and PSNR values will be obtained from the part that we want to observe  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The research that used digital image processing to detect glaucoma has been known as one of the popular methods. The beginning step of the research is to choose the best channel among red, green, or blue (RGB) so it can ease the glaucoma segmentation. In choosing the channel, it is important to analyze deeply the used retinal images. Choosing of best component can affect the accuracy of glaucoma diagnosis results. In this research, the most suitable component will be analyzed to detect glaucoma based on the visual, MSE (Mean Square Error) value, and PSNR (Peak Signal to Noise Ratio). In this research, we used 85 images of glaucoma from the DRISTHI-GS database and 101 normal images from the RIM-ONE database. From the visualization, it showed that the red component had high brightness level so it can differ the optic disc and other parts of retinal eyes. The green component still has vessel blood so it will make it more difficult to segment the images. Blue component results in very dark of retinal image. From MSE and PNSR values, it showed that the green component had the smallest MSE value while the blue component has the biggest MSE value. PSNR value was obtained from the green component. Both red and blue components had PSNR value which had a small difference. From these results, it can be concluded that the MSE and PSNR values do not guarantee visual results. So that for further research, it is expected that the MSE and PSNR values will be obtained from the part that we want to observe  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Analysis of Hotspot Data for Drought Clustering Using K-Means Algorithm"
        ],
        "penulis":"Ramadhan, Ekki Rizki;Sutoyo, Edi;Musnansyah, Ahmad;Belgaman, Halda Aditya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Drought is a disaster that is often experienced in Indonesia. This disaster occurred because Indonesia's geographical location is on the equator. Drought has had a major impact on the community such as crop failure, forest fires, soil damage, the emergence of disease outbreaks, and the extinction of animals and plants. Based on data from the Ministry of Environment of the Republic of Indonesia, the distribution of Riau's hotspots is quite unique. It is said so, because in this distribution, Riau has increased in every February and March as many as 277 and 248 hotspots in the last two years, namely between 2018 and 2019. To anticipate the drought that occurred in Riau, the clustering of drought-prone areas was conducted based on the analysis of hotspots data. This clustering of vulnerable areas is done by the K-Means algorithm. In determining the number of clusters of vulnerable areas, the elbow method is used as a determinant and produces as many as 4 cluster. The results of these method were analyzed by the silhouette coefficient. The result of analyzed is 0.388632163 and were classified as well-clustered. From these results, Rokan Hilir, Bengkalis, Kota Dumai are the dangerous district with 3106, 2361, and 117 point of dangerous distribution, respectively. \u00a9 2020 Association for Computing Machinery.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Drought is a disaster that is often experienced in Indonesia. This disaster occurred because Indonesia's geographical location is on the equator. Drought has had a major impact on the community such as crop failure, forest fires, soil damage, the emergence of disease outbreaks, and the extinction of animals and plants. Based on data from the Ministry of Environment of the Republic of Indonesia, the distribution of Riau's hotspots is quite unique. It is said so, because in this distribution, Riau has increased in every February and March as many as 277 and 248 hotspots in the last two years, namely between 2018 and 2019. To anticipate the drought that occurred in Riau, the clustering of drought-prone areas was conducted based on the analysis of hotspots data. This clustering of vulnerable areas is done by the K-Means algorithm. In determining the number of clusters of vulnerable areas, the elbow method is used as a determinant and produces as many as 4 cluster. The results of these method were analyzed by the silhouette coefficient. The result of analyzed is 0.388632163 and were classified as well-clustered. From these results, Rokan Hilir, Bengkalis, Kota Dumai are the dangerous district with 3106, 2361, and 117 point of dangerous distribution, respectively. \u00a9 2020 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Transfer Learning of BCI Using CUR Algorithm"
        ],
        "penulis":"Fauzi, Hilman;Shapiai, Mohd Ibrahim;Khairuddin, Uswah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The brain computer interface (BCI) are used in many applications including medical, environment, education, economy, and social fields. In order to have a high performing BCI classification, the training set must contain variations of high quality subjects which are discriminative. Variations will also drive transferability of training data for generalization purposes. However, if the test subject is unique from the training set variations, BCI performance may suffer. Previously, this problem was solved by introducing transfer learning in the context of spatial filtering on small training set by creating high quality variations within training subjects. In this study however, it was discovered that transfer learning can also be used to compress the training data into an optimal compact size while improving training data performance. The transfer learning framework proposed was on motor imagery BCI-EEG using CUR matrix decomposition algorithm which decomposes data into two components; C and UR which is each subject\u2019s EEG signal and common matrix derived from historical EEG data, respectively. The method is considered transfer learning process because it utilizes historical data as common matrix for the classification purposes. This framework is implemented in the BCI system along with Common Spatial Pattern (CSP) as features extractor and Extreme Learning Machine (ELM) as classifier and this combination exhibits an increase of accuracy to up to 26% with 83% training database compression. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The brain computer interface (BCI) are used in many applications including medical, environment, education, economy, and social fields. In order to have a high performing BCI classification, the training set must contain variations of high quality subjects which are discriminative. Variations will also drive transferability of training data for generalization purposes. However, if the test subject is unique from the training set variations, BCI performance may suffer. Previously, this problem was solved by introducing transfer learning in the context of spatial filtering on small training set by creating high quality variations within training subjects. In this study however, it was discovered that transfer learning can also be used to compress the training data into an optimal compact size while improving training data performance. The transfer learning framework proposed was on motor imagery BCI-EEG using CUR matrix decomposition algorithm which decomposes data into two components; C and UR which is each subject\u2019s EEG signal and common matrix derived from historical EEG data, respectively. The method is considered transfer learning process because it utilizes historical data as common matrix for the classification purposes. This framework is implemented in the BCI system along with Common Spatial Pattern (CSP) as features extractor and Extreme Learning Machine (ELM) as classifier and this combination exhibits an increase of accuracy to up to 26% with 83% training database compression. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "Analysis Simple Additive Weighting and Genetic Algorithm for Traffic Management System"
        ],
        "penulis":"Aziz, Abdul;Nasution, Surya Michrandi;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Bandung Tourism is currently developing rapidly, where every year the number of tourist attractions has increased. The convenience provided by today's technology such as Google Maps is still lacking in helping tourists. Until now, software that is useful for determining the route by selecting tourist attractions is still small. The problem of tourists in making a tour include traffic jams, distances and tourist attractions to be visited. Application development to help find the best route is very much needed by tourists. The best route search optimization can be done using Genetic Algorithms. Genetic Algorithms are often used in determining the route because based on previous research it produces optimal results. Weighting for a path can be done using the Simple Additive Weighting Algorithm. In this study optimization of route selection is done in the hope that it can provide solutions to tourists in route selection. \u00a9 2020 Universiti Tun Hussein Onn Malaysia Publisher\u2019s Office",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Bandung Tourism is currently developing rapidly, where every year the number of tourist attractions has increased. The convenience provided by today's technology such as Google Maps is still lacking in helping tourists. Until now, software that is useful for determining the route by selecting tourist attractions is still small. The problem of tourists in making a tour include traffic jams, distances and tourist attractions to be visited. Application development to help find the best route is very much needed by tourists. The best route search optimization can be done using Genetic Algorithms. Genetic Algorithms are often used in determining the route because based on previous research it produces optimal results. Weighting for a path can be done using the Simple Additive Weighting Algorithm. In this study optimization of route selection is done in the hope that it can provide solutions to tourists in route selection. \u00a9 2020 Universiti Tun Hussein Onn Malaysia Publisher\u2019s Office"
        ]
    },
    {
        "judul":[
            "The Analysis of User Intention Detection Related to Conventional Poster Advertisement by Using the Features of Face and Eye(s)"
        ],
        "penulis":"Modesty, Yolanda;Sudiharto, Dodi Wisaksono;Wijiutomo, Catur Wirawan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "There are official media to display conventional advertisements such as posters and billboards. However, those cannot tell to the owner related to the effectiveness of the advertisements directly. It can be recognized after the product items have been sold. Based on that problem, there is a requirement related to the media demonstrate an ability to instantly detect user intention. That function explained, generally, is held by a smart advertisement display. On that one, smart components can instantly detect the user intention, are attached to the monitor. Unfortunately, for some companies, the monitor is still expensive to be performed. This condition makes a potential desire to modify the existing smart advertisement system by gently moving the smart components (as an embedded system and a sensor) to other conventional displayed media such as posters. There is an underline state that has to be proven then that the smart modules attached on has to act similarly, likes when they are attached on the monitor. This study observes the ability of the smart components if they are attached to the posters to detect user intention directly. This study uses the previous observation result for elaborating user intention detection by using face and eye(s) features. The result gives a proven fact that smart parts attached to the posters produce the scoring which is relatively the same as the scoring by the smart display system in an arrangement, related to the effectiveness of the advertisement.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "There are official media to display conventional advertisements such as posters and billboards. However, those cannot tell to the owner related to the effectiveness of the advertisements directly. It can be recognized after the product items have been sold. Based on that problem, there is a requirement related to the media demonstrate an ability to instantly detect user intention. That function explained, generally, is held by a smart advertisement display. On that one, smart components can instantly detect the user intention, are attached to the monitor. Unfortunately, for some companies, the monitor is still expensive to be performed. This condition makes a potential desire to modify the existing smart advertisement system by gently moving the smart components (as an embedded system and a sensor) to other conventional displayed media such as posters. There is an underline state that has to be proven then that the smart modules attached on has to act similarly, likes when they are attached on the monitor. This study observes the ability of the smart components if they are attached to the posters to detect user intention directly. This study uses the previous observation result for elaborating user intention detection by using face and eye(s) features. The result gives a proven fact that smart parts attached to the posters produce the scoring which is relatively the same as the scoring by the smart display system in an arrangement, related to the effectiveness of the advertisement.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "New reconstruction method for needle contrast optimization in b-mode ultrasound image by extracting rf signal parameters in frequency domain"
        ],
        "penulis":"Susanti, Hesty;Suprijanto;Kurniadi, Deddy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Ultrasound-guided needle insertion has become standard in medical interventional procedures. Regardless of its advantages, it still has crucial problems related to needle visibility. Some technical factors affect the visibility with non-linear characteristic, i.e. frequency, insertion angle and depth. Here, backscattered signal parameters from measurement were compared to a simulation of a resonance scattering model. Raw radio frequency (RF) data were reconstructed with a new method to represent unique information on total backpropagation from the needle, which consists of non-resonance and resonance scattering components. The result suggests that reconstruction of the needle in B-mode images should be derived from the maximum power spectral density and the energy spectral density to optimize the contrast of the needle. In measurements with the center frequency at 1.87 MHz, the effect of resonance scattering on the total backpropagation around critical angles could be observed more clearly with this method than with standard reconstruction based on the signal envelope. The simulation showed that the fractional bandwidth of the spectrum of the backscattered pressure field centered at 1.87 MHz was relatively optimal at 40% to 100%. So that the simulation of the resonance scattering model can be used to predict the backscattered response from the needle, it must be able to confirm it to the real conditions of RF data with random characteristics. Therefore, extraction of the backscattered pressure field in a simulation with fractional bandwidth should be a concern. \u00a9 2020 Published by ITB Institute for Research and Community Services,.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ultrasound-guided needle insertion has become standard in medical interventional procedures. Regardless of its advantages, it still has crucial problems related to needle visibility. Some technical factors affect the visibility with non-linear characteristic, i.e. frequency, insertion angle and depth. Here, backscattered signal parameters from measurement were compared to a simulation of a resonance scattering model. Raw radio frequency (RF) data were reconstructed with a new method to represent unique information on total backpropagation from the needle, which consists of non-resonance and resonance scattering components. The result suggests that reconstruction of the needle in B-mode images should be derived from the maximum power spectral density and the energy spectral density to optimize the contrast of the needle. In measurements with the center frequency at 1.87 MHz, the effect of resonance scattering on the total backpropagation around critical angles could be observed more clearly with this method than with standard reconstruction based on the signal envelope. The simulation showed that the fractional bandwidth of the spectrum of the backscattered pressure field centered at 1.87 MHz was relatively optimal at 40% to 100%. So that the simulation of the resonance scattering model can be used to predict the backscattered response from the needle, it must be able to confirm it to the real conditions of RF data with random characteristics. Therefore, extraction of the backscattered pressure field in a simulation with fractional bandwidth should be a concern. \u00a9 2020 Published by ITB Institute for Research and Community Services,."
        ]
    },
    {
        "judul":[
            "The Prototype of In-Store Visitor and People Passing Counters using Single Shot Detector Performed by OpenCV"
        ],
        "penulis":"Herviana, Andes;Sudiharto, Dodi Wisaksono;Yulianto, Fazmah Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information related to the power hours of a mall or store is important. By typically knowing it, the manager of the store or the mall can wisely determine the staff planning decision. Without the right decision, it potentially decreases customer satisfaction. The decision can be defined by utilizing in-store visitors and people passing traffic patterns. The other problem also arises when the calculation of in-store visitors and people passing are executed manually, so it requires much effort. This study proposes a prototype design of the system which can automatically calculate visitors by utilizing Single Shot Detector (SSD) method. This method is performed by operating OpenCV library. It is used to detect a human object marked as in-store visitor or people passing. The embedded computer is conducted to process images captured by Pi Camera. Based on the study, the result accuracy is 65.08% for the system counts in-store visitors, and 66.12% for the system marks objects as people pass around in front of the store. Although the accuracy values obtained is not high, but all patterns show that the highest average values of in-store visitors and people passing occur on the days nearing weekend and also on the weekend, such as Friday, Saturday and Sunday. The peak time of in-store visitors (e.g. power hour) on Friday is between 12 PM and 1 PM. The peak time of in-store visitors on Saturday is between 3 PM and 4 PM, and on Monday, it is between 4 PM and 5 PM.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information related to the power hours of a mall or store is important. By typically knowing it, the manager of the store or the mall can wisely determine the staff planning decision. Without the right decision, it potentially decreases customer satisfaction. The decision can be defined by utilizing in-store visitors and people passing traffic patterns. The other problem also arises when the calculation of in-store visitors and people passing are executed manually, so it requires much effort. This study proposes a prototype design of the system which can automatically calculate visitors by utilizing Single Shot Detector (SSD) method. This method is performed by operating OpenCV library. It is used to detect a human object marked as in-store visitor or people passing. The embedded computer is conducted to process images captured by Pi Camera. Based on the study, the result accuracy is 65.08% for the system counts in-store visitors, and 66.12% for the system marks objects as people pass around in front of the store. Although the accuracy values obtained is not high, but all patterns show that the highest average values of in-store visitors and people passing occur on the days nearing weekend and also on the weekend, such as Friday, Saturday and Sunday. The peak time of in-store visitors (e.g. power hour) on Friday is between 12 PM and 1 PM. The peak time of in-store visitors on Saturday is between 3 PM and 4 PM, and on Monday, it is between 4 PM and 5 PM.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Measurement of Criterion Weight to Determine Industrial Area Location Using AHP for Economic Growth"
        ],
        "penulis":"Chumaidiyah E.;Dewantoro M.D.R.;Hakimah D.A.;Arffan Z.;Robbi R.M.N.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Industrial area is an infrastructure for the process of industrialization as a source that can trigger economic growth. Industrial areas that are structured and can support production operations are an appeal to foreign investors. However, the development of industrial areas requires careful planning because it impacts on the environmental carrying capacity and land loss. Therefore, industrial area development needs attention to a variety of important criteria as considerations in determining the location of an industrial area. This study aims to determine the criteria and measure the importance of each relative criterion to other criteria. The method used is Analytical Hierarchy Process (AHP). The results show that there are four important factors that need to be considered with each of the importance level, namely Infrastructure by 33.97%, Distance to Access by 31.74%, Land Soil by 19.57%, and Production Factors by 14.72%. The four factors have ten important criteria that need to be considered in making decisions to determine the location of an industrial area where the two highest criteria are electricity infrastructure with a significance level of 19.05% and telecommunications infrastructure with an importance level of 14.92%. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Industry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Industrial area is an infrastructure for the process of industrialization as a source that can trigger economic growth. Industrial areas that are structured and can support production operations are an appeal to foreign investors. However, the development of industrial areas requires careful planning because it impacts on the environmental carrying capacity and land loss. Therefore, industrial area development needs attention to a variety of important criteria as considerations in determining the location of an industrial area. This study aims to determine the criteria and measure the importance of each relative criterion to other criteria. The method used is Analytical Hierarchy Process (AHP). The results show that there are four important factors that need to be considered with each of the importance level, namely Infrastructure by 33.97%, Distance to Access by 31.74%, Land Soil by 19.57%, and Production Factors by 14.72%. The four factors have ten important criteria that need to be considered in making decisions to determine the location of an industrial area where the two highest criteria are electricity infrastructure with a significance level of 19.05% and telecommunications infrastructure with an importance level of 14.92%. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Exploiting non-orthogonal multiple access in downlink coordinated multipoint transmission with the presence of imperfect channel state information"
        ],
        "penulis":"Murti, Fahri Wisnu;Siregar, Rahmat Faddli;Royyan, Muhammad;Shin, Soo Young;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this paper, the impact of imperfect channel state information (CSI) on a downlink coordinated multipoint (CoMP) transmission system with non-orthogonal multiple access (NOMA) is investigated since perfect knowledge of a channel cannot be guaranteed in practice. Furthermore, the channel estimation error is applied to estimate the channel information wherein its a priori of variance is assumed to be known. The impact of the number of coordinated base stations (BSs) on downlink CoMP NOMA is investigated. Users are classified into one of two groups according to their position within the cell, namely, cell-center user (CCU) and cell-edge user (CEU). In this paper, ergodic capacity and sum capacity for both CCU and CEU are derived as closed forms. In addition, various experiments are conducted with different parameters such as SNR, error variance, and power allocation to show their impact on the CoMP method. The results show that CoMP NOMA outperforms the CoMP orthogonal multiple access (OMA) wherein the condition of the channel impacts the performance of CoMP NOMA less. It is worth noting that a higher number of coordinated BSs enhances the total capacity of CoMP NOMA. Finally, the performance analysis is validated due to the close accordance between the analytical and simulation results. \u00a9 2020 John Wiley & Sons, Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this paper, the impact of imperfect channel state information (CSI) on a downlink coordinated multipoint (CoMP) transmission system with non-orthogonal multiple access (NOMA) is investigated since perfect knowledge of a channel cannot be guaranteed in practice. Furthermore, the channel estimation error is applied to estimate the channel information wherein its a priori of variance is assumed to be known. The impact of the number of coordinated base stations (BSs) on downlink CoMP NOMA is investigated. Users are classified into one of two groups according to their position within the cell, namely, cell-center user (CCU) and cell-edge user (CEU). In this paper, ergodic capacity and sum capacity for both CCU and CEU are derived as closed forms. In addition, various experiments are conducted with different parameters such as SNR, error variance, and power allocation to show their impact on the CoMP method. The results show that CoMP NOMA outperforms the CoMP orthogonal multiple access (OMA) wherein the condition of the channel impacts the performance of CoMP NOMA less. It is worth noting that a higher number of coordinated BSs enhances the total capacity of CoMP NOMA. Finally, the performance analysis is validated due to the close accordance between the analytical and simulation results. \u00a9 2020 John Wiley & Sons, Ltd."
        ]
    },
    {
        "judul":[
            "Modeling Traffic Flow on Buah Batu Exit Toll Gate Using Cellular Automata"
        ],
        "penulis":"Ketaren, Raymondo Fitrah;Danufane, Fadil Habibi;Kurniawan, Isman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the last decade, Bandung has become one of the tourism destination places in Indonesia. It is reported that almost 6.7 million visitors come to Bandung in 2018, and the number increased by almost 4% per year since 2014. This rise in the number of visitors leads to the establishment of several toll gates as main access points throughout the city. As one of the busiest ones, Buah Batu toll gate is frequently congested because of the location that is close to the southern part of Bandung. To overcome this problem, a traffic regulation based on computer simulation is urgently required. In this study, we simulate the traffic system on the Buah Batu toll gate by using a combination of Nagel-Schreckenberg (NaSch) and Daoudia and Moussa (DM) models. NaSch model was used to defined vehicle movement, while the DM model was used to allow a vehicle to change lane. We defined three scenarios to evaluate the effectivity of the closing gate scheme. We found that the closing of gate 5 is more effective than the closing of gate 1. We also investigated the contribution of traffic density and driver's behavior, e.g., stopping behavior and lane-changing behavior, to the average velocity of the vehicles.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the last decade, Bandung has become one of the tourism destination places in Indonesia. It is reported that almost 6.7 million visitors come to Bandung in 2018, and the number increased by almost 4% per year since 2014. This rise in the number of visitors leads to the establishment of several toll gates as main access points throughout the city. As one of the busiest ones, Buah Batu toll gate is frequently congested because of the location that is close to the southern part of Bandung. To overcome this problem, a traffic regulation based on computer simulation is urgently required. In this study, we simulate the traffic system on the Buah Batu toll gate by using a combination of Nagel-Schreckenberg (NaSch) and Daoudia and Moussa (DM) models. NaSch model was used to defined vehicle movement, while the DM model was used to allow a vehicle to change lane. We defined three scenarios to evaluate the effectivity of the closing gate scheme. We found that the closing of gate 5 is more effective than the closing of gate 1. We also investigated the contribution of traffic density and driver's behavior, e.g., stopping behavior and lane-changing behavior, to the average velocity of the vehicles.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Creating employee job satisfaction in a telecommunications company: Perceived organisational support and work stress as antecedents"
        ],
        "penulis":"Prasetio, Arif Partono;Anggadwita, Grisna;Dewi, Nadya Ariana;Istitania, Rizky;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Job satisfaction is one of the important factors when it comes to companies to retaining their employees. Telecommunication companies in Indonesia continue to strive to develop the professionalism of their human resources through various programs and support. This article empirically investigates the effect of the perceived organisational support and work stress on job satisfaction in a telecommunication company. The data was collected from a sample of employees in a public telecommunications company; 200 questionnaires were distributed with a 51% response rate. The mediation analysis procedure was carried out to test the research hypotheses. The results revealed that perceived organisational support has a direct effect on job satisfaction and work stress. Work stress does not affect job satisfaction. This study contributes practically as a management guide in terms of helping companies to provide various types of support and empowerment for their employees. The implications of these findings have been further explored in this study. Copyright \u00a9 2020 Inderscience Enterprises Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Job satisfaction is one of the important factors when it comes to companies to retaining their employees. Telecommunication companies in Indonesia continue to strive to develop the professionalism of their human resources through various programs and support. This article empirically investigates the effect of the perceived organisational support and work stress on job satisfaction in a telecommunication company. The data was collected from a sample of employees in a public telecommunications company; 200 questionnaires were distributed with a 51% response rate. The mediation analysis procedure was carried out to test the research hypotheses. The results revealed that perceived organisational support has a direct effect on job satisfaction and work stress. Work stress does not affect job satisfaction. This study contributes practically as a management guide in terms of helping companies to provide various types of support and empowerment for their employees. The implications of these findings have been further explored in this study. Copyright \u00a9 2020 Inderscience Enterprises Ltd."
        ]
    },
    {
        "judul":[
            "In-vitro molecular docking analysis of microalgae extracted phycocyanin as an anti-diabetic candidate"
        ],
        "penulis":"Siti Halimatul Munawaroh, Heli;Gumilar, Gun Gun;Nurjanah, Fina;Yuliani, Galuh;Aisyah, Siti;Kurnia, Dewi;Wulandari, Asri Peni;Kurniawan, Isman;Ningrum, Andriati;Koyande, Apurav Krishna;Show, Pau-Loke;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Phycocyanin (PC) is the main pigment found in Spirulina platensis and has the potential effect to treat effectively type-2 diabetes mellitus by inhibiting \u03b1-amylase and \u03b1-glucosidase. However, studies on molecular interactions between PC with \u03b1-amylase and \u03b1-glucosidase enzymes are still rare. In this study, an in-silico study was carried out to predict the molecular interactions between PC with \u03b1-amylase and \u03b1-glucosidase enzymes. Molecular docking simulations indicated that PC inhibits the enzymes by binding to the active site and causing a disruption on substrate-enzyme binding. In both enzymes, PC seem to play a crucial role in establishing the interaction within the cavity of active sites. This result suggested PC as a potential candidate for antidiabetic natural therapeutic agents. An in-vitro inhibition activity test showed that PC inhibits human salivary amylase at average of 51.13 %. A storage stability tests showed that keeping PC in solid-state, absence of lights and low temperature can preserve the bioactivity when used as functional compounds. Taken together, this current result would be useful in elucidating the molecular mechanisms of the interaction between PC and carbohydrate-metabolisms enzymes and contribute to making full use of PC as antidiabetic drug or therapeutic agent. Further confirm on diabetic subjects is indispensable to provide the potential therapeutic of PC as an effective anti-diabetic with less frequent of side effect. \u00a9 2020 Elsevier B.V.",
            "OHOOOHOHOOHOHOCH3NHOHOOHOHOHOHHOHOOHView detailsExpand Substance acarbose",
            "Powered by",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Phycocyanin (PC) is the main pigment found in Spirulina platensis and has the potential effect to treat effectively type-2 diabetes mellitus by inhibiting \u03b1-amylase and \u03b1-glucosidase. However, studies on molecular interactions between PC with \u03b1-amylase and \u03b1-glucosidase enzymes are still rare. In this study, an in-silico study was carried out to predict the molecular interactions between PC with \u03b1-amylase and \u03b1-glucosidase enzymes. Molecular docking simulations indicated that PC inhibits the enzymes by binding to the active site and causing a disruption on substrate-enzyme binding. In both enzymes, PC seem to play a crucial role in establishing the interaction within the cavity of active sites. This result suggested PC as a potential candidate for antidiabetic natural therapeutic agents. An in-vitro inhibition activity test showed that PC inhibits human salivary amylase at average of 51.13 %. A storage stability tests showed that keeping PC in solid-state, absence of lights and low temperature can preserve the bioactivity when used as functional compounds. Taken together, this current result would be useful in elucidating the molecular mechanisms of the interaction between PC and carbohydrate-metabolisms enzymes and contribute to making full use of PC as antidiabetic drug or therapeutic agent. Further confirm on diabetic subjects is indispensable to provide the potential therapeutic of PC as an effective anti-diabetic with less frequent of side effect. \u00a9 2020 Elsevier B.V."
        ]
    },
    {
        "judul":[
            "Implicit Aspect Extraction in Product Reviews Using FIN Algorithm"
        ],
        "penulis":"Maylawati, Diah Hevyka;Maharani, Warih;Asror, Ibnu;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Online transactions are growing very rapidly right now. Every online transaction is often accompanied by a review. Product reviews from buyers can be used by sellers as feedback. Product reviews provide information as a consideration for decision making for potential buyers to find out the strengths and weaknesses of the product. Identifying specific product features from reviews written by buyers becomes a solution to make it easier to find information. Aspect-based extraction in sentiment analysis is divided into two, explicit aspects and implicit aspects. The explicit aspect is the explicit aspect in the sentence while the implicit aspect is the aspect that is implied in the sentence. The extraction carried out in this study is based on implicit aspects to determine its features because the majority of existing studies extract explicit aspects. Implicit extraction aspects of product reviews using the FIN algorithm in association rule mining. The dataset is in English text where to extract features using TF-IDF and select features using Particle Swarm optimization. Selected features are grouped using k-Means. After features are grouped based on their value, an associative rule is made using the FIN algorithm. The minimum support value applied and the number of sentence variations cause the accuracy value obtained by 0.678.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Online transactions are growing very rapidly right now. Every online transaction is often accompanied by a review. Product reviews from buyers can be used by sellers as feedback. Product reviews provide information as a consideration for decision making for potential buyers to find out the strengths and weaknesses of the product. Identifying specific product features from reviews written by buyers becomes a solution to make it easier to find information. Aspect-based extraction in sentiment analysis is divided into two, explicit aspects and implicit aspects. The explicit aspect is the explicit aspect in the sentence while the implicit aspect is the aspect that is implied in the sentence. The extraction carried out in this study is based on implicit aspects to determine its features because the majority of existing studies extract explicit aspects. Implicit extraction aspects of product reviews using the FIN algorithm in association rule mining. The dataset is in English text where to extract features using TF-IDF and select features using Particle Swarm optimization. Selected features are grouped using k-Means. After features are grouped based on their value, an associative rule is made using the FIN algorithm. The minimum support value applied and the number of sentence variations cause the accuracy value obtained by 0.678.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Extraction of Website Navigation Label Using A Multiple Web Crawler. A Case Study on 14 University Websites in Indonesia"
        ],
        "penulis":"Luthfiyanto, Arief;Kusumo, Dana Sulistiyo;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Labeling system is designed for a website to find information easily. Labeling system in a website is required to represent the information contents. One of methods to design labeling system is to compare a website with its competitors' websites. The benefit of comparing labels is to get common labels therefore it will make users to easily find and use the labeling system. Labels are extracted using a web crawler. To make web crawler, it must consider the structure of targeted website. The problems arise when there are several different target websites that will be compared. That means, it is necessary to create some unique and different web crawler program codes, so it takes a long time. This research proposes and analyzes multiple web crawler. The step to make multiple web crawler is, first, start to collect targeted website based on 14 top Indonesia's University (based on Indonesia Higher Education's University Ranking). Next step is analyzing the pattern of structure navigation labels. Then the results are used to make a multiple web crawler. The result of this research is a multiple web crawler that can extract navigation label of several different target websites automatically without writing another program code of different web crawler for each crawled website.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Labeling system is designed for a website to find information easily. Labeling system in a website is required to represent the information contents. One of methods to design labeling system is to compare a website with its competitors' websites. The benefit of comparing labels is to get common labels therefore it will make users to easily find and use the labeling system. Labels are extracted using a web crawler. To make web crawler, it must consider the structure of targeted website. The problems arise when there are several different target websites that will be compared. That means, it is necessary to create some unique and different web crawler program codes, so it takes a long time. This research proposes and analyzes multiple web crawler. The step to make multiple web crawler is, first, start to collect targeted website based on 14 top Indonesia's University (based on Indonesia Higher Education's University Ranking). Next step is analyzing the pattern of structure navigation labels. Then the results are used to make a multiple web crawler. The result of this research is a multiple web crawler that can extract navigation label of several different target websites automatically without writing another program code of different web crawler for each crawled website.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Predicting traffic conditions using knowledge-growing bayes classifier"
        ],
        "penulis":"Husni, Emir;Nasution, Surya Michrandi;Kuspriyanto;Yusuf, Rahadian;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Congestion often hinders human mobility. This problem occurs due to the constant increase in vehicles every year. Reliable predictions of traffic conditions would allow drivers to choose their routes to avoid traffic jams while providing the police with traffic management strategies. Therefore, this paper tests the ability of various machine learning methods to predict traffic conditions. The study assesses Neural Networks, Bayes Classifier, Decision Trees, SVM, Deep Neural Network, and Deep Learning. Of these methods, the Decision Tree, Deep Neural Network, and Bayes Classifier show the highest performance in predicting traffic conditions using static data testing. However, in dynamic testing to assess the growth of knowledge, the performance of the Knowledge-Growing Decision Tree tends to decrease as the training data grows. Its performance decreased 3.89 points (88.24% to 84.35%) in accuracy, and 7.55 points (76.25% to 68.70%) for each precision, recall, and F1 Score. Conversely, the Knowledge-Growing Deep Neural Network and Bayes Classifier had a better performance than Decision Tree. The performances of Knowledge-Growing Deep Neural Network increased slightly by 0.35 points (93.38% to 93.73%) for accuracy and 0.69 points (86.77% to 87.64%) in other measurements. Although its performance increased, the processing time takes very long, namely 139452.76 seconds and 318832.80 seconds for sub-scheme (a) and (b), respectively. Meanwhile, the Knowledge-Growing Bayes Classifier offers a greater performance increase of 2.3 points (80.52% to 82.82%) for the accuracy and 4.6 points (65.63% to 61.03%) for the other performance measurements. In addition, it also scored better for processing time, as predictions only take 3 seconds using sub-scheme (a), and 7 seconds when using sub-scheme (b). Therefore, the paper proposes the Knowledge-Growing Bayes Classifier to predict rapidly changing traffic conditions. This method outperform the others. These can be attributed to its ability to 1) adjust to ever-changing the traffic conditions; 2) predict the result as soon as the data are acquired; and 3) make decentralized predictions. \u00a9 2020 Lippincott Williams and Wilkins. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Congestion often hinders human mobility. This problem occurs due to the constant increase in vehicles every year. Reliable predictions of traffic conditions would allow drivers to choose their routes to avoid traffic jams while providing the police with traffic management strategies. Therefore, this paper tests the ability of various machine learning methods to predict traffic conditions. The study assesses Neural Networks, Bayes Classifier, Decision Trees, SVM, Deep Neural Network, and Deep Learning. Of these methods, the Decision Tree, Deep Neural Network, and Bayes Classifier show the highest performance in predicting traffic conditions using static data testing. However, in dynamic testing to assess the growth of knowledge, the performance of the Knowledge-Growing Decision Tree tends to decrease as the training data grows. Its performance decreased 3.89 points (88.24% to 84.35%) in accuracy, and 7.55 points (76.25% to 68.70%) for each precision, recall, and F1 Score. Conversely, the Knowledge-Growing Deep Neural Network and Bayes Classifier had a better performance than Decision Tree. The performances of Knowledge-Growing Deep Neural Network increased slightly by 0.35 points (93.38% to 93.73%) for accuracy and 0.69 points (86.77% to 87.64%) in other measurements. Although its performance increased, the processing time takes very long, namely 139452.76 seconds and 318832.80 seconds for sub-scheme (a) and (b), respectively. Meanwhile, the Knowledge-Growing Bayes Classifier offers a greater performance increase of 2.3 points (80.52% to 82.82%) for the accuracy and 4.6 points (65.63% to 61.03%) for the other performance measurements. In addition, it also scored better for processing time, as predictions only take 3 seconds using sub-scheme (a), and 7 seconds when using sub-scheme (b). Therefore, the paper proposes the Knowledge-Growing Bayes Classifier to predict rapidly changing traffic conditions. This method outperform the others. These can be attributed to its ability to 1) adjust to ever-changing the traffic conditions; 2) predict the result as soon as the data are acquired; and 3) make decentralized predictions. \u00a9 2020 Lippincott Williams and Wilkins. All rights reserved."
        ]
    },
    {
        "judul":[
            "The Influence of Blue Light in Maintaining Alertness in Tropical Country: A Preliminary Study"
        ],
        "penulis":"Rahma K.T.;Salma S.A.;Widyanti A.;Suprijanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Several studies have discussed the influence of blue light on cognitive activity. This study aims to determine the effectiveness of blue light in increasing alertness at night in tropical countries. Twelve healthy young males joined in this study. All participants were asked to do a monotonous activity that is reading activity. The experiment was a within-subject design with the independent variable is lighting condition (normal light and blue light) and duration of exposure (30 minutes and 60 minutes). Electroencephalography (EEG) signals were recorded continuously during the experiment. Alertness was measured based on theta, alpha, and beta activity. The result is the light condition not significantly affected the theta (F (1,11) = 0.608, \u03c1 = 0.452), alpha (F (1,11) = 1.561, \u03c1 = 0.237), and beta (F (1,11) = 0.608, \u03c1 = 0.700) activity. This shows that blue light is not effective in increasing alertness at night in the tropical country both in short and long duration of exposure. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Several studies have discussed the influence of blue light on cognitive activity. This study aims to determine the effectiveness of blue light in increasing alertness at night in tropical countries. Twelve healthy young males joined in this study. All participants were asked to do a monotonous activity that is reading activity. The experiment was a within-subject design with the independent variable is lighting condition (normal light and blue light) and duration of exposure (30 minutes and 60 minutes). Electroencephalography (EEG) signals were recorded continuously during the experiment. Alertness was measured based on theta, alpha, and beta activity. The result is the light condition not significantly affected the theta (F (1,11) = 0.608, \u03c1 = 0.452), alpha (F (1,11) = 1.561, \u03c1 = 0.237), and beta (F (1,11) = 0.608, \u03c1 = 0.700) activity. This shows that blue light is not effective in increasing alertness at night in the tropical country both in short and long duration of exposure. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Speech Emotion Detection Using Mel-Frequency Cepstral Coefficient and Hidden Markov Model"
        ],
        "penulis":"Muttaqin, Didik;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Emotion is one of the human ways to interact with each other, which can be expressed using a speech. An emotion in one of the seven states of happy, angry, sad, calm, scared, shocked, and disgust can be identified through its wave speech signal. Development of speech recognition is a kind of technology that rapidly growing to help human-machine interaction, at the moment the most used method is the Hidden Markov Model (HMM). In this paper, a Mel-Frequency Cepstral Coefficient (MFCC), which is commonly used to generate certain coefficients, is exploited as a determinant parameter for HMM to classify those seven emotions. Evaluation for a dataset of 240 utterances shows that the developed model gives quite high accuracy of 81.65%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Emotion is one of the human ways to interact with each other, which can be expressed using a speech. An emotion in one of the seven states of happy, angry, sad, calm, scared, shocked, and disgust can be identified through its wave speech signal. Development of speech recognition is a kind of technology that rapidly growing to help human-machine interaction, at the moment the most used method is the Hidden Markov Model (HMM). In this paper, a Mel-Frequency Cepstral Coefficient (MFCC), which is commonly used to generate certain coefficients, is exploited as a determinant parameter for HMM to classify those seven emotions. Evaluation for a dataset of 240 utterances shows that the developed model gives quite high accuracy of 81.65%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Automatic whole-body bone scan image segmentation based on constrained local model"
        ],
        "penulis":"Rachmawati, Ema;Jondri;Ramadhani, Kurniawan Nur;Kartamihardja, Achmad Hussein Sundawa;Achmad, Arifudin;Shintawati, Rini;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In Indonesia, cancer is very burdensome financially for sufferers as well as for the country. Increasing the access to early detection of cancer can be a solution to prevent the situation from worsening. Regarding the problem of cancer lesion detection, a whole-body bone scan image is the primary modality of nuclear medicine for the detection of cancer lesions on a bone. Therefore, high segmentation accuracy of the whole-body bone scan image is a crucial step in building the shape model of some predefined regions in the bone scan image where metastasis was predicted to appear frequently. In this article, we proposed an automatic whole-body bone scan image segmentation based on constrained local model (CLM). We determine 111 landmark points on the bone scan image as the input for the model building step. The resulting shape and texture model are further used in the fitting step to estimate the landmark points of predefined regions. We use the CLM-based approach using regularized landmark mean-shift (RLMS) to lessen the effect of ambiguity, which was struggled by the CLM-based approach. From the experimental result, we successfully show that our proposed image segmentation system achieves higher performance than the general CLM-based approach. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In Indonesia, cancer is very burdensome financially for sufferers as well as for the country. Increasing the access to early detection of cancer can be a solution to prevent the situation from worsening. Regarding the problem of cancer lesion detection, a whole-body bone scan image is the primary modality of nuclear medicine for the detection of cancer lesions on a bone. Therefore, high segmentation accuracy of the whole-body bone scan image is a crucial step in building the shape model of some predefined regions in the bone scan image where metastasis was predicted to appear frequently. In this article, we proposed an automatic whole-body bone scan image segmentation based on constrained local model (CLM). We determine 111 landmark points on the bone scan image as the input for the model building step. The resulting shape and texture model are further used in the fitting step to estimate the landmark points of predefined regions. We use the CLM-based approach using regularized landmark mean-shift (RLMS) to lessen the effect of ambiguity, which was struggled by the CLM-based approach. From the experimental result, we successfully show that our proposed image segmentation system achieves higher performance than the general CLM-based approach. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "ERP system implementation with accounting modules in national amil zakat institutions"
        ],
        "penulis":"Gantira Mira, Intan;Lubis, Muharman;Puspitasari, Warih;Ridho Lubis, Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Rumah Yatim is an authorized zakat institution in Indonesia with national-level task of collecting and distributing mandatory zakat to the eligible person fairly and evenly. Therefore, there are many issues that prevent zakat optimization such as lack of awareness to pay zakat, inaccessibility of required channel, disrupted of productive program and overlapping funds as the cause of incoordination. This study offers the system design in related to the accounting module to present the compliance and standards in order to convince relevant party and public eyes upon the credibility and reliability of zakat management. It was carried out by developing an Enterprise Resource Planning (ERP) system using the Odoo Quick Start method as the popular mechanism within small and medium enterprises (SMEs). The results of this study are an ERP system designed based on the customized Odoo module that has been aligned with the business processes and function within the institution. It has the purposes to make it easier and quicker for solving problem compare to the previous process in order to create effective and efficient management for the institution to carry out their agenda and activities based on meaningful and resourceful accounting performance. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Rumah Yatim is an authorized zakat institution in Indonesia with national-level task of collecting and distributing mandatory zakat to the eligible person fairly and evenly. Therefore, there are many issues that prevent zakat optimization such as lack of awareness to pay zakat, inaccessibility of required channel, disrupted of productive program and overlapping funds as the cause of incoordination. This study offers the system design in related to the accounting module to present the compliance and standards in order to convince relevant party and public eyes upon the credibility and reliability of zakat management. It was carried out by developing an Enterprise Resource Planning (ERP) system using the Odoo Quick Start method as the popular mechanism within small and medium enterprises (SMEs). The results of this study are an ERP system designed based on the customized Odoo module that has been aligned with the business processes and function within the institution. It has the purposes to make it easier and quicker for solving problem compare to the previous process in order to create effective and efficient management for the institution to carry out their agenda and activities based on meaningful and resourceful accounting performance. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "5G Channel Model for 28 GHz frequency in Palembang"
        ],
        "penulis":"Alfaresi B.;Nawawi Z.;Malik R.F.;Anwar K.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Next generation wireless technology require a wide frequency band. Current technology use a frequency of below 3 GHz which cannot provide a wide frequency band due to quite dense frequency utilization. The mm-Wave frequency guarantee to provide a wide band frequency band. The use of mm-Wave frequency will be influenced by climate factors. The characteristics of a place will cause a different channel model. Channel Model is useful for minimizes errors and maximizes information transmission or bitrate in communication model. The Channel Model will be represented as a PDP (Power Delay Profile). Channel model performance uses the Outage performance parameter in Shannon Theorem Implementation. Validation results using the CP-OFDM system with 5G BPSK. The parameters used for validation are FER and BER. In this paper, channel models will be analysed based on the characteristic of Palembang area as a reference channel model in Outer of Indonesia. Hopefully, it can be used as a reference for the development 5G wireless system. \u00a9 2020 IOP Publishing Ltd. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Next generation wireless technology require a wide frequency band. Current technology use a frequency of below 3 GHz which cannot provide a wide frequency band due to quite dense frequency utilization. The mm-Wave frequency guarantee to provide a wide band frequency band. The use of mm-Wave frequency will be influenced by climate factors. The characteristics of a place will cause a different channel model. Channel Model is useful for minimizes errors and maximizes information transmission or bitrate in communication model. The Channel Model will be represented as a PDP (Power Delay Profile). Channel model performance uses the Outage performance parameter in Shannon Theorem Implementation. Validation results using the CP-OFDM system with 5G BPSK. The parameters used for validation are FER and BER. In this paper, channel models will be analysed based on the characteristic of Palembang area as a reference channel model in Outer of Indonesia. Hopefully, it can be used as a reference for the development 5G wireless system. \u00a9 2020 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Process mining of disease trajectories: A feasibility study"
        ],
        "penulis":"Kusuma, Guntur P.;Sykes, Samantha;McInerney, Ciar\u00e1n;Johnson, Owen;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Modelling patient disease trajectories from evidence in electronic health records could help clinicians and medical researchers develop a better understanding of the progression of diseases within target populations. Process mining provides a set of well-established tools and techniques that have been used to mine electronic health record data to understand healthcare care pathways. In this paper we explore the feasibility for using a process mining methodology and toolset to automate the identification of disease trajectory models. We created synthetic electronic health record data based on a published disease trajectory model and developed a series of event log transformations to reproduce the disease trajectory model using standard process mining tools. Our approach will make it easier to produce disease trajectory models from routine health data. \u00a9 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved."
        ],
        "abstrak":[
            "Modelling patient disease trajectories from evidence in electronic health records could help clinicians and medical researchers develop a better understanding of the progression of diseases within target populations. Process mining provides a set of well-established tools and techniques that have been used to mine electronic health record data to understand healthcare care pathways. In this paper we explore the feasibility for using a process mining methodology and toolset to automate the identification of disease trajectory models. We created synthetic electronic health record data based on a published disease trajectory model and developed a series of event log transformations to reproduce the disease trajectory model using standard process mining tools. Our approach will make it easier to produce disease trajectory models from routine health data. \u00a9 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved."
        ]
    },
    {
        "judul":[
            "Sustainability analysis of dairy-horticulture integrated farming system"
        ],
        "penulis":"Rosmiati M.;Putra R.E.;Lastini T.;Hernawan E.;Pujo;Rahmayunita I.;Maulana F.R.;Liesdiana F.;Nurdiansyah M.A.;Azis A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Purpose: The Integrated farming system offers better opportunities to be implemented in smallholder agriculture because it ensures productivity and profitability for sustainable livelihoods. However, the evaluation of this practice has not been clearly identified. This study is aimed at evaluating the ecological, economic, social, institutional, and technological aspects of sustainability of existing dairy-horticulture farming systems at farm level. Research Method: Data were collected through survey design using questionnaire, observation, and literature review. This research used Multidimensional Scaling, leverage analysis and Monte Carlo called RAP-DHFS (Rapid Appraisal for Dairy-Horticulture Farming System) to analyze the data. Findings: The results showed that the sustainability status of ecological dimension, economic dimension, social dimension, and technological dimension were classified as less sustainable which were 28.07%, 29.52%, 27.37%, and 29.15, respectively while the institutional dimension was considered as unsustainable (21.77%). There were also 10 attributes identified as the most influential attributes on the sustainability status. Limitations: The study was conducted at one village, which is a small scope of area. Value: This study provides a holistic assessment of the integrated farming system and shows the concern and risk for further development in rural areas. \u00a9 2020, Faculty of Agricultural Sciences, Sabaragamuwa University of Sri Lanka. All rights reserved.",
            "Sustainable Development Goals mapped to this documentZero hungerGoal 2Quality educationGoal 4Decent work and economic growthGoal 8Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Purpose: The Integrated farming system offers better opportunities to be implemented in smallholder agriculture because it ensures productivity and profitability for sustainable livelihoods. However, the evaluation of this practice has not been clearly identified. This study is aimed at evaluating the ecological, economic, social, institutional, and technological aspects of sustainability of existing dairy-horticulture farming systems at farm level. Research Method: Data were collected through survey design using questionnaire, observation, and literature review. This research used Multidimensional Scaling, leverage analysis and Monte Carlo called RAP-DHFS (Rapid Appraisal for Dairy-Horticulture Farming System) to analyze the data. Findings: The results showed that the sustainability status of ecological dimension, economic dimension, social dimension, and technological dimension were classified as less sustainable which were 28.07%, 29.52%, 27.37%, and 29.15, respectively while the institutional dimension was considered as unsustainable (21.77%). There were also 10 attributes identified as the most influential attributes on the sustainability status. Limitations: The study was conducted at one village, which is a small scope of area. Value: This study provides a holistic assessment of the integrated farming system and shows the concern and risk for further development in rural areas. \u00a9 2020, Faculty of Agricultural Sciences, Sabaragamuwa University of Sri Lanka. All rights reserved."
        ]
    },
    {
        "judul":[
            "Characterization of Slotted Square Rings AMC Reflector Using Printed Dipole Antenna"
        ],
        "penulis":"Haryanto, Dwiki;Nur, Levy Olivia;Munir, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The reflector has a role in enhancing the return loss of antenna becoming a selective frequency. In this paper, an artificial magnetic conductor (AMC) based reflector composed of slotted square rings is proposed and characterized using a printed dipole antenna. The used of AMC layer which has high surface impedance is expected to reduce the distance between the antenna and the reflector yielding a compact device. The configuration of AMC reflector and printed dipole antenna is designed each on an RO3003 dielectric substrate with the relative permittivity of 3.0 and the thickness of 0.5 mm. The configuration is intended to be used for wireless communication at the Industrial, Scientific, and Medical (ISM) band frequency of 2.4 GHz. The proposed reflector is constructed by a 3\u00d73 unit cell of AMC structure where each unit cell is composed of slotted square rings configured concentrically. Meanwhile, the characterization is carried out by varying the parameters of AMC reflector and printed dipole antenna. The result shows the configuration with the distance between the antenna and the reflector of \u03bb\/23, or around 5 mm, could produce a significant value of reflection coefficient (S11) among others. This configuration could achieve the S11 value up to-24 dB at the frequency of 1.98 GHz. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The reflector has a role in enhancing the return loss of antenna becoming a selective frequency. In this paper, an artificial magnetic conductor (AMC) based reflector composed of slotted square rings is proposed and characterized using a printed dipole antenna. The used of AMC layer which has high surface impedance is expected to reduce the distance between the antenna and the reflector yielding a compact device. The configuration of AMC reflector and printed dipole antenna is designed each on an RO3003 dielectric substrate with the relative permittivity of 3.0 and the thickness of 0.5 mm. The configuration is intended to be used for wireless communication at the Industrial, Scientific, and Medical (ISM) band frequency of 2.4 GHz. The proposed reflector is constructed by a 3\u00d73 unit cell of AMC structure where each unit cell is composed of slotted square rings configured concentrically. Meanwhile, the characterization is carried out by varying the parameters of AMC reflector and printed dipole antenna. The result shows the configuration with the distance between the antenna and the reflector of \u03bb\/23, or around 5 mm, could produce a significant value of reflection coefficient (S11) among others. This configuration could achieve the S11 value up to-24 dB at the frequency of 1.98 GHz. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The role of tourism and renewable energy in testing the environmental Kuznets curve in the BRICS countries: fresh evidence from methods of moments quantile regression"
        ],
        "penulis":"Aziz, Noshaba;Mihardjo, Leonardus Ww;Sharif, Arshian;Jermsittiparsert, Kittisak;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "BRICS are among the rising nations which drive economic growth by excessive utilization of resources and resulting in environment degradation. Although there is bulk of research on environmental Kuznets curve (EKC), very limited studies explored the scope in context of tourism in BRICS countries. So this research is conducted to explore the association of tourism, renewable energy, and economic growth with carbon emissions by using annual data of BRICS countries from the year 1995 to 2018. By using the recent approach of method of moments quantile regression (MMQR), the finding shows that tourism has stronger significant negative effects from 10th to 40th quantile while the effects are insignificant at remaining quantiles. Furthermore, an inverted U-shape EKC curve is also apparent at all quantiles excluding 10th and 20th quantiles. For renewable energy, the results are found negatively significant across all quantiles (10th\u201390th) which claim that CO2 emission can be reduced by opting renewable sources. Hence, the empirical results of the current study provide insights for policymakers to consume renewable energy sources for the sustainable economic growth and solution of environmental problems. \u00a9 2020, Springer-Verlag GmbH Germany, part of Springer Nature.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Decent work and economic growthGoal 8Responsible consumption and productionGoal 12Climate actionGoal 13Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "BRICS are among the rising nations which drive economic growth by excessive utilization of resources and resulting in environment degradation. Although there is bulk of research on environmental Kuznets curve (EKC), very limited studies explored the scope in context of tourism in BRICS countries. So this research is conducted to explore the association of tourism, renewable energy, and economic growth with carbon emissions by using annual data of BRICS countries from the year 1995 to 2018. By using the recent approach of method of moments quantile regression (MMQR), the finding shows that tourism has stronger significant negative effects from 10th to 40th quantile while the effects are insignificant at remaining quantiles. Furthermore, an inverted U-shape EKC curve is also apparent at all quantiles excluding 10th and 20th quantiles. For renewable energy, the results are found negatively significant across all quantiles (10th\u201390th) which claim that CO2 emission can be reduced by opting renewable sources. Hence, the empirical results of the current study provide insights for policymakers to consume renewable energy sources for the sustainable economic growth and solution of environmental problems. \u00a9 2020, Springer-Verlag GmbH Germany, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "Project acceleration of outside plant-fiber optic (OSP-FO) project in pt. XYZ using time cost trade off (TCTO) method by adding overtime hours"
        ],
        "penulis":"Hasyyati, Syifa Nur;Puspita, Ika Arum;Tripiawan, Wawan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Various things can occur in the implementation of a construction project that could lead an increase implementation time so that the completion of the project tends to be delayed or not according to plan. The OSP-FO Project was chosen as a case study because of the 3rd license party is not released yet from 5th July 2018 until entered May, 2019. The project is not having production work for more than 6 weeks and the status of the project is become on hold project. Therefore, it is necessary to renew the schedule and accelerate the project when the license is release. Time Cost Trade Off (TCTO) method is a schedule compression to get a project that is more profitable in terms of time (duration), cost, and income. The goal is to compress projects with acceptable duration and minimize the total cost of the project by selecting critical activities with adding optimum working hours for 3 hours per day. From the results of the analysis, the optimum cost is Rp. 22,397,932,645,- and the optimum duration is 292 days, so that the cost efficiency is Rp. 91,596,790 or 0,0041% and the time efficiency is 78 days or 0.2110%. \u00a9 2020 Institute of Physics Publishing. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Various things can occur in the implementation of a construction project that could lead an increase implementation time so that the completion of the project tends to be delayed or not according to plan. The OSP-FO Project was chosen as a case study because of the 3rd license party is not released yet from 5th July 2018 until entered May, 2019. The project is not having production work for more than 6 weeks and the status of the project is become on hold project. Therefore, it is necessary to renew the schedule and accelerate the project when the license is release. Time Cost Trade Off (TCTO) method is a schedule compression to get a project that is more profitable in terms of time (duration), cost, and income. The goal is to compress projects with acceptable duration and minimize the total cost of the project by selecting critical activities with adding optimum working hours for 3 hours per day. From the results of the analysis, the optimum cost is Rp. 22,397,932,645,- and the optimum duration is 292 days, so that the cost efficiency is Rp. 91,596,790 or 0,0041% and the time efficiency is 78 days or 0.2110%. \u00a9 2020 Institute of Physics Publishing. All rights reserved."
        ]
    },
    {
        "judul":[
            "Comparison of EMD, VMD and EEMD Methods in Respiration Wave Extraction Based on PPG Waves"
        ],
        "penulis":"Hadiyoso S.;Dewi E.M.;Wijayanto I.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Plethysmographic (PPG) wave analysis can provide interesting information including heart rate and oxygen saturation. Since PPG signals are modulated by breathing waves, further analysis can provide additional information that is the respiration rate (RR). This is a way to simplify sensor devices. This paper discusses a respiration wave extraction mechanism to calculate RR using the signal decomposition approach. Decomposition methods which are applied in this study include empirical mode decomposition (EMD), variational mode decomposition (VMD) and ensemble empirical mode decomposition (EEMD). This paper specifically addresses the performance of EEMD to EMD and VMD. This proposed method has been tested on an open PPG dataset (containing PPG and RR wave signals). Test results on 20 PPG signals, each of which had a duration of 1 minute showed that the EEMD was able to estimate the RR with an accuracy of more than 90% with an average error rate of 1 rate\/minute. \u00a9 2020 IOP Publishing Ltd. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Plethysmographic (PPG) wave analysis can provide interesting information including heart rate and oxygen saturation. Since PPG signals are modulated by breathing waves, further analysis can provide additional information that is the respiration rate (RR). This is a way to simplify sensor devices. This paper discusses a respiration wave extraction mechanism to calculate RR using the signal decomposition approach. Decomposition methods which are applied in this study include empirical mode decomposition (EMD), variational mode decomposition (VMD) and ensemble empirical mode decomposition (EEMD). This paper specifically addresses the performance of EEMD to EMD and VMD. This proposed method has been tested on an open PPG dataset (containing PPG and RR wave signals). Test results on 20 PPG signals, each of which had a duration of 1 minute showed that the EEMD was able to estimate the RR with an accuracy of more than 90% with an average error rate of 1 rate\/minute. \u00a9 2020 IOP Publishing Ltd. All rights reserved."
        ]
    },
    {
        "judul":[
            "Minimax robust landmine detection using forward-looking ground-penetrating radar"
        ],
        "penulis":"Pambudi, Afief D.;Faub, Michael;Ahmad, Fauzia;Zoubir, Abdelhak M.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We propose a robust likelihood-ratio test (LRT) to detect landmines and unexploded ordnance using forward-looking ground-penetrating radar. Instead of modeling the distributions of the target and clutter returns with parametric families, we construct a band of feasible probability densities under each hypothesis. The LRT is then devised based on the least favorable densities within the bands. This detector is designed to maximize the worst case performance over all feasible density pairs and, hence, does not require strong assumptions about the clutter and noise distributions. The proposed technique is evaluated using electromagnetic field simulation data of shallow-buried targets. We show that, compared to detectors based on parametric models, robust detectors can lead to significantly reduced false alarm rates, particularly in cases where there is a mismatch between the assumed model and the true distributions.  \u00a9 1980-2012 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We propose a robust likelihood-ratio test (LRT) to detect landmines and unexploded ordnance using forward-looking ground-penetrating radar. Instead of modeling the distributions of the target and clutter returns with parametric families, we construct a band of feasible probability densities under each hypothesis. The LRT is then devised based on the least favorable densities within the bands. This detector is designed to maximize the worst case performance over all feasible density pairs and, hence, does not require strong assumptions about the clutter and noise distributions. The proposed technique is evaluated using electromagnetic field simulation data of shallow-buried targets. We show that, compared to detectors based on parametric models, robust detectors can lead to significantly reduced false alarm rates, particularly in cases where there is a mismatch between the assumed model and the true distributions.  \u00a9 1980-2012 IEEE."
        ]
    },
    {
        "judul":[
            "Classification of premature ventricular contraction (Pvc) based on ecg signal using convolutional neural network (cnn)"
        ],
        "penulis":"Jondri;Rizal, Achmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study observes one of the ECG signal abnormalities, which is the Premature Ventricular Contraction (PVC). Many studies applied a machine learning technique to develop a computer-aided diagnosis to classify normal and PVC conditions of ECG signals. The common process to obtain information from the ECG signal is by performing a feature extraction process. Since the ECG signal is a complex signal, there is a need to reduce the signal dimension to produce an optimal feature set. However, these processes can remove the information contained in the signal. Therefore, this study process the original ECG signal using a Convolutional Neural Network to avoid losing information. The input data were in the form of both one beat of normal ECG signal or PVC with size 1x200. The classification used four layers of convolutional neural network (CNN). There were eight 1x1 filters used in the input. Simultaneously, 16 and 32 of 1x1 filters were used in the second and the fourth convolutional layers, respectively. Thus the system produced a fully connected layer consisted of 512 neurons, while the output layer consisted of 2 neurons. The system is tested using 11361 beats of ECG data and achieved the highest accuracy of 99.59%, with the 10-fold cross-validation. This study emphasizes an opportunity to develop a wearable device to detect PVC since CNN can be implemented into an embedded system or an IoT based system. \u00a9 2020 Institute of Advanced Engineering and Science.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study observes one of the ECG signal abnormalities, which is the Premature Ventricular Contraction (PVC). Many studies applied a machine learning technique to develop a computer-aided diagnosis to classify normal and PVC conditions of ECG signals. The common process to obtain information from the ECG signal is by performing a feature extraction process. Since the ECG signal is a complex signal, there is a need to reduce the signal dimension to produce an optimal feature set. However, these processes can remove the information contained in the signal. Therefore, this study process the original ECG signal using a Convolutional Neural Network to avoid losing information. The input data were in the form of both one beat of normal ECG signal or PVC with size 1x200. The classification used four layers of convolutional neural network (CNN). There were eight 1x1 filters used in the input. Simultaneously, 16 and 32 of 1x1 filters were used in the second and the fourth convolutional layers, respectively. Thus the system produced a fully connected layer consisted of 512 neurons, while the output layer consisted of 2 neurons. The system is tested using 11361 beats of ECG data and achieved the highest accuracy of 99.59%, with the 10-fold cross-validation. This study emphasizes an opportunity to develop a wearable device to detect PVC since CNN can be implemented into an embedded system or an IoT based system. \u00a9 2020 Institute of Advanced Engineering and Science."
        ]
    },
    {
        "judul":[
            "Implementation of Data Cleansing Null Method for Data Quality Management Dashboard using Pentaho Data Integration"
        ],
        "penulis":"Sulistyo, Haidar Alvinanda;Kusumasari, Tien Febrianti;Alam, Ekky Novriza;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Data is a collection of facts or information collected from various sources that are dirty andwill affect the quality of decision-making in an organization. Data cleansing ensures that the datais correct, useable, and consistent. Data may be incomplete, inaccurate, or has the wrong format and needs to be corrected or deleted. Data cleansing processing can improve the quality of the data significantly. The data cleansing processing requires to create useful quality data that provides significant benefits for the recipient. The availability of data is crucial in an organization to develop competent, valid, and trustworthy decisions. The null or blank field in data is one of many problems to maintain data quality management in an organization, especially in Indonesian government agencies. The brand registration number permits contain many blank fields, including the complete data needed for the next step processing. Therefore, to solve the amount of blank data, this research will discuss the design and implementation of the data cleansing null method using Pentaho Data Integration (PDI). The result will be implemented to the data quality management (DQM) dashboard using the laravel framework and MySQL as a DBMS. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Data is a collection of facts or information collected from various sources that are dirty andwill affect the quality of decision-making in an organization. Data cleansing ensures that the datais correct, useable, and consistent. Data may be incomplete, inaccurate, or has the wrong format and needs to be corrected or deleted. Data cleansing processing can improve the quality of the data significantly. The data cleansing processing requires to create useful quality data that provides significant benefits for the recipient. The availability of data is crucial in an organization to develop competent, valid, and trustworthy decisions. The null or blank field in data is one of many problems to maintain data quality management in an organization, especially in Indonesian government agencies. The brand registration number permits contain many blank fields, including the complete data needed for the next step processing. Therefore, to solve the amount of blank data, this research will discuss the design and implementation of the data cleansing null method using Pentaho Data Integration (PDI). The result will be implemented to the data quality management (DQM) dashboard using the laravel framework and MySQL as a DBMS. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Event-based dynamic banking network exploration for economic anomaly detection"
        ],
        "penulis":"Alamsyah, Andry;Ramadhani, Dian Puteri;Kristanti, Farida Titik;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The instability of financial system issues might trigger a bank failure, evoke spillovers, and generate contagion effects which negatively impacted the financial system, ultimately on the economy. This phenomenon is the result of the highly interconnected banking transaction. The banking transactions network is considered as a financial architecture backbone. The strong interconnectedness between banks escalates contagion disruption spreading over the banking network and trigger the entire system collapse. This far, the financial instability is generally detected using macro approach mainly the uncontrolled transaction deficits amount and unpaid foreign debt. This research proposes financial instability detection in another point of view, through the macro view where the banking network structure are explored globally and micro view where focuses on the detailed network patterns called motif. Network triadic motif patterns used as a denomination to detect financial instability. The most related network triadic motif changes related to the instability period are determined as detector. We explore the banking network behavior under financial instability phenomenon along with the major religious event in Indonesia, Eid al-Fitr. We discover one motif pattern as the financial instability underlying detector. This research help to support the financial system stability supervision. \u00a9 2005 - ongoing JATIT & LLS.",
            "Sustainable Development Goals mapped to this documentReduced inequalitiesGoal 10Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The instability of financial system issues might trigger a bank failure, evoke spillovers, and generate contagion effects which negatively impacted the financial system, ultimately on the economy. This phenomenon is the result of the highly interconnected banking transaction. The banking transactions network is considered as a financial architecture backbone. The strong interconnectedness between banks escalates contagion disruption spreading over the banking network and trigger the entire system collapse. This far, the financial instability is generally detected using macro approach mainly the uncontrolled transaction deficits amount and unpaid foreign debt. This research proposes financial instability detection in another point of view, through the macro view where the banking network structure are explored globally and micro view where focuses on the detailed network patterns called motif. Network triadic motif patterns used as a denomination to detect financial instability. The most related network triadic motif changes related to the instability period are determined as detector. We explore the banking network behavior under financial instability phenomenon along with the major religious event in Indonesia, Eid al-Fitr. We discover one motif pattern as the financial instability underlying detector. This research help to support the financial system stability supervision. \u00a9 2005 - ongoing JATIT & LLS."
        ]
    },
    {
        "judul":[
            "The influence of ict capability on competitive advantage of small businesses through entrepreneurial orientation and organisational agility-the case of apparel retailers in Pekanbaru Indonesia"
        ],
        "penulis":"Andri, Seno;Arifin, Kasman;Febrian, Achmad Fajri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The aim of this paper is to find out how Information and Communication Technology (ICT) capability has affected competitive advantage through entrepreneurial orientation and organisational agility of the Indonesian apparel retailers. This study is based on resources that cannot be directly converted into competitive advantage for companies but must go through an entrepreneurial process and offer new insights into the use of ICT as a valuable company resource. The paper is based on a quantitative approach with the population of apparel retailers in traditional markets of Pekanbaru City, Indonesia. The sample was taken using random sampling. The survey was conducted in 104 small businesses in five traditional apparel markets centres. The data is processed with Structural Equation Modelling using Partial Least Squares. The results show that ICT capability has a significant effect on competitive advantage, entrepreneurial orientation and organisational agility. Organisational agility and entrepreneurial orientation have a significant effect on competitive advantage. This indicates that ICT capability in small businesses can be directly converted into a competitive advantage. The research findings show that ICT capability will be able to create competitive advantage for apparel retailers through entrepreneurial orientation and organisational agility. \u00a9 2020, Primrose Hall Publishing Group.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The aim of this paper is to find out how Information and Communication Technology (ICT) capability has affected competitive advantage through entrepreneurial orientation and organisational agility of the Indonesian apparel retailers. This study is based on resources that cannot be directly converted into competitive advantage for companies but must go through an entrepreneurial process and offer new insights into the use of ICT as a valuable company resource. The paper is based on a quantitative approach with the population of apparel retailers in traditional markets of Pekanbaru City, Indonesia. The sample was taken using random sampling. The survey was conducted in 104 small businesses in five traditional apparel markets centres. The data is processed with Structural Equation Modelling using Partial Least Squares. The results show that ICT capability has a significant effect on competitive advantage, entrepreneurial orientation and organisational agility. Organisational agility and entrepreneurial orientation have a significant effect on competitive advantage. This indicates that ICT capability in small businesses can be directly converted into a competitive advantage. The research findings show that ICT capability will be able to create competitive advantage for apparel retailers through entrepreneurial orientation and organisational agility. \u00a9 2020, Primrose Hall Publishing Group."
        ]
    },
    {
        "judul":[
            "Implementation of Simulated Annealing-Support Vector Machine on QSAR Study of Fusidic Acid Derivatives as Anti-Malarial Agent"
        ],
        "penulis":"Rahman, Farisi;Lhaksmana, Kemas Muslim;Kurniawan, Isman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Malaria is a disease caused by the Plasmodium falciparum parasite and leads to many cases of deaths. Recently, the combination of several drugs has been used to treat this disease. However, the parasite is known to be resistant to the anti-malarial agent. Hence, a new candidate for an anti-malarial drug is required to solve the resistance problem. One compound that is promising as an anti-malarial agent is fusidic acid derivatives. Fusidic acid is an antibiotic that is work by preventing parasite growth. Besides, fusidic acid is known to have antiplasmodial activity although the IC50 is still poor. However, the activity can be improved by optimizing the structure through its derivatives. In this study, we developed a QSAR model to predict the activity of fusidic acid derivatives as anti-malarial agent. The model was developed by using Simulated Annealing (SA) for feature selection and Support Vector Machine (SVM) for model development. The results show that SA produces a satisfying combination of features that are indicated by the trend of MSE value during the selection process. Regarding the performance, SVM with RBF kernel produces the best result of the validation parameter. This indicates that the model is valid to be used to predict a compound with unknown activity values for anti-malarial agents.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Malaria is a disease caused by the Plasmodium falciparum parasite and leads to many cases of deaths. Recently, the combination of several drugs has been used to treat this disease. However, the parasite is known to be resistant to the anti-malarial agent. Hence, a new candidate for an anti-malarial drug is required to solve the resistance problem. One compound that is promising as an anti-malarial agent is fusidic acid derivatives. Fusidic acid is an antibiotic that is work by preventing parasite growth. Besides, fusidic acid is known to have antiplasmodial activity although the IC50 is still poor. However, the activity can be improved by optimizing the structure through its derivatives. In this study, we developed a QSAR model to predict the activity of fusidic acid derivatives as anti-malarial agent. The model was developed by using Simulated Annealing (SA) for feature selection and Support Vector Machine (SVM) for model development. The results show that SA produces a satisfying combination of features that are indicated by the trend of MSE value during the selection process. Regarding the performance, SVM with RBF kernel produces the best result of the validation parameter. This indicates that the model is valid to be used to predict a compound with unknown activity values for anti-malarial agents.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Determinant Factors in Utilizing Electronic Signature Using the TAM and TOE Framework"
        ],
        "penulis":"Haryanto, Budi;Gandhi, Arfive;Giri Sucahyo, Yudho;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Electronic signature should accelerate and protect the electronic transactions in government agencies and non-governmental organizations, but its adoption is slow. Until the beginning of 2020, the number of organizations that utilize electronic signature is still very small compared to the number of organizations that have online service. This study aims to identify factors that determine employees in the organization to continue or are interested in utilizing electronic signature. The electronic signature referred to in this study is a certified electronic signature or digital signature. The survey was conducted on users and prospective users in government agencies and non-government organizations. The research uses an integrated framework Technology Acceptance Model (TAM) and Technology-Organization-Environment (TOE) in the information systems discipline. Based on 192 responses, the research framework is validated. Seven driving factors were successfully identified. The seven driving factors are security protection, internal need, training and education, government policy, vendor support, perceived ease of use, and perceived usefulness. The results of this study expand research on the adoption of electronic signature, and broaden research on technology acceptance models, specifically the TAM-TOE integration model. The findings of this study can be input for the government, electronic signature vendors, and organizations to increase the utilization of electronic signature. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electronic signature should accelerate and protect the electronic transactions in government agencies and non-governmental organizations, but its adoption is slow. Until the beginning of 2020, the number of organizations that utilize electronic signature is still very small compared to the number of organizations that have online service. This study aims to identify factors that determine employees in the organization to continue or are interested in utilizing electronic signature. The electronic signature referred to in this study is a certified electronic signature or digital signature. The survey was conducted on users and prospective users in government agencies and non-government organizations. The research uses an integrated framework Technology Acceptance Model (TAM) and Technology-Organization-Environment (TOE) in the information systems discipline. Based on 192 responses, the research framework is validated. Seven driving factors were successfully identified. The seven driving factors are security protection, internal need, training and education, government policy, vendor support, perceived ease of use, and perceived usefulness. The results of this study expand research on the adoption of electronic signature, and broaden research on technology acceptance models, specifically the TAM-TOE integration model. The findings of this study can be input for the government, electronic signature vendors, and organizations to increase the utilization of electronic signature. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Sentiment Analysis during Jakarta Flood for Emergency Responses and Situational Awareness in Disaster Management using BERT"
        ],
        "penulis":"Maharani, Warih;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Social media provide valuable information for disaster risk reduction as well as a disaster emergency response. Previous studies claim that social media data can be used in the emergency response effort, which is worthwhile for the Government, BNPB, as well as the community, to get a direct and credible information about the ongoing disaster situations. However, the social media data has not been widely used for emergency response and situational awareness in Indonesia. Therefore, in this paper we implement BERT method applied to a set of tweets related to Jakarta Flood in early 2020. We have crawled the tweet dataset during the Jakarta flood disaster in early 2020 which had become a trending topic on Twitter. We aim to identify the relevance tweets that may provide useful information related to emergency responses in disaster management. The experimental results indicate promising outcomes. However, the quality of the dataset greatly influences the system performance.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Social media provide valuable information for disaster risk reduction as well as a disaster emergency response. Previous studies claim that social media data can be used in the emergency response effort, which is worthwhile for the Government, BNPB, as well as the community, to get a direct and credible information about the ongoing disaster situations. However, the social media data has not been widely used for emergency response and situational awareness in Indonesia. Therefore, in this paper we implement BERT method applied to a set of tweets related to Jakarta Flood in early 2020. We have crawled the tweet dataset during the Jakarta flood disaster in early 2020 which had become a trending topic on Twitter. We aim to identify the relevance tweets that may provide useful information related to emergency responses in disaster management. The experimental results indicate promising outcomes. However, the quality of the dataset greatly influences the system performance.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Monitoring Financial Stability Based on Prediction of Cryptocurrencies Price Using Intelligent Algorithm"
        ],
        "penulis":"Saadah, Siti;Ahmad Whafa A.A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Financial stability is the problem that correlated with many aspects. In this digital era, virtual currency has emerged as one of financial assets. Fluctuation from cryptocurrencies price made an impact into financial stability indirectly. It has been proved by the market capitalization of publicly traded cryptocurrencies in 2019 reach USD 240 billion. The percentages reach 66% for the market capitalization. Three highest cryptocurrencies uphold are Bitcoin, Ethereum and XRP. This condition made these three cryptocurrencies become the important investment products. However, cryptocurrency is the product with high volatility. Because of that, this study aims to monitor financial stability from cryptocurrencies prediction using artificial intelligent algorithm. This research copes the problem by predicting bitcoin, Ethereum and XRP using three different intelligent algorithms, which are K-Nearest Neighbours (KNN), Support Vector Machine (SVM) and Long Short-Term Memory (LSTM). By this prediction had been figured out about up and down value of cryptocurrencies using Root Mean Square Error (RMSE) to evaluate stabilization of finance. Accuration system with LSTM shown that the price of cryptocurrency will fit with the data actual using LSTM, in which the accuracy around 80%. This condition meant that LSTM had been succeeded to proposed as algorithm that could fit the cryptocurrencies value. It could strengthen usability to indicate financial stability refer into cryptocurrencies price.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentReduced inequalitiesGoal 10",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Financial stability is the problem that correlated with many aspects. In this digital era, virtual currency has emerged as one of financial assets. Fluctuation from cryptocurrencies price made an impact into financial stability indirectly. It has been proved by the market capitalization of publicly traded cryptocurrencies in 2019 reach USD 240 billion. The percentages reach 66% for the market capitalization. Three highest cryptocurrencies uphold are Bitcoin, Ethereum and XRP. This condition made these three cryptocurrencies become the important investment products. However, cryptocurrency is the product with high volatility. Because of that, this study aims to monitor financial stability from cryptocurrencies prediction using artificial intelligent algorithm. This research copes the problem by predicting bitcoin, Ethereum and XRP using three different intelligent algorithms, which are K-Nearest Neighbours (KNN), Support Vector Machine (SVM) and Long Short-Term Memory (LSTM). By this prediction had been figured out about up and down value of cryptocurrencies using Root Mean Square Error (RMSE) to evaluate stabilization of finance. Accuration system with LSTM shown that the price of cryptocurrency will fit with the data actual using LSTM, in which the accuracy around 80%. This condition meant that LSTM had been succeeded to proposed as algorithm that could fit the cryptocurrencies value. It could strengthen usability to indicate financial stability refer into cryptocurrencies price.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A Reliable Public Safety Framework for Industrial Internet of Things (IIoT)"
        ],
        "penulis":"Reegu, Faheem;Zada Khan, Wazir;Mohd Daud, Salwani;Arshad, Quratulain;Armi, Nasrullah;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The paradigm of the Internet of Things (IoT) has revolutionized the industries which are also called Industry 4.0 or Industrial Internet of Things (IIoT). The major goal of IIoT or Industry 4.0 is to increase productivity and efficiency with minimum downtime and resources. To achieve the vision of IIoT, Public Safety (PS) should be the first concern of any industry. In this paper, we propose a reliable IoT based Public Safety (IoTPS) framework for IIoT. Besides, we also present a case study of the oil and gas industry to fully comprehend the importance of PS in IIoT. Finally, we highlighted the key characteristics of our pro-posed IoTPS system. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The paradigm of the Internet of Things (IoT) has revolutionized the industries which are also called Industry 4.0 or Industrial Internet of Things (IIoT). The major goal of IIoT or Industry 4.0 is to increase productivity and efficiency with minimum downtime and resources. To achieve the vision of IIoT, Public Safety (PS) should be the first concern of any industry. In this paper, we propose a reliable IoT based Public Safety (IoTPS) framework for IIoT. Besides, we also present a case study of the oil and gas industry to fully comprehend the importance of PS in IIoT. Finally, we highlighted the key characteristics of our pro-posed IoTPS system. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Ontology-based approach for dynamic e-learning personalization"
        ],
        "penulis":"Ayu Laksitowening, Kusuma;Arifin Hasibuan, Zainal;Budi Santoso, Harry;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "E-Learning personalization can be a solution to accommodate the variation of students' type since e-Learning allows the learning process of each student not to interfere with each other. Many variables may affect students' condition and behavior throughout the semester. Hence, students' type may change over time and different from one subject to another subject. Accordingly, the personalization should also be dynamic towards the changes that occur. In this research, we analyzed the students' type by processing the access log available on Learning Management Systems (LMS) from time to time. The results of the student analysis then become the reference for learning personalization using ontology. By utilizing ontology, personalization was presented by linking the students' type with activities that match the topic. The proposed personalized learning was applied to the prototype LMS later for testing and evaluation. The evaluation results indicated that personalized learning affects significantly to increase learning activities. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "E-Learning personalization can be a solution to accommodate the variation of students' type since e-Learning allows the learning process of each student not to interfere with each other. Many variables may affect students' condition and behavior throughout the semester. Hence, students' type may change over time and different from one subject to another subject. Accordingly, the personalization should also be dynamic towards the changes that occur. In this research, we analyzed the students' type by processing the access log available on Learning Management Systems (LMS) from time to time. The results of the student analysis then become the reference for learning personalization using ontology. By utilizing ontology, personalization was presented by linking the students' type with activities that match the topic. The proposed personalized learning was applied to the prototype LMS later for testing and evaluation. The evaluation results indicated that personalized learning affects significantly to increase learning activities. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Standalone Photovoltaic System Cost Optimization for Matantimali Village Central Sulawesi"
        ],
        "penulis":"Aprillia, Bandiyah Sri;Made Hendry Keswara I.;Raharjo, Jangkung;Ramdhani, Mohamad;Adam, Kharisma Bani;Suhartono, Efri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Electricity is very limited in Matantimali village where it is located on the slopes of Gawalise, Marawola District, Sigi Regency, Central Sulawesi Province. In this village, the state electricity company (PLN) can only provide electricity during the day from 06:00 to 18:00. During night, the diesel generator becomes the main energy source for the village providing electrical energy from 18:00 until 06:00. However, the use of diesel generators contradicts with the government commitment to generate environmental eco-friendly power generation. This study aims to analyse and to optimize the price of off-grid solar systems which will be implemented in the village of Matantimali as a potential replacement of the existing diesel based electric energy. We find in this study that 11 PV units with a total power of 3,686 Wp, two 2400 W powered inverter, and a 16-unit battery cover are the required specification for optimal power of 1300 VA load. The Off-grid solar panel installation system creates annual cost savings of IDR 3,543,397 compared to the use of conventional electricity using diesel generators and PLN.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Electricity is very limited in Matantimali village where it is located on the slopes of Gawalise, Marawola District, Sigi Regency, Central Sulawesi Province. In this village, the state electricity company (PLN) can only provide electricity during the day from 06:00 to 18:00. During night, the diesel generator becomes the main energy source for the village providing electrical energy from 18:00 until 06:00. However, the use of diesel generators contradicts with the government commitment to generate environmental eco-friendly power generation. This study aims to analyse and to optimize the price of off-grid solar systems which will be implemented in the village of Matantimali as a potential replacement of the existing diesel based electric energy. We find in this study that 11 PV units with a total power of 3,686 Wp, two 2400 W powered inverter, and a 16-unit battery cover are the required specification for optimal power of 1300 VA load. The Off-grid solar panel installation system creates annual cost savings of IDR 3,543,397 compared to the use of conventional electricity using diesel generators and PLN.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "PowerDoW (Power Digital Offset Weightage): Video ContentAdaptation (VCA) Profiling in Smartphone Devices for Energy Efficiency"
        ],
        "penulis":"Jofri, Muhammad Hanif;Lubis, Muharman;Fudzee, Mohd Farhan Md;Kasim, Shahreen;Ismail, Mohd Norasri;Witarsyah, Deden;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, the rapid enhancement of Internet connectivity and the recent progression of smartphone technologies lead to better smartphones quality towards video streaming activity. With the massive production of smartphone devices today, motivate studies of energy consumption behaviors to extend the smartphone device battery-life. Therefore, existing designs for smartphone devices occasionally lack energy-aware thus it need profiling optimization technique that reduces energy usage. Energy profiling in smartphone devices is one of the practical criteria for saving energy in smartphone devices during video streaming session. Energy efficiency features for smartphone devices, profiling and video content adaptation approach are the most critical parts for the energyefficient while streaming in course. However, the consideration of energy-aware profiling area has not yet been discovered widely. In this case, appointing promising approaches will be used to reduce energy consumption in the smartphone devices during video streaming session. A framework called PowerDoW will be benefited towards adding energy adaptation strategies. PowerDoW framework manage and utilize system profiling status to attain the entire streaming session activity and classify the streaming video format depending on the selective video parameter. Selection of the best quality depending on low energy usage will be determined in the profiling experimentation. The experimentations are based on the Android operating system in smartphone devices\u2014 instrumentation setup testing by using PowerTutor application to measure energy consumption in real-time. The result indicates that PowerDoW framework can reduce a huge energy consumption by selecting suitable video content adaptation during video streaming session. \u00a9 2020. All Rights Reserved.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, the rapid enhancement of Internet connectivity and the recent progression of smartphone technologies lead to better smartphones quality towards video streaming activity. With the massive production of smartphone devices today, motivate studies of energy consumption behaviors to extend the smartphone device battery-life. Therefore, existing designs for smartphone devices occasionally lack energy-aware thus it need profiling optimization technique that reduces energy usage. Energy profiling in smartphone devices is one of the practical criteria for saving energy in smartphone devices during video streaming session. Energy efficiency features for smartphone devices, profiling and video content adaptation approach are the most critical parts for the energyefficient while streaming in course. However, the consideration of energy-aware profiling area has not yet been discovered widely. In this case, appointing promising approaches will be used to reduce energy consumption in the smartphone devices during video streaming session. A framework called PowerDoW will be benefited towards adding energy adaptation strategies. PowerDoW framework manage and utilize system profiling status to attain the entire streaming session activity and classify the streaming video format depending on the selective video parameter. Selection of the best quality depending on low energy usage will be determined in the profiling experimentation. The experimentations are based on the Android operating system in smartphone devices\u2014 instrumentation setup testing by using PowerTutor application to measure energy consumption in real-time. The result indicates that PowerDoW framework can reduce a huge energy consumption by selecting suitable video content adaptation during video streaming session. \u00a9 2020. All Rights Reserved."
        ]
    },
    {
        "judul":[
            "Solar Cell Output Optimization using Light Convergence Method"
        ],
        "penulis":"Aprillia, Bandiyah Sri;Ekaputri, Cahyantari;Zul Fahmi, Muhammad Rafiqy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Light intensity is one of the many factors that can influence the power output of a solar cell. In this research, light convergence method is performed by using a Fresnel lens to increase the light intensity that are passes through the solar cells. 2 solar cells are used for this research. One of them is paired with a Fresnel lens positioned perpendicularly at a distance of 5cm. The output from both solar cells are then compared. The solar cell paired with the Fresnel lens contains a higher power output by up to 40.29% at 13.10 o'clock in the afternoon compared to a normal solar cell. However therein lies a decrease in power output at 10.00 - 10.30 o'clock and 13.30 - 14.00 o'clock by up to -30.65% because shadows from the Fresnel lens relative to the sun's position affects the light intensity a solar cell receives. Results from 3 days' worth of tests shows that at 10.00 - 14.00 o'clock, the solar cell paired with a Fresnel lens retain a higher average power output of around 6.08% compared to a solar cell without one. \u00a9 2020 IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Light intensity is one of the many factors that can influence the power output of a solar cell. In this research, light convergence method is performed by using a Fresnel lens to increase the light intensity that are passes through the solar cells. 2 solar cells are used for this research. One of them is paired with a Fresnel lens positioned perpendicularly at a distance of 5cm. The output from both solar cells are then compared. The solar cell paired with the Fresnel lens contains a higher power output by up to 40.29% at 13.10 o'clock in the afternoon compared to a normal solar cell. However therein lies a decrease in power output at 10.00 - 10.30 o'clock and 13.30 - 14.00 o'clock by up to -30.65% because shadows from the Fresnel lens relative to the sun's position affects the light intensity a solar cell receives. Results from 3 days' worth of tests shows that at 10.00 - 14.00 o'clock, the solar cell paired with a Fresnel lens retain a higher average power output of around 6.08% compared to a solar cell without one. \u00a9 2020 IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Motion control system of numerical control machine tool under image processing"
        ],
        "penulis":"Zeng, Qi;Luu, Viet Hung;Saedudin, Rd Rohmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper is to study the overall structure of the motion control system of the numerical control machine tool to improve motion control precision. It performs digital image processing on the obtained workpiece image, extracts the coordinate of the tool setting point, and calculates the distance of the tool setting. Comparison of algorithms in image processing accomplished and improved to increase the positioning accuracy and stability of the tool setting system. The results show that to improve the effect of workpiece edge detection, recommended by this study based on the Canny operator, and the morphological processing of the fusion image to detect the edge of the workpiece. In the algorithm of tool setting point coordinate extraction, an improved Hough transform algorithm is used to extract the coordinates of the center of a rectangular workpiece and a circular workpiece respectively, which reduces the complexity of the algorithm. In the algorithm of calculating the distance from the tool tip to the tool setting point, the optimization principle of the distance from the point to the straight line is used to determine the tool tip. Then, the descending distance of the tool is determined in the tool setting, completing the extraction of the three-dimensional machine coordinate of the tool setting point. Based on the camera calibration, the image is processed using a visual positioning software algorithm to extract the machine coordinates of the tool setting point of the workpiece and the tool\u2019s descending distance. The motion information instruction is sent to the motion controller via the host computer. The motion controller controls the movement of the actuator, adjusts the movement distance of the three axes of the machine tool, to complete an automatic tool setting of the workpiece of the numerical control machine tool. It improves the intelligence and automation of the numerical control machine tool setting technology. \u00a9 2020, Cefin Publishing House. All rights reserved."
        ],
        "abstrak":[
            "This paper is to study the overall structure of the motion control system of the numerical control machine tool to improve motion control precision. It performs digital image processing on the obtained workpiece image, extracts the coordinate of the tool setting point, and calculates the distance of the tool setting. Comparison of algorithms in image processing accomplished and improved to increase the positioning accuracy and stability of the tool setting system. The results show that to improve the effect of workpiece edge detection, recommended by this study based on the Canny operator, and the morphological processing of the fusion image to detect the edge of the workpiece. In the algorithm of tool setting point coordinate extraction, an improved Hough transform algorithm is used to extract the coordinates of the center of a rectangular workpiece and a circular workpiece respectively, which reduces the complexity of the algorithm. In the algorithm of calculating the distance from the tool tip to the tool setting point, the optimization principle of the distance from the point to the straight line is used to determine the tool tip. Then, the descending distance of the tool is determined in the tool setting, completing the extraction of the three-dimensional machine coordinate of the tool setting point. Based on the camera calibration, the image is processed using a visual positioning software algorithm to extract the machine coordinates of the tool setting point of the workpiece and the tool\u2019s descending distance. The motion information instruction is sent to the motion controller via the host computer. The motion controller controls the movement of the actuator, adjusts the movement distance of the three axes of the machine tool, to complete an automatic tool setting of the workpiece of the numerical control machine tool. It improves the intelligence and automation of the numerical control machine tool setting technology. \u00a9 2020, Cefin Publishing House. All rights reserved."
        ]
    },
    {
        "judul":[
            "Prognostics Health Management (PHM) System for Power Transformer Using Kernel Extreme Learning Machine (K-ELM)"
        ],
        "penulis":"Abdillah, Muhammad;Krismanto, Awan Uji;Nugroho, Teguh Aryo;Setiadi, Herlambang;Pertiwi, Nita Indriani;Mahmoud, Karar;Prasetio, Murman Dwi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A power transformer is one of the most important and valuable components for the power system network. This device is critical to ensure power quality and reliable electricity supply for consumers. When the power transformer could not work properly or out of service in unforeseen ways, it provides a severe impact on power system utilities and customers in term of the expensive of transformer's replacement cost and revenue lost caused by the electrical blackout. To overcome these issues, the proper prognostics health management (PHM) system as a tool for condition monitoring and health assessment of these valuable assets is required. This paper proposed a PHM system based on a kernel extreme learning machine (K-ELM) for power transformer's health assessment. Two sets of variable combinations called Set-1 and Set-2 were considered to examine the robustness and efficacy of the proposed method. In Set-1, the input variables were water content, total acidity, breakdown voltage, dissipation factor, dissolved combustible gases, and 2-furfuraldehyde. While the output of PHM system was the health condition which categorized as good, moderate, and bad circumstances. Set-2 utilized water content, total acidity, breakdown voltage, dissipation factor, and interfacial tension as input variables. Whereas, the PHM system outputs consisted of four categories: normal, good, moderate, and bad. The proposed method with two sets of variables had showed the satisfactory results for transformer's health condition assessment compared to an extreme learning machine (ELM), support vector machine (SVM), and least-square support vector machine (LS-SVM) in terms of learning and testing accuracies and computation time. The proposed PHM system using the Set-1 dataset could assess the transformer health as of 100% while in terms of the testing process, the proposed PHM system has an excellent accuracy result as of 68.67%. Furthermore, the proposed PHM system using the Set-2 dataset had successfully assessed the transformer health as of 100%. In the testing phase, the proposed PHM system model has a rigorous result for its accuracy result as of 93.61%. \u00a9 2020 Association for Computing Machinery.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A power transformer is one of the most important and valuable components for the power system network. This device is critical to ensure power quality and reliable electricity supply for consumers. When the power transformer could not work properly or out of service in unforeseen ways, it provides a severe impact on power system utilities and customers in term of the expensive of transformer's replacement cost and revenue lost caused by the electrical blackout. To overcome these issues, the proper prognostics health management (PHM) system as a tool for condition monitoring and health assessment of these valuable assets is required. This paper proposed a PHM system based on a kernel extreme learning machine (K-ELM) for power transformer's health assessment. Two sets of variable combinations called Set-1 and Set-2 were considered to examine the robustness and efficacy of the proposed method. In Set-1, the input variables were water content, total acidity, breakdown voltage, dissipation factor, dissolved combustible gases, and 2-furfuraldehyde. While the output of PHM system was the health condition which categorized as good, moderate, and bad circumstances. Set-2 utilized water content, total acidity, breakdown voltage, dissipation factor, and interfacial tension as input variables. Whereas, the PHM system outputs consisted of four categories: normal, good, moderate, and bad. The proposed method with two sets of variables had showed the satisfactory results for transformer's health condition assessment compared to an extreme learning machine (ELM), support vector machine (SVM), and least-square support vector machine (LS-SVM) in terms of learning and testing accuracies and computation time. The proposed PHM system using the Set-1 dataset could assess the transformer health as of 100% while in terms of the testing process, the proposed PHM system has an excellent accuracy result as of 68.67%. Furthermore, the proposed PHM system using the Set-2 dataset had successfully assessed the transformer health as of 100%. In the testing phase, the proposed PHM system model has a rigorous result for its accuracy result as of 93.61%. \u00a9 2020 Association for Computing Machinery."
        ]
    },
    {
        "judul":[
            "Face detection using the viola jones method with segmentation of skin color on face images"
        ],
        "penulis":"Fachrurrozi, Muhammad;Saparudin;Afif, Kerel Khalif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Face detection is a step used to look for faces in an image. The process of finding faces in this study uses the Viola-Jones method that detects faces in the color segmentation images. Skin color segmentation is used to remove information in images that have no potential as a face. Reducing unnecessary information on the image can improve the performance of face detection. One area that has potential as a face on the human body is skin color. Based on the test results with single face image data, the values of recall and precision were 94.11% and 99.83% and the accuracy of detection accuracy using Intersection over Union was 0.6963 with 6.14% faster processing time than the Viola-Jones only.\u00e2 \u00a9 School of Engineering, Taylor\u00e2\u2122s University.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Face detection is a step used to look for faces in an image. The process of finding faces in this study uses the Viola-Jones method that detects faces in the color segmentation images. Skin color segmentation is used to remove information in images that have no potential as a face. Reducing unnecessary information on the image can improve the performance of face detection. One area that has potential as a face on the human body is skin color. Based on the test results with single face image data, the values of recall and precision were 94.11% and 99.83% and the accuracy of detection accuracy using Intersection over Union was 0.6963 with 6.14% faster processing time than the Viola-Jones only.\u00e2 \u00a9 School of Engineering, Taylor\u00e2\u2122s University."
        ]
    },
    {
        "judul":[
            "Healthy food intake advisor using decision support system"
        ],
        "penulis":"Hwee, Lee Jia;Witarsyah, Deden;Kasim, Shahreen;Fudzee, Mohd Farhan Md;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The difficulties to decide the food to eat and do not have enough knowledge that what foods should be avoided when pregnant or when facing some health problem. Healthy Food Advisor is an Android based application which acts as a healthy controller to all of the users. The purpose of developing this application is to suggest healthy food to users based on their personal condition in order to make them have a healthy lifestyle. Users are required to record all of the details such as age, height and weight, so the application and calculate the Body Mass Index (BMI) value and caloric needs to user. Application will recommended the most suitable food lists to users according to their personal condition. Through this application, users no longer need to spend more time to think on a meal and busy to search from online that the nutrition information of food. The methodology used to develop this Android based application is Object-oriented Software Development (OOSD) model. Software technology used to develop this application is Ionic Framework where this technology uses web technology language to develop mobile hybrid application. Database used for this system is Firebase while programming language used to develop this application is AngularJS, HTML, TypeScript and SCSS. Hereby, this application is able to provide a simple and portable solution to help people decide the food and increase the knowledge of the public. \u00a9 2020, IJSTR.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The difficulties to decide the food to eat and do not have enough knowledge that what foods should be avoided when pregnant or when facing some health problem. Healthy Food Advisor is an Android based application which acts as a healthy controller to all of the users. The purpose of developing this application is to suggest healthy food to users based on their personal condition in order to make them have a healthy lifestyle. Users are required to record all of the details such as age, height and weight, so the application and calculate the Body Mass Index (BMI) value and caloric needs to user. Application will recommended the most suitable food lists to users according to their personal condition. Through this application, users no longer need to spend more time to think on a meal and busy to search from online that the nutrition information of food. The methodology used to develop this Android based application is Object-oriented Software Development (OOSD) model. Software technology used to develop this application is Ionic Framework where this technology uses web technology language to develop mobile hybrid application. Database used for this system is Firebase while programming language used to develop this application is AngularJS, HTML, TypeScript and SCSS. Hereby, this application is able to provide a simple and portable solution to help people decide the food and increase the knowledge of the public. \u00a9 2020, IJSTR."
        ]
    },
    {
        "judul":[
            "Traffic Flow Prediction using SUMO Application with K-Nearest Neighbor (KNN) Method"
        ],
        "penulis":"Aditya, Fikri;Nasution, Surya Michrandi;Virgono, Agus;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In Indonesia, the density of traffic flow occurs at the time of leaving and returning to work, long holidays or national holidays such as the end of the year (New Year). This annual routine activity is mostly carried out especially in big cities in Indonesia such as Bandung. Because Bandung is a city that has a lot of tourism, Bandung is therefore always the center of visitors to enjoy weekends or long holidays. So from this problem, we want to create a traffic prediction application that can help to solve congestion problems that have become an annual routine. The several types of vehicles used in the prediction are private cars, motorcycles, taxis, public transportation, large buses, mini buses, and mini trucks. Research conducted using the K-Nearest Neighbor method is a prediction of short-term traffic flow on Jl. Riau Bandung. The input used in making predictions is historical data on the number of vehicles going on Jl. Riau Bandung. The output generated from the use of the K-Nearest Neighbor method is the level of the jam class that runs on Jl. Riau Bandung in 2018 used a simulation on the SUMO (Simulation of Urban Mobility) application. The resulting performance of KNN with k = 3 has an accuracy of 99.21%, k = 5 has an accuracy of 99.60%, and k = 7 has an accuracy rate of 99.21% on 90% training data and 10% testing data. \u00a9 2020 Universiti Tun Hussein Onn Malaysia Publisher\u2019s Office",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In Indonesia, the density of traffic flow occurs at the time of leaving and returning to work, long holidays or national holidays such as the end of the year (New Year). This annual routine activity is mostly carried out especially in big cities in Indonesia such as Bandung. Because Bandung is a city that has a lot of tourism, Bandung is therefore always the center of visitors to enjoy weekends or long holidays. So from this problem, we want to create a traffic prediction application that can help to solve congestion problems that have become an annual routine. The several types of vehicles used in the prediction are private cars, motorcycles, taxis, public transportation, large buses, mini buses, and mini trucks. Research conducted using the K-Nearest Neighbor method is a prediction of short-term traffic flow on Jl. Riau Bandung. The input used in making predictions is historical data on the number of vehicles going on Jl. Riau Bandung. The output generated from the use of the K-Nearest Neighbor method is the level of the jam class that runs on Jl. Riau Bandung in 2018 used a simulation on the SUMO (Simulation of Urban Mobility) application. The resulting performance of KNN with k = 3 has an accuracy of 99.21%, k = 5 has an accuracy of 99.60%, and k = 7 has an accuracy rate of 99.21% on 90% training data and 10% testing data. \u00a9 2020 Universiti Tun Hussein Onn Malaysia Publisher\u2019s Office"
        ]
    },
    {
        "judul":[
            "Digital pulse analyzer for simultaneous measurement of pulse height, pulse width, and interval time on an optical particle counter"
        ],
        "penulis":"Saputra, Casmika;Munir, Muhammad Miftahul;Waris, Abdul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study examined the development of a digital pulse analyzer (DPA) used for obtaining the pulse height distribution (PHD), pulse width distribution (PWD), and interval time distribution (ITD) simultaneously by processing output signals from an optical particle counter (OPC). The characterization was performed by testing the response of the DPA as a function of its input frequency and pulse height using dummy signals from a signal generator (model DG1022, Rigol Technologies Inc., People's Republic of China) and actual OPC signals (Model KC-03, Rion Co. Ltd, Japan). Polystyrene latex particles of various sizes yielded by a scanning mobility particle sizer were used during the calibration of the DPA. It was found that the geometric mean of the PHDs was in accordance with Mie theory and could be used for converting pulse height into data which represents the size of particles. Furthermore, by using the PWD and ITD, we could estimate the viewing volume and dead time of the OPC. The DPA could successfully discriminate particles from baseline noise or voltage spikes by applying a novel algorithm to detect pulses based on the pulse area (integral of the voltage-time curve). The results showed that the ranges of particle diameter, viewing volume, and dead time measured by the OPC-DPA system were 0.2-1 \u00b5m, (0.78 0.09) mm3, and (45.9\u00b112.6) \u00b5s, respectively. The new algorithm can be applied to pulse height analyzers in general, in the measurement of aerosol particles or scintillator-based particle detectors. \u00a9 2020 IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study examined the development of a digital pulse analyzer (DPA) used for obtaining the pulse height distribution (PHD), pulse width distribution (PWD), and interval time distribution (ITD) simultaneously by processing output signals from an optical particle counter (OPC). The characterization was performed by testing the response of the DPA as a function of its input frequency and pulse height using dummy signals from a signal generator (model DG1022, Rigol Technologies Inc., People's Republic of China) and actual OPC signals (Model KC-03, Rion Co. Ltd, Japan). Polystyrene latex particles of various sizes yielded by a scanning mobility particle sizer were used during the calibration of the DPA. It was found that the geometric mean of the PHDs was in accordance with Mie theory and could be used for converting pulse height into data which represents the size of particles. Furthermore, by using the PWD and ITD, we could estimate the viewing volume and dead time of the OPC. The DPA could successfully discriminate particles from baseline noise or voltage spikes by applying a novel algorithm to detect pulses based on the pulse area (integral of the voltage-time curve). The results showed that the ranges of particle diameter, viewing volume, and dead time measured by the OPC-DPA system were 0.2-1 \u00b5m, (0.78 0.09) mm3, and (45.9\u00b112.6) \u00b5s, respectively. The new algorithm can be applied to pulse height analyzers in general, in the measurement of aerosol particles or scintillator-based particle detectors. \u00a9 2020 IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Band pass filter comparison of hairpin line and square open-loop resonator method for digital tv community"
        ],
        "penulis":"Prasetya, Budi;Rohmah, Yuyun Siti;Nurmantris, Dwi Andi;Mulyawati, Sarah;Dipayana, Reza;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The selection of the right filter design method is a very important first step for a radio frequency engineer. This paper presents the comparison of two methods of band pass filter design using hairpin-line and square open-loop resonator. Both methods were applied to obtain filter designs that can work for broadcasting system in digital television community. Band pass filter was simulated using design software and fabricated using epoxy FR-4 substrate. The results of simulation and measurement shown return loss value at 27.3 dB for hairpin line band pass filter and 25.901 for square open-loop resonator band pass filter. Voltage standing wave ratio parameter values were 1.09 and 1.1067 for hairpin line and square open-loop band pass filter respectively. The insertion loss values for the Hairpin line band pass filter and square open-loop band pass filter were 0.9692 and near 0 dB, respectively. Fractional bandwidth, for hairpin line band pass filter, was 6.7% while for square open-loop band pass filter was 4.8%. Regarding the size, the dimension of square open-loop resonator was approximately five times larger than hairpin-line band pass filter. Based on the advantages of the hairpin line method, we recommend that researchers choose the filter for digital TV broadcasting. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The selection of the right filter design method is a very important first step for a radio frequency engineer. This paper presents the comparison of two methods of band pass filter design using hairpin-line and square open-loop resonator. Both methods were applied to obtain filter designs that can work for broadcasting system in digital television community. Band pass filter was simulated using design software and fabricated using epoxy FR-4 substrate. The results of simulation and measurement shown return loss value at 27.3 dB for hairpin line band pass filter and 25.901 for square open-loop resonator band pass filter. Voltage standing wave ratio parameter values were 1.09 and 1.1067 for hairpin line and square open-loop band pass filter respectively. The insertion loss values for the Hairpin line band pass filter and square open-loop band pass filter were 0.9692 and near 0 dB, respectively. Fractional bandwidth, for hairpin line band pass filter, was 6.7% while for square open-loop band pass filter was 4.8%. Regarding the size, the dimension of square open-loop resonator was approximately five times larger than hairpin-line band pass filter. Based on the advantages of the hairpin line method, we recommend that researchers choose the filter for digital TV broadcasting. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Pushing the LTE Capability towards 5G: The Analysis of Licensed Assisted Access (LAA) Implementation for High-Density Area in Indonesia"
        ],
        "penulis":"Ksamawati, Ni Made Dwidhyana;Gunawan, Dadang;Nashiruddin, Muhammad Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The number of mobile network subscribers has increased over the past few years rapidly. 4G LTE, as a part of wireless technology, made a significant contribution through the coverage expansion around countries but still faces critical issues, namely spectrum scarcity. However, the growth of data users and data consumption seems to be increased. The Mobile Network Operator (MNO) tried to provide the infrastructures and services that capable of responding to the necessity of capacity, reliability, and availability. 3GPP answered the opportunity by introducing the LTE-Advanced Pro (4.9 G) technology with 3GPP Rel-13 that called Licensed Assisted Access (LAA). LAA uses carrier aggregation technology, both licensed and 5 GHz unlicensed band. Through utilizing the unlicensed band, MNO tried to face the necessity of improvement with the cost-efficiency. This paper tries to introduce the LAA implementation in a dense urban area of Indonesia. Based on the calculation result of capacity and coverage planning in Jakarta, LAA will increase the capacity from 41.95% to 61.67% in the time period 2020-2030 based on existing LTE capacity. Besides capacity planning, the coverage planning resulted in the amount of required LAA site to covered 40 Points of Interest (POI) area by 72 outdoor LAA and 119 indoor LAA. According to business feasibility analysis for economic aspects, LAA business implementation in the dense urban area is categorized as feasible with positive NPV value at IDR 390,653,517,937; IRR > rate at 40.61%, and three years and three months payback period (PP) on the baseline scenario. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The number of mobile network subscribers has increased over the past few years rapidly. 4G LTE, as a part of wireless technology, made a significant contribution through the coverage expansion around countries but still faces critical issues, namely spectrum scarcity. However, the growth of data users and data consumption seems to be increased. The Mobile Network Operator (MNO) tried to provide the infrastructures and services that capable of responding to the necessity of capacity, reliability, and availability. 3GPP answered the opportunity by introducing the LTE-Advanced Pro (4.9 G) technology with 3GPP Rel-13 that called Licensed Assisted Access (LAA). LAA uses carrier aggregation technology, both licensed and 5 GHz unlicensed band. Through utilizing the unlicensed band, MNO tried to face the necessity of improvement with the cost-efficiency. This paper tries to introduce the LAA implementation in a dense urban area of Indonesia. Based on the calculation result of capacity and coverage planning in Jakarta, LAA will increase the capacity from 41.95% to 61.67% in the time period 2020-2030 based on existing LTE capacity. Besides capacity planning, the coverage planning resulted in the amount of required LAA site to covered 40 Points of Interest (POI) area by 72 outdoor LAA and 119 indoor LAA. According to business feasibility analysis for economic aspects, LAA business implementation in the dense urban area is categorized as feasible with positive NPV value at IDR 390,653,517,937; IRR > rate at 40.61%, and three years and three months payback period (PP) on the baseline scenario. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Broadband Metasurfaces through First Order Approximation of Surface Impedances"
        ],
        "penulis":"Fathnan, Ashif A.;Olk, Andreas E.;Powell, David A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We introduce a method of bandwidth enhancement on metasurfaces based on a more insightful analytical approach of LC resonances. In obtaining L and C parameters, we use surface impedance model considering not only a single frequency matching but also its first frequency derivative. We show that broadband anomalous reflection can be obtain with simple geometries involving dipole and inverse dipole structures. We verified our method using experiment in millimeter-wave frequencies and show that the broadband metasurface achieves a significant increase of bandwidth (more than 80% increase) compared to a single frequency design, with minimum -3dB power is maintained in the desired reflection and maximum -10dB for all other diffraction orders. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We introduce a method of bandwidth enhancement on metasurfaces based on a more insightful analytical approach of LC resonances. In obtaining L and C parameters, we use surface impedance model considering not only a single frequency matching but also its first frequency derivative. We show that broadband anomalous reflection can be obtain with simple geometries involving dipole and inverse dipole structures. We verified our method using experiment in millimeter-wave frequencies and show that the broadband metasurface achieves a significant increase of bandwidth (more than 80% increase) compared to a single frequency design, with minimum -3dB power is maintained in the desired reflection and maximum -10dB for all other diffraction orders. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Service Platform for Smart City As A Service"
        ],
        "penulis":"Prasetyo, Yuli Adam;Albarda;Suhardi;Arman, Arry Ahmad;Yustianto, Purnomo;Hartanti, Fera Tri;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "An ecosystem of digital services requires a service platform to facilitate a dynamic service introduction. As a system of systems and a service-oriented system, Smart City has key characteristics of a service ecosystem. However, a service platform has unique characteristics to become a service platform for the implementation of Smart City. On the other hand, an implementation of a service platform for a Smart City must depart from a proven service platform concept conforming to the characteristics of a Smart City Architecture. This paper elaborates an initial process of a service platform implementation with Smart City characteristics. This initial study takes its form as a descriptive study from a systematic literature review employing a Design Research Methodology (DRM) approach. This paper provides an overview of an application of service platforms concept in the digital service ecosystem and service computing systems to fulfill the need of a Smart City Architecture characteristics.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An ecosystem of digital services requires a service platform to facilitate a dynamic service introduction. As a system of systems and a service-oriented system, Smart City has key characteristics of a service ecosystem. However, a service platform has unique characteristics to become a service platform for the implementation of Smart City. On the other hand, an implementation of a service platform for a Smart City must depart from a proven service platform concept conforming to the characteristics of a Smart City Architecture. This paper elaborates an initial process of a service platform implementation with Smart City characteristics. This initial study takes its form as a descriptive study from a systematic literature review employing a Design Research Methodology (DRM) approach. This paper provides an overview of an application of service platforms concept in the digital service ecosystem and service computing systems to fulfill the need of a Smart City Architecture characteristics.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A Selection of Bandung City Travel Route Using The FLOYD-WARSHALL Algorithm"
        ],
        "penulis":"Arfananda, Muhammad Ghifari;Nasution, Surya Michrandi;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The rapid development of information and technology, the city of Bandung tourism has also increased. However, tourists who visit the city of Bandung have problems with a limited time when visiting Bandung tourist attractions. Traffic congestion, distance, and the number of tourist destinations are the problems for tourists travel. The optimal route selection is the solution for those problems. Congestion and distance data are processed using the Simple Additive Weighting (SAW) method. Route selection uses the Floyd-Warshall Algorithm. In this study, the selection of the best route gets the smallest weight with a value of 5.127 from the Algorithm process. Based on testing, from two to five tourist attractions get an average calculation time of 3 to 5 seconds. This application is expected to provide optimal solutions for tourists in the selection of tourist travel routes. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher\u2019s Office",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The rapid development of information and technology, the city of Bandung tourism has also increased. However, tourists who visit the city of Bandung have problems with a limited time when visiting Bandung tourist attractions. Traffic congestion, distance, and the number of tourist destinations are the problems for tourists travel. The optimal route selection is the solution for those problems. Congestion and distance data are processed using the Simple Additive Weighting (SAW) method. Route selection uses the Floyd-Warshall Algorithm. In this study, the selection of the best route gets the smallest weight with a value of 5.127 from the Algorithm process. Based on testing, from two to five tourist attractions get an average calculation time of 3 to 5 seconds. This application is expected to provide optimal solutions for tourists in the selection of tourist travel routes. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher\u2019s Office"
        ]
    },
    {
        "judul":[
            "Green Production Using ERP: Case Study in the Leather Tanning Industry"
        ],
        "penulis":"Ikhsan, Ihwanul;Ridwan, Ari Yanuar;Saputra, Muhardi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Along with the times, information technology must be a public need that must be approved, including for companies. PT. Elco Indonesia Sejahtera is a company engaged in the trading of leather for the production of garment materials, gloves, and various other leather goods. This company is located on the street of Gagak Lumayung, Wetan City, Garut Kota District, Garut Regency, West Java. Production processes that produce complex solid and liquid environments use clam fuel in the process. This will be dangerous for the environment. Green Production is one way to overcome the process of making goods that can support business processes at PT. Elco Indonesia Sejahtera. Therefore in this study will develop a Green ERP application in the production module to realize an environmentally friendly green industry. This research uses SAP Activate method that starts from the interview process, starts with observation, and analyzes business processes, and analyzes and discusses the system by configuring and discussing module production. This study uses a system that supports the business process of PT Elco Indonesia Sejahtera, Odoo. The results of this study are ERP systems that are supported by Odoo and have been adapted to the company's business processes that have been redesigned and are expected to facilitate the company in carrying out business process activities specifically produced at PT. Elco Indonesia Sejahtera. This research is able to integrate the manufacturing module with the green procurement and green sales and distribution modules. The green production module can produce monitoring reports (Manufacturing Orders, Work Orders, and Overall Equipment Affection) from manufacturing orders in the Manufacturing module for the Odoo-based leather tanning industry.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Responsible consumption and productionGoal 12Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Along with the times, information technology must be a public need that must be approved, including for companies. PT. Elco Indonesia Sejahtera is a company engaged in the trading of leather for the production of garment materials, gloves, and various other leather goods. This company is located on the street of Gagak Lumayung, Wetan City, Garut Kota District, Garut Regency, West Java. Production processes that produce complex solid and liquid environments use clam fuel in the process. This will be dangerous for the environment. Green Production is one way to overcome the process of making goods that can support business processes at PT. Elco Indonesia Sejahtera. Therefore in this study will develop a Green ERP application in the production module to realize an environmentally friendly green industry. This research uses SAP Activate method that starts from the interview process, starts with observation, and analyzes business processes, and analyzes and discusses the system by configuring and discussing module production. This study uses a system that supports the business process of PT Elco Indonesia Sejahtera, Odoo. The results of this study are ERP systems that are supported by Odoo and have been adapted to the company's business processes that have been redesigned and are expected to facilitate the company in carrying out business process activities specifically produced at PT. Elco Indonesia Sejahtera. This research is able to integrate the manufacturing module with the green procurement and green sales and distribution modules. The green production module can produce monitoring reports (Manufacturing Orders, Work Orders, and Overall Equipment Affection) from manufacturing orders in the Manufacturing module for the Odoo-based leather tanning industry.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance of multiclass caching with static proportion in mobile named data network"
        ],
        "penulis":"Yovita, Leanna Vidya;Syambas, Nana Rachmana;Edward, Ian Yosef Matheus;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Regarding the caching needs of the NDN, traffic can be grouped by paying attention to storage requirements in the content store, such as how often requests come for the content in that class and how long the content in that class needs to be stored. Some previous studies explain content differentiated, but not yet analyze the performance of using the multiclass caching technique in various possible scenarios in detail. This paper will be evaluated and analyzed the performance of the multiclass cache technique with the various possible condition. Multiclass caching discussed in this paper is a caching algorithm that notices the content class distinctions and treats them differently in the content store. Each content class has a different logical cache portion in the content store. The goal of this research is to explore the performance of multiclass caching with the various condition of the system. The simulation result shows the effect of various cache portions, Zipf exponential factor, and the number of routers. It can be concluded that the multiclass cache is proven to accommodate the network performance per class and also the overall network cache hit ratio.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Regarding the caching needs of the NDN, traffic can be grouped by paying attention to storage requirements in the content store, such as how often requests come for the content in that class and how long the content in that class needs to be stored. Some previous studies explain content differentiated, but not yet analyze the performance of using the multiclass caching technique in various possible scenarios in detail. This paper will be evaluated and analyzed the performance of the multiclass cache technique with the various possible condition. Multiclass caching discussed in this paper is a caching algorithm that notices the content class distinctions and treats them differently in the content store. Each content class has a different logical cache portion in the content store. The goal of this research is to explore the performance of multiclass caching with the various condition of the system. The simulation result shows the effect of various cache portions, Zipf exponential factor, and the number of routers. It can be concluded that the multiclass cache is proven to accommodate the network performance per class and also the overall network cache hit ratio.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "IoT Object Security towards the Sybil Attack Using the Trustworthiness Management"
        ],
        "penulis":"Hadiansyah, Ridwan;Suryani, Vera;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Internet of Things (IoT), commonly referred to a physical object connected to network, refers to a paradigm in information technology integrating the advances in terms of sensing, computation and communication to improve the service in daily life. This physical object consists of sensors and actuators that are capable of changing the data to offer the improvement of service quality in daily life. When a data exchange occurs, the exchanged data become sensitive; making them vulnerable to any security attacks, one of which, for example, is Sybil attack. This paper aimed to propose a method of trustworthiness management based upon the authentication and trust value. Once performing the test on three scenarios, the system was found to be capable of detecting the Sybil attack rapidly and accurately. The average of time to detect the Sybil attacks was 9.3287 seconds and the average of time required to detect the intruder object in the system was 18.1029 seconds. The accuracy resulted in each scenario was found 100% indicating that the detection by the system to Sybil attack was 100% accurate.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet of Things (IoT), commonly referred to a physical object connected to network, refers to a paradigm in information technology integrating the advances in terms of sensing, computation and communication to improve the service in daily life. This physical object consists of sensors and actuators that are capable of changing the data to offer the improvement of service quality in daily life. When a data exchange occurs, the exchanged data become sensitive; making them vulnerable to any security attacks, one of which, for example, is Sybil attack. This paper aimed to propose a method of trustworthiness management based upon the authentication and trust value. Once performing the test on three scenarios, the system was found to be capable of detecting the Sybil attack rapidly and accurately. The average of time to detect the Sybil attacks was 9.3287 seconds and the average of time required to detect the intruder object in the system was 18.1029 seconds. The accuracy resulted in each scenario was found 100% indicating that the detection by the system to Sybil attack was 100% accurate.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Effects of Incriminating COVID-19 News on the Returning Indonesians\u2019 Anxiety"
        ],
        "penulis":"Pradana, Mahir;Syahputra, Syahputra;Wardhana, Aditya;Kartawinata, Budi Rustandi;Wijayangka, Candra;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The World Health Organization (WHO) has declared the novel coronavirus (COVID-19) as a global pandemic. Governments have urged their citizens to return to their home countries. In the case of Indonesia, some new coverage about COVID-19 which is disseminated by major national media channels has negatively influenced Indonesian travelers\u2019 mental condition. Returning Indonesians face anxiety for having been labeled as \u201cvirus carriers.\u201d This article explores how sensationalism in media reports may affect society\u2019s perspective toward returning Indonesian tourists during the COVID-19 pandemic. \u00a9 2020, \u00a9 2020 Taylor & Francis Group, LLC.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The World Health Organization (WHO) has declared the novel coronavirus (COVID-19) as a global pandemic. Governments have urged their citizens to return to their home countries. In the case of Indonesia, some new coverage about COVID-19 which is disseminated by major national media channels has negatively influenced Indonesian travelers\u2019 mental condition. Returning Indonesians face anxiety for having been labeled as \u201cvirus carriers.\u201d This article explores how sensationalism in media reports may affect society\u2019s perspective toward returning Indonesian tourists during the COVID-19 pandemic. \u00a9 2020, \u00a9 2020 Taylor & Francis Group, LLC."
        ]
    },
    {
        "judul":[
            "Determinant factors of consumer preferences on electronic wallet users in bandung"
        ],
        "penulis":"Hasbi, Imanuddin;Fakhri, Mahendra;Saragih, Romat;Kurnia, Benny;Aini, Alisha Gustiana;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this modern era, the use of digital wallets has become a trend in people's lifestyles in the transaction. In Indonesia, there are 38 digital wallets with official licenses, one of which is OVO. In its development, OVO is considered to have a very rapid growth to successfully occupy the position of the two most popular e-wallets in Indonesia. Because of this, this research was conducted to determine consumer preferences in using OVO in Bandung. In this study, the method used is a quantitative method with descriptive analysis and factor analysis as data processing assisted with SPSS. The sampling technique used is a nonprobability sampling technique with a purposive sampling type. The respondents surveyed in this study were 100 people who reside in Bandung and use OVO for transactions. The results showed that eleven initial factors became consumers' preferences in using OVO in Bandung. Based on the results of data processing with descriptive analysis, consumer preference variables are included in the high category, with a score of 81.85%. Based on factor analysis, the factor formed is one factor, namely competitive advantage, with the dominant factor being security, which has the most considerable correlation of 0.929 or 92, 9%. \u00a9 IEOM Society International.",
            "BHIPH2View detailsExpand Substance PBI-9393",
            "Powered by",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this modern era, the use of digital wallets has become a trend in people's lifestyles in the transaction. In Indonesia, there are 38 digital wallets with official licenses, one of which is OVO. In its development, OVO is considered to have a very rapid growth to successfully occupy the position of the two most popular e-wallets in Indonesia. Because of this, this research was conducted to determine consumer preferences in using OVO in Bandung. In this study, the method used is a quantitative method with descriptive analysis and factor analysis as data processing assisted with SPSS. The sampling technique used is a nonprobability sampling technique with a purposive sampling type. The respondents surveyed in this study were 100 people who reside in Bandung and use OVO for transactions. The results showed that eleven initial factors became consumers' preferences in using OVO in Bandung. Based on the results of data processing with descriptive analysis, consumer preference variables are included in the high category, with a score of 81.85%. Based on factor analysis, the factor formed is one factor, namely competitive advantage, with the dominant factor being security, which has the most considerable correlation of 0.929 or 92, 9%. \u00a9 IEOM Society International."
        ]
    },
    {
        "judul":[
            "Freight route planning in intermodal transportation network to deal with combinational disruptions"
        ],
        "penulis":"Rosyida, Erly E;Santosa, Budi;Pujawan, I Nyoman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In this study, we developed an intermodal transportation model that extends the VRP model and its recovery model. This study emphasizes re-identifying the best route, departure time, and the selection of the best ship with the right type of capacity booking that produces the lowest total cost after dealing with disruption. The re-routing process is shifted by transforming the disruption to a virtual node in order to define the added time and cost after a disruption occurred. The disruption types include link and customer disruptions. The numerical experiment uses the metaheuristics, namely, Genetic Algorithm and Simulated Annealing, because it is an np-hard problem. The results of the optimization process yielded the total cost increased when the average vehicle speed was enhanced. The starting service time provides cost savings through a reduction of penalties because the arrival is not within the time window that had been agreed upon. Besides, the type of capacity order, more specifically the type of direct purchase (on the spot), provides better costs when the level of disruption is heavy. In contrast, a lighter level of disruption can cause a minimal total cost for purchasing the up-front type of fee. However, the scenario of capacity cost shows that lower prices can make the direct purchasing type more profitable. On the other hand, increasing the price of renting a ship\u2019s capacity makes the up-front type of fees more profitable. \u00a9 2020 The Author(s). This open access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In this study, we developed an intermodal transportation model that extends the VRP model and its recovery model. This study emphasizes re-identifying the best route, departure time, and the selection of the best ship with the right type of capacity booking that produces the lowest total cost after dealing with disruption. The re-routing process is shifted by transforming the disruption to a virtual node in order to define the added time and cost after a disruption occurred. The disruption types include link and customer disruptions. The numerical experiment uses the metaheuristics, namely, Genetic Algorithm and Simulated Annealing, because it is an np-hard problem. The results of the optimization process yielded the total cost increased when the average vehicle speed was enhanced. The starting service time provides cost savings through a reduction of penalties because the arrival is not within the time window that had been agreed upon. Besides, the type of capacity order, more specifically the type of direct purchase (on the spot), provides better costs when the level of disruption is heavy. In contrast, a lighter level of disruption can cause a minimal total cost for purchasing the up-front type of fee. However, the scenario of capacity cost shows that lower prices can make the direct purchasing type more profitable. On the other hand, increasing the price of renting a ship\u2019s capacity makes the up-front type of fees more profitable. \u00a9 2020 The Author(s). This open access article is distributed under a Creative Commons Attribution (CC-BY) 4.0 license."
        ]
    },
    {
        "judul":[
            "A Distributed Fuzzy Logic with Consensus for Exhaust Fan Controller"
        ],
        "penulis":"Munir, Misbakhul;Erfianto, Bayu;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Recently, the deployment of several exhaust fans for indoor cannot perform smoke suction ditributedly with the different exhaust fan speed according to the spread of smoke concentrations. It is because of the commercial exhaust fans sold in the market only have a constant fan rotational speed (usually full speed). Therefore, in this paper, a distributed fuzzy logic exhaust fan controller system with consensus averaging is designed to control different fan speed based on the distribution of smoke concentration in a closed room. Smoke is detected by smoke sensor in the form of carbon monoxide (CO) gas from burning wood charcoal. Based on the experiment, after the fuzzy logic process, each controller can communicate and exchange fuzzy logic output with its adjacent controllers to execute average consensus algorithm to regulate fan speed with respect to smoke concentration.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Recently, the deployment of several exhaust fans for indoor cannot perform smoke suction ditributedly with the different exhaust fan speed according to the spread of smoke concentrations. It is because of the commercial exhaust fans sold in the market only have a constant fan rotational speed (usually full speed). Therefore, in this paper, a distributed fuzzy logic exhaust fan controller system with consensus averaging is designed to control different fan speed based on the distribution of smoke concentration in a closed room. Smoke is detected by smoke sensor in the form of carbon monoxide (CO) gas from burning wood charcoal. Based on the experiment, after the fuzzy logic process, each controller can communicate and exchange fuzzy logic output with its adjacent controllers to execute average consensus algorithm to regulate fan speed with respect to smoke concentration.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Optimization of Storage Allocation for Final Goods Warehouse Using Genetic Algorithm"
        ],
        "penulis":"Arif, Faizal Noor;Irawan, Budhi;Setianingsih, Casi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the manufacturing industry in the modern era, several constraints are often encountered in the development and management of warehouses, such as arranging goods that are not neatly arranged so that a lot of free space is not utilized optimally in the warehouse. In this research, the Genetic Algorithm application was discussed in optimizing the arrangement of storage of manufactured goods in warehouses. Genetic Algorithm is a method that is often used in optimizing by relying on natural selection to get the best fitness value; the items used are cubic with different sizes according to the type of thing. The use of Genetic Algorithms in this research aims to find the best fitness value in the allocation of goods in the finished warehouse so that the arrangement and allocation of goods are not done carelessly and can reduce the free space in the warehouse; the results of this study will be displayed in the java application in the form of tables and visualization of placement of goods on the shelf. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the manufacturing industry in the modern era, several constraints are often encountered in the development and management of warehouses, such as arranging goods that are not neatly arranged so that a lot of free space is not utilized optimally in the warehouse. In this research, the Genetic Algorithm application was discussed in optimizing the arrangement of storage of manufactured goods in warehouses. Genetic Algorithm is a method that is often used in optimizing by relying on natural selection to get the best fitness value; the items used are cubic with different sizes according to the type of thing. The use of Genetic Algorithms in this research aims to find the best fitness value in the allocation of goods in the finished warehouse so that the arrangement and allocation of goods are not done carelessly and can reduce the free space in the warehouse; the results of this study will be displayed in the java application in the form of tables and visualization of placement of goods on the shelf. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Performance Comparison of File Transfer Protocol Service between Link State and Distance Vector Routing Protocol in Software Defined Network"
        ],
        "penulis":"Tulloh, Rohmat;Amri Ginting, Jafaruddin Gusti;Mulyana, Asep;Lutfi, Muhammad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Software-Defined Network (SDN) is a new concept in computer networks where the network control function is separated from the data forwarding function (data plane). The control plane and data plane which are separated from each other is the answer for faster, more flexible, and secure internet service. File transfer protocol (FTP) is an internet protocol that runs at the application layer that is used to exchange data between server and client. Open Shortest Path First (OSPF) is a routing protocol for internet networks that belongs to the Interior Gateway Protocol (IGP) group and uses the Link State Routing algorithm (LSR). Routing Information Protocol (RIP) is a type of Distance Vector Routing protocol that is still used today. This study aims to compare the performance of FTP services using OSPF and RIP on SDN networks and conventional networks. The research was conducted with direct implementation on the device with a planned topology. The measurement results show that FTP using OSPF routing has better results than using RIP. FTP that runs on SDN also has a better quality of service value compared to conventional networks.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Software-Defined Network (SDN) is a new concept in computer networks where the network control function is separated from the data forwarding function (data plane). The control plane and data plane which are separated from each other is the answer for faster, more flexible, and secure internet service. File transfer protocol (FTP) is an internet protocol that runs at the application layer that is used to exchange data between server and client. Open Shortest Path First (OSPF) is a routing protocol for internet networks that belongs to the Interior Gateway Protocol (IGP) group and uses the Link State Routing algorithm (LSR). Routing Information Protocol (RIP) is a type of Distance Vector Routing protocol that is still used today. This study aims to compare the performance of FTP services using OSPF and RIP on SDN networks and conventional networks. The research was conducted with direct implementation on the device with a planned topology. The measurement results show that FTP using OSPF routing has better results than using RIP. FTP that runs on SDN also has a better quality of service value compared to conventional networks.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Function of PMO for successful program-project management in the bank company - A case study"
        ],
        "penulis":"Yana, Rika Rizki;Sasongko, Danarto Tri;Wardhana, Aditya Wisnu;Ilona, Kwee Felicia;Shihab, Muhammad Rifki;Ranti, Benny;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The purpose of this paper is to investigate the specific function of Program Management Office (PMO) to manage multiple Kaizen or improvement projects and how we can implement PMO with more effective and more efficient to deliver value, benefits and achieve business goal in bank company. Research indicate that project management become increasingly difficult to manage when multiple projects are many overlapping projects in a project-oriented company, the goal in a need for enhanced bank company controls to increase success rates. It caused with implementation of a system that help project management, the system named Project Management Office (PMO) that is essential for bank company that are project-oriented and faced many overlapping projects. The PMO with an essential model that will explain to us to have management system of multiple project effectively in a banking company. Using a case study in one of banking industry in Indonesia, to test the method of research found that PMO deliver excellent value for bank company. The survey result of PMO function saw that most of project stakeholders in banking company agreed to 5 (five) categories and 20 (twenty) specified of PMO function implementation to manage several banking projects excellent. based on the results of the questionnaire, stakeholders answered more agreeably with the function of PMO for success project management at bank company and it could answer to the question that the method has deliver benefit and create goals for project management office performance in bank company.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The purpose of this paper is to investigate the specific function of Program Management Office (PMO) to manage multiple Kaizen or improvement projects and how we can implement PMO with more effective and more efficient to deliver value, benefits and achieve business goal in bank company. Research indicate that project management become increasingly difficult to manage when multiple projects are many overlapping projects in a project-oriented company, the goal in a need for enhanced bank company controls to increase success rates. It caused with implementation of a system that help project management, the system named Project Management Office (PMO) that is essential for bank company that are project-oriented and faced many overlapping projects. The PMO with an essential model that will explain to us to have management system of multiple project effectively in a banking company. Using a case study in one of banking industry in Indonesia, to test the method of research found that PMO deliver excellent value for bank company. The survey result of PMO function saw that most of project stakeholders in banking company agreed to 5 (five) categories and 20 (twenty) specified of PMO function implementation to manage several banking projects excellent. based on the results of the questionnaire, stakeholders answered more agreeably with the function of PMO for success project management at bank company and it could answer to the question that the method has deliver benefit and create goals for project management office performance in bank company.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Acceptance and Usage of Bibliographic Management Software in Higher Education: The Student and Teacher Point of View"
        ],
        "penulis":"Setiani, Novi;Aditya, Bayu Rima;Wijayanto, Inung;Wijaya, Adi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "There is a need to investigate the factors affecting researchers' awareness and usage of Bibliographic Management Software (BMS) to deal with the plagiarism issue. This study aims to assess the student and teacher acceptance of BMS. A quantitative approach involves 108 samples collected from various higher education institutions in Indonesia is used. The design of the questionnaire adopts the six dimensions and 19 acceptance variables based on the Unified Theory Technology of Acceptance and User of Technology (UTAUT) model, and for the data analysis, this study uses a t-test for path analysis. This study found that the use of BMS has had accepted student and teacher points of view. In addition, this study confirms that behavior intention and facilitating conditions significantly influence the use of behavior from the student and teacher's point of view when interacting with BMS. This finding could provide more understanding of students' and teachers' acceptance of BMS use for academic activities.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "There is a need to investigate the factors affecting researchers' awareness and usage of Bibliographic Management Software (BMS) to deal with the plagiarism issue. This study aims to assess the student and teacher acceptance of BMS. A quantitative approach involves 108 samples collected from various higher education institutions in Indonesia is used. The design of the questionnaire adopts the six dimensions and 19 acceptance variables based on the Unified Theory Technology of Acceptance and User of Technology (UTAUT) model, and for the data analysis, this study uses a t-test for path analysis. This study found that the use of BMS has had accepted student and teacher points of view. In addition, this study confirms that behavior intention and facilitating conditions significantly influence the use of behavior from the student and teacher's point of view when interacting with BMS. This finding could provide more understanding of students' and teachers' acceptance of BMS use for academic activities.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A Proposed user requirements document for children's learning application"
        ],
        "penulis":"Sabariah, Mira Kania;Santosa, Paulus Insap;Ferdiana, Ridi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "User requirements are the highest level of requirements. Flawed user requirements document can cause defects in the software being built-aspects of applications that were not presented in the user requirements document to cause a defect. In learning applications for children, there are aspects of pedagogy that need to be well documented. This aspect is not available in the general user requirements document, so it is often not well presented. The learning style and thinking skills level is crucial to be well presented in the user requirements document. That was because the children's persona cannot be compared at every range criteria of developmental age. That factor will undoubtedly affect the specifications of the software to be built. Users' viewpoints about different requirements can also make developers wrong in determining requirements. Applying requirements prioritization in the user requirements document can help resolve the problem. Measurement of document quality was also performed using parameters in measuring the quality of the user requirements document. The results of measuring the quality of the user requirements document found that it is reliable for use. \u00a9 2020, Science and Information Organization.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "User requirements are the highest level of requirements. Flawed user requirements document can cause defects in the software being built-aspects of applications that were not presented in the user requirements document to cause a defect. In learning applications for children, there are aspects of pedagogy that need to be well documented. This aspect is not available in the general user requirements document, so it is often not well presented. The learning style and thinking skills level is crucial to be well presented in the user requirements document. That was because the children's persona cannot be compared at every range criteria of developmental age. That factor will undoubtedly affect the specifications of the software to be built. Users' viewpoints about different requirements can also make developers wrong in determining requirements. Applying requirements prioritization in the user requirements document can help resolve the problem. Measurement of document quality was also performed using parameters in measuring the quality of the user requirements document. The results of measuring the quality of the user requirements document found that it is reliable for use. \u00a9 2020, Science and Information Organization."
        ]
    },
    {
        "judul":[
            "Preliminary Study for identifying Rice Plant Disease Based on Thermal Images"
        ],
        "penulis":"Silvi Lydia, Maya;Aulia, Indra;Jaya, Ivan;Sofiah Hanafiah, Diana;Hakim Lubis, Rizky;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Accurate and timely identification of plant disease can help stakeholders and farmers to mitigate losses due to pests and diseases. One of the identification techniques is indirect detection using thermal imaging technology. This technology has been considered a fast way without damaging the profile of a plant. In this paper, we describe the preliminary study of the thermal images gathering, so that the rice plant disease on the leaf canopy can be identified by using a thermal imaging camera. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Accurate and timely identification of plant disease can help stakeholders and farmers to mitigate losses due to pests and diseases. One of the identification techniques is indirect detection using thermal imaging technology. This technology has been considered a fast way without damaging the profile of a plant. In this paper, we describe the preliminary study of the thermal images gathering, so that the rice plant disease on the leaf canopy can be identified by using a thermal imaging camera. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Parallel Algorithm for K-Means Clustering in Wood Species Classification"
        ],
        "penulis":"Gunawan P.H.;Fathurahman, Taufik;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Wood is one of the commodities that are often traded for industrial materials such as furniture, crafts, building raw materials, etc. Therefore identification system of wood species is needed to find out how the condition of the wood which can be seen from the vessel structure and its diameter. To do this identification, a large enough dataset of wood image is needed so that the data can be validated. From large datasets of wood image, the grouping of wooden vessels can be carried out using computing method which is called K-means clustering. However, using large wood image datasets will increase the computational cost. In this research, K-means clustering method will be implemented in serial and parallel programs to see the use of parallel program to handle computational cost. Here speedup and efficiency measurements will be elaborated to see the benefit of parallel program. The experiment result show that speedup using parallel computing is increasingly 4 times faster then serial computing. Moreover the efficiency using parallel architecture is observed 96.04%. Therefore it can be concluded that implementing the K-means clustering method in parallel programs can obtain optimal computational cost and produce high-efficiency values using the same workload as the serial program. \u00a9 2020, Springer Nature Switzerland AG.",
            "NONHSH2CCH3H3CView detailsExpand Substance Albutoin",
            "Powered by"
        ],
        "abstrak":[
            "Wood is one of the commodities that are often traded for industrial materials such as furniture, crafts, building raw materials, etc. Therefore identification system of wood species is needed to find out how the condition of the wood which can be seen from the vessel structure and its diameter. To do this identification, a large enough dataset of wood image is needed so that the data can be validated. From large datasets of wood image, the grouping of wooden vessels can be carried out using computing method which is called K-means clustering. However, using large wood image datasets will increase the computational cost. In this research, K-means clustering method will be implemented in serial and parallel programs to see the use of parallel program to handle computational cost. Here speedup and efficiency measurements will be elaborated to see the benefit of parallel program. The experiment result show that speedup using parallel computing is increasingly 4 times faster then serial computing. Moreover the efficiency using parallel architecture is observed 96.04%. Therefore it can be concluded that implementing the K-means clustering method in parallel programs can obtain optimal computational cost and produce high-efficiency values using the same workload as the serial program. \u00a9 2020, Springer Nature Switzerland AG."
        ]
    },
    {
        "judul":[
            "Design of IOT-based smart laundry applications using fuzzy algorithms"
        ],
        "penulis":"Saleha, Baqiatus;Nasution, Surya Michrandi;Prasasti, Anggunmeka Luhur;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A smart city is a city concept who designed to help make it easy for people to access information and communication in their daily lives, with the Internet of things technology that helps to create electronic devices connected to each other so that they can send data or do anything by reducing the function of humans. This research is to make the newest ideas in laundry services that support the development of smart cities, on IoT-based Smart Laundry on web applications that can simplify make the use of laundry more easier and more practical for users of laundry services on IoT-based Smart Laundry on web applications that can make it easier to use laundry services so that it will be saves more time and more practical for laundry service users. By using the Fuzzy Algorithm as one of the Artificial Intelligence methods to support decision making in this system. This algorithm serves to make decisions in sorting which laundry will be picked up and also in this study the Fuzzy Algorithm will produce the output to classify the price of laundry that will be paid by the user with the parameters of weight, humidity, and color. So, the laundry owner doesn't need to calculate manually again.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A smart city is a city concept who designed to help make it easy for people to access information and communication in their daily lives, with the Internet of things technology that helps to create electronic devices connected to each other so that they can send data or do anything by reducing the function of humans. This research is to make the newest ideas in laundry services that support the development of smart cities, on IoT-based Smart Laundry on web applications that can simplify make the use of laundry more easier and more practical for users of laundry services on IoT-based Smart Laundry on web applications that can make it easier to use laundry services so that it will be saves more time and more practical for laundry service users. By using the Fuzzy Algorithm as one of the Artificial Intelligence methods to support decision making in this system. This algorithm serves to make decisions in sorting which laundry will be picked up and also in this study the Fuzzy Algorithm will produce the output to classify the price of laundry that will be paid by the user with the parameters of weight, humidity, and color. So, the laundry owner doesn't need to calculate manually again.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Oversampling based on data augmentation in convolutional neural network for silicon wafer defect classification"
        ],
        "penulis":"Batool, Uzma;Shapiai, Mohd Ibrahim;Ismail, Nordinah;Fauzi, Hilman;Salleh, Syahrizal;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Silicon wafer defect data collected from fabrication facilities is intrinsically imbalanced because of the variable frequencies of defect types. Frequently occurring types will have more influence on the classification predictions if a model gets trained on such skewed data. A fair classifier for such imbalanced data requires a mechanism to deal with type imbalance in order to avoid biased results. This study has proposed a convolutional neural network for wafer map defect classification, employing oversampling as an imbalance addressing technique. To have an equal participation of all classes in the classifier's training, data augmentation has been employed, generating more samples in minor classes. The proposed deep learning method has been evaluated on a real wafer map defect dataset and its classification results on the test set returned a 97.91% accuracy. The results were compared with another deep learning based auto-encoder model demonstrating the proposed method, a potential approach for silicon wafer defect classification that needs to be investigated further for its robustness.  \u00a9 2020 The authors and IOS Press. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Silicon wafer defect data collected from fabrication facilities is intrinsically imbalanced because of the variable frequencies of defect types. Frequently occurring types will have more influence on the classification predictions if a model gets trained on such skewed data. A fair classifier for such imbalanced data requires a mechanism to deal with type imbalance in order to avoid biased results. This study has proposed a convolutional neural network for wafer map defect classification, employing oversampling as an imbalance addressing technique. To have an equal participation of all classes in the classifier's training, data augmentation has been employed, generating more samples in minor classes. The proposed deep learning method has been evaluated on a real wafer map defect dataset and its classification results on the test set returned a 97.91% accuracy. The results were compared with another deep learning based auto-encoder model demonstrating the proposed method, a potential approach for silicon wafer defect classification that needs to be investigated further for its robustness.  \u00a9 2020 The authors and IOS Press. All rights reserved."
        ]
    },
    {
        "judul":[
            "Classification of Road Surface Quality Based on SVM Method"
        ],
        "penulis":"Afenika, Adhelinia;Gunawan P.H.;Tarwidi D.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Damaged and potholes roads can occur due to rain puddles, too many heavy vehicles, poor asphalt quality, or maybe long road life. Damaged roads can hamper activities and endanger the safety of road users. It is necessary to monitor road quality periodically which is conducted by government, so that roads improvement can be done quick as possible. The aim of this study is to build a systemthat can classify roads surface quality. Support Vector Machine (SVM) classifications method is used to classify roads based on roadworthiness. In this study, 300 road surface data which contains good\/smooth and damage quality of road are used. The simulation results show that SVM model can classify road surface data into two classes with average accuracy of 93%. The results can be a recommendation for government to prioritize which roads need to be improved. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Damaged and potholes roads can occur due to rain puddles, too many heavy vehicles, poor asphalt quality, or maybe long road life. Damaged roads can hamper activities and endanger the safety of road users. It is necessary to monitor road quality periodically which is conducted by government, so that roads improvement can be done quick as possible. The aim of this study is to build a systemthat can classify roads surface quality. Support Vector Machine (SVM) classifications method is used to classify roads based on roadworthiness. In this study, 300 road surface data which contains good\/smooth and damage quality of road are used. The simulation results show that SVM model can classify road surface data into two classes with average accuracy of 93%. The results can be a recommendation for government to prioritize which roads need to be improved. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Performance of multiclass caching with static proportion in mobile named data network"
        ],
        "penulis":"Yovita, Leanna Vidya;Syambas, Nana Rachmana;Edward, Ian Yosef Matheus;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Regarding the caching needs of the NDN, traffic can be grouped by paying attention to storage requirements in the content store, such as how often requests come for the content in that class and how long the content in that class needs to be stored. Some previous studies explain content differentiated, but not yet analyze the performance of using the multiclass caching technique in various possible scenarios in detail. This paper will be evaluated and analyzed the performance of the multiclass cache technique with the various possible condition. Multiclass caching discussed in this paper is a caching algorithm that notices the content class distinctions and treats them differently in the content store. Each content class has a different logical cache portion in the content store. The goal of this research is to explore the performance of multiclass caching with the various condition of the system. The simulation result shows the effect of various cache portions, Zipf exponential factor, and the number of routers. It can be concluded that the multiclass cache is proven to accommodate the network performance per class and also the overall network cache hit ratio.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Regarding the caching needs of the NDN, traffic can be grouped by paying attention to storage requirements in the content store, such as how often requests come for the content in that class and how long the content in that class needs to be stored. Some previous studies explain content differentiated, but not yet analyze the performance of using the multiclass caching technique in various possible scenarios in detail. This paper will be evaluated and analyzed the performance of the multiclass cache technique with the various possible condition. Multiclass caching discussed in this paper is a caching algorithm that notices the content class distinctions and treats them differently in the content store. Each content class has a different logical cache portion in the content store. The goal of this research is to explore the performance of multiclass caching with the various condition of the system. The simulation result shows the effect of various cache portions, Zipf exponential factor, and the number of routers. It can be concluded that the multiclass cache is proven to accommodate the network performance per class and also the overall network cache hit ratio.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "IoT Object Security towards the Sybil Attack Using the Trustworthiness Management"
        ],
        "penulis":"Hadiansyah, Ridwan;Suryani, Vera;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Internet of Things (IoT), commonly referred to a physical object connected to network, refers to a paradigm in information technology integrating the advances in terms of sensing, computation and communication to improve the service in daily life. This physical object consists of sensors and actuators that are capable of changing the data to offer the improvement of service quality in daily life. When a data exchange occurs, the exchanged data become sensitive; making them vulnerable to any security attacks, one of which, for example, is Sybil attack. This paper aimed to propose a method of trustworthiness management based upon the authentication and trust value. Once performing the test on three scenarios, the system was found to be capable of detecting the Sybil attack rapidly and accurately. The average of time to detect the Sybil attacks was 9.3287 seconds and the average of time required to detect the intruder object in the system was 18.1029 seconds. The accuracy resulted in each scenario was found 100% indicating that the detection by the system to Sybil attack was 100% accurate.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet of Things (IoT), commonly referred to a physical object connected to network, refers to a paradigm in information technology integrating the advances in terms of sensing, computation and communication to improve the service in daily life. This physical object consists of sensors and actuators that are capable of changing the data to offer the improvement of service quality in daily life. When a data exchange occurs, the exchanged data become sensitive; making them vulnerable to any security attacks, one of which, for example, is Sybil attack. This paper aimed to propose a method of trustworthiness management based upon the authentication and trust value. Once performing the test on three scenarios, the system was found to be capable of detecting the Sybil attack rapidly and accurately. The average of time to detect the Sybil attacks was 9.3287 seconds and the average of time required to detect the intruder object in the system was 18.1029 seconds. The accuracy resulted in each scenario was found 100% indicating that the detection by the system to Sybil attack was 100% accurate.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Coordinated Beamforming for Multi-Cell Non-Orthogonal Multiple Access-Based Spatial Modulation"
        ],
        "penulis":"Hendraningrat, Denny Kusuma;Satrya, Gandeva Bayu;Ramatryana, I. Nyoman Apraz;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper proposes coordinated beamforming (CB) that works over non-orthogonal multiple access (NOMA) scheme integrated with spatial modulation (SM), termed as CB NOMA-SM, to improve capacity and user fairness. User capacity, ergodic sum capacity (ESC), and user fairness of $K$ number of coordinated base stations (BSs) are simulated and analyzed by comparing them with joint transmission coordinated multi-point based NOMA with SM (JT-CoMP NOMA-SM), NOMA, and orthogonal multiple access (OMA). The results show that the proposed system outperforms the other schemes both in ESC and user fairness due to the enhancing CEU while CCU capacity still can be maintained. \u00a9 2013 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes coordinated beamforming (CB) that works over non-orthogonal multiple access (NOMA) scheme integrated with spatial modulation (SM), termed as CB NOMA-SM, to improve capacity and user fairness. User capacity, ergodic sum capacity (ESC), and user fairness of $K$ number of coordinated base stations (BSs) are simulated and analyzed by comparing them with joint transmission coordinated multi-point based NOMA with SM (JT-CoMP NOMA-SM), NOMA, and orthogonal multiple access (OMA). The results show that the proposed system outperforms the other schemes both in ESC and user fairness due to the enhancing CEU while CCU capacity still can be maintained. \u00a9 2013 IEEE."
        ]
    },
    {
        "judul":[
            "Long term evolution (lte) network planning in jakarta-cikampek elevated toll"
        ],
        "penulis":"Nursafitri, Dennisa Aliffa;Usman, Uke Kurniawan;Maulana, M. Irfan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Motorized vehicles user, especially those who use the four wheels, who often pass the Jakarta-Cikampek toll road, may often have difficulty connecting to their cellular operator network services, which may be due to the density of users and the influence of the condition of the area which is classified as open space. Along with the increase of users passing through the Cikampek Toll Road, the construction of the overpass on the Jakarta-Cikampek route was held as a form of anticipation of traffic congestion. With this condition, the number of devices requiring network services in the area will also increase. Therefore, in this research will carry out network planning for the Cikampek elevated toll area. Network planning in this research will carry out by conducting capacity planning and coverage planning. The data that will be used for the planning will be base on Cikampek toll users, also the population of the cities around Cikampek elevated toll route. Then, from the data obtained will be use for calculations in coverage and capacity planning for the elevated toll that is being built. With this planning, it is known the minimum site of 8 to fulfilled the service to fulfilled the need of the users. By doing the simulation using Atoll software, was measure the quality of the network from the planning. With the SINR average of 8.23 dB, throughput average of 31.99 Mbps, and BLER average of 0,01%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Motorized vehicles user, especially those who use the four wheels, who often pass the Jakarta-Cikampek toll road, may often have difficulty connecting to their cellular operator network services, which may be due to the density of users and the influence of the condition of the area which is classified as open space. Along with the increase of users passing through the Cikampek Toll Road, the construction of the overpass on the Jakarta-Cikampek route was held as a form of anticipation of traffic congestion. With this condition, the number of devices requiring network services in the area will also increase. Therefore, in this research will carry out network planning for the Cikampek elevated toll area. Network planning in this research will carry out by conducting capacity planning and coverage planning. The data that will be used for the planning will be base on Cikampek toll users, also the population of the cities around Cikampek elevated toll route. Then, from the data obtained will be use for calculations in coverage and capacity planning for the elevated toll that is being built. With this planning, it is known the minimum site of 8 to fulfilled the service to fulfilled the need of the users. By doing the simulation using Atoll software, was measure the quality of the network from the planning. With the SINR average of 8.23 dB, throughput average of 31.99 Mbps, and BLER average of 0,01%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Security Value Issues on eHealth Implementation in Indonesia"
        ],
        "penulis":"Sari P.K.;Handayani P.W.;Hidayanto A.N.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "eHealth is an information technology solution for improving healthcare to be more effective and efficient. eHealth innovations not only give expected benefits but also new problems, one of them is security value issues. This inquiry has purpose to identify problems of security-related value in eHealth implementation in Indonesia involving its stakeholders. We use constructivism as research paradigm with qualitative method. Data was collected through focus group discussion with five information security experts from State Cyber and Code Agency that work on security controls in healthcare sector. Data analysis using thematic coding with Atlas.ti as tool. This research explored some security value issues on eHealth implementation in Indonesia, including regulator value conflict, data integrity and reliability, and data privacy and confidentiality. Some of those problems are caused by specific regulation about information security for healthcare in Indonesia is not available yet that makes some value conflict among stakeholders involved in this sector. Some implications are also proposed, both practically and theoretically.  \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "eHealth is an information technology solution for improving healthcare to be more effective and efficient. eHealth innovations not only give expected benefits but also new problems, one of them is security value issues. This inquiry has purpose to identify problems of security-related value in eHealth implementation in Indonesia involving its stakeholders. We use constructivism as research paradigm with qualitative method. Data was collected through focus group discussion with five information security experts from State Cyber and Code Agency that work on security controls in healthcare sector. Data analysis using thematic coding with Atlas.ti as tool. This research explored some security value issues on eHealth implementation in Indonesia, including regulator value conflict, data integrity and reliability, and data privacy and confidentiality. Some of those problems are caused by specific regulation about information security for healthcare in Indonesia is not available yet that makes some value conflict among stakeholders involved in this sector. Some implications are also proposed, both practically and theoretically.  \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Implementation voice command system for soccer robot ersow"
        ],
        "penulis":"Prasetyo, Muhammad Rizal;Wibowo, Iwan Kumianto;Bachtiar, Mochamad Mobed;Priambudi, Renardi Adryantoro;Anwar, Khoirul;Segara, Putu Bagus Kertha;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "ERSOW is a wheeled soccer robot that is included in the Middle Size League (MSL) category in the Indonesian Wheeled Robot Soccer Contest division (Wheeled KRSBI). Wheeled soccer robot has Artificial Intelligent (AI) for kick the ball, receive the ball, feed the ball, recognize the ball, recognize the opponent, recognize the goal, receive instructions from the base station, and so forth. This research focuses on giving instructions to ERSOW through the base station using the voice command system. The system uses speech as input in the form of analog signals. Speech recognition is done by using a deep speech package so as to produce output in the form of text. The system will run on the Robot Operating System (ROS). The result of speech recognition using 13 trained speakers when tested by one speaker in different distance show average Word Error Rate (WER) 0.46% and Word Accuracy (W Acc) is 99.54%. When tested by five different speaker using trained speakers show average WER is 4.37% and W Acc is 95.63%, when using non trained speakers show average WER is 28.25% and W Acc is 71.75%. Base station implementation shows the simulation of the robot when the user gives instruction by his or her own voice.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "ERSOW is a wheeled soccer robot that is included in the Middle Size League (MSL) category in the Indonesian Wheeled Robot Soccer Contest division (Wheeled KRSBI). Wheeled soccer robot has Artificial Intelligent (AI) for kick the ball, receive the ball, feed the ball, recognize the ball, recognize the opponent, recognize the goal, receive instructions from the base station, and so forth. This research focuses on giving instructions to ERSOW through the base station using the voice command system. The system uses speech as input in the form of analog signals. Speech recognition is done by using a deep speech package so as to produce output in the form of text. The system will run on the Robot Operating System (ROS). The result of speech recognition using 13 trained speakers when tested by one speaker in different distance show average Word Error Rate (WER) 0.46% and Word Accuracy (W Acc) is 99.54%. When tested by five different speaker using trained speakers show average WER is 4.37% and W Acc is 95.63%, when using non trained speakers show average WER is 28.25% and W Acc is 71.75%. Base station implementation shows the simulation of the robot when the user gives instruction by his or her own voice.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Macroscopic Wood Blurred Image Analysis to Determine the Factors of Causing Blur"
        ],
        "penulis":"Barus, Dandi T.;Gunawan P.H.;Prakasa, Esa;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents an analysis of what factors cause blur on an image, especially macroscopic images of wood. The image is divided into 6x6 sub-images (blocks), which will then be determined factors causing blur based on patterns and variations of Laplacian calculated from each block. Validation is conducted using two different datasets. The first dataset is Wood Species Dataset that is given a median blur, and testing is performed to validate the proposed algorithm. The second dataset is a dataset collected directly using a smartphone camera, and testing is carried out to determine what factors influence the occurrence of blur in wood macroscopic images. The test results show the proposed algorithm produces a pattern that can determine the factors causing blur.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents an analysis of what factors cause blur on an image, especially macroscopic images of wood. The image is divided into 6x6 sub-images (blocks), which will then be determined factors causing blur based on patterns and variations of Laplacian calculated from each block. Validation is conducted using two different datasets. The first dataset is Wood Species Dataset that is given a median blur, and testing is performed to validate the proposed algorithm. The second dataset is a dataset collected directly using a smartphone camera, and testing is carried out to determine what factors influence the occurrence of blur in wood macroscopic images. The test results show the proposed algorithm produces a pattern that can determine the factors causing blur.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Discovering the Influencing Factors of Trust on Social Commerce in the Jastip Business Model"
        ],
        "penulis":"Nefiratika, Afifah;Sucahyo, Yudho Giri;Gandhi, Arfive;Ruldeviyani, Yova;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, social media does not only have functions to communicate with family and friends but also has a function as a place to do business. Online shopping activities carried out on social media are called social commerce. One of the social commerce business models is currently being carried out on social media is the Jastip business. However, the high level of risk and uncertainty in Jastip makes it difficult for Jastip businesses to gain customer trust. This research aims to identify the factors that influence customer trust in Jastip market on social media. Data obtained through the distribution of questionnaires to 213 respondents who have social media and know Jastip business. Data was collected and analyzed by PLS-SEM using SmartPLS3. Based on the results of the analysis of key opinion leaders (an expert in a particular field), emotional support, endorsements by social media influencers, familiarity, and word of mouth (recommendations and comments) can influence trust in Jastip business on social media positively. The results of this study can be used as input to be able to determine the best strategy to be able to gain customer trust on social media.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, social media does not only have functions to communicate with family and friends but also has a function as a place to do business. Online shopping activities carried out on social media are called social commerce. One of the social commerce business models is currently being carried out on social media is the Jastip business. However, the high level of risk and uncertainty in Jastip makes it difficult for Jastip businesses to gain customer trust. This research aims to identify the factors that influence customer trust in Jastip market on social media. Data obtained through the distribution of questionnaires to 213 respondents who have social media and know Jastip business. Data was collected and analyzed by PLS-SEM using SmartPLS3. Based on the results of the analysis of key opinion leaders (an expert in a particular field), emotional support, endorsements by social media influencers, familiarity, and word of mouth (recommendations and comments) can influence trust in Jastip business on social media positively. The results of this study can be used as input to be able to determine the best strategy to be able to gain customer trust on social media.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Implementation of Depth Control using a Blue robotic Ping Sonar Altimeter and Echo sounder in Explorer Class ROV"
        ],
        "penulis":"Siregar, Simon;Febriansyah, Ryan;Sani, Muhammad Ikhsan;Ikbal, Ulil;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Underwater vehicles have essential roles in exploration and research for shallow and deepwatermissions. Most ROV is controlled by an operator who is on the surface via a tethered cable. With this cable, the operator will send data from the ground station to the ROV or vice versa. Due to the environment's disturbance, the ROV motion must control inputs to maintain the desired position. This problem can be solved by controlled them autonomously. The autonomous motion such as maintaining depth, roll, and pitch is executed by collecting state feedback from several types of sensors such as acoustic and inertia sensors. With this information and controller strategy, autonomous tasks can be performed. In this research, the ROV uses six motors as the thruster. Two motors are used for heavy motions, and four motors are used for surge, pitch, and roll motion. The proposed ROV uses a Raspberry Pi as its primary data processing and communication hub from the camera and controller tothe ground controller. Several methods can be used to maintain depth depends on the sensor. In thispaper, an acoustic sonar-based is used for maintaining the ROV's depth autonomously. The experimental results show that the Explorer Class ROV can maintain depth with an average depth accuracy of 95.77%. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Underwater vehicles have essential roles in exploration and research for shallow and deepwatermissions. Most ROV is controlled by an operator who is on the surface via a tethered cable. With this cable, the operator will send data from the ground station to the ROV or vice versa. Due to the environment's disturbance, the ROV motion must control inputs to maintain the desired position. This problem can be solved by controlled them autonomously. The autonomous motion such as maintaining depth, roll, and pitch is executed by collecting state feedback from several types of sensors such as acoustic and inertia sensors. With this information and controller strategy, autonomous tasks can be performed. In this research, the ROV uses six motors as the thruster. Two motors are used for heavy motions, and four motors are used for surge, pitch, and roll motion. The proposed ROV uses a Raspberry Pi as its primary data processing and communication hub from the camera and controller tothe ground controller. Several methods can be used to maintain depth depends on the sensor. In thispaper, an acoustic sonar-based is used for maintaining the ROV's depth autonomously. The experimental results show that the Explorer Class ROV can maintain depth with an average depth accuracy of 95.77%. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Implementation of Stream Architecture for Handling Big Data Velocity in Social Media"
        ],
        "penulis":"Hamami F.;Dahlan I.A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Big data is a term of complex data and difficult to process. It consists of several characteristics called 6 Vs. Many applications generate huge data and grow rapidly in seconds. This kind of data comes from many sources such as social media, Internet of Things, log system, e-commerce and soon. This rapid data should be handled with a different approach in big data solutions. This paper proposes to create stream architecture for big data velocity with open source technologies such as Apache Kafka and NoSQL database. The implementation is to handle massive incoming data from social media with specific keywords from Twitter and ingested to NoSQL Database though stream architecture.Historical data then processed to gain valuable insight for better information. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Big data is a term of complex data and difficult to process. It consists of several characteristics called 6 Vs. Many applications generate huge data and grow rapidly in seconds. This kind of data comes from many sources such as social media, Internet of Things, log system, e-commerce and soon. This rapid data should be handled with a different approach in big data solutions. This paper proposes to create stream architecture for big data velocity with open source technologies such as Apache Kafka and NoSQL database. The implementation is to handle massive incoming data from social media with specific keywords from Twitter and ingested to NoSQL Database though stream architecture.Historical data then processed to gain valuable insight for better information. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "City brand attractiveness on tourism using rasch model approach"
        ],
        "penulis":"Miftahuddin, Asep;Hermanto, Bambang;Raharja, Sam'un Jaja;Chan, Arianis;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The study presented in this paper analyzes City Brand Attractiveness. Focusing on the city in Indonesia, namely West Bandung Regency, this study aims to examine the factors that affect the City Brand Attractiveness. The empirical application is per-formed on the basis of a sample of 373 visitors who have traveled to West Bandung Regency, analyzed by using Rasch Model. The findings show that tourists response to the city's attractiveness is low, the Ancillary Service factor with a low response, and the Tourism Attraction factor get high expectations from tourists responses. To the researcher understanding, there are limited studies on city brand attractiveness from the perspective of visitors, this could be a novelty of this paper is to explain how the city brand attractiveness affect city branding, Hence, the findings provide a guideline for future researchers or city branding stakeholders an overview of city brand attractiveness on city branding. \u00a9 ExcelingTech Pub, UK.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The study presented in this paper analyzes City Brand Attractiveness. Focusing on the city in Indonesia, namely West Bandung Regency, this study aims to examine the factors that affect the City Brand Attractiveness. The empirical application is per-formed on the basis of a sample of 373 visitors who have traveled to West Bandung Regency, analyzed by using Rasch Model. The findings show that tourists response to the city's attractiveness is low, the Ancillary Service factor with a low response, and the Tourism Attraction factor get high expectations from tourists responses. To the researcher understanding, there are limited studies on city brand attractiveness from the perspective of visitors, this could be a novelty of this paper is to explain how the city brand attractiveness affect city branding, Hence, the findings provide a guideline for future researchers or city branding stakeholders an overview of city brand attractiveness on city branding. \u00a9 ExcelingTech Pub, UK."
        ]
    },
    {
        "judul":[
            "Data Augmentation Methods for Low-Resource Orthographic Syllabification"
        ],
        "penulis":"Suyanto, Suyanto;Lhaksmana, Kemas M.;Bijaksana, Moch Arif;Kurniawan, Adriana;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "An n-gram syllabification model generally produces a high error rate for a low-resource language, such as Indonesian, because of the high rate of out-of-vocabulary (OOV) n-grams. In this paper, a combination of three methods of data augmentations is proposed to solve the problem, namely swapping consonant-graphemes, flipping onsets, and transposing nuclei. An investigation on 50k Indonesian words shows that the combination of three data augmentation methods drastically increases the amount of both unigrams and bigrams. A previous procedure of flipping onsets has been proven to enhance the standard bigram-syllabification by relatively decreasing the syllable error rate (SER) by up to 18.02%. Meanwhile, the previous swapping consonant-graphemes has been proven to give a relative decrement of SER up to 31.39%. In this research, a new transposing nuclei-based augmentation method is proposed and combined with both flipping and swapping procedures to tackle the drawback of bigram syllabification in handling the OOV bigrams. An evaluation based on k-fold cross-validation (k-FCV), using k= 5, for 50 thousand Indonesian formal words concludes that the proposed combination of the three procedures relatively decreases the mean SER produced by the standard bigram model by up to 37.63%. The proposed model is comparable to the fuzzy k-nearest neighbor in every class (FkNNC)-based model. It is worse than the state-of-the-art model, which is developed using a combination of bidirectional long short-term memory (BiLSTM), convolutional neural networks (CNN), and conditional random fields (CRF), but it offers a low complexity.  \u00a9 2013 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An n-gram syllabification model generally produces a high error rate for a low-resource language, such as Indonesian, because of the high rate of out-of-vocabulary (OOV) n-grams. In this paper, a combination of three methods of data augmentations is proposed to solve the problem, namely swapping consonant-graphemes, flipping onsets, and transposing nuclei. An investigation on 50k Indonesian words shows that the combination of three data augmentation methods drastically increases the amount of both unigrams and bigrams. A previous procedure of flipping onsets has been proven to enhance the standard bigram-syllabification by relatively decreasing the syllable error rate (SER) by up to 18.02%. Meanwhile, the previous swapping consonant-graphemes has been proven to give a relative decrement of SER up to 31.39%. In this research, a new transposing nuclei-based augmentation method is proposed and combined with both flipping and swapping procedures to tackle the drawback of bigram syllabification in handling the OOV bigrams. An evaluation based on k-fold cross-validation (k-FCV), using k= 5, for 50 thousand Indonesian formal words concludes that the proposed combination of the three procedures relatively decreases the mean SER produced by the standard bigram model by up to 37.63%. The proposed model is comparable to the fuzzy k-nearest neighbor in every class (FkNNC)-based model. It is worse than the state-of-the-art model, which is developed using a combination of bidirectional long short-term memory (BiLSTM), convolutional neural networks (CNN), and conditional random fields (CRF), but it offers a low complexity.  \u00a9 2013 IEEE."
        ]
    },
    {
        "judul":[
            "Building a smart city 4.0 ecosystem platform: An overview and case study"
        ],
        "penulis":"Nugraha, Yudhistira;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents an overview of a smart city 4.0 framework in accelerating digital transformation, especially during the COVID-19 pandemic, using Jakarta as a case study. The findings of this study provide new insights how to translate a vision into a reality in the form of smart city 4.0 framework that offers a significant opportunity to advance the understanding of building a smart city ecosystem with technologies, innovations and collaborations. This paper applies four principles of the framework, namely mobile-first, system-and-data driven, digital experience, and smart collaboration in building a smart city 4.0 ecosystem platform. Part of the aim of this paper is to examine Jakarta's super-app called JAKI that is compatible with such principles as a use case in the time of the pandemic. It provides a better understanding of common elements in building a new concept of a smart city. The results will inspire and give a contribution to other cities to consider the framework in building a smart city 4.0 ecosystem platform to foster quality of life, economic growth and sustainability. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentDecent work and economic growthGoal 8Sustainable cities and communitiesGoal 11",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents an overview of a smart city 4.0 framework in accelerating digital transformation, especially during the COVID-19 pandemic, using Jakarta as a case study. The findings of this study provide new insights how to translate a vision into a reality in the form of smart city 4.0 framework that offers a significant opportunity to advance the understanding of building a smart city ecosystem with technologies, innovations and collaborations. This paper applies four principles of the framework, namely mobile-first, system-and-data driven, digital experience, and smart collaboration in building a smart city 4.0 ecosystem platform. Part of the aim of this paper is to examine Jakarta's super-app called JAKI that is compatible with such principles as a use case in the time of the pandemic. It provides a better understanding of common elements in building a new concept of a smart city. The results will inspire and give a contribution to other cities to consider the framework in building a smart city 4.0 ecosystem platform to foster quality of life, economic growth and sustainability. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Purchase intention of halal food products in Spain: The moderating effect of religious involvement"
        ],
        "penulis":"Pradana M.;Huertas-Garc\u00eda R.;Marimon F.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The present work aims to empirically analyse the halal food purchase intention from the perspective of Spanish consumers. This is considering the fact that even though Spain is a country where Muslims are not the majority, it still has a big potential to become a major halal tourist destination. The collected data were retrieved through a survey of 500 Muslims in various regions of Spain. Structured questionnaires were used to gather information on their purchase intention of halal food products. The research used a quantitative method to analyse 500 respondents to represent the Muslim community in Spain. The results of the present work suggest that religious involvement acts as a moderator on the relationship between presumed influence and purchase intention. However, it does not act as a moderator on the relationship between attitude towards halal and purchase intention. The most possible reason behind this is because Muslim consumers, especially the second or third generation of Muslims in a non-Muslim country such as Spain, do not have the same food-shopping habits as their parents. \u00a9 All Rights Reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The present work aims to empirically analyse the halal food purchase intention from the perspective of Spanish consumers. This is considering the fact that even though Spain is a country where Muslims are not the majority, it still has a big potential to become a major halal tourist destination. The collected data were retrieved through a survey of 500 Muslims in various regions of Spain. Structured questionnaires were used to gather information on their purchase intention of halal food products. The research used a quantitative method to analyse 500 respondents to represent the Muslim community in Spain. The results of the present work suggest that religious involvement acts as a moderator on the relationship between presumed influence and purchase intention. However, it does not act as a moderator on the relationship between attitude towards halal and purchase intention. The most possible reason behind this is because Muslim consumers, especially the second or third generation of Muslims in a non-Muslim country such as Spain, do not have the same food-shopping habits as their parents. \u00a9 All Rights Reserved."
        ]
    },
    {
        "judul":[
            "E-learning for a Boring Process at an Aerospace Industry Company"
        ],
        "penulis":"Dindana, Dasilva;Muhammad, Fadel;Kurniawati, Amelia;Kurniawan, Mochamad Teguh;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Massive development of information technology and internet access have driven major changes in people's behavior in certain activities. In the education sector, e-learning becomes a new trend in educational technology. A company of aerospace tried to implement e-learning as a breakthrough project to boost knowledge sharing among its employees. The purpose of this study is to design e-learning for boring process activity. The result of this study is expected to help the company to develop employees' production expertise and reduce production defect rate. The e-learning development was divided into two parts. The first part is the knowledge conversion process based on the SECI model. The second part is the e-learning development process based on the waterfall method and the KM Cycle framework. The three e-learning main structures developed are the online course, the articles that contain best practice and lesson-learned, and the community of practice. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Massive development of information technology and internet access have driven major changes in people's behavior in certain activities. In the education sector, e-learning becomes a new trend in educational technology. A company of aerospace tried to implement e-learning as a breakthrough project to boost knowledge sharing among its employees. The purpose of this study is to design e-learning for boring process activity. The result of this study is expected to help the company to develop employees' production expertise and reduce production defect rate. The e-learning development was divided into two parts. The first part is the knowledge conversion process based on the SECI model. The second part is the e-learning development process based on the waterfall method and the KM Cycle framework. The three e-learning main structures developed are the online course, the articles that contain best practice and lesson-learned, and the community of practice. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Influence of Website-Based and Company-Based Quality toward Loyalty with Perceived Website Trust as Antecedents"
        ],
        "penulis":"Indrawati;Shabila, Arlinda Meidina;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Traveloka is a platform that is leading among Southeast Asia online travel company that provides a wide range of travel needs. A rapid change of digital business transformation has brought Traveloka to become the first startup company that has gained the status as unicorn among the other four tech startups and also categorized as the only online travel services in the startups' unicorn. Unicorn is a startup company that has a valuation of over 1 billion US Dollars. Since the exposure of startups' unicorn is relatively new in Indonesia, thus there is a need to investigate the market's preference of using Traveloka's website by predicting the customer's loyalty. Moreover, to continue using such startups by conducting research related to the consumergenerated media and measuring the customer's loyalty in supporting Traveloka to become one of the startups' unicorn. This proposed investigation applies the antecedents and consequences of the trust model, which describes the constructs of information quality, perceived website quality, and user satisfaction with previous experiences toward loyalty with the dimensions of referral, repurchase intention, and reject others through perceived website trust as an intervening variable. The data were collected from 445 valid respondents with a non-probability purposive sampling technique. Data analysis conducted using the SmartPLS 3.2.9 software and the results show that the factors that have a significant positive influence on customer loyalty of using Traveloka's Website through Perceived Website Trust from the highest to the lowest mainly are User Satisfaction with previous experiences, Information Quality, and Perceived Website Quality. These antecedents and consequences of the trust model can be used to utilize further studies with the extensions of unexplored factors.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Traveloka is a platform that is leading among Southeast Asia online travel company that provides a wide range of travel needs. A rapid change of digital business transformation has brought Traveloka to become the first startup company that has gained the status as unicorn among the other four tech startups and also categorized as the only online travel services in the startups' unicorn. Unicorn is a startup company that has a valuation of over 1 billion US Dollars. Since the exposure of startups' unicorn is relatively new in Indonesia, thus there is a need to investigate the market's preference of using Traveloka's website by predicting the customer's loyalty. Moreover, to continue using such startups by conducting research related to the consumergenerated media and measuring the customer's loyalty in supporting Traveloka to become one of the startups' unicorn. This proposed investigation applies the antecedents and consequences of the trust model, which describes the constructs of information quality, perceived website quality, and user satisfaction with previous experiences toward loyalty with the dimensions of referral, repurchase intention, and reject others through perceived website trust as an intervening variable. The data were collected from 445 valid respondents with a non-probability purposive sampling technique. Data analysis conducted using the SmartPLS 3.2.9 software and the results show that the factors that have a significant positive influence on customer loyalty of using Traveloka's Website through Perceived Website Trust from the highest to the lowest mainly are User Satisfaction with previous experiences, Information Quality, and Perceived Website Quality. These antecedents and consequences of the trust model can be used to utilize further studies with the extensions of unexplored factors.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Anomaly Behavior Detection of Angkot Based on Transportation Data"
        ],
        "penulis":"Nurmalasari, Rin Rin;Putri, Elbananda Permana;Prihatmanto, Ary Setijadi;Yusuf, Rahadian;Wijaya, Rifki;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Public transportation in Indonesia as a developing country differs from developed country, and there is a certain public transportation called angkot (angkutan kota, or city transport), which became the focus of our research. This paper presents the experiments on data transportation to analyze and detect anomaly behavior of angkot. The focus is on discussing the results of experiments to calculate the length of waiting time for angkot at hotspots, clustering of angkot trips patterns and building a model to detect anomaly behavior of angkot. The results of the review and experiment indicate the length of the time needed for angkot in waiting for the passengers and show which angkot that exceeds the normal time limit set by the government in waiting for the passengers, which suggests a deviant behavior. The results for clustering angkot that have similiar trips patterns using principal component analysis and K-Means give fairly high accuracy. The result for detection of anomaly behavior using autoencoder and Long Short-Term Memory (LSTM) can be used to detect anomaly behavior of angkot when data are collected without labels. The results of the evaluation of model have a loss mean absolute error (MAE) value which is getting smaller. In addition, the output data from the detection of anomaly behavior using autoencoder and LSTM will automatically be labeled true or false, which indicates true if there is an anomalous behavior, while false if there is no anomaly behavior.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentSustainable cities and communitiesGoal 11Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Public transportation in Indonesia as a developing country differs from developed country, and there is a certain public transportation called angkot (angkutan kota, or city transport), which became the focus of our research. This paper presents the experiments on data transportation to analyze and detect anomaly behavior of angkot. The focus is on discussing the results of experiments to calculate the length of waiting time for angkot at hotspots, clustering of angkot trips patterns and building a model to detect anomaly behavior of angkot. The results of the review and experiment indicate the length of the time needed for angkot in waiting for the passengers and show which angkot that exceeds the normal time limit set by the government in waiting for the passengers, which suggests a deviant behavior. The results for clustering angkot that have similiar trips patterns using principal component analysis and K-Means give fairly high accuracy. The result for detection of anomaly behavior using autoencoder and Long Short-Term Memory (LSTM) can be used to detect anomaly behavior of angkot when data are collected without labels. The results of the evaluation of model have a loss mean absolute error (MAE) value which is getting smaller. In addition, the output data from the detection of anomaly behavior using autoencoder and LSTM will automatically be labeled true or false, which indicates true if there is an anomalous behavior, while false if there is no anomaly behavior.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Reporting system design for family planning field officers in DPPKB using business process improvement (BPI)"
        ],
        "penulis":"Alifah, Fakhirah Nur;Triwibisono, Christanto;Suwarsono, Litasari Widyastuti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Family Planning (FP) field officers are the people actively working in the field to encourage people to get involved in the family planning program that supports the government in controlling the population of the country. However, many of the officers have stated that their recruits often make mistakes during the process of inputting data along, added with the long manual validation process. The available digital reporting application called Sistem Informasi Keluarga (SIGA) is also not used at its maximum capability, causing the decrease of data validity collected through the process. Using business process improvement (BPI), valueadded analysis, and gap analysis are performed to find the issues in the system that will become the base of the reporting system redesign. This research was done to provide a proper business process design that is needed to ensure maximum comprehension and reduction of data invalidity with the help of the existing application. The result of this research shows that the new business process design required the digitalization of the data input process using an information system and the reduction of the use of offline forms to increase the validity of data in the reporting system.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Family Planning (FP) field officers are the people actively working in the field to encourage people to get involved in the family planning program that supports the government in controlling the population of the country. However, many of the officers have stated that their recruits often make mistakes during the process of inputting data along, added with the long manual validation process. The available digital reporting application called Sistem Informasi Keluarga (SIGA) is also not used at its maximum capability, causing the decrease of data validity collected through the process. Using business process improvement (BPI), valueadded analysis, and gap analysis are performed to find the issues in the system that will become the base of the reporting system redesign. This research was done to provide a proper business process design that is needed to ensure maximum comprehension and reduction of data invalidity with the help of the existing application. The result of this research shows that the new business process design required the digitalization of the data input process using an information system and the reduction of the use of offline forms to increase the validity of data in the reporting system.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Performance Comparison of Yolo-Lite and YoloV3 Using Raspberry Pi and MotionEyeOS"
        ],
        "penulis":"Sismananda, Pertiwang;Abdurohman, Maman;Putrada, Aji Gautama;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper proposes system comparison on identifying and processing of human image based on YOLOLITE and YOLOV3 algorithms. Computer Vision (CV) is a field of computer science where the focus is on learning how computers can be trained to identify and process image data as humans do. There are many open source CV frameworks have been proposed such as OpenCV. This paper shows a comparison between YOLO-LITE and YOLOV3 algorithms and analyzes their performance. We have implemented both algorithms in several test cases in the real time domain and carried out in the same test environment. The result shows that the Raspberry Pi camera worked at 15 fps on YOLO-LITE and 1 fps on YOLOV3. This indicates that YOLO-LITE has an average performance of 1 second faster while YOLOV3 has an average accuracy of 30% better.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper proposes system comparison on identifying and processing of human image based on YOLOLITE and YOLOV3 algorithms. Computer Vision (CV) is a field of computer science where the focus is on learning how computers can be trained to identify and process image data as humans do. There are many open source CV frameworks have been proposed such as OpenCV. This paper shows a comparison between YOLO-LITE and YOLOV3 algorithms and analyzes their performance. We have implemented both algorithms in several test cases in the real time domain and carried out in the same test environment. The result shows that the Raspberry Pi camera worked at 15 fps on YOLO-LITE and 1 fps on YOLOV3. This indicates that YOLO-LITE has an average performance of 1 second faster while YOLOV3 has an average accuracy of 30% better.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "IoT Object Security towards On-off Attack Using Trustworthiness Management"
        ],
        "penulis":"Nasution, Anggi Pratama;Suryani, Vera;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Internet of Things (IoT) can create the world with the integration of the physical things with the seamlessly network of information purposely to give a sophisticated and smart service for human life. A variety of threats and attacks to IoT object, however, can lead to the misuse of data or information to the IoT objects. One of the attacks is On-off Attack in which the attacker acts not only as an object with a good manner by sending the valid trust value but also sometimes as a bad object by sending invalid one. To respond this action, there is a need for the object security to such attacks. Here the writer used the Trustworthiness Management as a method to cope with this attack. Trustworthiness Management can use the aspect of trust value security as a reference for detecting an attack to the object. In addition, with the support of security system using the authentication provided by MQTT, it is expected that it can provide an additional security. The approach used in this research was the test on On-Off Attack detection directly to the object connected to the network. The results of the test were then displayed on the webpage made using PHP and MySQL database as the storage of the values sent by the object to the server. The test on the On-off Attack detection was successfully conducted with the success level of 100% and the execution to detection took 0.5518318 seconds. This then showed that Trustworthiness Management can be used as one of the methods to cope with On-off Attack.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet of Things (IoT) can create the world with the integration of the physical things with the seamlessly network of information purposely to give a sophisticated and smart service for human life. A variety of threats and attacks to IoT object, however, can lead to the misuse of data or information to the IoT objects. One of the attacks is On-off Attack in which the attacker acts not only as an object with a good manner by sending the valid trust value but also sometimes as a bad object by sending invalid one. To respond this action, there is a need for the object security to such attacks. Here the writer used the Trustworthiness Management as a method to cope with this attack. Trustworthiness Management can use the aspect of trust value security as a reference for detecting an attack to the object. In addition, with the support of security system using the authentication provided by MQTT, it is expected that it can provide an additional security. The approach used in this research was the test on On-Off Attack detection directly to the object connected to the network. The results of the test were then displayed on the webpage made using PHP and MySQL database as the storage of the values sent by the object to the server. The test on the On-off Attack detection was successfully conducted with the success level of 100% and the execution to detection took 0.5518318 seconds. This then showed that Trustworthiness Management can be used as one of the methods to cope with On-off Attack.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The Concave n-Square Salient Wood Image-based Quality Assessment"
        ],
        "penulis":"Risnandar;Prakasa, Esa;Erwin, Iwan Muhammad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We make an offer of a state-of-the-art method of the deep salient wood image-based quality assessment (DS-WIQA) for no-reference image appraisal. We explore a five-layer deep convolutional neural network (DCNN) for the salient wood image map. The DS-WIQA uses the concave n-square method. The outcomes allow that DS-WIQA model has a greater achievement on Zenodo and Lignoindo datasets, respectively. We appraise a salient wood image map by extracting in small wood image patches. The DS-WIQA has an admirable performance of other recent methods on Zenodo and Lignoindo datasets, respectively. DS-WIQA outdoes other recent techniques by 14.29% and 19.96% more advanced than other techniques with respect to SROCC and LCC measurement, respectively. DS-WIQA shows up to be more significant than the other DCNN methods.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "We make an offer of a state-of-the-art method of the deep salient wood image-based quality assessment (DS-WIQA) for no-reference image appraisal. We explore a five-layer deep convolutional neural network (DCNN) for the salient wood image map. The DS-WIQA uses the concave n-square method. The outcomes allow that DS-WIQA model has a greater achievement on Zenodo and Lignoindo datasets, respectively. We appraise a salient wood image map by extracting in small wood image patches. The DS-WIQA has an admirable performance of other recent methods on Zenodo and Lignoindo datasets, respectively. DS-WIQA outdoes other recent techniques by 14.29% and 19.96% more advanced than other techniques with respect to SROCC and LCC measurement, respectively. DS-WIQA shows up to be more significant than the other DCNN methods.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The QoS Improvement Using CDN for Live Video Streaming with HLS"
        ],
        "penulis":"Shabrina, Wella Edli;Wisaksono Sudiharto, Dodi;Ariyanto, Endro;Makky, Muhammad Al;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, people commonly use streaming technology to enjoy audio or video broadcasted from the server. With this technology, they do not need to download the content first. But, they can directly enjoy the content through the streaming mechanism. Generally, this technology requires high bandwidth to maintain its Quality of Service (QoS) to stay at a good level. The problem can occur, such as packet loss because of limited bandwidth supported by the network provider. This condition can reduce the quality of the content delivered. One technology that can be used to improve the quality of content delivered by streaming service is CDN (Content Delivery Network). This study is going to improve the quality of live video streaming by using CDN. The global CDN infrastructure used is Cloudfront, supported by AWS (Amazon Web Services). The broadcaster is located in Bandung, Indonesia, and the client is placed in Tokyo, Japan. HTTP Live Streaming (HLS) format is performed for content streaming. It is proved CDN can increase the QoS of content delivered. The result presents live video streaming with CDN has better achievement than the other one without CDN. The broadcasting of live video streaming gives a throughput average of 4452.6 kbps and a packet loss ratio average of 0.08% by using CDN. Without using CDN, it presents the throughput average of 3990.4 kbps and the packet loss ratio average of 0.33%. \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, people commonly use streaming technology to enjoy audio or video broadcasted from the server. With this technology, they do not need to download the content first. But, they can directly enjoy the content through the streaming mechanism. Generally, this technology requires high bandwidth to maintain its Quality of Service (QoS) to stay at a good level. The problem can occur, such as packet loss because of limited bandwidth supported by the network provider. This condition can reduce the quality of the content delivered. One technology that can be used to improve the quality of content delivered by streaming service is CDN (Content Delivery Network). This study is going to improve the quality of live video streaming by using CDN. The global CDN infrastructure used is Cloudfront, supported by AWS (Amazon Web Services). The broadcaster is located in Bandung, Indonesia, and the client is placed in Tokyo, Japan. HTTP Live Streaming (HLS) format is performed for content streaming. It is proved CDN can increase the QoS of content delivered. The result presents live video streaming with CDN has better achievement than the other one without CDN. The broadcasting of live video streaming gives a throughput average of 4452.6 kbps and a packet loss ratio average of 0.08% by using CDN. Without using CDN, it presents the throughput average of 3990.4 kbps and the packet loss ratio average of 0.33%. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Propagation of apis cerana fabr. (hymenoptera: Apidae) prospective queen bee"
        ],
        "penulis":"Jasmi, Jasmi;Syarifuddin, Syarifuddin;Putra, Dewirman Prima;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Honey bee, Apis cerana Fabr. (Hymenoptera; Apidae) has been domesticated in West Sumatra. Various attempts to obtain practical and effective methods for multiplying superior colonies have been made. Optimizing the role of worker bees as a determinant of the future colony can be done by creating an emergency colony condition (queen bee not present). In this kind of colony, the worker bees immediately produced a new queen bee candidate from young larvae. This research was conducted at Trigona Mandiri Apiary, Padang Pariaman, West Sumatra, Indonesia from February to May 2019. The method used was a complete randomized design with four treatments and 10 replications. Results showed that the comb isolation technique was the best method for producing new queen bee candidates and increasing the appearance of young queen bee (gyn). The mean appearance of gyn from pupae was 4.8 per colony so that the number and quality of pupae to be maintained can be selected. \u00a9 2020, Universiti Kebangsaan Malaysia Press. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Honey bee, Apis cerana Fabr. (Hymenoptera; Apidae) has been domesticated in West Sumatra. Various attempts to obtain practical and effective methods for multiplying superior colonies have been made. Optimizing the role of worker bees as a determinant of the future colony can be done by creating an emergency colony condition (queen bee not present). In this kind of colony, the worker bees immediately produced a new queen bee candidate from young larvae. This research was conducted at Trigona Mandiri Apiary, Padang Pariaman, West Sumatra, Indonesia from February to May 2019. The method used was a complete randomized design with four treatments and 10 replications. Results showed that the comb isolation technique was the best method for producing new queen bee candidates and increasing the appearance of young queen bee (gyn). The mean appearance of gyn from pupae was 4.8 per colony so that the number and quality of pupae to be maintained can be selected. \u00a9 2020, Universiti Kebangsaan Malaysia Press. All rights reserved."
        ]
    },
    {
        "judul":[
            "Culturable gut bacteria of ikan batak (Neolissochilus sumatranus weber & de beaufort, 1916) collected in toba samosir, indonesia"
        ],
        "penulis":"Dinoto, Achmad;Handayani, Rini;Setianingrum, Ninu;Julistiono, Heddy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Ikan Batak (Neolissochilus sumatranus Weber & de Beaufort, 1916) is one of the fish species that is rarely found in water and have the status of endangered species. In consequence, the loss of endemic fish may contribute to the loss of microorganisms that inhabits the fish as a host. The studies on microorganisms associated with N. sumatranus are very limited. Therefore, the purpose of this study was to isolate and identify the culturable bacteria isolated from the gut of N. sumatranus. Sampling of N. sumatranus was carried out in a river within Toba Samosir area which flows to Lake Toba. Fish gut content was collected for isolating microorganisms using three media, including MRS, 10X diluted MRS, and MRS supplemented with 1% bile salt. Thirteen isolates were successfully isolated and identified based on 16S rRNA. This study revealed various species of gut bacteria recovered from N. sumatranus based on BLAST analysis. The isolates showed closest relationship to species Bacillus subtilis (3 isolates), Bacillus tequilensis (2 isolates), Tumebacillus ginsengisoli (6 isolates), Klebsiella pneumoniae (1 isolate), and Lactobacillus pentosus (1 isolate) with the similarity ranging at 98.7 to 100%. All 16S rRNA gene nucleotides of isolates have been submitted to GenBank. This study also described the isolates that have a very close relationship with Bacillus tequilla and Bacillus subtilis. Further identification is challenged to obtain a big picture of the diversity of microorganisms and the functionality in the digestive ecosystem of N. sumatranus for their conservation and bioprospecting of microbial-based aquaculture. \u00a9 2020, Society for Indonesian Biodiversity. All rights reserved.",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3Clean water and sanitationGoal 6Life below waterGoal 14Life on landGoal 15",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Ikan Batak (Neolissochilus sumatranus Weber & de Beaufort, 1916) is one of the fish species that is rarely found in water and have the status of endangered species. In consequence, the loss of endemic fish may contribute to the loss of microorganisms that inhabits the fish as a host. The studies on microorganisms associated with N. sumatranus are very limited. Therefore, the purpose of this study was to isolate and identify the culturable bacteria isolated from the gut of N. sumatranus. Sampling of N. sumatranus was carried out in a river within Toba Samosir area which flows to Lake Toba. Fish gut content was collected for isolating microorganisms using three media, including MRS, 10X diluted MRS, and MRS supplemented with 1% bile salt. Thirteen isolates were successfully isolated and identified based on 16S rRNA. This study revealed various species of gut bacteria recovered from N. sumatranus based on BLAST analysis. The isolates showed closest relationship to species Bacillus subtilis (3 isolates), Bacillus tequilensis (2 isolates), Tumebacillus ginsengisoli (6 isolates), Klebsiella pneumoniae (1 isolate), and Lactobacillus pentosus (1 isolate) with the similarity ranging at 98.7 to 100%. All 16S rRNA gene nucleotides of isolates have been submitted to GenBank. This study also described the isolates that have a very close relationship with Bacillus tequilla and Bacillus subtilis. Further identification is challenged to obtain a big picture of the diversity of microorganisms and the functionality in the digestive ecosystem of N. sumatranus for their conservation and bioprospecting of microbial-based aquaculture. \u00a9 2020, Society for Indonesian Biodiversity. All rights reserved."
        ]
    },
    {
        "judul":[
            "BIODIVERSITY CONSERVATION MONITORING SYSTEM IMAGE DETECTION USING TENSORFLOW"
        ],
        "penulis":"Wijaya, Rifki;Prihatmanto, Ary Setijadi;Sukoco, Agus;Syahfirin, Marzuki;Shusanti, Maria;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "As we know, there are a huge variety of animals in the nature. Some of these are rare animals that are protected under governmental legislation. Technology can help people discover the condition of animals that are protected by the government. With the forest characteristic, Deep learning is a multilayer neural network, a kind of machine learning based on pattern recognition from input data; it has a property of unsupervised features learning which mean it can learn a datasets that only contain very few labelled data along with unlabeled data which is important in image recognition method. There are some of deep learning methods such as CNN, DBNs and auto-encoders. In this paper we using TensorFlow an open source library for numerical computation, specializing in machine learning developed by Google Brain. TensorFlow is library that used in deep learning methods, similar to convolutional neural networks (CNN). The methods using inception a huge image classification model with millions of parameters that can differentiate a large number of kinds images[poets], to classified and training image data layer by layer. We are using TensorFlow as architecture to image detection system for detection and recognition an endangered animal. This image detection system could help researcher\u2019s detect and recognize one of endangered animal (Dicerorhinussumatrensis) such as sumatran rhino with population of approximately 100at the end of 2015. Our proposed model achieved 95% accuracy to recognize such images. \u00a9 2006-2020 Asian Research Publishing Network (ARPN). All rights reserved.",
            "NHNSCH3H3CNHOOH3CView detailsExpand Substance sumatripanOHH2NView detailsExpand Substance hydroxylamineCH3OHH3CCH3OHHHView detailsExpand Substance 17-methyltestosterone",
            "Powered by",
            "Sustainable Development Goals mapped to this documentLife on landGoal 15",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "As we know, there are a huge variety of animals in the nature. Some of these are rare animals that are protected under governmental legislation. Technology can help people discover the condition of animals that are protected by the government. With the forest characteristic, Deep learning is a multilayer neural network, a kind of machine learning based on pattern recognition from input data; it has a property of unsupervised features learning which mean it can learn a datasets that only contain very few labelled data along with unlabeled data which is important in image recognition method. There are some of deep learning methods such as CNN, DBNs and auto-encoders. In this paper we using TensorFlow an open source library for numerical computation, specializing in machine learning developed by Google Brain. TensorFlow is library that used in deep learning methods, similar to convolutional neural networks (CNN). The methods using inception a huge image classification model with millions of parameters that can differentiate a large number of kinds images[poets], to classified and training image data layer by layer. We are using TensorFlow as architecture to image detection system for detection and recognition an endangered animal. This image detection system could help researcher\u2019s detect and recognize one of endangered animal (Dicerorhinussumatrensis) such as sumatran rhino with population of approximately 100at the end of 2015. Our proposed model achieved 95% accuracy to recognize such images. \u00a9 2006-2020 Asian Research Publishing Network (ARPN). All rights reserved."
        ]
    },
    {
        "judul":[
            "Twitter sentiment analysis of the relocation of Indonesia's capital city"
        ],
        "penulis":"Sutoyo, Edi;Almaarif, Ahmad;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Indonesia has a capital city which is one of the many big cities in the world called Jakarta. Jakarta's role in the dynamics that occur in Indonesia is very central because it functions as a political and government center, and is a business and economic center that drives the economy. Recently the discourse of the government to relocate the capital city has invited various reactions from the community. Therefore, in this study, sentiment analysis of the relocation of the capital city was carried out. The analysis was performed by doing a classification to describe the public sentiment sourced from twitter data, the data is classified into 2 classes, namely positive and negative sentiments. The algorithms used in this study include Na\u00efve Bayes classifier, logistic regression, support vector machine, and K-nearest neighbor. The results of the performance evaluation algorithm showed that support vector machine outperformed as compared to 3 algorithms with the results of Accuracy, Precision, Recall, and F-measure are 97.72%, 96.01%, 99.18%, and 97.57%, respectively. Sentiment analysis of the discourse of relocation of the capital city is expected to provide an overview to the government of public opinion from the point of view of data coming from social media. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Indonesia has a capital city which is one of the many big cities in the world called Jakarta. Jakarta's role in the dynamics that occur in Indonesia is very central because it functions as a political and government center, and is a business and economic center that drives the economy. Recently the discourse of the government to relocate the capital city has invited various reactions from the community. Therefore, in this study, sentiment analysis of the relocation of the capital city was carried out. The analysis was performed by doing a classification to describe the public sentiment sourced from twitter data, the data is classified into 2 classes, namely positive and negative sentiments. The algorithms used in this study include Na\u00efve Bayes classifier, logistic regression, support vector machine, and K-nearest neighbor. The results of the performance evaluation algorithm showed that support vector machine outperformed as compared to 3 algorithms with the results of Accuracy, Precision, Recall, and F-measure are 97.72%, 96.01%, 99.18%, and 97.57%, respectively. Sentiment analysis of the discourse of relocation of the capital city is expected to provide an overview to the government of public opinion from the point of view of data coming from social media. \u00a9 2020, Institute of Advanced Engineering and Science. All rights reserved."
        ]
    },
    {
        "judul":[
            "Parallel Programming of Churn Prediction Using Gaussian Na\u00efve Bayes"
        ],
        "penulis":"Barus, Dandi T.;Elfarizy R.;Masri F.;Gunawan P.H.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This paper presents churn predictions with the Gaussian Na\u00efve Bayes method. Churn prediction is a forecasting method to predict customer decisions in a company's service or product (churn). With high public enthusiasm and an increasing number of customers in the Big Data era, a fast computing process is needed to predict churn as quickly as possible. In this paper, computing is accelerated by the OpenMP platform parallel algorithm. Churn prediction experiments are performed with different amounts of test data, ranging from 100, 300, 500, 700, to 900 data. The results obtained show that implementing OpenMP in predicting churn is faster than serial processing. The obtained speedup and efficiency reached more than 1.49 and 37%, even for test data of 300 and 500, based on the tests, the speedup and efficiency reached 1.99 and 50%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This paper presents churn predictions with the Gaussian Na\u00efve Bayes method. Churn prediction is a forecasting method to predict customer decisions in a company's service or product (churn). With high public enthusiasm and an increasing number of customers in the Big Data era, a fast computing process is needed to predict churn as quickly as possible. In this paper, computing is accelerated by the OpenMP platform parallel algorithm. Churn prediction experiments are performed with different amounts of test data, ranging from 100, 300, 500, 700, to 900 data. The results obtained show that implementing OpenMP in predicting churn is faster than serial processing. The obtained speedup and efficiency reached more than 1.49 and 37%, even for test data of 300 and 500, based on the tests, the speedup and efficiency reached 1.99 and 50%.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Age Group Based Document Classification in Bahasa Indonesia"
        ],
        "penulis":"Putra, M. Iqbal D.;Irmawati, Budi;Wedashwara, Wirarama;Pramesti, Dita;Khairunnisa, Siti Oryza;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Internet provides articles that may be categorized to various target readers based on genders, ages, hobbies, etc. To make sure that readers consume a proper article based on their age group, methods and training data were proposed and collected to classify the articles. This paper reported a document classification based on age groups using a binary classification method for Indonesian documents. The document classification used the term frequency and inverse document frequency (TF-IDF) features run on the Multinomial Na\u00efve Bayes Classifier. The dataset was crowdsourced from three different sites: bobo.grid.id, hai.grid.id, and www.detik.com for three age group readers such as elementary school children, teenagers, and adults. The experimental results obtained 0.9406, 0.9341, and 0.9374 of precision, recall, and F-score respectively. This experiment also reported that for the datasets that were not stemmed performed better than those that were stemmed. It shows that the stemming process, which usually be done in the document classification, throws some information in the Indonesian texts. However, because this behavior was not happen on nouns, our future work is to elaborate further on the role of affixations in the lower age group documents. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Internet provides articles that may be categorized to various target readers based on genders, ages, hobbies, etc. To make sure that readers consume a proper article based on their age group, methods and training data were proposed and collected to classify the articles. This paper reported a document classification based on age groups using a binary classification method for Indonesian documents. The document classification used the term frequency and inverse document frequency (TF-IDF) features run on the Multinomial Na\u00efve Bayes Classifier. The dataset was crowdsourced from three different sites: bobo.grid.id, hai.grid.id, and www.detik.com for three age group readers such as elementary school children, teenagers, and adults. The experimental results obtained 0.9406, 0.9341, and 0.9374 of precision, recall, and F-score respectively. This experiment also reported that for the datasets that were not stemmed performed better than those that were stemmed. It shows that the stemming process, which usually be done in the document classification, throws some information in the Indonesian texts. However, because this behavior was not happen on nouns, our future work is to elaborate further on the role of affixations in the lower age group documents. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Relationship of Personal Data Protection towards the Electoral Measures: Partial Least Square Analysis"
        ],
        "penulis":"Lubis, Muharman;Ridho Lubis, Arif;Almaarif, Ahmad;Amalia Nur Fajrillah, Asti;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The adoptionF of e-voting in several countries poses certain challenges, which are very similar when electronic means are applied to any activities, such as e-governance or e-commerce. Therefore, some people due to economics, politics or social reasons expect the e-voting use will facilitate and solve previous election's problem. Unfortunately, the most complex and difficult practical implementation with distinct problems depends on the particular condition or culture. One of essential factor concerning the adoption related to privacy protection. Thus, this study examines the relationship of perceived benefit and privacy concern towards personal data protection by establishing model of formative measurement. For the generalization purposes, a survey questionnaire consists of 4 categories of 45 items was distributed offline and online to approximately 800 people with purposive sampling in selected multicultural cities in Indonesia. The result suggested that the Perceived Benefit (PBen) has the strongest predictive value of2and Q2compare to Privacy Concern (PCon) with 0.212 and 0.083 respectively. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPeace, justice and strong institutionsGoal 16Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The adoptionF of e-voting in several countries poses certain challenges, which are very similar when electronic means are applied to any activities, such as e-governance or e-commerce. Therefore, some people due to economics, politics or social reasons expect the e-voting use will facilitate and solve previous election's problem. Unfortunately, the most complex and difficult practical implementation with distinct problems depends on the particular condition or culture. One of essential factor concerning the adoption related to privacy protection. Thus, this study examines the relationship of perceived benefit and privacy concern towards personal data protection by establishing model of formative measurement. For the generalization purposes, a survey questionnaire consists of 4 categories of 45 items was distributed offline and online to approximately 800 people with purposive sampling in selected multicultural cities in Indonesia. The result suggested that the Perceived Benefit (PBen) has the strongest predictive value of2and Q2compare to Privacy Concern (PCon) with 0.212 and 0.083 respectively. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Indonesian Graphemic Syllabification Using n-Gram Tagger with State-Elimination"
        ],
        "penulis":"Ismail, Rezza Nafi;Suyanto, Suyanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Syllabification can be approached using either grapheme or phoneme-based. Graphemic syllabification is simpler than phonemic syllabification since it does not require grapheme-to-phoneme conversion (G2P). Both phonemic and graphemic syllabification has been done on Indonesian words with average SER of 0.64% and 2.27%, respectively. The performance of Indonesian graphemic syllabification is considerably lower than the phonemic one. This research aims to improve Indonesian graphemic syllabification using a syllable boundary tagger based on the statistical n-gram model. Using fivefold cross-validation on 50k formal Indonesian words, the proposed model gives an average syllable error rate (SER) of 0.94% while the introduced state-elimination procedure reduces the SER to 0.92%, which is much lower than the previous Indonesian graphemic syllabification. Most syllabification errors come from derivative words and adapted foreign terms.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Syllabification can be approached using either grapheme or phoneme-based. Graphemic syllabification is simpler than phonemic syllabification since it does not require grapheme-to-phoneme conversion (G2P). Both phonemic and graphemic syllabification has been done on Indonesian words with average SER of 0.64% and 2.27%, respectively. The performance of Indonesian graphemic syllabification is considerably lower than the phonemic one. This research aims to improve Indonesian graphemic syllabification using a syllable boundary tagger based on the statistical n-gram model. Using fivefold cross-validation on 50k formal Indonesian words, the proposed model gives an average syllable error rate (SER) of 0.94% while the introduced state-elimination procedure reduces the SER to 0.92%, which is much lower than the previous Indonesian graphemic syllabification. Most syllabification errors come from derivative words and adapted foreign terms.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Vulnerability Assessment and Penetration Testing (VAPT) Framework: Case Study of Government\u2019s Website"
        ],
        "penulis":"Almaarif, Ahmad;Lubis, Muharman;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Information security often neglected by individual or employee or even by the enterprise, with there is no proper strategy to raise awareness, promote consistency and maintain performance regarding protect sensitive, confidential, and critical data. One of the common techniques used is a vulnerability assessment and penetration testing (VAPT) to assure the security strategy has been implemented into the computer system by analyzing both its strength and weakness. SQL plays an essential role in the Relation Database Management System (RDBMS) and its relationship to the existence of a website and its flexible operation because of its simplicity and integrity. To anticipate these types of threats or other Internet attacks, a goal-oriented penetration test that has a framework is recommended to identify specific types of vulnerabilities that lead to business concessions and to avoid the risks that adversely affect the enterprise Thus. This study conducts VAPT to uncover the possibility of threats and evaluate the potential impact to be reported to the system owner through a proper engagement framework that allows systematic measurement. Government websites have been identified for this purpose of the research to show the current trend that occurred in cyber communities, especially in Indonesia. This study has found various vulnerabilities lies in the directory listing, full path disclosure, PHP info disclosure, folder webserver disclosure, and other potential threats, which present 2 (two) critical, 6 (six) medium, and 2 (two) low level of risk. \u00a9",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Information security often neglected by individual or employee or even by the enterprise, with there is no proper strategy to raise awareness, promote consistency and maintain performance regarding protect sensitive, confidential, and critical data. One of the common techniques used is a vulnerability assessment and penetration testing (VAPT) to assure the security strategy has been implemented into the computer system by analyzing both its strength and weakness. SQL plays an essential role in the Relation Database Management System (RDBMS) and its relationship to the existence of a website and its flexible operation because of its simplicity and integrity. To anticipate these types of threats or other Internet attacks, a goal-oriented penetration test that has a framework is recommended to identify specific types of vulnerabilities that lead to business concessions and to avoid the risks that adversely affect the enterprise Thus. This study conducts VAPT to uncover the possibility of threats and evaluate the potential impact to be reported to the system owner through a proper engagement framework that allows systematic measurement. Government websites have been identified for this purpose of the research to show the current trend that occurred in cyber communities, especially in Indonesia. This study has found various vulnerabilities lies in the directory listing, full path disclosure, PHP info disclosure, folder webserver disclosure, and other potential threats, which present 2 (two) critical, 6 (six) medium, and 2 (two) low level of risk. \u00a9"
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "Model+Learning-based Optimal Control: An Inverted Pendulum Study"
        ],
        "penulis":"Baldi, Simone;Rosa, Muhammad Ridho;Wang, Yuzhang;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This work extends and compares some recent model+learning-based methodologies for optimal control with input saturation. We focus on two methodologies: a model-based actor-critic (MBAC) strategy, and a nonlinear policy iteration strategy. To evaluate the performance of the algorithms, these strategies are applied to the swinging up an inverted pendulum. Numerical simulations show that the neural network approximation in the MBAC strategy can be poor, and the algorithm may converge far from the optimum. In the MBAC approach neither stabilization nor monotonic convergence can be guaranteed, and it is observed that the best value function is not always corresponding to the last one. On the other side the nonlinear policy iteration approach guarantees that every new control policy is stabilizing and generally leads to a monotonically decreasing cost. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This work extends and compares some recent model+learning-based methodologies for optimal control with input saturation. We focus on two methodologies: a model-based actor-critic (MBAC) strategy, and a nonlinear policy iteration strategy. To evaluate the performance of the algorithms, these strategies are applied to the swinging up an inverted pendulum. Numerical simulations show that the neural network approximation in the MBAC strategy can be poor, and the algorithm may converge far from the optimum. In the MBAC approach neither stabilization nor monotonic convergence can be guaranteed, and it is observed that the best value function is not always corresponding to the last one. On the other side the nonlinear policy iteration approach guarantees that every new control policy is stabilizing and generally leads to a monotonically decreasing cost. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Multilabel Classification of Hate Speech and Abusive Words on Indonesian Twitter Social Media"
        ],
        "penulis":"Hendrawan, Rahmat;Adiwijaya;Al Faraby, Said;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Hate speech and abusive words spread widely on social media. The impact of hate speech on social media is hazardous, which can lead to discrimination, social conflict, and even genocide. Hate speech also has target types, categories, and levels. This research discusses the classification of hate speech and abusive words in the text on social media Twitter in Indonesian, English, and a mixture of both up to the types, categories, and levels. Classification of hate speech multilabel text is investigated using RFDT, BiLSTM, and BiLSTM with the pre-trained BERT model. The Classifier Chains, Label Powerset, and Binary Relevance methods are also used as data transformation, and TF-IDF is also used as feature extraction combined with the RFDT classification method. Some scenarios of the preprocessing stage are also carried out to find the best results, namely full preprocess, without stopword removal, and without stemming and without stopword removal. The problem of having Indonesian, English, and a mixture of both is solved in two ways, namely, without being translated and translated into Indonesian. The best results with an accuracy of 76.12% were obtained using the RFDT classification method with Classifier Chains, without translation, without stemming, and without stopword removal. This research also shows that the translation, stemming, and stopword removal are not effective, and the problem of dependencies between labels greatly affects the results of classification.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Hate speech and abusive words spread widely on social media. The impact of hate speech on social media is hazardous, which can lead to discrimination, social conflict, and even genocide. Hate speech also has target types, categories, and levels. This research discusses the classification of hate speech and abusive words in the text on social media Twitter in Indonesian, English, and a mixture of both up to the types, categories, and levels. Classification of hate speech multilabel text is investigated using RFDT, BiLSTM, and BiLSTM with the pre-trained BERT model. The Classifier Chains, Label Powerset, and Binary Relevance methods are also used as data transformation, and TF-IDF is also used as feature extraction combined with the RFDT classification method. Some scenarios of the preprocessing stage are also carried out to find the best results, namely full preprocess, without stopword removal, and without stemming and without stopword removal. The problem of having Indonesian, English, and a mixture of both is solved in two ways, namely, without being translated and translated into Indonesian. The best results with an accuracy of 76.12% were obtained using the RFDT classification method with Classifier Chains, without translation, without stemming, and without stopword removal. This research also shows that the translation, stemming, and stopword removal are not effective, and the problem of dependencies between labels greatly affects the results of classification.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Japanese language conjunction and Indonesian language conjunction: Review of contrastive analysis as seen from the use and teaching method"
        ],
        "penulis":"Aditiawarman, Mac;Kartika, Diana;Prajana, Andika;Yuhendra;Mardius, Ali;Fauzi, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Language is the most important part in meeting socially and getting together to wherever and whenever you live. Language becomes very important because without language human can not interact and understand one to another culture. Nowadays Japanese language becomes one of foreign languages which is preferred by most Indonesia people either high school and university students or anyone who is interested in learning Japanese. Furthermore, Japanese language is learned as linguistics which is used to study in Japan or as introductory language at Japanese corporate outside their own country. As mentioned in the introductory chapter, the purpose of this research is to find out the form of conjunctions in Indonesian, the form of conjunctions in Japanese and what are the differences and similarities between forms of conjunctions between the two languages. The research method used by the writer is descriptive analysis method. The author uses research sources derived from written works such as books, theses, journals and the internet. First of all the writer will gather theories and select them according to their level of relevance to the topic under study. Furthermore, the writer will describe and analyse conjunctions contained in Indonesian and Japanese sentences. After being analysed, the writer found 4 conjunctions in Japanese, namely; \u201csoshite\u201d,\u201d kara\u201d, \u201cdemo\u201d and \u201cdesukara\u201d. Whereas in Indonesian the writer found; \u201cdan\u201d, \u201ctetapi\u201d, \u201coleh karena\u201d, \u201cbiarpun\u201d. \u00a9 2020 Asian E F L Journal Press. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Language is the most important part in meeting socially and getting together to wherever and whenever you live. Language becomes very important because without language human can not interact and understand one to another culture. Nowadays Japanese language becomes one of foreign languages which is preferred by most Indonesia people either high school and university students or anyone who is interested in learning Japanese. Furthermore, Japanese language is learned as linguistics which is used to study in Japan or as introductory language at Japanese corporate outside their own country. As mentioned in the introductory chapter, the purpose of this research is to find out the form of conjunctions in Indonesian, the form of conjunctions in Japanese and what are the differences and similarities between forms of conjunctions between the two languages. The research method used by the writer is descriptive analysis method. The author uses research sources derived from written works such as books, theses, journals and the internet. First of all the writer will gather theories and select them according to their level of relevance to the topic under study. Furthermore, the writer will describe and analyse conjunctions contained in Indonesian and Japanese sentences. After being analysed, the writer found 4 conjunctions in Japanese, namely; \u201csoshite\u201d,\u201d kara\u201d, \u201cdemo\u201d and \u201cdesukara\u201d. Whereas in Indonesian the writer found; \u201cdan\u201d, \u201ctetapi\u201d, \u201coleh karena\u201d, \u201cbiarpun\u201d. \u00a9 2020 Asian E F L Journal Press. All rights reserved."
        ]
    },
    {
        "judul":[
            "Sigfox-based internet of things network planning for advanced metering infrastructure services in urban scenario"
        ],
        "penulis":"Purnama, Arrizky Ayu Faradila;Nashiruddin, Muhammad Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "SigFox is a Low Power Wide Area Network (LPWAN) technology using unlicensed frequency bands with Ultra Narrow Band technology. It has advantages in terms of very low power consumption, high receiver sensitivity, and the cheap cost of end devices. SigFox technology is based on Link Quality Control (LQI). One parameter is the division of zones is based on radio configuration, where Indonesia included in zone 2 with radio configuration RC4. SigFox is very suitable as a solution in terms of radio connectivity. In this study, an analysis of the Internet of Thing (IoT) network design was carried out in the East Java province of Indonesia, particularly in the cities of Surabaya, Sidoarjo, and Gresik as Urban Scenario. The Advanced Metering Infrastructure services include electricity, water, gas, and fuel. From the simulations that have been carried out, the optimal number of gateways obtained respectively 34 sites for the Surabaya area with the average signal level received was -78 dBm, and SNR value was 17.27 dB. While five gateways need for the Sidoarjo area with the average signal level received was -89.68 dBm, and SNR value was -1.06 dB, and eight sites for the Gresik area with the average signal level received was -89.14 dBm, and SNR value was -1.12 dB.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SigFox is a Low Power Wide Area Network (LPWAN) technology using unlicensed frequency bands with Ultra Narrow Band technology. It has advantages in terms of very low power consumption, high receiver sensitivity, and the cheap cost of end devices. SigFox technology is based on Link Quality Control (LQI). One parameter is the division of zones is based on radio configuration, where Indonesia included in zone 2 with radio configuration RC4. SigFox is very suitable as a solution in terms of radio connectivity. In this study, an analysis of the Internet of Thing (IoT) network design was carried out in the East Java province of Indonesia, particularly in the cities of Surabaya, Sidoarjo, and Gresik as Urban Scenario. The Advanced Metering Infrastructure services include electricity, water, gas, and fuel. From the simulations that have been carried out, the optimal number of gateways obtained respectively 34 sites for the Surabaya area with the average signal level received was -78 dBm, and SNR value was 17.27 dB. While five gateways need for the Sidoarjo area with the average signal level received was -89.68 dBm, and SNR value was -1.06 dB, and eight sites for the Gresik area with the average signal level received was -89.14 dBm, and SNR value was -1.12 dB.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Blacklisted IP distribution system to handle DDoS attacks on IPS Snort based on Blockchain"
        ],
        "penulis":"Al'Aziz, Bram Andika Ahmad;Sukarno, Parman;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The mechanism for distributing information on the source of the attack by combining blockchain technology with the Intrusion Prevention System (IPS) can be done so that DDoS attack mitigation becomes more flexible, saves resources and costs. Also, by informing the blacklisted Internet Protocol(IP), each IPS can share attack source information so that attack traffic blocking can be carried out on IPS that are closer to the source of the attack. Therefore, the attack traffic passing through the network can be drastically reduced because the attack traffic has been blocked on the IPS that is closer to the attack source. The blocking of existing DDoS attack traffic is generally carried out on each IPS without a mechanism to share information on the source of the attack so that each IPS cannot cooperate. Also, even though the DDoS attack traffic did not reach the server because it had been blocked by IPS, the attack traffic still flooded the network so that network performance was reduced. Through smart contracts on the Ethereum blockchain, it is possible to inform the source of the attack or blacklisted IP addresses without requiring additional infrastructure. The blacklisted IP address is used by IPS to detect and handle DDoS attacks. Through the blacklisted IP distribution scheme, testing and analysis are carried out to see information on the source of the attack on each IPS and the attack traffic that passes on the network. The result is that each IPS can have the same blacklisted IP so that each IPS can have the same attack source information. The results also showed that the attack traffic through the network infrastructure can be drastically reduced. Initially, the total number of attack packets had an average of 115, 578 reduced to 27, 165.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The mechanism for distributing information on the source of the attack by combining blockchain technology with the Intrusion Prevention System (IPS) can be done so that DDoS attack mitigation becomes more flexible, saves resources and costs. Also, by informing the blacklisted Internet Protocol(IP), each IPS can share attack source information so that attack traffic blocking can be carried out on IPS that are closer to the source of the attack. Therefore, the attack traffic passing through the network can be drastically reduced because the attack traffic has been blocked on the IPS that is closer to the attack source. The blocking of existing DDoS attack traffic is generally carried out on each IPS without a mechanism to share information on the source of the attack so that each IPS cannot cooperate. Also, even though the DDoS attack traffic did not reach the server because it had been blocked by IPS, the attack traffic still flooded the network so that network performance was reduced. Through smart contracts on the Ethereum blockchain, it is possible to inform the source of the attack or blacklisted IP addresses without requiring additional infrastructure. The blacklisted IP address is used by IPS to detect and handle DDoS attacks. Through the blacklisted IP distribution scheme, testing and analysis are carried out to see information on the source of the attack on each IPS and the attack traffic that passes on the network. The result is that each IPS can have the same blacklisted IP so that each IPS can have the same attack source information. The results also showed that the attack traffic through the network infrastructure can be drastically reduced. Initially, the total number of attack packets had an average of 115, 578 reduced to 27, 165.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Feasibility Study of the IoT-Connectivity Deployment for AMI Service: A Case Study in Surabaya City"
        ],
        "penulis":"Purnama, Arrizky Ayu Faradila;Nashiruddin, Muhammad Imam;Murti, Muhammad Ary;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The manual reading of electricity, water, gas, and fuel tank meters requires increased fieldwork efficiency and improved measurement accuracy and monitoring related to service users and reducing fraud potential. The implementation of measurement services needs to be supported by communication technology, which has low cost and reliability characteristics.AMI (Advanced Meter Infrastructure) is an integrated smart meter system, communication network, and data management system that enables two-way communication between utilities and customers. With AMI's application, it is expected to increase efficiency in monitoring and detecting leaks to overcome losses. IoT is a concept where particular objects can transfer data over the network without requiring human-to-human or human-to-computer interaction. There is technology standardization, namely LPWAN.Planning is done by comparing LoRaWAN, Sigfox, and NB-IoT with the main topic of discussion regarding network connectivity for AMI service needs. Based on the planning results, LoRaWAN requires at least 31 gateways with an average signal level of -83.11 dBm, an average throughput of 21.88 kbps, and an average SNR -0.13 dB. Sigfox requires at least 32 gateways with an intermediate signal level of -81.28 dBm, an average throughput of 0.6 kbps, and an average SNR of 14.79 dB. NB-IoT requires at least 31 gateways with an average signal level of -57.38 dBm, an average throughput of 220.36 kbps, and an average SNR of 8.87 dB. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The manual reading of electricity, water, gas, and fuel tank meters requires increased fieldwork efficiency and improved measurement accuracy and monitoring related to service users and reducing fraud potential. The implementation of measurement services needs to be supported by communication technology, which has low cost and reliability characteristics.AMI (Advanced Meter Infrastructure) is an integrated smart meter system, communication network, and data management system that enables two-way communication between utilities and customers. With AMI's application, it is expected to increase efficiency in monitoring and detecting leaks to overcome losses. IoT is a concept where particular objects can transfer data over the network without requiring human-to-human or human-to-computer interaction. There is technology standardization, namely LPWAN.Planning is done by comparing LoRaWAN, Sigfox, and NB-IoT with the main topic of discussion regarding network connectivity for AMI service needs. Based on the planning results, LoRaWAN requires at least 31 gateways with an average signal level of -83.11 dBm, an average throughput of 21.88 kbps, and an average SNR -0.13 dB. Sigfox requires at least 32 gateways with an intermediate signal level of -81.28 dBm, an average throughput of 0.6 kbps, and an average SNR of 14.79 dB. NB-IoT requires at least 31 gateways with an average signal level of -57.38 dBm, an average throughput of 220.36 kbps, and an average SNR of 8.87 dB. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The routing protocol efficiency of named data network"
        ],
        "penulis":"Wibowo, Tody Ariefianto;Syambas, Nana Rachmana;Hendrawan, Hendrawan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "An efficient routing protocol is needed in transmitting data on the network, especially on Named Data Network. This means that the routing mechanism must be made in such a way that the data transmission rate is close to the transmission link rate. This study investigates the effect of a geographic-based routing protocol compared to the link state from an efficiency point of view. The system model is built to see the effect of link bitrate, path stretch, packet header, and packet size on the efficiency of the routing protocol in sending data. From the mathematical model, Link State routing is outperformed geographic routing protocol for 24% on average.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "An efficient routing protocol is needed in transmitting data on the network, especially on Named Data Network. This means that the routing mechanism must be made in such a way that the data transmission rate is close to the transmission link rate. This study investigates the effect of a geographic-based routing protocol compared to the link state from an efficiency point of view. The system model is built to see the effect of link bitrate, path stretch, packet header, and packet size on the efficiency of the routing protocol in sending data. From the mathematical model, Link State routing is outperformed geographic routing protocol for 24% on average.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Developing vocational training: Lesson learnt from building business model innovation through customer experience and distinctive organizational capability"
        ],
        "penulis":"Mihardjo, Leonardus;Elidjen;Alamsjah, Firdaus;Sasmoko;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "A vocational training can be invested based on the degree of innovation, such as on business models to face challenges in the era of Industrial Revolution 4.0. The lesson learnt can be captured through the formulation of strategy that needed to consider internal and external aspects. For example, as in the digital world, customer experience as well as customer satisfaction. Capability on the side of the network owned combined with network and social capabilities are expected to create distinctive organizational capability. Based on this background, the study aims to examine the effects of customer experience and distinctive organizational capability on the business model innovations of telecommunication firms in Indonesia using quantitative research. The target population are 445 telecommunication network companies in Indonesia which includes 312 ISP firms, 34 satellite firms, 27 tower firms, and 72 Telkom subsidiaries and affiliates, with samples taken from 34 firms. PLS is used as the analytical tool to process the data in this study. The results of the study show that customer experience and distinctive organizational capabilities have an influence to business model innovations. Customer experience has a bigger role than distinctive organizational capability in building business model innovation. These findings have practical implications for the management of telecommunications industries in Indonesia as the development of vocational training rely on the needs of business model innovation development, which directly based on the development of customer experience and supported with development of distinctive organizational capability. Further research can be explored by expanding the sample, industry and in other countries. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher\u2019s Office.",
            "Sustainable Development Goals mapped to this documentQuality educationGoal 4Industry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "A vocational training can be invested based on the degree of innovation, such as on business models to face challenges in the era of Industrial Revolution 4.0. The lesson learnt can be captured through the formulation of strategy that needed to consider internal and external aspects. For example, as in the digital world, customer experience as well as customer satisfaction. Capability on the side of the network owned combined with network and social capabilities are expected to create distinctive organizational capability. Based on this background, the study aims to examine the effects of customer experience and distinctive organizational capability on the business model innovations of telecommunication firms in Indonesia using quantitative research. The target population are 445 telecommunication network companies in Indonesia which includes 312 ISP firms, 34 satellite firms, 27 tower firms, and 72 Telkom subsidiaries and affiliates, with samples taken from 34 firms. PLS is used as the analytical tool to process the data in this study. The results of the study show that customer experience and distinctive organizational capabilities have an influence to business model innovations. Customer experience has a bigger role than distinctive organizational capability in building business model innovation. These findings have practical implications for the management of telecommunications industries in Indonesia as the development of vocational training rely on the needs of business model innovation development, which directly based on the development of customer experience and supported with development of distinctive organizational capability. Further research can be explored by expanding the sample, industry and in other countries. \u00a9 Universiti Tun Hussein Onn Malaysia Publisher\u2019s Office."
        ]
    },
    {
        "judul":[
            "Comparison of rainfall bias correction in sumatra island using the cordex regional climate model (RCM) output model"
        ],
        "penulis":"Nur, Irza Arnita;Misnawati;Amalo, Luisa Febrina;Hidayat, Rahmat;Latifah, Arnida lailatul;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Drought is a natural hazard which frequently occurs in Indonesia that impacting many sectors, particularly agriculture. In this study, rainfall is used as the main parameter to determine drought area. Currently, the use of global data is increasing in order to overcome unavailability of rainfall data. Therefore, we compare the observed rainfall data from the Climate Hazards Group InfraRed Precipitation with Station (CHIRPS) with Regional Climate Model (RCM) output from the Coordinated Regional Climate Downscaling Experiment (CORDEX) data of five models, including CSIRO MK3.6, EC -Earth, GFDL-ESM2M, IPSLCM5A-LR, MPI-ESM-LR. However, it is still constrained due to inconsistencies (bias) to the observational data. Therefore, bias correction is needed for further use of this study. Bias correction with observational data (CHIRPS) were done using Piani method. The results showed, CSIRO MK3.6 correction value is the closest to the CHIRPS observation rainfall pattern with r2= 0.38. \u00a9 2020 ACRS 2020 - 41st Asian Conference on Remote Sensing. All rights reserved.",
            "Sustainable Development Goals mapped to this documentClimate actionGoal 13Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Drought is a natural hazard which frequently occurs in Indonesia that impacting many sectors, particularly agriculture. In this study, rainfall is used as the main parameter to determine drought area. Currently, the use of global data is increasing in order to overcome unavailability of rainfall data. Therefore, we compare the observed rainfall data from the Climate Hazards Group InfraRed Precipitation with Station (CHIRPS) with Regional Climate Model (RCM) output from the Coordinated Regional Climate Downscaling Experiment (CORDEX) data of five models, including CSIRO MK3.6, EC -Earth, GFDL-ESM2M, IPSLCM5A-LR, MPI-ESM-LR. However, it is still constrained due to inconsistencies (bias) to the observational data. Therefore, bias correction is needed for further use of this study. Bias correction with observational data (CHIRPS) were done using Piani method. The results showed, CSIRO MK3.6 correction value is the closest to the CHIRPS observation rainfall pattern with r2= 0.38. \u00a9 2020 ACRS 2020 - 41st Asian Conference on Remote Sensing. All rights reserved."
        ]
    },
    {
        "judul":[
            "A dataset for emotional reactions and family resilience during COVID-19 isolation period among Indonesian families"
        ],
        "penulis":"Ramadhana, Maulana Rezi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study presents a survey dataset describing families\u2019 conditions during the COVID-19 isolation period obtained from individuals who serve as parents. A survey was conducted to measure the family's positive or negative emotional reactions and the degree of their resilience. The data were categorized into age, sex, type of family, family size, length of marriage, family's environment, and family COVID-19 status. The samples were gathered from 365 parents of Indonesian students who were willing to fill an online questionnaire. SPSS v.23.0 was used to carry out descriptive statistics and intercorrelations. Additional results from chi-square analyses are available as supplemental tables in the Mendeley repository. \u00a9 2020 The Author(s)",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study presents a survey dataset describing families\u2019 conditions during the COVID-19 isolation period obtained from individuals who serve as parents. A survey was conducted to measure the family's positive or negative emotional reactions and the degree of their resilience. The data were categorized into age, sex, type of family, family size, length of marriage, family's environment, and family COVID-19 status. The samples were gathered from 365 parents of Indonesian students who were willing to fill an online questionnaire. SPSS v.23.0 was used to carry out descriptive statistics and intercorrelations. Additional results from chi-square analyses are available as supplemental tables in the Mendeley repository. \u00a9 2020 The Author(s)"
        ]
    },
    {
        "judul":[

        ],
        "penulis":"",
        "tahun":2020,
        "sdgs":[

        ],
        "abstrak":[

        ]
    },
    {
        "judul":[
            "The NPD Process Design Canvas: Tool for NPD Process Creation"
        ],
        "penulis":"Iqbal M.;Suzianti A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "New Product Development (NPD) is important for the growth and sustainability of companies. One of the most important factors in NPD is the management of the NPD process. NPD process is believed to be a crucial factor in NPD success. NPD process may vary between organizations. Companies must be able to implement the most suitable NPD process. Therefore, the design of NPD process is crucial. This article proposes a tool that can support organizations to design their NPD process. The tool is conceptualized based on the sequence of NPD design method. The tool is based on the form of 'space of elements' and called the NPD Process Design Canvas. The concept has been tested and several feedbacks identified. Some of the pros are its ability to capture the risks and elements of process design. Some of the cons are the variation of detail and inability to describe the existing process. Based on the feedbacks, improvements proposed are the addition of specific 'iterations' and 'reviews' analysis in the canvas, and the paradigm of the canvas as the integrator of several analyses carried out based on the sequence of NPD design method. Further research may focus on the testing of a more sophisticated canvas implementation and how the tool considers the position of companies' existing NPD process. \u00a9 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "New Product Development (NPD) is important for the growth and sustainability of companies. One of the most important factors in NPD is the management of the NPD process. NPD process is believed to be a crucial factor in NPD success. NPD process may vary between organizations. Companies must be able to implement the most suitable NPD process. Therefore, the design of NPD process is crucial. This article proposes a tool that can support organizations to design their NPD process. The tool is conceptualized based on the sequence of NPD design method. The tool is based on the form of 'space of elements' and called the NPD Process Design Canvas. The concept has been tested and several feedbacks identified. Some of the pros are its ability to capture the risks and elements of process design. Some of the cons are the variation of detail and inability to describe the existing process. Based on the feedbacks, improvements proposed are the addition of specific 'iterations' and 'reviews' analysis in the canvas, and the paradigm of the canvas as the integrator of several analyses carried out based on the sequence of NPD design method. Further research may focus on the testing of a more sophisticated canvas implementation and how the tool considers the position of companies' existing NPD process. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "The Influence of Blue Light in Maintaining Alertness in Tropical Country: A Preliminary Study"
        ],
        "penulis":"Rahma K.T.;Salma S.A.;Widyanti A.;Suprijanto;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Several studies have discussed the influence of blue light on cognitive activity. This study aims to determine the effectiveness of blue light in increasing alertness at night in tropical countries. Twelve healthy young males joined in this study. All participants were asked to do a monotonous activity that is reading activity. The experiment was a within-subject design with the independent variable is lighting condition (normal light and blue light) and duration of exposure (30 minutes and 60 minutes). Electroencephalography (EEG) signals were recorded continuously during the experiment. Alertness was measured based on theta, alpha, and beta activity. The result is the light condition not significantly affected the theta (F (1,11) = 0.608, \u03c1 = 0.452), alpha (F (1,11) = 1.561, \u03c1 = 0.237), and beta (F (1,11) = 0.608, \u03c1 = 0.700) activity. This shows that blue light is not effective in increasing alertness at night in the tropical country both in short and long duration of exposure. \u00a9 2020 Published under licence by IOP Publishing Ltd.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Several studies have discussed the influence of blue light on cognitive activity. This study aims to determine the effectiveness of blue light in increasing alertness at night in tropical countries. Twelve healthy young males joined in this study. All participants were asked to do a monotonous activity that is reading activity. The experiment was a within-subject design with the independent variable is lighting condition (normal light and blue light) and duration of exposure (30 minutes and 60 minutes). Electroencephalography (EEG) signals were recorded continuously during the experiment. Alertness was measured based on theta, alpha, and beta activity. The result is the light condition not significantly affected the theta (F (1,11) = 0.608, \u03c1 = 0.452), alpha (F (1,11) = 1.561, \u03c1 = 0.237), and beta (F (1,11) = 0.608, \u03c1 = 0.700) activity. This shows that blue light is not effective in increasing alertness at night in the tropical country both in short and long duration of exposure. \u00a9 2020 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "Smart Safe Prototype Based Internet of Things (IoT) with Face and Fingerprint Recognition"
        ],
        "penulis":"Setyadi, Ramadhan Rizki;Istikmal;Irawan, Arif Indra;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The safe box is currently considered safe but is not truly safe. That is because safe storage has a security method using PINs that can be seen by others. Therefore, a more secure safe box security system is needed. This paper purpose a safe box prototype with an added security system using a two-way verification system and an integrated Internet of Things (IoT) system. The face recognition system and fingerprint system used in this system. The face recognition system developed an LBP (Local Binary Pattern) clarification and embedded Haar cascade program in raspberry Pi. For real-time monitoring, the safe box has been designed to provide violation alerts via notifications on android apps. Two-way verification smart safe box has a good face recognition system especially when the conditions are bright and also the best way to identify fingerprints on a flat position. In LOS conditions, the best distance is at 4 meters with a delay value of 0.373 s and throughput of 3680.533 bps. In non-LOS condition, the best distance is 2 meters with a delay value of 0.380 seconds and throughput of 4055.73 bytes\/s.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The safe box is currently considered safe but is not truly safe. That is because safe storage has a security method using PINs that can be seen by others. Therefore, a more secure safe box security system is needed. This paper purpose a safe box prototype with an added security system using a two-way verification system and an integrated Internet of Things (IoT) system. The face recognition system and fingerprint system used in this system. The face recognition system developed an LBP (Local Binary Pattern) clarification and embedded Haar cascade program in raspberry Pi. For real-time monitoring, the safe box has been designed to provide violation alerts via notifications on android apps. Two-way verification smart safe box has a good face recognition system especially when the conditions are bright and also the best way to identify fingerprints on a flat position. In LOS conditions, the best distance is at 4 meters with a delay value of 0.373 s and throughput of 3680.533 bps. In non-LOS condition, the best distance is 2 meters with a delay value of 0.380 seconds and throughput of 4055.73 bytes\/s.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Consumer Trust to Buy Green Product: Investigation of Green Perceived Value with Green Satisfaction Mediation"
        ],
        "penulis":"Lutfie, Harrie;Marcelino, Dandy;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The current level of human awareness of the environment began to grow since the emergence of negative environmental issues like global warming. Global warming causes consumers to be more interested in buying products from companies that care about the environment. One form of consumer concern today is the emergence of green lifestyle trends. Green lifestyle is currently being widely adopted by the community as natural damage caused by that community as well. Consumers who have an environmental concern will make changes by buying products that are proven to be environmentally friendly. This study aims to determine whether the green marketing strategy implemented by Starbucks runs effectively and to find out the role of Green Perceived Value towards Green Trust mediated by Green Satisfaction on Starbucks Bandung consumers. The analysis method employed in this research is quantitative with causal type research, as well as data analysis techniques using path analysis which is divided into two substructures. The results showed the Green Perceived Value and Green Satisfaction variables had a positive and significant effect on the Green Trust variables simultaneously. The total effect of the independent variables studied is equal to 68.68% and the rest 31.32% is influenced by other variables or factors not examined that could increase Green Trust. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The current level of human awareness of the environment began to grow since the emergence of negative environmental issues like global warming. Global warming causes consumers to be more interested in buying products from companies that care about the environment. One form of consumer concern today is the emergence of green lifestyle trends. Green lifestyle is currently being widely adopted by the community as natural damage caused by that community as well. Consumers who have an environmental concern will make changes by buying products that are proven to be environmentally friendly. This study aims to determine whether the green marketing strategy implemented by Starbucks runs effectively and to find out the role of Green Perceived Value towards Green Trust mediated by Green Satisfaction on Starbucks Bandung consumers. The analysis method employed in this research is quantitative with causal type research, as well as data analysis techniques using path analysis which is divided into two substructures. The results showed the Green Perceived Value and Green Satisfaction variables had a positive and significant effect on the Green Trust variables simultaneously. The total effect of the independent variables studied is equal to 68.68% and the rest 31.32% is influenced by other variables or factors not examined that could increase Green Trust. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Intelligent decision support systems for determining tour bus route with time windows: A metaheuristic approach"
        ],
        "penulis":"Hudzaifah H.;Rizana A.F.;Ramadhan F.;Imran A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The transportation routing problem is a very popular field in operations research and management science area. Many previous researches are still continuing to develop model and algorithm to produce the best transportation route optimization in various research objects. Technology has enabled the development of the intelligent decision support system (I-DSS) to optimize transportation route. Although technology has evolved, there are still few researches that build I-DSS software to minimize transportation distance and fuel consumption, especially using the metaheuristic approach. Thus, this paper aims to develop I-DSS software to minimize fuel consumption and travel distance by considering time-windows constraint using metaheuristic approach. The software can receive input dynamically to evaluate and select the best transportation route. The results of this software have been tested using real historical data from one of tour and travel company in Indonesia. The company provides travel services using a bus to visit several tourist attractions based on the opening hours of the destinations. I-DSS software output shows that the travel distance is 25.64% more efficient than the current real conditions. In addition, the fuel consumption produced by I-DSS is better than the actual conditions, which is 17.35% more efficient. \u00a9 Published under licence by IOP Publishing Ltd.",
            "Sustainable Development Goals mapped to this documentPartnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The transportation routing problem is a very popular field in operations research and management science area. Many previous researches are still continuing to develop model and algorithm to produce the best transportation route optimization in various research objects. Technology has enabled the development of the intelligent decision support system (I-DSS) to optimize transportation route. Although technology has evolved, there are still few researches that build I-DSS software to minimize transportation distance and fuel consumption, especially using the metaheuristic approach. Thus, this paper aims to develop I-DSS software to minimize fuel consumption and travel distance by considering time-windows constraint using metaheuristic approach. The software can receive input dynamically to evaluate and select the best transportation route. The results of this software have been tested using real historical data from one of tour and travel company in Indonesia. The company provides travel services using a bus to visit several tourist attractions based on the opening hours of the destinations. I-DSS software output shows that the travel distance is 25.64% more efficient than the current real conditions. In addition, the fuel consumption produced by I-DSS is better than the actual conditions, which is 17.35% more efficient. \u00a9 Published under licence by IOP Publishing Ltd."
        ]
    },
    {
        "judul":[
            "A Comparative Study of Deepfake Video Detection Method"
        ],
        "penulis":"Ramadhani, Kurniawan Nur;Munir, Rinaldi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Deepfake technology allows humans to manipulate images and videos using deep learning technology. The results from deepfakes are very difficult to distinguish using ordinary vision. Many algorithms are built to detect deepfake content in images and videos. There are several approaches in deepfake detection, including a visual feature-based approach, a local feature-based approach, a deep feature-based approach and a temporal feature-based approach. The main challenge in developing deepfake detection algorithms is the variety of existing deepfake models in both images and videos. Another challenge is that deepfake technology is still evolving, making deepfake images and videos look more realistic and harder to detect. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Deepfake technology allows humans to manipulate images and videos using deep learning technology. The results from deepfakes are very difficult to distinguish using ordinary vision. Many algorithms are built to detect deepfake content in images and videos. There are several approaches in deepfake detection, including a visual feature-based approach, a local feature-based approach, a deep feature-based approach and a temporal feature-based approach. The main challenge in developing deepfake detection algorithms is the variety of existing deepfake models in both images and videos. Another challenge is that deepfake technology is still evolving, making deepfake images and videos look more realistic and harder to detect. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "The role of tourism and renewable energy in testing the environmental Kuznets curve in the BRICS countries: fresh evidence from methods of moments quantile regression"
        ],
        "penulis":"Aziz, Noshaba;Mihardjo, Leonardus Ww;Sharif, Arshian;Jermsittiparsert, Kittisak;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "BRICS are among the rising nations which drive economic growth by excessive utilization of resources and resulting in environment degradation. Although there is bulk of research on environmental Kuznets curve (EKC), very limited studies explored the scope in context of tourism in BRICS countries. So this research is conducted to explore the association of tourism, renewable energy, and economic growth with carbon emissions by using annual data of BRICS countries from the year 1995 to 2018. By using the recent approach of method of moments quantile regression (MMQR), the finding shows that tourism has stronger significant negative effects from 10th to 40th quantile while the effects are insignificant at remaining quantiles. Furthermore, an inverted U-shape EKC curve is also apparent at all quantiles excluding 10th and 20th quantiles. For renewable energy, the results are found negatively significant across all quantiles (10th\u201390th) which claim that CO2 emission can be reduced by opting renewable sources. Hence, the empirical results of the current study provide insights for policymakers to consume renewable energy sources for the sustainable economic growth and solution of environmental problems. \u00a9 2020, Springer-Verlag GmbH Germany, part of Springer Nature.",
            "Sustainable Development Goals mapped to this documentAffordable and clean energyGoal 7Decent work and economic growthGoal 8Responsible consumption and productionGoal 12Climate actionGoal 13Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "BRICS are among the rising nations which drive economic growth by excessive utilization of resources and resulting in environment degradation. Although there is bulk of research on environmental Kuznets curve (EKC), very limited studies explored the scope in context of tourism in BRICS countries. So this research is conducted to explore the association of tourism, renewable energy, and economic growth with carbon emissions by using annual data of BRICS countries from the year 1995 to 2018. By using the recent approach of method of moments quantile regression (MMQR), the finding shows that tourism has stronger significant negative effects from 10th to 40th quantile while the effects are insignificant at remaining quantiles. Furthermore, an inverted U-shape EKC curve is also apparent at all quantiles excluding 10th and 20th quantiles. For renewable energy, the results are found negatively significant across all quantiles (10th\u201390th) which claim that CO2 emission can be reduced by opting renewable sources. Hence, the empirical results of the current study provide insights for policymakers to consume renewable energy sources for the sustainable economic growth and solution of environmental problems. \u00a9 2020, Springer-Verlag GmbH Germany, part of Springer Nature."
        ]
    },
    {
        "judul":[
            "A System Dynamics for Financial Strategy Model Assessment in National Health Insurance System"
        ],
        "penulis":"Kurnianingtyas, Diva;Santosa, Budi;Siswanto, Nurhadi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The National Health Insurance System (NHIS) was established by the government to provide health insurance to its people. However, some obstacles will be faced by NHIS. For example, when not having proper financial management, the fiscal budget sector will experience a deficit. The issue is happening in Indonesia. The purpose of this research is to develop and evaluate problem models so it can be used for consideration in determining relevant proposed policies. This research uses NHIS data in Indonesia from 2014 to 2018. The method used is a system dynamics approach. The validation of the SD model uses the mean comparison test and t statistic. Next, the model is tested for sensitivity under extreme conditions of low, basic, and high. Patient variables generate low and high states of 34.34% and 33.24%, respectively, which affect the variable fund inventory about 49.3 trillion and -93.46 trillion, respectively. Otherwise, participant variables affect the supply of funds in low and high conditions were about -19.60 trillion and -26.19 trillion, respectively. It can be concluded variable have a direct influence on the expense variable (patient variable) gives a more dominant effect than the variable gives the overall impact (variable of expense and income) such as participant variables. Therefore, strategies related to patient variables are used as short-term strategies, while those related to participant variables are used as long-term strategies. \u00a9 2020 ACM.",
            "Sustainable Development Goals mapped to this documentNo povertyGoal 1",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The National Health Insurance System (NHIS) was established by the government to provide health insurance to its people. However, some obstacles will be faced by NHIS. For example, when not having proper financial management, the fiscal budget sector will experience a deficit. The issue is happening in Indonesia. The purpose of this research is to develop and evaluate problem models so it can be used for consideration in determining relevant proposed policies. This research uses NHIS data in Indonesia from 2014 to 2018. The method used is a system dynamics approach. The validation of the SD model uses the mean comparison test and t statistic. Next, the model is tested for sensitivity under extreme conditions of low, basic, and high. Patient variables generate low and high states of 34.34% and 33.24%, respectively, which affect the variable fund inventory about 49.3 trillion and -93.46 trillion, respectively. Otherwise, participant variables affect the supply of funds in low and high conditions were about -19.60 trillion and -26.19 trillion, respectively. It can be concluded variable have a direct influence on the expense variable (patient variable) gives a more dominant effect than the variable gives the overall impact (variable of expense and income) such as participant variables. Therefore, strategies related to patient variables are used as short-term strategies, while those related to participant variables are used as long-term strategies. \u00a9 2020 ACM."
        ]
    },
    {
        "judul":[
            "Blacklisted IP distribution system to handle DDoS attacks on IPS Snort based on Blockchain"
        ],
        "penulis":"Al'Aziz, Bram Andika Ahmad;Sukarno, Parman;Wardana, Aulia Arif;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The mechanism for distributing information on the source of the attack by combining blockchain technology with the Intrusion Prevention System (IPS) can be done so that DDoS attack mitigation becomes more flexible, saves resources and costs. Also, by informing the blacklisted Internet Protocol(IP), each IPS can share attack source information so that attack traffic blocking can be carried out on IPS that are closer to the source of the attack. Therefore, the attack traffic passing through the network can be drastically reduced because the attack traffic has been blocked on the IPS that is closer to the attack source. The blocking of existing DDoS attack traffic is generally carried out on each IPS without a mechanism to share information on the source of the attack so that each IPS cannot cooperate. Also, even though the DDoS attack traffic did not reach the server because it had been blocked by IPS, the attack traffic still flooded the network so that network performance was reduced. Through smart contracts on the Ethereum blockchain, it is possible to inform the source of the attack or blacklisted IP addresses without requiring additional infrastructure. The blacklisted IP address is used by IPS to detect and handle DDoS attacks. Through the blacklisted IP distribution scheme, testing and analysis are carried out to see information on the source of the attack on each IPS and the attack traffic that passes on the network. The result is that each IPS can have the same blacklisted IP so that each IPS can have the same attack source information. The results also showed that the attack traffic through the network infrastructure can be drastically reduced. Initially, the total number of attack packets had an average of 115, 578 reduced to 27, 165.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The mechanism for distributing information on the source of the attack by combining blockchain technology with the Intrusion Prevention System (IPS) can be done so that DDoS attack mitigation becomes more flexible, saves resources and costs. Also, by informing the blacklisted Internet Protocol(IP), each IPS can share attack source information so that attack traffic blocking can be carried out on IPS that are closer to the source of the attack. Therefore, the attack traffic passing through the network can be drastically reduced because the attack traffic has been blocked on the IPS that is closer to the attack source. The blocking of existing DDoS attack traffic is generally carried out on each IPS without a mechanism to share information on the source of the attack so that each IPS cannot cooperate. Also, even though the DDoS attack traffic did not reach the server because it had been blocked by IPS, the attack traffic still flooded the network so that network performance was reduced. Through smart contracts on the Ethereum blockchain, it is possible to inform the source of the attack or blacklisted IP addresses without requiring additional infrastructure. The blacklisted IP address is used by IPS to detect and handle DDoS attacks. Through the blacklisted IP distribution scheme, testing and analysis are carried out to see information on the source of the attack on each IPS and the attack traffic that passes on the network. The result is that each IPS can have the same blacklisted IP so that each IPS can have the same attack source information. The results also showed that the attack traffic through the network infrastructure can be drastically reduced. Initially, the total number of attack packets had an average of 115, 578 reduced to 27, 165.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Japanese language conjunction and Indonesian language conjunction: Review of contrastive analysis as seen from the use and teaching method"
        ],
        "penulis":"Aditiawarman, Mac;Kartika, Diana;Prajana, Andika;Yuhendra;Mardius, Ali;Fauzi, Rahmat;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Language is the most important part in meeting socially and getting together to wherever and whenever you live. Language becomes very important because without language human can not interact and understand one to another culture. Nowadays Japanese language becomes one of foreign languages which is preferred by most Indonesia people either high school and university students or anyone who is interested in learning Japanese. Furthermore, Japanese language is learned as linguistics which is used to study in Japan or as introductory language at Japanese corporate outside their own country. As mentioned in the introductory chapter, the purpose of this research is to find out the form of conjunctions in Indonesian, the form of conjunctions in Japanese and what are the differences and similarities between forms of conjunctions between the two languages. The research method used by the writer is descriptive analysis method. The author uses research sources derived from written works such as books, theses, journals and the internet. First of all the writer will gather theories and select them according to their level of relevance to the topic under study. Furthermore, the writer will describe and analyse conjunctions contained in Indonesian and Japanese sentences. After being analysed, the writer found 4 conjunctions in Japanese, namely; \u201csoshite\u201d,\u201d kara\u201d, \u201cdemo\u201d and \u201cdesukara\u201d. Whereas in Indonesian the writer found; \u201cdan\u201d, \u201ctetapi\u201d, \u201coleh karena\u201d, \u201cbiarpun\u201d. \u00a9 2020 Asian E F L Journal Press. All rights reserved.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Language is the most important part in meeting socially and getting together to wherever and whenever you live. Language becomes very important because without language human can not interact and understand one to another culture. Nowadays Japanese language becomes one of foreign languages which is preferred by most Indonesia people either high school and university students or anyone who is interested in learning Japanese. Furthermore, Japanese language is learned as linguistics which is used to study in Japan or as introductory language at Japanese corporate outside their own country. As mentioned in the introductory chapter, the purpose of this research is to find out the form of conjunctions in Indonesian, the form of conjunctions in Japanese and what are the differences and similarities between forms of conjunctions between the two languages. The research method used by the writer is descriptive analysis method. The author uses research sources derived from written works such as books, theses, journals and the internet. First of all the writer will gather theories and select them according to their level of relevance to the topic under study. Furthermore, the writer will describe and analyse conjunctions contained in Indonesian and Japanese sentences. After being analysed, the writer found 4 conjunctions in Japanese, namely; \u201csoshite\u201d,\u201d kara\u201d, \u201cdemo\u201d and \u201cdesukara\u201d. Whereas in Indonesian the writer found; \u201cdan\u201d, \u201ctetapi\u201d, \u201coleh karena\u201d, \u201cbiarpun\u201d. \u00a9 2020 Asian E F L Journal Press. All rights reserved."
        ]
    },
    {
        "judul":[
            "Sigfox-based internet of things network planning for advanced metering infrastructure services in urban scenario"
        ],
        "penulis":"Purnama, Arrizky Ayu Faradila;Nashiruddin, Muhammad Imam;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "SigFox is a Low Power Wide Area Network (LPWAN) technology using unlicensed frequency bands with Ultra Narrow Band technology. It has advantages in terms of very low power consumption, high receiver sensitivity, and the cheap cost of end devices. SigFox technology is based on Link Quality Control (LQI). One parameter is the division of zones is based on radio configuration, where Indonesia included in zone 2 with radio configuration RC4. SigFox is very suitable as a solution in terms of radio connectivity. In this study, an analysis of the Internet of Thing (IoT) network design was carried out in the East Java province of Indonesia, particularly in the cities of Surabaya, Sidoarjo, and Gresik as Urban Scenario. The Advanced Metering Infrastructure services include electricity, water, gas, and fuel. From the simulations that have been carried out, the optimal number of gateways obtained respectively 34 sites for the Surabaya area with the average signal level received was -78 dBm, and SNR value was 17.27 dB. While five gateways need for the Sidoarjo area with the average signal level received was -89.68 dBm, and SNR value was -1.06 dB, and eight sites for the Gresik area with the average signal level received was -89.14 dBm, and SNR value was -1.12 dB.  \u00a9 2020 IEEE.",
            "Sustainable Development Goals mapped to this documentIndustry, innovation and infrastructureGoal 9Partnership for the goalsGoal 17",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "SigFox is a Low Power Wide Area Network (LPWAN) technology using unlicensed frequency bands with Ultra Narrow Band technology. It has advantages in terms of very low power consumption, high receiver sensitivity, and the cheap cost of end devices. SigFox technology is based on Link Quality Control (LQI). One parameter is the division of zones is based on radio configuration, where Indonesia included in zone 2 with radio configuration RC4. SigFox is very suitable as a solution in terms of radio connectivity. In this study, an analysis of the Internet of Thing (IoT) network design was carried out in the East Java province of Indonesia, particularly in the cities of Surabaya, Sidoarjo, and Gresik as Urban Scenario. The Advanced Metering Infrastructure services include electricity, water, gas, and fuel. From the simulations that have been carried out, the optimal number of gateways obtained respectively 34 sites for the Surabaya area with the average signal level received was -78 dBm, and SNR value was 17.27 dB. While five gateways need for the Sidoarjo area with the average signal level received was -89.68 dBm, and SNR value was -1.06 dB, and eight sites for the Gresik area with the average signal level received was -89.14 dBm, and SNR value was -1.12 dB.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Feasibility Study of the IoT-Connectivity Deployment for AMI Service: A Case Study in Surabaya City"
        ],
        "penulis":"Purnama, Arrizky Ayu Faradila;Nashiruddin, Muhammad Imam;Murti, Muhammad Ary;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "The manual reading of electricity, water, gas, and fuel tank meters requires increased fieldwork efficiency and improved measurement accuracy and monitoring related to service users and reducing fraud potential. The implementation of measurement services needs to be supported by communication technology, which has low cost and reliability characteristics.AMI (Advanced Meter Infrastructure) is an integrated smart meter system, communication network, and data management system that enables two-way communication between utilities and customers. With AMI's application, it is expected to increase efficiency in monitoring and detecting leaks to overcome losses. IoT is a concept where particular objects can transfer data over the network without requiring human-to-human or human-to-computer interaction. There is technology standardization, namely LPWAN.Planning is done by comparing LoRaWAN, Sigfox, and NB-IoT with the main topic of discussion regarding network connectivity for AMI service needs. Based on the planning results, LoRaWAN requires at least 31 gateways with an average signal level of -83.11 dBm, an average throughput of 21.88 kbps, and an average SNR -0.13 dB. Sigfox requires at least 32 gateways with an intermediate signal level of -81.28 dBm, an average throughput of 0.6 kbps, and an average SNR of 14.79 dB. NB-IoT requires at least 31 gateways with an average signal level of -57.38 dBm, an average throughput of 220.36 kbps, and an average SNR of 8.87 dB. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "The manual reading of electricity, water, gas, and fuel tank meters requires increased fieldwork efficiency and improved measurement accuracy and monitoring related to service users and reducing fraud potential. The implementation of measurement services needs to be supported by communication technology, which has low cost and reliability characteristics.AMI (Advanced Meter Infrastructure) is an integrated smart meter system, communication network, and data management system that enables two-way communication between utilities and customers. With AMI's application, it is expected to increase efficiency in monitoring and detecting leaks to overcome losses. IoT is a concept where particular objects can transfer data over the network without requiring human-to-human or human-to-computer interaction. There is technology standardization, namely LPWAN.Planning is done by comparing LoRaWAN, Sigfox, and NB-IoT with the main topic of discussion regarding network connectivity for AMI service needs. Based on the planning results, LoRaWAN requires at least 31 gateways with an average signal level of -83.11 dBm, an average throughput of 21.88 kbps, and an average SNR -0.13 dB. Sigfox requires at least 32 gateways with an intermediate signal level of -81.28 dBm, an average throughput of 0.6 kbps, and an average SNR of 14.79 dB. NB-IoT requires at least 31 gateways with an average signal level of -57.38 dBm, an average throughput of 220.36 kbps, and an average SNR of 8.87 dB. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Broadband Achromatic Printed-Circuit Metasurfaces"
        ],
        "penulis":"Fathnan, Ashif. A.;Powell, David A.;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "We develop broadband achromatic metasurfaces suited for microwave frequencies, by tailoring LC resonances in series and parallel configurations. We present a synthesis method for a transmissive metasurface and discuss limits on their realizable bandwidth. \u00a9 2020 IEEE."
        ],
        "abstrak":[
            "We develop broadband achromatic metasurfaces suited for microwave frequencies, by tailoring LC resonances in series and parallel configurations. We present a synthesis method for a transmissive metasurface and discuss limits on their realizable bandwidth. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "EDGAN: Disguising Text as Image using Generative Adversarial Network"
        ],
        "penulis":"Arifianto, Anditya;Maulana, Malik Anhar;Mahadi, Made Raharja Surya;Jamaluddin, Triwidyastuti;Subhi, Rajabandanu;Rendragraha, Adriansyah Dwi;Satya, Muhammad Ferianda;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "In the concept of data hiding, image is often used as a cover to hide sensitive data inside it. This approach is considered a good addition in securing information to cryptography which only hides the information and not the presence of the message itself. The combination of Deep Learning with Steganography and Cryptography is rarely done. By utilizing Deep Neural Networks to encrypt and hide the messages, it will be increasingly difficult to decrypt and track.In this study, we developed an encryption mechanism to not only conceal messages, but transforming them into images. The image containing the hidden messages can later be decrypted and converted back into the original message. We use Generative Adversarial Network to develop the encryption and decryption models. Text data is converted into a word vector using word2vec model which then used as input for the encryption model to produce the word images. We use the MNIST dataset to train models which are able to produce images that encrypt 1000 word variations. Based on our experiments, we were able to produce robust encrypted images with 98% accuracy of reversible words. We also show that our model is resistant to various minor image attacks such as scaling, noise addition, and image rotation.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "In the concept of data hiding, image is often used as a cover to hide sensitive data inside it. This approach is considered a good addition in securing information to cryptography which only hides the information and not the presence of the message itself. The combination of Deep Learning with Steganography and Cryptography is rarely done. By utilizing Deep Neural Networks to encrypt and hide the messages, it will be increasingly difficult to decrypt and track.In this study, we developed an encryption mechanism to not only conceal messages, but transforming them into images. The image containing the hidden messages can later be decrypted and converted back into the original message. We use Generative Adversarial Network to develop the encryption and decryption models. Text data is converted into a word vector using word2vec model which then used as input for the encryption model to produce the word images. We use the MNIST dataset to train models which are able to produce images that encrypt 1000 word variations. Based on our experiments, we were able to produce robust encrypted images with 98% accuracy of reversible words. We also show that our model is resistant to various minor image attacks such as scaling, noise addition, and image rotation.  \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "A dataset for emotional reactions and family resilience during COVID-19 isolation period among Indonesian families"
        ],
        "penulis":"Ramadhana, Maulana Rezi;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "This study presents a survey dataset describing families\u2019 conditions during the COVID-19 isolation period obtained from individuals who serve as parents. A survey was conducted to measure the family's positive or negative emotional reactions and the degree of their resilience. The data were categorized into age, sex, type of family, family size, length of marriage, family's environment, and family COVID-19 status. The samples were gathered from 365 parents of Indonesian students who were willing to fill an online questionnaire. SPSS v.23.0 was used to carry out descriptive statistics and intercorrelations. Additional results from chi-square analyses are available as supplemental tables in the Mendeley repository. \u00a9 2020 The Author(s)",
            "Sustainable Development Goals mapped to this documentGood health and well-beingGoal 3",
            "Sustainable Development Goals mapped to this document",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "This study presents a survey dataset describing families\u2019 conditions during the COVID-19 isolation period obtained from individuals who serve as parents. A survey was conducted to measure the family's positive or negative emotional reactions and the degree of their resilience. The data were categorized into age, sex, type of family, family size, length of marriage, family's environment, and family COVID-19 status. The samples were gathered from 365 parents of Indonesian students who were willing to fill an online questionnaire. SPSS v.23.0 was used to carry out descriptive statistics and intercorrelations. Additional results from chi-square analyses are available as supplemental tables in the Mendeley repository. \u00a9 2020 The Author(s)"
        ]
    },
    {
        "judul":[
            "Identification and analysis of factors affecting e-survey response rate at central bureau of statistics"
        ],
        "penulis":"Adetia, Aisha;Budi, Indra;Setiadi, Farisya;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Central Bureau of Statistics - BPS is a institution that carries out statistical activities. One of the strategic objectives is to increase response rates. BPS hopes that the response rate of 104 BPS census and survey activities in 2017 will be achieved according to the target set. The problem is 59.61% of these activities have a response rate that does not reach the target. One of the root causes of the target response rate is not achieved because the method of data collection using e-survey technology has not reached the expected target response rate. This study aims to analyze the factors that affect the response rate of e-surveys at BPS and provide recommendations for raising it. The method used in this research is a quantitative case study through surveys and qualitative for give recommendations. The list of variables was obtained from literature and then validated by experts using the Delphi Technique. The results of the model are based on Theory of Planned Behavior, Cognitive Dissonance Theory, Gamification Theory, Social Exchange Theory, Preference of Device and Legal Punishment Theory. The results of data collection obtained 41 company responses and 106 valid household responses. Data analysis using the PLS-SEM. The results showed that the factors that had a significant positive influence were attitude, legal punishment and trust for household respondents and device preference and trust factors for company respondents. \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Central Bureau of Statistics - BPS is a institution that carries out statistical activities. One of the strategic objectives is to increase response rates. BPS hopes that the response rate of 104 BPS census and survey activities in 2017 will be achieved according to the target set. The problem is 59.61% of these activities have a response rate that does not reach the target. One of the root causes of the target response rate is not achieved because the method of data collection using e-survey technology has not reached the expected target response rate. This study aims to analyze the factors that affect the response rate of e-surveys at BPS and provide recommendations for raising it. The method used in this research is a quantitative case study through surveys and qualitative for give recommendations. The list of variables was obtained from literature and then validated by experts using the Delphi Technique. The results of the model are based on Theory of Planned Behavior, Cognitive Dissonance Theory, Gamification Theory, Social Exchange Theory, Preference of Device and Legal Punishment Theory. The results of data collection obtained 41 company responses and 106 valid household responses. Data analysis using the PLS-SEM. The results showed that the factors that had a significant positive influence were attitude, legal punishment and trust for household respondents and device preference and trust factors for company respondents. \u00a9 2020 IEEE."
        ]
    },
    {
        "judul":[
            "Investigating generation Z' intention to use learners' generated content for learning activity: A theory of planned behavior approach"
        ],
        "penulis":"Persada, Satria Fadil;Ivanovski, Jeremy;Miraja, Bobby Ardiansyah;Nadlifatin, Reny;Mufidah, Ilma;Chin, Jacky;Redi, A.A.N Perwira;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Nowadays, learning media has developed rapidly, opening infinite possibilities for students to access their educational materials. Learner's Generated Content (LGC) is one of the emerging learning media that showed interesting promises. LGC is based on the concept of User Generated Content; many advantages of UGC also existed in LGC: speed, collaboration, and the diversity of contents. Although past researches have already proven that LGC has positive effects on the educational process, mainly, these previous researches focused only on the perspective of the educators. This study questioned how today's students, mostly comprised of Generation Z, see LGC. Employing the Theory of Planned Behaviour (TPB), we revealed several statistical results followed by managerial interpretations. Attitude (AT) was shown to have the highest correlation with Generation Z's students (\u03b2=0.43), educators could utilise this fact; they can be more reassured when implementing LGC in their future curriculum. The Perceived Behavioral Control (PBC) was also significant towards our respondent's behavioural intention (\u03b2=0.34), indicating that there is a little limitation for students to use LGC as part of their learning activity. \u00a9 2020 Kassel University Press GmbH.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Nowadays, learning media has developed rapidly, opening infinite possibilities for students to access their educational materials. Learner's Generated Content (LGC) is one of the emerging learning media that showed interesting promises. LGC is based on the concept of User Generated Content; many advantages of UGC also existed in LGC: speed, collaboration, and the diversity of contents. Although past researches have already proven that LGC has positive effects on the educational process, mainly, these previous researches focused only on the perspective of the educators. This study questioned how today's students, mostly comprised of Generation Z, see LGC. Employing the Theory of Planned Behaviour (TPB), we revealed several statistical results followed by managerial interpretations. Attitude (AT) was shown to have the highest correlation with Generation Z's students (\u03b2=0.43), educators could utilise this fact; they can be more reassured when implementing LGC in their future curriculum. The Perceived Behavioral Control (PBC) was also significant towards our respondent's behavioural intention (\u03b2=0.34), indicating that there is a little limitation for students to use LGC as part of their learning activity. \u00a9 2020 Kassel University Press GmbH."
        ]
    },
    {
        "judul":[
            "Long term evolution (lte) network planning in jakarta-cikampek elevated toll"
        ],
        "penulis":"Nursafitri, Dennisa Aliffa;Usman, Uke Kurniawan;Maulana, M. Irfan;Save all to author list",
        "tahun":2020,
        "sdgs":[
            "Motorized vehicles user, especially those who use the four wheels, who often pass the Jakarta-Cikampek toll road, may often have difficulty connecting to their cellular operator network services, which may be due to the density of users and the influence of the condition of the area which is classified as open space. Along with the increase of users passing through the Cikampek Toll Road, the construction of the overpass on the Jakarta-Cikampek route was held as a form of anticipation of traffic congestion. With this condition, the number of devices requiring network services in the area will also increase. Therefore, in this research will carry out network planning for the Cikampek elevated toll area. Network planning in this research will carry out by conducting capacity planning and coverage planning. The data that will be used for the planning will be base on Cikampek toll users, also the population of the cities around Cikampek elevated toll route. Then, from the data obtained will be use for calculations in coverage and capacity planning for the elevated toll that is being built. With this planning, it is known the minimum site of 8 to fulfilled the service to fulfilled the need of the users. By doing the simulation using Atoll software, was measure the quality of the network from the planning. With the SINR average of 8.23 dB, throughput average of 31.99 Mbps, and BLER average of 0,01%.  \u00a9 2020 IEEE.",
            "PlumX metricsPlumX metrics (opens in new window)"
        ],
        "abstrak":[
            "Motorized vehicles user, especially those who use the four wheels, who often pass the Jakarta-Cikampek toll road, may often have difficulty connecting to their cellular operator network services, which may be due to the density of users and the influence of the condition of the area which is classified as open space. Along with the increase of users passing through the Cikampek Toll Road, the construction of the overpass on the Jakarta-Cikampek route was held as a form of anticipation of traffic congestion. With this condition, the number of devices requiring network services in the area will also increase. Therefore, in this research will carry out network planning for the Cikampek elevated toll area. Network planning in this research will carry out by conducting capacity planning and coverage planning. The data that will be used for the planning will be base on Cikampek toll users, also the population of the cities around Cikampek elevated toll route. Then, from the data obtained will be use for calculations in coverage and capacity planning for the elevated toll that is being built. With this planning, it is known the minimum site of 8 to fulfilled the service to fulfilled the need of the users. By doing the simulation using Atoll software, was measure the quality of the network from the planning. With the SINR average of 8.23 dB, throughput average of 31.99 Mbps, and BLER average of 0,01%.  \u00a9 2020 IEEE."
        ]
    }
]